[{"Q_Title":"Does Python have an “or equals” function like ||= in Ruby?","A_Content":"  The accepted answer is good for dicts, but the title seeks a general equivalent to Ruby's ||= operator.  A common way to do something like ||= in Python is  x = x or new_value      ","Language":"Python","Tags":["python","ruby"],"URL":"https://stackoverflow.com/questions/3929433/does-python-have-an-or-equals-function-like-in-ruby","A_Votes":"138","_type":"dict","isAccepted":"Yes","Q_Content":"    If not, what is the best way to do this?  Right now I'm doing (for a django project):  if not 'thing_for_purpose' in request.session:     request.session['thing_for_purpose'] = 5   but its pretty awkward. In Ruby it would be:  request.session['thing_for_purpose'] ||= 5   which is much nicer.     ","Q_Votes":"54"},{"Q_Title":"Does Python have an “or equals” function like ||= in Ruby?","A_Content":"  dict has setdefault().  So if request.session is a dict:  request.session.setdefault('thing_for_purpose', 5)      ","Language":"Python","Tags":["python","ruby"],"URL":"https://stackoverflow.com/questions/3929433/does-python-have-an-or-equals-function-like-in-ruby","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    If not, what is the best way to do this?  Right now I'm doing (for a django project):  if not 'thing_for_purpose' in request.session:     request.session['thing_for_purpose'] = 5   but its pretty awkward. In Ruby it would be:  request.session['thing_for_purpose'] ||= 5   which is much nicer.     ","Q_Votes":"54"},{"Q_Title":"Does Python have an “or equals” function like ||= in Ruby?","A_Content":"  Setting a default makes sense if you're doing it in a middleware or something, but if you need a default value in the context of one request:  request.session.get('thing_for_purpose', 5) # gets a default   bonus: here's how to really do an ||= in Python.  def test_function(self, d=None):     'a simple test function'     d = d or {}      # ... do things with d and return ...      ","Language":"Python","Tags":["python","ruby"],"URL":"https://stackoverflow.com/questions/3929433/does-python-have-an-or-equals-function-like-in-ruby","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    If not, what is the best way to do this?  Right now I'm doing (for a django project):  if not 'thing_for_purpose' in request.session:     request.session['thing_for_purpose'] = 5   but its pretty awkward. In Ruby it would be:  request.session['thing_for_purpose'] ||= 5   which is much nicer.     ","Q_Votes":"54"},{"Q_Title":"Does Python have an “or equals” function like ||= in Ruby?","A_Content":"  Precise answer: No.  Python does not have a single built-in operator op that can translate x = x or y into x op y.  But, it almost does.  The bitwise or-equals operator (|=) will function as described above if both operands are being treated as booleans, with a caveat. (What's the caveat? Answer is below of course.)  First, the basic demonstration of functionality:  x = True x     Out[141]: True  x |= True x     Out[142]: True  x |= False x     Out[143]: True  x &= False x     Out[144]: False  x &= True x     Out[145]: False  x |= False x     Out[146]: False  x |= True x    Out[147]: True   The caveat is due python not being strictly-typed, and thus even if the values are being treated as booleans in an expression they will not be short-circuited if given to a bitwise operator.  For example, suppose we had a boolean function which clears a list and returns True iff there were elements deleted:  def  my_clear_list(lst):     if not lst:         return False     else:         del lst[:]         return True   Now we can see the short-circuited behavior as so:  x = True lst = [1, 2, 3] x = x or my_clear_list(lst) print(x, lst)  Output: True [1, 2, 3]   However, switching the or to a bitwise or (|) removes the short-circuit, so the function my_clear_list executes.  x = True lst = [1, 2, 3] x = x | my_clear_list(lst) print(x, lst)  Output: True []   Above, x = x | my_clear_list(lst) is equivalent to x |= my_clear_list(lst).     ","Language":"Python","Tags":["python","ruby"],"URL":"https://stackoverflow.com/questions/3929433/does-python-have-an-or-equals-function-like-in-ruby","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    If not, what is the best way to do this?  Right now I'm doing (for a django project):  if not 'thing_for_purpose' in request.session:     request.session['thing_for_purpose'] = 5   but its pretty awkward. In Ruby it would be:  request.session['thing_for_purpose'] ||= 5   which is much nicer.     ","Q_Votes":"54"},{"Q_Title":"Does Python have an “or equals” function like ||= in Ruby?","A_Content":"  In general, you can use dict[key] = dict.get(key, 0) + val.      ","Language":"Python","Tags":["python","ruby"],"URL":"https://stackoverflow.com/questions/3929433/does-python-have-an-or-equals-function-like-in-ruby","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    If not, what is the best way to do this?  Right now I'm doing (for a django project):  if not 'thing_for_purpose' in request.session:     request.session['thing_for_purpose'] = 5   but its pretty awkward. In Ruby it would be:  request.session['thing_for_purpose'] ||= 5   which is much nicer.     ","Q_Votes":"54"},{"Q_Title":"Loop through a list in Python and modify it [duplicate]","A_Content":"  This is one of the gotchas! of python, that can escape beginners.  The words[:] is the magic sauce here.   Observe:  >>> words =  ['cat', 'window', 'defenestrate'] >>> words2 = words[:] >>> words2.insert(0, 'hello') >>> words2 ['hello', 'cat', 'window', 'defenestrate'] >>> words ['cat', 'window', 'defenestrate']   And now without the [:]:  >>> words =  ['cat', 'window', 'defenestrate'] >>> words2 = words >>> words2.insert(0, 'hello') >>> words2 ['hello', 'cat', 'window', 'defenestrate'] >>> words ['hello', 'cat', 'window', 'defenestrate']   The main thing to note here is that words[:] returns a copy of the existing list, so you are iterating over a copy, which is not modified.   You can check whether you are referring to the same lists using id():  In the first case:  >>> words2 = words[:] >>> id(words2) 4360026736 >>> id(words) 4360188992 >>> words2 is words False   In the second case:  >>> id(words2) 4360188992 >>> id(words) 4360188992 >>> words2 is words True   It is worth noting that [i:j] is called the slicing operator, and what it does is it returns a fresh copy of the list starting from index i, upto (but not including) index j.  So, words[0:2] gives you  >>> words[0:2] ['hello', 'cat']   Omitting the starting index means it defaults to 0, while omitting the last index means it defaults to len(words), and the end result is that you receive a copy of the entire list.    If you want to make your code a little more readable, I recommend the copy module.  from copy import copy   words = ['cat', 'window', 'defenestrate'] for w in copy(words):     if len(w) > 6:         words.insert(0, w) print(words)   This basically does the same thing as your first code snippet, and is much more readable.  Alternatively (as mentioned by DSM in the comments) and on python >=3, you may also use words.copy() which does the same thing.      ","Language":"Python","Tags":["python","list","for-loop","iteration"],"URL":"https://stackoverflow.com/questions/44633798/loop-through-a-list-in-python-and-modify-it","A_Votes":"78","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              What is the difference between list and list[:] in python?                                        6 answers                                          This code is from Python's Documentation. I'm a little confused.  words = ['cat', 'window', 'defenestrate'] for w in words[:]:     if len(w) > 6:         words.insert(0, w) print(words)   And the following is what I thought at first:  words = ['cat', 'window', 'defenestrate'] for w in words:     if len(w) > 6:         words.insert(0, w) print(words)   Why does this code create a infinite loop and the first one doesn't?     ","Q_Votes":"55"},{"Q_Title":"Loop through a list in Python and modify it [duplicate]","A_Content":"  words[:] copies all the elements in words into a new list. So when you iterate over words[:], you're actually iterating over all the elements that words currently has. So when you modify words, the effects of those modifications are not visible in words[:] (because you called on words[:] before starting to modify words)  In the latter example, you are iterating over words, which means that any changes you make to words is indeed visible to your iterator. As a result, when you insert into index 0 of words, you \"bump up\" every other element in words by one index. So when you move on to the next iteration of your for-loop, you'll get the element at the next index of words, but that's just the element that you just saw (because you inserted an element at the beginning of the list, moving all the other element up by an index).  To see this in action, try the following code:  words = ['cat', 'window', 'defenestrate'] for w in words:     print(\"The list is:\", words)     print(\"I am looking at this word:\", w)     if len(w) > 6:         print(\"inserting\", w)         words.insert(0, w)         print(\"the list now looks like this:\", words) print(words)      ","Language":"Python","Tags":["python","list","for-loop","iteration"],"URL":"https://stackoverflow.com/questions/44633798/loop-through-a-list-in-python-and-modify-it","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              What is the difference between list and list[:] in python?                                        6 answers                                          This code is from Python's Documentation. I'm a little confused.  words = ['cat', 'window', 'defenestrate'] for w in words[:]:     if len(w) > 6:         words.insert(0, w) print(words)   And the following is what I thought at first:  words = ['cat', 'window', 'defenestrate'] for w in words:     if len(w) > 6:         words.insert(0, w) print(words)   Why does this code create a infinite loop and the first one doesn't?     ","Q_Votes":"55"},{"Q_Title":"Loop through a list in Python and modify it [duplicate]","A_Content":"  (In addition to @Coldspeed answer)  Look at the below examples:  words = ['cat', 'window', 'defenestrate'] words2 = words words2 is words   results: True  It means names word and words2 refer to the same object.  words = ['cat', 'window', 'defenestrate'] words2 = words[:] words2 is words   results: False  In this case, we have created the new object.     ","Language":"Python","Tags":["python","list","for-loop","iteration"],"URL":"https://stackoverflow.com/questions/44633798/loop-through-a-list-in-python-and-modify-it","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              What is the difference between list and list[:] in python?                                        6 answers                                          This code is from Python's Documentation. I'm a little confused.  words = ['cat', 'window', 'defenestrate'] for w in words[:]:     if len(w) > 6:         words.insert(0, w) print(words)   And the following is what I thought at first:  words = ['cat', 'window', 'defenestrate'] for w in words:     if len(w) > 6:         words.insert(0, w) print(words)   Why does this code create a infinite loop and the first one doesn't?     ","Q_Votes":"55"},{"Q_Title":"Loop through a list in Python and modify it [duplicate]","A_Content":"  Let's have a look at iterator and iterables:     An iterable is an object that has an __iter__ method which returns an   iterator, or which defines a __getitem__ method that can take   sequential indexes starting from zero (and raises an IndexError when   the indexes are no longer valid). So an iterable is an object that you   can get an iterator from.   An iterator is an object with a next (Python 2) or __next__ (Python 3) method.  iter(iterable) returns iterator object, and list_obj[:] returns a new list object, exact copy of list_object.  In your first case:  for w in words[:]   The for loop will iterate over new copy of the list not the original words. Any change in words has no effect on loop iteration, and the loop terminates normally.  This is how the loop does its work:   loop calls iter method on iterable and iterates over the iterator loop calls next method on iterator object to get next item from iterator. This step is repeated until there are no more elements left loop terminates when a StopIteration exception is raised.   In your second case:  words = ['cat', 'window', 'defenestrate'] for w in words:     if len(w) > 6:         words.insert(0, w) print(words)   You are iterating over the original list words and adding elements to words have a direct impact on the iterator object. So every time your words is updated, the corresponding iterator object is also updated and therefore creates an infinite loop.   Look at this:   >>> l = [2, 4, 6, 8] >>> i = iter(l) # returns list_iterator object which has next method >>> next(i) 2 >>> next(i) 4 >>> l.insert(2, 'A') >>> next(i) 'A'   Every time you update your original list before StopIteration you will get the updated iterator and next returns accordingly. That's why your loop runs infinitely.  For more on iteration and the iteration protocol you can look here.     ","Language":"Python","Tags":["python","list","for-loop","iteration"],"URL":"https://stackoverflow.com/questions/44633798/loop-through-a-list-in-python-and-modify-it","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              What is the difference between list and list[:] in python?                                        6 answers                                          This code is from Python's Documentation. I'm a little confused.  words = ['cat', 'window', 'defenestrate'] for w in words[:]:     if len(w) > 6:         words.insert(0, w) print(words)   And the following is what I thought at first:  words = ['cat', 'window', 'defenestrate'] for w in words:     if len(w) > 6:         words.insert(0, w) print(words)   Why does this code create a infinite loop and the first one doesn't?     ","Q_Votes":"55"},{"Q_Title":"How to check the TEMPLATE_DEBUG flag in a django template?","A_Content":"  Assuming you haven't set TEMPLATE_CONTEXT_PROCESSORS to some other value in settings.py, Django will automatically load the debug context preprocessor (as noted here). This means that you will have access to a variable called debug in your templates if settings.DEBUG is true and your local machine's IP address (which can simply be 127.0.0.1) is set in the variable settings.INTERNAL_IPS (which is described here). settings.INTERNAL_IPS is a tuple or list of IP addresses that Django should recognize as \"internal\".     ","Language":"Python","Tags":["python","django","templates"],"URL":"https://stackoverflow.com/questions/1271631/how-to-check-the-template-debug-flag-in-a-django-template","A_Votes":"66","_type":"dict","isAccepted":"Yes","Q_Content":"    Do you know if it is possible to know in a django template if the TEMPLATE_DEBUG flag is set?  I would like to disable my google analytics script when I am running my django app on my development machine. Something like a {% if debug %} template tag would be perfect. Unfortunately, I didn't find something like that in the documentation.  For sure, I can add this flag to the context but I would like to know if there is a better way to do that.     ","Q_Votes":"55"},{"Q_Title":"How to check the TEMPLATE_DEBUG flag in a django template?","A_Content":"  If modifying INTERNAL_IPS is not possible/suitable, you can do this with a context processor:  in myapp/context_processors.py:  from django.conf import settings  def debug(context):   return {'DEBUG': settings.DEBUG}   in settings.py:  TEMPLATE_CONTEXT_PROCESSORS = (     ...     'myapp.context_processors.debug', )   Then in my templates, simply:   {% if DEBUG %} .header { background:#f00; } {% endif %}      ","Language":"Python","Tags":["python","django","templates"],"URL":"https://stackoverflow.com/questions/1271631/how-to-check-the-template-debug-flag-in-a-django-template","A_Votes":"51","_type":"dict","isAccepted":"No","Q_Content":"    Do you know if it is possible to know in a django template if the TEMPLATE_DEBUG flag is set?  I would like to disable my google analytics script when I am running my django app on my development machine. Something like a {% if debug %} template tag would be perfect. Unfortunately, I didn't find something like that in the documentation.  For sure, I can add this flag to the context but I would like to know if there is a better way to do that.     ","Q_Votes":"55"},{"Q_Title":"How to check the TEMPLATE_DEBUG flag in a django template?","A_Content":"  Django 1.9 settings.py:  INTERNAL_IPS = (     '127.0.0.1', )   Templates:  {% if debug %}   https://docs.djangoproject.com/en/1.9/ref/settings/#std:setting-INTERNAL_IPS says:     A list of IP addresses, as strings, that:         Allow the debug() context processor to add some variables to the template context.      The debug context processor is in the default settings.py.     ","Language":"Python","Tags":["python","django","templates"],"URL":"https://stackoverflow.com/questions/1271631/how-to-check-the-template-debug-flag-in-a-django-template","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    Do you know if it is possible to know in a django template if the TEMPLATE_DEBUG flag is set?  I would like to disable my google analytics script when I am running my django app on my development machine. Something like a {% if debug %} template tag would be perfect. Unfortunately, I didn't find something like that in the documentation.  For sure, I can add this flag to the context but I would like to know if there is a better way to do that.     ","Q_Votes":"55"},{"Q_Title":"How to check the TEMPLATE_DEBUG flag in a django template?","A_Content":"  If you haven't already, it always helps to see if/how others have dealt with same issue on djangosnippets. The most recent snippet working with analytics tag is 1656: http://www.djangosnippets.org/snippets/1656/  What is nice about this solution is that it allows you to keep your GOOGLE_ANALYTICS_CODE = xxxxxx in local_settings.py in the case rest of your source is public, your key remains private. In addition it goes an extra step to not use analytics for logged in users.     Includes the Javascript for Google Analytics. Will not show Google Analytics code when DEBUG is on or to staff users.      Use {% googleanalyticsjs %} in your templates.      You must set something like  GOOGLE_ANALYTICS_CODE = \"UA-1234567-1\"       in your settings file.      Assumes 'user' in your template variables is request.user, which it will be if you use:  return render_to_response('template.html',{ }, context_instance=RequestContext(request))       (Assuming django.core.context_processors.auth is in TEMPLATE_CONTEXT_PROCESSORS, which it is by default)        from django import template import settings register = template.Library()   class ShowGoogleAnalyticsJS(template.Node):   def render(self, context):       code =  getattr(settings, \"GOOGLE_ANALYTICS_CODE\", False)       if not code:           return \"<!-- Goggle Analytics not included because you haven't set the settings.GOOGLE_ANALYTICS_CODE variable! -->\"        if 'user' in context and context['user'] and context['user'].is_staff:           return \"<!-- Goggle Analytics not included because you are a staff user! -->\"        if settings.DEBUG:           return \"<!-- Goggle Analytics not included because you are in Debug mode! -->\"        return \"\"\"       <script type=\"text/javascript\">           var gaJsHost = ((\"https:\" == document.location.protocol) ? \"https://ssl.\" : \"http://www.\");           document.write(unescape(\"%3Cscript src='\" + gaJsHost + \"google-analytics.com/ga.js'             type='text/javascript'%3E%3C/script%3E\"));       </script>       <script type=\"text/javascript\">           try {           var pageTracker = _gat._getTracker('\"\"\" + str(code) + \"\"\"');           pageTracker._trackPageview();       } catch(err) {}</script>       \"\"\"  def googleanalyticsjs(parser, token):   return ShowGoogleAnalyticsJS()  show_common_data = register.tag(googleanalyticsjs)       ","Language":"Python","Tags":["python","django","templates"],"URL":"https://stackoverflow.com/questions/1271631/how-to-check-the-template-debug-flag-in-a-django-template","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Do you know if it is possible to know in a django template if the TEMPLATE_DEBUG flag is set?  I would like to disable my google analytics script when I am running my django app on my development machine. Something like a {% if debug %} template tag would be perfect. Unfortunately, I didn't find something like that in the documentation.  For sure, I can add this flag to the context but I would like to know if there is a better way to do that.     ","Q_Votes":"55"},{"Q_Title":"How to check the TEMPLATE_DEBUG flag in a django template?","A_Content":"  {% if debug %} can do the trick but only if you pass RequestContext instead of Context. Additionally, debug is not a boolean flag, its a function that when evaluated while DEBUG = True return some debugging information. This can be unnecessary overhead for your template.  Personally, I do this trick instead.  {% if request.META.HTTP_HOST == \"127.0.0.1:8000\" %}   This will always work but instead of relying on both DEBUG flag and INTERNAL_IP, it just work for the hard coded IP.     ","Language":"Python","Tags":["python","django","templates"],"URL":"https://stackoverflow.com/questions/1271631/how-to-check-the-template-debug-flag-in-a-django-template","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Do you know if it is possible to know in a django template if the TEMPLATE_DEBUG flag is set?  I would like to disable my google analytics script when I am running my django app on my development machine. Something like a {% if debug %} template tag would be perfect. Unfortunately, I didn't find something like that in the documentation.  For sure, I can add this flag to the context but I would like to know if there is a better way to do that.     ","Q_Votes":"55"},{"Q_Title":"How to check the TEMPLATE_DEBUG flag in a django template?","A_Content":"  You will need to add the DEBUG flag to your context_processors.  There may not even be an alternative way. At least, none that I know of.     ","Language":"Python","Tags":["python","django","templates"],"URL":"https://stackoverflow.com/questions/1271631/how-to-check-the-template-debug-flag-in-a-django-template","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Do you know if it is possible to know in a django template if the TEMPLATE_DEBUG flag is set?  I would like to disable my google analytics script when I am running my django app on my development machine. Something like a {% if debug %} template tag would be perfect. Unfortunately, I didn't find something like that in the documentation.  For sure, I can add this flag to the context but I would like to know if there is a better way to do that.     ","Q_Votes":"55"},{"Q_Title":"Why does Python have a limit on the number of static blocks that can be nested?","A_Content":"  This limit not only applies to for loops, but to all other control flow blocks as well. The limit for the number of nested control flow blocks is defined inside of code.h with a constant named CO_MAXBLOCKS:  #define CO_MAXBLOCKS 20 /* Max static block nesting within a function */   This constant is used to set the maximum size for the stack Python uses to execute exceptions and loops named blockstack. This limit is imposed upon all frame objects and is shown in frameobject.h:  int blockstack[CO_MAXBLOCKS];       /* Walking the 'finally' blocks */   The most likely reason for this limit is to keep memory usage at a sane level when executing nested blocks. It's probably similar to the limit Python imposes on recursive calls. This limit can be seen being enforced in compile.c:  if (c->u->u_nfblocks >= CO_MAXBLOCKS) {     PyErr_SetString(PyExc_SyntaxError,                     \"too many statically nested blocks\");     return 0; }   A more concrete answer as to why Python has this specfic limit and why they cannot get rid of it, was given by Michael Hudson in a 2004 Python mailing list letter:     Spot on.  This has to do with the 'blockstack', very much an internal   detail to Python's implementation.  We'd like to get rid of it (not   because we want to let people write code with more than 20 nested for   loops :-) but it's not especially easy (finally: blocks are the   biggest problem).   Note that in Python 2.6 and lower, breaking the maximum number of nested loops would've cause a SystemError not a SyntaxError. This was changed however  in Python 3 and back-patched to Python 2.7 so a SyntaxError would be raised instead. This was documented in #issue 27514:     Issue #27514: Make having too many statically nested blocks a SyntaxError     instead of SystemError.   The reason for this change in exception types was given by Serhiy Storchaka :     [...] SystemError is not an exception that should be raised. SystemError is for errors that can't be occurred in normal case. It should only be caused by incorrect use of C API or hacking Python internals. I think SyntaxError is more appropriate in this case [...].      ","Language":"Python","Tags":["python","nested-loops","language-implementation"],"URL":"https://stackoverflow.com/questions/44972719/why-does-python-have-a-limit-on-the-number-of-static-blocks-that-can-be-nested","A_Votes":"70","_type":"dict","isAccepted":"Yes","Q_Content":"    The number of statically nested blocks in Python is limited to 20. That is, nesting 19 for loops will be fine (although excessively time consuming; O(n^19) is insane), but nesting 20 will fail with:  SyntaxError: too many statically nested blocks   What is the underlying reason for having such a limit? Is there a way to increase the limit?     ","Q_Votes":"56"},{"Q_Title":"Why does Python have a limit on the number of static blocks that can be nested?","A_Content":"  This has to do with the blockstack, which is a stack of the byte code addresses, and is used to execute code blocks such as loops and exceptions.  It just so happens that a version of C (older than C99) had set this limit to 20, and since the CPython interpreter is built with C, the same convention has been followed:  #define CO_MAXBLOCKS 20 /* Max static block nesting within a function */   The constant 20 seems to be set out of convention, and nothing more.  [Links courtesy Christian Dean.]    Why is the limit 20?  If the argument of convention isn't convincing, then take a look at The Zen of Python:  In [4]: import this The Zen of Python, by Tim Peters  ... Flat is better than nested. ...     How can you increase this value?  Since this value is a hardcoded constant, the only way to change it to effect in your programs is to rebuild your python distribution and run your script on the new build.    Download the cpython source code from github Navigate to cpython/Include/code.h Change the value of CO_MAXBLOCKS to anything greater than 20 Recompile Python (disable tests, they'll complain)      ","Language":"Python","Tags":["python","nested-loops","language-implementation"],"URL":"https://stackoverflow.com/questions/44972719/why-does-python-have-a-limit-on-the-number-of-static-blocks-that-can-be-nested","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    The number of statically nested blocks in Python is limited to 20. That is, nesting 19 for loops will be fine (although excessively time consuming; O(n^19) is insane), but nesting 20 will fail with:  SyntaxError: too many statically nested blocks   What is the underlying reason for having such a limit? Is there a way to increase the limit?     ","Q_Votes":"56"},{"Q_Title":"Why does Python have a limit on the number of static blocks that can be nested?","A_Content":"  See answer here: too many statically nested blocks python You cannot increase it as it is builtin to the python syntax. The limit applies to any kind of code stack (exceptions, loops, etc.) and is a decision by the designers (presumably to keep memory usage reasonable). One weird thing is that here: https://github.com/python/cpython/blob/6f0eb93183519024cb360162bdd81b9faec97ba6/Include/code.h#L95 it says 20 is the max number in a function. But I just tried nesting 23 for loops, not inside a function, and you still get the error.     ","Language":"Python","Tags":["python","nested-loops","language-implementation"],"URL":"https://stackoverflow.com/questions/44972719/why-does-python-have-a-limit-on-the-number-of-static-blocks-that-can-be-nested","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    The number of statically nested blocks in Python is limited to 20. That is, nesting 19 for loops will be fine (although excessively time consuming; O(n^19) is insane), but nesting 20 will fail with:  SyntaxError: too many statically nested blocks   What is the underlying reason for having such a limit? Is there a way to increase the limit?     ","Q_Votes":"56"},{"Q_Title":"Examples for string find in Python","A_Content":"  you can use str.index too:  >>> 'sdfasdf'.index('cc') Traceback (most recent call last):   File \"<pyshell#144>\", line 1, in <module>     'sdfasdf'.index('cc') ValueError: substring not found >>> 'sdfasdf'.index('df') 1      ","Language":"Python","Tags":["python","string","find"],"URL":"https://stackoverflow.com/questions/674764/examples-for-string-find-in-python","A_Votes":"40","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to find some examples but no luck. Does anyone know of some examples on the net? I would like to know what it returns when it can't find, and how to specify from start to end, which I guess is going to be 0, -1.     ","Q_Votes":"56"},{"Q_Title":"Examples for string find in Python","A_Content":"  I'm not sure what you're looking for, do you mean find()?  >>> x = \"Hello World\" >>> x.find('World') 6 >>> x.find('Aloha'); -1      ","Language":"Python","Tags":["python","string","find"],"URL":"https://stackoverflow.com/questions/674764/examples-for-string-find-in-python","A_Votes":"105","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to find some examples but no luck. Does anyone know of some examples on the net? I would like to know what it returns when it can't find, and how to specify from start to end, which I guess is going to be 0, -1.     ","Q_Votes":"56"},{"Q_Title":"Examples for string find in Python","A_Content":"  From here:  str.find(sub[, start[, end]])     Return the lowest index in the string where substring sub is found, such that sub is contained in the range [start, end]. Optional arguments start and end are interpreted as in slice notation. Return -1 if sub is not found.\"  So, some examples:  >>> str = \"abcdefioshgoihgs sijsiojs \" >>> str.find('a') 0 >>> str.find('g') 10 >>> str.find('s',11) 15 >>> str.find('s',15) 15 >>> str.find('s',16) 17 >>> str.find('s',11,14) -1      ","Language":"Python","Tags":["python","string","find"],"URL":"https://stackoverflow.com/questions/674764/examples-for-string-find-in-python","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to find some examples but no luck. Does anyone know of some examples on the net? I would like to know what it returns when it can't find, and how to specify from start to end, which I guess is going to be 0, -1.     ","Q_Votes":"56"},{"Q_Title":"Examples for string find in Python","A_Content":"  Honestly, this is the sort of situation where I just open up Python on the command line and start messing around:   >>> x = \"Dana Larose is playing with find()\"  >>> x.find(\"Dana\")  0  >>> x.find(\"ana\")  1  >>> x.find(\"La\")  5  >>> x.find(\"La\", 6)  -1   Python's interpreter makes this sort of experimentation easy.  (Same goes for other languages with a similar interpreter)     ","Language":"Python","Tags":["python","string","find"],"URL":"https://stackoverflow.com/questions/674764/examples-for-string-find-in-python","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to find some examples but no luck. Does anyone know of some examples on the net? I would like to know what it returns when it can't find, and how to specify from start to end, which I guess is going to be 0, -1.     ","Q_Votes":"56"},{"Q_Title":"Examples for string find in Python","A_Content":"  If you want to search for the last instance of a string in a text, you can run rfind.  Example:      s=\"Hello\"    print s.rfind('l')   output: 3   *no import needed  Complete syntax:  stringEx.rfind(substr, beg=0, end=len(stringEx))      ","Language":"Python","Tags":["python","string","find"],"URL":"https://stackoverflow.com/questions/674764/examples-for-string-find-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to find some examples but no luck. Does anyone know of some examples on the net? I would like to know what it returns when it can't find, and how to specify from start to end, which I guess is going to be 0, -1.     ","Q_Votes":"56"},{"Q_Title":"Examples for string find in Python","A_Content":"  find(      sub[, start[, end]])  Return the lowest index in the string where substring sub is found, such that sub is contained in the range [start, end]. Optional arguments start and end are interpreted as in slice notation. Return -1 if sub is not found.   From the docs.     ","Language":"Python","Tags":["python","string","find"],"URL":"https://stackoverflow.com/questions/674764/examples-for-string-find-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to find some examples but no luck. Does anyone know of some examples on the net? I would like to know what it returns when it can't find, and how to specify from start to end, which I guess is going to be 0, -1.     ","Q_Votes":"56"},{"Q_Title":"Examples for string find in Python","A_Content":"  Try this:  with open(file_dmp_path, 'rb') as file: fsize = bsize = os.path.getsize(file_dmp_path) word_len = len(SEARCH_WORD) while True:     p = file.read(bsize).find(SEARCH_WORD)     if p > -1:         pos_dec = file.tell() - (bsize - p)         file.seek(pos_dec + word_len)         bsize = fsize - file.tell()     if file.tell() < fsize:         seek = file.tell() - word_len + 1         file.seek(seek)     else:         break      ","Language":"Python","Tags":["python","string","find"],"URL":"https://stackoverflow.com/questions/674764/examples-for-string-find-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to find some examples but no luck. Does anyone know of some examples on the net? I would like to know what it returns when it can't find, and how to specify from start to end, which I guess is going to be 0, -1.     ","Q_Votes":"56"},{"Q_Title":"Examples for string find in Python","A_Content":"  if x is a string and you search for y which also a string  their is two cases : case 1: y is exist in x so  x.find(y) = the index (the position) of the y in x . case 2: y is not exist so   x.find (y) = -1 this mean y is not found in x.      ","Language":"Python","Tags":["python","string","find"],"URL":"https://stackoverflow.com/questions/674764/examples-for-string-find-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to find some examples but no luck. Does anyone know of some examples on the net? I would like to know what it returns when it can't find, and how to specify from start to end, which I guess is going to be 0, -1.     ","Q_Votes":"56"},{"Q_Title":"How to print pandas DataFrame without index","A_Content":"  print df.to_string(index=False)      ","Language":"Python","Tags":["python","datetime","pandas","dataframe"],"URL":"https://stackoverflow.com/questions/24644656/how-to-print-pandas-dataframe-without-index","A_Votes":"91","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to print the whole dataframe, but I don't want to print the index  Besides, one column is datetime type, I just want to print time, not date.  The dataframe looks like:     User ID           Enter Time   Activity Number 0      123  2014-07-08 00:09:00              1411 1      123  2014-07-08 00:18:00               893 2      123  2014-07-08 00:49:00              1041   I want it print as  User ID   Enter Time   Activity Number 123         00:09:00              1411 123         00:18:00               893 123         00:49:00              1041      ","Q_Votes":"57"},{"Q_Title":"How to print pandas DataFrame without index","A_Content":"  print(df.to_csv(sep='\\t', index=False))   Or possibly:  print(df.to_csv(columns=['A', 'B', 'C'], sep='\\t', index=False))      ","Language":"Python","Tags":["python","datetime","pandas","dataframe"],"URL":"https://stackoverflow.com/questions/24644656/how-to-print-pandas-dataframe-without-index","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I want to print the whole dataframe, but I don't want to print the index  Besides, one column is datetime type, I just want to print time, not date.  The dataframe looks like:     User ID           Enter Time   Activity Number 0      123  2014-07-08 00:09:00              1411 1      123  2014-07-08 00:18:00               893 2      123  2014-07-08 00:49:00              1041   I want it print as  User ID   Enter Time   Activity Number 123         00:09:00              1411 123         00:18:00               893 123         00:49:00              1041      ","Q_Votes":"57"},{"Q_Title":"How to print pandas DataFrame without index","A_Content":"  If you just want a string/json to print it can be solved with:  print(df.to_string(index=False))  Buf if you want to serialize the data too or even send to a MongoDB, would be better to do something like:  document = df.to_dict(orient='list')  There are 6 ways by now to orient the data, check more in the panda docs which better fits you.     ","Language":"Python","Tags":["python","datetime","pandas","dataframe"],"URL":"https://stackoverflow.com/questions/24644656/how-to-print-pandas-dataframe-without-index","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I want to print the whole dataframe, but I don't want to print the index  Besides, one column is datetime type, I just want to print time, not date.  The dataframe looks like:     User ID           Enter Time   Activity Number 0      123  2014-07-08 00:09:00              1411 1      123  2014-07-08 00:18:00               893 2      123  2014-07-08 00:49:00              1041   I want it print as  User ID   Enter Time   Activity Number 123         00:09:00              1411 123         00:18:00               893 123         00:49:00              1041      ","Q_Votes":"57"},{"Q_Title":"Using Flask-SQLAlchemy in Blueprint models without reference to the app","A_Content":"  I believe the truest answer is that modular blueprints shouldn't concern themselves directly with data access, but instead rely on the application providing a compatible implementation.  So given your example blueprint.  from flask import current_app, Blueprint, render_template  flat_pages = Blueprint('flat_pages', __name__, template_folder='templates')  @flat_pages.record def record(state):     db = state.app.config.get(\"flat_pages.db\")      if db is None:         raise Exception(\"This blueprint expects you to provide \"                         \"database access through flat_pages.db\")  @flat_pages.route('/<page>') def show(page):     db = current_app.config[\"flat_pages.db\"]     page_object = db.find_page_by_name(page)     return render_template('pages/{}.html'.format(page), page=page_object)   From this, there is nothing preventing you from providing a default implementation.  def setup_default_flat_pages_db(db):     class Page(db.Model):         name = db.Column(db.String(255), primary_key=True)         title = db.Column(db.String(255))         content = db.Column(db.String(255))          def __init__(self, name, title, content):             self.name = name             self.title = title             self.content = content      class FlatPagesDBO(object):         def find_page_by_name(self, name):             return Page.query.filter_by(name=name).first()      return FlatPagesDBO()   And in your configuration.  app.config[\"flat_pages.db\"] = setup_default_flat_pages_db(db)   The above could be made cleaner by not relying in direct inheritance from db.Model and instead just use a vanilla declarative_base from sqlalchemy, but this should represent the gist of it.     ","Language":"Python","Tags":["python","design","flask","flask-sqlalchemy"],"URL":"https://stackoverflow.com/questions/13058800/using-flask-sqlalchemy-in-blueprint-models-without-reference-to-the-app","A_Votes":"33","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to create a \"modular application\" in Flask using Blueprints.  When creating models, however, I'm running into the problem of having to reference the app in order to get the db-object provided by Flask-SQLAlchemy. I'd like to be able to use some blueprints with more than one app (similar to how Django apps can be used), so this is not a good solution.*   It's possible to do a switcharoo, and have the Blueprint create the db instance, which the app then imports together with the rest of the blueprint. But then, any other blueprint wishing to create models need to import from that blueprint instead of the app.   My questions are thus:   Is there a way to let Blueprints define models without any awareness of the app they're being used in later -- and have several Blueprints come together? By this, I mean having to import the app module/package from your Blueprint. Am I wrong from the outset? Are Blueprints not meant to be independent of the app and be redistributable (à la Django apps)?   If not, then what pattern should you use to create something like that? Flask extensions? Should you simply not do it -- and maybe centralize all models/schemas à la Ruby on Rails?       Edit: I've been thinking about this myself now, and this might be more related to SQLAlchemy than Flask because you have to have the declarative_base() when declaring models. And that's got to come from somewhere, anyway!      Perhaps the best solution is to have your project's schema defined in one place and spread it around, like Ruby on Rails does. Declarative SQLAlchemy class definitions are really more like schema.rb than Django's models.py. I imagine this would also make it easier to use migrations (from alembic or sqlalchemy-migrate).     I was asked to provide an example, so let's do something simple: Say I have a blueprint describing \"flatpages\" -- simple, \"static\" content stored in the database. It uses a table with just shortname (for URLs), a title and a body. This is simple_pages/__init__.py:  from flask import Blueprint, render_template from .models import Page  flat_pages = Blueprint('flat_pages', __name__, template_folder='templates')  @flat_pages.route('/<page>') def show(page):     page_object = Page.query.filter_by(name=page).first()     return render_template('pages/{}.html'.format(page), page=page_object)   Then, it would be nice to let this blueprint define its own model (this in simple_page/models.py):  # TODO Somehow get ahold of a `db` instance without referencing the app # I might get used in!  class Page(db.Model):     name = db.Column(db.String(255), primary_key=True)     title = db.Column(db.String(255))     content = db.Column(db.String(255))      def __init__(self, name, title, content):         self.name = name         self.title = title         self.content = content     This question is related to:   Flask-SQLAlchemy import/context issue What's your folder layout for a Flask app divided in modules?   And various others, but all replies seem to rely on import the app's db instance, or doing the reverse. The \"Large app how to\" wiki page also uses the \"import your app in your blueprint\" pattern.  * Since the official documentation shows how to create routes, views, templates and assets in a Blueprint without caring about what app it's \"in\", I've assumed that Blueprints should, in general, be reusable across apps. However, this modularity doesn't seem that useful without also having independent models.  Since Blueprints can be hooked into an app more than once, it might simply be the wrong approach to have models in Blueprints?     ","Q_Votes":"58"},{"Q_Title":"Using Flask-SQLAlchemy in Blueprint models without reference to the app","A_Content":"  I have similar needs of making Blueprints completely modular and having no reference to the App. I came up with a possibly clean solution but I'm not sure how correct it is and what its limitations are.  The idea is to create a separate db object (db = SQLAlchemy()) inside the blueprint and call the init_app() and create_all() methods from where the root app is created.  Here's some sample code to show how the project is structured: The app is called jobs and the blueprint is called status and it is stored inside the blueprints folder.  blueprints.status.models.py  from flask_sqlalchemy import SQLAlchemy db = SQLAlchemy()  # <--- The db object belonging to the blueprint  class Status(db.Model):     __tablename__ = 'status'     id = db.Column(db.Integer, primary_key=True)     job_id = db.Column(db.Integer)     status = db.Column(db.String(120))   models.py  from flask_sqlalchemy import SQLAlchemy db = SQLAlchemy()  # <--- The db object belonging to the root app  class Job(db.Model):     __tablename__ = 'job'     id = db.Column(db.Integer, primary_key=True)     state = db.Column(db.String(120)   factory.py  from .blueprints.status.models import db as status_db  # blueprint db from .blueprints.status.routes import status_handler   # blueprint handler from .models import db as root_db                      # root db from flask import Flask  def create_app():     app = Flask(__name__)      # Create database resources.     app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:////path/to/app.db'     root_db.init_app(app)     status_db.init_app(app)     # <--- Init blueprint db object.     with app.app_context():         root_db.create_all()         status_db.create_all()  # <--- Create blueprint db.      # Register blueprint routes.     app.register_blueprint(status_handler, url_prefix=\"/status\")      return app   I tested it with gunicorn with gevent worker and it works. I asked a separate question about the robustness of the solution here: Create one SQLAlchemy instance per blueprint and call create_all multiple times     ","Language":"Python","Tags":["python","design","flask","flask-sqlalchemy"],"URL":"https://stackoverflow.com/questions/13058800/using-flask-sqlalchemy-in-blueprint-models-without-reference-to-the-app","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to create a \"modular application\" in Flask using Blueprints.  When creating models, however, I'm running into the problem of having to reference the app in order to get the db-object provided by Flask-SQLAlchemy. I'd like to be able to use some blueprints with more than one app (similar to how Django apps can be used), so this is not a good solution.*   It's possible to do a switcharoo, and have the Blueprint create the db instance, which the app then imports together with the rest of the blueprint. But then, any other blueprint wishing to create models need to import from that blueprint instead of the app.   My questions are thus:   Is there a way to let Blueprints define models without any awareness of the app they're being used in later -- and have several Blueprints come together? By this, I mean having to import the app module/package from your Blueprint. Am I wrong from the outset? Are Blueprints not meant to be independent of the app and be redistributable (à la Django apps)?   If not, then what pattern should you use to create something like that? Flask extensions? Should you simply not do it -- and maybe centralize all models/schemas à la Ruby on Rails?       Edit: I've been thinking about this myself now, and this might be more related to SQLAlchemy than Flask because you have to have the declarative_base() when declaring models. And that's got to come from somewhere, anyway!      Perhaps the best solution is to have your project's schema defined in one place and spread it around, like Ruby on Rails does. Declarative SQLAlchemy class definitions are really more like schema.rb than Django's models.py. I imagine this would also make it easier to use migrations (from alembic or sqlalchemy-migrate).     I was asked to provide an example, so let's do something simple: Say I have a blueprint describing \"flatpages\" -- simple, \"static\" content stored in the database. It uses a table with just shortname (for URLs), a title and a body. This is simple_pages/__init__.py:  from flask import Blueprint, render_template from .models import Page  flat_pages = Blueprint('flat_pages', __name__, template_folder='templates')  @flat_pages.route('/<page>') def show(page):     page_object = Page.query.filter_by(name=page).first()     return render_template('pages/{}.html'.format(page), page=page_object)   Then, it would be nice to let this blueprint define its own model (this in simple_page/models.py):  # TODO Somehow get ahold of a `db` instance without referencing the app # I might get used in!  class Page(db.Model):     name = db.Column(db.String(255), primary_key=True)     title = db.Column(db.String(255))     content = db.Column(db.String(255))      def __init__(self, name, title, content):         self.name = name         self.title = title         self.content = content     This question is related to:   Flask-SQLAlchemy import/context issue What's your folder layout for a Flask app divided in modules?   And various others, but all replies seem to rely on import the app's db instance, or doing the reverse. The \"Large app how to\" wiki page also uses the \"import your app in your blueprint\" pattern.  * Since the official documentation shows how to create routes, views, templates and assets in a Blueprint without caring about what app it's \"in\", I've assumed that Blueprints should, in general, be reusable across apps. However, this modularity doesn't seem that useful without also having independent models.  Since Blueprints can be hooked into an app more than once, it might simply be the wrong approach to have models in Blueprints?     ","Q_Votes":"58"},{"Q_Title":"Using Flask-SQLAlchemy in Blueprint models without reference to the app","A_Content":"  You asked \"Are Blueprints not meant to be independent of the app and be redistributable (à la Django apps)? \"  The answer is yes. Blueprints are not similar to Django App.  If you want to use different app/configurations, then you need to use \"Application Dispatching\" and not blueprints. Read this    [1]: http://flask.pocoo.org/docs/patterns/appdispatch/#app-dispatch [1]  Also, the link here [1] http://flask.pocoo.org/docs/blueprints/#the-concept-of-blueprints [1]  It clearly says and I quote \"A blueprint in Flask is not a pluggable app because it is not actually an application – it’s a set of operations which can be registered on an application, even multiple times. Why not have multiple application objects? You can do that (see Application Dispatching), but your applications will have separate configs and will be managed at the WSGI layer.\"     ","Language":"Python","Tags":["python","design","flask","flask-sqlalchemy"],"URL":"https://stackoverflow.com/questions/13058800/using-flask-sqlalchemy-in-blueprint-models-without-reference-to-the-app","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to create a \"modular application\" in Flask using Blueprints.  When creating models, however, I'm running into the problem of having to reference the app in order to get the db-object provided by Flask-SQLAlchemy. I'd like to be able to use some blueprints with more than one app (similar to how Django apps can be used), so this is not a good solution.*   It's possible to do a switcharoo, and have the Blueprint create the db instance, which the app then imports together with the rest of the blueprint. But then, any other blueprint wishing to create models need to import from that blueprint instead of the app.   My questions are thus:   Is there a way to let Blueprints define models without any awareness of the app they're being used in later -- and have several Blueprints come together? By this, I mean having to import the app module/package from your Blueprint. Am I wrong from the outset? Are Blueprints not meant to be independent of the app and be redistributable (à la Django apps)?   If not, then what pattern should you use to create something like that? Flask extensions? Should you simply not do it -- and maybe centralize all models/schemas à la Ruby on Rails?       Edit: I've been thinking about this myself now, and this might be more related to SQLAlchemy than Flask because you have to have the declarative_base() when declaring models. And that's got to come from somewhere, anyway!      Perhaps the best solution is to have your project's schema defined in one place and spread it around, like Ruby on Rails does. Declarative SQLAlchemy class definitions are really more like schema.rb than Django's models.py. I imagine this would also make it easier to use migrations (from alembic or sqlalchemy-migrate).     I was asked to provide an example, so let's do something simple: Say I have a blueprint describing \"flatpages\" -- simple, \"static\" content stored in the database. It uses a table with just shortname (for URLs), a title and a body. This is simple_pages/__init__.py:  from flask import Blueprint, render_template from .models import Page  flat_pages = Blueprint('flat_pages', __name__, template_folder='templates')  @flat_pages.route('/<page>') def show(page):     page_object = Page.query.filter_by(name=page).first()     return render_template('pages/{}.html'.format(page), page=page_object)   Then, it would be nice to let this blueprint define its own model (this in simple_page/models.py):  # TODO Somehow get ahold of a `db` instance without referencing the app # I might get used in!  class Page(db.Model):     name = db.Column(db.String(255), primary_key=True)     title = db.Column(db.String(255))     content = db.Column(db.String(255))      def __init__(self, name, title, content):         self.name = name         self.title = title         self.content = content     This question is related to:   Flask-SQLAlchemy import/context issue What's your folder layout for a Flask app divided in modules?   And various others, but all replies seem to rely on import the app's db instance, or doing the reverse. The \"Large app how to\" wiki page also uses the \"import your app in your blueprint\" pattern.  * Since the official documentation shows how to create routes, views, templates and assets in a Blueprint without caring about what app it's \"in\", I've assumed that Blueprints should, in general, be reusable across apps. However, this modularity doesn't seem that useful without also having independent models.  Since Blueprints can be hooked into an app more than once, it might simply be the wrong approach to have models in Blueprints?     ","Q_Votes":"58"},{"Q_Title":"How to dynamically change base class of instances at runtime?","A_Content":"  Ok, again, this is not something you should normally do, this is for informational purposes only.    Where Python looks for a method on an instance object is determined by the __mro__ attribute of the class which defines that object (the M ethod R esolution O rder attribute).  Thus, if we could modify the __mro__ of Person, we'd get the desired behaviour.  Something like:  setattr(Person, '__mro__', (Person, Friendly, object))   The problem is that __mro__ is a readonly attribute, and thus setattr won't work.  Maybe if you're a Python guru there's a way around that, but clearly I fall short of guru status as I cannot think of one.  A possible workaround is to simply redefine the class:  def modify_Person_to_be_friendly():     # so that we're modifying the global identifier 'Person'     global Person      # now just redefine the class using type(), specifying that the new     # class should inherit from Friendly and have all attributes from     # our old Person class     Person = type('Person', (Friendly,), dict(Person.__dict__))   def main():     modify_Person_to_be_friendly()     p = Person()     p.hello()  # works!   What this doesn't do is modify any previously created Person instances to have the hello() method.  For example (just modifying main()):  def main():     oldperson = Person()     ModifyPersonToBeFriendly()     p = Person()     p.hello()       # works!  But:     oldperson.hello()     # does not   If the details of the type call aren't clear, then read e-satis' excellent answer on 'What is a metaclass in Python?'.     ","Language":"Python","Tags":["python","inheritance","dynamic"],"URL":"https://stackoverflow.com/questions/9539052/how-to-dynamically-change-base-class-of-instances-at-runtime","A_Votes":"32","_type":"dict","isAccepted":"Yes","Q_Content":"    This article has a snippet showing usage of __bases__ to dynamically change the inheritance hierarchy of some Python code, by adding a class to an existing classes collection of classes from which it inherits.  Ok, that's hard to read, code is probably clearer:  class Friendly:     def hello(self):         print 'Hello'  class Person: pass  p = Person() Person.__bases__ = (Friendly,) p.hello()  # prints \"Hello\"   That is, Person doesn't inherit from Friendly at the source level, but rather this inheritance relation is added dynamically at runtime by modification of the __bases__attribute of the Person class.  However, if you change Friendly and Person to be new style classes (by inheriting from object), you get the following error:  TypeError: __bases__ assignment: 'Friendly' deallocator differs from 'object'   A bit of Googling on this seems to indicate some incompatibilities between new-style and old style classes in regards to changing the inheritance hierarchy at runtime.  Specifically: \"New-style class objects don't support assignment to their bases attribute\".  My question, is it possible to make the above Friendly/Person example work using new-style classes in Python 2.7+, possibly by use of the __mro__ attribute?  Disclaimer: I fully realise that this is obscure code.  I fully realize that in real production code tricks like this tend to border on unreadable, this is purely a thought experiment, and for funzies to learn something about how Python deals with issues related to multiple inheritance.     ","Q_Votes":"59"},{"Q_Title":"How to dynamically change base class of instances at runtime?","A_Content":"  I've been struggling with this too, and was intrigued by your solution, but Python 3 takes it away from us:  AttributeError: attribute '__dict__' of 'type' objects is not writable   I actually have a legitimate need for a decorator that replaces the (single) superclass of the decorated class. It would require too lengthy a description to include here (I tried, but couldn't get it to a reasonably length and limited complexity -- it came up in the context of the use by many Python applications of an Python-based enterprise server where different applications needed slightly different variations of some of the code.)  The discussion on this page and others like it provided hints that the problem of assigning to __bases__ only occurs for classes with no superclass defined (i.e., whose only superclass is object). I was able to solve this problem (for both Python 2.7 and 3.2) by defining the classes whose superclass I needed to replace as being subclasses of a trivial class:  ## T is used so that the other classes are not direct subclasses of object, ## since classes whose base is object don't allow assignment to their __bases__ attribute.  class T: pass  class A(T):     def __init__(self):         print('Creating instance of {}'.format(self.__class__.__name__))  ## ordinary inheritance class B(A): pass  ## dynamically specified inheritance class C(T): pass  A()                 # -> Creating instance of A B()                 # -> Creating instance of B C.__bases__ = (A,) C()                 # -> Creating instance of C  ## attempt at dynamically specified inheritance starting with a direct subclass ## of object doesn't work class D: pass  D.__bases__ = (A,) D()  ## Result is: ##     TypeError: __bases__ assignment: 'A' deallocator differs from 'object'      ","Language":"Python","Tags":["python","inheritance","dynamic"],"URL":"https://stackoverflow.com/questions/9539052/how-to-dynamically-change-base-class-of-instances-at-runtime","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    This article has a snippet showing usage of __bases__ to dynamically change the inheritance hierarchy of some Python code, by adding a class to an existing classes collection of classes from which it inherits.  Ok, that's hard to read, code is probably clearer:  class Friendly:     def hello(self):         print 'Hello'  class Person: pass  p = Person() Person.__bases__ = (Friendly,) p.hello()  # prints \"Hello\"   That is, Person doesn't inherit from Friendly at the source level, but rather this inheritance relation is added dynamically at runtime by modification of the __bases__attribute of the Person class.  However, if you change Friendly and Person to be new style classes (by inheriting from object), you get the following error:  TypeError: __bases__ assignment: 'Friendly' deallocator differs from 'object'   A bit of Googling on this seems to indicate some incompatibilities between new-style and old style classes in regards to changing the inheritance hierarchy at runtime.  Specifically: \"New-style class objects don't support assignment to their bases attribute\".  My question, is it possible to make the above Friendly/Person example work using new-style classes in Python 2.7+, possibly by use of the __mro__ attribute?  Disclaimer: I fully realise that this is obscure code.  I fully realize that in real production code tricks like this tend to border on unreadable, this is purely a thought experiment, and for funzies to learn something about how Python deals with issues related to multiple inheritance.     ","Q_Votes":"59"},{"Q_Title":"How to dynamically change base class of instances at runtime?","A_Content":"  I can not vouch for the consequences, but that this code does what you want at py2.7.2.  class Friendly(object):     def hello(self):         print 'Hello'  class Person(object): pass  # we can't change the original classes, so we replace them class newFriendly: pass newFriendly.__dict__ = dict(Friendly.__dict__) Friendly = newFriendly class newPerson: pass newPerson.__dict__ = dict(Person.__dict__) Person = newPerson  p = Person() Person.__bases__ = (Friendly,) p.hello()  # prints \"Hello\"   We know that this is possible. Cool. But we'll never use it!     ","Language":"Python","Tags":["python","inheritance","dynamic"],"URL":"https://stackoverflow.com/questions/9539052/how-to-dynamically-change-base-class-of-instances-at-runtime","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    This article has a snippet showing usage of __bases__ to dynamically change the inheritance hierarchy of some Python code, by adding a class to an existing classes collection of classes from which it inherits.  Ok, that's hard to read, code is probably clearer:  class Friendly:     def hello(self):         print 'Hello'  class Person: pass  p = Person() Person.__bases__ = (Friendly,) p.hello()  # prints \"Hello\"   That is, Person doesn't inherit from Friendly at the source level, but rather this inheritance relation is added dynamically at runtime by modification of the __bases__attribute of the Person class.  However, if you change Friendly and Person to be new style classes (by inheriting from object), you get the following error:  TypeError: __bases__ assignment: 'Friendly' deallocator differs from 'object'   A bit of Googling on this seems to indicate some incompatibilities between new-style and old style classes in regards to changing the inheritance hierarchy at runtime.  Specifically: \"New-style class objects don't support assignment to their bases attribute\".  My question, is it possible to make the above Friendly/Person example work using new-style classes in Python 2.7+, possibly by use of the __mro__ attribute?  Disclaimer: I fully realise that this is obscure code.  I fully realize that in real production code tricks like this tend to border on unreadable, this is purely a thought experiment, and for funzies to learn something about how Python deals with issues related to multiple inheritance.     ","Q_Votes":"59"},{"Q_Title":"How to dynamically change base class of instances at runtime?","A_Content":"  Right of the bat, all the caveats of messing with class hierarchy dynamically are in effect.   But if it has to be done then, apparently, there is a hack that get's around the \"deallocator differs from 'object\" issue when modifying the __bases__ attribute for the new style classes.  You can define  a class object  class Object(object): pass   Which derives a class from the built-in metaclass type. That's it, now your new style classes can modify the __bases__ without any problem.  In my tests this actually worked very well as all existing (before changing the inheritance) instances of it and its derived classes felt the effect of the change including their mro getting updated.     ","Language":"Python","Tags":["python","inheritance","dynamic"],"URL":"https://stackoverflow.com/questions/9539052/how-to-dynamically-change-base-class-of-instances-at-runtime","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    This article has a snippet showing usage of __bases__ to dynamically change the inheritance hierarchy of some Python code, by adding a class to an existing classes collection of classes from which it inherits.  Ok, that's hard to read, code is probably clearer:  class Friendly:     def hello(self):         print 'Hello'  class Person: pass  p = Person() Person.__bases__ = (Friendly,) p.hello()  # prints \"Hello\"   That is, Person doesn't inherit from Friendly at the source level, but rather this inheritance relation is added dynamically at runtime by modification of the __bases__attribute of the Person class.  However, if you change Friendly and Person to be new style classes (by inheriting from object), you get the following error:  TypeError: __bases__ assignment: 'Friendly' deallocator differs from 'object'   A bit of Googling on this seems to indicate some incompatibilities between new-style and old style classes in regards to changing the inheritance hierarchy at runtime.  Specifically: \"New-style class objects don't support assignment to their bases attribute\".  My question, is it possible to make the above Friendly/Person example work using new-style classes in Python 2.7+, possibly by use of the __mro__ attribute?  Disclaimer: I fully realise that this is obscure code.  I fully realize that in real production code tricks like this tend to border on unreadable, this is purely a thought experiment, and for funzies to learn something about how Python deals with issues related to multiple inheritance.     ","Q_Votes":"59"},{"Q_Title":"How to dynamically change base class of instances at runtime?","A_Content":"  I needed a solution for this which:   Works with both Python 2 (>= 2.7) and Python 3 (>= 3.2). Lets the class bases be changed after dynamically importing a dependency. Lets the class bases be changed from unit test code. Works with types that have a custom metaclass. Still allows unittest.mock.patch to function as expected.   Here's what I came up with:  def ensure_class_bases_begin_with(namespace, class_name, base_class):     \"\"\" Ensure the named class's bases start with the base class.          :param namespace: The namespace containing the class name.         :param class_name: The name of the class to alter.         :param base_class: The type to be the first base class for the             newly created type.         :return: ``None``.          Call this function after ensuring `base_class` is         available, before using the class named by `class_name`.          \"\"\"     existing_class = namespace[class_name]     assert isinstance(existing_class, type)      bases = list(existing_class.__bases__)     if base_class is bases[0]:         # Already bound to a type with the right bases.         return     bases.insert(0, base_class)      new_class_namespace = existing_class.__dict__.copy()     # Type creation will assign the correct ‘__dict__’ attribute.     del new_class_namespace['__dict__']      metaclass = existing_class.__metaclass__     new_class = metaclass(class_name, tuple(bases), new_class_namespace)      namespace[class_name] = new_class   Used like this within the application:  # foo.py  # Type `Bar` is not available at first, so can't inherit from it yet. class Foo(object):     __metaclass__ = type      def __init__(self):         self.frob = \"spam\"      def __unicode__(self): return \"Foo\"  # … later … import bar ensure_class_bases_begin_with(         namespace=globals(),         class_name=str('Foo'),   # `str` type differs on Python 2 vs. 3.         base_class=bar.Bar)   Use like this from within unit test code:  # test_foo.py  \"\"\" Unit test for `foo` module. \"\"\"  import unittest import mock  import foo import bar  ensure_class_bases_begin_with(         namespace=foo.__dict__,         class_name=str('Foo'),   # `str` type differs on Python 2 vs. 3.         base_class=bar.Bar)   class Foo_TestCase(unittest.TestCase):     \"\"\" Test cases for `Foo` class. \"\"\"      def setUp(self):         patcher_unicode = mock.patch.object(                 foo.Foo, '__unicode__')         patcher_unicode.start()         self.addCleanup(patcher_unicode.stop)          self.test_instance = foo.Foo()          patcher_frob = mock.patch.object(                 self.test_instance, 'frob')         patcher_frob.start()         self.addCleanup(patcher_frob.stop)      def test_instantiate(self):         \"\"\" Should create an instance of `Foo`. \"\"\"         instance = foo.Foo()      ","Language":"Python","Tags":["python","inheritance","dynamic"],"URL":"https://stackoverflow.com/questions/9539052/how-to-dynamically-change-base-class-of-instances-at-runtime","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    This article has a snippet showing usage of __bases__ to dynamically change the inheritance hierarchy of some Python code, by adding a class to an existing classes collection of classes from which it inherits.  Ok, that's hard to read, code is probably clearer:  class Friendly:     def hello(self):         print 'Hello'  class Person: pass  p = Person() Person.__bases__ = (Friendly,) p.hello()  # prints \"Hello\"   That is, Person doesn't inherit from Friendly at the source level, but rather this inheritance relation is added dynamically at runtime by modification of the __bases__attribute of the Person class.  However, if you change Friendly and Person to be new style classes (by inheriting from object), you get the following error:  TypeError: __bases__ assignment: 'Friendly' deallocator differs from 'object'   A bit of Googling on this seems to indicate some incompatibilities between new-style and old style classes in regards to changing the inheritance hierarchy at runtime.  Specifically: \"New-style class objects don't support assignment to their bases attribute\".  My question, is it possible to make the above Friendly/Person example work using new-style classes in Python 2.7+, possibly by use of the __mro__ attribute?  Disclaimer: I fully realise that this is obscure code.  I fully realize that in real production code tricks like this tend to border on unreadable, this is purely a thought experiment, and for funzies to learn something about how Python deals with issues related to multiple inheritance.     ","Q_Votes":"59"},{"Q_Title":"How to dynamically change base class of instances at runtime?","A_Content":"  The above answers are good if you need to change an existing class at runtime. However, if you are just looking to create a new class that inherits by some other class, there is a much cleaner solution. I got this idea from https://stackoverflow.com/a/21060094/3533440, but I think the example below better illustrates a legitimate use case.   def make_default(Map, default_default=None):     \"\"\"Returns a class which behaves identically to the given     Map class, except it gives a default value for unknown keys.\"\"\"     class DefaultMap(Map):         def __init__(self, default=default_default, **kwargs):             self._default = default             super().__init__(**kwargs)          def __missing__(self, key):             return self._default      return DefaultMap  DefaultDict = make_default(dict, default_default='wug')  d = DefaultDict(a=1, b=2) assert d['a'] is 1 assert d['b'] is 2 assert d['c'] is 'wug'   Correct me if I'm wrong, but this strategy seems very readable to me, and I would use it in production code. This is very similar to functors in OCaml.     ","Language":"Python","Tags":["python","inheritance","dynamic"],"URL":"https://stackoverflow.com/questions/9539052/how-to-dynamically-change-base-class-of-instances-at-runtime","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    This article has a snippet showing usage of __bases__ to dynamically change the inheritance hierarchy of some Python code, by adding a class to an existing classes collection of classes from which it inherits.  Ok, that's hard to read, code is probably clearer:  class Friendly:     def hello(self):         print 'Hello'  class Person: pass  p = Person() Person.__bases__ = (Friendly,) p.hello()  # prints \"Hello\"   That is, Person doesn't inherit from Friendly at the source level, but rather this inheritance relation is added dynamically at runtime by modification of the __bases__attribute of the Person class.  However, if you change Friendly and Person to be new style classes (by inheriting from object), you get the following error:  TypeError: __bases__ assignment: 'Friendly' deallocator differs from 'object'   A bit of Googling on this seems to indicate some incompatibilities between new-style and old style classes in regards to changing the inheritance hierarchy at runtime.  Specifically: \"New-style class objects don't support assignment to their bases attribute\".  My question, is it possible to make the above Friendly/Person example work using new-style classes in Python 2.7+, possibly by use of the __mro__ attribute?  Disclaimer: I fully realise that this is obscure code.  I fully realize that in real production code tricks like this tend to border on unreadable, this is purely a thought experiment, and for funzies to learn something about how Python deals with issues related to multiple inheritance.     ","Q_Votes":"59"},{"Q_Title":"why do we invoke print after importing print_function (in Python 2.6)","A_Content":"  The reason is that when you import from __future__ you're really just setting a flag that tells the interpreter to behave a bit differently than usual -- in the case of print_function, the print() function is made available in place of the statement. The __future__ module is thus \"special\" or \"magic\" -- it doesn't work like the usual modules.     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/4560804/why-do-we-invoke-print-after-importing-print-function-in-python-2-6","A_Votes":"47","_type":"dict","isAccepted":"Yes","Q_Content":"    To get the 3.0 print function we do the following in Python 2.6:  from __future__ import print_function   But to use the function we invoke print() not print_function().  Is this just an inconsistency or is there a good reason for this?  Why not the following:  from __future__ import print      ","Q_Votes":"59"},{"Q_Title":"why do we invoke print after importing print_function (in Python 2.6)","A_Content":"  print_function is a FeatureName not be confused with the print built-in function itself. It is a feature that is available from the future so that you can use the built-in function that it can provide.  Other Features include:  all_feature_names = [     \"nested_scopes\",     \"generators\",     \"division\",     \"absolute_import\",     \"with_statement\",     \"print_function\",     \"unicode_literals\", ]   There are specific reasons as when you migrate your code to next higher version, your program will remain as such as use the updated feature instead of the __future__ version. Also if it were function name or the keyword itself, it may cause confusion to the parser.     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/4560804/why-do-we-invoke-print-after-importing-print-function-in-python-2-6","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    To get the 3.0 print function we do the following in Python 2.6:  from __future__ import print_function   But to use the function we invoke print() not print_function().  Is this just an inconsistency or is there a good reason for this?  Why not the following:  from __future__ import print      ","Q_Votes":"59"},{"Q_Title":"why do we invoke print after importing print_function (in Python 2.6)","A_Content":"  Simple. print is keyword in Python 2.  So a statement like  from somewhere import print   would be an automatic SyntaxError in Python 2.  Allowing (hardcoding it in the syntax)  from __future__ import print   was deemed not worth the effort.     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/4560804/why-do-we-invoke-print-after-importing-print-function-in-python-2-6","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    To get the 3.0 print function we do the following in Python 2.6:  from __future__ import print_function   But to use the function we invoke print() not print_function().  Is this just an inconsistency or is there a good reason for this?  Why not the following:  from __future__ import print      ","Q_Votes":"59"},{"Q_Title":"why do we invoke print after importing print_function (in Python 2.6)","A_Content":"  In Python 3, the keyword print has been changed from calling a statement to calling a function.  So instead of saying print value you now need to say print(value), or you'll get a SyntaxError.  By doing the import, this change is effected in Python 2, too, so you can write programs using the same syntax as Python 3 (at least as far as print is concerned).     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/4560804/why-do-we-invoke-print-after-importing-print-function-in-python-2-6","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    To get the 3.0 print function we do the following in Python 2.6:  from __future__ import print_function   But to use the function we invoke print() not print_function().  Is this just an inconsistency or is there a good reason for this?  Why not the following:  from __future__ import print      ","Q_Votes":"59"},{"Q_Title":"why do we invoke print after importing print_function (in Python 2.6)","A_Content":"  Minimal example  >>> print     # Statement.  >>> from __future__ import print_function >>> print     # Function object. <built-in function print> >>> print()   # Function call.  >>>   As mentioned at: What is __future__ in Python used for and how/when to use it, and how it works from __future__ are magic statements that alter how Python parses code.  from __future__ import print_function in particular changes print from a statement into a built-in function, as shown in the interactive shell above.  Why print(1) works without from __future__ import print_function in Python 2   Because the:  print(1)   is parsed as:  print (1) ^^^^^ ^^^ 1     2    print statement argument   instead of:  print( 1 ) ^^^^^^ ^ ^ 1      2 1    print() function argument   And:  assert 1 == (1)   as mentioned at: Python tuple trailing comma syntax rule     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/4560804/why-do-we-invoke-print-after-importing-print-function-in-python-2-6","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    To get the 3.0 print function we do the following in Python 2.6:  from __future__ import print_function   But to use the function we invoke print() not print_function().  Is this just an inconsistency or is there a good reason for this?  Why not the following:  from __future__ import print      ","Q_Votes":"59"},{"Q_Title":"ipython notebook clear cell output in code","A_Content":"  You can use IPython.display.clear_output to clear the output of a cell.  from IPython.display import clear_output  for i in range(10):     clear_output()     print(\"Hello World!\")   At the end of this loop you will only see one Hello World!.  Without a code example it's not easy to give you working code. Probably buffering the latest n events is a good strategy. Whenever the buffer changes you can clear the cell's output and print the buffer again.     ","Language":"Python","Tags":["python","ipython","ipython-notebook"],"URL":"https://stackoverflow.com/questions/24816237/ipython-notebook-clear-cell-output-in-code","A_Votes":"128","_type":"dict","isAccepted":"Yes","Q_Content":"    In a iPython notebook, I have a while loop that listens to a Serial port and print the received data in real time.  What I want to achieve to only show the latest received data (i.e only one line showing the most recent data. no scrolling in the cell output area)  What I need(i think) is to clear the old cell output when I receives new data, and then prints the new data. I am wondering how can I clear old data programmatically ?     ","Q_Votes":"59"},{"Q_Title":"When does the App Engine scheduler use a new thread vs. a new instance?","A_Content":"  The following set of rules are currently used to determine if a given instance can accept a new request:  if processing more than N concurrent requests (today N=10): false elif exceeding the soft memory limit: false elif exceeding the instance class CPU limit: false elif warming up: false else true   The following of total CPU/core limits currently apply to each instance classes:  CLASS 1: 600MHz 1 core CLASS 2: 1.2GHz 1 core CLASS 4: 2.4GHz 1 core CLASS 8: 4.8GHz 2 core   So only a B8 instance can process up to 2 fully CPU bound requests in parallel.  Setting threadsafe: true (Python) or <threadsafe>true</threadsafe> (Java) for instances classes < 8 would not allow more than one CPU bound requests to be processed in parallel on a single instance.  If you are not fully CPU bound or doing I/O, the Python and Java runtime will spawn new threads for handling new request up to 10 concurrent requests with threadsafe: true  Also note that even though the Go runtime is single threaded, it does support concurrent requests: It will spawn 1 goroutine per requests and yield control between goroutines while they are performing I/O.     ","Language":"Python","Tags":["python","google-app-engine"],"URL":"https://stackoverflow.com/questions/11525717/when-does-the-app-engine-scheduler-use-a-new-thread-vs-a-new-instance","A_Votes":"36","_type":"dict","isAccepted":"Yes","Q_Content":"    If I set threadsafe: true in my app.yaml file, what are the rules that govern when a new instance will be created to serve a request, versus when a new thread will be created on an existing instance?  If I have an app which performs something computationally intensive on each request, does multi-threading buy me anything? In other words, is an instance a multi-core instance or a single core?  Or, are new threads only spun up when existing threads are waiting on IO?     ","Q_Votes":"60"},{"Q_Title":"When does the App Engine scheduler use a new thread vs. a new instance?","A_Content":"  Read the next messages from link which was suggested by Kyle Finley      Jeff Schnitzer:  Is there still a hard limit of 10 threads?       Yes, but probably not for the reason you expect. The primary  issue we   run into is memory management. If we raised the default  to 100, many   apps would then see out-of-memory deaths (more than  they do now), and   these deaths show up differently for  python/java/go. The right path   forward is more intelligent  algorithms wrt memory, providing   configurability, and so on. This  is an example of the kinds of   projects we work on for the  scheduler, but as with any team we have   to prioritize our  projects. I'd recommend filing this (or any other   desired  scheduler enhancements) on the public issue tracker so they   can  get feedback/data/votes.      ","Language":"Python","Tags":["python","google-app-engine"],"URL":"https://stackoverflow.com/questions/11525717/when-does-the-app-engine-scheduler-use-a-new-thread-vs-a-new-instance","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    If I set threadsafe: true in my app.yaml file, what are the rules that govern when a new instance will be created to serve a request, versus when a new thread will be created on an existing instance?  If I have an app which performs something computationally intensive on each request, does multi-threading buy me anything? In other words, is an instance a multi-core instance or a single core?  Or, are new threads only spun up when existing threads are waiting on IO?     ","Q_Votes":"60"},{"Q_Title":"When does the App Engine scheduler use a new thread vs. a new instance?","A_Content":"     If I set threadsafe: true in my app.yaml file, what are the rules that govern when a new instance will be created to serve a request, versus when a new thread will be created on an existing instance?   Like people are saying here, if a previous instance is already using 10 threads, a new instance with a new thread would be initiated.  A new thread will be created if all other threads are busy, they must be either waiting for some response or with computing results.     If I have an app which performs something computationally intensive on each request, does multi-threading buy me anything? In other words, is an instance a multi-core instance or a single core?   Now this question is very controversial. Everyone knows the answer but still they are skeptical. Multi-threading can never buy you any good if your task is based on just computations unless you're using a multi-core processor, don't ask me why a multi-core processor will help better, you know the answer. Now google app engine is not sophisticated enough to decide that when new threads should be dispatched to the other processor/core(if it exists), only new instances are dispatched to the other core/processor. Want your thread to run in the other core/processor? Well, throw some skills there and booya! Remember, it's upto you to decide if threads should run in other cores/processors, the engine can not take the responsibility for such because this could lead to so many confusions, the engine is not God. In short, by default the instance is single core, the engine can't decide for you when it should go multi-core.     Or, are new threads only spun up when existing threads are waiting on IO?   The first part of my answer clears this out. Yes, they only spun up when existing threads are busy, this is how threadsafe works, to prevent deadlocks.  Now I can tell you this all, from my personal experience, I worked on the app engine for many months and programmed/debugged/tested apps that were highly dependent on the threadsafe architecture.  If you want I can add references(I don't have references, just personal experience, but I'm ready to search and put things on the table for you), but I don't think they are needed in this case, threadsafe works in obvious ways which I have validated myself.     ","Language":"Python","Tags":["python","google-app-engine"],"URL":"https://stackoverflow.com/questions/11525717/when-does-the-app-engine-scheduler-use-a-new-thread-vs-a-new-instance","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    If I set threadsafe: true in my app.yaml file, what are the rules that govern when a new instance will be created to serve a request, versus when a new thread will be created on an existing instance?  If I have an app which performs something computationally intensive on each request, does multi-threading buy me anything? In other words, is an instance a multi-core instance or a single core?  Or, are new threads only spun up when existing threads are waiting on IO?     ","Q_Votes":"60"},{"Q_Title":"using __init__.py","A_Content":"  The vast majority of the __init__.py files I write are empty, because many packages don't have anything to initialize.  One example in which I may want initialization is when at package-load time I want to read in a bunch of data once and for all (from files, a DB, or the web, say) -- in which case it's much nicer to put that reading in a private function in the package's __init__.py rather than have a separate \"initialization module\" and redundantly import that module from every single real module in the package (uselessly repetitive and error-prone: that's obviously a case in which relying on the language's guarantee that the package's __init__.py is loaded once before any module in the package is obviously much more Pythonic!).  For other concrete and authoritative expressions of opinion, look at the different approaches taken in the various packages that are part of Python's standard library.     ","Language":"Python","Tags":["python","module","initialization","packages"],"URL":"https://stackoverflow.com/questions/2361124/using-init-py","A_Votes":"47","_type":"dict","isAccepted":"Yes","Q_Content":"    I am having difficulty understanding the usage scenarios or design goals of python's __init__.py files in my projects.  Assume that I have 'model' directory (refers as a package) which contains the following files   __init__.py meta.py solrmodel.py mongomodel.py samodel.py   I found two ways of using __init__.py:   I have common a definition which needs to be used in solrmodel.py, mongomodel.py, samodel.py. Can I use __init__.py as a base/common definition for all the *model.py classes? This means that I have to import model/__init__.py. Or, the __init__.py shall have imported definitions of solrmodel.py, mongomodel.py, samodel.py in its own and it allows the easy import of classes or function like this:  # file: __init__.py  from mongomodel import * from solrmodel import * from samodel import *   (I am aware that import * is not recommended and I just used it as a convention)   I could not decide between above two scenarios. Are there more usage scenarios for __init__.py and can you explain the usage?     ","Q_Votes":"61"},{"Q_Title":"using __init__.py","A_Content":"  The contents of __init__.py are imported when you import a module within the package.  You're overlooking a third scenario, which is to put the common parts in a separate module and then have the other modules import that, leaving __init__.py for things that will be used outside the package. This is the practice I usually follow.     ","Language":"Python","Tags":["python","module","initialization","packages"],"URL":"https://stackoverflow.com/questions/2361124/using-init-py","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I am having difficulty understanding the usage scenarios or design goals of python's __init__.py files in my projects.  Assume that I have 'model' directory (refers as a package) which contains the following files   __init__.py meta.py solrmodel.py mongomodel.py samodel.py   I found two ways of using __init__.py:   I have common a definition which needs to be used in solrmodel.py, mongomodel.py, samodel.py. Can I use __init__.py as a base/common definition for all the *model.py classes? This means that I have to import model/__init__.py. Or, the __init__.py shall have imported definitions of solrmodel.py, mongomodel.py, samodel.py in its own and it allows the easy import of classes or function like this:  # file: __init__.py  from mongomodel import * from solrmodel import * from samodel import *   (I am aware that import * is not recommended and I just used it as a convention)   I could not decide between above two scenarios. Are there more usage scenarios for __init__.py and can you explain the usage?     ","Q_Votes":"61"},{"Q_Title":"More Pythonic Way to Run a Process X Times","A_Content":"  Personally:  for _ in range(50):     print \"Some thing\"   if you don't need i. If you use Python < 3 and you want to repeat the loop a lot of times, use xrange as there is no need to generate the whole list beforehand.     ","Language":"Python","Tags":["python","loops"],"URL":"https://stackoverflow.com/questions/4264634/more-pythonic-way-to-run-a-process-x-times","A_Votes":"77","_type":"dict","isAccepted":"Yes","Q_Content":"    Which is more pythonic?  While loop:  count = 0 while count < 50:     print \"Some thing\"     count = count + 1   For loop:  for i in range(50):     print \"Some thing\"   Edit: not duplicate because this has answers to determine which is clearer, vs. how to run a range without 'i' -- even though that ended up being the most elegant     ","Q_Votes":"61"},{"Q_Title":"More Pythonic Way to Run a Process X Times","A_Content":"  If you are after the side effects that happen within the loop, I'd personally go for the range() approach.  If you care about the result of whatever functions you call within the loop, I'd go for a list comprehension or map approach. Something like this:  def f(n):     return n * n  results = [f(i) for i in range(50)] # or using map: results = map(f, range(50))      ","Language":"Python","Tags":["python","loops"],"URL":"https://stackoverflow.com/questions/4264634/more-pythonic-way-to-run-a-process-x-times","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Which is more pythonic?  While loop:  count = 0 while count < 50:     print \"Some thing\"     count = count + 1   For loop:  for i in range(50):     print \"Some thing\"   Edit: not duplicate because this has answers to determine which is clearer, vs. how to run a range without 'i' -- even though that ended up being the most elegant     ","Q_Votes":"61"},{"Q_Title":"More Pythonic Way to Run a Process X Times","A_Content":"  The for loop is definitely more pythonic, as it uses Python's higher level built in functionality to convey what you're doing both more clearly and concisely. The overhead of range vs xrange, and assigning an unused i variable, stem from the absence of a statement like Verilog's repeat statement. The main reason to stick to the for range solution is that other ways are more complex. For instance:  from itertools import repeat  for unused in repeat(None, 10):     del unused   # redundant and inefficient, the name is clear enough     print \"This is run 10 times\"   Using repeat instead of range here is less clear because it's not as well known a function, and more complex because you need to import it. The main style guides if you need a reference are PEP 20 - The Zen of Python and PEP 8 - Style Guide for Python Code.   We also note that the for range version is an explicit example used in both the language reference and tutorial, although in that case the value is used. It does mean the form is bound to be more familiar than the while expansion of a C-style for loop.      ","Language":"Python","Tags":["python","loops"],"URL":"https://stackoverflow.com/questions/4264634/more-pythonic-way-to-run-a-process-x-times","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Which is more pythonic?  While loop:  count = 0 while count < 50:     print \"Some thing\"     count = count + 1   For loop:  for i in range(50):     print \"Some thing\"   Edit: not duplicate because this has answers to determine which is clearer, vs. how to run a range without 'i' -- even though that ended up being the most elegant     ","Q_Votes":"61"},{"Q_Title":"How can I use different pipelines for different spiders in a single Scrapy project","A_Content":"  Just remove all pipelines from main settings and use this inside spider.  This will define the pipeline to user per spider  class testSpider(InitSpider):     name = 'test'     custom_settings = {         'ITEM_PIPELINES': {             'app.MyPipeline': 400         }     }      ","Language":"Python","Tags":["python","scrapy","web-crawler"],"URL":"https://stackoverflow.com/questions/8372703/how-can-i-use-different-pipelines-for-different-spiders-in-a-single-scrapy-proje","A_Votes":"71","_type":"dict","isAccepted":"No","Q_Content":"    I have a scrapy project which contains multiple spiders. Is there any way I can define which pipelines to use for which spider? Not all the pipelines i have defined are applicable for every spider.  Thanks     ","Q_Votes":"61"},{"Q_Title":"How can I use different pipelines for different spiders in a single Scrapy project","A_Content":"  Building on the solution from Pablo Hoffman, you can use the following decorator on the process_item method of a Pipeline object so that it checks the pipeline attribute of your spider for whether or not it should be executed. For example:  def check_spider_pipeline(process_item_method):      @functools.wraps(process_item_method)     def wrapper(self, item, spider):          # message template for debugging         msg = '%%s %s pipeline step' % (self.__class__.__name__,)          # if class is in the spider's pipeline, then use the         # process_item method normally.         if self.__class__ in spider.pipeline:             spider.log(msg % 'executing', level=log.DEBUG)             return process_item_method(self, item, spider)          # otherwise, just return the untouched item (skip this step in         # the pipeline)         else:             spider.log(msg % 'skipping', level=log.DEBUG)             return item      return wrapper   For this decorator to work correctly, the spider must have a pipeline attribute with a container of the Pipeline objects that you want to use to process the item, for example:  class MySpider(BaseSpider):      pipeline = set([         pipelines.Save,         pipelines.Validate,     ])      def parse(self, response):         # insert scrapy goodness here         return item   And then in a pipelines.py file:  class Save(object):      @check_spider_pipeline     def process_item(self, item, spider):         # do saving here         return item  class Validate(object):      @check_spider_pipeline     def process_item(self, item, spider):         # do validating here         return item   All Pipeline objects should still be defined in ITEM_PIPELINES in settings (in the correct order -- would be nice to change so that the order could be specified on the Spider, too).     ","Language":"Python","Tags":["python","scrapy","web-crawler"],"URL":"https://stackoverflow.com/questions/8372703/how-can-i-use-different-pipelines-for-different-spiders-in-a-single-scrapy-proje","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I have a scrapy project which contains multiple spiders. Is there any way I can define which pipelines to use for which spider? Not all the pipelines i have defined are applicable for every spider.  Thanks     ","Q_Votes":"61"},{"Q_Title":"How can I use different pipelines for different spiders in a single Scrapy project","A_Content":"  I can think of at least four approaches:   Use a different scrapy project per set of spiders+pipelines (might be appropriate if your spiders are different enough warrant being in different projects) On the scrapy tool command line, change the pipeline setting with scrapy settings in between each invocation of your spider Isolate your spiders into their own scrapy tool commands, and define the default_settings['ITEM_PIPELINES'] on your command class to the pipeline list you want for that command. See line 6 of this example. In the pipeline classes themselves, have process_item() check what spider it's running against, and do nothing if it should be ignored for that spider. See the example using resources per spider to get you started. (This seems like an ugly solution because it tightly couples spiders and item pipelines. You probably shouldn't use this one.)      ","Language":"Python","Tags":["python","scrapy","web-crawler"],"URL":"https://stackoverflow.com/questions/8372703/how-can-i-use-different-pipelines-for-different-spiders-in-a-single-scrapy-proje","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I have a scrapy project which contains multiple spiders. Is there any way I can define which pipelines to use for which spider? Not all the pipelines i have defined are applicable for every spider.  Thanks     ","Q_Votes":"61"},{"Q_Title":"How can I use different pipelines for different spiders in a single Scrapy project","A_Content":"  You can use the name attribute of the spider in your pipeline  class CustomPipeline(object)      def process_item(self, item, spider)          if spider.name == 'spider1':              # do something              return item          return item   Defining all pipelines this way can accomplish what you want.     ","Language":"Python","Tags":["python","scrapy","web-crawler"],"URL":"https://stackoverflow.com/questions/8372703/how-can-i-use-different-pipelines-for-different-spiders-in-a-single-scrapy-proje","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a scrapy project which contains multiple spiders. Is there any way I can define which pipelines to use for which spider? Not all the pipelines i have defined are applicable for every spider.  Thanks     ","Q_Votes":"61"},{"Q_Title":"How can I use different pipelines for different spiders in a single Scrapy project","A_Content":"  The other solutions given here are good, but I think they could be slow, because we are not really not using the pipeline per spider, instead we are checking if a pipeline exists every time an item is returned (and in some cases this could reach millions).  A good way to completely disable (or enable) a feature per spider is using custom_setting and from_crawler for all extensions like this:  pipelines.py  from scrapy.exceptions import NotConfigured  class SomePipeline(object):     def __init__(self):         pass      @classmethod     def from_crawler(cls, crawler):         if not crawler.settings.getbool('SOMEPIPELINE_ENABLED'):             # if this isn't specified in settings, the pipeline will be completely disabled             raise NotConfigured         return cls()      def process_item(self, item, spider):         # change my item         return item   settings.py  ITEM_PIPELINES = {    'myproject.pipelines.SomePipeline': 300, } SOMEPIPELINE_ENABLED = True # you could have the pipeline enabled by default   spider1.py  class Spider1(Spider):      name = 'spider1'      start_urls = [\"http://example.com\"]      custom_settings = {         'SOMEPIPELINE_ENABLED': False     }   As you check, we have specified custom_settings that will override the things specified in settings.py, and we are disabling SOMEPIPELINE_ENABLED for this spider.  Now when you run this spider, check for something like:  [scrapy] INFO: Enabled item pipelines: []   Now scrapy has completely disabled the pipeline, not bothering of its existence for the whole run. Check that this also works for scrapy extensions and middlewares.     ","Language":"Python","Tags":["python","scrapy","web-crawler"],"URL":"https://stackoverflow.com/questions/8372703/how-can-i-use-different-pipelines-for-different-spiders-in-a-single-scrapy-proje","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a scrapy project which contains multiple spiders. Is there any way I can define which pipelines to use for which spider? Not all the pipelines i have defined are applicable for every spider.  Thanks     ","Q_Votes":"61"},{"Q_Title":"How can I use different pipelines for different spiders in a single Scrapy project","A_Content":"  I am using two pipelines, one for image download (MyImagesPipeline) and second for save data in mongodb (MongoPipeline).  suppose we have many spiders(spider1,spider2,...........),in my example spider1 and spider5 can not use MyImagesPipeline  settings.py  ITEM_PIPELINES = {'scrapycrawler.pipelines.MyImagesPipeline' : 1,'scrapycrawler.pipelines.MongoPipeline' : 2} IMAGES_STORE = '/var/www/scrapycrawler/dowload'   And bellow complete code of pipeline  import scrapy import string import pymongo from scrapy.pipelines.images import ImagesPipeline  class MyImagesPipeline(ImagesPipeline):     def process_item(self, item, spider):         if spider.name not in ['spider1', 'spider5']:             return super(ImagesPipeline, self).process_item(item, spider)         else:            return item       def file_path(self, request, response=None, info=None):         image_name = string.split(request.url, '/')[-1]         dir1 = image_name[0]         dir2 = image_name[1]         return dir1 + '/' + dir2 + '/' +image_name  class MongoPipeline(object):      collection_name = 'scrapy_items'     collection_url='snapdeal_urls'      def __init__(self, mongo_uri, mongo_db):         self.mongo_uri = mongo_uri         self.mongo_db = mongo_db      @classmethod     def from_crawler(cls, crawler):         return cls(             mongo_uri=crawler.settings.get('MONGO_URI'),             mongo_db=crawler.settings.get('MONGO_DATABASE', 'scraping')         )      def open_spider(self, spider):         self.client = pymongo.MongoClient(self.mongo_uri)         self.db = self.client[self.mongo_db]      def close_spider(self, spider):         self.client.close()      def process_item(self, item, spider):         #self.db[self.collection_name].insert(dict(item))         collection_name=item.get( 'collection_name', self.collection_name )         self.db[collection_name].insert(dict(item))         data = {}         data['base_id'] = item['base_id']         self.db[self.collection_url].update({             'base_id': item['base_id']         }, {             '$set': {             'image_download': 1             }         }, upsert=False, multi=True)         return item      ","Language":"Python","Tags":["python","scrapy","web-crawler"],"URL":"https://stackoverflow.com/questions/8372703/how-can-i-use-different-pipelines-for-different-spiders-in-a-single-scrapy-proje","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a scrapy project which contains multiple spiders. Is there any way I can define which pipelines to use for which spider? Not all the pipelines i have defined are applicable for every spider.  Thanks     ","Q_Votes":"61"},{"Q_Title":"Access outer class from inner class in python","A_Content":"  The methods of a nested class cannot directly access the instance attributes of the outer class.   Note that it is not necessarily the case that an instance of the outer class exists even when you have created an instance of the inner class.  In fact, it is often recommended against using nested classes, since the nesting does not imply any particular relationship between the inner and outer classes.     ","Language":"Python","Tags":["python","scope","nested","inner-classes"],"URL":"https://stackoverflow.com/questions/2024566/access-outer-class-from-inner-class-in-python","A_Votes":"42","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a situation like so...  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             self.Outer.some_method()    # <-- this is the line in question   How can I access the Outer class's method from the Inner class?  Edit -- Thanks for the responses.  I'm concluding that I need to re-assess how I had designed this to be implemented and come up with a more robust method.     ","Q_Votes":"62"},{"Q_Title":"Access outer class from inner class in python","A_Content":"  You're trying to access Outer's class instance, from inner class instance. So just use factory-method to build Inner instance and pass Outer instance to it.  class Outer(object):      def createInner(self):         return Outer.Inner(self)      class Inner(object):         def __init__(self, outer_instance):             self.outer_instance = outer_instance             self.outer_instance.somemethod()          def inner_method(self):             self.outer_instance.anothermethod()      ","Language":"Python","Tags":["python","scope","nested","inner-classes"],"URL":"https://stackoverflow.com/questions/2024566/access-outer-class-from-inner-class-in-python","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    I have a situation like so...  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             self.Outer.some_method()    # <-- this is the line in question   How can I access the Outer class's method from the Inner class?  Edit -- Thanks for the responses.  I'm concluding that I need to re-assess how I had designed this to be implemented and come up with a more robust method.     ","Q_Votes":"62"},{"Q_Title":"Access outer class from inner class in python","A_Content":"  maybe I'm mad but this seems very easy indeed - the thing is to make your inner class inside a method of the outer class...   def do_sthg( self ):     ...  def messAround( self ):      outerClassSelf = self      class mooble():         def do_sthg_different( self ):             ...             outerClassSelf.do_sthg()   Plus... \"self\" is only used by convention, so you could do this:  def do_sthg( self ):     ...  def messAround( outerClassSelf ):      class mooble():         def do_sthg_different( self ):             ...             outerClassSelf.do_sthg()   It might be objected that you can't then create this inner class from outside the outer class... but this ain't true:  class Bumblebee():      def do_sthg( self ):         print \"sthg\"      def giveMeAnInnerClass( outerClassSelf ):          class mooble():             def do_sthg_different( self ):                 print \"something diff\\n\"                 outerClassSelf.do_sthg()         return mooble   then, somewhere miles away:  blob = Bumblebee().giveMeAnInnerClass()() blob.do_sthg_different()       even push the boat out a bit and extend this inner class (NB to get super() to work you have to change the class signature of mooble to \"class mooble( object )\"  class InnerBumblebeeWithAddedBounce( Bumblebee().giveMeAnInnerClass() ):     def bounce( self ):         print \"bounce\"      def do_sthg_different( self ):         super( InnerBumblebeeWithAddedBounce, self ).do_sthg_different()         print \"and more different\"   ibwab = InnerBumblebeeWithAddedBounce()     ibwab.bounce() ibwab.do_sthg_different()   later  mrh1997 raised an interesting point about the non-common inheritance of inner classes delivered using this technique. But it seems that the solution is pretty straightforward:  class Fatty():     def do_sthg( self ):         pass      class InnerFatty( object ):         pass      def giveMeAnInnerFattyClass(self):         class ExtendedInnerFatty( Fatty.InnerFatty ):             pass         return ExtendedInnerFatty  fatty1 = Fatty() fatty2 = Fatty()  innerFattyClass1 = fatty1.giveMeAnInnerFattyClass() innerFattyClass2 = fatty2.giveMeAnInnerFattyClass()  print ( issubclass( innerFattyClass1, Fatty.InnerFatty )) print ( issubclass( innerFattyClass2, Fatty.InnerFatty ))      ","Language":"Python","Tags":["python","scope","nested","inner-classes"],"URL":"https://stackoverflow.com/questions/2024566/access-outer-class-from-inner-class-in-python","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I have a situation like so...  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             self.Outer.some_method()    # <-- this is the line in question   How can I access the Outer class's method from the Inner class?  Edit -- Thanks for the responses.  I'm concluding that I need to re-assess how I had designed this to be implemented and come up with a more robust method.     ","Q_Votes":"62"},{"Q_Title":"Access outer class from inner class in python","A_Content":"  Do you mean to use inheritance, rather than nesting classes like this? What you're doing doesn't make a heap of sense in Python.  You can access the Outer's some_method by just referencing Outer.some_method within the inner class's methods, but it's not going to work as you expect it will. For example, if you try this:  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             Outer.some_method()   ...you'll get a TypeError when initialising an Inner object, because Outer.some_method expects to receive an Outer instance as its first argument. (In the example above, you're basically trying to call some_method as a class method of Outer.)     ","Language":"Python","Tags":["python","scope","nested","inner-classes"],"URL":"https://stackoverflow.com/questions/2024566/access-outer-class-from-inner-class-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have a situation like so...  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             self.Outer.some_method()    # <-- this is the line in question   How can I access the Outer class's method from the Inner class?  Edit -- Thanks for the responses.  I'm concluding that I need to re-assess how I had designed this to be implemented and come up with a more robust method.     ","Q_Votes":"62"},{"Q_Title":"Access outer class from inner class in python","A_Content":"  I've created some Python code to use an outer class from its inner class, based on a good idea from another answer for this question. I think it's short, simple and easy to understand.    class higher_level__unknown_irrelevant_name__class:     def __init__(self, ...args...):         ...other code...         # Important lines to access sub-classes.         subclasses = self._subclass_container()         self.some_subclass = subclasses[\"some_subclass\"]         del subclasses # Free up variable for other use.      def sub_function(self, ...args...):         ...other code...      def _subclass_container(self):         _parent_class = self # Create access to parent class.         class some_subclass:             def __init__(self):                 self._parent_class = _parent_class # Easy access from self.                 # Optional line, clears variable space, but SHOULD NOT BE USED                 # IF THERE ARE MULTIPLE SUBCLASSES as would stop their parent access.                 #  del _parent_class         class subclass_2:             def __init__(self):                 self._parent_class = _parent_class         # Return reference(s) to the subclass(es).         return {\"some_subclass\": some_subclass, \"subclass_2\": subclass_2}   The main code, \"production ready\" (without comments, etc.). Remember to replace all of each value in angle brackets (e.g. <x>) with the desired value.   class <higher_level_class>:     def __init__(self):         subclasses = self._subclass_container()         self.<sub_class> = subclasses[<sub_class, type string>]         del subclasses      def _subclass_container(self):         _parent_class = self         class <sub_class>:             def __init__(self):                 self._parent_class = _parent_class         return {<sub_class, type string>: <sub_class>}   Explanation of how this method works (the basic steps):   Create a function named _subclass_container to act as a wrapper to access the variable self, a reference to the higher level class (from code running inside the function).   Create a variable named _parent_class which is a reference to the variable self of this function, that the sub-classes of _subclass_container can access (avoids name conflicts with other self variables in subclasses). Return the sub-class/sub-classes as a dictionary/list so code calling the _subclass_container function can access the sub-classes inside.  In the __init__ function inside the higher level class (or wherever else needed), receive the returned sub-classes from the function _subclass_container into the variable subclasses. Assign sub-classes stored in the subclasses variable to attributes of the higher level class.   A few tips to make scenarios easier:  Making the code to assign the sub classes to the higher level class easier to copy and be used in classes derived from the higher level class that have their __init__ function changed:  Insert before line 12 in the main code:       def _subclass_init(self):   Then insert into this function lines 5-6 (of the main code) and replace lines 4-7 with the following code:           self._subclass_init(self)   Making subclass assigning to the higher level class possible when there are many/unknown quantities of subclasses.  Replace line 6 with the following code:           for subclass_name in list(subclasses.keys()):             setattr(self, subclass_name, subclasses[subclass_name])   Example scenario of where this solution would be useful and where the higher level class name should be impossible to get:  A class, named \"a\" (class a:) is created. It has subclasses that need to access it (the parent). One subclass is called \"x1\". In this subclass, the code a.run_func() is run.  Then another class, named \"b\" is created, derived from class \"a\" (class b(a):). After that, some code runs b.x1() (calling the sub function \"x1\" of b, a derived sub-class). This function runs a.run_func(), calling the function \"run_func\" of class \"a\", not the function \"run_func\" of its parent, \"b\" (as it should), because the function which was defined in class \"a\" is set to refer to the function of class \"a\", as that was its parent.  This would cause problems (e.g. if function a.run_func has been deleted) and the only solution without rewriting the code in class a.x1 would be to redefine the sub-class x1 with updated code for all classes derived from class \"a\" which would obviously be difficult and not worth it.     ","Language":"Python","Tags":["python","scope","nested","inner-classes"],"URL":"https://stackoverflow.com/questions/2024566/access-outer-class-from-inner-class-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a situation like so...  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             self.Outer.some_method()    # <-- this is the line in question   How can I access the Outer class's method from the Inner class?  Edit -- Thanks for the responses.  I'm concluding that I need to re-assess how I had designed this to be implemented and come up with a more robust method.     ","Q_Votes":"62"},{"Q_Title":"Access outer class from inner class in python","A_Content":"  Another possibility:  class _Outer (object):     # Define your static methods here, e.g.     @staticmethod     def subclassRef ():         return Outer  class Outer (_Outer):     class Inner (object):         def outer (self):             return _Outer          def doSomething (self):             outer = self.outer ()             # Call your static mehthods.             cls = outer.subclassRef ()             return cls ()      ","Language":"Python","Tags":["python","scope","nested","inner-classes"],"URL":"https://stackoverflow.com/questions/2024566/access-outer-class-from-inner-class-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a situation like so...  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             self.Outer.some_method()    # <-- this is the line in question   How can I access the Outer class's method from the Inner class?  Edit -- Thanks for the responses.  I'm concluding that I need to re-assess how I had designed this to be implemented and come up with a more robust method.     ","Q_Votes":"62"},{"Q_Title":"Access outer class from inner class in python","A_Content":"  You can easily access to outer class using metaclass: after creation of outer class check it's attribute dict for any classes (or apply any logic you need - mine is just trivial example) and set corresponding values:  import six import inspect   # helper method from `peewee` project to add metaclass _METACLASS_ = '_metaclass_helper_' def with_metaclass(meta, base=object):     return meta(_METACLASS_, (base,), {})   class OuterMeta(type):     def __new__(mcs, name, parents, dct):         cls = super(OuterMeta, mcs).__new__(mcs, name, parents, dct)         for klass in dct.values():             if inspect.isclass(klass):                 print(\"Setting outer of '%s' to '%s'\" % (klass, cls))                 klass.outer = cls          return cls   # @six.add_metaclass(OuterMeta) -- this is alternative to `with_metaclass` class Outer(with_metaclass(OuterMeta)):     def foo(self):         return \"I'm outer class!\"      class Inner(object):         outer = None  # <-- by default it's None          def bar(self):             return \"I'm inner class\"   print(Outer.Inner.outer) >>> <class '__main__.Outer'> assert isinstance(Outer.Inner.outer(), Outer)  print(Outer().foo()) >>> I'm outer class! print(Outer.Inner.outer().foo()) >>> I'm outer class! print(Outer.Inner().outer().foo()) >>> I'm outer class! print(Outer.Inner().bar()) >>> I'm inner class!   Using this approach, you can easily bind and refer two classes between each other.     ","Language":"Python","Tags":["python","scope","nested","inner-classes"],"URL":"https://stackoverflow.com/questions/2024566/access-outer-class-from-inner-class-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a situation like so...  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             self.Outer.some_method()    # <-- this is the line in question   How can I access the Outer class's method from the Inner class?  Edit -- Thanks for the responses.  I'm concluding that I need to re-assess how I had designed this to be implemented and come up with a more robust method.     ","Q_Votes":"62"},{"Q_Title":"Access outer class from inner class in python","A_Content":"  Expanding on @tsnorri's cogent thinking, that the outer method may be a static method:  class Outer(object):      @staticmethod     def some_static_method(self):         # do something      class Inner(object):         def __init__(self):             self.some_static_method()    # <-- this will work later      Inner.some_static_method = some_static_method   Now the line in question should work by the time it is actually called.  The last line in the above code gives the Inner class a static method that's a clone of the Outer static method.      This takes advantage of two Python features, that functions are objects, and scope is textual.     Usually, the local scope references the local names of the (textually) current function.   ...or current class in our case. So objects \"local\" to the definition of the Outer class (Inner and some_static_method) may be referred to directly within that definition.     ","Language":"Python","Tags":["python","scope","nested","inner-classes"],"URL":"https://stackoverflow.com/questions/2024566/access-outer-class-from-inner-class-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a situation like so...  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             self.Outer.some_method()    # <-- this is the line in question   How can I access the Outer class's method from the Inner class?  Edit -- Thanks for the responses.  I'm concluding that I need to re-assess how I had designed this to be implemented and come up with a more robust method.     ","Q_Votes":"62"},{"Q_Title":"Access outer class from inner class in python","A_Content":"  i found this.  Tweaked to suite your question, it is the answer:  class Outer(object):     def some_method(self):         # do something      class _Inner(object):         def __init__(self, outer):             outer.some_method()     def Inner(self):         return _Inner(self)   I’m sure you can somehow write a decorator for this or something :) /edit: kinda     ","Language":"Python","Tags":["python","scope","nested","inner-classes"],"URL":"https://stackoverflow.com/questions/2024566/access-outer-class-from-inner-class-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a situation like so...  class Outer(object):      def some_method(self):         # do something      class Inner(object):         def __init__(self):             self.Outer.some_method()    # <-- this is the line in question   How can I access the Outer class's method from the Inner class?  Edit -- Thanks for the responses.  I'm concluding that I need to re-assess how I had designed this to be implemented and come up with a more robust method.     ","Q_Votes":"62"},{"Q_Title":"How to install cryptography on ubuntu?","A_Content":"  The answer is on the docs of cryptography's installation section which pretty much reflects Angelos' answer:  Quoting it:     For Debian and Ubuntu, the following command will ensure that the   required dependencies are installed:  $ sudo apt-get install build-essential libssl-dev libffi-dev python-dev       For Fedora and RHEL-derivatives, the following command will ensure   that the required dependencies are installed:  $ sudo yum install gcc libffi-devel python-devel openssl-devel       You should now be able to build and install cryptography with the   usual  $ pip install cryptography       ","Language":"Python","Tags":["python","ubuntu","cryptography","pip"],"URL":"https://stackoverflow.com/questions/35144550/how-to-install-cryptography-on-ubuntu","A_Votes":"120","_type":"dict","isAccepted":"No","Q_Content":"    My ubuntu is 14.04 LTS.  When I install cryptography, the error is:  Installing egg-scripts. uses namespace packages but the distribution does not require setuptools. Getting distribution for 'cryptography==0.2.1'.  no previously-included directories found matching 'documentation/_build' zip_safe flag not set; analyzing archive contents... six: module references __path__  Installed /tmp/easy_install-oUz7ei/cryptography-0.2.1/.eggs/six-1.10.0-py2.7.egg Searching for cffi>=0.8 Reading https://pypi.python.org/simple/cffi/ Best match: cffi 1.5.0 Downloading https://pypi.python.org/packages/source/c/cffi/cffi-1.5.0.tar.gz#md5=dec8441e67880494ee881305059af656 Processing cffi-1.5.0.tar.gz Writing /tmp/easy_install-oUz7ei/cryptography-0.2.1/temp/easy_install-Yf2Yl3/cffi-1.5.0/setup.cfg Running cffi-1.5.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-oUz7ei/cryptography-0.2.1/temp/easy_install-Yf2Yl3/cffi-1.5.0/egg-dist-tmp-A2kjMD c/_cffi_backend.c:15:17: fatal error: ffi.h: No such file or directory  #include <ffi.h>                  ^ compilation terminated. error: Setup script exited with error: command 'x86_64-linux-gnu-gcc' failed with exit status 1 An error occurred when trying to install cryptography 0.2.1. Look above this message for any errors that were output by easy_install. While:   Installing egg-scripts.   Getting distribution for 'cryptography==0.2.1'. Error: Couldn't install: cryptography 0.2.1   I don't know why it was failed. What is the reason. Is there something necessary when install it on ubuntu system?     ","Q_Votes":"62"},{"Q_Title":"How to install cryptography on ubuntu?","A_Content":"  I had the same problem when pip installing the cryptography module on Ubuntu 14.04. I solved it by installing libffi-dev:  apt-get install -y libffi-dev   Then I got the following error:  build/temp.linux-x86_64-3.4/_openssl.c:431:25: fatal error: openssl/aes.h: No such file or directory  #include <openssl/aes.h>                          ^ compilation terminated. error: command 'x86_64-linux-gnu-gcc' failed with exit status 1   Which I resolved by installing libssl-dev:  apt-get install -y libssl-dev      ","Language":"Python","Tags":["python","ubuntu","cryptography","pip"],"URL":"https://stackoverflow.com/questions/35144550/how-to-install-cryptography-on-ubuntu","A_Votes":"49","_type":"dict","isAccepted":"No","Q_Content":"    My ubuntu is 14.04 LTS.  When I install cryptography, the error is:  Installing egg-scripts. uses namespace packages but the distribution does not require setuptools. Getting distribution for 'cryptography==0.2.1'.  no previously-included directories found matching 'documentation/_build' zip_safe flag not set; analyzing archive contents... six: module references __path__  Installed /tmp/easy_install-oUz7ei/cryptography-0.2.1/.eggs/six-1.10.0-py2.7.egg Searching for cffi>=0.8 Reading https://pypi.python.org/simple/cffi/ Best match: cffi 1.5.0 Downloading https://pypi.python.org/packages/source/c/cffi/cffi-1.5.0.tar.gz#md5=dec8441e67880494ee881305059af656 Processing cffi-1.5.0.tar.gz Writing /tmp/easy_install-oUz7ei/cryptography-0.2.1/temp/easy_install-Yf2Yl3/cffi-1.5.0/setup.cfg Running cffi-1.5.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-oUz7ei/cryptography-0.2.1/temp/easy_install-Yf2Yl3/cffi-1.5.0/egg-dist-tmp-A2kjMD c/_cffi_backend.c:15:17: fatal error: ffi.h: No such file or directory  #include <ffi.h>                  ^ compilation terminated. error: Setup script exited with error: command 'x86_64-linux-gnu-gcc' failed with exit status 1 An error occurred when trying to install cryptography 0.2.1. Look above this message for any errors that were output by easy_install. While:   Installing egg-scripts.   Getting distribution for 'cryptography==0.2.1'. Error: Couldn't install: cryptography 0.2.1   I don't know why it was failed. What is the reason. Is there something necessary when install it on ubuntu system?     ","Q_Votes":"62"},{"Q_Title":"How to install cryptography on ubuntu?","A_Content":"  Installing libssl-dev and python-dev was enough for me on ubuntu 16.04.     ","Language":"Python","Tags":["python","ubuntu","cryptography","pip"],"URL":"https://stackoverflow.com/questions/35144550/how-to-install-cryptography-on-ubuntu","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    My ubuntu is 14.04 LTS.  When I install cryptography, the error is:  Installing egg-scripts. uses namespace packages but the distribution does not require setuptools. Getting distribution for 'cryptography==0.2.1'.  no previously-included directories found matching 'documentation/_build' zip_safe flag not set; analyzing archive contents... six: module references __path__  Installed /tmp/easy_install-oUz7ei/cryptography-0.2.1/.eggs/six-1.10.0-py2.7.egg Searching for cffi>=0.8 Reading https://pypi.python.org/simple/cffi/ Best match: cffi 1.5.0 Downloading https://pypi.python.org/packages/source/c/cffi/cffi-1.5.0.tar.gz#md5=dec8441e67880494ee881305059af656 Processing cffi-1.5.0.tar.gz Writing /tmp/easy_install-oUz7ei/cryptography-0.2.1/temp/easy_install-Yf2Yl3/cffi-1.5.0/setup.cfg Running cffi-1.5.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-oUz7ei/cryptography-0.2.1/temp/easy_install-Yf2Yl3/cffi-1.5.0/egg-dist-tmp-A2kjMD c/_cffi_backend.c:15:17: fatal error: ffi.h: No such file or directory  #include <ffi.h>                  ^ compilation terminated. error: Setup script exited with error: command 'x86_64-linux-gnu-gcc' failed with exit status 1 An error occurred when trying to install cryptography 0.2.1. Look above this message for any errors that were output by easy_install. While:   Installing egg-scripts.   Getting distribution for 'cryptography==0.2.1'. Error: Couldn't install: cryptography 0.2.1   I don't know why it was failed. What is the reason. Is there something necessary when install it on ubuntu system?     ","Q_Votes":"62"},{"Q_Title":"How to have logarithmic bins in a Python histogram","A_Content":"  use logspace() to create a geometric sequence, and pass it to bins parameter. And set the scale of xaxis to log scale.  import pylab as pl import numpy as np  data = np.random.normal(size=10000) pl.hist(data, bins=np.logspace(np.log10(0.1),np.log10(1.0), 50)) pl.gca().set_xscale(\"log\") pl.show()        ","Language":"Python","Tags":["python","numpy","matplotlib","histogram"],"URL":"https://stackoverflow.com/questions/6855710/how-to-have-logarithmic-bins-in-a-python-histogram","A_Votes":"101","_type":"dict","isAccepted":"Yes","Q_Content":"    As far as I know the option Log=True in the histogram function only refers to the y-axis.  P.hist(d,bins=50,log=True,alpha=0.5,color='b',histtype='step')   I need the bins to be equally spaced in log10. Is there something that can do this?     ","Q_Votes":"63"},{"Q_Title":"How to have logarithmic bins in a Python histogram","A_Content":"  The most direct way is to just compute the log10 of the limits, compute linearly spaced bins, and then convert back by raising to the power of 10, as below:  import pylab as pl import numpy as np  data = np.random.normal(size=10000)  MIN, MAX = .01, 10.0  pl.figure() pl.hist(data, bins = 10 ** np.linspace(np.log10(MIN), np.log10(MAX), 50)) pl.gca().set_xscale(\"log\") pl.show()        ","Language":"Python","Tags":["python","numpy","matplotlib","histogram"],"URL":"https://stackoverflow.com/questions/6855710/how-to-have-logarithmic-bins-in-a-python-histogram","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    As far as I know the option Log=True in the histogram function only refers to the y-axis.  P.hist(d,bins=50,log=True,alpha=0.5,color='b',histtype='step')   I need the bins to be equally spaced in log10. Is there something that can do this?     ","Q_Votes":"63"},{"Q_Title":"How to have logarithmic bins in a Python histogram","A_Content":"  The following code indicates how you can use bins='auto' with the log scale.  import numpy as np import matplotlib.pyplot as plt  data = 10**np.random.normal(size=500)  _, bins = np.histogram(np.log10(data + 1), bins='auto') plt.hist(data, bins=10**bins); plt.gca().set_xscale(\"log\")      ","Language":"Python","Tags":["python","numpy","matplotlib","histogram"],"URL":"https://stackoverflow.com/questions/6855710/how-to-have-logarithmic-bins-in-a-python-histogram","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    As far as I know the option Log=True in the histogram function only refers to the y-axis.  P.hist(d,bins=50,log=True,alpha=0.5,color='b',histtype='step')   I need the bins to be equally spaced in log10. Is there something that can do this?     ","Q_Votes":"63"},{"Q_Title":"How to have logarithmic bins in a Python histogram","A_Content":"  In addition to what was stated, performing this on pandas dataframes works as well:  some_column_hist = dataframe['some_column'].plot(bins=np.logspace(-2, np.log10(max_value), 100), kind='hist', loglog=True, xlim=(0,max_value))   I would caution, that there may be an issue with normalizing the bins. Each bin is larger than the previous one, and therefore must be divided by it's size to normalize the frequencies before plotting, and it seems that neither my solution, nor HYRY's solution accounts for this.  Source: https://arxiv.org/pdf/cond-mat/0412004.pdf     ","Language":"Python","Tags":["python","numpy","matplotlib","histogram"],"URL":"https://stackoverflow.com/questions/6855710/how-to-have-logarithmic-bins-in-a-python-histogram","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    As far as I know the option Log=True in the histogram function only refers to the y-axis.  P.hist(d,bins=50,log=True,alpha=0.5,color='b',histtype='step')   I need the bins to be equally spaced in log10. Is there something that can do this?     ","Q_Votes":"63"},{"Q_Title":"Accessing dict_keys element by index in Python3","A_Content":"  Call list() on the dictionary instead:  keys = list(test)   In Python 3, the dict.keys() method returns a dictionary view object, which acts as a set. Iterating over the dictionary directly also yields keys, so turning a dictionary into a list results in a list of all the keys:  >>> test = {'foo': 'bar', 'hello': 'world'} >>> list(test) ['foo', 'hello'] >>> list(test)[0] 'foo'      ","Language":"Python","Tags":["python","dictionary","python-3.x","key"],"URL":"https://stackoverflow.com/questions/18552001/accessing-dict-keys-element-by-index-in-python3","A_Votes":"85","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to access a dict_key's element by its index:  test = {'foo': 'bar', 'hello': 'world'} keys = test.keys()  # dict_keys object  keys.index(0) AttributeError: 'dict_keys' object has no attribute 'index'   I want to get foo.  same with:  keys[0] TypeError: 'dict_keys' object does not support indexing   How can I do this?     ","Q_Votes":"63"},{"Q_Title":"Accessing dict_keys element by index in Python3","A_Content":"  Not a full answer but perhaps a useful hint. If it is really the first item you want*, then   next(iter(q))   is much faster than   list(q)[0]   for large dicts, since the whole thing doesn't have to be stored in memory.  For 10.000.000 items I found it to be almost 40.000 times faster.  *The first item in case of a dict being just a pseudo-random item before Python 3.6 (after that it's ordered in the standard implementation, although it's not advised to rely on it).     ","Language":"Python","Tags":["python","dictionary","python-3.x","key"],"URL":"https://stackoverflow.com/questions/18552001/accessing-dict-keys-element-by-index-in-python3","A_Votes":"34","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to access a dict_key's element by its index:  test = {'foo': 'bar', 'hello': 'world'} keys = test.keys()  # dict_keys object  keys.index(0) AttributeError: 'dict_keys' object has no attribute 'index'   I want to get foo.  same with:  keys[0] TypeError: 'dict_keys' object does not support indexing   How can I do this?     ","Q_Votes":"63"},{"Q_Title":"Accessing dict_keys element by index in Python3","A_Content":"  Another different approach would be use a pandas Series like this:  import pandas as pd pd.Series(dict).index.values.tolist()   This might be overkilling and not very fast, but for me is very clear and readable.     ","Language":"Python","Tags":["python","dictionary","python-3.x","key"],"URL":"https://stackoverflow.com/questions/18552001/accessing-dict-keys-element-by-index-in-python3","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to access a dict_key's element by its index:  test = {'foo': 'bar', 'hello': 'world'} keys = test.keys()  # dict_keys object  keys.index(0) AttributeError: 'dict_keys' object has no attribute 'index'   I want to get foo.  same with:  keys[0] TypeError: 'dict_keys' object does not support indexing   How can I do this?     ","Q_Votes":"63"},{"Q_Title":"Plotting a list of (x, y) coordinates in python matplotlib","A_Content":"  As per this example:  import numpy as np import matplotlib.pyplot as plt  N = 50 x = np.random.rand(N) y = np.random.rand(N)  plt.scatter(x, y) plt.show()   will produce:    To unpack your data from pairs into lists use zip:  x, y = zip(*li)   So, the one-liner:  plt.scatter(*zip(*li))      ","Language":"Python","Tags":["python","matplotlib","plot","coordinates"],"URL":"https://stackoverflow.com/questions/21519203/plotting-a-list-of-x-y-coordinates-in-python-matplotlib","A_Votes":"101","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a list of pairs (a, b) that I would like to plot with matplotlib in python as actual x-y coordinates. Currently, it is making two plots, where the index of the list gives the x-coordinate, and the first plot's y values are the as in the pairs and the second plot's y values are the bs in the pairs.  To clarify, my data looks like this: li = [(a,b), (c,d), ... , (t, u)] I want to do a one-liner that just calls plt.plot() incorrect. If I didn't require a one-liner I could trivially do:   xs = [x[0] for x in li] ys = [x[1] for x in li] plt.plot(xs, ys)    How can I get matplotlib to plot these pairs as x-y coordinates?   Thanks for all the help!     ","Q_Votes":"63"},{"Q_Title":"Plotting a list of (x, y) coordinates in python matplotlib","A_Content":"  If you have a numpy array you can do this:  import numpy as np from matplotlib import pyplot as plt  data = np.array([     [1, 2],     [2, 3],     [3, 6], ]) x, y = data.T plt.scatter(x,y)      ","Language":"Python","Tags":["python","matplotlib","plot","coordinates"],"URL":"https://stackoverflow.com/questions/21519203/plotting-a-list-of-x-y-coordinates-in-python-matplotlib","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of pairs (a, b) that I would like to plot with matplotlib in python as actual x-y coordinates. Currently, it is making two plots, where the index of the list gives the x-coordinate, and the first plot's y values are the as in the pairs and the second plot's y values are the bs in the pairs.  To clarify, my data looks like this: li = [(a,b), (c,d), ... , (t, u)] I want to do a one-liner that just calls plt.plot() incorrect. If I didn't require a one-liner I could trivially do:   xs = [x[0] for x in li] ys = [x[1] for x in li] plt.plot(xs, ys)    How can I get matplotlib to plot these pairs as x-y coordinates?   Thanks for all the help!     ","Q_Votes":"63"},{"Q_Title":"Plotting a list of (x, y) coordinates in python matplotlib","A_Content":"  If you want to plot a single line connecting all the points in the list  plt . plot ( li [ : ] )  plt . show ( )   This will plot a line connecting all the pairs in the list as points on a Cartesian plane from the starting of the list to the end. I hope that this is what you wanted.     ","Language":"Python","Tags":["python","matplotlib","plot","coordinates"],"URL":"https://stackoverflow.com/questions/21519203/plotting-a-list-of-x-y-coordinates-in-python-matplotlib","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of pairs (a, b) that I would like to plot with matplotlib in python as actual x-y coordinates. Currently, it is making two plots, where the index of the list gives the x-coordinate, and the first plot's y values are the as in the pairs and the second plot's y values are the bs in the pairs.  To clarify, my data looks like this: li = [(a,b), (c,d), ... , (t, u)] I want to do a one-liner that just calls plt.plot() incorrect. If I didn't require a one-liner I could trivially do:   xs = [x[0] for x in li] ys = [x[1] for x in li] plt.plot(xs, ys)    How can I get matplotlib to plot these pairs as x-y coordinates?   Thanks for all the help!     ","Q_Votes":"63"},{"Q_Title":"Does Python have a stack/heap and how is memory managed?","A_Content":"     How are variables and memory managed in Python.   Automagically! No, really, you just create an object and the Python Virtual Machine handles the memory needed and where it shall be placed in the memory layout.     Does it have a stack and a heap and what algorithm is used to manage   memory?   When we are talking about CPython it uses a private heap for storing objects. From the CPython C API documentation:     Memory management in Python involves a private heap containing all   Python objects and data structures. The management of this private   heap is ensured internally by the Python memory manager. The Python   memory manager has different components which deal with various   dynamic storage management aspects, like sharing, segmentation,   preallocation or caching.   Memory reclamation is mostly handled by reference counting. That is, the Python VM keeps an internal journal of how many references refer to an object, and automatically garbage collects it when there are no more references referring to it. In addition, there is a mechanism to break circular references (which reference counting can't handle) by detecting unreachable \"islands\" of objects, somewhat in reverse of traditional GC algorithms that try to find all the reachable objects.  NOTE: Please keep in mind that this information is CPython specific. Other python implementations, such as pypy, iron python, jython and others may differ from one another and from CPython when it comes to their implementation specifics. To understand that better, it may help to understand that there is a difference between Python the semantics (the language) and the underlying implementation     Given this knowledge are there any recommendations on memory management for large number/data crunching?   Now I can not speak about this, but I am sure that NumPy (the most popular python library for number crunching) has mechanisms that handle memory consumption gracefully.  If you would like to know more about Python's Internals take a look at these resources:    Stepping through CPython (video) A presentation about the internals of the Python Virtual Machine In true hacker spirit, the CPython Object Allocator source code      ","Language":"Python","Tags":["python","memory","memory-management"],"URL":"https://stackoverflow.com/questions/14546178/does-python-have-a-stack-heap-and-how-is-memory-managed","A_Votes":"82","_type":"dict","isAccepted":"Yes","Q_Content":"    How are variables and memory managed in Python? Does it have a stack and a heap and what algorithm is used to manage memory? Given this knowledge are there any recommendations on memory management for large number/data crunching?     ","Q_Votes":"63"},{"Q_Title":"Does Python have a stack/heap and how is memory managed?","A_Content":"  Python doesn't have any such thing.  Python is the language and does not specify how exactly implementations must achieve the semantics defined by Python the language.  Every implementation (CPython, PyPy, IronPython, Stackless, Jython...) is free to do its own thing!  In CPython, all objects live on the heap:     Memory management in Python involves a private heap containing all Python objects and data structures.1   The CPython virtual machine is stack based:  >>> def g():     x = 1     y = 2     return f(x, y)  >>> import dis >>> dis.dis(g)   2           0 LOAD_CONST           1 (1) # Push 1 onto the stack               3 STORE_FAST           0 (x) # Stores top of stack into local var x    3           6 LOAD_CONST           2 (2) # Push 2 onto stack               9 STORE_FAST           1 (y) # Store TOS into local var y    4          12 LOAD_GLOBAL          0 (f) # Push f onto stack              15 LOAD_FAST            0 (x) # Push x onto stack              18 LOAD_FAST            1 (y) # Push y onto stack              21 CALL_FUNCTION        2     # Execute function with 2                                             # f's return value is pushed on stack              24 RETURN_VALUE               # Return TOS to caller (result of f)   Keep in mind, that this is CPython specific. The stack does not contain the actual values though, it keeps references to those objects.  1: Source     ","Language":"Python","Tags":["python","memory","memory-management"],"URL":"https://stackoverflow.com/questions/14546178/does-python-have-a-stack-heap-and-how-is-memory-managed","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    How are variables and memory managed in Python? Does it have a stack and a heap and what algorithm is used to manage memory? Given this knowledge are there any recommendations on memory management for large number/data crunching?     ","Q_Votes":"63"},{"Q_Title":"Can I catch error codes when using Fabric to run() calls in a remote shell?","A_Content":"  You can prevent aborting on non-zero exit codes by using the settings context manager and the warn_only setting:  from fabric.api import settings  with settings(warn_only=True):     result = run('pngout old.png new.png')     if result.return_code == 0:          do something     elif result.return_code == 2:          do something else      else: #print error to user         print result         raise SystemExit()   Update: My answer is outdated. See comments below.      ","Language":"Python","Tags":["python","error-handling","fabric"],"URL":"https://stackoverflow.com/questions/4888568/can-i-catch-error-codes-when-using-fabric-to-run-calls-in-a-remote-shell","A_Votes":"89","_type":"dict","isAccepted":"Yes","Q_Content":"    Normally Fabric quits as soon as a run() call returns a non-zero exit code. For some calls, however, this is expected. For example, PNGOut returns an error code of 2 when it is unable to compress a file.  Currently I can only circumvent this limitation by either using shell logic (do_something_that_fails || true or do_something_that_fails || do_something_else), but I'd rather be able to keep my logic in plain Python (as is the Fabric promise).  Is there a way to check for an error code and react to it rather than having Fabric panic and die? I still want the default behaviours for other calls, so changing its behaviour by modifying the environment doesn't seem like a good option (and as far as I recall, you can only use that to tell it to warn instead of dying anyway).     ","Q_Votes":"63"},{"Q_Title":"Can I catch error codes when using Fabric to run() calls in a remote shell?","A_Content":"  Yes, you can. Just change the environment's abort_exception. For example:  from fabric.api import settings  class FabricException(Exception):     pass  with settings(abort_exception = FabricException):     try:         run(<something that might fail>)     except FabricException:         <handle the exception>   The documentation on abort_exception is here.     ","Language":"Python","Tags":["python","error-handling","fabric"],"URL":"https://stackoverflow.com/questions/4888568/can-i-catch-error-codes-when-using-fabric-to-run-calls-in-a-remote-shell","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    Normally Fabric quits as soon as a run() call returns a non-zero exit code. For some calls, however, this is expected. For example, PNGOut returns an error code of 2 when it is unable to compress a file.  Currently I can only circumvent this limitation by either using shell logic (do_something_that_fails || true or do_something_that_fails || do_something_else), but I'd rather be able to keep my logic in plain Python (as is the Fabric promise).  Is there a way to check for an error code and react to it rather than having Fabric panic and die? I still want the default behaviours for other calls, so changing its behaviour by modifying the environment doesn't seem like a good option (and as far as I recall, you can only use that to tell it to warn instead of dying anyway).     ","Q_Votes":"63"},{"Q_Title":"Can I catch error codes when using Fabric to run() calls in a remote shell?","A_Content":"  Apparently messing with the environment is the answer.  fabric.api.settings can be used as a context manager (with with) to apply it to individual statements. The return value of run(), local() and sudo() calls isn't just the output of the shell command, but also has special properties (return_code and failed) that allow reacting to the errors.  I guess I was looking for something closer to the behaviour of subprocess.Popen or Python's usual exception handling.     ","Language":"Python","Tags":["python","error-handling","fabric"],"URL":"https://stackoverflow.com/questions/4888568/can-i-catch-error-codes-when-using-fabric-to-run-calls-in-a-remote-shell","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Normally Fabric quits as soon as a run() call returns a non-zero exit code. For some calls, however, this is expected. For example, PNGOut returns an error code of 2 when it is unable to compress a file.  Currently I can only circumvent this limitation by either using shell logic (do_something_that_fails || true or do_something_that_fails || do_something_else), but I'd rather be able to keep my logic in plain Python (as is the Fabric promise).  Is there a way to check for an error code and react to it rather than having Fabric panic and die? I still want the default behaviours for other calls, so changing its behaviour by modifying the environment doesn't seem like a good option (and as far as I recall, you can only use that to tell it to warn instead of dying anyway).     ","Q_Votes":"63"},{"Q_Title":"Can I catch error codes when using Fabric to run() calls in a remote shell?","A_Content":"  try this  from fabric.api import run, env env.warn_only = True # if you want to ignore exceptions and handle them yurself  command = \"your command\" x = run(command, capture=True) # run or local or sudo if(x.stderr != \"\"):     error = \"On %s: %s\" %(command, x.stderr)     print error     print x.return_code # which may be 1 or 2     # do what you want or     raise Exception(error) #optional else:     print \"the output of %s is: %s\" %(command, x)     print x.return_code # which is 0      ","Language":"Python","Tags":["python","error-handling","fabric"],"URL":"https://stackoverflow.com/questions/4888568/can-i-catch-error-codes-when-using-fabric-to-run-calls-in-a-remote-shell","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Normally Fabric quits as soon as a run() call returns a non-zero exit code. For some calls, however, this is expected. For example, PNGOut returns an error code of 2 when it is unable to compress a file.  Currently I can only circumvent this limitation by either using shell logic (do_something_that_fails || true or do_something_that_fails || do_something_else), but I'd rather be able to keep my logic in plain Python (as is the Fabric promise).  Is there a way to check for an error code and react to it rather than having Fabric panic and die? I still want the default behaviours for other calls, so changing its behaviour by modifying the environment doesn't seem like a good option (and as far as I recall, you can only use that to tell it to warn instead of dying anyway).     ","Q_Votes":"63"},{"Q_Title":"What is the pythonic way to avoid default parameters that are empty lists?","A_Content":"  def myFunc(working_list=None):     if working_list is None:          working_list = []     working_list.append(\"a\")     print working_list   is how I do it.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/366422/what-is-the-pythonic-way-to-avoid-default-parameters-that-are-empty-lists","A_Votes":"94","_type":"dict","isAccepted":"Yes","Q_Content":"    Sometimes it seems natural to have a default parameter which is an empty list. Yet Python gives unexpected behavior in these situations.    If for example, I have a function:  def myFunc(working_list = []):     working_list.append(\"a\")     print working_list   The first time it is called with the default will work, but calls after that will use a constantly updating list.  So, what is the pythonic way to get the behavior I desire (a fresh list on each call)?     ","Q_Votes":"63"},{"Q_Title":"What is the pythonic way to avoid default parameters that are empty lists?","A_Content":"  Not that it matters in this case, but you can use object identity to test for None:  if working_list is None: working_list = []   You could also take advantage of how the boolean operator or is defined in python:  working_list = working_list or []   Though this will behave unexpectedly if the caller gives you an empty list (which counts as false) as working_list and expects your function to modify the list he gave it.      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/366422/what-is-the-pythonic-way-to-avoid-default-parameters-that-are-empty-lists","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    Sometimes it seems natural to have a default parameter which is an empty list. Yet Python gives unexpected behavior in these situations.    If for example, I have a function:  def myFunc(working_list = []):     working_list.append(\"a\")     print working_list   The first time it is called with the default will work, but calls after that will use a constantly updating list.  So, what is the pythonic way to get the behavior I desire (a fresh list on each call)?     ","Q_Votes":"63"},{"Q_Title":"What is the pythonic way to avoid default parameters that are empty lists?","A_Content":"  Existing answers have already provided the direct solutions as asked for. However, since this is a very common pitfall for new Python programmers, it worth to add the explanation why python behaves this way, which is nicely summarized in \"the Hitchhikers Guide to Python\" as \"Mutable Default Arguments\": http://docs.python-guide.org/en/latest/writing/gotchas/  Quote:  \"Python’s default arguments are evaluated once when the function is defined, not each time the function is called (like it is in say, Ruby). This means that if you use a mutable default argument and mutate it, you will and have mutated that object for all future calls to the function as well\"  Sample code to implement it:   def foo(element, to=None):     if to is None:         to = []     to.append(element)     return to      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/366422/what-is-the-pythonic-way-to-avoid-default-parameters-that-are-empty-lists","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    Sometimes it seems natural to have a default parameter which is an empty list. Yet Python gives unexpected behavior in these situations.    If for example, I have a function:  def myFunc(working_list = []):     working_list.append(\"a\")     print working_list   The first time it is called with the default will work, but calls after that will use a constantly updating list.  So, what is the pythonic way to get the behavior I desire (a fresh list on each call)?     ","Q_Votes":"63"},{"Q_Title":"What is the pythonic way to avoid default parameters that are empty lists?","A_Content":"  If the intent of the function is to modify the parameter passed as working_list, see HenryR's answer (=None, check for None inside).  But if you didn't intend to mutate the argument, just use it as starting point for a list, you can simply copy it:  def myFunc(starting_list = []):     starting_list = list(starting_list)     starting_list.append(\"a\")     print starting_list   (or in this simple case just print starting_list + [\"a\"] but I guess that was just a toy example)  In general, mutating your arguments is bad style in Python.  The only functions that are fully expected to mutate an object are methods of the object.  It's even rarer to mutate an optional argument — is a side effect that happens only in some calls really the best interface?   If you do it from the C habit of \"output arguments\", that's completely unnecessary - you can always return multiple values as a tuple. If you do this to efficiently build a long list of results without building intermediate lists, consider writing it as a generator and using result_list.extend(myFunc()) when you are calling it.  This way your calling conventions remains very clean.   One pattern where mutating an optional arg is frequently done is a hidden \"memo\" arg in recursive functions:  def depth_first_walk_graph(graph, node, _visited=None):     if _visited is None:         _visited = set()  # create memo once in top-level call      if node in _visited:         return     _visited.add(node)     for neighbour in graph[node]:         depth_first_walk_graph(graph, neighbour, _visited)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/366422/what-is-the-pythonic-way-to-avoid-default-parameters-that-are-empty-lists","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    Sometimes it seems natural to have a default parameter which is an empty list. Yet Python gives unexpected behavior in these situations.    If for example, I have a function:  def myFunc(working_list = []):     working_list.append(\"a\")     print working_list   The first time it is called with the default will work, but calls after that will use a constantly updating list.  So, what is the pythonic way to get the behavior I desire (a fresh list on each call)?     ","Q_Votes":"63"},{"Q_Title":"What is the pythonic way to avoid default parameters that are empty lists?","A_Content":"  I might be off-topic, but remember that if you just want to pass a variable number of arguments, the pythonic way is to pass a tuple *args or a dictionary **kargs. These are optional and are better than the syntax myFunc([1, 2, 3]).  If you want to pass a tuple:  def myFunc(arg1, *args):   print args   w = []   w += args   print w >>>myFunc(1, 2, 3, 4, 5, 6, 7) (2, 3, 4, 5, 6, 7) [2, 3, 4, 5, 6, 7]   If you want to pass a dictionary:  def myFunc(arg1, **kargs):    print kargs >>>myFunc(1, option1=2, option2=3) {'option2' : 2, 'option1' : 3}      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/366422/what-is-the-pythonic-way-to-avoid-default-parameters-that-are-empty-lists","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Sometimes it seems natural to have a default parameter which is an empty list. Yet Python gives unexpected behavior in these situations.    If for example, I have a function:  def myFunc(working_list = []):     working_list.append(\"a\")     print working_list   The first time it is called with the default will work, but calls after that will use a constantly updating list.  So, what is the pythonic way to get the behavior I desire (a fresh list on each call)?     ","Q_Votes":"63"},{"Q_Title":"What is the pythonic way to avoid default parameters that are empty lists?","A_Content":"  There have already been good and correct answers provided. I just wanted to give another syntax to write what you want to do which I find more beautiful when you for instance want to create a class with default empty lists:  class Node(object):     def __init__(self, _id, val, parents=None, children=None):         self.id = _id         self.val = val         self.parents = parents if parents is not None else []         self.children = children if children is not None else []   This snippet makes use of the if else operator syntax. I like it especially because it's a neat little one-liner without colons, etc. involved and it nearly reads like a normal English sentence. :)  In your case you could write  def myFunc(working_list=None):     working_list = [] if working_list is None else working_list     working_list.append(\"a\")     print working_list      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/366422/what-is-the-pythonic-way-to-avoid-default-parameters-that-are-empty-lists","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Sometimes it seems natural to have a default parameter which is an empty list. Yet Python gives unexpected behavior in these situations.    If for example, I have a function:  def myFunc(working_list = []):     working_list.append(\"a\")     print working_list   The first time it is called with the default will work, but calls after that will use a constantly updating list.  So, what is the pythonic way to get the behavior I desire (a fresh list on each call)?     ","Q_Votes":"63"},{"Q_Title":"Representing graphs (data structure) in Python","A_Content":"  Even though this is a somewhat old question, I thought I'd give a practical answer for anyone stumbling across this.  Let's say you get your input data for your connections as a list of tuples like so:  [('A', 'B'), ('B', 'C'), ('B', 'D'), ('C', 'D'), ('E', 'F'), ('F', 'C')]   The data structure I've found to be most useful and efficient for graphs in Python is a dict of sets. This will be the underlying structure for our Graph class. You also have to know if these connections are arcs (directed, connect one way) or edges (undirected, connect both ways). We'll handle that by adding a directed parameter to the Graph.__init__ method. We'll also add some other helpful methods.  from collections import defaultdict   class Graph(object):     \"\"\" Graph data structure, undirected by default. \"\"\"      def __init__(self, connections, directed=False):         self._graph = defaultdict(set)         self._directed = directed         self.add_connections(connections)      def add_connections(self, connections):         \"\"\" Add connections (list of tuple pairs) to graph \"\"\"          for node1, node2 in connections:             self.add(node1, node2)      def add(self, node1, node2):         \"\"\" Add connection between node1 and node2 \"\"\"          self._graph[node1].add(node2)         if not self._directed:             self._graph[node2].add(node1)      def remove(self, node):         \"\"\" Remove all references to node \"\"\"          for n, cxns in self._graph.iteritems():             try:                 cxns.remove(node)             except KeyError:                 pass         try:             del self._graph[node]         except KeyError:             pass      def is_connected(self, node1, node2):         \"\"\" Is node1 directly connected to node2 \"\"\"          return node1 in self._graph and node2 in self._graph[node1]      def find_path(self, node1, node2, path=[]):         \"\"\" Find any path between node1 and node2 (may not be shortest) \"\"\"          path = path + [node1]         if node1 == node2:             return path         if node1 not in self._graph:             return None         for node in self._graph[node1]:             if node not in path:                 new_path = self.find_path(node, node2, path)                 if new_path:                     return new_path         return None      def __str__(self):         return '{}({})'.format(self.__class__.__name__, dict(self._graph))   I'll leave it as an \"exercise for the reader\" to create a find_shortest_path and other methods.  Let's see this in action though...  >>> connections = [('A', 'B'), ('B', 'C'), ('B', 'D'),                    ('C', 'D'), ('E', 'F'), ('F', 'C')] >>> g = Graph(connections, directed=True) >>> pprint(g._graph) {'A': {'B'},  'B': {'D', 'C'},  'C': {'D'},  'E': {'F'},  'F': {'C'}}  >>> g = Graph(connections)  # undirected >>> pprint(g._graph) {'A': {'B'},  'B': {'D', 'A', 'C'},  'C': {'D', 'F', 'B'},  'D': {'C', 'B'},  'E': {'F'},  'F': {'E', 'C'}}  >>> g.add('E', 'D') >>> pprint(g._graph) {'A': {'B'},  'B': {'D', 'A', 'C'},  'C': {'D', 'F', 'B'},  'D': {'C', 'E', 'B'},  'E': {'D', 'F'},  'F': {'E', 'C'}}  >>> g.remove('A') >>> pprint(g._graph) {'B': {'D', 'C'},  'C': {'D', 'F', 'B'},  'D': {'C', 'E', 'B'},  'E': {'D', 'F'},  'F': {'E', 'C'}}  >>> g.add('G', 'B') >>> pprint(g._graph) {'B': {'D', 'G', 'C'},  'C': {'D', 'F', 'B'},  'D': {'C', 'E', 'B'},  'E': {'D', 'F'},  'F': {'E', 'C'},  'G': {'B'}}  >>> g.find_path('G', 'E') ['G', 'B', 'D', 'C', 'F', 'E']      ","Language":"Python","Tags":["python","data-structures","graph"],"URL":"https://stackoverflow.com/questions/19472530/representing-graphs-data-structure-in-python","A_Votes":"92","_type":"dict","isAccepted":"Yes","Q_Content":"    How can one neatly represent a graph in Python? (Starting from scratch i.e. no libraries!)What data structure (e.g. dicts/tuples/dict(tuples)) will be fast but also memory efficient?One must be able to do various graph operations on it. As pointed out, the various graph representations might help. How does one go about implementing them in Python?As for the libraries, this question has quite good answers.     ","Q_Votes":"63"},{"Q_Title":"Representing graphs (data structure) in Python","A_Content":"  NetworkX is an awesome Python graph library. You'll be hard pressed to find something you need that it doesn't already do.  And it's open source so you can see how they implemented their algorithms. You can also add additional algorithms.  https://github.com/networkx/networkx/tree/master/networkx/algorithms     ","Language":"Python","Tags":["python","data-structures","graph"],"URL":"https://stackoverflow.com/questions/19472530/representing-graphs-data-structure-in-python","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    How can one neatly represent a graph in Python? (Starting from scratch i.e. no libraries!)What data structure (e.g. dicts/tuples/dict(tuples)) will be fast but also memory efficient?One must be able to do various graph operations on it. As pointed out, the various graph representations might help. How does one go about implementing them in Python?As for the libraries, this question has quite good answers.     ","Q_Votes":"63"},{"Q_Title":"Representing graphs (data structure) in Python","A_Content":"  First, the choice of classical list vs. matrix representations depends on the purpose (on what do you want to do with the representation). The well-known problems and algorithms are related to the choice. The choice of the abstract representation kind of dictates how it should be implemented.   Second, the question is whether the vertices and edges should be expressed only in terms of existence, or whether they carry some extra information.  From Python built-in data types point-of-view, any value contained elsewhere is expressed as a (hidden) reference to the target object. If it is a variable (i.e. named reference), then the name and the reference is always stored in (an internal) dictionary. If you do not need names, then the reference can be stored in your own container -- here probably Python list will always be used for the list as abstraction.  Python list is implemented as a dynamic array of references, Python tuple is implemented as static array of references with constant content (the value of references cannot be changed). Because of that they can be easily indexed. This way, the list can be used also for implementation of matrices.  Another way to represent matrices are the arrays implemented by the standard module array -- more constrained with respect to the stored type, homogeneous value. The elements store the value directly. (The list stores the references to the value objects instead). This way, it is more memory efficient and also the access to the value is faster.  Sometimes, you may find useful even more restricted representation like bytearray.     ","Language":"Python","Tags":["python","data-structures","graph"],"URL":"https://stackoverflow.com/questions/19472530/representing-graphs-data-structure-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    How can one neatly represent a graph in Python? (Starting from scratch i.e. no libraries!)What data structure (e.g. dicts/tuples/dict(tuples)) will be fast but also memory efficient?One must be able to do various graph operations on it. As pointed out, the various graph representations might help. How does one go about implementing them in Python?As for the libraries, this question has quite good answers.     ","Q_Votes":"63"},{"Q_Title":"Representing graphs (data structure) in Python","A_Content":"  There are two excellent graph libraries NetworkX and igraph. You can find both library source codes on GitHub. You can always see how the functions are written. But I prefer NetworkX because of its ease to understand. See their codes how they make the functions. You will get multiples idea and then chose how you want to make a graph using data structures.     ","Language":"Python","Tags":["python","data-structures","graph"],"URL":"https://stackoverflow.com/questions/19472530/representing-graphs-data-structure-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    How can one neatly represent a graph in Python? (Starting from scratch i.e. no libraries!)What data structure (e.g. dicts/tuples/dict(tuples)) will be fast but also memory efficient?One must be able to do various graph operations on it. As pointed out, the various graph representations might help. How does one go about implementing them in Python?As for the libraries, this question has quite good answers.     ","Q_Votes":"63"},{"Q_Title":"What is an efficient way of inserting thousands of records into an SQLite table using Django?","A_Content":"  You want to check out django.db.transaction.commit_manually.  http://docs.djangoproject.com/en/dev/topics/db/transactions/#django-db-transaction-commit-manually  So it would be something like:  from django.db import transaction  @transaction.commit_manually def viewfunc(request):     ...     for item in items:         entry = Entry(a1=item.a1, a2=item.a2)         entry.save()     transaction.commit()   Which will only commit once, instead at each save().  In django 1.3 context managers were introduced. So now you can use transaction.commit_on_success() in a similar way:  from django.db import transaction  def viewfunc(request):     ...     with transaction.commit_on_success():         for item in items:             entry = Entry(a1=item.a1, a2=item.a2)             entry.save()   In django 1.4, bulk_create was added, allowing you to create lists of your model objects and then commit them all at once.    NOTE the save method will not be called when using bulk create.  >>> Entry.objects.bulk_create([ ...     Entry(headline=\"Django 1.0 Released\"), ...     Entry(headline=\"Django 1.1 Announced\"), ...     Entry(headline=\"Breaking: Django is awesome\") ... ])   In django 1.6, transaction.atomic was introduced, intended to replace now legacy functions commit_on_success and commit_manually.  from the django documentation on atomic:   atomic is usable both as a decorator:  from django.db import transaction  @transaction.atomic def viewfunc(request):     # This code executes inside a transaction.     do_stuff()   and as a context manager:  from django.db import transaction  def viewfunc(request):     # This code executes in autocommit mode (Django's default).     do_stuff()      with transaction.atomic():         # This code executes inside a transaction.         do_more_stuff()      ","Language":"Python","Tags":["python","sql","django","sqlite","insert"],"URL":"https://stackoverflow.com/questions/1136106/what-is-an-efficient-way-of-inserting-thousands-of-records-into-an-sqlite-table","A_Votes":"110","_type":"dict","isAccepted":"Yes","Q_Content":"    I have to insert 8000+ records into a SQLite database using Django's ORM. This operation needs to be run as a cronjob about once per minute. At the moment I'm using a for loop to iterate through all the items and then insert them one by one. Example:  for item in items:     entry = Entry(a1=item.a1, a2=item.a2)     entry.save()   What is an efficient way of doing this?  Edit: A little comparison between the two insertion methods.  Without commit_manually decorator (11245 records):  nox@noxdevel marinetraffic]$ time python manage.py insrec               real    1m50.288s user    0m6.710s sys     0m23.445s   Using commit_manually decorator (11245 records):  [nox@noxdevel marinetraffic]$ time python manage.py insrec                  real    0m18.464s user    0m5.433s sys     0m10.163s   Note: The test script also does some other operations besides inserting into the database (downloads a ZIP file, extracts an XML file from the ZIP archive, parses the XML file) so the time needed for execution does not necessarily represent the time needed to insert the records.     ","Q_Votes":"63"},{"Q_Title":"What is an efficient way of inserting thousands of records into an SQLite table using Django?","A_Content":"  Bulk creation is available in Django 1.4:  https://django.readthedocs.io/en/1.4/ref/models/querysets.html#bulk-create     ","Language":"Python","Tags":["python","sql","django","sqlite","insert"],"URL":"https://stackoverflow.com/questions/1136106/what-is-an-efficient-way-of-inserting-thousands-of-records-into-an-sqlite-table","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I have to insert 8000+ records into a SQLite database using Django's ORM. This operation needs to be run as a cronjob about once per minute. At the moment I'm using a for loop to iterate through all the items and then insert them one by one. Example:  for item in items:     entry = Entry(a1=item.a1, a2=item.a2)     entry.save()   What is an efficient way of doing this?  Edit: A little comparison between the two insertion methods.  Without commit_manually decorator (11245 records):  nox@noxdevel marinetraffic]$ time python manage.py insrec               real    1m50.288s user    0m6.710s sys     0m23.445s   Using commit_manually decorator (11245 records):  [nox@noxdevel marinetraffic]$ time python manage.py insrec                  real    0m18.464s user    0m5.433s sys     0m10.163s   Note: The test script also does some other operations besides inserting into the database (downloads a ZIP file, extracts an XML file from the ZIP archive, parses the XML file) so the time needed for execution does not necessarily represent the time needed to insert the records.     ","Q_Votes":"63"},{"Q_Title":"What is an efficient way of inserting thousands of records into an SQLite table using Django?","A_Content":"  Have a look at this. It's meant for use out-of-the-box with MySQL only, but there are pointers on what to do for other databases.     ","Language":"Python","Tags":["python","sql","django","sqlite","insert"],"URL":"https://stackoverflow.com/questions/1136106/what-is-an-efficient-way-of-inserting-thousands-of-records-into-an-sqlite-table","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have to insert 8000+ records into a SQLite database using Django's ORM. This operation needs to be run as a cronjob about once per minute. At the moment I'm using a for loop to iterate through all the items and then insert them one by one. Example:  for item in items:     entry = Entry(a1=item.a1, a2=item.a2)     entry.save()   What is an efficient way of doing this?  Edit: A little comparison between the two insertion methods.  Without commit_manually decorator (11245 records):  nox@noxdevel marinetraffic]$ time python manage.py insrec               real    1m50.288s user    0m6.710s sys     0m23.445s   Using commit_manually decorator (11245 records):  [nox@noxdevel marinetraffic]$ time python manage.py insrec                  real    0m18.464s user    0m5.433s sys     0m10.163s   Note: The test script also does some other operations besides inserting into the database (downloads a ZIP file, extracts an XML file from the ZIP archive, parses the XML file) so the time needed for execution does not necessarily represent the time needed to insert the records.     ","Q_Votes":"63"},{"Q_Title":"What is an efficient way of inserting thousands of records into an SQLite table using Django?","A_Content":"  You might be better off bulk-loading the items - prepare a file and use a bulk load tool.  This will be vastly more efficient than 8000 individual inserts.     ","Language":"Python","Tags":["python","sql","django","sqlite","insert"],"URL":"https://stackoverflow.com/questions/1136106/what-is-an-efficient-way-of-inserting-thousands-of-records-into-an-sqlite-table","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have to insert 8000+ records into a SQLite database using Django's ORM. This operation needs to be run as a cronjob about once per minute. At the moment I'm using a for loop to iterate through all the items and then insert them one by one. Example:  for item in items:     entry = Entry(a1=item.a1, a2=item.a2)     entry.save()   What is an efficient way of doing this?  Edit: A little comparison between the two insertion methods.  Without commit_manually decorator (11245 records):  nox@noxdevel marinetraffic]$ time python manage.py insrec               real    1m50.288s user    0m6.710s sys     0m23.445s   Using commit_manually decorator (11245 records):  [nox@noxdevel marinetraffic]$ time python manage.py insrec                  real    0m18.464s user    0m5.433s sys     0m10.163s   Note: The test script also does some other operations besides inserting into the database (downloads a ZIP file, extracts an XML file from the ZIP archive, parses the XML file) so the time needed for execution does not necessarily represent the time needed to insert the records.     ","Q_Votes":"63"},{"Q_Title":"What is an efficient way of inserting thousands of records into an SQLite table using Django?","A_Content":"  You should check out DSE. I wrote DSE to solve these kinds of problems ( massive insert or updates ). Using the django orm is a dead-end, you got to do it in plain SQL and DSE takes care of much of that for you.  Thomas     ","Language":"Python","Tags":["python","sql","django","sqlite","insert"],"URL":"https://stackoverflow.com/questions/1136106/what-is-an-efficient-way-of-inserting-thousands-of-records-into-an-sqlite-table","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have to insert 8000+ records into a SQLite database using Django's ORM. This operation needs to be run as a cronjob about once per minute. At the moment I'm using a for loop to iterate through all the items and then insert them one by one. Example:  for item in items:     entry = Entry(a1=item.a1, a2=item.a2)     entry.save()   What is an efficient way of doing this?  Edit: A little comparison between the two insertion methods.  Without commit_manually decorator (11245 records):  nox@noxdevel marinetraffic]$ time python manage.py insrec               real    1m50.288s user    0m6.710s sys     0m23.445s   Using commit_manually decorator (11245 records):  [nox@noxdevel marinetraffic]$ time python manage.py insrec                  real    0m18.464s user    0m5.433s sys     0m10.163s   Note: The test script also does some other operations besides inserting into the database (downloads a ZIP file, extracts an XML file from the ZIP archive, parses the XML file) so the time needed for execution does not necessarily represent the time needed to insert the records.     ","Q_Votes":"63"},{"Q_Title":"What is an efficient way of inserting thousands of records into an SQLite table using Django?","A_Content":"  To answer the question particularly with regard to SQLite, as asked, while I have just now confirmed that bulk_create does provide a tremendous speedup there is a limitation with SQLite: \"The default is to create all objects in one batch, except for SQLite where the default is such that at maximum 999 variables per query is used.\"  The quoted stuff is from the docs--- A-IV provided a link.   What I have to add is that this djangosnippets entry by alpar also seems to be working for me. It's a little wrapper that breaks the big batch that you want to process into smaller batches, managing the 999 variables limit.     ","Language":"Python","Tags":["python","sql","django","sqlite","insert"],"URL":"https://stackoverflow.com/questions/1136106/what-is-an-efficient-way-of-inserting-thousands-of-records-into-an-sqlite-table","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have to insert 8000+ records into a SQLite database using Django's ORM. This operation needs to be run as a cronjob about once per minute. At the moment I'm using a for loop to iterate through all the items and then insert them one by one. Example:  for item in items:     entry = Entry(a1=item.a1, a2=item.a2)     entry.save()   What is an efficient way of doing this?  Edit: A little comparison between the two insertion methods.  Without commit_manually decorator (11245 records):  nox@noxdevel marinetraffic]$ time python manage.py insrec               real    1m50.288s user    0m6.710s sys     0m23.445s   Using commit_manually decorator (11245 records):  [nox@noxdevel marinetraffic]$ time python manage.py insrec                  real    0m18.464s user    0m5.433s sys     0m10.163s   Note: The test script also does some other operations besides inserting into the database (downloads a ZIP file, extracts an XML file from the ZIP archive, parses the XML file) so the time needed for execution does not necessarily represent the time needed to insert the records.     ","Q_Votes":"63"},{"Q_Title":"What is an efficient way of inserting thousands of records into an SQLite table using Django?","A_Content":"  I recommend using plain SQL (not ORM) you can insert multiple rows with a single insert:  insert into A select from B;   The select from B portion of your sql could be as complicated as you want it to get as long as the results match the columns in table A and there are no constraint conflicts.     ","Language":"Python","Tags":["python","sql","django","sqlite","insert"],"URL":"https://stackoverflow.com/questions/1136106/what-is-an-efficient-way-of-inserting-thousands-of-records-into-an-sqlite-table","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I have to insert 8000+ records into a SQLite database using Django's ORM. This operation needs to be run as a cronjob about once per minute. At the moment I'm using a for loop to iterate through all the items and then insert them one by one. Example:  for item in items:     entry = Entry(a1=item.a1, a2=item.a2)     entry.save()   What is an efficient way of doing this?  Edit: A little comparison between the two insertion methods.  Without commit_manually decorator (11245 records):  nox@noxdevel marinetraffic]$ time python manage.py insrec               real    1m50.288s user    0m6.710s sys     0m23.445s   Using commit_manually decorator (11245 records):  [nox@noxdevel marinetraffic]$ time python manage.py insrec                  real    0m18.464s user    0m5.433s sys     0m10.163s   Note: The test script also does some other operations besides inserting into the database (downloads a ZIP file, extracts an XML file from the ZIP archive, parses the XML file) so the time needed for execution does not necessarily represent the time needed to insert the records.     ","Q_Votes":"63"},{"Q_Title":"Getting Python error “from: can't read /var/mail/Bio”","A_Content":"  No, it's not the script, it's the fact that your script is not executed by Python at all. If your script is stored in a file named script.py, you have to execute it as python script.py, otherwise the default shell will execute it and it will bail out at the from keyword. (Incidentally, from is the name of a command line utility which prints names of those who have sent mail to the given username, so that's why it tries to access the mailboxes).  Another possibility is to add the following line to the top of the script:  #!/usr/bin/env python   This will instruct your shell to execute the script via python instead of trying to interpret it on its own.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/16069816/getting-python-error-from-cant-read-var-mail-bio","A_Votes":"119","_type":"dict","isAccepted":"Yes","Q_Content":"    I am running a (bio)python script which results in the following error:  from: can't read /var/mail/Bio   seeing as my script doesn't have anything to with mail, I don't understand why my script is looking in /var/mail.  What seems to be the problem here? i doubt it will help as the script doesn't seem to be the problem, but here's my script anyway:  from Bio import SeqIO from Bio.SeqUtils import ProtParam  handle = open(\"examplefasta.fasta\")  for record in SeqIO.parse(handle, \"fasta\"):      seq = str(record.seq)     X = ProtParam.ProteinAnalysis(seq)     print X.count_amino_acids()      print X.get_amino_acids_percent()      print X.molecular_weight()      print X.aromaticity()      print X.instability_index()      print X.flexibility()      print X.isoelectric_point()      print X.secondary_structure_fraction()   what is the problem here? bad python setup? I really don't think it's the script.     ","Q_Votes":"63"},{"Q_Title":"Getting Python error “from: can't read /var/mail/Bio”","A_Content":"  I ran into a similar error  \"from: can't read /var/mail/django.test.utils\"  when trying to run a command  >>> from django.test.utils import setup_test_environment >>> setup_test_environment()   in the tutorial at https://docs.djangoproject.com/en/1.8/intro/tutorial05/  after reading the answer by Tamás I realized I was not trying this command in the python shell but in the termnial (this can happen to those new to linux)  solution was to first enter in the python shell with the command python and when you get these >>> then run any python commands     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/16069816/getting-python-error-from-cant-read-var-mail-bio","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am running a (bio)python script which results in the following error:  from: can't read /var/mail/Bio   seeing as my script doesn't have anything to with mail, I don't understand why my script is looking in /var/mail.  What seems to be the problem here? i doubt it will help as the script doesn't seem to be the problem, but here's my script anyway:  from Bio import SeqIO from Bio.SeqUtils import ProtParam  handle = open(\"examplefasta.fasta\")  for record in SeqIO.parse(handle, \"fasta\"):      seq = str(record.seq)     X = ProtParam.ProteinAnalysis(seq)     print X.count_amino_acids()      print X.get_amino_acids_percent()      print X.molecular_weight()      print X.aromaticity()      print X.instability_index()      print X.flexibility()      print X.isoelectric_point()      print X.secondary_structure_fraction()   what is the problem here? bad python setup? I really don't think it's the script.     ","Q_Votes":"63"},{"Q_Title":"Getting Python error “from: can't read /var/mail/Bio”","A_Content":"  Same here. I had this error when running an import command from terminal without activating python3 shell through manage.py in a django project (yes, I am a newbie yet). As one must expect, activating shell allowed the command to be interpreted correctly.  ./manage.py shell   and only then  >>> from django.contrib.sites.models import Site      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/16069816/getting-python-error-from-cant-read-var-mail-bio","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am running a (bio)python script which results in the following error:  from: can't read /var/mail/Bio   seeing as my script doesn't have anything to with mail, I don't understand why my script is looking in /var/mail.  What seems to be the problem here? i doubt it will help as the script doesn't seem to be the problem, but here's my script anyway:  from Bio import SeqIO from Bio.SeqUtils import ProtParam  handle = open(\"examplefasta.fasta\")  for record in SeqIO.parse(handle, \"fasta\"):      seq = str(record.seq)     X = ProtParam.ProteinAnalysis(seq)     print X.count_amino_acids()      print X.get_amino_acids_percent()      print X.molecular_weight()      print X.aromaticity()      print X.instability_index()      print X.flexibility()      print X.isoelectric_point()      print X.secondary_structure_fraction()   what is the problem here? bad python setup? I really don't think it's the script.     ","Q_Votes":"63"},{"Q_Title":"Getting Python error “from: can't read /var/mail/Bio”","A_Content":"  Put this at the top of your .py file  #!/usr/bin/env python    for python 2.x, or  #!/usr/bin/env python3   for python 3.x  This should look up the python environment, without it, it will execute the code as if it were not python code, but straight to the CLI. If you need to specify a manual location of python environment put  #!/#path/#to/#python      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/16069816/getting-python-error-from-cant-read-var-mail-bio","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am running a (bio)python script which results in the following error:  from: can't read /var/mail/Bio   seeing as my script doesn't have anything to with mail, I don't understand why my script is looking in /var/mail.  What seems to be the problem here? i doubt it will help as the script doesn't seem to be the problem, but here's my script anyway:  from Bio import SeqIO from Bio.SeqUtils import ProtParam  handle = open(\"examplefasta.fasta\")  for record in SeqIO.parse(handle, \"fasta\"):      seq = str(record.seq)     X = ProtParam.ProteinAnalysis(seq)     print X.count_amino_acids()      print X.get_amino_acids_percent()      print X.molecular_weight()      print X.aromaticity()      print X.instability_index()      print X.flexibility()      print X.isoelectric_point()      print X.secondary_structure_fraction()   what is the problem here? bad python setup? I really don't think it's the script.     ","Q_Votes":"63"},{"Q_Title":"How assignment works with python list slice","A_Content":"  You are confusing two distinct operation that use very similar syntax:  1) slicing:  b = a[0:2]   This makes a copy of the slice of a and assigns it to b.  2) slice assignment:  a[0:2] = b   This replaces the slice of a with the contents of b.  Although the syntax is similar (I imagine by design!), these are two different operations.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10623302/how-assignment-works-with-python-list-slice","A_Votes":"74","_type":"dict","isAccepted":"Yes","Q_Content":"    Python doc says that slicing a list returns a new list. Now if a \"new\" list is being returned I've the following doubts related to \"Assignment to slices\"  a = [1, 2, 3] a[0:2] = [4, 5] print a   Now the output would be:  [4, 5, 3]     How can something that is returning something come on the left side of expression. Yes, I read the docs and it says it is possible, now since slicing a list returns a \"new\" list,why is the original list being modified, I am not able to understand the mechanics behind it.      ","Q_Votes":"63"},{"Q_Title":"How assignment works with python list slice","A_Content":"  When you specify a on the left side of the = operator, you are using Python's normal assignment, which changes the name a in the current context to point to the new value.  This does not change the previous value to which a was pointing.  By specifying a[0:2] on the left side of the = operator, you are telling Python you want to use Slice Assignment.  Slice Assignment is a special syntax for lists, where you can insert, delete, or replace contents from a list:  Insertion:  >>> a = [1, 2, 3] >>> a[0:0] = [-3, -2, -1, 0] >>> a [-3, -2, -1, 0, 1, 2, 3]   Deletion:  >>> a [-3, -2, -1, 0, 1, 2, 3] >>> a[2:4] = [] >>> a [-3, -2, 1, 2, 3]   Replacement:  >>> a [-3, -2, 1, 2, 3] >>> a[:] = [1, 2, 3] >>> a [1, 2, 3]   Note:     The length of the slice may be different from the length of the   assigned sequence, thus changing the length of the target sequence, if   the target sequence allows it. - source   Slice Assignment provides similar function to Tuple Unpacking.  For example, a[0:1] = [4, 5] is equivalent to:  # Tuple Unpacking a[0], a[1] = [4, 5]   With Tuple Unpacking, you can modify non-sequential lists:  >>> a [4, 5, 3] >>> a[-1], a[0] = [7, 3] >>> a [3, 5, 7]   However, tuple unpacking is limited to replacement, as you cannot insert or remove elements.  Before and after all these operations, a is the same exact list.  Python simply provides nice syntactic sugar to modify a list in-place.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10623302/how-assignment-works-with-python-list-slice","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    Python doc says that slicing a list returns a new list. Now if a \"new\" list is being returned I've the following doubts related to \"Assignment to slices\"  a = [1, 2, 3] a[0:2] = [4, 5] print a   Now the output would be:  [4, 5, 3]     How can something that is returning something come on the left side of expression. Yes, I read the docs and it says it is possible, now since slicing a list returns a \"new\" list,why is the original list being modified, I am not able to understand the mechanics behind it.      ","Q_Votes":"63"},{"Q_Title":"How assignment works with python list slice","A_Content":"  I came across the same question before and it's related to the language specification. According to assignment-statements,  (1) if the left side of assignment is subscription, python will call__setitem__ on that object. a[i] = x is equivalent to a.__setitem__(i, x).  (2) if the left side of assignment is slice, python will also call __setitem__, but with different arguments:     a[1:4]=[1,2,3] is equivalent to  a.__setitem__(slice(1,4,None), [1,2,3])  That's why list slice on the left side of '=' behaves differently.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10623302/how-assignment-works-with-python-list-slice","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    Python doc says that slicing a list returns a new list. Now if a \"new\" list is being returned I've the following doubts related to \"Assignment to slices\"  a = [1, 2, 3] a[0:2] = [4, 5] print a   Now the output would be:  [4, 5, 3]     How can something that is returning something come on the left side of expression. Yes, I read the docs and it says it is possible, now since slicing a list returns a \"new\" list,why is the original list being modified, I am not able to understand the mechanics behind it.      ","Q_Votes":"63"},{"Q_Title":"How assignment works with python list slice","A_Content":"  By slicing on the left hand side of an assignment operation, you are specifying which items to assign to.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/10623302/how-assignment-works-with-python-list-slice","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Python doc says that slicing a list returns a new list. Now if a \"new\" list is being returned I've the following doubts related to \"Assignment to slices\"  a = [1, 2, 3] a[0:2] = [4, 5] print a   Now the output would be:  [4, 5, 3]     How can something that is returning something come on the left side of expression. Yes, I read the docs and it says it is possible, now since slicing a list returns a \"new\" list,why is the original list being modified, I am not able to understand the mechanics behind it.      ","Q_Votes":"63"},{"Q_Title":"u'\\ufeff' in Python string","A_Content":"  The Unicode character U+FEFF is the byte order mark, or BOM, and is used to tell the difference between big- and little-endian UTF-16 encoding.  If you decode the web page using the right codec, Python will remove it for you.  Examples:  #!python2 #coding: utf8 u = u'ABC' e8 = u.encode('utf-8')        # encode without BOM e8s = u.encode('utf-8-sig')   # encode with BOM e16 = u.encode('utf-16')      # encode with BOM e16le = u.encode('utf-16le')  # encode without BOM e16be = u.encode('utf-16be')  # encode without BOM print 'utf-8     %r' % e8 print 'utf-8-sig %r' % e8s print 'utf-16    %r' % e16 print 'utf-16le  %r' % e16le print 'utf-16be  %r' % e16be print print 'utf-8  w/ BOM decoded with utf-8     %r' % e8s.decode('utf-8') print 'utf-8  w/ BOM decoded with utf-8-sig %r' % e8s.decode('utf-8-sig') print 'utf-16 w/ BOM decoded with utf-16    %r' % e16.decode('utf-16') print 'utf-16 w/ BOM decoded with utf-16le  %r' % e16.decode('utf-16le')   Note that EF BB BF is a UTF-8-encoded BOM.  It is not required for UTF-8, but serves only as a signature (usually on Windows).  Output:  utf-8     'ABC' utf-8-sig '\\xef\\xbb\\xbfABC' utf-16    '\\xff\\xfeA\\x00B\\x00C\\x00'    # Adds BOM and encodes using native processor endian-ness. utf-16le  'A\\x00B\\x00C\\x00' utf-16be  '\\x00A\\x00B\\x00C'  utf-8  w/ BOM decoded with utf-8     u'\\ufeffABC'    # doesn't remove BOM if present. utf-8  w/ BOM decoded with utf-8-sig u'ABC'          # removes BOM if present. utf-16 w/ BOM decoded with utf-16    u'ABC'          # *requires* BOM to be present. utf-16 w/ BOM decoded with utf-16le  u'\\ufeffABC'    # doesn't remove BOM if present.   Note that the utf-16 coded requires BOM to be present, or Python won't know if the data is big- or little-endian.     ","Language":"Python","Tags":["python","unicode","utf-8"],"URL":"https://stackoverflow.com/questions/17912307/u-ufeff-in-python-string","A_Votes":"99","_type":"dict","isAccepted":"Yes","Q_Content":"    I get an error with the following patter:  UnicodeEncodeError: 'ascii' codec can't encode character u'\\ufeff' in position 155: ordinal not in range(128)   Not sure what u'\\ufeff' is, it shows up when I'm web scraping. How can I remedy the situation? The .replace() string method doesn't work on it.      ","Q_Votes":"63"},{"Q_Title":"u'\\ufeff' in Python string","A_Content":"  I ran into this on Python 3 and found this question (and solution). When opening a file, Python 3 supports the encoding keyword to automatically handle the encoding.  Without it, the BOM is included in the read result:  >>> f = open('file', mode='r') >>> f.read() '\\ufefftest'   Giving the correct encoding, the BOM is omitted in the result:  >>> f = open('file', mode='r', encoding='utf-8-sig') >>> f.read() 'test'   Just my 2 cents.     ","Language":"Python","Tags":["python","unicode","utf-8"],"URL":"https://stackoverflow.com/questions/17912307/u-ufeff-in-python-string","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    I get an error with the following patter:  UnicodeEncodeError: 'ascii' codec can't encode character u'\\ufeff' in position 155: ordinal not in range(128)   Not sure what u'\\ufeff' is, it shows up when I'm web scraping. How can I remedy the situation? The .replace() string method doesn't work on it.      ","Q_Votes":"63"},{"Q_Title":"u'\\ufeff' in Python string","A_Content":"  The content you're scraping is encoded in unicode rather than ascii text, and you're getting a character that doesn't convert to ascii.  The right 'translation' depends on what the original web page thought it was.  Python's unicode page gives the background on how it works.   Are you trying to print the result or stick it in a file? The error suggests it's writing the data that's causing the problem, not reading it. This question is a good place to look for the fixes.     ","Language":"Python","Tags":["python","unicode","utf-8"],"URL":"https://stackoverflow.com/questions/17912307/u-ufeff-in-python-string","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I get an error with the following patter:  UnicodeEncodeError: 'ascii' codec can't encode character u'\\ufeff' in position 155: ordinal not in range(128)   Not sure what u'\\ufeff' is, it shows up when I'm web scraping. How can I remedy the situation? The .replace() string method doesn't work on it.      ","Q_Votes":"63"},{"Q_Title":"u'\\ufeff' in Python string","A_Content":"  That character is the BOM or \"Byte Order Mark\".  It is usually received as the first few bytes of a file, telling you how to interpret the encoding of the rest of the data.  You can simply remove the character to continue.  Although, since the error says you were trying to convert to 'ascii', you should probably pick another encoding for whatever you were trying to do.     ","Language":"Python","Tags":["python","unicode","utf-8"],"URL":"https://stackoverflow.com/questions/17912307/u-ufeff-in-python-string","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I get an error with the following patter:  UnicodeEncodeError: 'ascii' codec can't encode character u'\\ufeff' in position 155: ordinal not in range(128)   Not sure what u'\\ufeff' is, it shows up when I'm web scraping. How can I remedy the situation? The .replace() string method doesn't work on it.      ","Q_Votes":"63"},{"Q_Title":"u'\\ufeff' in Python string","A_Content":"  This problem arise basically when you save your python code in a UTF-8 or UTF-16 encoding because python add some special character at the beginning of the code automatically (which is not shown by the text editors) to identify the encoding format. But, when you try to execute the code it gives you the syntax error in line 1 i.e, start of code because python compiler understands ASCII encoding. when you view the code of file using read() function you can see at the begin of the returned code '\\ufeff' is shown. The one simplest solution to this problem is just by changing the encoding back to ASCII encoding(for this you can copy your code to a notepad and save it Remember! choose the ASCII encoding... Hope this will help.     ","Language":"Python","Tags":["python","unicode","utf-8"],"URL":"https://stackoverflow.com/questions/17912307/u-ufeff-in-python-string","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I get an error with the following patter:  UnicodeEncodeError: 'ascii' codec can't encode character u'\\ufeff' in position 155: ordinal not in range(128)   Not sure what u'\\ufeff' is, it shows up when I'm web scraping. How can I remedy the situation? The .replace() string method doesn't work on it.      ","Q_Votes":"63"},{"Q_Title":"u'\\ufeff' in Python string","A_Content":"  Specifically the Byte Order Mark of feff is an indicator of utf-16 encoding. Since all of the bytes of utf-16 are seldom used, there are two different encoding schemes that people use. Since the different encodings are basically just flipping the bytes in utf-16 the standard is that the Byte Order Mark will always be feff. That way, if someone sends something in with a Byte Order Mark of ffef the unicode encoder knows to flip the order of all bytes in the document that follows.     ","Language":"Python","Tags":["python","unicode","utf-8"],"URL":"https://stackoverflow.com/questions/17912307/u-ufeff-in-python-string","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I get an error with the following patter:  UnicodeEncodeError: 'ascii' codec can't encode character u'\\ufeff' in position 155: ordinal not in range(128)   Not sure what u'\\ufeff' is, it shows up when I'm web scraping. How can I remedy the situation? The .replace() string method doesn't work on it.      ","Q_Votes":"63"},{"Q_Title":"Matplotlib Legends not working","A_Content":"  You should add commas:  plot1, = plt.plot(a,b) plot2, = plt.plot(a,c)   The reason you need the commas is because plt.plot() returns a tuple of line objects, no matter how many are actually created from the command. Without the comma, \"plot1\" and \"plot2\" are tuples instead of line objects, making the later call to plt.legend() fail.   The comma implicitly unpacks the results so that instead of a tuple, \"plot1\" and \"plot2\" automatically become the first objects within the tuple, i.e. the line objects you actually want.  http://matplotlib.sourceforge.net/users/legend_guide.html#adjusting-the-order-of-legend-items  line, = plot(x,sin(x)) what does comma stand for?     ","Language":"Python","Tags":["python","plot","matplotlib"],"URL":"https://stackoverflow.com/questions/11983024/matplotlib-legends-not-working","A_Votes":"125","_type":"dict","isAccepted":"Yes","Q_Content":"    Ever since upgrading matplotlib I get the following error whenever trying to create a legend:  /usr/lib/pymodules/python2.7/matplotlib/legend.py:610: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x3a30810>] Use proxy artist instead.  http://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist    warnings.warn(\"Legend does not support %s\\nUse proxy artist instead.\\n\\nhttp://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist\\n\" % (str(orig_handle),)) /usr/lib/pymodules/python2.7/matplotlib/legend.py:610: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x3a30990>] Use proxy artist instead.  http://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist    warnings.warn(\"Legend does not support %s\\nUse proxy artist instead.\\n\\nhttp://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist\\n\" % (str(orig_handle),))   This even occurs with a trivial script like this:  import matplotlib.pyplot as plt  a = [1,2,3] b = [4,5,6] c = [7,8,9]  plot1 = plt.plot(a,b) plot2 = plt.plot(a,c)  plt.legend([plot1,plot2],[\"plot 1\", \"plot 2\"]) plt.show()   I've found the link that the error points me towards pretty useless in diagnosing the source of the error.     ","Q_Votes":"63"},{"Q_Title":"Matplotlib Legends not working","A_Content":"  Use handles AKA Proxy artists  import matplotlib.lines as mlines import matplotlib.pyplot as plt  blue_line = mlines.Line2D([], [], color='blue', label='My Label') reds_line = mlines.Line2D([], [], color='reds', label='My Othes')  plt.legend(handles=[blue_line, reds_line])  plt.show()      ","Language":"Python","Tags":["python","plot","matplotlib"],"URL":"https://stackoverflow.com/questions/11983024/matplotlib-legends-not-working","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Ever since upgrading matplotlib I get the following error whenever trying to create a legend:  /usr/lib/pymodules/python2.7/matplotlib/legend.py:610: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x3a30810>] Use proxy artist instead.  http://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist    warnings.warn(\"Legend does not support %s\\nUse proxy artist instead.\\n\\nhttp://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist\\n\" % (str(orig_handle),)) /usr/lib/pymodules/python2.7/matplotlib/legend.py:610: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x3a30990>] Use proxy artist instead.  http://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist    warnings.warn(\"Legend does not support %s\\nUse proxy artist instead.\\n\\nhttp://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist\\n\" % (str(orig_handle),))   This even occurs with a trivial script like this:  import matplotlib.pyplot as plt  a = [1,2,3] b = [4,5,6] c = [7,8,9]  plot1 = plt.plot(a,b) plot2 = plt.plot(a,c)  plt.legend([plot1,plot2],[\"plot 1\", \"plot 2\"]) plt.show()   I've found the link that the error points me towards pretty useless in diagnosing the source of the error.     ","Q_Votes":"63"},{"Q_Title":"Matplotlib Legends not working","A_Content":"  Use the \"label\" keyword, like so:  pyplot.plot(x, y, label='x vs. y')   and then add the legend like so:  pyplot.legend()   The legend will retain line properties like thickness, colours, etc.       ","Language":"Python","Tags":["python","plot","matplotlib"],"URL":"https://stackoverflow.com/questions/11983024/matplotlib-legends-not-working","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Ever since upgrading matplotlib I get the following error whenever trying to create a legend:  /usr/lib/pymodules/python2.7/matplotlib/legend.py:610: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x3a30810>] Use proxy artist instead.  http://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist    warnings.warn(\"Legend does not support %s\\nUse proxy artist instead.\\n\\nhttp://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist\\n\" % (str(orig_handle),)) /usr/lib/pymodules/python2.7/matplotlib/legend.py:610: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x3a30990>] Use proxy artist instead.  http://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist    warnings.warn(\"Legend does not support %s\\nUse proxy artist instead.\\n\\nhttp://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist\\n\" % (str(orig_handle),))   This even occurs with a trivial script like this:  import matplotlib.pyplot as plt  a = [1,2,3] b = [4,5,6] c = [7,8,9]  plot1 = plt.plot(a,b) plot2 = plt.plot(a,c)  plt.legend([plot1,plot2],[\"plot 1\", \"plot 2\"]) plt.show()   I've found the link that the error points me towards pretty useless in diagnosing the source of the error.     ","Q_Votes":"63"},{"Q_Title":"Matplotlib Legends not working","A_Content":"  use label while plotting graph then only u can use legend. x axis name and y axis name is different than legend name.     ","Language":"Python","Tags":["python","plot","matplotlib"],"URL":"https://stackoverflow.com/questions/11983024/matplotlib-legends-not-working","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Ever since upgrading matplotlib I get the following error whenever trying to create a legend:  /usr/lib/pymodules/python2.7/matplotlib/legend.py:610: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x3a30810>] Use proxy artist instead.  http://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist    warnings.warn(\"Legend does not support %s\\nUse proxy artist instead.\\n\\nhttp://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist\\n\" % (str(orig_handle),)) /usr/lib/pymodules/python2.7/matplotlib/legend.py:610: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x3a30990>] Use proxy artist instead.  http://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist    warnings.warn(\"Legend does not support %s\\nUse proxy artist instead.\\n\\nhttp://matplotlib.sourceforge.net/users/legend_guide.html#using-proxy-artist\\n\" % (str(orig_handle),))   This even occurs with a trivial script like this:  import matplotlib.pyplot as plt  a = [1,2,3] b = [4,5,6] c = [7,8,9]  plot1 = plt.plot(a,b) plot2 = plt.plot(a,c)  plt.legend([plot1,plot2],[\"plot 1\", \"plot 2\"]) plt.show()   I've found the link that the error points me towards pretty useless in diagnosing the source of the error.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  This answer is similar in spirit to Douglas Leeder's, with the following changes:   It doesn't use actual Base64, so there's no padding characters Instead of converting the number first to a byte-string (base 256), it converts it directly to base 64, which has the advantage of letting you represent negative numbers using a sign character.  import string ALPHABET = string.ascii_uppercase + string.ascii_lowercase + \\            string.digits + '-_' ALPHABET_REVERSE = dict((c, i) for (i, c) in enumerate(ALPHABET)) BASE = len(ALPHABET) SIGN_CHARACTER = '$'  def num_encode(n):     if n < 0:         return SIGN_CHARACTER + num_encode(-n)     s = []     while True:         n, r = divmod(n, BASE)         s.append(ALPHABET[r])         if n == 0: break     return ''.join(reversed(s))  def num_decode(s):     if s[0] == SIGN_CHARACTER:         return -num_decode(s[1:])     n = 0     for c in s:         n = n * BASE + ALPHABET_REVERSE[c]     return n          >>> num_encode(0)     'A'     >>> num_encode(64)     'BA'     >>> num_encode(-(64**5-1))     '$_____'     A few side notes:   You could (marginally) increase the human-readibility of the base-64 numbers by putting string.digits first in the alphabet (and making the sign character '-'); I chose the order that I did based on Python's urlsafe_b64encode. If you're encoding a lot of negative numbers, you could increase the efficiency by using a sign bit or one's/two's complement instead of a sign character. You should be able to easily adapt this code to different bases by changing the alphabet, either to restrict it to only alphanumeric characters or to add additional \"URL-safe\" characters. I would recommend against using a representation other than base 10 in URIs in most cases—it adds complexity and makes debugging harder without significant savings compared to the overhead of HTTP—unless you're going for something TinyURL-esque.      ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"60","_type":"dict","isAccepted":"Yes","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  All the answers given regarding Base64 are very reasonable solutions. But they're technically incorrect. To convert an integer to the shortest URL safe string possible, what you want is base 66 (there are 66 URL safe characters).  That code looks like this:  from io import StringIO import urllib  BASE66_ALPHABET = u\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-_.~\" BASE = len(BASE66_ALPHABET)  def hexahexacontadecimal_encode_int(n):     if n == 0:         return BASE66_ALPHABET[0].encode('ascii')      r = StringIO()     while n:         n, t = divmod(n, BASE)         r.write(BASE66_ALPHABET[t])     return r.getvalue().encode('ascii')[::-1]   Here's a full implementation with source and ready to go pip installable package:   https://github.com/aljungberg/hexahexacontadecimal     ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  You probably do not want real base64 encoding for this - it will add padding etc, potentially even resulting in larger strings than hex would for small numbers.  If there's no need to interoperate with anything else, just use your own encoding.  Eg. here's a function that will encode to any base (note the digits are actually stored least-significant first to avoid extra reverse() calls:  def make_encoder(baseString):     size = len(baseString)     d = dict((ch, i) for (i, ch) in enumerate(baseString)) # Map from char -> value     if len(d) != size:         raise Exception(\"Duplicate characters in encoding string\")      def encode(x):         if x==0: return baseString[0]  # Only needed if don't want '' for 0         l=[]         while x>0:             l.append(baseString[x % size])             x //= size         return ''.join(l)      def decode(s):         return sum(d[ch] * size**i for (i,ch) in enumerate(s))      return encode, decode  # Base 64 version: encode,decode = make_encoder(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\")  assert decode(encode(435346456456)) == 435346456456   This has the advantage that you can use whatever base you want, just by adding appropriate characters to the encoder's base string.  Note that the gains for larger bases are not going to be that big however.  base 64 will only reduce the size to 2/3rds of base 16 (6 bits/char instead of 4).  Each doubling only adds one more bit per character.  Unless you've a real need to compact things, just using hex will probably be the simplest and fastest option.     ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  To encode n:  data = '' while n > 0:     data = chr(n & 255) + data     n = n >> 8 encoded = base64.urlsafe_b64encode(data).rstrip('=')   To decode s:  data = base64.urlsafe_b64decode(s + '===') decoded = 0 while len(data) > 0:     decoded = (decoded << 8) | ord(data[0])     data = data[1:]   In the same spirit as other for some “optimal” encoding, you can use 73 characters according to RFC 1738 (actually 74 if you count “+” as usable):  alphabet = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz_`\\\"!$'()*,-.\" encoded = '' while n > 0:     n, r = divmod(n, len(alphabet))     encoded = alphabet[r] + encoded   and the decoding:  decoded = 0 while len(s) > 0:     decoded = decoded * len(alphabet) + alphabet.find(s[0])     s = s[1:]      ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  The easy bit is converting the byte string to web-safe base64:  import base64 output = base64.urlsafe_b64encode(s)   The tricky bit is the first step - convert the integer to a byte string.  If your integers are small you're better off hex encoding them - see saua  Otherwise (hacky recursive version):  def convertIntToByteString(i):     if i == 0:         return \"\"     else:         return convertIntToByteString(i >> 8) + chr(i & 255)      ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  You don't want base64 encoding, you want to represent a base 10 numeral in numeral base X.  If you want your base 10 numeral represented in the 26 letters available you could use:  http://en.wikipedia.org/wiki/Hexavigesimal. (You can extend that example for a much larger base by using all the legal url characters)  You should atleast be able to get base 38 (26 letters, 10 numbers, +, _)     ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  Base64 takes 4 bytes/characters to encode 3 bytes and can only encode multiples of 3 bytes (and adds padding otherwise).  So representing 4 bytes (your average int) in Base64 would take 8 bytes. Encoding the same 4 bytes in hex would also take 8 bytes. So you wouldn't gain anything for a single int.     ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  a little hacky, but it works:  def b64num(num_to_encode):   h = hex(num_to_encode)[2:]     # hex(n) returns 0xhh, strip off the 0x   h = len(h) & 1 and '0'+h or h  # if odd number of digits, prepend '0' which hex codec requires   return h.decode('hex').encode('base64')    you could replace the call to .encode('base64') with something in the base64 module, such as  urlsafe_b64encode()     ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  I maintain a little library named zbase62: http://pypi.python.org/pypi/zbase62  With it you can convert from a Python 2 str object to a base-62 encoded string and vice versa:  Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53)  [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import os >>> d = os.urandom(32) >>> d 'C$\\x8f\\xf9\\x92NV\\x97\\x13H\\xc7F\\x0c\\x0f\\x8d9}\\xf5.u\\xeeOr\\xc2V\\x92f\\x1b=:\\xc3\\xbc' >>> from zbase62 import zbase62 >>> encoded = zbase62.b2a(d) >>> encoded 'Fv8kTvGhIrJvqQ2oTojUGlaVIxFE1b6BCLpH8JfYNRs' >>> zbase62.a2b(encoded) 'C$\\x8f\\xf9\\x92NV\\x97\\x13H\\xc7F\\x0c\\x0f\\x8d9}\\xf5.u\\xeeOr\\xc2V\\x92f\\x1b=:\\xc3\\xbc'   However, you still need to convert from integer to str. This comes built-in to Python 3:  Python 3.2 (r32:88445, Mar 25 2011, 19:56:22) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import os >>> d = os.urandom(32) >>> d b'\\xe4\\x0b\\x94|\\xb6o\\x08\\xe9oR\\x1f\\xaa\\xa8\\xe8qS3\\x86\\x82\\t\\x15\\xf2\"\\x1dL%?\\xda\\xcc3\\xe3\\xba' >>> int.from_bytes(d, 'big') 103147789615402524662804907510279354159900773934860106838120923694590497907642 >>> x= _  >>> x.to_bytes(32, 'big') b'\\xe4\\x0b\\x94|\\xb6o\\x08\\xe9oR\\x1f\\xaa\\xa8\\xe8qS3\\x86\\x82\\t\\x15\\xf2\"\\x1dL%?\\xda\\xcc3\\xe3\\xba'   To convert from int to bytes and vice versa in Python 2, there is not a convenient, standard way as far as I know. I guess maybe I should copy some implementation, such as this one: https://github.com/warner/foolscap/blob/46e3a041167950fa93e48f65dcf106a576ed110e/foolscap/banana.py#L41 into zbase62 for your convenience.     ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  If you are looking for a way to shorten the integer representation using base64, I think you need to look elsewhere. When you encode something with base64 it doesn't get shorter, in fact it gets longer.   E.g. 11234 encoded with base64 would yield MTEyMzQ=  When using base64 you have overlooked the fact that you are not converting just the digits (0-9) to a 64 character encoding. You are converting 3 bytes into 4 bytes so you are guaranteed your base64 encoded string would be 33.33% longer.     ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  I needed a signed integer, so I ended up going with:  import struct, base64  def b64encode_integer(i):    return base64.urlsafe_b64encode(struct.pack('i', i)).rstrip('=\\n')   Example:  >>> b64encode_integer(1) 'AQAAAA' >>> b64encode_integer(-1) '_____w' >>> b64encode_integer(256) 'AAEAAA'      ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  I'm working on making a pip package for this.  I recommend you use my bases.py https://github.com/kamijoutouma/bases.py which was inspired by bases.js  from bases import Bases bases = Bases()  bases.toBase16(200)                // => 'c8' bases.toBase(200, 16)              // => 'c8' bases.toBase62(99999)              // => 'q0T' bases.toBase(200, 62)              // => 'q0T' bases.toAlphabet(300, 'aAbBcC')    // => 'Abba'  bases.fromBase16('c8')               // => 200 bases.fromBase('c8', 16)             // => 200 bases.fromBase62('q0T')              // => 99999 bases.fromBase('q0T', 62)            // => 99999 bases.fromAlphabet('Abba', 'aAbBcC') // => 300   refer to https://github.com/kamijoutouma/bases.py#known-basesalphabets for what bases are usable  For your case   I recommend you use either base 32, 58 or 64  Base-64 warning: besides there being several different standards, padding isn't currently added and line lengths aren't tracked. Not recommended for use with APIs that expect formal base-64 strings!  Same goes for base 66 which is currently not supported by both bases.js and bases.py but it might in the future     ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  I'd go the 'encode integer as binary string, then base64 encode that' method you suggest, and I'd do it using struct:  >>> import struct, base64 >>> base64.b64encode(struct.pack('l', 47)) 'LwAAAA==' >>> struct.unpack('l', base64.b64decode(_)) (47,)   Edit again: To strip out the extra 0s on numbers that are too small to need full 32-bit precision, try this:  def pad(str, l=4):     while len(str) < l:         str = '\\x00' + str     return str  >>> base64.b64encode(struct.pack('!l', 47).replace('\\x00', '')) 'Lw==' >>> struct.unpack('!l', pad(base64.b64decode('Lw=='))) (47,)      ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"How to convert an integer to the shortest url-safe string in Python?","A_Content":"  Pure python, no dependancies, no encoding of byte strings etc. , just turning a base 10 int into base 64 int with the correct RFC 4648 characters:  def tetrasexagesimal(number):     out=\"\"     while number>=0:         if number == 0:             out = 'A' + out             break         digit = number % 64         out = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\"[digit] + out         number /= 64 # //= 64 for py3 (thank spanishgum!)         if number == 0:             break     return out  tetrasexagesimal(1)      ","Language":"Python","Tags":["python","url","base64"],"URL":"https://stackoverflow.com/questions/561486/how-to-convert-an-integer-to-the-shortest-url-safe-string-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.  The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  Because it's a HyperlinkedModelSerializer your serializer is trying to resolve the URL for the related User on your Bottle. As you don't have the user detail view it can't do this. Hence the exception.   Would not just registering the UserViewSet with the router solve your issue? You could define the user field on your BottleSerializer to explicitly use the UserSerializer rather than trying to resolve the URL. See the serializer docs on dealing with nested objects for that.       ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"66","_type":"dict","isAccepted":"Yes","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  I came across this error too and solved it as follows:  The reason is I forgot giving \"**-detail\" (view_name, e.g.: user-detail) a namespace. So, Django Rest Framework could not find that view.  There is one app in my project, suppose that my project name is myproject, and the app name is myapp.  There is two urls.py file, one is myproject/urls.py and the other is myapp/urls.py. I give the app a namespace in myproject/urls.py, just like:  url(r'', include(myapp.urls, namespace=\"myapp\")),   I registered the rest framework routers in myapp/urls.py, and then got this error.  My solution was to provide url with namespace explicitly:  class UserSerializer(serializers.HyperlinkedModelSerializer):     url = serializers.HyperlinkedIdentityField(view_name=\"myapp:user-detail\")      class Meta:         model = User         fields = ('url', 'username')   And it solved my problem.     ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  Maybe someone can have a look at this :  http://www.django-rest-framework.org/api-guide/routers/  If using namespacing with hyperlinked serializers you'll also need to ensure that any view_name parameters on the serializers correctly reflect the namespace. For example:  urlpatterns = [     url(r'^forgot-password/$', ForgotPasswordFormView.as_view()),     url(r'^api/', include(router.urls, namespace='api')), ]   you'd need to include a parameter such as view_name='api:user-detail' for serializer fields hyperlinked to the user detail view.  class UserSerializer(serializers.HyperlinkedModelSerializer):     url = serializers.HyperlinkedIdentityField(view_name=\"api:user-detail\")  class Meta:     model = User     fields = ('url', 'username')      ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  This code should work, too.  class BottleSerializer(serializers.HyperlinkedModelSerializer):    user = UserSerializer()    class Meta:     model = Bottle     fields = ('url', 'wine', 'user')      ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  Another nasty mistake that causes this error is having the base_name unnecessarily defined in your urls.py.  For example:  router.register(r'{pathname}, views.{ViewName}ViewSet, base_name='pathname')   This will cause the error noted above.  Get that base_name outta there and get back to a working API. The code below would fix the error.  Hooray!  router.register(r'{pathname}, views.{ViewName}ViewSet)   However, you probably didn't just arbitrarily add the base_name, you might have done it because you defined a custom def get_queryset() for the View and so Django mandates that you add the base_name.  In this case you'll need to explicitly define the 'url' as a HyperlinkedIdentityField for the serializer in question.  Notice we are defining this HyperlinkedIdentityField ON THE SERIALIZER of the view that is throwing the error.  If my error were \"Could not resolve URL for hyperlinked relationship using view name \"study-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.\"  I could fix this with the following code.   My ModelViewSet (the custom get_queryset is why I had to add the base_name to the router.register() in the first place):   class StudyViewSet(viewsets.ModelViewSet):     serializer_class = StudySerializer      '''custom get_queryset'''     def get_queryset(self):         queryset = Study.objects.all()         return queryset   My router registration for this ModelViewSet in urls.py:  router.register(r'studies', views.StudyViewSet, base_name='studies')   AND HERE'S WHERE THE MONEY IS!  Then I could solve it like so:  class StudySerializer(serializers.HyperlinkedModelSerializer):     url = serializers.HyperlinkedIdentityField(view_name=\"studies-detail\")     class Meta:         model = Study         fields = ('url', 'name', 'active', 'created',               'time_zone', 'user', 'surveys')   Yep.  You have to explicitly define this HyperlinkedIdentityField on itself for it to work. And you need to make sure that the view_name defined on the HyperlinkedIdentityField is the same as you defined on the base_name in urls.py with a '-detail' added after it.     ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  Same Error, but different reason:  I define a custom user model, nothing new field:  from django.contrib.auth.models import (AbstractUser) class CustomUser(AbstractUser):     \"\"\"     custom user, reference below example     https://github.com/jonathanchu/django-custom-user-example/blob/master/customuser/accounts/models.py      # original User class has all I need     # Just add __str__, not rewrite other field     - id     - username     - password     - email     - is_active     - date_joined     - method, email_user     \"\"\"      def __str__(self):         return self.username   This is my view function:  from rest_framework import permissions from rest_framework import viewsets from .models import (CustomUser) class UserViewSet(viewsets.ModelViewSet):     permission_classes = (permissions.AllowAny,)     serializer_class = UserSerializer      def get_queryset(self):         queryset = CustomUser.objects.filter(id=self.request.user.id)         if self.request.user.is_superuser:             queryset = CustomUser.objects.all()         return queryset   Since I didn't give queryset directly in UserViewSet, I have to set base_name when I register this viewset. This is where my error message caused by urls.py file:  from myapp.views import (UserViewSet) from rest_framework.routers import DefaultRouter router = DefaultRouter() router.register(r'users', UserViewSet, base_name='customuser')  # <--base_name needs to be 'customuser' instead of 'user'   You need a base_name same as your model name - customuser.     ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  I ran into the same error while I was following the DRF quickstart guide http://www.django-rest-framework.org/tutorial/quickstart/ and then attempting to browse to /users.  I've done this setup many times before without problems.  My solution was not in the code but in replacing the database.  The difference between this install and the others before was when I created the local database.  This time I ran my  ./manage.py migrate ./manage.py createsuperuser   immediately after running  virtualenv venv . venv/bin/activate pip install django pip install djangorestframework   Instead of the exact order listed in the guide.  I suspected something wasn't properly created in the DB. I didn't care about my dev db so I deleted it and ran the ./manage.py migrate command once more, created a super user, browsed to /users and the error was gone.  Something was problematic with the order of operations in which I configured DRF and the db.  If you are using sqlite and are able to test changing to a fresh DB then it's worth an attempt before you go dissecting all of your code.     ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  Bottle = serializers.PrimaryKeyRelatedField(read_only=True)  read_only allows you to represent the field without having to link it to another view of the model.     ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  If you're extending the GenericViewSet and ListModelMixin classes, and have the same error when adding the url field in the list view, it's because you're not defining the detail view. Be sure you're extending the RetrieveModelMixin mixin:  class UserViewSet (mixins.ListModelMixin,                    mixins.RetrieveModelMixin,                    viewsets.GenericViewSet):      ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  I got that error on DRF 3.7.7 when a slug value was empty (equals to '') in the database.      ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  I ran into this same issue and resolved it by adding generics.RetrieveAPIView as a base class to my viewset.     ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django Rest Framework - Could not resolve URL for hyperlinked relationship using view name “user-detail”","A_Content":"  I was stuck in this error for almost 2 hours:  ImproperlyConfigured at /api_users/users/1/ Could not resolve URL for hyperlinked relationship using view name \"users-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.  When I finally get the solution  but I don't understand why, so my code is:  #models.py class Users(models.Model):     id          = models.AutoField(primary_key=True)     name        = models.CharField(max_length=50, blank=False, null=False)     email       = models.EmailField(null=False, blank=False)      class Meta:         verbose_name = \"Usuario\"         verbose_name_plural = \"Usuarios\"      def __str__(self):         return str(self.name)   #serializers.py class UserSerializer(serializers.HyperlinkedModelSerializer):     class Meta:         model = Users         fields = (             'id',             'url',             'name',                     'email',                    'description',              'active',                   'age',                      'some_date',                'timestamp',             ) #views.py class UserViewSet(viewsets.ModelViewSet):     queryset = Users.objects.all()     serializer_class = UserSerializer  #urls_api.py router = routers.DefaultRouter() router.register(r'users',UserViewSet, base_name='users')  urlpatterns = [          url(r'^', include(router.urls)), ]   but in my main URLs, it was:  urlpatterns = [     url(r'^admin/', admin.site.urls),     #api users     url(r'^api_users/', include('usersApi.users_urls', namespace='api')),  ]   So to finally I resolve the problem erasing namespace:  urlpatterns = [     url(r'^admin/', admin.site.urls),     #api users     url(r'^api_users/', include('usersApi.users_urls')),  ]   And I finally resolve my problem, so any one can let me know why, bests.     ","Language":"Python","Tags":["python","django","django-rest-framework"],"URL":"https://stackoverflow.com/questions/20550598/django-rest-framework-could-not-resolve-url-for-hyperlinked-relationship-using","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am building a project in Django Rest Framework where users can login to view their wine cellar. My ModelViewSets were working just fine and all of a sudden I get this frustrating error:     Could not resolve URL for hyperlinked relationship using view name \"user-detail\". You may have failed to include the related model in your API, or incorrectly configured the lookup_field attribute on this field.   The traceback shows:      [12/Dec/2013 18:35:29] \"GET /bottles/ HTTP/1.1\" 500 76677 Internal Server Error: /bottles/ Traceback (most recent call last):   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/core/handlers/base.py\", line 114, in get_response     response = wrapped_callback(request, *callback_args, **callback_kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/viewsets.py\", line 78, in view     return self.dispatch(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 57, in wrapped_view     return view_func(*args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 399, in dispatch     response = self.handle_exception(exc)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/views.py\", line 396, in dispatch     response = handler(request, *args, **kwargs)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/mixins.py\", line 96, in list     return Response(serializer.data)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 535, in data     self._data = [self.to_native(item) for item in obj]   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/serializers.py\", line 325, in to_native     value = field.field_to_native(obj, field_name)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 153, in field_to_native     return self.to_native(value)   File \"/Users/bpipat/.virtualenvs/usertest2/lib/python2.7/site-packages/rest_framework/relations.py\", line 452, in to_native     raise Exception(msg % view_name) Exception: Could not resolve URL for hyperlinked relationship using view  name \"user-detail\". You may have failed to include the related model in  your API, or incorrectly configured the `lookup_field` attribute on this  field.   I have a custom email user model and the bottle model in models.py is:  class Bottle(models.Model):           wine = models.ForeignKey(Wine, null=False)       user = models.ForeignKey(User, null=False, related_name='bottles')   My serializers:  class BottleSerializer(serializers.HyperlinkedModelSerializer):      class Meta:         model = Bottle         fields = ('url', 'wine', 'user')  class UserSerializer(serializers.ModelSerializer):      class Meta:         model = User         fields = ('email', 'first_name', 'last_name', 'password', 'is_superuser')   My views:  class BottleViewSet(viewsets.ModelViewSet):     \"\"\"     API endpoint that allows bottles to be viewed or edited.     \"\"\"     queryset = Bottle.objects.all()     serializer_class = BottleSerializer  class UserViewSet(ListCreateAPIView):     \"\"\"     API endpoint that allows users to be viewed or edited.     \"\"\"     queryset = User.objects.all()     serializer_class = UserSerializer   and finally the url:  router = routers.DefaultRouter() router.register(r'bottles', views.BottleViewSet, base_name='bottles')  urlpatterns = patterns('',     url(r'^', include(router.urls)),     # ...   I don't have a user detail view and I don't see where this issue could come from. Any ideas?  Thanks     ","Q_Votes":"63"},{"Q_Title":"Django. You don't have permission to edit anything","A_Content":"  I checked files one more time and found the difference. I forgot to add admin.autodiscover() in urls.py of the project. Thanks.     ","Language":"Python","Tags":["python","django","django-admin"],"URL":"https://stackoverflow.com/questions/3718077/django-you-dont-have-permission-to-edit-anything","A_Votes":"134","_type":"dict","isAccepted":"Yes","Q_Content":"    I created a little app a while ago. I created admin.py and used admin.site.register(MenuEntry) to add the class to admin console. It showed the items of that class just fine. Then I began working on another app and created everything as before. But now it says:  You don't have permission to edit anything. I compared files from that and from this apps and they look quite similar, so I just can't find the difference and I can't realize what to do now to make it work.     ","Q_Votes":"63"},{"Q_Title":"Django. You don't have permission to edit anything","A_Content":"  I had another case where this happened. I had an app called \"transcription\", with two models: Project and Recording. After getting it mostly developed I decided to rename the app \"recordings\". The admin app worked fine as the admin but any non-admin user got this error message. Eventually I found (in my sqlite db) the table django_content_type. It had these records:   id  name      app_label     model ------------------------------------- 8   project   transcription project 9   recording transcription recording 10  project   recording     project 11  recording recordings    recording   Somewhere along the way I had managed to add two (almost - don't know why \"recording\" in record 10) correct records while leaving the now incorrect records intact. The admin user worked just fine (I wonder why), but any other group got the error. When I  looked at auth_group_permissions I saw that only records 8 and 9 were being assigned and of course there was no longer an app called \"transcription\". Hence the error.  I deleted records 10 and 11 and changed the app_labels of 8 and 9 to \"recordings\" and there's joy in  Mudville.     ","Language":"Python","Tags":["python","django","django-admin"],"URL":"https://stackoverflow.com/questions/3718077/django-you-dont-have-permission-to-edit-anything","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I created a little app a while ago. I created admin.py and used admin.site.register(MenuEntry) to add the class to admin console. It showed the items of that class just fine. Then I began working on another app and created everything as before. But now it says:  You don't have permission to edit anything. I compared files from that and from this apps and they look quite similar, so I just can't find the difference and I can't realize what to do now to make it work.     ","Q_Votes":"63"},{"Q_Title":"Django. You don't have permission to edit anything","A_Content":"  Upgrade your Django to 1.7 or more, This problem will be automatically solved.  Upgrading Django:  pip install -U django      ","Language":"Python","Tags":["python","django","django-admin"],"URL":"https://stackoverflow.com/questions/3718077/django-you-dont-have-permission-to-edit-anything","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I created a little app a while ago. I created admin.py and used admin.site.register(MenuEntry) to add the class to admin console. It showed the items of that class just fine. Then I began working on another app and created everything as before. But now it says:  You don't have permission to edit anything. I compared files from that and from this apps and they look quite similar, so I just can't find the difference and I can't realize what to do now to make it work.     ","Q_Votes":"63"},{"Q_Title":"Django. You don't have permission to edit anything","A_Content":"  I was receiving the same error and had to refactor the appname as it conflicted with one of the modules being used. My app's name was admin and I was also using Django's admin.  Check the link - Change app's name, on how to do it.     ","Language":"Python","Tags":["python","django","django-admin"],"URL":"https://stackoverflow.com/questions/3718077/django-you-dont-have-permission-to-edit-anything","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I created a little app a while ago. I created admin.py and used admin.site.register(MenuEntry) to add the class to admin console. It showed the items of that class just fine. Then I began working on another app and created everything as before. But now it says:  You don't have permission to edit anything. I compared files from that and from this apps and they look quite similar, so I just can't find the difference and I can't realize what to do now to make it work.     ","Q_Votes":"63"},{"Q_Title":"Django. You don't have permission to edit anything","A_Content":"  I just simply Removed all currently installed versions of Django. Then freshly install the latest version of Django and it works     ","Language":"Python","Tags":["python","django","django-admin"],"URL":"https://stackoverflow.com/questions/3718077/django-you-dont-have-permission-to-edit-anything","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I created a little app a while ago. I created admin.py and used admin.site.register(MenuEntry) to add the class to admin console. It showed the items of that class just fine. Then I began working on another app and created everything as before. But now it says:  You don't have permission to edit anything. I compared files from that and from this apps and they look quite similar, so I just can't find the difference and I can't realize what to do now to make it work.     ","Q_Votes":"63"},{"Q_Title":"Why can't I get `pip install lxml` to work within a virtualenv?","A_Content":"  You probably already have lxml installed on your system, perhaps installed due to a system package. Thus, the first attempt (pip install lxml without an active virtualenv) doesn't fail, but it also doesn't install it; it really doesn't do anything.  In a virtualenv, by default, the system packages are ignored. Therefore, pip thinks that lxml is not installed. Therefore, it tries to install it into your virtual environment.  lxml contains C modules that need to be compiled in order to install properly. However, the compilation of those C modules rely on your having some \"development libraries\" already installed as well. These development libraries are C libraries, not Python, and as such pip won't be able to automatically fetch them from the internet and install them for you.  Therefore, you will need to install these development libraries on your own, most likely using your package manager. In a Debian system (like Ubuntu), this is...  apt-get install libxml2-dev libxslt-dev   This will install the libxml2 and libxslt development libraries to your local system. If you try again to install lxml, the C module compilation step should work because now these development libraries are on your system.  The error message you were receiving was due to the fact that these libraries were missing (the libxml/xmlversion.h: No such file or directory part of the error message).  See also: How to install lxml on Ubuntu     ","Language":"Python","Tags":["python","virtualenv","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/13019942/why-cant-i-get-pip-install-lxml-to-work-within-a-virtualenv","A_Votes":"115","_type":"dict","isAccepted":"Yes","Q_Content":"    Note: I'm using virtualenvwrapper.  Before activating the virtual environment:  $ pip install lxml Requirement already satisfied (use --upgrade to upgrade): lxml in /usr/lib/python2.7/dist-packages   Cleaning up...     After activating the virtual environment:  (test-env)$ pip install lxml force/build/lxml/src/lxml/includes/etree_defs.h:9:31: fatal error:  libxml/xmlversion.h: No such file or directory  compilation terminated.  error: command 'gcc' failed with exit status 1  ---------------------------------------- Command /home/chaz/dev/envs/test-with-system-python-force/bin/python2 .7 -c \"import setuptools;__file__='/home/chaz/dev/envs/test-with- system-python-force/build/lxml/setup.py';exec(compile(open(__file__). read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record  /tmp/pip-bJ6Q_B-record/install-record.txt --single-version-externally -managed --install-headers /home/chaz/dev/envs/test-env/include/site/python2.7 failed with error code 1 in  /home/chaz/dev/envs/test-env/build/lxml Storing complete log in /home/chaz/.pip/pip.log      ","Q_Votes":"63"},{"Q_Title":"Why can't I get `pip install lxml` to work within a virtualenv?","A_Content":"  for centos users: when getting:     error: command 'gcc' failed with exit status 1   DO:  sudo yum install libxslt-devel libxml2-devel      ","Language":"Python","Tags":["python","virtualenv","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/13019942/why-cant-i-get-pip-install-lxml-to-work-within-a-virtualenv","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    Note: I'm using virtualenvwrapper.  Before activating the virtual environment:  $ pip install lxml Requirement already satisfied (use --upgrade to upgrade): lxml in /usr/lib/python2.7/dist-packages   Cleaning up...     After activating the virtual environment:  (test-env)$ pip install lxml force/build/lxml/src/lxml/includes/etree_defs.h:9:31: fatal error:  libxml/xmlversion.h: No such file or directory  compilation terminated.  error: command 'gcc' failed with exit status 1  ---------------------------------------- Command /home/chaz/dev/envs/test-with-system-python-force/bin/python2 .7 -c \"import setuptools;__file__='/home/chaz/dev/envs/test-with- system-python-force/build/lxml/setup.py';exec(compile(open(__file__). read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record  /tmp/pip-bJ6Q_B-record/install-record.txt --single-version-externally -managed --install-headers /home/chaz/dev/envs/test-env/include/site/python2.7 failed with error code 1 in  /home/chaz/dev/envs/test-env/build/lxml Storing complete log in /home/chaz/.pip/pip.log      ","Q_Votes":"63"},{"Q_Title":"Why can't I get `pip install lxml` to work within a virtualenv?","A_Content":"  If you have lxml installed at the system level, and want to migrate it into a virtualenv that you didn't create with --system-site-packages, you can symlink it into your virtualenv's dist-packages folder.  Outside your virtualenv, in a python shell:  import lxml print lxml.__file__   In my case, it's found in /usr/lib/python2.7/dist-packages. There'll be an lxml folder and egg-info file. Wherever your virtualenv is, go into its /lib/python-x.y/dist-packages folder (you may need to create dist-packages), and symlink both the library folder and egg into it.     ","Language":"Python","Tags":["python","virtualenv","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/13019942/why-cant-i-get-pip-install-lxml-to-work-within-a-virtualenv","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Note: I'm using virtualenvwrapper.  Before activating the virtual environment:  $ pip install lxml Requirement already satisfied (use --upgrade to upgrade): lxml in /usr/lib/python2.7/dist-packages   Cleaning up...     After activating the virtual environment:  (test-env)$ pip install lxml force/build/lxml/src/lxml/includes/etree_defs.h:9:31: fatal error:  libxml/xmlversion.h: No such file or directory  compilation terminated.  error: command 'gcc' failed with exit status 1  ---------------------------------------- Command /home/chaz/dev/envs/test-with-system-python-force/bin/python2 .7 -c \"import setuptools;__file__='/home/chaz/dev/envs/test-with- system-python-force/build/lxml/setup.py';exec(compile(open(__file__). read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record  /tmp/pip-bJ6Q_B-record/install-record.txt --single-version-externally -managed --install-headers /home/chaz/dev/envs/test-env/include/site/python2.7 failed with error code 1 in  /home/chaz/dev/envs/test-env/build/lxml Storing complete log in /home/chaz/.pip/pip.log      ","Q_Votes":"63"},{"Q_Title":"Why can't I get `pip install lxml` to work within a virtualenv?","A_Content":"  You're most likely looking for this: Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)  Look for the visual studio website and go into: \"Tools for visual studio\" at the bottom, expand it by clicking. Select Download next to \"Build Tools for Visual Studio 2017\" at the top.     ","Language":"Python","Tags":["python","virtualenv","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/13019942/why-cant-i-get-pip-install-lxml-to-work-within-a-virtualenv","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Note: I'm using virtualenvwrapper.  Before activating the virtual environment:  $ pip install lxml Requirement already satisfied (use --upgrade to upgrade): lxml in /usr/lib/python2.7/dist-packages   Cleaning up...     After activating the virtual environment:  (test-env)$ pip install lxml force/build/lxml/src/lxml/includes/etree_defs.h:9:31: fatal error:  libxml/xmlversion.h: No such file or directory  compilation terminated.  error: command 'gcc' failed with exit status 1  ---------------------------------------- Command /home/chaz/dev/envs/test-with-system-python-force/bin/python2 .7 -c \"import setuptools;__file__='/home/chaz/dev/envs/test-with- system-python-force/build/lxml/setup.py';exec(compile(open(__file__). read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record  /tmp/pip-bJ6Q_B-record/install-record.txt --single-version-externally -managed --install-headers /home/chaz/dev/envs/test-env/include/site/python2.7 failed with error code 1 in  /home/chaz/dev/envs/test-env/build/lxml Storing complete log in /home/chaz/.pip/pip.log      ","Q_Votes":"63"},{"Q_Title":"Sending mail via sendmail from python","A_Content":"  Header injection isn't a factor in how you send the mail, it's a factor in how you construct the mail.  Check the email package, construct the mail with that, serialise it, and send it to /usr/sbin/sendmail using the subprocess module:  from email.mime.text import MIMEText from subprocess import Popen, PIPE  msg = MIMEText(\"Here is the body of my message\") msg[\"From\"] = \"me@example.com\" msg[\"To\"] = \"you@example.com\" msg[\"Subject\"] = \"This is the subject.\" p = Popen([\"/usr/sbin/sendmail\", \"-t\", \"-oi\"], stdin=PIPE) p.communicate(msg.as_string())      ","Language":"Python","Tags":["python","email","sendmail"],"URL":"https://stackoverflow.com/questions/73781/sending-mail-via-sendmail-from-python","A_Votes":"103","_type":"dict","isAccepted":"Yes","Q_Content":"    If I want to send mail not via SMTP, but rather via sendmail, is there a library for python that encapsulates this process?  Better yet, is there a good library that abstracts the whole 'sendmail -versus- smtp' choice?  I'll be running this script on a bunch of unix hosts, only some of which are listening on localhost:25; a few of these are part of embedded systems and can't be set up to accept SMTP.  As part of Good Practice, I'd really like to have the library take care of header injection vulnerabilities itself -- so just dumping a string to popen('/usr/bin/sendmail', 'w') is a little closer to the metal than I'd like.  If the answer is 'go write a library,' so be it ;-)     ","Q_Votes":"63"},{"Q_Title":"Sending mail via sendmail from python","A_Content":"  This is a simple python function that uses the unix sendmail to deliver a mail.  def sendMail():     sendmail_location = \"/usr/sbin/sendmail\" # sendmail location     p = os.popen(\"%s -t\" % sendmail_location, \"w\")     p.write(\"From: %s\\n\" % \"from@somewhere.com\")     p.write(\"To: %s\\n\" % \"to@somewhereelse.com\")     p.write(\"Subject: thesubject\\n\")     p.write(\"\\n\") # blank line separating headers from body     p.write(\"body of the mail\")     status = p.close()     if status != 0:            print \"Sendmail exit status\", status      ","Language":"Python","Tags":["python","email","sendmail"],"URL":"https://stackoverflow.com/questions/73781/sending-mail-via-sendmail-from-python","A_Votes":"31","_type":"dict","isAccepted":"No","Q_Content":"    If I want to send mail not via SMTP, but rather via sendmail, is there a library for python that encapsulates this process?  Better yet, is there a good library that abstracts the whole 'sendmail -versus- smtp' choice?  I'll be running this script on a bunch of unix hosts, only some of which are listening on localhost:25; a few of these are part of embedded systems and can't be set up to accept SMTP.  As part of Good Practice, I'd really like to have the library take care of header injection vulnerabilities itself -- so just dumping a string to popen('/usr/bin/sendmail', 'w') is a little closer to the metal than I'd like.  If the answer is 'go write a library,' so be it ;-)     ","Q_Votes":"63"},{"Q_Title":"Sending mail via sendmail from python","A_Content":"  Jim's answer did not work for me in Python 3.4. I had to add an additional universal_newlines=True argument to subrocess.Popen()  from email.mime.text import MIMEText from subprocess import Popen, PIPE  msg = MIMEText(\"Here is the body of my message\") msg[\"From\"] = \"me@example.com\" msg[\"To\"] = \"you@example.com\" msg[\"Subject\"] = \"This is the subject.\" p = Popen([\"/usr/sbin/sendmail\", \"-t\", \"-oi\"], stdin=PIPE, universal_newlines=True) p.communicate(msg.as_string())   Without the universal_newlines=True I get  TypeError: 'str' does not support the buffer interface      ","Language":"Python","Tags":["python","email","sendmail"],"URL":"https://stackoverflow.com/questions/73781/sending-mail-via-sendmail-from-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    If I want to send mail not via SMTP, but rather via sendmail, is there a library for python that encapsulates this process?  Better yet, is there a good library that abstracts the whole 'sendmail -versus- smtp' choice?  I'll be running this script on a bunch of unix hosts, only some of which are listening on localhost:25; a few of these are part of embedded systems and can't be set up to accept SMTP.  As part of Good Practice, I'd really like to have the library take care of header injection vulnerabilities itself -- so just dumping a string to popen('/usr/bin/sendmail', 'w') is a little closer to the metal than I'd like.  If the answer is 'go write a library,' so be it ;-)     ","Q_Votes":"63"},{"Q_Title":"Sending mail via sendmail from python","A_Content":"  It's quite common to just use the sendmail command from Python using os.popen  Personally, for scripts i didn't write myself, I think just using the SMTP-protocol is better, since it wouldn't require installing say an sendmail clone to run on windows.  https://docs.python.org/library/smtplib.html     ","Language":"Python","Tags":["python","email","sendmail"],"URL":"https://stackoverflow.com/questions/73781/sending-mail-via-sendmail-from-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    If I want to send mail not via SMTP, but rather via sendmail, is there a library for python that encapsulates this process?  Better yet, is there a good library that abstracts the whole 'sendmail -versus- smtp' choice?  I'll be running this script on a bunch of unix hosts, only some of which are listening on localhost:25; a few of these are part of embedded systems and can't be set up to accept SMTP.  As part of Good Practice, I'd really like to have the library take care of header injection vulnerabilities itself -- so just dumping a string to popen('/usr/bin/sendmail', 'w') is a little closer to the metal than I'd like.  If the answer is 'go write a library,' so be it ;-)     ","Q_Votes":"63"},{"Q_Title":"Sending mail via sendmail from python","A_Content":"  This question is very old, but it's worthwhile to note that there is a message construction and e-mail delivery system called Marrow Mailer (previously TurboMail) which has been available since before this message was asked.  It's now being ported to support Python 3 and updated as part of the Marrow suite.     ","Language":"Python","Tags":["python","email","sendmail"],"URL":"https://stackoverflow.com/questions/73781/sending-mail-via-sendmail-from-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    If I want to send mail not via SMTP, but rather via sendmail, is there a library for python that encapsulates this process?  Better yet, is there a good library that abstracts the whole 'sendmail -versus- smtp' choice?  I'll be running this script on a bunch of unix hosts, only some of which are listening on localhost:25; a few of these are part of embedded systems and can't be set up to accept SMTP.  As part of Good Practice, I'd really like to have the library take care of header injection vulnerabilities itself -- so just dumping a string to popen('/usr/bin/sendmail', 'w') is a little closer to the metal than I'd like.  If the answer is 'go write a library,' so be it ;-)     ","Q_Votes":"63"},{"Q_Title":"Drop all duplicate rows in Python Pandas","A_Content":"  This is much easier in pandas now with drop_duplicates and the keep parameter.  import pandas as pd df = pd.DataFrame({\"A\":[\"foo\", \"foo\", \"foo\", \"bar\"], \"B\":[0,1,1,1], \"C\":[\"A\",\"A\",\"B\",\"A\"]}) df.drop_duplicates(subset=['A', 'C'], keep=False)      ","Language":"Python","Tags":["python","pandas","duplicates"],"URL":"https://stackoverflow.com/questions/23667369/drop-all-duplicate-rows-in-python-pandas","A_Votes":"112","_type":"dict","isAccepted":"Yes","Q_Content":"    The pandas drop_duplicates function is great for \"uniquifying\" a dataframe. However, one of the keyword arguments to pass is take_last=True or take_last=False, while I would like to drop all rows which are duplicates across a subset of columns. Is this possible?      A   B   C 0   foo 0   A 1   foo 1   A 2   foo 1   B 3   bar 1   A   As an example, I would like to drop rows which match on columns A and C so this should drop rows 0 and 1.     ","Q_Votes":"63"},{"Q_Title":"Drop all duplicate rows in Python Pandas","A_Content":"  Just want to add to Ben's answer on drop_duplicates:  keep : {‘first’, ‘last’, False}, default ‘first’   first : Drop duplicates except for the first occurrence. last : Drop duplicates except for the last occurrence. False : Drop all duplicates.   So set keep to False we give you desired answer.     DataFrame.drop_duplicates(*args, **kwargs) Return DataFrame with   duplicate rows removed, optionally only considering certain columns      Parameters:    subset : column label or sequence of labels, optional   Only consider certain columns for identifying duplicates, by default   use all of the columns keep : {‘first’, ‘last’, False}, default   ‘first’ first : Drop duplicates except for the first occurrence. last   : Drop duplicates except for the last occurrence. False : Drop all   duplicates. take_last : deprecated inplace : boolean, default False   Whether to drop duplicates in place or to return a copy cols : kwargs   only argument of subset [deprecated] Returns:  deduplicated :   DataFrame      ","Language":"Python","Tags":["python","pandas","duplicates"],"URL":"https://stackoverflow.com/questions/23667369/drop-all-duplicate-rows-in-python-pandas","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    The pandas drop_duplicates function is great for \"uniquifying\" a dataframe. However, one of the keyword arguments to pass is take_last=True or take_last=False, while I would like to drop all rows which are duplicates across a subset of columns. Is this possible?      A   B   C 0   foo 0   A 1   foo 1   A 2   foo 1   B 3   bar 1   A   As an example, I would like to drop rows which match on columns A and C so this should drop rows 0 and 1.     ","Q_Votes":"63"},{"Q_Title":"Drop all duplicate rows in Python Pandas","A_Content":"  use groupby and filter  import pandas as pd df = pd.DataFrame({\"A\":[\"foo\", \"foo\", \"foo\", \"bar\"], \"B\":[0,1,1,1], \"C\":[\"A\",\"A\",\"B\",\"A\"]}) df.groupby([\"A\", \"C\"]).filter(lambda df:df.shape[0] == 1)      ","Language":"Python","Tags":["python","pandas","duplicates"],"URL":"https://stackoverflow.com/questions/23667369/drop-all-duplicate-rows-in-python-pandas","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    The pandas drop_duplicates function is great for \"uniquifying\" a dataframe. However, one of the keyword arguments to pass is take_last=True or take_last=False, while I would like to drop all rows which are duplicates across a subset of columns. Is this possible?      A   B   C 0   foo 0   A 1   foo 1   A 2   foo 1   B 3   bar 1   A   As an example, I would like to drop rows which match on columns A and C so this should drop rows 0 and 1.     ","Q_Votes":"63"},{"Q_Title":"Drop all duplicate rows in Python Pandas","A_Content":"  Actually, drop rows 0 and 1 only requires (any observations containing matched A and C is kept.):  In [335]:  df['AC']=df.A+df.C In [336]:  print df.drop_duplicates('C', take_last=True) #this dataset is a special case, in general, one may need to first drop_duplicates by 'c' and then by 'a'.      A  B  C    AC 2  foo  1  B  fooB 3  bar  1  A  barA  [2 rows x 4 columns]   But I suspect what you really want is this (one observation containing matched A and C is kept.):  In [337]:  print df.drop_duplicates('AC')      A  B  C    AC 0  foo  0  A  fooA 2  foo  1  B  fooB 3  bar  1  A  barA  [3 rows x 4 columns]   Edit:  Now it is much clearer, therefore:  In [352]: DG=df.groupby(['A', 'C'])    print pd.concat([DG.get_group(item) for item, value in DG.groups.items() if len(value)==1])      A  B  C 2  foo  1  B 3  bar  1  A  [2 rows x 3 columns]      ","Language":"Python","Tags":["python","pandas","duplicates"],"URL":"https://stackoverflow.com/questions/23667369/drop-all-duplicate-rows-in-python-pandas","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    The pandas drop_duplicates function is great for \"uniquifying\" a dataframe. However, one of the keyword arguments to pass is take_last=True or take_last=False, while I would like to drop all rows which are duplicates across a subset of columns. Is this possible?      A   B   C 0   foo 0   A 1   foo 1   A 2   foo 1   B 3   bar 1   A   As an example, I would like to drop rows which match on columns A and C so this should drop rows 0 and 1.     ","Q_Votes":"63"},{"Q_Title":"Drop all duplicate rows in Python Pandas","A_Content":"  If you want result to be stored in another dataset:  df.drop_duplicates(keep=False)   or  df.drop_duplicates(keep=False, inplace=False)   If same dataset needs to updated:  df.drop_duplicates(keep=False, inplace=True)   Above examples will remove all duplicates and keep one, similar to DISTINCT * in SQL     ","Language":"Python","Tags":["python","pandas","duplicates"],"URL":"https://stackoverflow.com/questions/23667369/drop-all-duplicate-rows-in-python-pandas","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    The pandas drop_duplicates function is great for \"uniquifying\" a dataframe. However, one of the keyword arguments to pass is take_last=True or take_last=False, while I would like to drop all rows which are duplicates across a subset of columns. Is this possible?      A   B   C 0   foo 0   A 1   foo 1   A 2   foo 1   B 3   bar 1   A   As an example, I would like to drop rows which match on columns A and C so this should drop rows 0 and 1.     ","Q_Votes":"63"},{"Q_Title":"How to add items into a numpy array","A_Content":"  Appending data to an existing array is a natural thing to want to do for anyone with python experience.  However, if you find yourself regularly appending to large arrays, you'll quickly discover that NumPy doesn't easily or efficiently do this the way a python list will.  You'll find that every \"append\" action requires re-allocation of the array memory and short-term doubling of memory requirements.  So, the more general solution to the problem is to try to allocate arrays to be as large as the final output of your algorithm.  Then perform all your operations on sub-sets (slices) of that array.  Array creation and destruction should ideally be minimized.  That said, It's often unavoidable and the functions that do this are:  for 2-D arrays:   np.hstack  np.vstack np.column_stack np.row_stack   for 3-D arrays (the above plus):   np.dstack   for N-D arrays:   np.concatenate      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/5064822/how-to-add-items-into-a-numpy-array","A_Votes":"119","_type":"dict","isAccepted":"Yes","Q_Content":"    I need to accomplish the following task:  from:  a = array([[1,3,4],[1,2,3]...[1,2,1]])   (add one element to each row) to:  a = array([[1,3,4,x],[1,2,3,x]...[1,2,1,x]])   I have tried doing stuff like a[n] = array([1,3,4,x])  but numpy complained of shape mismatch. I tried iterating through a and appending element x to each item, but the changes are not reflected.  Any ideas on how I can accomplish this?     ","Q_Votes":"63"},{"Q_Title":"How to add items into a numpy array","A_Content":"  import numpy as np a = np.array([[1,3,4],[1,2,3],[1,2,1]]) b = np.array([10,20,30]) c = np.hstack((a, np.atleast_2d(b).T))   returns c:  array([[ 1,  3,  4, 10],        [ 1,  2,  3, 20],        [ 1,  2,  1, 30]])      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/5064822/how-to-add-items-into-a-numpy-array","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I need to accomplish the following task:  from:  a = array([[1,3,4],[1,2,3]...[1,2,1]])   (add one element to each row) to:  a = array([[1,3,4,x],[1,2,3,x]...[1,2,1,x]])   I have tried doing stuff like a[n] = array([1,3,4,x])  but numpy complained of shape mismatch. I tried iterating through a and appending element x to each item, but the changes are not reflected.  Any ideas on how I can accomplish this?     ","Q_Votes":"63"},{"Q_Title":"How to add items into a numpy array","A_Content":"  One way to do it (may not be the best) is to create another array with the new elements and do column_stack. i.e.  >>>a = array([[1,3,4],[1,2,3]...[1,2,1]]) [[1 3 4]  [1 2 3]  [1 2 1]]  >>>b = array([1,2,3]) >>>column_stack((a,b)) array([[1, 3, 4, 1],        [1, 2, 3, 2],        [1, 2, 1, 3]])      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/5064822/how-to-add-items-into-a-numpy-array","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I need to accomplish the following task:  from:  a = array([[1,3,4],[1,2,3]...[1,2,1]])   (add one element to each row) to:  a = array([[1,3,4,x],[1,2,3,x]...[1,2,1,x]])   I have tried doing stuff like a[n] = array([1,3,4,x])  but numpy complained of shape mismatch. I tried iterating through a and appending element x to each item, but the changes are not reflected.  Any ideas on how I can accomplish this?     ","Q_Votes":"63"},{"Q_Title":"How to add items into a numpy array","A_Content":"  Appending a single scalar could be done a bit easier as already shown (and also without converting to float) by expanding the scalar to a python-list-type:    import numpy as np a = np.array([[1,3,4],[1,2,3],[1,2,1]]) x = 10  b = np.hstack ((a, [[x]] * len (a) ))   returns b as:  array([[ 1,  3,  4, 10],        [ 1,  2,  3, 10],        [ 1,  2,  1, 10]])   Appending a row could be done by:  c = np.vstack ((a, [x] * len (a[0]) ))   returns c as:  array([[ 1,  3,  4],        [ 1,  2,  3],        [ 1,  2,  1],        [10, 10, 10]])      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/5064822/how-to-add-items-into-a-numpy-array","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I need to accomplish the following task:  from:  a = array([[1,3,4],[1,2,3]...[1,2,1]])   (add one element to each row) to:  a = array([[1,3,4,x],[1,2,3,x]...[1,2,1,x]])   I have tried doing stuff like a[n] = array([1,3,4,x])  but numpy complained of shape mismatch. I tried iterating through a and appending element x to each item, but the changes are not reflected.  Any ideas on how I can accomplish this?     ","Q_Votes":"63"},{"Q_Title":"How to add items into a numpy array","A_Content":"  If x is just a single scalar value, you could try something like this to ensure the correct shape of the array that is being appended/concatenated to the rightmost column of a:  import numpy as np a = np.array([[1,3,4],[1,2,3],[1,2,1]]) x = 10 b = np.hstack((a,x*np.ones((a.shape[0],1))))   returns b as:  array([[  1.,   3.,   4.,  10.],        [  1.,   2.,   3.,  10.],        [  1.,   2.,   1.,  10.]])      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/5064822/how-to-add-items-into-a-numpy-array","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to accomplish the following task:  from:  a = array([[1,3,4],[1,2,3]...[1,2,1]])   (add one element to each row) to:  a = array([[1,3,4,x],[1,2,3,x]...[1,2,1,x]])   I have tried doing stuff like a[n] = array([1,3,4,x])  but numpy complained of shape mismatch. I tried iterating through a and appending element x to each item, but the changes are not reflected.  Any ideas on how I can accomplish this?     ","Q_Votes":"63"},{"Q_Title":"How to add items into a numpy array","A_Content":"  target = []  for line in a.tolist():     new_line = line.append(X)     target.append(new_line)  return array(target)      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/5064822/how-to-add-items-into-a-numpy-array","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I need to accomplish the following task:  from:  a = array([[1,3,4],[1,2,3]...[1,2,1]])   (add one element to each row) to:  a = array([[1,3,4,x],[1,2,3,x]...[1,2,1,x]])   I have tried doing stuff like a[n] = array([1,3,4,x])  but numpy complained of shape mismatch. I tried iterating through a and appending element x to each item, but the changes are not reflected.  Any ideas on how I can accomplish this?     ","Q_Votes":"63"},{"Q_Title":"URL-parameters and logic in Django class-based views (TemplateView)","A_Content":"  To access the url parameters in class based views, use self.args or self.kwargs so you would access it by doing self.kwargs['year']     ","Language":"Python","Tags":["python","django","django-class-based-views"],"URL":"https://stackoverflow.com/questions/15754122/url-parameters-and-logic-in-django-class-based-views-templateview","A_Votes":"82","_type":"dict","isAccepted":"No","Q_Content":"    It is unclear to me how it is best to access URL-parameters in class-based-views in Django 1.5.   Consider the following:  View:  from django.views.generic.base import TemplateView   class Yearly(TemplateView):     template_name = \"calendars/yearly.html\"      current_year = datetime.datetime.now().year     current_month = datetime.datetime.now().month      def get_context_data(self, **kwargs):         context = super(Yearly, self).get_context_data(**kwargs)         context['current_year'] = self.current_year         context['current_month'] = self.current_month         return context   URLCONF:  from .views import Yearly   urlpatterns = patterns('',     url(         regex=r'^(?P<year>\\d+)/$',         view=Yearly.as_view(),         name='yearly-view'     ), )   I want to access the year parameter in my view, so I can do logic like:  month_names = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\",                \"August\", \"September\", \"October\", \"November\", \"December\"]       for month, month_name in enumerate(month_names, start=1):         is_current = False         if year == current_year and month == current_month:             is_current = True         months.append({             'month': month,             'name': month_name,             'is_current': is_current})   How would one best access the url parameter in CBVs like the above that is subclassed of TemplateView and where should one ideally place the logic like this, eg. in a method?     ","Q_Votes":"63"},{"Q_Title":"URL-parameters and logic in Django class-based views (TemplateView)","A_Content":"  In case you pass URL parameter like this:  http://<my_url>/?order_by=created   You can access it in class based view by using self.request.GET (its not presented in self.args nor in self.kwargs):  class MyClassBasedView(ObjectList):     ...     def get_queryset(self):         order_by = self.request.GET.get('order_by') or '-created'         qs = super(MyClassBasedView, self).get_queryset()         return qs.order_by(order_by)      ","Language":"Python","Tags":["python","django","django-class-based-views"],"URL":"https://stackoverflow.com/questions/15754122/url-parameters-and-logic-in-django-class-based-views-templateview","A_Votes":"40","_type":"dict","isAccepted":"No","Q_Content":"    It is unclear to me how it is best to access URL-parameters in class-based-views in Django 1.5.   Consider the following:  View:  from django.views.generic.base import TemplateView   class Yearly(TemplateView):     template_name = \"calendars/yearly.html\"      current_year = datetime.datetime.now().year     current_month = datetime.datetime.now().month      def get_context_data(self, **kwargs):         context = super(Yearly, self).get_context_data(**kwargs)         context['current_year'] = self.current_year         context['current_month'] = self.current_month         return context   URLCONF:  from .views import Yearly   urlpatterns = patterns('',     url(         regex=r'^(?P<year>\\d+)/$',         view=Yearly.as_view(),         name='yearly-view'     ), )   I want to access the year parameter in my view, so I can do logic like:  month_names = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\",                \"August\", \"September\", \"October\", \"November\", \"December\"]       for month, month_name in enumerate(month_names, start=1):         is_current = False         if year == current_year and month == current_month:             is_current = True         months.append({             'month': month,             'name': month_name,             'is_current': is_current})   How would one best access the url parameter in CBVs like the above that is subclassed of TemplateView and where should one ideally place the logic like this, eg. in a method?     ","Q_Votes":"63"},{"Q_Title":"URL-parameters and logic in Django class-based views (TemplateView)","A_Content":"  I found this elegant solution, and for django 1.5 or higher, as pointed out here:       Django’s generic class based views now automatically include a view   variable in the context. This variable points at your view object.   In your views.py:  from django.views.generic.base import TemplateView      class Yearly(TemplateView):     template_name = \"calendars/yearly.html\"     # No here      current_year = datetime.datetime.now().year     current_month = datetime.datetime.now().month      # dispatch is called when the class instance loads     def dispatch(self, request, *args, **kwargs):         self.year = kwargs.get('year', \"any_default\")      # other code      # needed to have an HttpResponse     return super(Yearly, self).dispatch(request, *args, **kwargs)   The dispatch solution found in this question. As view is already passed within Template context, you don't really need to care about it. In your template file yearly.html, it is possible to access those view attributes simply by:  {{ view.year }} {{ view.current_year }} {{ view.current_month }}   You can keep your urlconf as it is.  Good to mention that getting information into your template’s context overwrites the get_context_data(), so it is somehow breaking the django's action bean flow.     ","Language":"Python","Tags":["python","django","django-class-based-views"],"URL":"https://stackoverflow.com/questions/15754122/url-parameters-and-logic-in-django-class-based-views-templateview","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    It is unclear to me how it is best to access URL-parameters in class-based-views in Django 1.5.   Consider the following:  View:  from django.views.generic.base import TemplateView   class Yearly(TemplateView):     template_name = \"calendars/yearly.html\"      current_year = datetime.datetime.now().year     current_month = datetime.datetime.now().month      def get_context_data(self, **kwargs):         context = super(Yearly, self).get_context_data(**kwargs)         context['current_year'] = self.current_year         context['current_month'] = self.current_month         return context   URLCONF:  from .views import Yearly   urlpatterns = patterns('',     url(         regex=r'^(?P<year>\\d+)/$',         view=Yearly.as_view(),         name='yearly-view'     ), )   I want to access the year parameter in my view, so I can do logic like:  month_names = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\",                \"August\", \"September\", \"October\", \"November\", \"December\"]       for month, month_name in enumerate(month_names, start=1):         is_current = False         if year == current_year and month == current_month:             is_current = True         months.append({             'month': month,             'name': month_name,             'is_current': is_current})   How would one best access the url parameter in CBVs like the above that is subclassed of TemplateView and where should one ideally place the logic like this, eg. in a method?     ","Q_Votes":"63"},{"Q_Title":"URL-parameters and logic in Django class-based views (TemplateView)","A_Content":"  So far I've only been able to access these url parameters from within the get_queryset method, although I've only tried it with a ListView not a TemplateView. I'll use the url param to create an attribute on the object instance, then use that attribute in get_context_data to populate the context:  class Yearly(TemplateView):     template_name = \"calendars/yearly.html\"      current_year = datetime.datetime.now().year     current_month = datetime.datetime.now().month      def get_queryset(self):         self.year = self.kwargs['year']         queryset = super(Yearly, self).get_queryset()         return queryset      def get_context_data(self, **kwargs):         context = super(Yearly, self).get_context_data(**kwargs)         context['current_year'] = self.current_year         context['current_month'] = self.current_month         context['year'] = self.year         return context      ","Language":"Python","Tags":["python","django","django-class-based-views"],"URL":"https://stackoverflow.com/questions/15754122/url-parameters-and-logic-in-django-class-based-views-templateview","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    It is unclear to me how it is best to access URL-parameters in class-based-views in Django 1.5.   Consider the following:  View:  from django.views.generic.base import TemplateView   class Yearly(TemplateView):     template_name = \"calendars/yearly.html\"      current_year = datetime.datetime.now().year     current_month = datetime.datetime.now().month      def get_context_data(self, **kwargs):         context = super(Yearly, self).get_context_data(**kwargs)         context['current_year'] = self.current_year         context['current_month'] = self.current_month         return context   URLCONF:  from .views import Yearly   urlpatterns = patterns('',     url(         regex=r'^(?P<year>\\d+)/$',         view=Yearly.as_view(),         name='yearly-view'     ), )   I want to access the year parameter in my view, so I can do logic like:  month_names = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\",                \"August\", \"September\", \"October\", \"November\", \"December\"]       for month, month_name in enumerate(month_names, start=1):         is_current = False         if year == current_year and month == current_month:             is_current = True         months.append({             'month': month,             'name': month_name,             'is_current': is_current})   How would one best access the url parameter in CBVs like the above that is subclassed of TemplateView and where should one ideally place the logic like this, eg. in a method?     ","Q_Votes":"63"},{"Q_Title":"URL-parameters and logic in Django class-based views (TemplateView)","A_Content":"  How about just use Python decorators to make this intelligible:  class Yearly(TemplateView):      @property     def year(self):        return self.kwargs['year']      ","Language":"Python","Tags":["python","django","django-class-based-views"],"URL":"https://stackoverflow.com/questions/15754122/url-parameters-and-logic-in-django-class-based-views-templateview","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    It is unclear to me how it is best to access URL-parameters in class-based-views in Django 1.5.   Consider the following:  View:  from django.views.generic.base import TemplateView   class Yearly(TemplateView):     template_name = \"calendars/yearly.html\"      current_year = datetime.datetime.now().year     current_month = datetime.datetime.now().month      def get_context_data(self, **kwargs):         context = super(Yearly, self).get_context_data(**kwargs)         context['current_year'] = self.current_year         context['current_month'] = self.current_month         return context   URLCONF:  from .views import Yearly   urlpatterns = patterns('',     url(         regex=r'^(?P<year>\\d+)/$',         view=Yearly.as_view(),         name='yearly-view'     ), )   I want to access the year parameter in my view, so I can do logic like:  month_names = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\",                \"August\", \"September\", \"October\", \"November\", \"December\"]       for month, month_name in enumerate(month_names, start=1):         is_current = False         if year == current_year and month == current_month:             is_current = True         months.append({             'month': month,             'name': month_name,             'is_current': is_current})   How would one best access the url parameter in CBVs like the above that is subclassed of TemplateView and where should one ideally place the logic like this, eg. in a method?     ","Q_Votes":"63"},{"Q_Title":"Pandas: sum DataFrame rows for given columns","A_Content":"  You can just sum and set param axis=1 to sum the rows, this will ignore none numeric columns:  In [91]:  df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]}) df['e'] = df.sum(axis=1) df Out[91]:    a  b   c  d   e 0  1  2  dd  5   8 1  2  3  ee  9  14 2  3  4  ff  1   8   If you want to just sum specific columns then you can create a list of the columns and remove the ones you are not interested in:  In [98]:  col_list= list(df) col_list.remove('d') col_list Out[98]: ['a', 'b', 'c'] In [99]:  df['e'] = df[col_list].sum(axis=1) df Out[99]:    a  b   c  d  e 0  1  2  dd  5  3 1  2  3  ee  9  5 2  3  4  ff  1  7      ","Language":"Python","Tags":["python","pandas","dataframe","sum"],"URL":"https://stackoverflow.com/questions/25748683/pandas-sum-dataframe-rows-for-given-columns","A_Votes":"126","_type":"dict","isAccepted":"Yes","Q_Content":"    I have the following DataFrame:  In [1]:  import pandas as pd df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]}) df Out [1]:    a  b   c  d 0  1  2  dd  5 1  2  3  ee  9 2  3  4  ff  1   I would like to add a column 'e' which is the sum of column 'a', 'b' and 'd'.  Going across forums, I thought something like this would work:  df['e'] = df[['a','b','d']].map(sum)   But no!  I would like to realize the operation having the list of columns ['a','b','d'] and df as inputs.     ","Q_Votes":"63"},{"Q_Title":"Pandas: sum DataFrame rows for given columns","A_Content":"  If you have just a few columns to sum, you can write:   df['e'] = df['a'] + df['b'] + df['d']   This creates new column e with the values:     a  b   c  d   e 0  1  2  dd  5   8 1  2  3  ee  9  14 2  3  4  ff  1   8   For longer lists of columns, EdChum's answer is preferred.     ","Language":"Python","Tags":["python","pandas","dataframe","sum"],"URL":"https://stackoverflow.com/questions/25748683/pandas-sum-dataframe-rows-for-given-columns","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I have the following DataFrame:  In [1]:  import pandas as pd df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]}) df Out [1]:    a  b   c  d 0  1  2  dd  5 1  2  3  ee  9 2  3  4  ff  1   I would like to add a column 'e' which is the sum of column 'a', 'b' and 'd'.  Going across forums, I thought something like this would work:  df['e'] = df[['a','b','d']].map(sum)   But no!  I would like to realize the operation having the list of columns ['a','b','d'] and df as inputs.     ","Q_Votes":"63"},{"Q_Title":"Pandas: sum DataFrame rows for given columns","A_Content":"  This is a simpler way using iloc to select which columns to sum:  df['f']=df.iloc[:,0:2].sum(axis=1) df['g']=df.iloc[:,[0,1]].sum(axis=1) df['h']=df.iloc[:,[0,3]].sum(axis=1)   Produces:     a  b   c  d   e  f  g   h 0  1  2  dd  5   8  3  3   6 1  2  3  ee  9  14  5  5  11 2  3  4  ff  1   8  7  7   4   I can't find a way to combine a range and specific columns that works e.g. something like:  df['i']=df.iloc[:,[[0:2],3]].sum(axis=1) df['i']=df.iloc[:,[0:2,3]].sum(axis=1)      ","Language":"Python","Tags":["python","pandas","dataframe","sum"],"URL":"https://stackoverflow.com/questions/25748683/pandas-sum-dataframe-rows-for-given-columns","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have the following DataFrame:  In [1]:  import pandas as pd df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]}) df Out [1]:    a  b   c  d 0  1  2  dd  5 1  2  3  ee  9 2  3  4  ff  1   I would like to add a column 'e' which is the sum of column 'a', 'b' and 'd'.  Going across forums, I thought something like this would work:  df['e'] = df[['a','b','d']].map(sum)   But no!  I would like to realize the operation having the list of columns ['a','b','d'] and df as inputs.     ","Q_Votes":"63"},{"Q_Title":"Pandas: sum DataFrame rows for given columns","A_Content":"  Create a list of column names you want to add up.  df['total']=df.loc[:,list_name].sum(axis=1)   If you want the sum for certain rows, specify the rows using ':'     ","Language":"Python","Tags":["python","pandas","dataframe","sum"],"URL":"https://stackoverflow.com/questions/25748683/pandas-sum-dataframe-rows-for-given-columns","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have the following DataFrame:  In [1]:  import pandas as pd df = pd.DataFrame({'a': [1,2,3], 'b': [2,3,4], 'c':['dd','ee','ff'], 'd':[5,9,1]}) df Out [1]:    a  b   c  d 0  1  2  dd  5 1  2  3  ee  9 2  3  4  ff  1   I would like to add a column 'e' which is the sum of column 'a', 'b' and 'd'.  Going across forums, I thought something like this would work:  df['e'] = df[['a','b','d']].map(sum)   But no!  I would like to realize the operation having the list of columns ['a','b','d'] and df as inputs.     ","Q_Votes":"63"},{"Q_Title":"Django DateField default options","A_Content":"  This is why you should always import the base datetime module: import datetime, rather than the datetime class within that module: from datetime import datetime.   The other mistake you have made is to actually call the function in the default, with the (). This means that all models will get the date at the time the class is first defined - so if your server stays up for days or weeks without restarting Apache, all elements will get same the initial date.  So the field should be:  import datetime date = models.DateField(_(\"Date\"), default=datetime.date.today)      ","Language":"Python","Tags":["python","django","django-models"],"URL":"https://stackoverflow.com/questions/2029295/django-datefield-default-options","A_Votes":"114","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a model which has a date time field:  date = models.DateField(_(\"Date\"), default=datetime.now())  When I check the app in the built in django admin, the DateField also has the time appended to it, so that if you try to save it it returns an error. How do I make the default just the date? (datetime.today() isn't working either)     ","Q_Votes":"63"},{"Q_Title":"Django DateField default options","A_Content":"  You mistake is using the datetime module instead of the date module.  You meant to do this:  from datetime import date date = models.DateField(_(\"Date\"), default=date.today)   If you only want to capture the current date the proper way to handle this is to use the auto_now_add parameter:  date = models.DateField(_(\"Date\"), auto_now_add=True)   However, the modelfield docs clearly state that auto_now_add and auto_now will always use the current date and are not a default value that you can override.     ","Language":"Python","Tags":["python","django","django-models"],"URL":"https://stackoverflow.com/questions/2029295/django-datefield-default-options","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    I have a model which has a date time field:  date = models.DateField(_(\"Date\"), default=datetime.now())  When I check the app in the built in django admin, the DateField also has the time appended to it, so that if you try to save it it returns an error. How do I make the default just the date? (datetime.today() isn't working either)     ","Q_Votes":"63"},{"Q_Title":"Django DateField default options","A_Content":"  date = models.DateTimeField(default=datetime.now, blank=True)      ","Language":"Python","Tags":["python","django","django-models"],"URL":"https://stackoverflow.com/questions/2029295/django-datefield-default-options","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have a model which has a date time field:  date = models.DateField(_(\"Date\"), default=datetime.now())  When I check the app in the built in django admin, the DateField also has the time appended to it, so that if you try to save it it returns an error. How do I make the default just the date? (datetime.today() isn't working either)     ","Q_Votes":"63"},{"Q_Title":"Django DateField default options","A_Content":"  This should do the trick:  models.DateTimeField(_(\"Date\"), auto_now_add = True)      ","Language":"Python","Tags":["python","django","django-models"],"URL":"https://stackoverflow.com/questions/2029295/django-datefield-default-options","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a model which has a date time field:  date = models.DateField(_(\"Date\"), default=datetime.now())  When I check the app in the built in django admin, the DateField also has the time appended to it, so that if you try to save it it returns an error. How do I make the default just the date? (datetime.today() isn't working either)     ","Q_Votes":"63"},{"Q_Title":"Django DateField default options","A_Content":"  You could also use lambda. Useful if you're using django.utils.timezone.now  date = models.DateField(_(\"Date\"), default=lambda: now().date())      ","Language":"Python","Tags":["python","django","django-models"],"URL":"https://stackoverflow.com/questions/2029295/django-datefield-default-options","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a model which has a date time field:  date = models.DateField(_(\"Date\"), default=datetime.now())  When I check the app in the built in django admin, the DateField also has the time appended to it, so that if you try to save it it returns an error. How do I make the default just the date? (datetime.today() isn't working either)     ","Q_Votes":"63"},{"Q_Title":"Is it possible to run python SimpleHTTPServer on localhost only?","A_Content":"  If you read the source you will see that only the port can be overridden on the command line.  If you want to change the host it is served on, you will need to implement the test() method of the SimpleHTTPServer and BaseHTTPServer yourself.  But that should be really easy.  Here is how you can do it, pretty easily:  import sys from SimpleHTTPServer import SimpleHTTPRequestHandler import BaseHTTPServer   def test(HandlerClass=SimpleHTTPRequestHandler,          ServerClass=BaseHTTPServer.HTTPServer):      protocol = \"HTTP/1.0\"     host = ''     port = 8000     if len(sys.argv) > 1:         arg = sys.argv[1]         if ':' in arg:             host, port = arg.split(':')             port = int(port)         else:             try:                 port = int(sys.argv[1])             except:                 host = sys.argv[1]      server_address = (host, port)      HandlerClass.protocol_version = protocol     httpd = ServerClass(server_address, HandlerClass)      sa = httpd.socket.getsockname()     print \"Serving HTTP on\", sa[0], \"port\", sa[1], \"...\"     httpd.serve_forever()   if __name__ == \"__main__\":     test()   And to use it:    > python server.py 127.0.0.1      Serving HTTP on 127.0.0.1 port 8000 ...  > python server.py 127.0.0.1:9000 Serving HTTP on 127.0.0.1 port 9000 ...  > python server.py 8080           Serving HTTP on 0.0.0.0 port 8080 ...      ","Language":"Python","Tags":["python","http","command-line","python-2.x","simplehttpserver"],"URL":"https://stackoverflow.com/questions/12268835/is-it-possible-to-run-python-simplehttpserver-on-localhost-only","A_Votes":"45","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a vpn connection and when I'm running python -m SimpleHTTPServer, it serves on 0.0.0.0:8000, which means it can be accessed via localhost and via my real ip. I don't want robots to scan me and interested that the server will be accessed only via localhost.  Is it possible?   python -m SimpleHTTPServer 127.0.0.1:8000  # doesn't work.   Any other simple http server which can be executed instantly using the command line is also welcome.     ","Q_Votes":"63"},{"Q_Title":"Is it possible to run python SimpleHTTPServer on localhost only?","A_Content":"  As @sberry explained, simply doing it by using the nice python -m ... method won't be possible, because the IP address is hardcoded in the implementation of the BaseHttpServer.test function.  A way of doing it from the command line without writing code to a file first would be  python -c 'import BaseHTTPServer as bhs, SimpleHTTPServer as shs; bhs.HTTPServer((\"127.0.0.1\", 8888), shs.SimpleHTTPRequestHandler).serve_forever()'   If that still counts as a one liner depends on your terminal width ;-) It's certainly not very easy to remember.     ","Language":"Python","Tags":["python","http","command-line","python-2.x","simplehttpserver"],"URL":"https://stackoverflow.com/questions/12268835/is-it-possible-to-run-python-simplehttpserver-on-localhost-only","A_Votes":"65","_type":"dict","isAccepted":"No","Q_Content":"    I have a vpn connection and when I'm running python -m SimpleHTTPServer, it serves on 0.0.0.0:8000, which means it can be accessed via localhost and via my real ip. I don't want robots to scan me and interested that the server will be accessed only via localhost.  Is it possible?   python -m SimpleHTTPServer 127.0.0.1:8000  # doesn't work.   Any other simple http server which can be executed instantly using the command line is also welcome.     ","Q_Votes":"63"},{"Q_Title":"Is it possible to run python SimpleHTTPServer on localhost only?","A_Content":"  In Python versions 3.4 and higher, the http.server module accepts a bind parameter.  According to the docs:     python -m http.server 8000      By default, server binds itself to all interfaces. The option   -b/--bind specifies a specific address to which it should bind. For example, the following command causes the server to bind to localhost   only:      python -m http.server 8000 --bind 127.0.0.1      New in version 3.4: --bind argument was introduced.      ","Language":"Python","Tags":["python","http","command-line","python-2.x","simplehttpserver"],"URL":"https://stackoverflow.com/questions/12268835/is-it-possible-to-run-python-simplehttpserver-on-localhost-only","A_Votes":"42","_type":"dict","isAccepted":"No","Q_Content":"    I have a vpn connection and when I'm running python -m SimpleHTTPServer, it serves on 0.0.0.0:8000, which means it can be accessed via localhost and via my real ip. I don't want robots to scan me and interested that the server will be accessed only via localhost.  Is it possible?   python -m SimpleHTTPServer 127.0.0.1:8000  # doesn't work.   Any other simple http server which can be executed instantly using the command line is also welcome.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  more_itertools.consecutive_groups was added in version 4.0.  Demo  import more_itertools as mit   iterable = [2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20] [list(group) for group in mit.consecutive_groups(iterable)] # [[2, 3, 4, 5], [12, 13, 14, 15, 16, 17], [20]]   Code  Applying this tool, we make a generator function that finds ranges of consecutive numbers.  def find_ranges(iterable):     \"\"\"Yield range of consecutive numbers.\"\"\"     for group in mit.consecutive_groups(iterable):         group = list(group)         if len(group) == 1:             yield group[0]         else:             yield group[0], group[-1]   iterable = [2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20] list(find_ranges(iterable)) # [(2, 5), (12, 17), 20]   The source implementation emulates a classic recipe (as demonstrated by @Nadia Alramli).  Note: more_itertools is a third-party package installable via pip install more_itertools.     ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"10","_type":"dict","isAccepted":"Yes","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  EDIT 2: To answer the OP new requirement  ranges = [] for key, group in groupby(enumerate(data), lambda (index, item): index - item):     group = map(itemgetter(1), group)     if len(group) > 1:         ranges.append(xrange(group[0], group[-1]))     else:         ranges.append(group[0])   Output:  [xrange(2, 5), xrange(12, 17), 20]   You can replace xrange with range or any other custom class.    Python docs have a very neat recipe for this:  from operator import itemgetter from itertools import groupby data = [2, 3, 4, 5, 12, 13, 14, 15, 16, 17] for k, g in groupby(enumerate(data), lambda (i,x):i-x):     print map(itemgetter(1), g)   Output:  [2, 3, 4, 5] [12, 13, 14, 15, 16, 17]   If you want to get the exact same output, you can do this:  ranges = [] for k, g in groupby(enumerate(data), lambda (i,x):i-x):     group = map(itemgetter(1), g)     ranges.append((group[0], group[-1]))   output:  [(2, 5), (12, 17)]     EDIT: The example is already explained in the documentation but maybe I should explain it more:     The key to the solution is   differencing with a range so that   consecutive numbers all appear in same   group.   If the data was: [2, 3, 4, 5, 12, 13, 14, 15, 16, 17] Then groupby(enumerate(data), lambda (i,x):i-x) is equivalent of the following:  groupby(     [(0, 2), (1, 3), (2, 4), (3, 5), (4, 12),     (5, 13), (6, 14), (7, 15), (8, 16), (9, 17)],     lambda (i,x):i-x )   The lambda function subtracts the element index from the element value. So when you apply the lambda on each item. You'll get the following keys for groupby:  [-2, -2, -2, -2, -8, -8, -8, -8, -8, -8]   groupby groups elements by equal key value, so the first 4 elements will be grouped together and so forth.  I hope this makes it more readable.   python 3 version may be helpful for beginners  import the libraries required first  from itertools import groupby from operator import itemgetter  ranges =[]  for k,g in groupby(enumerate(data),lambda x:x[0]-x[1]):     group = (map(itemgetter(1),g))     group = list(map(int,group))     ranges.append((group[0],group[-1]))      ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"98","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  The \"naive\" solution which I find somewhat readable atleast.  x = [2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 22, 25, 26, 28, 51, 52, 57]  def group(L):     first = last = L[0]     for n in L[1:]:         if n - 1 == last: # Part of the group, bump the end             last = n         else: # Not part of the group, yield current group and start a new             yield first, last             first = last = n     yield first, last # Yield the last group   >>>print list(group(x)) [(2, 5), (12, 17), (22, 22), (25, 26), (28, 28), (51, 52), (57, 57)]      ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  Assuming your list is sorted:  >>> from itertools import groupby >>> def ranges(lst):     pos = (j - i for i, j in enumerate(lst))     t = 0     for i, els in groupby(pos):         l = len(list(els))         el = lst[t]         t += l         yield range(el, el+l)   >>> lst = [2, 3, 4, 5, 12, 13, 14, 15, 16, 17] >>> list(ranges(lst)) [range(2, 6), range(12, 18)]      ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  Here it is something that should work, without any import needed:  def myfunc(lst):     ret = []     a = b = lst[0]                           # a and b are range's bounds      for el in lst[1:]:         if el == b+1:              b = el                           # range grows         else:                                # range ended             ret.append(a if a==b else (a,b)) # is a single or a range?             a = b = el                       # let's start again with a single     ret.append(a if a==b else (a,b))         # corner case for last single/range     return ret      ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  Please note that the code using groupby doesn't work as given in Python 3 so use this.  for k, g in groupby(enumerate(data), lambda x:x[0]-x[1]):     group = list(map(itemgetter(1), g))     ranges.append((group[0], group[-1]))      ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  This doesn't use a standard function - it just iiterates over the input, but it should work:  def myfunc(l):     r = []     p = q = None     for x in l + [-1]:         if x - 1 == q:             q += 1         else:             if p:                if q > p:                    r.append('%s-%s' % (p, q))                else:                    r.append(str(p))             p = q = x     return '(%s)' % ', '.join(r)   Note that it requires that the input contains only positive numbers in ascending order. You should validate the input, but this code is omitted for clarity.     ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  Here's the answer I came up with. I'm writing the code for other people to understand, so I'm fairly verbose with variable names and comments.  First a quick helper function:  def getpreviousitem(mylist,myitem):     '''Given a list and an item, return previous item in list'''     for position, item in enumerate(mylist):         if item == myitem:             # First item has no previous item             if position == 0:                 return None             # Return previous item                 return mylist[position-1]    And then the actual code:   def getranges(cpulist):     '''Given a sorted list of numbers, return a list of ranges'''     rangelist = []     inrange = False     for item in cpulist:         previousitem = getpreviousitem(cpulist,item)         if previousitem == item - 1:             # We're in a range             if inrange == True:                 # It's an existing range - change the end to the current item                 newrange[1] = item             else:                     # We've found a new range.                 newrange = [item-1,item]             # Update to show we are now in a range                 inrange = True             else:                # We were in a range but now it just ended             if inrange == True:                 # Save the old range                 rangelist.append(newrange)             # Update to show we're no longer in a range                 inrange = False      # Add the final range found to our list     if inrange == True:         rangelist.append(newrange)     return rangelist   Example run:  getranges([2, 3, 4, 5, 12, 13, 14, 15, 16, 17])   returns:  [[2, 5], [12, 17]]      ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  import numpy as np  myarray = [2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20] sequences = np.split(myarray, np.array(np.where(np.diff(myarray) > 1)[0]) + 1) l = [] for s in sequences:     if len(s) > 1:         l.append((np.min(s), np.max(s)))     else:         l.append(s[0]) print(l)   Output:  [(2, 5), (12, 17), 20]      ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  Using numpy + comprehension lists: With numpy diff function, consequent input vector entries that their difference is not equal to one can be identified. The start and end of the input vector need to be considered.    import numpy as np data = np.array([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])  d = [i for i, df in enumerate(np.diff(data)) if df!= 1]  d = np.hstack([-1, d, len(data)-1])  # add first and last elements  d = np.vstack([d[:-1]+1, d[1:]]).T  print(data[d])   Output:   [[ 2  5]      [12 17]      [20 20]]   Note: The request that individual numbers should be treated differently, (returned as individual, not ranges) was omitted. This can be reached by further post-processing the results. Usually this will make things more complex without gaining any benefit.       ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Identify groups of continuous numbers in a list","A_Content":"  A short solution that works without additional imports. It accepts any iterable, sorts unsorted inputs, and removes duplicate items:  def ranges(nums):     nums = sorted(set(nums))     gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s+1 < e]     edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])     return list(zip(edges, edges))   Example:  >>> ranges([2, 3, 4, 7, 8, 9, 15]) [(2, 4), (7, 9), (15, 15)]  >>> ranges([-1, 0, 1, 2, 3, 12, 13, 15, 100]) [(-1, 3), (12, 13), (15, 15), (100, 100)]  >>> ranges(range(100)) [(0, 99)]  >>> ranges([0]) [(0, 0)]  >>> ranges([]) []   This is the same as @dansalmo's solution which I found amazing, albeit a bit hard to read and apply (as it's not given as a function).  Note that it could easily be modified to spit out \"traditional\" open ranges [start, end), by e.g. altering the return statement:      return [(s, e+1) for s, e in zip(edges, edges)]   I copied this answer over from another question that was marked as a duplicate of this one with the intention to make it easier findable (after I just now searched again for this topic, finding only the question here at first and not being satisfied with the answers given).     ","Language":"Python","Tags":["python","list","range","continuous"],"URL":"https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'd like to identify groups of continuous numbers in a list, so that:  myfunc([2, 3, 4, 5, 12, 13, 14, 15, 16, 17, 20])   Returns:  [(2,5), (12,17), 20]   And was wondering what the best way to do this was (particularly if there's something inbuilt into Python).  Edit: Note I originally forgot to mention that individual numbers should be returned as individual numbers, not ranges.     ","Q_Votes":"63"},{"Q_Title":"Add a prefix to all Flask routes","A_Content":"  The answer depends on how you are serving this application.  Sub-mounted inside of another WSGI container  Assuming that you are going to run this application inside of a WSGI container (mod_wsgi, uwsgi, gunicorn, etc); you need to actually mount, at that prefix the application as a sub-part of that WSGI container (anything that speaks WSGI will do) and to set your APPLICATION_ROOT config value to your prefix:  app.config[\"APPLICATION_ROOT\"] = \"/abc/123\"  @app.route(\"/\") def index():     return \"The URL for this page is {}\".format(url_for(\"index\"))  # Will return \"The URL for this page is /abc/123/\"   Setting the APPLICATION_ROOT config value simply limit Flask's session cookie to that URL prefix.  Everything else will be automatically handled for you by Flask and Werkzeug's excellent WSGI handling capabilities.  An example of properly sub-mounting your app  If you are not sure what the first paragraph means, take a look at this example application with Flask mounted inside of it:  from flask import Flask, url_for from werkzeug.serving import run_simple from werkzeug.wsgi import DispatcherMiddleware  app = Flask(__name__) app.config['APPLICATION_ROOT'] = '/abc/123'  @app.route('/') def index():     return 'The URL for this page is {}'.format(url_for('index'))  def simple(env, resp):     resp(b'200 OK', [(b'Content-Type', b'text/plain')])     return [b'Hello WSGI World']  app.wsgi_app = DispatcherMiddleware(simple, {'/abc/123': app.wsgi_app})  if __name__ == '__main__':     app.run('localhost', 5000)   Proxying requests to the app  If, on the other hand, you will be running your Flask application at the root of its WSGI container and proxying requests to it (for example, if it's being FastCGI'd to, or if nginx is proxy_pass-ing requests for a sub-endpoint to your stand-alone uwsgi / gevent server then you can either:   Use a Blueprint, as Miguel points out in his answer. or use the DispatcherMiddleware from werkzeug (or the PrefixMiddleware from su27's answer) to sub-mount your application in the stand-alone WSGI server you're using.  (See An example of properly sub-mounting your app above for the code to use).      ","Language":"Python","Tags":["python","routes","flask"],"URL":"https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes","A_Votes":"55","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a prefix that I want to add to every route.  Right now I add a constant to the route at every definition.  Is there a way to do this automatically?  PREFIX = \"/abc/123\"  @app.route(PREFIX + \"/\") def index_page():   return \"This is a website about burritos\"  @app.route(PREFIX + \"/about\") def about_page():   return \"This is a website about burritos\"      ","Q_Votes":"63"},{"Q_Title":"Add a prefix to all Flask routes","A_Content":"  You can put your routes in a blueprint:  bp = Blueprint('burritos', __name__,                         template_folder='templates')  @bp.route(\"/\") def index_page():   return \"This is a website about burritos\"  @bp.route(\"/about\") def about_page():   return \"This is a website about burritos\"   Then you register the blueprint with the application using a prefix:  app = Flask(__name__) app.register_blueprint(bp, url_prefix='/abc/123')      ","Language":"Python","Tags":["python","routes","flask"],"URL":"https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes","A_Votes":"63","_type":"dict","isAccepted":"No","Q_Content":"    I have a prefix that I want to add to every route.  Right now I add a constant to the route at every definition.  Is there a way to do this automatically?  PREFIX = \"/abc/123\"  @app.route(PREFIX + \"/\") def index_page():   return \"This is a website about burritos\"  @app.route(PREFIX + \"/about\") def about_page():   return \"This is a website about burritos\"      ","Q_Votes":"63"},{"Q_Title":"Add a prefix to all Flask routes","A_Content":"  You should note that the APPLICATION_ROOT is NOT for this purpose.  All you have to do is to write a middleware to make the following changes:   modify PATH_INFO to handle the prefixed url. modify SCRIPT_NAME to generate the prefixed url.   Like this:  class PrefixMiddleware(object):      def __init__(self, app, prefix=''):         self.app = app         self.prefix = prefix      def __call__(self, environ, start_response):          if environ['PATH_INFO'].startswith(self.prefix):             environ['PATH_INFO'] = environ['PATH_INFO'][len(self.prefix):]             environ['SCRIPT_NAME'] = self.prefix             return self.app(environ, start_response)         else:             start_response('404', [('Content-Type', 'text/plain')])             return [\"This url does not belong to the app.\".encode()]   Wrap your app with the middleware, like this:  from flask import Flask, url_for  app = Flask(__name__) app.debug = True app.wsgi_app = PrefixMiddleware(app.wsgi_app, prefix='/foo')   @app.route('/bar') def bar():     return \"The URL for this page is {}\".format(url_for('bar'))   if __name__ == '__main__':     app.run('0.0.0.0', 9010)   Visit http://localhost:9010/foo/bar,  You will get the right result: The URL for this page is /foo/bar  And don't forget to set the cookie domain if you need to.  This solution is given by Larivact's gist. The APPLICATION_ROOT is not for this job, although it looks like to be. It's really confusing.     ","Language":"Python","Tags":["python","routes","flask"],"URL":"https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I have a prefix that I want to add to every route.  Right now I add a constant to the route at every definition.  Is there a way to do this automatically?  PREFIX = \"/abc/123\"  @app.route(PREFIX + \"/\") def index_page():   return \"This is a website about burritos\"  @app.route(PREFIX + \"/about\") def about_page():   return \"This is a website about burritos\"      ","Q_Votes":"63"},{"Q_Title":"Add a prefix to all Flask routes","A_Content":"  This is more of a python answer than a Flask/werkzeug answer; but it's simple and works.  If, like me, you want your application settings (loaded from an .ini file) to also contain the prefix of your Flask application (thus, not to have the value set during deployment, but during runtime), you can opt for the following:  def prefix_route(route_function, prefix='', mask='{0}{1}'):   '''     Defines a new route function with a prefix.     The mask argument is a `format string` formatted with, in that order:       prefix, route   '''   def newroute(route, *args, **kwargs):     '''New function to prefix the route'''     return route_function(mask.format(prefix, route), *args, **kwargs)   return newroute   Arguably, this is somewhat hackish and relies on the fact that the Flask route function requires a route as a first positional argument.  You can use it like this:  app = Flask(__name__) app.route = prefix_route(app.route, '/your_prefix')   NB: It is worth nothing that it is possible to use a variable in the prefix (for example by setting it to /<prefix>), and then process this prefix in the functions you decorate with your @app.route(...). If you do so, you obviously have to declare the prefix parameter in your decorated function(s). In addition, you might want to check the submitted prefix against some rules, and return a 404 if the check fails. In order to avoid a 404 custom re-implementation, please from werkzeug.exceptions import NotFound and then raise NotFound() if the check fails.     ","Language":"Python","Tags":["python","routes","flask"],"URL":"https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have a prefix that I want to add to every route.  Right now I add a constant to the route at every definition.  Is there a way to do this automatically?  PREFIX = \"/abc/123\"  @app.route(PREFIX + \"/\") def index_page():   return \"This is a website about burritos\"  @app.route(PREFIX + \"/about\") def about_page():   return \"This is a website about burritos\"      ","Q_Votes":"63"},{"Q_Title":"Add a prefix to all Flask routes","A_Content":"  So, I believe that a valid answer to this is: the prefix should be configured in the actual server application that you use when development is completed. Apache, nginx, etc.  However, if you would like this to work during development while running the Flask app in debug, take a look at this gist.  Flask's DispatcherMiddleware to the rescue!  I'll copy the code here for posterity:  \"Serve a Flask app on a sub-url during localhost development.\"  from flask import Flask   APPLICATION_ROOT = '/spam'   app = Flask(__name__) app.config.from_object(__name__)  # I think this adds APPLICATION_ROOT                                   # to the config - I'm not exactly sure how! # alternatively: # app.config['APPLICATION_ROOT'] = APPLICATION_ROOT   @app.route('/') def index():     return 'Hello, world!'   if __name__ == '__main__':     # Relevant documents:     # http://werkzeug.pocoo.org/docs/middlewares/     # http://flask.pocoo.org/docs/patterns/appdispatch/     from werkzeug.serving import run_simple     from werkzeug.wsgi import DispatcherMiddleware     app.config['DEBUG'] = True     # Load a dummy app at the root URL to give 404 errors.     # Serve app at APPLICATION_ROOT for localhost development.     application = DispatcherMiddleware(Flask('dummy_app'), {         app.config['APPLICATION_ROOT']: app,     })     run_simple('localhost', 5000, application, use_reloader=True)   Now, when running the above code as a standalone Flask app, http://localhost:5000/spam/ will display Hello, world!.  In a comment on another answer, I expressed that I wished to do something like this:  from flask import Flask, Blueprint  # Let's pretend module_blueprint defines a route, '/record/<id>/' from some_submodule.flask import module_blueprint  app = Flask(__name__) app.config['APPLICATION_ROOT'] = '/api' app.register_blueprint(module_blueprint, url_prefix='/some_submodule') app.run()  # I now would like to be able to get to my route via this url: # http://host:8080/api/some_submodule/record/1/   Applying DispatcherMiddleware to my contrived example:  from flask import Flask, Blueprint from flask.serving import run_simple from flask.wsgi import DispatcherMiddleware  # Let's pretend module_blueprint defines a route, '/record/<id>/' from some_submodule.flask import module_blueprint  app = Flask(__name__) app.config['APPLICATION_ROOT'] = '/api' app.register_blueprint(module_blueprint, url_prefix='/some_submodule') application = DispatcherMiddleware(Flask('dummy_app'), {     app.config['APPLICATION_ROOT']: app }) run_simple('localhost', 5000, application, use_reloader=True)  # Now, this url works! # http://host:8080/api/some_submodule/record/1/      ","Language":"Python","Tags":["python","routes","flask"],"URL":"https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a prefix that I want to add to every route.  Right now I add a constant to the route at every definition.  Is there a way to do this automatically?  PREFIX = \"/abc/123\"  @app.route(PREFIX + \"/\") def index_page():   return \"This is a website about burritos\"  @app.route(PREFIX + \"/about\") def about_page():   return \"This is a website about burritos\"      ","Q_Votes":"63"},{"Q_Title":"Add a prefix to all Flask routes","A_Content":"  I needed similar so called \"context-root\". I did it in conf file under /etc/httpd/conf.d/ using WSGIScriptAlias :  myapp.conf:  <VirtualHost *:80>     WSGIScriptAlias /myapp /home/<myid>/myapp/wsgi.py      <Directory /home/<myid>/myapp>         Order deny,allow         Allow from all     </Directory>  </VirtualHost>   So now I can access my app as : http://localhost:5000/myapp  See the guide - http://modwsgi.readthedocs.io/en/develop/user-guides/quick-configuration-guide.html     ","Language":"Python","Tags":["python","routes","flask"],"URL":"https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a prefix that I want to add to every route.  Right now I add a constant to the route at every definition.  Is there a way to do this automatically?  PREFIX = \"/abc/123\"  @app.route(PREFIX + \"/\") def index_page():   return \"This is a website about burritos\"  @app.route(PREFIX + \"/about\") def about_page():   return \"This is a website about burritos\"      ","Q_Votes":"63"},{"Q_Title":"Add a prefix to all Flask routes","A_Content":"  Another completely different way is with mountpoints in uwsgi.  From the doc about Hosting multiple apps in the same process (permalink).  In your uwsgi.ini you add  [uwsgi] mount = /foo=main.py manage-script-name = true  # also stuff which is not relevant for this, but included for completeness sake:     module = main callable = app socket = /tmp/uwsgi.sock   If you don't call your file main.py, you need to change both the mount and the module     Your main.py could look like this:  from flask import Flask, url_for app = Flask(__name__) @app.route('/bar') def bar():   return \"The URL for this page is {}\".format(url_for('bar')) # end def   And a nginx config (again for completeness):  server {   listen 80;   server_name example.com    location /foo {     include uwsgi_params;     uwsgi_pass unix:///temp/uwsgi.sock;   } }   Now calling example.com/foo/bar will display /foo/bar as returned by flask's url_for('bar'), as it adapts automatically. That way your links will work without prefix problems.     ","Language":"Python","Tags":["python","routes","flask"],"URL":"https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a prefix that I want to add to every route.  Right now I add a constant to the route at every definition.  Is there a way to do this automatically?  PREFIX = \"/abc/123\"  @app.route(PREFIX + \"/\") def index_page():   return \"This is a website about burritos\"  @app.route(PREFIX + \"/about\") def about_page():   return \"This is a website about burritos\"      ","Q_Votes":"63"},{"Q_Title":"Add a prefix to all Flask routes","A_Content":"  I always prefer to use the following when it comes to adding a prefix on the entire app:  app = Flask(__name__, root_path='/operators')   Clean and clear.     ","Language":"Python","Tags":["python","routes","flask"],"URL":"https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a prefix that I want to add to every route.  Right now I add a constant to the route at every definition.  Is there a way to do this automatically?  PREFIX = \"/abc/123\"  @app.route(PREFIX + \"/\") def index_page():   return \"This is a website about burritos\"  @app.route(PREFIX + \"/about\") def about_page():   return \"This is a website about burritos\"      ","Q_Votes":"63"},{"Q_Title":"Access request in django custom template tags","A_Content":"  request is not a variable in that scope. You will have to get it from the context first. Pass takes_context to the decorator and add context to the tag arguments.  Like this:  @register.inclusion_tag('new/userinfo.html', takes_context=True) def address(context):     request = context['request']     address = request.session['address']     return {'address':address}      ","Language":"Python","Tags":["python","django","django-templates","django-custom-tags"],"URL":"https://stackoverflow.com/questions/2160261/access-request-in-django-custom-template-tags","A_Votes":"141","_type":"dict","isAccepted":"Yes","Q_Content":"    My code in myapp_extras.py:  from django import template  register = template.Library()  @register.inclusion_tag('new/userinfo.html') def address():     address = request.session['address']     return {'address':address}   in 'settings.py':  TEMPLATE_CONTEXT_PROCESSORS =(     \"django.core.context_processors.auth\",     \"django.core.context_processors.debug\",     \"django.core.context_processors.i18n\",     \"django.core.context_processors.media\",     'django.core.context_processors.request' )   but I got an error:  TemplateSyntaxError at /items/  Caught an exception while rendering: global name 'request' is not defined  Original Traceback (most recent call last):   File \"C:\\Python25\\lib\\site-packages\\django\\template\\debug.py\", line 71, in render_node     result = node.render(context)   File \"C:\\Python25\\lib\\site-packages\\django\\template\\__init__.py\", line 915, in render     dict = func(*args)   File \"C:\\p4\\projects\\myproject\\..\\myproject\\invoice\\templatetags\\myapp_extras.py\", line 9, in address     address = request.session['address'] NameError: global name 'request' is not defined   I referenced this one In Django, is it possible to access the current user session from within a custom tag?.     ","Q_Votes":"63"},{"Q_Title":"Access request in django custom template tags","A_Content":"  I've tried solution from above (from Ignacio Vazquez-Abrams) and it actually didn't work until I've found out that context processors works only with RequestContext wrapper class.  So in main view method you should add the following line:  from django.template import RequestContext         return render_to_response('index.html', {'form': form, },                                context_instance = RequestContext(request))      ","Language":"Python","Tags":["python","django","django-templates","django-custom-tags"],"URL":"https://stackoverflow.com/questions/2160261/access-request-in-django-custom-template-tags","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    My code in myapp_extras.py:  from django import template  register = template.Library()  @register.inclusion_tag('new/userinfo.html') def address():     address = request.session['address']     return {'address':address}   in 'settings.py':  TEMPLATE_CONTEXT_PROCESSORS =(     \"django.core.context_processors.auth\",     \"django.core.context_processors.debug\",     \"django.core.context_processors.i18n\",     \"django.core.context_processors.media\",     'django.core.context_processors.request' )   but I got an error:  TemplateSyntaxError at /items/  Caught an exception while rendering: global name 'request' is not defined  Original Traceback (most recent call last):   File \"C:\\Python25\\lib\\site-packages\\django\\template\\debug.py\", line 71, in render_node     result = node.render(context)   File \"C:\\Python25\\lib\\site-packages\\django\\template\\__init__.py\", line 915, in render     dict = func(*args)   File \"C:\\p4\\projects\\myproject\\..\\myproject\\invoice\\templatetags\\myapp_extras.py\", line 9, in address     address = request.session['address'] NameError: global name 'request' is not defined   I referenced this one In Django, is it possible to access the current user session from within a custom tag?.     ","Q_Votes":"63"},{"Q_Title":"Access request in django custom template tags","A_Content":"  I've done this way:  from django import template register = template.Library()  def do_test_request(parser,token):     try:         tag_name = token.split_contents() # Not really useful     except ValueError:         raise template.TemplateSyntaxError(\"%r error\" % token.contents.split()[0])     return RequestTestNode()  class RequestTestNode(template.Node):     def __init__(self,):         self.request = template.Variable('request')     def render(self, context):         rqst = self.request.resolve(context)         return \"The URL is: %s\" % rqst.get_full_path()  register.tag('test_request', do_test_request)   There is also a function called resolve_variable, but it's deprecated.  Hope it helps!     ","Language":"Python","Tags":["python","django","django-templates","django-custom-tags"],"URL":"https://stackoverflow.com/questions/2160261/access-request-in-django-custom-template-tags","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    My code in myapp_extras.py:  from django import template  register = template.Library()  @register.inclusion_tag('new/userinfo.html') def address():     address = request.session['address']     return {'address':address}   in 'settings.py':  TEMPLATE_CONTEXT_PROCESSORS =(     \"django.core.context_processors.auth\",     \"django.core.context_processors.debug\",     \"django.core.context_processors.i18n\",     \"django.core.context_processors.media\",     'django.core.context_processors.request' )   but I got an error:  TemplateSyntaxError at /items/  Caught an exception while rendering: global name 'request' is not defined  Original Traceback (most recent call last):   File \"C:\\Python25\\lib\\site-packages\\django\\template\\debug.py\", line 71, in render_node     result = node.render(context)   File \"C:\\Python25\\lib\\site-packages\\django\\template\\__init__.py\", line 915, in render     dict = func(*args)   File \"C:\\p4\\projects\\myproject\\..\\myproject\\invoice\\templatetags\\myapp_extras.py\", line 9, in address     address = request.session['address'] NameError: global name 'request' is not defined   I referenced this one In Django, is it possible to access the current user session from within a custom tag?.     ","Q_Votes":"63"},{"Q_Title":"How can I install the Python library 'gevent' on Mac OS X Lion","A_Content":"  Don't post the entire thing!  That's too much!  90% of the time, the first error is enough...   gevent/libevent.h:9:19: error: event.h: No such file or directory   This means that the library which provides the event.h header is not installed.  The library is called libevent (website).  In general, compilation errors like these are a flaw in the build scripts.  The build script should give an error message that libevent is not installed, and it is a bug that it did not do so.  To get libevent from MacPorts and then manually tell compiler with CFLAGS environment variable where to find event.h and libevent while running pip.  sudo port install libevent CFLAGS=\"-I /opt/local/include -L /opt/local/lib\" pip install gevent   You can also use homebrew for installing libevent : brew install libevent  (from David Wolever's comment)     ","Language":"Python","Tags":["python","macos","osx-lion","gevent"],"URL":"https://stackoverflow.com/questions/7630388/how-can-i-install-the-python-library-gevent-on-mac-os-x-lion","A_Votes":"114","_type":"dict","isAccepted":"Yes","Q_Content":"    Python library gevent, version 0.13.6 (the current version on PyPI) will not pip install on OS X Lion, Python 2.7 (and probably others.) It works fine on Snow Leopard.  How can I get this library installed?  Bonus points if it can be done using pip install, rather than a manual or custom process, because then it will play nicely with automated builds.  Here is my pip install output:  pip install gevent Downloading/unpacking gevent   Running setup.py egg_info for package gevent  Requirement already satisfied (use --upgrade to upgrade): greenlet in ./tl_env/lib/python2.7/site-packages (from gevent) Installing collected packages: gevent   Running setup.py install for gevent     building 'gevent.core' extension     gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o     In file included from gevent/core.c:225:     gevent/libevent.h:9:19: error: event.h: No such file or directory     gevent/libevent.h:38:20: error: evhttp.h: No such file or directory     gevent/libevent.h:39:19: error: evdns.h: No such file or directory     gevent/core.c:361: error: field ‘ev’ has incomplete type     gevent/core.c:741: warning: parameter names (without types) in function declaration     gevent/core.c: In function ‘__pyx_f_6gevent_4core___event_handler’:     gevent/core.c:1619: error: ‘EV_READ’ undeclared (first use in this function)     gevent/core.c:1619: error: (Each undeclared identifier is reported only once     gevent/core.c:15376: warning: assignment makes pointer from integer without a cast    [... about 1000 more lines of compiler errors...]     gevent/core.c:15385: error: dereferencing pointer to incomplete type     gevent/core.c: In function ‘__pyx_pf_6gevent_4core_4http___init__’:     gevent/core.c:15559: warning: assignment makes pointer from integer without a cast     gevent/core.c: At top level:     gevent/core.c:21272: error: expected ‘)’ before ‘val’     lipo: can't figure out the architecture type of: /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T//cczk54q7.out     error: command 'gcc-4.2' failed with exit status 1     Complete output from command /Users/jacob/code/toplevel/tl_env/bin/python -c \"import setuptools;__file__='/Users/jacob/code/toplevel/tl_env/build/gevent/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T/pip-s2hPd3-record/install-record.txt --install-headers /Users/jacob/code/toplevel/tl_env/bin/../include/site/python2.7:     running install  running build  running build_py  running build_ext  building 'gevent.core' extension  gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o      ","Q_Votes":"63"},{"Q_Title":"How can I install the Python library 'gevent' on Mac OS X Lion","A_Content":"  CFLAGS='-std=c99' pip install gevent   See in: Can't install gevent OSX 10.11  on OS X 10.11, clang uses c11 as the default, so just turn it back to c99.     ","Language":"Python","Tags":["python","macos","osx-lion","gevent"],"URL":"https://stackoverflow.com/questions/7630388/how-can-i-install-the-python-library-gevent-on-mac-os-x-lion","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    Python library gevent, version 0.13.6 (the current version on PyPI) will not pip install on OS X Lion, Python 2.7 (and probably others.) It works fine on Snow Leopard.  How can I get this library installed?  Bonus points if it can be done using pip install, rather than a manual or custom process, because then it will play nicely with automated builds.  Here is my pip install output:  pip install gevent Downloading/unpacking gevent   Running setup.py egg_info for package gevent  Requirement already satisfied (use --upgrade to upgrade): greenlet in ./tl_env/lib/python2.7/site-packages (from gevent) Installing collected packages: gevent   Running setup.py install for gevent     building 'gevent.core' extension     gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o     In file included from gevent/core.c:225:     gevent/libevent.h:9:19: error: event.h: No such file or directory     gevent/libevent.h:38:20: error: evhttp.h: No such file or directory     gevent/libevent.h:39:19: error: evdns.h: No such file or directory     gevent/core.c:361: error: field ‘ev’ has incomplete type     gevent/core.c:741: warning: parameter names (without types) in function declaration     gevent/core.c: In function ‘__pyx_f_6gevent_4core___event_handler’:     gevent/core.c:1619: error: ‘EV_READ’ undeclared (first use in this function)     gevent/core.c:1619: error: (Each undeclared identifier is reported only once     gevent/core.c:15376: warning: assignment makes pointer from integer without a cast    [... about 1000 more lines of compiler errors...]     gevent/core.c:15385: error: dereferencing pointer to incomplete type     gevent/core.c: In function ‘__pyx_pf_6gevent_4core_4http___init__’:     gevent/core.c:15559: warning: assignment makes pointer from integer without a cast     gevent/core.c: At top level:     gevent/core.c:21272: error: expected ‘)’ before ‘val’     lipo: can't figure out the architecture type of: /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T//cczk54q7.out     error: command 'gcc-4.2' failed with exit status 1     Complete output from command /Users/jacob/code/toplevel/tl_env/bin/python -c \"import setuptools;__file__='/Users/jacob/code/toplevel/tl_env/build/gevent/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T/pip-s2hPd3-record/install-record.txt --install-headers /Users/jacob/code/toplevel/tl_env/bin/../include/site/python2.7:     running install  running build  running build_py  running build_ext  building 'gevent.core' extension  gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o      ","Q_Votes":"63"},{"Q_Title":"How can I install the Python library 'gevent' on Mac OS X Lion","A_Content":"  After a while, I realized that the paths for the CFLAGS variable mentioned above works when installing libevent from port, but not from brew. The following worked for me (on OSX Mavericks):   $ brew install libevent $ export CFLAGS=\"-I /usr/local/Cellar/libevent/2.0.21/include -L /usr/local/Cellar/libevent/2.0.21/lib\" $ pip install gevent      ","Language":"Python","Tags":["python","macos","osx-lion","gevent"],"URL":"https://stackoverflow.com/questions/7630388/how-can-i-install-the-python-library-gevent-on-mac-os-x-lion","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    Python library gevent, version 0.13.6 (the current version on PyPI) will not pip install on OS X Lion, Python 2.7 (and probably others.) It works fine on Snow Leopard.  How can I get this library installed?  Bonus points if it can be done using pip install, rather than a manual or custom process, because then it will play nicely with automated builds.  Here is my pip install output:  pip install gevent Downloading/unpacking gevent   Running setup.py egg_info for package gevent  Requirement already satisfied (use --upgrade to upgrade): greenlet in ./tl_env/lib/python2.7/site-packages (from gevent) Installing collected packages: gevent   Running setup.py install for gevent     building 'gevent.core' extension     gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o     In file included from gevent/core.c:225:     gevent/libevent.h:9:19: error: event.h: No such file or directory     gevent/libevent.h:38:20: error: evhttp.h: No such file or directory     gevent/libevent.h:39:19: error: evdns.h: No such file or directory     gevent/core.c:361: error: field ‘ev’ has incomplete type     gevent/core.c:741: warning: parameter names (without types) in function declaration     gevent/core.c: In function ‘__pyx_f_6gevent_4core___event_handler’:     gevent/core.c:1619: error: ‘EV_READ’ undeclared (first use in this function)     gevent/core.c:1619: error: (Each undeclared identifier is reported only once     gevent/core.c:15376: warning: assignment makes pointer from integer without a cast    [... about 1000 more lines of compiler errors...]     gevent/core.c:15385: error: dereferencing pointer to incomplete type     gevent/core.c: In function ‘__pyx_pf_6gevent_4core_4http___init__’:     gevent/core.c:15559: warning: assignment makes pointer from integer without a cast     gevent/core.c: At top level:     gevent/core.c:21272: error: expected ‘)’ before ‘val’     lipo: can't figure out the architecture type of: /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T//cczk54q7.out     error: command 'gcc-4.2' failed with exit status 1     Complete output from command /Users/jacob/code/toplevel/tl_env/bin/python -c \"import setuptools;__file__='/Users/jacob/code/toplevel/tl_env/build/gevent/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T/pip-s2hPd3-record/install-record.txt --install-headers /Users/jacob/code/toplevel/tl_env/bin/../include/site/python2.7:     running install  running build  running build_py  running build_ext  building 'gevent.core' extension  gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o      ","Q_Votes":"63"},{"Q_Title":"How can I install the Python library 'gevent' on Mac OS X Lion","A_Content":"  This is the way I found the easiest:  install libevent using homebrew  $ brew install libevent   install gevent  $ pip install gevent   This was the only way I could get it to work.     ","Language":"Python","Tags":["python","macos","osx-lion","gevent"],"URL":"https://stackoverflow.com/questions/7630388/how-can-i-install-the-python-library-gevent-on-mac-os-x-lion","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Python library gevent, version 0.13.6 (the current version on PyPI) will not pip install on OS X Lion, Python 2.7 (and probably others.) It works fine on Snow Leopard.  How can I get this library installed?  Bonus points if it can be done using pip install, rather than a manual or custom process, because then it will play nicely with automated builds.  Here is my pip install output:  pip install gevent Downloading/unpacking gevent   Running setup.py egg_info for package gevent  Requirement already satisfied (use --upgrade to upgrade): greenlet in ./tl_env/lib/python2.7/site-packages (from gevent) Installing collected packages: gevent   Running setup.py install for gevent     building 'gevent.core' extension     gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o     In file included from gevent/core.c:225:     gevent/libevent.h:9:19: error: event.h: No such file or directory     gevent/libevent.h:38:20: error: evhttp.h: No such file or directory     gevent/libevent.h:39:19: error: evdns.h: No such file or directory     gevent/core.c:361: error: field ‘ev’ has incomplete type     gevent/core.c:741: warning: parameter names (without types) in function declaration     gevent/core.c: In function ‘__pyx_f_6gevent_4core___event_handler’:     gevent/core.c:1619: error: ‘EV_READ’ undeclared (first use in this function)     gevent/core.c:1619: error: (Each undeclared identifier is reported only once     gevent/core.c:15376: warning: assignment makes pointer from integer without a cast    [... about 1000 more lines of compiler errors...]     gevent/core.c:15385: error: dereferencing pointer to incomplete type     gevent/core.c: In function ‘__pyx_pf_6gevent_4core_4http___init__’:     gevent/core.c:15559: warning: assignment makes pointer from integer without a cast     gevent/core.c: At top level:     gevent/core.c:21272: error: expected ‘)’ before ‘val’     lipo: can't figure out the architecture type of: /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T//cczk54q7.out     error: command 'gcc-4.2' failed with exit status 1     Complete output from command /Users/jacob/code/toplevel/tl_env/bin/python -c \"import setuptools;__file__='/Users/jacob/code/toplevel/tl_env/build/gevent/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T/pip-s2hPd3-record/install-record.txt --install-headers /Users/jacob/code/toplevel/tl_env/bin/../include/site/python2.7:     running install  running build  running build_py  running build_ext  building 'gevent.core' extension  gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o      ","Q_Votes":"63"},{"Q_Title":"How can I install the Python library 'gevent' on Mac OS X Lion","A_Content":"  Found this answer when looking for help installing on Snow Leopard, posting this in case someone else comes this way with the same problem.  I had libevent installed via macports.  export CFLAGS=-I/opt/local/include export LDFLAGS=-L/opt/local/lib sudo pip install gevent     ","Language":"Python","Tags":["python","macos","osx-lion","gevent"],"URL":"https://stackoverflow.com/questions/7630388/how-can-i-install-the-python-library-gevent-on-mac-os-x-lion","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Python library gevent, version 0.13.6 (the current version on PyPI) will not pip install on OS X Lion, Python 2.7 (and probably others.) It works fine on Snow Leopard.  How can I get this library installed?  Bonus points if it can be done using pip install, rather than a manual or custom process, because then it will play nicely with automated builds.  Here is my pip install output:  pip install gevent Downloading/unpacking gevent   Running setup.py egg_info for package gevent  Requirement already satisfied (use --upgrade to upgrade): greenlet in ./tl_env/lib/python2.7/site-packages (from gevent) Installing collected packages: gevent   Running setup.py install for gevent     building 'gevent.core' extension     gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o     In file included from gevent/core.c:225:     gevent/libevent.h:9:19: error: event.h: No such file or directory     gevent/libevent.h:38:20: error: evhttp.h: No such file or directory     gevent/libevent.h:39:19: error: evdns.h: No such file or directory     gevent/core.c:361: error: field ‘ev’ has incomplete type     gevent/core.c:741: warning: parameter names (without types) in function declaration     gevent/core.c: In function ‘__pyx_f_6gevent_4core___event_handler’:     gevent/core.c:1619: error: ‘EV_READ’ undeclared (first use in this function)     gevent/core.c:1619: error: (Each undeclared identifier is reported only once     gevent/core.c:15376: warning: assignment makes pointer from integer without a cast    [... about 1000 more lines of compiler errors...]     gevent/core.c:15385: error: dereferencing pointer to incomplete type     gevent/core.c: In function ‘__pyx_pf_6gevent_4core_4http___init__’:     gevent/core.c:15559: warning: assignment makes pointer from integer without a cast     gevent/core.c: At top level:     gevent/core.c:21272: error: expected ‘)’ before ‘val’     lipo: can't figure out the architecture type of: /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T//cczk54q7.out     error: command 'gcc-4.2' failed with exit status 1     Complete output from command /Users/jacob/code/toplevel/tl_env/bin/python -c \"import setuptools;__file__='/Users/jacob/code/toplevel/tl_env/build/gevent/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T/pip-s2hPd3-record/install-record.txt --install-headers /Users/jacob/code/toplevel/tl_env/bin/../include/site/python2.7:     running install  running build  running build_py  running build_ext  building 'gevent.core' extension  gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o      ","Q_Votes":"63"},{"Q_Title":"How can I install the Python library 'gevent' on Mac OS X Lion","A_Content":"  I had libevent installed via brew and it failed too, what worked was similar to what Stephen done, but pointing to brew default install:  CFLAGS=-I/usr/local/include LDFLAGS=-L/usr/local/lib pip install gevent     ","Language":"Python","Tags":["python","macos","osx-lion","gevent"],"URL":"https://stackoverflow.com/questions/7630388/how-can-i-install-the-python-library-gevent-on-mac-os-x-lion","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Python library gevent, version 0.13.6 (the current version on PyPI) will not pip install on OS X Lion, Python 2.7 (and probably others.) It works fine on Snow Leopard.  How can I get this library installed?  Bonus points if it can be done using pip install, rather than a manual or custom process, because then it will play nicely with automated builds.  Here is my pip install output:  pip install gevent Downloading/unpacking gevent   Running setup.py egg_info for package gevent  Requirement already satisfied (use --upgrade to upgrade): greenlet in ./tl_env/lib/python2.7/site-packages (from gevent) Installing collected packages: gevent   Running setup.py install for gevent     building 'gevent.core' extension     gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o     In file included from gevent/core.c:225:     gevent/libevent.h:9:19: error: event.h: No such file or directory     gevent/libevent.h:38:20: error: evhttp.h: No such file or directory     gevent/libevent.h:39:19: error: evdns.h: No such file or directory     gevent/core.c:361: error: field ‘ev’ has incomplete type     gevent/core.c:741: warning: parameter names (without types) in function declaration     gevent/core.c: In function ‘__pyx_f_6gevent_4core___event_handler’:     gevent/core.c:1619: error: ‘EV_READ’ undeclared (first use in this function)     gevent/core.c:1619: error: (Each undeclared identifier is reported only once     gevent/core.c:15376: warning: assignment makes pointer from integer without a cast    [... about 1000 more lines of compiler errors...]     gevent/core.c:15385: error: dereferencing pointer to incomplete type     gevent/core.c: In function ‘__pyx_pf_6gevent_4core_4http___init__’:     gevent/core.c:15559: warning: assignment makes pointer from integer without a cast     gevent/core.c: At top level:     gevent/core.c:21272: error: expected ‘)’ before ‘val’     lipo: can't figure out the architecture type of: /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T//cczk54q7.out     error: command 'gcc-4.2' failed with exit status 1     Complete output from command /Users/jacob/code/toplevel/tl_env/bin/python -c \"import setuptools;__file__='/Users/jacob/code/toplevel/tl_env/build/gevent/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T/pip-s2hPd3-record/install-record.txt --install-headers /Users/jacob/code/toplevel/tl_env/bin/../include/site/python2.7:     running install  running build  running build_py  running build_ext  building 'gevent.core' extension  gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o      ","Q_Votes":"63"},{"Q_Title":"How can I install the Python library 'gevent' on Mac OS X Lion","A_Content":"  In case you install all from sources and use csh the following works on mac os 10.9   download latest stable http://libevent.org/ libevent-2.0.21-stable   ./configure make sudo make install  virtualenv env source env/bin/activate.csh setenv CFLAGS \"-I /usr/local/include -L /usr/local/lib\" pip install gevent      ","Language":"Python","Tags":["python","macos","osx-lion","gevent"],"URL":"https://stackoverflow.com/questions/7630388/how-can-i-install-the-python-library-gevent-on-mac-os-x-lion","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Python library gevent, version 0.13.6 (the current version on PyPI) will not pip install on OS X Lion, Python 2.7 (and probably others.) It works fine on Snow Leopard.  How can I get this library installed?  Bonus points if it can be done using pip install, rather than a manual or custom process, because then it will play nicely with automated builds.  Here is my pip install output:  pip install gevent Downloading/unpacking gevent   Running setup.py egg_info for package gevent  Requirement already satisfied (use --upgrade to upgrade): greenlet in ./tl_env/lib/python2.7/site-packages (from gevent) Installing collected packages: gevent   Running setup.py install for gevent     building 'gevent.core' extension     gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o     In file included from gevent/core.c:225:     gevent/libevent.h:9:19: error: event.h: No such file or directory     gevent/libevent.h:38:20: error: evhttp.h: No such file or directory     gevent/libevent.h:39:19: error: evdns.h: No such file or directory     gevent/core.c:361: error: field ‘ev’ has incomplete type     gevent/core.c:741: warning: parameter names (without types) in function declaration     gevent/core.c: In function ‘__pyx_f_6gevent_4core___event_handler’:     gevent/core.c:1619: error: ‘EV_READ’ undeclared (first use in this function)     gevent/core.c:1619: error: (Each undeclared identifier is reported only once     gevent/core.c:15376: warning: assignment makes pointer from integer without a cast    [... about 1000 more lines of compiler errors...]     gevent/core.c:15385: error: dereferencing pointer to incomplete type     gevent/core.c: In function ‘__pyx_pf_6gevent_4core_4http___init__’:     gevent/core.c:15559: warning: assignment makes pointer from integer without a cast     gevent/core.c: At top level:     gevent/core.c:21272: error: expected ‘)’ before ‘val’     lipo: can't figure out the architecture type of: /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T//cczk54q7.out     error: command 'gcc-4.2' failed with exit status 1     Complete output from command /Users/jacob/code/toplevel/tl_env/bin/python -c \"import setuptools;__file__='/Users/jacob/code/toplevel/tl_env/build/gevent/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T/pip-s2hPd3-record/install-record.txt --install-headers /Users/jacob/code/toplevel/tl_env/bin/../include/site/python2.7:     running install  running build  running build_py  running build_ext  building 'gevent.core' extension  gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o      ","Q_Votes":"63"},{"Q_Title":"How can I install the Python library 'gevent' on Mac OS X Lion","A_Content":"  I use virtualenv and virtualenv wrapper, and so I wanted this to be self contained. I got gevent working like so:  Assuming you have virtual env setup, then:  workon {my_virtual_env}   Then download libevent and install it against the virtualenv.  curl -L -O https://github.com/downloads/libevent/libevent/libevent-2.0.21-stable.tar.gz  tar -xzf libevent-2.0.21-stable.tar.gz cd libevent-2.0.21-stable ./configure --prefix=\"$VIRTUAL_ENV\" make && make install   I'm assuming you've got gcc 5+ installed (I use brew)  Hope this helps.     ","Language":"Python","Tags":["python","macos","osx-lion","gevent"],"URL":"https://stackoverflow.com/questions/7630388/how-can-i-install-the-python-library-gevent-on-mac-os-x-lion","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Python library gevent, version 0.13.6 (the current version on PyPI) will not pip install on OS X Lion, Python 2.7 (and probably others.) It works fine on Snow Leopard.  How can I get this library installed?  Bonus points if it can be done using pip install, rather than a manual or custom process, because then it will play nicely with automated builds.  Here is my pip install output:  pip install gevent Downloading/unpacking gevent   Running setup.py egg_info for package gevent  Requirement already satisfied (use --upgrade to upgrade): greenlet in ./tl_env/lib/python2.7/site-packages (from gevent) Installing collected packages: gevent   Running setup.py install for gevent     building 'gevent.core' extension     gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o     In file included from gevent/core.c:225:     gevent/libevent.h:9:19: error: event.h: No such file or directory     gevent/libevent.h:38:20: error: evhttp.h: No such file or directory     gevent/libevent.h:39:19: error: evdns.h: No such file or directory     gevent/core.c:361: error: field ‘ev’ has incomplete type     gevent/core.c:741: warning: parameter names (without types) in function declaration     gevent/core.c: In function ‘__pyx_f_6gevent_4core___event_handler’:     gevent/core.c:1619: error: ‘EV_READ’ undeclared (first use in this function)     gevent/core.c:1619: error: (Each undeclared identifier is reported only once     gevent/core.c:15376: warning: assignment makes pointer from integer without a cast    [... about 1000 more lines of compiler errors...]     gevent/core.c:15385: error: dereferencing pointer to incomplete type     gevent/core.c: In function ‘__pyx_pf_6gevent_4core_4http___init__’:     gevent/core.c:15559: warning: assignment makes pointer from integer without a cast     gevent/core.c: At top level:     gevent/core.c:21272: error: expected ‘)’ before ‘val’     lipo: can't figure out the architecture type of: /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T//cczk54q7.out     error: command 'gcc-4.2' failed with exit status 1     Complete output from command /Users/jacob/code/toplevel/tl_env/bin/python -c \"import setuptools;__file__='/Users/jacob/code/toplevel/tl_env/build/gevent/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T/pip-s2hPd3-record/install-record.txt --install-headers /Users/jacob/code/toplevel/tl_env/bin/../include/site/python2.7:     running install  running build  running build_py  running build_ext  building 'gevent.core' extension  gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o      ","Q_Votes":"63"},{"Q_Title":"How can I install the Python library 'gevent' on Mac OS X Lion","A_Content":"  sudo pip install cython git+git://github.com/gevent/gevent.git#egg=gevent      ","Language":"Python","Tags":["python","macos","osx-lion","gevent"],"URL":"https://stackoverflow.com/questions/7630388/how-can-i-install-the-python-library-gevent-on-mac-os-x-lion","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Python library gevent, version 0.13.6 (the current version on PyPI) will not pip install on OS X Lion, Python 2.7 (and probably others.) It works fine on Snow Leopard.  How can I get this library installed?  Bonus points if it can be done using pip install, rather than a manual or custom process, because then it will play nicely with automated builds.  Here is my pip install output:  pip install gevent Downloading/unpacking gevent   Running setup.py egg_info for package gevent  Requirement already satisfied (use --upgrade to upgrade): greenlet in ./tl_env/lib/python2.7/site-packages (from gevent) Installing collected packages: gevent   Running setup.py install for gevent     building 'gevent.core' extension     gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o     In file included from gevent/core.c:225:     gevent/libevent.h:9:19: error: event.h: No such file or directory     gevent/libevent.h:38:20: error: evhttp.h: No such file or directory     gevent/libevent.h:39:19: error: evdns.h: No such file or directory     gevent/core.c:361: error: field ‘ev’ has incomplete type     gevent/core.c:741: warning: parameter names (without types) in function declaration     gevent/core.c: In function ‘__pyx_f_6gevent_4core___event_handler’:     gevent/core.c:1619: error: ‘EV_READ’ undeclared (first use in this function)     gevent/core.c:1619: error: (Each undeclared identifier is reported only once     gevent/core.c:15376: warning: assignment makes pointer from integer without a cast    [... about 1000 more lines of compiler errors...]     gevent/core.c:15385: error: dereferencing pointer to incomplete type     gevent/core.c: In function ‘__pyx_pf_6gevent_4core_4http___init__’:     gevent/core.c:15559: warning: assignment makes pointer from integer without a cast     gevent/core.c: At top level:     gevent/core.c:21272: error: expected ‘)’ before ‘val’     lipo: can't figure out the architecture type of: /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T//cczk54q7.out     error: command 'gcc-4.2' failed with exit status 1     Complete output from command /Users/jacob/code/toplevel/tl_env/bin/python -c \"import setuptools;__file__='/Users/jacob/code/toplevel/tl_env/build/gevent/setup.py';exec(compile(open(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --single-version-externally-managed --record /var/folders/s5/t94kn0p10hdgxzx9_9sprpg40000gq/T/pip-s2hPd3-record/install-record.txt --install-headers /Users/jacob/code/toplevel/tl_env/bin/../include/site/python2.7:     running install  running build  running build_py  running build_ext  building 'gevent.core' extension  gcc-4.2 -fno-strict-aliasing -fno-common -dynamic -isysroot /Developer/SDKs/MacOSX10.6.sdk -arch i386 -arch x86_64 -g -O2 -DNDEBUG -g -O3 -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c gevent/core.c -o build/temp.macosx-10.6-intel-2.7/gevent/core.o      ","Q_Votes":"63"},{"Q_Title":"How to set virtualenv for a crontab?","A_Content":"  If you're using \"workon\" you're actually using \"virtualenv wrapper\" which is another layer of abstraction that sits on top of virtualenv.  virtualenv alone can be activated by cd'ing to your virtualenv root directory and running:  source bin/activate   workon is a command provided by virtualenv wrapper, not virtualenv, and it does some additional stuff that is not necessarily required for plain virtualenv.  All you really need to do is source the bin/activate file in your virtualenv root directory to \"activate\" a virtualenv.  You can setup your crontab to invoke a bash script which does this:  #! /bin/bash     cd my/virtual/env/root/dir source bin/activate  # virtualenv is now active, which means your PATH has been modified. # Don't try to run python from /usr/bin/python, just run \"python\" and # let the PATH figure out which version to run (based on what your # virtualenv has configured).  python myScript.py      ","Language":"Python","Tags":["python","cron","virtualenv","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/4150671/how-to-set-virtualenv-for-a-crontab","A_Votes":"77","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to set up a crontab to run a Python script.  Say the script is something like:  #!/usr/bin/python print \"hello world\"   Is there a way I could specify a virtualenv for that Python script to run in? In shell I'd just do:  ~$ workon myenv   Is there something equivalent I could do in crontab to activate a virtualenv?     ","Q_Votes":"63"},{"Q_Title":"How to set virtualenv for a crontab?","A_Content":"  Another solution that works well for me...  0    9    *    *    *    /path/to/virtenv/bin/python /path/to/cron_script.py   I prefer using python directly from the virtualenv...     ","Language":"Python","Tags":["python","cron","virtualenv","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/4150671/how-to-set-virtualenv-for-a-crontab","A_Votes":"86","_type":"dict","isAccepted":"No","Q_Content":"    I want to set up a crontab to run a Python script.  Say the script is something like:  #!/usr/bin/python print \"hello world\"   Is there a way I could specify a virtualenv for that Python script to run in? In shell I'd just do:  ~$ workon myenv   Is there something equivalent I could do in crontab to activate a virtualenv?     ","Q_Votes":"63"},{"Q_Title":"How to set virtualenv for a crontab?","A_Content":"  With bash, you can create a generic virtual env wrapper that you can use to invoke any command, much like how time can wrapper any command.  virt_env_wrapper.bash:  #!/bin/bash     source path/to/virtual/env/bin/activate \"$@\"   Bash's magical incantation \"$@\" re-escapes all tokens on the original command line so that if you were to invoke:  virt_env_wrapper.bash python foo.py bar 'baz blap'   foo.py would see a sys.argv of ['bar', 'baz blap']     ","Language":"Python","Tags":["python","cron","virtualenv","virtualenvwrapper"],"URL":"https://stackoverflow.com/questions/4150671/how-to-set-virtualenv-for-a-crontab","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I want to set up a crontab to run a Python script.  Say the script is something like:  #!/usr/bin/python print \"hello world\"   Is there a way I could specify a virtualenv for that Python script to run in? In shell I'd just do:  ~$ workon myenv   Is there something equivalent I could do in crontab to activate a virtualenv?     ","Q_Votes":"63"},{"Q_Title":"SQLAlchemy: Creating vs. Reusing a Session","A_Content":"  sessionmaker() is a factory, it's there to encourage placing configuration options for creating new Session objects in just one place.   It is optional, in that you could just as easily call Session(bind=engine, expire_on_commit=False) anytime you needed a new Session, except that its verbose and redundant, and I wanted to stop the proliferation of small-scale \"helpers\" that each approached the issue of this redundancy in some new and more confusing way.  So sessionmaker() is just a tool to help you create Session objects when you need them.  Next part.   I think the question is, what's the difference between making a new Session() at various points versus just using one all the way through.  The answer, not very much.   Session is a container for all the objects you put into it, and then it also keeps track of an open transaction.  At the moment you call rollback() or commit(), the transaction is over, and the Session has no connection to the database until it is called upon to emit SQL again.   The links it holds to your mapped objects are weak referencing, provided the objects are clean of pending changes, so even in that regard the Session will empty itself out back to a brand new state when your application loses all references to mapped objects.  If you leave it with its default \"expire_on_commit\" setting, then all the objects are expired after a commit.  If that Session hangs around for five or twenty minutes, and all kinds of things have changed in the database the next time you use it, it will load all brand new state the next time you access those objects even though they've been sitting in memory for twenty minutes.  In web applications, we usually say, hey why don't you make a brand new Session on each request, rather than using the same one over and over again.  This practice ensures that the new request begins \"clean\".  If some objects from the previous request haven't been garbage collected yet, and if maybe you've turned off \"expire_on_commit\", maybe some state from the previous request is still hanging around, and that state might even be pretty old.   If you're careful to leave expire_on_commit turned on and to definitely call commit() or rollback() at request end, then it's fine, but if you start with a brand new Session, then there's not even any question that you're starting clean.   So the idea to start each request with a new Session is really just the simplest way to make sure you're starting fresh, and to make the usage of expire_on_commit pretty much optional, as this flag can incur a lot of extra SQL for an operation that calls commit() in the middle of a series of operations.   Not sure if this answers your question.  The next round is what you mention about threading.   If your app is multithreaded, we recommend making sure the Session in use is local to...something.   scoped_session() by default makes it local to the current thread.  In a web app, local to the request is in fact even better.   Flask-SQLAlchemy actually sends a custom \"scope function\" to scoped_session() so that you get a request-scoped session.  The average Pyramid application sticks the Session into the \"request\" registry.   When using schemes like these, the \"create new Session on request start\" idea continues to look like the most straightforward way to keep things straight.     ","Language":"Python","Tags":["python","sqlalchemy"],"URL":"https://stackoverflow.com/questions/12223335/sqlalchemy-creating-vs-reusing-a-session","A_Votes":"158","_type":"dict","isAccepted":"Yes","Q_Content":"    Just a quick question: SQLAlchemy talks about calling sessionmaker() once but calling the resulting Session() class each time you need to talk to your DB. For me that means the second I would do my first session.add(x) or something similar, I would first do  from project import Session session = Session()   What I did until now was to make the call session = Session() in my model once and then always import the same session anywhere in my application. Since this is a web-applications this would usually mean the same (as one view is executed).  But where is the difference? What is the disadvantage of using one session all the time against using it for my database stuff until my function is done and then creating a new one the next time I want to talk to my DB?  I get that if I use multiple threads, each one should get their own session. But using scoped_session(), I already make sure that problem doesn't exist, do I?  Please clarify if any of my assumptions are wrong.     ","Q_Votes":"63"},{"Q_Title":"SQLAlchemy: Creating vs. Reusing a Session","A_Content":"  In addition to the excellent zzzeek's answer, here's a simple recipe to quickly create throwaway, self-enclosed sessions:  from contextlib import contextmanager  from sqlalchemy import create_engine from sqlalchemy.orm import scoped_session, sessionmaker  @contextmanager def db_session(db_url):     \"\"\" Creates a context with an open SQLAlchemy session.     \"\"\"     engine = create_engine(db_url, convert_unicode=True)     connection = engine.connect()     db_session = scoped_session(sessionmaker(autocommit=False, autoflush=True, bind=engine))     yield db_session     db_session.close()     connection.close()   Usage:  from mymodels import Foo  with db_session(\"sqlite://\") as db:     foos = db.query(Foo).all()      ","Language":"Python","Tags":["python","sqlalchemy"],"URL":"https://stackoverflow.com/questions/12223335/sqlalchemy-creating-vs-reusing-a-session","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    Just a quick question: SQLAlchemy talks about calling sessionmaker() once but calling the resulting Session() class each time you need to talk to your DB. For me that means the second I would do my first session.add(x) or something similar, I would first do  from project import Session session = Session()   What I did until now was to make the call session = Session() in my model once and then always import the same session anywhere in my application. Since this is a web-applications this would usually mean the same (as one view is executed).  But where is the difference? What is the disadvantage of using one session all the time against using it for my database stuff until my function is done and then creating a new one the next time I want to talk to my DB?  I get that if I use multiple threads, each one should get their own session. But using scoped_session(), I already make sure that problem doesn't exist, do I?  Please clarify if any of my assumptions are wrong.     ","Q_Votes":"63"},{"Q_Title":"SQLAlchemy: Creating vs. Reusing a Session","A_Content":"  You can create the session using the db  db = SQLAlchemy(app) engine = db.engine Session = sessionmaker(engine) session = Session()      ","Language":"Python","Tags":["python","sqlalchemy"],"URL":"https://stackoverflow.com/questions/12223335/sqlalchemy-creating-vs-reusing-a-session","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Just a quick question: SQLAlchemy talks about calling sessionmaker() once but calling the resulting Session() class each time you need to talk to your DB. For me that means the second I would do my first session.add(x) or something similar, I would first do  from project import Session session = Session()   What I did until now was to make the call session = Session() in my model once and then always import the same session anywhere in my application. Since this is a web-applications this would usually mean the same (as one view is executed).  But where is the difference? What is the disadvantage of using one session all the time against using it for my database stuff until my function is done and then creating a new one the next time I want to talk to my DB?  I get that if I use multiple threads, each one should get their own session. But using scoped_session(), I already make sure that problem doesn't exist, do I?  Please clarify if any of my assumptions are wrong.     ","Q_Votes":"63"},{"Q_Title":"How to hide *pyc files in atom editor","A_Content":"  The method for hiding files that you do not want showing up in the Tree View (which is what most people mean when they ask this question) depends on whether or not you've added the files to your .gitignore. If you have, then all you have to do is:   Open Settings Scroll down the list on the left to find the Tree View package Click on it to bring up the package-specific settings Ensure Hide Vcs Ignored Files is checked   If you want to hide certain files in the Tree View whether you have a Git project open or not:   Open Settings Add the file mask to the comma-separated list under Ignored Names (add *.pyc in your case) Scroll down the list on the left to find the Tree View package Click on it to bring up the package-specific settings Ensure Hide Ignored Names is checked   Also note that when you add a file mask to the list of Ignored Names that files matching that mask will not show up in other parts of Atom like the fuzzy-finder:find-file (Cmd+T on OS X and Ctrl+T on Windows/Linux by default) command.     ","Language":"Python","Tags":["python","atom-editor"],"URL":"https://stackoverflow.com/questions/24079976/how-to-hide-pyc-files-in-atom-editor","A_Votes":"154","_type":"dict","isAccepted":"Yes","Q_Content":"    Started using https://atom.io/ fro Python/Django development and would like to hide all the *.pyc files from sidebar.   How to configure it?     ","Q_Votes":"63"},{"Q_Title":"How to hide *pyc files in atom editor","A_Content":"  I found this where it is said that you can toggle that in Preferences->Tree View->Hide Ignored Names and Hide Vcs Ignored Files.  Edit: The files to hide you have to specify first in Preferences->Settings->Core Settings->Ignored Names. This was described here.  Let me know if it works.     ","Language":"Python","Tags":["python","atom-editor"],"URL":"https://stackoverflow.com/questions/24079976/how-to-hide-pyc-files-in-atom-editor","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    Started using https://atom.io/ fro Python/Django development and would like to hide all the *.pyc files from sidebar.   How to configure it?     ","Q_Votes":"63"},{"Q_Title":"How to hide *pyc files in atom editor","A_Content":"  In Atom 1.25.0 on Ubuntu I found this settings (Hide Vcs Ignored Files). Under packages configuration: Preferences -> Packages -> Tree View -> Settings.  Also, pressing 'I' while Tree View activated also works for me (@Suraj Thapar's comment).  Please note, you have 2 options here: Ignore file by .gitignore and ignore files by Hide Ignored Names which refers to Ignored Names core config settings.     ","Language":"Python","Tags":["python","atom-editor"],"URL":"https://stackoverflow.com/questions/24079976/how-to-hide-pyc-files-in-atom-editor","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Started using https://atom.io/ fro Python/Django development and would like to hide all the *.pyc files from sidebar.   How to configure it?     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  Here is a cleaned up version I finally produced that worked for me. The following just simply returns the string in a PDF, given its filename. I hope this saves someone time.  from pdfminer.pdfinterp import PDFResourceManager, process_pdf from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from cStringIO import StringIO  def convert_pdf(path):      rsrcmgr = PDFResourceManager()     retstr = StringIO()     codec = 'utf-8'     laparams = LAParams()     device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)      fp = file(path, 'rb')     process_pdf(rsrcmgr, device, fp)     fp.close()     device.close()      str = retstr.getvalue()     retstr.close()     return str   This solution was valid until API changes in November 2013.     ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"65","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  Here is a new solution that works with the latest version:  from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from pdfminer.pdfpage import PDFPage from cStringIO import StringIO  def convert_pdf_to_txt(path):     rsrcmgr = PDFResourceManager()     retstr = StringIO()     codec = 'utf-8'     laparams = LAParams()     device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)     fp = file(path, 'rb')     interpreter = PDFPageInterpreter(rsrcmgr, device)     password = \"\"     maxpages = 0     caching = True     pagenos=set()     for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):         interpreter.process_page(page)     fp.close()     device.close()     str = retstr.getvalue()     retstr.close()     return str      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"69","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  I know it is poor taste to answer your own question, but I think I may have figured this out and I don't want anyone else to waste their time looking for a solution to my problem.  I followed the suggestion in a one of the links posted in my question and re-purposed the current pdf2txt.py script included with pdfminer. Here is the function in case it is useful to anyone else.  Thanks to the user skyl for posting that answer, all I had to to was make a couple of changes to make it work with the current version of pdfminer.    This function take a pdf and creates a .txt file in the same directory with the same name.  def convert_pdf(path, outtype='txt', opts={}): import sys from pdfminer.pdfparser import PDFDocument, PDFParser from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter, process_pdf from pdfminer.pdfdevice import PDFDevice, TagExtractor from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter from pdfminer.cmapdb import CMapDB from pdfminer.layout import LAParams import getopt  outfile = path[:-3] + outtype outdir = '/'.join(path.split('/')[:-1])  # debug option debug = 0 # input option password = '' pagenos = set() maxpages = 0 # output option # ?outfile = None # ?outtype = None outdir = None #layoutmode = 'normal' codec = 'utf-8' pageno = 1 scale = 1 showpageno = True laparams = LAParams() for (k, v) in opts:     if k == '-d': debug += 1     elif k == '-p': pagenos.update( int(x)-1 for x in v.split(',') )     elif k == '-m': maxpages = int(v)     elif k == '-P': password = v     elif k == '-o': outfile = v     elif k == '-n': laparams = None     elif k == '-A': laparams.all_texts = True     elif k == '-V': laparams.detect_vertical = True     elif k == '-M': laparams.char_margin = float(v)     elif k == '-L': laparams.line_margin = float(v)     elif k == '-W': laparams.word_margin = float(v)     elif k == '-F': laparams.boxes_flow = float(v)     elif k == '-Y': layoutmode = v     elif k == '-O': outdir = v     elif k == '-t': outtype = v     elif k == '-c': codec = v     elif k == '-s': scale = float(v) # #PDFDocument.debug = debug #PDFParser.debug = debug CMapDB.debug = debug PDFResourceManager.debug = debug PDFPageInterpreter.debug = debug PDFDevice.debug = debug # rsrcmgr = PDFResourceManager()  outtype = 'text'  if outfile:     outfp = file(outfile, 'w') else:     outfp = sys.stdout device = TextConverter(rsrcmgr, outfp, codec=codec, laparams=laparams)   fp = file(path, 'rb') process_pdf(rsrcmgr, device, fp, pagenos, maxpages=maxpages, password=password,                 check_extractable=True) fp.close() device.close() outfp.close() return      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  This worked for me using the most recent version of pdfminer (as of September 2014):  from pdfminer.pdfparser import PDFParser from pdfminer.pdfdocument import PDFDocument from pdfminer.pdfpage import PDFPage from pdfminer.pdfpage import PDFTextExtractionNotAllowed from pdfminer.pdfinterp import PDFResourceManager from pdfminer.pdfinterp import PDFPageInterpreter from pdfminer.pdfdevice import PDFDevice from pdfminer.converter import TextConverter from pdfminer.layout import LAParams import unicodedata, codecs from cStringIO import StringIO  def getPDFText(pdfFilenamePath):     retstr = StringIO()     parser = PDFParser(open(pdfFilenamePath,'r'))     try:         document = PDFDocument(parser)     except Exception as e:         print(pdfFilenamePath,'is not a readable pdf')         return ''     if document.is_extractable:         rsrcmgr = PDFResourceManager()         device = TextConverter(rsrcmgr,retstr, codec='ascii' , laparams = LAParams())         interpreter = PDFPageInterpreter(rsrcmgr, device)         for page in PDFPage.create_pages(document):             interpreter.process_page(page)         return retstr.getvalue()     else:         print(pdfFilenamePath,\"Warning: could not extract text from pdf file.\")         return ''  if __name__ == '__main__':     words = getPDFText(path)      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  If you are working with scraped data via urllib2, try this (which is developed and explained here):  def pdf_to_text(scraped_pdf_data):      from pdfminer.pdfinterp import PDFResourceManager, process_pdf      from pdfminer.pdfdevice import PDFDevice      from pdfminer.converter import TextConverter      from pdfminer.layout import LAParams       import StringIO      fp = StringIO.StringIO()      fp.write(scraped_pdf_data)      fp.seek(0)      outfp = StringIO.StringIO()       rsrcmgr = PDFResourceManager()      device = TextConverter(rsrcmgr, outfp, laparams=LAParams())      process_pdf(rsrcmgr, device, fp)      device.close()       t = outfp.getvalue()      outfp.close()      fp.close()      return t   Like the other answers, the code here adapts the pdf2txt utility that PDFMiner itself provides. You can thus also convert to html or xml -- just sub HTMLConverter or XMLConverter for TextConverter everywhere above.      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  The following modification of the non-process_pdf answers pulls the text straight from a URL string name and works with version 20140328 and Python 2.7:  from urllib2 import urlopen from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from pdfminer.pdfpage import PDFPage from cStringIO import StringIO def convert_pdf_to_txt(url):     rsrcmgr = PDFResourceManager()     retstr = StringIO()     codec = 'utf-8'     laparams = LAParams()     device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)      scrape = urlopen(url).read()     fp = StringIO(scrape)      interpreter = PDFPageInterpreter(rsrcmgr, device)     password = \"\"     maxpages = 0     caching = True     pagenos=set()     for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):         interpreter.process_page(page)      fp.close()     device.close()     textstr = retstr.getvalue()     retstr.close()     return textstr      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  The following code works for me with latest version of PDFMiner it takes path of pdf and return text in .txt format.  P.S: This is a modification of above answer.  from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from pdfminer.pdfpage import PDFPage from cStringIO import StringIO  def convert_pdf_to_txt(path, outtype='txt'):     outfile = path[:-3] + outtype     rsrcmgr = PDFResourceManager()     codec = 'utf-8'     laparams = LAParams()     if outfile:         outfp = file(outfile, 'w')     else:         outfp = sys.stdout     device = TextConverter(rsrcmgr, outfp, codec=codec, laparams=laparams)     fp = file(path, 'rb')     interpreter = PDFPageInterpreter(rsrcmgr, device)     password = \"\"     maxpages = 0     caching = True     pagenos=set()     for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):         interpreter.process_page(page)     fp.close()     device.close()     outfp.close()     return      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  Here's my solution  from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from pdfminer.pdfpage import PDFPage from io import StringIO import os   def convert_pdf_to_txt(path, pages=None):     if not pages:         pagenums = set()     else:         pagenums = set(pages)     output = StringIO()     manager = PDFResourceManager()     converter = TextConverter(manager, output, laparams=LAParams())     interpreter = PDFPageInterpreter(manager, converter)      infile = open(path, 'rb')     for page in PDFPage.get_pages(infile, pagenums):         interpreter.process_page(page)     infile.close()     converter.close()     text = output.getvalue()     output.close()     return text   For example you just want to read the first 3 pages of a pdf file:  text = convert('../Data/EN-FINAL Table 9.pdf', pages=[0,1,2])   pdfminer.six==20160614  python: 3.x     ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  Here is a cleaned up version I finally produced that worked for me. The following just simply returns the string in a PDF, given its filename. I hope this saves someone time.  from pdfminer.pdfinterp import PDFResourceManager, process_pdf from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from cStringIO import StringIO  def convert_pdf(path):      rsrcmgr = PDFResourceManager()     retstr = StringIO()     codec = 'utf-8'     laparams = LAParams()     device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)      fp = file(path, 'rb')     process_pdf(rsrcmgr, device, fp)     fp.close()     device.close()      str = retstr.getvalue()     retstr.close()     return str   can anybody say me : is there any specific place where the pdf file  is to be placed??     ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  just in case anyone still needs this, got it working with requests and python 3.4. thanks to @bahmait for his answer above :)  import requests  from io import StringIO from pdfminer.pdfinterp import PDFResourceManager, process_pdf from pdfminer.converter import TextConverter from pdfminer.layout import LAParams   def pdf_to_text(url=None):     text = None     pdf = requests.get(url)      if pdf.ok:         fp = StringIO(str(pdf.content, 'utf-8'))         outfp = StringIO()          rsrcmgr = PDFResourceManager()         device = TextConverter(rsrcmgr, outfp, laparams=LAParams())         process_pdf(rsrcmgr, device, fp)         device.close()          text = outfp.getvalue()         outfp.close()         fp.close()     return text   if __name__ == \"__main__\":     hello_world_text = pdf_to_text(\"https://bytebucket.org/hsoft/pdfminer3k/raw/28edfc91caed830674ca0b928f42571f7dee6091/samples/simple1.pdf\")     no_pdf = pdf_to_text('http://www.google.com/404')     print(hello_world_text)     print(no_pdf)      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  Thanks user3577380  I get pdfminer.six https://github.com/goulu/pdfminer  I changed a bit for python3.5 to parse local Chinese PDF successfully, but how can I parse online PDF with Requests? For example: http://pythonscraping.com/pages/warandpeace/chapter1.pdf  from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from pdfminer.pdfpage import PDFPage from pdfminer.pdfparser import PDFParser from pdfminer.pdfdocument import PDFDocument from io import StringIO import sys, io  sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding='gb18030')   def convert_pdf_to_txt(path):     rsrcmgr = PDFResourceManager()     retstr = StringIO()     codec = 'utf-8'     laparams = LAParams()     device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)      fp = open(path, 'rb')      interpreter = PDFPageInterpreter(rsrcmgr, device)     password = \"\"     maxpages = 0     caching = True     pagenos=set()      for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,          password=password,caching=caching, check_extractable=True):         interpreter.process_page(page)      text = retstr.getvalue()      fp.close()     device.close()     retstr.close()     print(text.encode('gb18030', 'ignore').decode('gb18030', 'ignore'))     return text  path_of_the_pdf_file = r'E:\\迅雷下载\\过表达Smad7基因对瘢痕疙瘩成纤维细胞的影响.pdf'  convert_pdf_to_txt(path_of_the_pdf_file)      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  Here's an answer that works with pdfminer.six running python 3.6. It uses the pdfminer.high_level module that abstracts away a lot of the underlying detail if you just want to get out the raw text from a simple PDF file.  import pdfminer import io  def extract_raw_text(pdf_filename):     output = io.StringIO()     laparams = pdfminer.layout.LAParams() # Using the defaults seems to work fine      with open(pdf_filename, \"rb\") as pdffile:         pdfminer.high_level.extract_text_to_fp(pdffile, output, laparams=laparams)      return output.getvalue()      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  Only if someone still needs it: How to print the HTML from a PDF using PDFMiner:  import sys import getopt from Core.Interfaces.IReader import IReader from pdfminer.pdfparser import PDFDocument, PDFParser from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter, process_pdf from pdfminer.pdfdevice import PDFDevice, TagExtractor from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter from pdfminer.cmapdb import CMapDB from pdfminer.layout import LAParams from cStringIO import StringIO  class PdfReader(object): def __init__(self):     pass  def readText(self,path, outtype='text', opts={}):     outfile = path[:-3] + outtype     outdir = '/'.join(path.split('/')[:-1])     # debug option     debug = 0     # input option     password = ''     pagenos = set()     maxpages = 0     # output option     # ?outfile = None     # ?outtype = None     outdir = None     #layoutmode = 'normal'     codec = 'utf-8'     pageno = 1     scale = 1     showpageno = True     laparams = LAParams()     for (k, v) in opts:         if k == '-d': debug += 1         elif k == '-p': pagenos.update( int(x)-1 for x in v.split(',') )         elif k == '-m': maxpages = int(v)         elif k == '-P': password = v         elif k == '-o': outfile = v         elif k == '-n': laparams = None         elif k == '-A': laparams.all_texts = True         elif k == '-V': laparams.detect_vertical = True         elif k == '-M': laparams.char_margin = float(v)         elif k == '-L': laparams.line_margin = float(v)         elif k == '-W': laparams.word_margin = float(v)         elif k == '-F': laparams.boxes_flow = float(v)         elif k == '-Y': layoutmode = v         elif k == '-O': outdir = v         elif k == '-t': outtype = v         elif k == '-c': codec = v         elif k == '-s': scale = float(v)      print laparams     #     #PDFDocument.debug = debug     #PDFParser.debug = debug     CMapDB.debug = debug     PDFResourceManager.debug = debug     PDFPageInterpreter.debug = debug     PDFDevice.debug = debug     #     rsrcmgr = PDFResourceManager()      #outtype = 'text'      outfp = StringIO()      device = HTMLConverter(rsrcmgr, outfp, codec=codec, laparams=laparams)       fp = file(path, 'rb')     process_pdf(rsrcmgr, device, fp, pagenos, maxpages=maxpages, password=password,                     check_extractable=True)     fp.close()     device.close()     print outfp.getvalue()     outfp.close()      return    reader = PdfReader() opt = map(None,['-W','-L','-t'],[0.5,0.4,'html']) reader.readText(\"/test_data/test.pdf\",\"html\",opt)      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"How do I use pdfminer as a library","A_Content":"  The following code snippets is able to extract plain text from pdf documents using the latest version of pdfminer(as of 23-Mar-2016). Hope this helps.  from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from pdfminer.pdfpage import PDFPage from cStringIO import StringIO  def convert_pdf_to_txt(path):     rsrcmgr = PDFResourceManager()     retstr = StringIO()     codec = 'utf-8'     laparams = LAParams()     device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)      fp = file(path, 'rb')      parser = PDFParser(fp)     doc = PDFDocument(parser)     parser.set_document(doc)      interpreter = PDFPageInterpreter(rsrcmgr, device)     password = \"\"     maxpages = 0     caching = True     pagenos=set()      for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,        password=password,caching=caching, check_extractable=True):         interpreter.process_page(page)      text = retstr.getvalue()      fp.close()     device.close()     retstr.close()     print text     return text  convert_pdf_to_txt(<path_of_the_pdf_file>)      ","Language":"Python","Tags":["python","pdf","pdfminer"],"URL":"https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to get text data from a pdf using pdfminer.  I am able to extract this data to a .txt file successfully with the pdfminer command line tool pdf2txt.py.  I currently do this and then use a python script to clean up the .txt file.  I would like to incorporate the pdf extract process into the script and save myself a step.    I thought I was on to something when I found this link, but I didn't have success with any of the solutions.  Perhaps the function listed there needs to be updated again because I am using a newer version of pdfminer.    I also tried the function shown here, but it also did not work.    Another approach I tried was to call the script within a script using os.system.  This was also unsuccessful.  I am using Python version 2.7.1 and pdfminer version 20110227.     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  In case of windows, in cmd try to run pip install using python executable   e.g.  python -m pip install mitmproxy   this should work, at least it worked for me for other package installation.     ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"89","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  Change your Python installation folder's security permissions by:   Open a Python shell Go to task manager Find the python process Right-click and open location The folder will open in explorer, go up a directory Right-click the folder and select properties Click the security tab and hit 'edit' Add everyone and give them permission to Read and Write. Save your changes   If you open cmd as admin; then you can do the following:  If Python is set in your PATH, then:  python -m pip install mitmproxy      ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"45","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  Personally, I found that by opening cmd as admin then run  python -m pip install mitproxy  seems to fix my problem.   Note:- I installed python through chocolatey      ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  One additional thing that has not been covered in previous answers and that often cause issues on Windows and stopped me from installing some package despite running as admin is that you get the same permission denied error if there is another program that use some of the files you (or pip install) try to access. This is a really stupid \"feature\" of Windows that pops up many times, e.g. when trying to move some files.  In addition I have no clue how to figure out which program locks a particular file, so the easiest ting to do is to reboot and do the installation before starting anything, in particular before running e.g. Spyder or any other Python-based software. You can also try to close all programs, but it can be tricky to know which one actually holds a file. For a directory for example, it is enough that you have an Explorer window open at that directory.     ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  Open cmd with \"Run as administrator\" and execute the command pip install mitmproxy. It will install it.     ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  Try to delete the folder c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u manually and then retry the pip command.      ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  Opening command prompt As Administrator just worked for me without using Python executable. Right click on command prompt shortcut and choose \"Run as Administrator\". Then run the following command.  pip install Django      ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  The cause in my case was having a jupyter notebook open, which was importing the relevant library; the root cause seems to be windows error due to the file being open / in use (see also @Robert's answer, and the recommendation to reboot).  So another thing to verify is that no other python processes are running.  For me, shutting down the notebook server solved the issue.     ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  When all else fails, try quitting your IDE. I had many cases in which PyCharm was causing this. As soon as I quit PyCharm, I was able to finally install my packages from the command line. Alternatively, you can also install through PyCharm itself in Settings -> Project: xxx -> Project Interpreter -> +.     ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  I met a similar problem.But the error report is about   [SSL: TLSV1_ALERT_ACCESS_DENIED] tlsv1 alert access denied (_ssl.c:777)   First I tried this https://python-forum.io/Thread-All-pip-install-attempts-are-met-with-SSL-error#pid_28035 ,but seems it couldn't solve my problems,and still repeat the same issue.  And Second if you are working on a business computer,generally it may exist a web content filter(but I can access  https://pypi.python.org through browser directly).And solve this issue by adding a proxy server.  For windows,open the Internet properties through IE or Chrome or whatsoever ,then set valid proxy address and port,and this way solve my problems  Or just adding the option pip --proxy [proxy-address]:port install mitmproxy.But you always need to add this option while installing by pypi   The above two solution is alternative for you demand.     ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  Try to give permission to full control the python folder.  Find the python root directory-->right button click-->properties-->security-->edit-->give users Full Control-->yes and wait the process finished.  It works for me.     ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  Just close all the python files opened. And try to run as administrator. It will work.  e.g.  pip install numpy      ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"pip install access denied on Windows","A_Content":"  Run cmd.exe as an administrator then type:  python -m pip install      ","Language":"Python","Tags":["python","windows","pip","access-denied"],"URL":"https://stackoverflow.com/questions/31172719/pip-install-access-denied-on-windows","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to run pip install mitmproxy on Windows, but I keep getting access denied, even with cmd and PowerShell using the Run as Administrator option.  WindowsError: [Error 5] Access is denied: 'c:\\\\users\\\\bruno\\\\appdata\\\\local\\\\temp\\\\easy_install-0fme6u\\\\cryptography-0.9.1\\\\.eggs\\\\cffi-1.1.2-py2.7-win-amd64.egg\\\\_cffi_backend.pyd'   How can I make this work?     ","Q_Votes":"63"},{"Q_Title":"Iterating through a JSON object","A_Content":"  Your loading of the JSON data is a little fragile. Instead of:  json_raw= raw.readlines() json_object = json.loads(json_raw[0])   you should really just do:  json_object = json.load(raw)   You shouldn't think of what you get as a \"JSON object\". What you have is a list. The list contains two dicts. The dicts contain various key/value pairs, all strings. When you do json_object[0], you're asking for the first dict in the list. When you iterate over that, with for song in json_object[0]:, you iterate over the keys of the dict. Because that's what you get when you iterate over the dict. If you want to access the value associated with the key in that dict, you would use, for example, json_object[0][song].  None of this is specific to JSON. It's just basic Python types, with their basic operations as covered in any tutorial.     ","Language":"Python","Tags":["python","dictionary","loops"],"URL":"https://stackoverflow.com/questions/2733813/iterating-through-a-json-object","A_Votes":"59","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to iterate through a JSON object to import data, i.e. title and link. I can't seem to get to the content that is past the :.   JSON:   [     {         \"title\": \"Baby (Feat. Ludacris) - Justin Bieber\",         \"description\": \"Baby (Feat. Ludacris) by Justin Bieber on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Baby+Feat+Ludacris+/2Bqvdq\",         \"pubDate\": \"Wed, 28 Apr 2010 02:37:53 -0400\",         \"pubTime\": 1272436673,         \"TinyLink\": \"http://tinysong.com/d3wI\",         \"SongID\": \"24447862\",         \"SongName\": \"Baby (Feat. Ludacris)\",         \"ArtistID\": \"1118876\",         \"ArtistName\": \"Justin Bieber\",         \"AlbumID\": \"4104002\",         \"AlbumName\": \"My World (Part II);\\nhttp://tinysong.com/gQsw\",         \"LongLink\": \"11578982\",         \"GroovesharkLink\": \"11578982\",         \"Link\": \"http://tinysong.com/d3wI\"     },     {         \"title\": \"Feel Good Inc - Gorillaz\",         \"description\": \"Feel Good Inc by Gorillaz on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Feel+Good+Inc/1UksmI\",         \"pubDate\": \"Wed, 28 Apr 2010 02:25:30 -0400\",         \"pubTime\": 1272435930     } ]   I tried using a dictionary:  def getLastSong(user,limit):     base_url = 'http://gsuser.com/lastSong/'     user_url = base_url + str(user) + '/' + str(limit) + \"/\"     raw = urllib.urlopen(user_url)     json_raw= raw.readlines()     json_object = json.loads(json_raw[0])      #filtering and making it look good.     gsongs = []     print json_object     for song in json_object[0]:            print song   This code only prints the information before :. (ignore the Justin Bieber track :))     ","Q_Votes":"63"},{"Q_Title":"Iterating through a JSON object","A_Content":"  I believe you probably meant:  for song in json_object:     # now song is a dictionary     for attribute, value in song.iteritems():         print attribute, value # example usage   NB: use song.items instead of song.iteritems for Python 3.     ","Language":"Python","Tags":["python","dictionary","loops"],"URL":"https://stackoverflow.com/questions/2733813/iterating-through-a-json-object","A_Votes":"58","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to iterate through a JSON object to import data, i.e. title and link. I can't seem to get to the content that is past the :.   JSON:   [     {         \"title\": \"Baby (Feat. Ludacris) - Justin Bieber\",         \"description\": \"Baby (Feat. Ludacris) by Justin Bieber on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Baby+Feat+Ludacris+/2Bqvdq\",         \"pubDate\": \"Wed, 28 Apr 2010 02:37:53 -0400\",         \"pubTime\": 1272436673,         \"TinyLink\": \"http://tinysong.com/d3wI\",         \"SongID\": \"24447862\",         \"SongName\": \"Baby (Feat. Ludacris)\",         \"ArtistID\": \"1118876\",         \"ArtistName\": \"Justin Bieber\",         \"AlbumID\": \"4104002\",         \"AlbumName\": \"My World (Part II);\\nhttp://tinysong.com/gQsw\",         \"LongLink\": \"11578982\",         \"GroovesharkLink\": \"11578982\",         \"Link\": \"http://tinysong.com/d3wI\"     },     {         \"title\": \"Feel Good Inc - Gorillaz\",         \"description\": \"Feel Good Inc by Gorillaz on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Feel+Good+Inc/1UksmI\",         \"pubDate\": \"Wed, 28 Apr 2010 02:25:30 -0400\",         \"pubTime\": 1272435930     } ]   I tried using a dictionary:  def getLastSong(user,limit):     base_url = 'http://gsuser.com/lastSong/'     user_url = base_url + str(user) + '/' + str(limit) + \"/\"     raw = urllib.urlopen(user_url)     json_raw= raw.readlines()     json_object = json.loads(json_raw[0])      #filtering and making it look good.     gsongs = []     print json_object     for song in json_object[0]:            print song   This code only prints the information before :. (ignore the Justin Bieber track :))     ","Q_Votes":"63"},{"Q_Title":"Iterating through a JSON object","A_Content":"  This question has been out here a long time, but I wanted to contribute how I usually iterate through a JSON object.  In the example below, I've shown a hard-coded string that contains the JSON, but the JSON string could just as easily have come from a web service or a file.  import json  def main():      # create a simple JSON array     jsonString = '{\"key1\":\"value1\",\"key2\":\"value2\",\"key3\":\"value3\"}'      # change the JSON string into a JSON object     jsonObject = json.loads(jsonString)      # print the keys and values     for key in jsonObject:         value = jsonObject[key]         print(\"The key and value are ({}) = ({})\".format(key, value))      pass  if __name__ == '__main__':     main()      ","Language":"Python","Tags":["python","dictionary","loops"],"URL":"https://stackoverflow.com/questions/2733813/iterating-through-a-json-object","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to iterate through a JSON object to import data, i.e. title and link. I can't seem to get to the content that is past the :.   JSON:   [     {         \"title\": \"Baby (Feat. Ludacris) - Justin Bieber\",         \"description\": \"Baby (Feat. Ludacris) by Justin Bieber on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Baby+Feat+Ludacris+/2Bqvdq\",         \"pubDate\": \"Wed, 28 Apr 2010 02:37:53 -0400\",         \"pubTime\": 1272436673,         \"TinyLink\": \"http://tinysong.com/d3wI\",         \"SongID\": \"24447862\",         \"SongName\": \"Baby (Feat. Ludacris)\",         \"ArtistID\": \"1118876\",         \"ArtistName\": \"Justin Bieber\",         \"AlbumID\": \"4104002\",         \"AlbumName\": \"My World (Part II);\\nhttp://tinysong.com/gQsw\",         \"LongLink\": \"11578982\",         \"GroovesharkLink\": \"11578982\",         \"Link\": \"http://tinysong.com/d3wI\"     },     {         \"title\": \"Feel Good Inc - Gorillaz\",         \"description\": \"Feel Good Inc by Gorillaz on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Feel+Good+Inc/1UksmI\",         \"pubDate\": \"Wed, 28 Apr 2010 02:25:30 -0400\",         \"pubTime\": 1272435930     } ]   I tried using a dictionary:  def getLastSong(user,limit):     base_url = 'http://gsuser.com/lastSong/'     user_url = base_url + str(user) + '/' + str(limit) + \"/\"     raw = urllib.urlopen(user_url)     json_raw= raw.readlines()     json_object = json.loads(json_raw[0])      #filtering and making it look good.     gsongs = []     print json_object     for song in json_object[0]:            print song   This code only prints the information before :. (ignore the Justin Bieber track :))     ","Q_Votes":"63"},{"Q_Title":"Iterating through a JSON object","A_Content":"  After deserializing the JSON, you have a python object. Use the regular object methods.  In this case you have a list made of dictionaries:  json_object[0].items()  json_object[0][\"title\"]   etc.     ","Language":"Python","Tags":["python","dictionary","loops"],"URL":"https://stackoverflow.com/questions/2733813/iterating-through-a-json-object","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to iterate through a JSON object to import data, i.e. title and link. I can't seem to get to the content that is past the :.   JSON:   [     {         \"title\": \"Baby (Feat. Ludacris) - Justin Bieber\",         \"description\": \"Baby (Feat. Ludacris) by Justin Bieber on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Baby+Feat+Ludacris+/2Bqvdq\",         \"pubDate\": \"Wed, 28 Apr 2010 02:37:53 -0400\",         \"pubTime\": 1272436673,         \"TinyLink\": \"http://tinysong.com/d3wI\",         \"SongID\": \"24447862\",         \"SongName\": \"Baby (Feat. Ludacris)\",         \"ArtistID\": \"1118876\",         \"ArtistName\": \"Justin Bieber\",         \"AlbumID\": \"4104002\",         \"AlbumName\": \"My World (Part II);\\nhttp://tinysong.com/gQsw\",         \"LongLink\": \"11578982\",         \"GroovesharkLink\": \"11578982\",         \"Link\": \"http://tinysong.com/d3wI\"     },     {         \"title\": \"Feel Good Inc - Gorillaz\",         \"description\": \"Feel Good Inc by Gorillaz on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Feel+Good+Inc/1UksmI\",         \"pubDate\": \"Wed, 28 Apr 2010 02:25:30 -0400\",         \"pubTime\": 1272435930     } ]   I tried using a dictionary:  def getLastSong(user,limit):     base_url = 'http://gsuser.com/lastSong/'     user_url = base_url + str(user) + '/' + str(limit) + \"/\"     raw = urllib.urlopen(user_url)     json_raw= raw.readlines()     json_object = json.loads(json_raw[0])      #filtering and making it look good.     gsongs = []     print json_object     for song in json_object[0]:            print song   This code only prints the information before :. (ignore the Justin Bieber track :))     ","Q_Votes":"63"},{"Q_Title":"Iterating through a JSON object","A_Content":"  I would solve this problem more like this  import json import urllib2  def last_song(user, limit):     # Assembling strings with \"foo\" + str(bar) + \"baz\" + ... generally isn't      # as nice as using real string formatting. It can seem simpler at first,      # but leaves you less happy in the long run.     url = 'http://gsuser.com/lastSong/%s/%d/' % (user, limit)      # urllib.urlopen is deprecated in favour of urllib2.urlopen     site = urllib2.urlopen(url)      # The json module has a function load for loading from file-like objects,      # like the one you get from `urllib2.urlopen`. You don't need to turn      # your data into a string and use loads and you definitely don't need to      # use readlines or readline (there is seldom if ever reason to use a      # file-like object's readline(s) methods.)     songs = json.load(site)      # I don't know why \"lastSong\" stuff returns something like this, but      # your json thing was a JSON array of two JSON objects. This will      # deserialise as a list of two dicts, with each item representing      # each of those two songs.     #     # Since each of the songs is represented by a dict, it will iterate      # over its keys (like any other Python dict).      baby, feel_good = songs      # Rather than printing in a function, it's usually better to      # return the string then let the caller do whatever with it.      # You said you wanted to make the output pretty but you didn't      # mention *how*, so here's an example of a prettyish representation     # from the song information given.     return \"%(SongName)s by %(ArtistName)s - listen at %(link)s\" % baby      ","Language":"Python","Tags":["python","dictionary","loops"],"URL":"https://stackoverflow.com/questions/2733813/iterating-through-a-json-object","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to iterate through a JSON object to import data, i.e. title and link. I can't seem to get to the content that is past the :.   JSON:   [     {         \"title\": \"Baby (Feat. Ludacris) - Justin Bieber\",         \"description\": \"Baby (Feat. Ludacris) by Justin Bieber on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Baby+Feat+Ludacris+/2Bqvdq\",         \"pubDate\": \"Wed, 28 Apr 2010 02:37:53 -0400\",         \"pubTime\": 1272436673,         \"TinyLink\": \"http://tinysong.com/d3wI\",         \"SongID\": \"24447862\",         \"SongName\": \"Baby (Feat. Ludacris)\",         \"ArtistID\": \"1118876\",         \"ArtistName\": \"Justin Bieber\",         \"AlbumID\": \"4104002\",         \"AlbumName\": \"My World (Part II);\\nhttp://tinysong.com/gQsw\",         \"LongLink\": \"11578982\",         \"GroovesharkLink\": \"11578982\",         \"Link\": \"http://tinysong.com/d3wI\"     },     {         \"title\": \"Feel Good Inc - Gorillaz\",         \"description\": \"Feel Good Inc by Gorillaz on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Feel+Good+Inc/1UksmI\",         \"pubDate\": \"Wed, 28 Apr 2010 02:25:30 -0400\",         \"pubTime\": 1272435930     } ]   I tried using a dictionary:  def getLastSong(user,limit):     base_url = 'http://gsuser.com/lastSong/'     user_url = base_url + str(user) + '/' + str(limit) + \"/\"     raw = urllib.urlopen(user_url)     json_raw= raw.readlines()     json_object = json.loads(json_raw[0])      #filtering and making it look good.     gsongs = []     print json_object     for song in json_object[0]:            print song   This code only prints the information before :. (ignore the Justin Bieber track :))     ","Q_Votes":"63"},{"Q_Title":"Iterating through a JSON object","A_Content":"  For Python 3, you have to decode the data you get back from the web server. For instance I decode the data as utf8 then deal with it:   # example of json data object group with two values of key id jsonstufftest = '{'group':{'id':'2','id':'3'}}  # always set your headers headers = {'User-Agent': 'Moz & Woz'}  # the url you are trying to load and get json from url = 'http://www.cooljson.com/cooljson.json'  # in python 3 you can build the request using request.Request req = urllib.request.Request(url,None,headers)  # try to connect or fail gracefully try:     response = urllib.request.urlopen(req) # new python 3 code -jc except:     exit('could not load page, check connection')  # read the response and DECODE html=response.read().decode('utf8') # new python3 code  # now convert the decoded string into real JSON loadedjson = json.loads(html)  # print to make sure it worked print (loadedjson) # works like a charm  # iterate through each key value for testdata in loadedjson['group']:     print (accesscount['id']) # should print 2 then 3 if using test json   If you don't decode you will get bytes vs string errors in Python 3.     ","Language":"Python","Tags":["python","dictionary","loops"],"URL":"https://stackoverflow.com/questions/2733813/iterating-through-a-json-object","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to iterate through a JSON object to import data, i.e. title and link. I can't seem to get to the content that is past the :.   JSON:   [     {         \"title\": \"Baby (Feat. Ludacris) - Justin Bieber\",         \"description\": \"Baby (Feat. Ludacris) by Justin Bieber on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Baby+Feat+Ludacris+/2Bqvdq\",         \"pubDate\": \"Wed, 28 Apr 2010 02:37:53 -0400\",         \"pubTime\": 1272436673,         \"TinyLink\": \"http://tinysong.com/d3wI\",         \"SongID\": \"24447862\",         \"SongName\": \"Baby (Feat. Ludacris)\",         \"ArtistID\": \"1118876\",         \"ArtistName\": \"Justin Bieber\",         \"AlbumID\": \"4104002\",         \"AlbumName\": \"My World (Part II);\\nhttp://tinysong.com/gQsw\",         \"LongLink\": \"11578982\",         \"GroovesharkLink\": \"11578982\",         \"Link\": \"http://tinysong.com/d3wI\"     },     {         \"title\": \"Feel Good Inc - Gorillaz\",         \"description\": \"Feel Good Inc by Gorillaz on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Feel+Good+Inc/1UksmI\",         \"pubDate\": \"Wed, 28 Apr 2010 02:25:30 -0400\",         \"pubTime\": 1272435930     } ]   I tried using a dictionary:  def getLastSong(user,limit):     base_url = 'http://gsuser.com/lastSong/'     user_url = base_url + str(user) + '/' + str(limit) + \"/\"     raw = urllib.urlopen(user_url)     json_raw= raw.readlines()     json_object = json.loads(json_raw[0])      #filtering and making it look good.     gsongs = []     print json_object     for song in json_object[0]:            print song   This code only prints the information before :. (ignore the Justin Bieber track :))     ","Q_Votes":"63"},{"Q_Title":"Iterating through a JSON object","A_Content":"  for iterating through JSON you can use this:  json_object = json.loads(json_file) for element in json_object:      for value in json_object['Name_OF_YOUR_KEY/ELEMENT']:         print(json_object['Name_OF_YOUR_KEY/ELEMENT']['INDEX_OF_VALUE']['VALUE'])      ","Language":"Python","Tags":["python","dictionary","loops"],"URL":"https://stackoverflow.com/questions/2733813/iterating-through-a-json-object","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to iterate through a JSON object to import data, i.e. title and link. I can't seem to get to the content that is past the :.   JSON:   [     {         \"title\": \"Baby (Feat. Ludacris) - Justin Bieber\",         \"description\": \"Baby (Feat. Ludacris) by Justin Bieber on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Baby+Feat+Ludacris+/2Bqvdq\",         \"pubDate\": \"Wed, 28 Apr 2010 02:37:53 -0400\",         \"pubTime\": 1272436673,         \"TinyLink\": \"http://tinysong.com/d3wI\",         \"SongID\": \"24447862\",         \"SongName\": \"Baby (Feat. Ludacris)\",         \"ArtistID\": \"1118876\",         \"ArtistName\": \"Justin Bieber\",         \"AlbumID\": \"4104002\",         \"AlbumName\": \"My World (Part II);\\nhttp://tinysong.com/gQsw\",         \"LongLink\": \"11578982\",         \"GroovesharkLink\": \"11578982\",         \"Link\": \"http://tinysong.com/d3wI\"     },     {         \"title\": \"Feel Good Inc - Gorillaz\",         \"description\": \"Feel Good Inc by Gorillaz on Grooveshark\",         \"link\": \"http://listen.grooveshark.com/s/Feel+Good+Inc/1UksmI\",         \"pubDate\": \"Wed, 28 Apr 2010 02:25:30 -0400\",         \"pubTime\": 1272435930     } ]   I tried using a dictionary:  def getLastSong(user,limit):     base_url = 'http://gsuser.com/lastSong/'     user_url = base_url + str(user) + '/' + str(limit) + \"/\"     raw = urllib.urlopen(user_url)     json_raw= raw.readlines()     json_object = json.loads(json_raw[0])      #filtering and making it look good.     gsongs = []     print json_object     for song in json_object[0]:            print song   This code only prints the information before :. (ignore the Justin Bieber track :))     ","Q_Votes":"63"},{"Q_Title":"Adding docstrings to namedtuples?","A_Content":"  You can achieve this by creating a simple, empty wrapper class around the returned value from namedtuple.  Contents of a file I created (nt.py):  from collections import namedtuple  Point_ = namedtuple(\"Point\", [\"x\", \"y\"])  class Point(Point_):     \"\"\" A point in 2d space \"\"\"     pass   Then in the Python REPL:  >>> print nt.Point.__doc__  A point in 2d space    Or you could do:  >>> help(nt.Point)  # which outputs...    Help on class Point in module nt:  class Point(Point)  |  A point in 2d space  |    |  Method resolution order:  |      Point  |      Point  |      __builtin__.tuple  |      __builtin__.object  ...   If you don't like doing that by hand every time, it's trivial to write a sort-of factory function to do this:  def NamedTupleWithDocstring(docstring, *ntargs):     nt = namedtuple(*ntargs)     class NT(nt):         __doc__ = docstring     return NT  Point3D = NamedTupleWithDocstring(\"A point in 3d space\", \"Point3d\", [\"x\", \"y\", \"z\"])  p3 = Point3D(1,2,3)  print p3.__doc__   which outputs:  A point in 3d space      ","Language":"Python","Tags":["python","docstring","namedtuple"],"URL":"https://stackoverflow.com/questions/1606436/adding-docstrings-to-namedtuples","A_Votes":"42","_type":"dict","isAccepted":"Yes","Q_Content":"    Is it possible to add a documentation string to a namedtuple in an easy manner?  I tried  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) \"\"\" A point in 2D space \"\"\"  # Yet another test  \"\"\" A(nother) point in 2D space \"\"\" Point2 = namedtuple(\"Point2\", [\"x\", \"y\"])  print Point.__doc__ # -> \"Point(x, y)\" print Point2.__doc__ # -> \"Point2(x, y)\"   but that doesn't cut it. Is it possible to do in some other way?     ","Q_Votes":"63"},{"Q_Title":"Adding docstrings to namedtuples?","A_Content":"  Came across this old question via Google while wondering the same thing.  Just wanted to point out that you can tidy it up even more by calling namedtuple() right from the class declaration:  from collections import namedtuple  class Point(namedtuple('Point', 'x y')):     \"\"\"Here is the docstring.\"\"\"      ","Language":"Python","Tags":["python","docstring","namedtuple"],"URL":"https://stackoverflow.com/questions/1606436/adding-docstrings-to-namedtuples","A_Votes":"55","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to add a documentation string to a namedtuple in an easy manner?  I tried  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) \"\"\" A point in 2D space \"\"\"  # Yet another test  \"\"\" A(nother) point in 2D space \"\"\" Point2 = namedtuple(\"Point2\", [\"x\", \"y\"])  print Point.__doc__ # -> \"Point(x, y)\" print Point2.__doc__ # -> \"Point2(x, y)\"   but that doesn't cut it. Is it possible to do in some other way?     ","Q_Votes":"63"},{"Q_Title":"Adding docstrings to namedtuples?","A_Content":"  In Python 3, no wrapper is needed, as the __doc__ attributes of types is writable.  from collections import namedtuple  Point = namedtuple('Point', 'x y') Point.__doc__ = '''\\ A 2-dimensional coordinate  x - the abscissa y - the ordinate'''   This closely corresponds to a standard class definition, where the docstring follows the header.  class Point():     '''A 2-dimensional coordinate      x - the abscissa     y - the ordinate'''     <class code>   This does not work in Python 2.  AttributeError: attribute '__doc__' of 'type' objects is not writable.      ","Language":"Python","Tags":["python","docstring","namedtuple"],"URL":"https://stackoverflow.com/questions/1606436/adding-docstrings-to-namedtuples","A_Votes":"51","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to add a documentation string to a namedtuple in an easy manner?  I tried  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) \"\"\" A point in 2D space \"\"\"  # Yet another test  \"\"\" A(nother) point in 2D space \"\"\" Point2 = namedtuple(\"Point2\", [\"x\", \"y\"])  print Point.__doc__ # -> \"Point(x, y)\" print Point2.__doc__ # -> \"Point2(x, y)\"   but that doesn't cut it. Is it possible to do in some other way?     ","Q_Votes":"63"},{"Q_Title":"Adding docstrings to namedtuples?","A_Content":"     Is it possible to add a documentation string to a namedtuple in an easy manner?   Python 3  In Python 3, you can easily alter the doc on your namedtuple:  NT = collections.namedtuple('NT', 'foo bar')  NT.__doc__ = \"\"\":param str foo: foo name :param list bar: List of bars to bar\"\"\"   Which allows us to view the intent for them when we call help on them:  Help on class NT in module __main__:  class NT(builtins.tuple)  |  :param str foo: foo name  |  :param list bar: List of bars to bar ...   This is really straightforward compared to the difficulties we have accomplishing the same thing in Python 2.  Python 2  In Python 2, you'll need to   subclass the namedtuple, and  declare __slots__ == ()    Declaring __slots__ is an important part that the other answers here miss .   If you don't declare __slots__ - you could add mutable ad-hoc attributes to the instances, introducing bugs.  class Foo(namedtuple('Foo', 'bar')):     \"\"\"no __slots__ = ()!!!\"\"\"   And now:  >>> f = Foo('bar') >>> f.bar 'bar' >>> f.baz = 'what?' >>> f.__dict__ {'baz': 'what?'}   Each instance will create a separate __dict__ when __dict__ is accessed (the lack of __slots__ won't otherwise impede the functionality, but the lightweightness of the tuple, immutability, and declared attributes are all important features of namedtuples).   You'll also want a __repr__, if you want what is echoed on the command line to give you an equivalent object:  NTBase = collections.namedtuple('NTBase', 'foo bar')  class NT(NTBase):     \"\"\"     Individual foo bar, a namedtuple      :param str foo: foo name     :param list bar: List of bars to bar     \"\"\"     __slots__ = ()   a __repr__ like this is needed if you create the base namedtuple with a different name (like we did above with the name string argument, 'NTBase'):      def __repr__(self):         return 'NT(foo={0}, bar={1})'.format(                 repr(self.foo), repr(self.bar))   To test the repr, instantiate, then test for equality of a pass to eval(repr(instance))  nt = NT('foo', 'bar') assert eval(repr(nt)) == nt   Example from the documentation  The docs also give such an example, regarding __slots__ - I'm adding my own docstring to it:   class Point(namedtuple('Point', 'x y')):     \"\"\"Docstring added here, not in original\"\"\"     __slots__ = ()     @property     def hypot(self):         return (self.x ** 2 + self.y ** 2) ** 0.5     def __str__(self):         return 'Point: x=%6.3f  y=%6.3f  hypot=%6.3f' % (self.x, self.y, self.hypot)       ...      The subclass shown above sets __slots__ to an empty tuple. This helps   keep memory requirements low by preventing the creation of instance   dictionaries.   This demonstrates in-place usage (like another answer here suggests), but note that the in-place usage may become confusing when you look at the method resolution order, if you're debugging, which is why I originally suggested using Base as a suffix for the base namedtuple:  >>> Point.mro() [<class '__main__.Point'>, <class '__main__.Point'>, <type 'tuple'>, <type 'object'>]                 # ^^^^^---------------------^^^^^-- same names!           To prevent creation of a __dict__ when subclassing from a class that uses it, you must also declare it in the subclass. See also this answer for more caveats on using __slots__.     ","Language":"Python","Tags":["python","docstring","namedtuple"],"URL":"https://stackoverflow.com/questions/1606436/adding-docstrings-to-namedtuples","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to add a documentation string to a namedtuple in an easy manner?  I tried  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) \"\"\" A point in 2D space \"\"\"  # Yet another test  \"\"\" A(nother) point in 2D space \"\"\" Point2 = namedtuple(\"Point2\", [\"x\", \"y\"])  print Point.__doc__ # -> \"Point(x, y)\" print Point2.__doc__ # -> \"Point2(x, y)\"   but that doesn't cut it. Is it possible to do in some other way?     ","Q_Votes":"63"},{"Q_Title":"Adding docstrings to namedtuples?","A_Content":"  Since Python 3.5, docstrings for namedtuple objects can be updated.  From the whatsnew:   Point = namedtuple('Point', ['x', 'y']) Point.__doc__ += ': Cartesian coodinate' Point.x.__doc__ = 'abscissa' Point.y.__doc__ = 'ordinate'       ","Language":"Python","Tags":["python","docstring","namedtuple"],"URL":"https://stackoverflow.com/questions/1606436/adding-docstrings-to-namedtuples","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to add a documentation string to a namedtuple in an easy manner?  I tried  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) \"\"\" A point in 2D space \"\"\"  # Yet another test  \"\"\" A(nother) point in 2D space \"\"\" Point2 = namedtuple(\"Point2\", [\"x\", \"y\"])  print Point.__doc__ # -> \"Point(x, y)\" print Point2.__doc__ # -> \"Point2(x, y)\"   but that doesn't cut it. Is it possible to do in some other way?     ","Q_Votes":"63"},{"Q_Title":"Adding docstrings to namedtuples?","A_Content":"  No need to use a wrapper class as suggested by the accepted answer. Simply literally add a docstring:  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) Point.__doc__=\"A point in 2D space\"   This results in: (example using ipython3):  In [1]: Point? Type:       type String Form:<class '__main__.Point'> Docstring:  A point in 2D space  In [2]:    Voilà!     ","Language":"Python","Tags":["python","docstring","namedtuple"],"URL":"https://stackoverflow.com/questions/1606436/adding-docstrings-to-namedtuples","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to add a documentation string to a namedtuple in an easy manner?  I tried  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) \"\"\" A point in 2D space \"\"\"  # Yet another test  \"\"\" A(nother) point in 2D space \"\"\" Point2 = namedtuple(\"Point2\", [\"x\", \"y\"])  print Point.__doc__ # -> \"Point(x, y)\" print Point2.__doc__ # -> \"Point2(x, y)\"   but that doesn't cut it. Is it possible to do in some other way?     ","Q_Votes":"63"},{"Q_Title":"Adding docstrings to namedtuples?","A_Content":"  You could concoct your own version of the namedtuple factory function by Raymond Hettinger and add an optional docstring argument.  However it would be easier -- and arguably better -- to just define your own factory function using the same basic technique as in the recipe.  Either way, you'll end up with something reusable.  from collections import namedtuple  def my_namedtuple(typename, field_names, verbose=False,                  rename=False, docstring=''):     '''Returns a new subclass of namedtuple with the supplied        docstring appended to the default one.      >>> Point = my_namedtuple('Point', 'x, y', docstring='A point in 2D space')     >>> print Point.__doc__     Point(x, y):  A point in 2D space     '''     # create a base class and concatenate its docstring and the one passed     _base = namedtuple(typename, field_names, verbose, rename)     _docstring = ''.join([_base.__doc__, ':  ', docstring])      # fill in template to create a no-op subclass with the combined docstring     template = '''class subclass(_base):         %(_docstring)r         pass\\n''' % locals()      # execute code string in a temporary namespace     namespace = dict(_base=_base, _docstring=_docstring)     try:         exec template in namespace     except SyntaxError, e:         raise SyntaxError(e.message + ':\\n' + template)      return namespace['subclass']  # subclass object created      ","Language":"Python","Tags":["python","docstring","namedtuple"],"URL":"https://stackoverflow.com/questions/1606436/adding-docstrings-to-namedtuples","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to add a documentation string to a namedtuple in an easy manner?  I tried  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) \"\"\" A point in 2D space \"\"\"  # Yet another test  \"\"\" A(nother) point in 2D space \"\"\" Point2 = namedtuple(\"Point2\", [\"x\", \"y\"])  print Point.__doc__ # -> \"Point(x, y)\" print Point2.__doc__ # -> \"Point2(x, y)\"   but that doesn't cut it. Is it possible to do in some other way?     ","Q_Votes":"63"},{"Q_Title":"Adding docstrings to namedtuples?","A_Content":"  In Python 3.6+ you can use:  class Point(NamedTuple):     \"\"\"     A point in 2D space     \"\"\"     x: float     y: float      ","Language":"Python","Tags":["python","docstring","namedtuple"],"URL":"https://stackoverflow.com/questions/1606436/adding-docstrings-to-namedtuples","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to add a documentation string to a namedtuple in an easy manner?  I tried  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) \"\"\" A point in 2D space \"\"\"  # Yet another test  \"\"\" A(nother) point in 2D space \"\"\" Point2 = namedtuple(\"Point2\", [\"x\", \"y\"])  print Point.__doc__ # -> \"Point(x, y)\" print Point2.__doc__ # -> \"Point2(x, y)\"   but that doesn't cut it. Is it possible to do in some other way?     ","Q_Votes":"63"},{"Q_Title":"Adding docstrings to namedtuples?","A_Content":"  No, you can only add doc strings to modules, classes and function (including methods)     ","Language":"Python","Tags":["python","docstring","namedtuple"],"URL":"https://stackoverflow.com/questions/1606436/adding-docstrings-to-namedtuples","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to add a documentation string to a namedtuple in an easy manner?  I tried  from collections import namedtuple  Point = namedtuple(\"Point\", [\"x\", \"y\"]) \"\"\" A point in 2D space \"\"\"  # Yet another test  \"\"\" A(nother) point in 2D space \"\"\" Point2 = namedtuple(\"Point2\", [\"x\", \"y\"])  print Point.__doc__ # -> \"Point(x, y)\" print Point2.__doc__ # -> \"Point2(x, y)\"   but that doesn't cut it. Is it possible to do in some other way?     ","Q_Votes":"63"},{"Q_Title":"Python split text on sentences","A_Content":"  The Natural Language Toolkit (nltk.org) has what you need.  This group posting indicates this does it:  import nltk.data  tokenizer = nltk.data.load('tokenizers/punkt/english.pickle') fp = open(\"test.txt\") data = fp.read() print '\\n-----\\n'.join(tokenizer.tokenize(data))   (I haven't tried it!)      ","Language":"Python","Tags":["python","text","split"],"URL":"https://stackoverflow.com/questions/4576077/python-split-text-on-sentences","A_Votes":"107","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a text file. I need get a list of sentences.   How can this be implemented? There are a lot of subtleties, such as dot being used in abbreviations.  My old regexp works  bad.  re.compile('(\\. |^|!|\\?)([A-Z][^;↑\\.<>@\\^&/\\[\\]]*(\\.|!|\\?) )',re.M)      ","Q_Votes":"63"},{"Q_Title":"Python split text on sentences","A_Content":"  This function can split the entire text of Huckleberry Finn into sentences in about 0.1 seconds and handles many of the more painful edge cases that make sentence parsing non-trivial e.g. \"Mr. John Johnson Jr. was born in the U.S.A but earned his Ph.D. in Israel before joining Nike Inc. as an engineer. He also worked at craigslist.org as a business analyst.\"  # -*- coding: utf-8 -*- import re caps = \"([A-Z])\" prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\" suffixes = \"(Inc|Ltd|Jr|Sr|Co)\" starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\" acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\" websites = \"[.](com|net|org|io|gov)\"  def split_into_sentences(text):     text = \" \" + text + \"  \"     text = text.replace(\"\\n\",\" \")     text = re.sub(prefixes,\"\\\\1<prd>\",text)     text = re.sub(websites,\"<prd>\\\\1\",text)     if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")     text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)     text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)     text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)     text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)     text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)     text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)     text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)     if \"”\" in text: text = text.replace(\".”\",\"”.\")     if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")     if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")     if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")     text = text.replace(\".\",\".<stop>\")     text = text.replace(\"?\",\"?<stop>\")     text = text.replace(\"!\",\"!<stop>\")     text = text.replace(\"<prd>\",\".\")     sentences = text.split(\"<stop>\")     sentences = sentences[:-1]     sentences = [s.strip() for s in sentences]     return sentences      ","Language":"Python","Tags":["python","text","split"],"URL":"https://stackoverflow.com/questions/4576077/python-split-text-on-sentences","A_Votes":"50","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file. I need get a list of sentences.   How can this be implemented? There are a lot of subtleties, such as dot being used in abbreviations.  My old regexp works  bad.  re.compile('(\\. |^|!|\\?)([A-Z][^;↑\\.<>@\\^&/\\[\\]]*(\\.|!|\\?) )',re.M)      ","Q_Votes":"63"},{"Q_Title":"Python split text on sentences","A_Content":"  Here is a middle of the road approach that doesn't rely on any external libraries.  I use list comprehension to exclude overlaps between abbreviations and terminators as well as to exclude overlaps between variations on terminations, for example: '.' vs. '.\"'  abbreviations = {'dr.': 'doctor', 'mr.': 'mister', 'bro.': 'brother', 'bro': 'brother', 'mrs.': 'mistress', 'ms.': 'miss', 'jr.': 'junior', 'sr.': 'senior',                  'i.e.': 'for example', 'e.g.': 'for example', 'vs.': 'versus'} terminators = ['.', '!', '?'] wrappers = ['\"', \"'\", ')', ']', '}']   def find_sentences(paragraph):    end = True    sentences = []    while end > -1:        end = find_sentence_end(paragraph)        if end > -1:            sentences.append(paragraph[end:].strip())            paragraph = paragraph[:end]    sentences.append(paragraph)    sentences.reverse()    return sentences   def find_sentence_end(paragraph):     [possible_endings, contraction_locations] = [[], []]     contractions = abbreviations.keys()     sentence_terminators = terminators + [terminator + wrapper for wrapper in wrappers for terminator in terminators]     for sentence_terminator in sentence_terminators:         t_indices = list(find_all(paragraph, sentence_terminator))         possible_endings.extend(([] if not len(t_indices) else [[i, len(sentence_terminator)] for i in t_indices]))     for contraction in contractions:         c_indices = list(find_all(paragraph, contraction))         contraction_locations.extend(([] if not len(c_indices) else [i + len(contraction) for i in c_indices]))     possible_endings = [pe for pe in possible_endings if pe[0] + pe[1] not in contraction_locations]     if len(paragraph) in [pe[0] + pe[1] for pe in possible_endings]:         max_end_start = max([pe[0] for pe in possible_endings])         possible_endings = [pe for pe in possible_endings if pe[0] != max_end_start]     possible_endings = [pe[0] + pe[1] for pe in possible_endings if sum(pe) > len(paragraph) or (sum(pe) < len(paragraph) and paragraph[sum(pe)] == ' ')]     end = (-1 if not len(possible_endings) else max(possible_endings))     return end   def find_all(a_str, sub):     start = 0     while True:         start = a_str.find(sub, start)         if start == -1:             return         yield start         start += len(sub)   I used Karl's find_all function from this entry: Find all occurrences of a substring in Python     ","Language":"Python","Tags":["python","text","split"],"URL":"https://stackoverflow.com/questions/4576077/python-split-text-on-sentences","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file. I need get a list of sentences.   How can this be implemented? There are a lot of subtleties, such as dot being used in abbreviations.  My old regexp works  bad.  re.compile('(\\. |^|!|\\?)([A-Z][^;↑\\.<>@\\^&/\\[\\]]*(\\.|!|\\?) )',re.M)      ","Q_Votes":"63"},{"Q_Title":"Python split text on sentences","A_Content":"  Instead of using regex for spliting the text into sentences, you can also use nltk library.  >>> from nltk import tokenize >>> p = \"Good morning Dr. Adams. The patient is waiting for you in room number 3.\"  >>> tokenize.sent_tokenize(p) ['Good morning Dr. Adams.', 'The patient is waiting for you in room number 3.']   ref: https://stackoverflow.com/a/9474645/2877052     ","Language":"Python","Tags":["python","text","split"],"URL":"https://stackoverflow.com/questions/4576077/python-split-text-on-sentences","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file. I need get a list of sentences.   How can this be implemented? There are a lot of subtleties, such as dot being used in abbreviations.  My old regexp works  bad.  re.compile('(\\. |^|!|\\?)([A-Z][^;↑\\.<>@\\^&/\\[\\]]*(\\.|!|\\?) )',re.M)      ","Q_Votes":"63"},{"Q_Title":"Python split text on sentences","A_Content":"  For simple cases (where sentences are terminated normally), this should work:  import re text = ''.join(open('somefile.txt').readlines()) sentences = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', text)   The regex is *\\. +, which matches a period surrounded by 0 or more spaces to the left and 1 or more to the right (to prevent something like the period in re.split being counted as a change in sentence).  Obviously, not the most robust solution, but it'll do fine in most cases. The only case this won't cover is abbreviations (perhaps run through the list of sentences and check that each string in sentences starts with a capital letter?)     ","Language":"Python","Tags":["python","text","split"],"URL":"https://stackoverflow.com/questions/4576077/python-split-text-on-sentences","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file. I need get a list of sentences.   How can this be implemented? There are a lot of subtleties, such as dot being used in abbreviations.  My old regexp works  bad.  re.compile('(\\. |^|!|\\?)([A-Z][^;↑\\.<>@\\^&/\\[\\]]*(\\.|!|\\?) )',re.M)      ","Q_Votes":"63"},{"Q_Title":"Python split text on sentences","A_Content":"  You can try using Spacy instead of regex. I use it and it does the job.  import spacy nlp = spacy.load('en')  text = '''Your text here''' tokens = nlp(text)  for sent in tokens.sents:     print(sent.string.strip())      ","Language":"Python","Tags":["python","text","split"],"URL":"https://stackoverflow.com/questions/4576077/python-split-text-on-sentences","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file. I need get a list of sentences.   How can this be implemented? There are a lot of subtleties, such as dot being used in abbreviations.  My old regexp works  bad.  re.compile('(\\. |^|!|\\?)([A-Z][^;↑\\.<>@\\^&/\\[\\]]*(\\.|!|\\?) )',re.M)      ","Q_Votes":"63"},{"Q_Title":"Python split text on sentences","A_Content":"  @Artyom,  Hi! You could make a new tokenizer for Russian (and some other languages) using this function:  def russianTokenizer(text):     result = text     result = result.replace('.', ' . ')     result = result.replace(' .  .  . ', ' ... ')     result = result.replace(',', ' , ')     result = result.replace(':', ' : ')     result = result.replace(';', ' ; ')     result = result.replace('!', ' ! ')     result = result.replace('?', ' ? ')     result = result.replace('\\\"', ' \\\" ')     result = result.replace('\\'', ' \\' ')     result = result.replace('(', ' ( ')     result = result.replace(')', ' ) ')      result = result.replace('  ', ' ')     result = result.replace('  ', ' ')     result = result.replace('  ', ' ')     result = result.replace('  ', ' ')     result = result.strip()     result = result.split(' ')     return result   and then call it in this way:  text = 'вы выполняете поиск, используя Google SSL;' tokens = russianTokenizer(text)   Good luck, Marilena.     ","Language":"Python","Tags":["python","text","split"],"URL":"https://stackoverflow.com/questions/4576077/python-split-text-on-sentences","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file. I need get a list of sentences.   How can this be implemented? There are a lot of subtleties, such as dot being used in abbreviations.  My old regexp works  bad.  re.compile('(\\. |^|!|\\?)([A-Z][^;↑\\.<>@\\^&/\\[\\]]*(\\.|!|\\?) )',re.M)      ","Q_Votes":"63"},{"Q_Title":"Python split text on sentences","A_Content":"  No doubt that NLTK is the most suitable for the purpose. But getting started with NLTK is quite painful (But once you install it - you just reap the rewards)  So here is simple re based code available at http://pythonicprose.blogspot.com/2009/09/python-split-paragraph-into-sentences.html  # split up a paragraph into sentences # using regular expressions   def splitParagraphIntoSentences(paragraph):     ''' break a paragraph into sentences         and return a list '''     import re     # to split by multile characters      #   regular expressions are easiest (and fastest)     sentenceEnders = re.compile('[.!?]')     sentenceList = sentenceEnders.split(paragraph)     return sentenceList   if __name__ == '__main__':     p = \"\"\"This is a sentence.  This is an excited sentence! And do you think this is a question?\"\"\"      sentences = splitParagraphIntoSentences(p)     for s in sentences:         print s.strip()  #output: #   This is a sentence #   This is an excited sentence  #   And do you think this is a question       ","Language":"Python","Tags":["python","text","split"],"URL":"https://stackoverflow.com/questions/4576077/python-split-text-on-sentences","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file. I need get a list of sentences.   How can this be implemented? There are a lot of subtleties, such as dot being used in abbreviations.  My old regexp works  bad.  re.compile('(\\. |^|!|\\?)([A-Z][^;↑\\.<>@\\^&/\\[\\]]*(\\.|!|\\?) )',re.M)      ","Q_Votes":"63"},{"Q_Title":"Python split text on sentences","A_Content":"  I had to read subtitles files and split them into sentences. After pre-processing (like removing time information etc in the .srt files), the variable fullFile contained the full text of the subtitle file. The below crude way neatly split them into sentences. Probably I was lucky that the sentences always ended (correctly) with a space. Try this first and if it has any exceptions, add more checks and balances.  # Very approximate way to split the text into sentences - Break after ? . and ! fullFile = re.sub(\"(\\!|\\?|\\.) \",\"\\\\1<BRK>\",fullFile) sentences = fullFile.split(\"<BRK>\"); sentFile = open(\"./sentences.out\", \"w+\"); for line in sentences:     sentFile.write (line);     sentFile.write (\"\\n\"); sentFile.close;   Oh! well. I now realize that since my content was Spanish, I did not have the issues of dealing with \"Mr. Smith\" etc. Still, if someone wants a quick and dirty parser...     ","Language":"Python","Tags":["python","text","split"],"URL":"https://stackoverflow.com/questions/4576077/python-split-text-on-sentences","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a text file. I need get a list of sentences.   How can this be implemented? There are a lot of subtleties, such as dot being used in abbreviations.  My old regexp works  bad.  re.compile('(\\. |^|!|\\?)([A-Z][^;↑\\.<>@\\^&/\\[\\]]*(\\.|!|\\?) )',re.M)      ","Q_Votes":"63"},{"Q_Title":"Python HTML sanitizer / scrubber / filter [closed]","A_Content":"  Here's a simple solution using BeautifulSoup:  from bs4 import BeautifulSoup  VALID_TAGS = ['strong', 'em', 'p', 'ul', 'li', 'br']  def sanitize_html(value):      soup = BeautifulSoup(value)      for tag in soup.findAll(True):         if tag.name not in VALID_TAGS:             tag.hidden = True      return soup.renderContents()   If you want to remove the contents of the invalid tags as well, substitute tag.extract() for tag.hidden.  You might also look into using lxml and Tidy.     ","Language":"Python","Tags":["python","html","filter"],"URL":"https://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter","A_Votes":"40","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm looking for a module that will remove any HTML tags from a string that are not found in a whitelist.     ","Q_Votes":"63"},{"Q_Title":"Python HTML sanitizer / scrubber / filter [closed]","A_Content":"  Use lxml.html.clean! It's VERY easy!  from lxml.html.clean import clean_html print clean_html(html)   Suppose the following html:  html = '''\\ <html>  <head>    <script type=\"text/javascript\" src=\"evil-site\"></script>    <link rel=\"alternate\" type=\"text/rss\" src=\"evil-rss\">    <style>      body {background-image: url(javascript:do_evil)};      div {color: expression(evil)};    </style>  </head>  <body onload=\"evil_function()\">     <!-- I am interpreted for EVIL! -->    <a href=\"javascript:evil_function()\">a link</a>    <a href=\"#\" onclick=\"evil_function()\">another link</a>    <p onclick=\"evil_function()\">a paragraph</p>    <div style=\"display: none\">secret EVIL!</div>    <object> of EVIL! </object>    <iframe src=\"evil-site\"></iframe>    <form action=\"evil-site\">      Password: <input type=\"password\" name=\"password\">    </form>    <blink>annoying EVIL!</blink>    <a href=\"evil-site\">spam spam SPAM!</a>    <image src=\"evil!\">  </body> </html>'''   The results...  <html>   <body>     <div>       <style>/* deleted */</style>       <a href=\"\">a link</a>       <a href=\"#\">another link</a>       <p>a paragraph</p>       <div>secret EVIL!</div>       of EVIL!       Password:       annoying EVIL!       <a href=\"evil-site\">spam spam SPAM!</a>       <img src=\"evil!\">     </div>   </body> </html>   You can customize the elements you want to clean and whatnot.     ","Language":"Python","Tags":["python","html","filter"],"URL":"https://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter","A_Votes":"53","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for a module that will remove any HTML tags from a string that are not found in a whitelist.     ","Q_Votes":"63"},{"Q_Title":"Python HTML sanitizer / scrubber / filter [closed]","A_Content":"  The above solutions via Beautiful Soup will not work. You might be able to hack something with Beautiful Soup above and beyond them, because Beautiful Soup provides access to the parse tree. In a while, I think I'll try to solve the problem properly, but it's a week-long project or so, and I don't have a free week soon.   Just to be specific, not only will Beautiful Soup throw exceptions for some parsing errors which the above code doesn't catch; but also, there are plenty of very real XSS vulnerabilities that aren't caught, like:  <<script>script> alert(\"Haha, I hacked your page.\"); </</script>script>   Probably the best thing that you can do is instead to strip out the < element as &lt;, to prohibit all HTML, and then use a restricted subset like Markdown to render formatting properly. In particular, you can also go back and re-introduce common bits of HTML with a regex. Here's what the process looks like, roughly:  _lt_     = re.compile('<') _tc_ = '~(lt)~'   # or whatever, so long as markdown doesn't mangle it.      _ok_ = re.compile(_tc_ + '(/?(?:u|b|i|em|strong|sup|sub|p|br|q|blockquote|code))>', re.I) _sqrt_ = re.compile(_tc_ + 'sqrt>', re.I)     #just to give an example of extending _endsqrt_ = re.compile(_tc_ + '/sqrt>', re.I) #html syntax with your own elements. _tcre_ = re.compile(_tc_)  def sanitize(text):     text = _lt_.sub(_tc_, text)     text = markdown(text)     text = _ok_.sub(r'<\\1>', text)     text = _sqrt_.sub(r'&radic;<span style=\"text-decoration:overline;\">', text)     text = _endsqrt_.sub(r'</span>', text)     return _tcre_.sub('&lt;', text)   I haven't tested that code yet, so there may be bugs. But you see the general idea: you have to blacklist all HTML in general before you whitelist the ok stuff.     ","Language":"Python","Tags":["python","html","filter"],"URL":"https://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter","A_Votes":"34","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for a module that will remove any HTML tags from a string that are not found in a whitelist.     ","Q_Votes":"63"},{"Q_Title":"Python HTML sanitizer / scrubber / filter [closed]","A_Content":"  Here is what i use in my own project. The acceptable_elements/attributes come from feedparser and BeautifulSoup does the work.  from BeautifulSoup import BeautifulSoup  acceptable_elements = ['a', 'abbr', 'acronym', 'address', 'area', 'b', 'big',       'blockquote', 'br', 'button', 'caption', 'center', 'cite', 'code', 'col',       'colgroup', 'dd', 'del', 'dfn', 'dir', 'div', 'dl', 'dt', 'em',       'font', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'hr', 'i', 'img',        'ins', 'kbd', 'label', 'legend', 'li', 'map', 'menu', 'ol',        'p', 'pre', 'q', 's', 'samp', 'small', 'span', 'strike',       'strong', 'sub', 'sup', 'table', 'tbody', 'td', 'tfoot', 'th',       'thead', 'tr', 'tt', 'u', 'ul', 'var']  acceptable_attributes = ['abbr', 'accept', 'accept-charset', 'accesskey',   'action', 'align', 'alt', 'axis', 'border', 'cellpadding', 'cellspacing',   'char', 'charoff', 'charset', 'checked', 'cite', 'clear', 'cols',   'colspan', 'color', 'compact', 'coords', 'datetime', 'dir',    'enctype', 'for', 'headers', 'height', 'href', 'hreflang', 'hspace',   'id', 'ismap', 'label', 'lang', 'longdesc', 'maxlength', 'method',   'multiple', 'name', 'nohref', 'noshade', 'nowrap', 'prompt',    'rel', 'rev', 'rows', 'rowspan', 'rules', 'scope', 'shape', 'size',   'span', 'src', 'start', 'summary', 'tabindex', 'target', 'title', 'type',   'usemap', 'valign', 'value', 'vspace', 'width']  def clean_html( fragment ):     while True:         soup = BeautifulSoup( fragment )         removed = False                 for tag in soup.findAll(True): # find all tags             if tag.name not in acceptable_elements:                 tag.extract() # remove the bad ones                 removed = True             else: # it might have bad attributes                 # a better way to get all attributes?                 for attr in tag._getAttrMap().keys():                     if attr not in acceptable_attributes:                         del tag[attr]          # turn it back to html         fragment = unicode(soup)          if removed:             # we removed tags and tricky can could exploit that!             # we need to reparse the html until it stops changing             continue # next round          return fragment   Some small tests to make sure this behaves correctly:  tests = [   #text should work             ('<p>this is text</p>but this too', '<p>this is text</p>but this too'),             # make sure we cant exploit removal of tags             ('<<script></script>script> alert(\"Haha, I hacked your page.\"); <<script></script>/script>', ''),             # try the same trick with attributes, gives an Exception             ('<div on<script></script>load=\"alert(\"Haha, I hacked your page.\");\">1</div>',  Exception),              # no tags should be skipped             ('<script>bad</script><script>bad</script><script>bad</script>', ''),             # leave valid tags but remove bad attributes             ('<a href=\"good\" onload=\"bad\" onclick=\"bad\" alt=\"good\">1</div>', '<a href=\"good\" alt=\"good\">1</a>'), ]  for text, out in tests:     try:         res = clean_html(text)         assert res == out, \"%s => %s != %s\" % (text, res, out)     except out, e:         assert isinstance(e, out), \"Wrong exception %r\" % e      ","Language":"Python","Tags":["python","html","filter"],"URL":"https://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for a module that will remove any HTML tags from a string that are not found in a whitelist.     ","Q_Votes":"63"},{"Q_Title":"Python HTML sanitizer / scrubber / filter [closed]","A_Content":"  Bleach does better with more useful options. It's built on html5lib and ready for production.  Check this documents.     ","Language":"Python","Tags":["python","html","filter"],"URL":"https://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for a module that will remove any HTML tags from a string that are not found in a whitelist.     ","Q_Votes":"63"},{"Q_Title":"Python HTML sanitizer / scrubber / filter [closed]","A_Content":"  I modified Bryan's solution with BeautifulSoup to address the problem raised by Chris Drost. A little crude, but does the job:  from BeautifulSoup import BeautifulSoup, Comment  VALID_TAGS = {'strong': [],               'em': [],               'p': [],               'ol': [],               'ul': [],               'li': [],               'br': [],               'a': ['href', 'title']               }  def sanitize_html(value, valid_tags=VALID_TAGS):     soup = BeautifulSoup(value)     comments = soup.findAll(text=lambda text:isinstance(text, Comment))     [comment.extract() for comment in comments]     # Some markup can be crafted to slip through BeautifulSoup's parser, so     # we run this repeatedly until it generates the same output twice.     newoutput = soup.renderContents()     while 1:         oldoutput = newoutput         soup = BeautifulSoup(newoutput)         for tag in soup.findAll(True):             if tag.name not in valid_tags:                 tag.hidden = True             else:                 tag.attrs = [(attr, value) for attr, value in tag.attrs if attr in valid_tags[tag.name]]         newoutput = soup.renderContents()         if oldoutput == newoutput:             break     return newoutput   Edit: Updated to support valid attributes.     ","Language":"Python","Tags":["python","html","filter"],"URL":"https://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for a module that will remove any HTML tags from a string that are not found in a whitelist.     ","Q_Votes":"63"},{"Q_Title":"Python HTML sanitizer / scrubber / filter [closed]","A_Content":"  I use this:  FilterHTML  It's simple and lets you define a well-controlled white-list, scrubs URLs and even matches attribute values against regex or have custom filtering functions per attribute.  If used carefully it could be a safe solution.     ","Language":"Python","Tags":["python","html","filter"],"URL":"https://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for a module that will remove any HTML tags from a string that are not found in a whitelist.     ","Q_Votes":"63"},{"Q_Title":"Python HTML sanitizer / scrubber / filter [closed]","A_Content":"  You could use html5lib, which uses a whitelist to sanitize.  An example:  import html5lib from html5lib import sanitizer, treebuilders, treewalkers, serializer  def clean_html(buf):     \"\"\"Cleans HTML of dangerous tags and content.\"\"\"     buf = buf.strip()     if not buf:         return buf      p = html5lib.HTMLParser(tree=treebuilders.getTreeBuilder(\"dom\"),             tokenizer=sanitizer.HTMLSanitizer)     dom_tree = p.parseFragment(buf)      walker = treewalkers.getTreeWalker(\"dom\")     stream = walker(dom_tree)      s = serializer.htmlserializer.HTMLSerializer(             omit_optional_tags=False,             quote_attr_values=True)     return s.render(stream)       ","Language":"Python","Tags":["python","html","filter"],"URL":"https://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for a module that will remove any HTML tags from a string that are not found in a whitelist.     ","Q_Votes":"63"},{"Q_Title":"Python HTML sanitizer / scrubber / filter [closed]","A_Content":"  I prefer the lxml.html.clean solution, like nosklo points out. Here's to also remove some empty tags:  from lxml import etree from lxml.html import clean, fromstring, tostring  remove_attrs = ['class'] remove_tags = ['table', 'tr', 'td'] nonempty_tags = ['a', 'p', 'span', 'div']  cleaner = clean.Cleaner(remove_tags=remove_tags)  def squeaky_clean(html):     clean_html = cleaner.clean_html(html)     # now remove the useless empty tags     root = fromstring(clean_html)     context = etree.iterwalk(root) # just the end tag event     for action, elem in context:         clean_text = elem.text and elem.text.strip(' \\t\\r\\n')         if elem.tag in nonempty_tags and \\         not (len(elem) or clean_text): # no children nor text             elem.getparent().remove(elem)             continue         elem.text = clean_text # if you want         # and if you also wanna remove some attrs:         for badattr in remove_attrs:             if elem.attrib.has_key(badattr):                 del elem.attrib[badattr]     return tostring(root)      ","Language":"Python","Tags":["python","html","filter"],"URL":"https://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm looking for a module that will remove any HTML tags from a string that are not found in a whitelist.     ","Q_Votes":"63"},{"Q_Title":"How to get current available GPUs in tensorflow?","A_Content":"  There is an undocumented method called device_lib.list_local_devices() that enables you to list the devices available in the local process. (N.B. As an undocumented method, this is subject to backwards incompatible changes.) The function returns a list of DeviceAttributes protocol buffer objects. You can extract a list of string device names for the GPU devices as follows:  from tensorflow.python.client import device_lib  def get_available_gpus():     local_device_protos = device_lib.list_local_devices()     return [x.name for x in local_device_protos if x.device_type == 'GPU']   Note that (at least up to TensorFlow 1.4), calling device_lib.list_local_devices() will run some initialization code that, by default, will allocate all of the GPU memory on all of the devices (GitHub issue). To avoid this, first create a session with an explicitly small per_process_gpu_fraction, or allow_growth=True, to prevent all of the memory being allocated. See this question for more details.     ","Language":"Python","Tags":["python","gpu","tensorflow"],"URL":"https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow","A_Votes":"125","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a plan to use distributed TensorFlow, and I saw TensorFlow can use GPUs for training and testing. In a cluster environment, each machine could have 0 or 1 or more GPUs, and I want to run my TensorFlow graph into GPUs on as many machines as possible.  I found that when running tf.Session() TensorFlow gives information about GPU in the log messages like below:  I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0  I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y  I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)   My question is how do I get information about current available GPU from TensorFlow? I can get loaded GPU information from the log, but I want to do it in a more sophisticated, programmatic way. I also could restrict GPUs intentionally using the CUDA_VISIBLE_DEVICES environment variable, so I don't want to know a way of getting GPU information from OS kernel.  In short, I want a function like tf.get_available_gpus() that will return ['/gpu:0', '/gpu:1'] if there are two GPUs available in the machine. How can I implement this?     ","Q_Votes":"63"},{"Q_Title":"How to get current available GPUs in tensorflow?","A_Content":"  You can check all device list using following code:  from tensorflow.python.client import device_lib  device_lib.list_local_devices()      ","Language":"Python","Tags":["python","gpu","tensorflow"],"URL":"https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow","A_Votes":"54","_type":"dict","isAccepted":"No","Q_Content":"    I have a plan to use distributed TensorFlow, and I saw TensorFlow can use GPUs for training and testing. In a cluster environment, each machine could have 0 or 1 or more GPUs, and I want to run my TensorFlow graph into GPUs on as many machines as possible.  I found that when running tf.Session() TensorFlow gives information about GPU in the log messages like below:  I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0  I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y  I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)   My question is how do I get information about current available GPU from TensorFlow? I can get loaded GPU information from the log, but I want to do it in a more sophisticated, programmatic way. I also could restrict GPUs intentionally using the CUDA_VISIBLE_DEVICES environment variable, so I don't want to know a way of getting GPU information from OS kernel.  In short, I want a function like tf.get_available_gpus() that will return ['/gpu:0', '/gpu:1'] if there are two GPUs available in the machine. How can I implement this?     ","Q_Votes":"63"},{"Q_Title":"How to get current available GPUs in tensorflow?","A_Content":"  Apart from the excellent explanation by Mrry, where he suggested to use device_lib.list_local_devices() I can show you how you can check for GPU related information from the command line.  Because currently only Nvidia's gpus work for NN frameworks, the answer covers only them. Nvidia has a page where they document how you can use the /proc filesystem interface to obtain run-time information about the driver, any installed NVIDIA graphics cards, and the AGP status.     /proc/driver/nvidia/gpus/0..N/information      Provide information about   each of the installed NVIDIA graphics adapters (model name, IRQ, BIOS   version, Bus Type). Note that the BIOS version is only available while   X is running.   So you can run this from command line cat /proc/driver/nvidia/gpus/0/information and see information about your first GPU. It is easy to run this from python and also you can check second, third, fourth GPU till it will fail.  Definitely Mrry's answer is more robust and I am not sure whether my answer will work on non-linux machine, but that Nvidia's page provide other interesting information, which not many people know about.     ","Language":"Python","Tags":["python","gpu","tensorflow"],"URL":"https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a plan to use distributed TensorFlow, and I saw TensorFlow can use GPUs for training and testing. In a cluster environment, each machine could have 0 or 1 or more GPUs, and I want to run my TensorFlow graph into GPUs on as many machines as possible.  I found that when running tf.Session() TensorFlow gives information about GPU in the log messages like below:  I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0  I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y  I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)   My question is how do I get information about current available GPU from TensorFlow? I can get loaded GPU information from the log, but I want to do it in a more sophisticated, programmatic way. I also could restrict GPUs intentionally using the CUDA_VISIBLE_DEVICES environment variable, so I don't want to know a way of getting GPU information from OS kernel.  In short, I want a function like tf.get_available_gpus() that will return ['/gpu:0', '/gpu:1'] if there are two GPUs available in the machine. How can I implement this?     ","Q_Votes":"63"},{"Q_Title":"How to get current available GPUs in tensorflow?","A_Content":"  There is also a method in the test util. So all that has to be done is:  tf.test.is_gpu_available()   and/or  tf.test.gpu_device_name()   Look up the Tensorflow docs for arguments.     ","Language":"Python","Tags":["python","gpu","tensorflow"],"URL":"https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have a plan to use distributed TensorFlow, and I saw TensorFlow can use GPUs for training and testing. In a cluster environment, each machine could have 0 or 1 or more GPUs, and I want to run my TensorFlow graph into GPUs on as many machines as possible.  I found that when running tf.Session() TensorFlow gives information about GPU in the log messages like below:  I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0  I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y  I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)   My question is how do I get information about current available GPU from TensorFlow? I can get loaded GPU information from the log, but I want to do it in a more sophisticated, programmatic way. I also could restrict GPUs intentionally using the CUDA_VISIBLE_DEVICES environment variable, so I don't want to know a way of getting GPU information from OS kernel.  In short, I want a function like tf.get_available_gpus() that will return ['/gpu:0', '/gpu:1'] if there are two GPUs available in the machine. How can I implement this?     ","Q_Votes":"63"},{"Q_Title":"Best way to generate xml? [duplicate]","A_Content":"  Using lxml:  from lxml import etree  # create XML  root = etree.Element('root') root.append(etree.Element('child')) # another child with text child = etree.Element('child') child.text = 'some text' root.append(child)  # pretty string s = etree.tostring(root, pretty_print=True) print s   Output:  <root>   <child/>   <child>some text</child> </root>   See the tutorial for more information.     ","Language":"Python","Tags":["python","xml","api"],"URL":"https://stackoverflow.com/questions/3844360/best-way-to-generate-xml","A_Votes":"81","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              Creating a simple XML file using python                                        5 answers                                          I'm creating an web api and need a good way to very quickly generate some well formatted xml. I cannot find any good way of doing this in python.  Note: Some libraries look promising but either lack documentation or only output to files.      ","Q_Votes":"63"},{"Q_Title":"Best way to generate xml? [duplicate]","A_Content":"  ElementTree is a good module for reading xml and writing too e.g.  from xml.etree.ElementTree import Element, SubElement, tostring  root = Element('root') child = SubElement(root, \"child\") child.text = \"I am a child\"  print tostring(root)   Output:  <root><child>I am a child</child></root>   See this tutorial for more details and how to pretty print.  Alternatively if your XML is simple, do not underestimate the power of string formatting :)  xmlTemplate = \"\"\"<root>     <person>         <name>%(name)s</name>         <address>%(address)s</address>      </person> </root>\"\"\"  data = {'name':'anurag', 'address':'Pune, india'} print xmlTemplate%data   Output:  <root>     <person>         <name>anurag</name>         <address>Pune, india</address>      </person> </root>   You can use string.Template or some template engine too, for complex formatting.     ","Language":"Python","Tags":["python","xml","api"],"URL":"https://stackoverflow.com/questions/3844360/best-way-to-generate-xml","A_Votes":"77","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Creating a simple XML file using python                                        5 answers                                          I'm creating an web api and need a good way to very quickly generate some well formatted xml. I cannot find any good way of doing this in python.  Note: Some libraries look promising but either lack documentation or only output to files.      ","Q_Votes":"63"},{"Q_Title":"Best way to generate xml? [duplicate]","A_Content":"  Use lxml.builder class, from: http://lxml.de/tutorial.html#the-e-factory  import lxml.builder as lb from lxml import etree  nstext = \"new story\" story = lb.E.Asset(   lb.E.Attribute(nstext, name=\"Name\", act=\"set\"),   lb.E.Relation(lb.E.Asset(idref=\"Scope:767\"),             name=\"Scope\", act=\"set\")   )  print 'story:\\n', etree.tostring(story, pretty_print=True)   Output:  story: <Asset>   <Attribute name=\"Name\" act=\"set\">new story</Attribute>   <Relation name=\"Scope\" act=\"set\">     <Asset idref=\"Scope:767\"/>   </Relation> </Asset>      ","Language":"Python","Tags":["python","xml","api"],"URL":"https://stackoverflow.com/questions/3844360/best-way-to-generate-xml","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Creating a simple XML file using python                                        5 answers                                          I'm creating an web api and need a good way to very quickly generate some well formatted xml. I cannot find any good way of doing this in python.  Note: Some libraries look promising but either lack documentation or only output to files.      ","Q_Votes":"63"},{"Q_Title":"Best way to generate xml? [duplicate]","A_Content":"  I would use the yattag library. I think it's the most pythonic way:  from yattag import Doc  doc, tag, text = Doc().tagtext()  with tag('food'):     with tag('name'):         text('French Breakfast')     with tag('price', currency='USD'):         text('6.95')     with tag('ingredients'):         for ingredient in ('baguettes', 'jam', 'butter', 'croissants'):             with tag('ingredient'):                 text(ingredient)   print(doc.getvalue())      ","Language":"Python","Tags":["python","xml","api"],"URL":"https://stackoverflow.com/questions/3844360/best-way-to-generate-xml","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Creating a simple XML file using python                                        5 answers                                          I'm creating an web api and need a good way to very quickly generate some well formatted xml. I cannot find any good way of doing this in python.  Note: Some libraries look promising but either lack documentation or only output to files.      ","Q_Votes":"63"},{"Q_Title":"Best way to generate xml? [duplicate]","A_Content":"  An optional way if you want to use pure Python:  ElementTree is good for most cases, but it can't CData and pretty print.  So, if you need CData and pretty print you should use minidom:  minidom_example.py:  from xml.dom import minidom  doc = minidom.Document()  root = doc.createElement('root') doc.appendChild(root)  leaf = doc.createElement('leaf') text = doc.createTextNode('Text element with attributes') leaf.appendChild(text) leaf.setAttribute('color', 'white') root.appendChild(leaf)  leaf_cdata = doc.createElement('leaf_cdata') cdata = doc.createCDATASection('<em>CData</em> can contain <strong>HTML tags</strong> without encoding') leaf_cdata.appendChild(cdata) root.appendChild(leaf_cdata)  branch = doc.createElement('branch') branch.appendChild(leaf.cloneNode(True)) root.appendChild(branch)  mixed = doc.createElement('mixed') mixed_leaf = leaf.cloneNode(True) mixed_leaf.setAttribute('color', 'black') mixed_leaf.setAttribute('state', 'modified') mixed.appendChild(mixed_leaf) mixed_text = doc.createTextNode('Do not use mixed elements if it possible.') mixed.appendChild(mixed_text) root.appendChild(mixed)  xml_str = doc.toprettyxml(indent=\"  \") with open(\"minidom_example.xml\", \"w\") as f:     f.write(xml_str)   minidom_example.xml:  <?xml version=\"1.0\" ?> <root>   <leaf color=\"white\">Text element with attributes</leaf>   <leaf_cdata> <![CDATA[<em>CData</em> can contain <strong>HTML tags</strong> without encoding]]>  </leaf_cdata>   <branch>     <leaf color=\"white\">Text element with attributes</leaf>   </branch>   <mixed>     <leaf color=\"black\" state=\"modified\">Text element with attributes</leaf>     Do not use mixed elements if it possible.   </mixed> </root>      ","Language":"Python","Tags":["python","xml","api"],"URL":"https://stackoverflow.com/questions/3844360/best-way-to-generate-xml","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Creating a simple XML file using python                                        5 answers                                          I'm creating an web api and need a good way to very quickly generate some well formatted xml. I cannot find any good way of doing this in python.  Note: Some libraries look promising but either lack documentation or only output to files.      ","Q_Votes":"63"},{"Q_Title":"Best way to generate xml? [duplicate]","A_Content":"  I've tried a some of the solutions in this thread, and unfortunately, I found some of them to be cumbersome (i.e. requiring excessive effort when doing something non-trivial) and inelegant. Consequently, I thought I'd throw my preferred solution, web2py HTML helper objects, into the mix.   First, install the the standalone web2py module:  pip install web2py   Unfortunately, the above installs an extremely antiquated version of web2py, but it'll be good enough for this example. The updated source is here.  Import web2py HTML helper objects documented here.  from gluon.html import *   Now, you can use web2py helpers to generate XML/HTML.  words = ['this', 'is', 'my', 'item', 'list'] # helper function create_item = lambda idx, word: LI(word, _id = 'item_%s' % idx, _class = 'item') # create the HTML items = [create_item(idx, word) for idx,word in enumerate(words)] ul = UL(items, _id = 'my_item_list', _class = 'item_list') my_div = DIV(ul, _class = 'container')  >>> my_div  <gluon.html.DIV object at 0x00000000039DEAC8>  >>> my_div.xml() # I added the line breaks for clarity <div class=\"container\">    <ul class=\"item_list\" id=\"my_item_list\">       <li class=\"item\" id=\"item_0\">this</li>       <li class=\"item\" id=\"item_1\">is</li>       <li class=\"item\" id=\"item_2\">my</li>       <li class=\"item\" id=\"item_3\">item</li>       <li class=\"item\" id=\"item_4\">list</li>    </ul> </div>      ","Language":"Python","Tags":["python","xml","api"],"URL":"https://stackoverflow.com/questions/3844360/best-way-to-generate-xml","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Creating a simple XML file using python                                        5 answers                                          I'm creating an web api and need a good way to very quickly generate some well formatted xml. I cannot find any good way of doing this in python.  Note: Some libraries look promising but either lack documentation or only output to files.      ","Q_Votes":"63"},{"Q_Title":"How to display full (non-truncated) dataframe information in html when converting from pandas dataframe to html?","A_Content":"  Set the display.max_colwidth option to -1:  pd.set_option('display.max_colwidth', -1)   set_option docs     ","Language":"Python","Tags":["python","html","pandas"],"URL":"https://stackoverflow.com/questions/25351968/how-to-display-full-non-truncated-dataframe-information-in-html-when-convertin","A_Votes":"150","_type":"dict","isAccepted":"Yes","Q_Content":"    I converted a pandas dataframe to an html output using the DataFrame.to_html function. When I save this to a separate html file, the file shows truncated output.  For example, in my TEXT column,   df.head(1) will show   The film was an excellent effort...  instead of   The film was an excellent effort in deconstructing the complex social sentiments that prevailed during this period.  This rendition is fine in the case of a screen-friendly format of a massive pandas dataframe, but I need an html file that will show complete tabular data contained in the dataframe, that is, something that will show the latter text element rather than the former text snippet.   How would I be able to show the complete, non-truncated text data for each element in my TEXT column in the html version of the information? I would imagine that the html table would have to display long cells to show the complete data, but as far as I understand, only column-width parameters can be passed into the DataFrame.to_html function.     ","Q_Votes":"63"},{"Q_Title":"How to display full (non-truncated) dataframe information in html when converting from pandas dataframe to html?","A_Content":"  pd.set_option('display.max_columns', None)     id (second argument) can fully show the columns.      ","Language":"Python","Tags":["python","html","pandas"],"URL":"https://stackoverflow.com/questions/25351968/how-to-display-full-non-truncated-dataframe-information-in-html-when-convertin","A_Votes":"44","_type":"dict","isAccepted":"No","Q_Content":"    I converted a pandas dataframe to an html output using the DataFrame.to_html function. When I save this to a separate html file, the file shows truncated output.  For example, in my TEXT column,   df.head(1) will show   The film was an excellent effort...  instead of   The film was an excellent effort in deconstructing the complex social sentiments that prevailed during this period.  This rendition is fine in the case of a screen-friendly format of a massive pandas dataframe, but I need an html file that will show complete tabular data contained in the dataframe, that is, something that will show the latter text element rather than the former text snippet.   How would I be able to show the complete, non-truncated text data for each element in my TEXT column in the html version of the information? I would imagine that the html table would have to display long cells to show the complete data, but as far as I understand, only column-width parameters can be passed into the DataFrame.to_html function.     ","Q_Votes":"63"},{"Q_Title":"How to display full (non-truncated) dataframe information in html when converting from pandas dataframe to html?","A_Content":"  While pd.set_option('display.max_columns', None) sets the number of the maximum columns shown, the option pd.set_option('display.max_colwidth', -1) sets the maximum width of each single field.  For my purposes I wrote a small helper function to fully print huge data frames without affecting the rest of the code, it also reformats float numbers and sets the virtual display width. You may adopt it for your use cases.  def print_full(x):     pd.set_option('display.max_rows', len(x))     pd.set_option('display.max_columns', None)     pd.set_option('display.width', 2000)     pd.set_option('display.float_format', '{:20,.2f}'.format)     pd.set_option('display.max_colwidth', -1)     print(x)     pd.reset_option('display.max_rows')     pd.reset_option('display.max_columns')     pd.reset_option('display.width')     pd.reset_option('display.float_format')     pd.reset_option('display.max_colwidth')      ","Language":"Python","Tags":["python","html","pandas"],"URL":"https://stackoverflow.com/questions/25351968/how-to-display-full-non-truncated-dataframe-information-in-html-when-convertin","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I converted a pandas dataframe to an html output using the DataFrame.to_html function. When I save this to a separate html file, the file shows truncated output.  For example, in my TEXT column,   df.head(1) will show   The film was an excellent effort...  instead of   The film was an excellent effort in deconstructing the complex social sentiments that prevailed during this period.  This rendition is fine in the case of a screen-friendly format of a massive pandas dataframe, but I need an html file that will show complete tabular data contained in the dataframe, that is, something that will show the latter text element rather than the former text snippet.   How would I be able to show the complete, non-truncated text data for each element in my TEXT column in the html version of the information? I would imagine that the html table would have to display long cells to show the complete data, but as far as I understand, only column-width parameters can be passed into the DataFrame.to_html function.     ","Q_Votes":"63"},{"Q_Title":"I want to exception handle 'list index out of range.'","A_Content":"  Handling the exception is the way to go:  try:     gotdata = dlist[1] except IndexError:     gotdata = 'null'   Of course you could also check the len() of dlist; but handling the exception is more intuitive.     ","Language":"Python","Tags":["python","list","exception-handling"],"URL":"https://stackoverflow.com/questions/11902458/i-want-to-exception-handle-list-index-out-of-range","A_Votes":"153","_type":"dict","isAccepted":"Yes","Q_Content":"    I am using BeautifulSoup and parsing some HTMLs.  I'm getting a certain data from each HTML (using for loop) and adding that data to a certain list.  The problem is, some of the HTMLs have different format (and they don't have the data that I want in them).  So, I was trying to use exception handling and add value null to the list (I should do this since the sequence of data is important.)  For instance, I have a code like:  soup = BeautifulSoup(links) dlist = soup.findAll('dd', 'title') # I'm trying to find content between <dd class='title'> and </dd> gotdata = dlist[1] # and what i want is the 2nd content of those newlist.append(gotdata) # and I add that to a newlist   and some of the links don't have any <dd class='title'>, so what I want to do is add string null to the list instead.  The error appears:   list index out of range.   What I have done tried is to add some lines like this:  if not dlist[1]:      newlist.append('null')    continue   But it doesn't work out. It still shows error:  list index out of range.   What should I do about this? Should I use exception handling? or is there any easier way?  Any suggestions? Any help would be really great!     ","Q_Votes":"63"},{"Q_Title":"I want to exception handle 'list index out of range.'","A_Content":"  You have two options; either handle the exception or test the length:  if len(dlist) > 1:     newlist.append(dlist[1])     continue   or  try:     newlist.append(dlist[1]) except IndexError:     pass continue   Use the first if there often is no second item, the second if there sometimes is no second item.     ","Language":"Python","Tags":["python","list","exception-handling"],"URL":"https://stackoverflow.com/questions/11902458/i-want-to-exception-handle-list-index-out-of-range","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I am using BeautifulSoup and parsing some HTMLs.  I'm getting a certain data from each HTML (using for loop) and adding that data to a certain list.  The problem is, some of the HTMLs have different format (and they don't have the data that I want in them).  So, I was trying to use exception handling and add value null to the list (I should do this since the sequence of data is important.)  For instance, I have a code like:  soup = BeautifulSoup(links) dlist = soup.findAll('dd', 'title') # I'm trying to find content between <dd class='title'> and </dd> gotdata = dlist[1] # and what i want is the 2nd content of those newlist.append(gotdata) # and I add that to a newlist   and some of the links don't have any <dd class='title'>, so what I want to do is add string null to the list instead.  The error appears:   list index out of range.   What I have done tried is to add some lines like this:  if not dlist[1]:      newlist.append('null')    continue   But it doesn't work out. It still shows error:  list index out of range.   What should I do about this? Should I use exception handling? or is there any easier way?  Any suggestions? Any help would be really great!     ","Q_Votes":"63"},{"Q_Title":"I want to exception handle 'list index out of range.'","A_Content":"  A ternary will suffice. change:  gotdata = dlist[1]   to  gotdata = dlist[1] if len(dlist) > 1 else 'null'   this is a short hand for  if len(dlist) > 1:     gotdata = dlist[1] else:      gotdata = 'null'      ","Language":"Python","Tags":["python","list","exception-handling"],"URL":"https://stackoverflow.com/questions/11902458/i-want-to-exception-handle-list-index-out-of-range","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I am using BeautifulSoup and parsing some HTMLs.  I'm getting a certain data from each HTML (using for loop) and adding that data to a certain list.  The problem is, some of the HTMLs have different format (and they don't have the data that I want in them).  So, I was trying to use exception handling and add value null to the list (I should do this since the sequence of data is important.)  For instance, I have a code like:  soup = BeautifulSoup(links) dlist = soup.findAll('dd', 'title') # I'm trying to find content between <dd class='title'> and </dd> gotdata = dlist[1] # and what i want is the 2nd content of those newlist.append(gotdata) # and I add that to a newlist   and some of the links don't have any <dd class='title'>, so what I want to do is add string null to the list instead.  The error appears:   list index out of range.   What I have done tried is to add some lines like this:  if not dlist[1]:      newlist.append('null')    continue   But it doesn't work out. It still shows error:  list index out of range.   What should I do about this? Should I use exception handling? or is there any easier way?  Any suggestions? Any help would be really great!     ","Q_Votes":"63"},{"Q_Title":"I want to exception handle 'list index out of range.'","A_Content":"  Taking reference of ThiefMaster♦ sometimes we get an error with value given as '\\n' or null and perform for that required to handle ValueError:  Handling the exception is the way to go  try:     gotdata = dlist[1] except (IndexError, ValueError):     gotdata = 'null'      ","Language":"Python","Tags":["python","list","exception-handling"],"URL":"https://stackoverflow.com/questions/11902458/i-want-to-exception-handle-list-index-out-of-range","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am using BeautifulSoup and parsing some HTMLs.  I'm getting a certain data from each HTML (using for loop) and adding that data to a certain list.  The problem is, some of the HTMLs have different format (and they don't have the data that I want in them).  So, I was trying to use exception handling and add value null to the list (I should do this since the sequence of data is important.)  For instance, I have a code like:  soup = BeautifulSoup(links) dlist = soup.findAll('dd', 'title') # I'm trying to find content between <dd class='title'> and </dd> gotdata = dlist[1] # and what i want is the 2nd content of those newlist.append(gotdata) # and I add that to a newlist   and some of the links don't have any <dd class='title'>, so what I want to do is add string null to the list instead.  The error appears:   list index out of range.   What I have done tried is to add some lines like this:  if not dlist[1]:      newlist.append('null')    continue   But it doesn't work out. It still shows error:  list index out of range.   What should I do about this? Should I use exception handling? or is there any easier way?  Any suggestions? Any help would be really great!     ","Q_Votes":"63"},{"Q_Title":"I want to exception handle 'list index out of range.'","A_Content":"  for i in range (1, len(list))     try:         print (list[i])      except ValueError:         print(\"Error Value.\")     except indexError:         print(\"Erorr index\")     except :         print('error ')      ","Language":"Python","Tags":["python","list","exception-handling"],"URL":"https://stackoverflow.com/questions/11902458/i-want-to-exception-handle-list-index-out-of-range","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am using BeautifulSoup and parsing some HTMLs.  I'm getting a certain data from each HTML (using for loop) and adding that data to a certain list.  The problem is, some of the HTMLs have different format (and they don't have the data that I want in them).  So, I was trying to use exception handling and add value null to the list (I should do this since the sequence of data is important.)  For instance, I have a code like:  soup = BeautifulSoup(links) dlist = soup.findAll('dd', 'title') # I'm trying to find content between <dd class='title'> and </dd> gotdata = dlist[1] # and what i want is the 2nd content of those newlist.append(gotdata) # and I add that to a newlist   and some of the links don't have any <dd class='title'>, so what I want to do is add string null to the list instead.  The error appears:   list index out of range.   What I have done tried is to add some lines like this:  if not dlist[1]:      newlist.append('null')    continue   But it doesn't work out. It still shows error:  list index out of range.   What should I do about this? Should I use exception handling? or is there any easier way?  Any suggestions? Any help would be really great!     ","Q_Votes":"63"},{"Q_Title":"I want to exception handle 'list index out of range.'","A_Content":"  for any one interested in a shorter way:  gotdata = len(dlist)>1 and dlist[1] or 'null'   But for best performance, I suggest using False instead of 'null', then a one line test will suffice:  gotdata = len(dlist)>1 and dlist[1]      ","Language":"Python","Tags":["python","list","exception-handling"],"URL":"https://stackoverflow.com/questions/11902458/i-want-to-exception-handle-list-index-out-of-range","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am using BeautifulSoup and parsing some HTMLs.  I'm getting a certain data from each HTML (using for loop) and adding that data to a certain list.  The problem is, some of the HTMLs have different format (and they don't have the data that I want in them).  So, I was trying to use exception handling and add value null to the list (I should do this since the sequence of data is important.)  For instance, I have a code like:  soup = BeautifulSoup(links) dlist = soup.findAll('dd', 'title') # I'm trying to find content between <dd class='title'> and </dd> gotdata = dlist[1] # and what i want is the 2nd content of those newlist.append(gotdata) # and I add that to a newlist   and some of the links don't have any <dd class='title'>, so what I want to do is add string null to the list instead.  The error appears:   list index out of range.   What I have done tried is to add some lines like this:  if not dlist[1]:      newlist.append('null')    continue   But it doesn't work out. It still shows error:  list index out of range.   What should I do about this? Should I use exception handling? or is there any easier way?  Any suggestions? Any help would be really great!     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  imshow() only works with waitKey():  import cv2 img = cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow', img) cv2.waitKey()   (The whole message-loop necessary for updating the window is hidden in there.)     ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"141","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  I found the answer that worked for me here: http://txt.arboreus.com/2012/07/11/highgui-opencv-window-from-ipython.html     If you run an interactive ipython session, and want to use highgui   windows, do cv2.startWindowThread() first.      In detail: HighGUI is a simplified interface to display images and   video from OpenCV code. It should be as easy as:   import cv2 img = cv2.imread(\"image.jpg\") cv2.startWindowThread() cv2.namedWindow(\"preview\") cv2.imshow(\"preview\", img)      ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  You must use cv2.waitKey(0) after cv2.imshow(\"window\",img). Only then will it work.  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('Window',img) cv2.waitKey(0)      ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  I faced the same issue. I tried to read an image from IDLE and tried to display it using cv2.imshow(), but the display window freezes and shows pythonw.exe is not responding when trying to close the window.  The post below gives a possible explanation for why this is happening  pythonw.exe is not responding  \"Basically, don't do this from IDLE. Write a script and run it from the shell or the script directly if in windows, by naming it with a .pyw extension and double clicking it. There is apparently a conflict between IDLE's own event loop and the ones from GUI toolkits.\"  When I used imshow() in a script and execute it rather than running it directly over IDLE, it worked.      ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  You've got all the necessary pieces somewhere in this thread:  if cv2.waitKey(): cv2.destroyAllWindows()   works fine for me in IDLE.     ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  I had similar-ish problem and solved it by removing  import gtk, pygtk  # remove these   I'm using Linux so it might be that too gtk won't work. I was going to use it to get the screen size to put two shown images nicely side by side, but I guess I have to figure another way to do that. Hardcoded it 1920x1080 for now..     ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  add cv2.waitKey(0) in the end.     ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  If you have not made this working, you better put  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('Window',img) cv2.waitKey(0)   into one file and run it.     ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  If you choose to use \"cv2.waitKey(0)\", be sure that you have written \"cv2.waitKey(0)\" instead of \"cv2.waitkey(0)\", because that lowercase \"k\" might freeze your program too.     ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  If you are running python console, do this:  img = cv2.imread(\"yourimage.jpg\")  cv2.imshow(\"img\", img); cv2.waitKey(0); cv2.destroyAllWindows()  Then if you press Enter on the image, it will successfully close the image and you can proceed running other commands.     ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  I was using openCV with pyplot and was able to get the image to render in jupyter's current window using pyplots imshow and show.      import matplotlib.pyplot as plt     import matplotlib.image as mpimg      # First, we need to read in an image     image = mpimg.imread('my_image.jpg')     plt.imshow(image)      # then using openCV's algorithms on the image, e.g. grey scale     import cv2      gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) #grayscale conversion      # finally output the result through pyplot in the current window     plt.imshow(gray, cmap='gray')     plt.show()      ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"cv2.imshow command doesn't work properly in opencv-python","A_Content":"  error: (-215) size.width>0 && size.height>0 in function imshow  This error is produced because the image is not found. So it's not an error of imshow function.     ","Language":"Python","Tags":["python","opencv","image-processing"],"URL":"https://stackoverflow.com/questions/21810452/cv2-imshow-command-doesnt-work-properly-in-opencv-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I'm using opencv 2.4.2, python 2.7 The following simple code created a window of the correct name, but its content is just blank and doesn't show the image:  import cv2 img=cv2.imread('C:/Python27/03323_HD.jpg') cv2.imshow('ImageWindow',img)   does anyone knows about this issue?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  Do you happen to have the Perl pip lying around somewhere?  Sounds like the problem described here:  https://github.com/mike-perdide/gitbuster/issues/62  To check, in Windows command prompt execute:  C:\\>where pip   This will potentially output the following:  C:\\strawberry\\perl\\bin\\pip C:\\strawberry\\perl\\bin\\pip.bat   If so, this is your problem. Unistall Strawberry Perl or use the full path to python pip.     ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"156","_type":"dict","isAccepted":"Yes","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  Had the same problem under Ubuntu and did:  $ sudo apt-get remove pip $ sudo apt-get install python-pip      ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  This error is because the system is finding pip.bat before it finds pip.exe.  You do NOT need to uninstall Strawberry Perl or type the whole path.  What I do is to simply type pip.exe (same number of keystrokes as apt-get) when I want to use the Python utility.  This method seems to work find for me on Win7 with Python(x,y) 2.7x and Strawberry Perl installed.     ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  In addition to the very helpful nswer of Johannes: If you don't want to uninstalll Strawberry, you can re-arrange the order of PATH entrys in your Windows system to ensure your Python\\Scripts are found before the strawberry entries. If you don't want to do this manually, you can use tools like the \"Rapid Environment Editor\".      ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  You can also solve this problem without removing Strawberry Perl or type the whole path.Move to this C:\\Python2.7\\Scripts(your Python directory) directory,then use pip command.     ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  You should provide path in environment variable for pip.exe file   while executing install command you should use below command  pip.exe install selenium    This will surely work, for me this worked :)     ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  I had this problem as well, and like Johannes said, it's because the perl pip is interfering with your Python pip.  To get around it, you can simply do this as well:    python -m pip install <package_name>     ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  For Python 3.X and above:  In the CMD prompt type:   py -m pip install  <package_name>   Make sure pip is installed already.  Setup the environment variable for pip pointing to the exe file  To upgrade:   py -m pip install --upgrade pip      ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  Same issue with DwimPerl. Uninstalling Dwim fixed the issue as well.     ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"pip on Windows giving the error - Unknown or unsupported command 'install'","A_Content":"  C:\\Python27\\Scripts\\pip.exe install -U selenium     ","Language":"Python","Tags":["python","selenium","pip"],"URL":"https://stackoverflow.com/questions/7469361/pip-on-windows-giving-the-error-unknown-or-unsupported-command-install","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I installed pip on Windows by downloading http://pypi.python.org/packages/source/p/pip/pip-1.0.2.tar.gz#md5=47ec6ff3f6d962696fe08d4c8264ad49 and running python setup.py install  Installation went fine with no errors.  But when I tried installing selenium package with it, it gives me the following error -  pip install -U selenium Unknown option: u Unknown or unsupported command 'install'   Where I'm making the mistake?     ","Q_Votes":"63"},{"Q_Title":"ImportError: no module named win32api","A_Content":"  This is resolve my case as found on  Where to find the win32api module for Python?  pip install pypiwin32      ","Language":"Python","Tags":["python","winapi"],"URL":"https://stackoverflow.com/questions/21343774/importerror-no-module-named-win32api","A_Votes":"148","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 2.7 and I want to use pywin32-214 on Windows 7. I installed pywin32-214 by using the msi installer. But when I import win32api in my Python script, it throws the error:  no module named win32api.    What should I do? Can I use pywin32 api for Windows 7?     ","Q_Votes":"63"},{"Q_Title":"ImportError: no module named win32api","A_Content":"  I had an identical problem, which I solved by restarting my Python editor and shell. I had installed pywin32 but the new modules were not picked up until the restarts.  If you've already done that, do a search in your Python installation for win32api and you should find win32api.pyd under ${PYTHON_HOME}\\Lib\\site-packages\\win32.     ","Language":"Python","Tags":["python","winapi"],"URL":"https://stackoverflow.com/questions/21343774/importerror-no-module-named-win32api","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 2.7 and I want to use pywin32-214 on Windows 7. I installed pywin32-214 by using the msi installer. But when I import win32api in my Python script, it throws the error:  no module named win32api.    What should I do? Can I use pywin32 api for Windows 7?     ","Q_Votes":"63"},{"Q_Title":"ImportError: no module named win32api","A_Content":"  We can solve this problem by installing pypiwin32  Try this command:   pip install pypiwin32      ","Language":"Python","Tags":["python","winapi"],"URL":"https://stackoverflow.com/questions/21343774/importerror-no-module-named-win32api","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 2.7 and I want to use pywin32-214 on Windows 7. I installed pywin32-214 by using the msi installer. But when I import win32api in my Python script, it throws the error:  no module named win32api.    What should I do? Can I use pywin32 api for Windows 7?     ","Q_Votes":"63"},{"Q_Title":"ImportError: no module named win32api","A_Content":"  According to pywin32 github you must run       pip install pywin32   and after that, you must run      python Scripts/pywin32_postinstall.py -install   I know I'm reviving an old thread, but I just had this problem and this was the only way to solve it.     ","Language":"Python","Tags":["python","winapi"],"URL":"https://stackoverflow.com/questions/21343774/importerror-no-module-named-win32api","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 2.7 and I want to use pywin32-214 on Windows 7. I installed pywin32-214 by using the msi installer. But when I import win32api in my Python script, it throws the error:  no module named win32api.    What should I do? Can I use pywin32 api for Windows 7?     ","Q_Votes":"63"},{"Q_Title":"ImportError: no module named win32api","A_Content":"  Open command prompt in windows and type following    pip install pypiwin32     ","Language":"Python","Tags":["python","winapi"],"URL":"https://stackoverflow.com/questions/21343774/importerror-no-module-named-win32api","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 2.7 and I want to use pywin32-214 on Windows 7. I installed pywin32-214 by using the msi installer. But when I import win32api in my Python script, it throws the error:  no module named win32api.    What should I do? Can I use pywin32 api for Windows 7?     ","Q_Votes":"63"},{"Q_Title":"ImportError: no module named win32api","A_Content":"  I solved it by installing the module pypiwin32:  pip install pypiwin32      ","Language":"Python","Tags":["python","winapi"],"URL":"https://stackoverflow.com/questions/21343774/importerror-no-module-named-win32api","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 2.7 and I want to use pywin32-214 on Windows 7. I installed pywin32-214 by using the msi installer. But when I import win32api in my Python script, it throws the error:  no module named win32api.    What should I do? Can I use pywin32 api for Windows 7?     ","Q_Votes":"63"},{"Q_Title":"ImportError: no module named win32api","A_Content":"  I didn't find the package of the most voted answer in my Python 3 dist.  I had the same problem and solved it installing the module pywin32:  In a normal python:  pip install pywin32   In anaconda:  conda install pywin32   My python installation (Intel® Distribution for Python) had some kind of dependency problem and was giving this error. After installing this module it stopped appearing.     ","Language":"Python","Tags":["python","winapi"],"URL":"https://stackoverflow.com/questions/21343774/importerror-no-module-named-win32api","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 2.7 and I want to use pywin32-214 on Windows 7. I installed pywin32-214 by using the msi installer. But when I import win32api in my Python script, it throws the error:  no module named win32api.    What should I do? Can I use pywin32 api for Windows 7?     ","Q_Votes":"63"},{"Q_Title":"ImportError: no module named win32api","A_Content":"  using pypiwin32 I was able to install win32api  pip install pypiwin32        ","Language":"Python","Tags":["python","winapi"],"URL":"https://stackoverflow.com/questions/21343774/importerror-no-module-named-win32api","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 2.7 and I want to use pywin32-214 on Windows 7. I installed pywin32-214 by using the msi installer. But when I import win32api in my Python script, it throws the error:  no module named win32api.    What should I do? Can I use pywin32 api for Windows 7?     ","Q_Votes":"63"},{"Q_Title":"Specify format for input arguments argparse python","A_Content":"  Per the documentation:     The type keyword argument of add_argument() allows any necessary type-checking and type conversions to be performed ... type= can take any callable that takes a single string argument and returns the converted value   You could do something like:  def valid_date(s):     try:         return datetime.strptime(s, \"%Y-%m-%d\")     except ValueError:         msg = \"Not a valid date: '{0}'.\".format(s)         raise argparse.ArgumentTypeError(msg)   Then use that as type:  parser.add_argument(\"-s\",                      \"--startdate\",                      help=\"The Start Date - format YYYY-MM-DD\",                      required=True,                      type=valid_date)      ","Language":"Python","Tags":["python","python-2.7","argparse"],"URL":"https://stackoverflow.com/questions/25470844/specify-format-for-input-arguments-argparse-python","A_Votes":"164","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a python script that requires some command line inputs and I am using argparse for parsing them. I found the documentation a bit confusing and couldn't find a way to check for a format in the input parameters. What I mean by checking format is explained with this example script:  parser.add_argument('-s', \"--startdate\", help=\"The Start Date - format YYYY-MM-DD \", required=True) parser.add_argument('-e', \"--enddate\", help=\"The End Date format YYYY-MM-DD (Inclusive)\", required=True) parser.add_argument('-a', \"--accountid\", type=int, help='Account ID for the account for which data is required (Default: 570)') parser.add_argument('-o', \"--outputpath\", help='Directory where output needs to be stored (Default: ' + os.path.dirname(os.path.abspath(__file__)))   I need to check for option -s and -e that the input by the user is in the format YYYY-MM-DD. Is there an option in argparse that I do not know of which accomplishes this.     ","Q_Votes":"63"},{"Q_Title":"Specify format for input arguments argparse python","A_Content":"  Just to add on to the answer above, you can use a lambda function if you want to keep it to a one-liner. For example:  parser.add_argument('--date', type=lambda d: datetime.strptime(d, '%Y%m%d'))   Old thread but the question was still relevant for me at least!     ","Language":"Python","Tags":["python","python-2.7","argparse"],"URL":"https://stackoverflow.com/questions/25470844/specify-format-for-input-arguments-argparse-python","A_Votes":"48","_type":"dict","isAccepted":"No","Q_Content":"    I have a python script that requires some command line inputs and I am using argparse for parsing them. I found the documentation a bit confusing and couldn't find a way to check for a format in the input parameters. What I mean by checking format is explained with this example script:  parser.add_argument('-s', \"--startdate\", help=\"The Start Date - format YYYY-MM-DD \", required=True) parser.add_argument('-e', \"--enddate\", help=\"The End Date format YYYY-MM-DD (Inclusive)\", required=True) parser.add_argument('-a', \"--accountid\", type=int, help='Account ID for the account for which data is required (Default: 570)') parser.add_argument('-o', \"--outputpath\", help='Directory where output needs to be stored (Default: ' + os.path.dirname(os.path.abspath(__file__)))   I need to check for option -s and -e that the input by the user is in the format YYYY-MM-DD. Is there an option in argparse that I do not know of which accomplishes this.     ","Q_Votes":"63"},{"Q_Title":"Specify format for input arguments argparse python","A_Content":"  For others who hit this via search engines: in Python 3.7, you can use the standard .fromisoformat class method instead of reinventing the wheel for ISO-8601 compliant dates, e.g.:  parser.add_argument('-s', \"--startdate\",     help=\"The Start Date - format YYYY-MM-DD\",     required=True,     type=datetime.date.fromisoformat) parser.add_argument('-e', \"--enddate\",     help=\"The End Date format YYYY-MM-DD (Inclusive)\",     required=True,     type=datetime.date.fromisoformat)      ","Language":"Python","Tags":["python","python-2.7","argparse"],"URL":"https://stackoverflow.com/questions/25470844/specify-format-for-input-arguments-argparse-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a python script that requires some command line inputs and I am using argparse for parsing them. I found the documentation a bit confusing and couldn't find a way to check for a format in the input parameters. What I mean by checking format is explained with this example script:  parser.add_argument('-s', \"--startdate\", help=\"The Start Date - format YYYY-MM-DD \", required=True) parser.add_argument('-e', \"--enddate\", help=\"The End Date format YYYY-MM-DD (Inclusive)\", required=True) parser.add_argument('-a', \"--accountid\", type=int, help='Account ID for the account for which data is required (Default: 570)') parser.add_argument('-o', \"--outputpath\", help='Directory where output needs to be stored (Default: ' + os.path.dirname(os.path.abspath(__file__)))   I need to check for option -s and -e that the input by the user is in the format YYYY-MM-DD. Is there an option in argparse that I do not know of which accomplishes this.     ","Q_Votes":"63"},{"Q_Title":"Getting distance between two points based on latitude/longitude","A_Content":"  It's because in Python, all the trig functions use radians, not degrees.  You can either convert the numbers manually to radians, or use the radians function from the math module:  from math import sin, cos, sqrt, atan2, radians  # approximate radius of earth in km R = 6373.0  lat1 = radians(52.2296756) lon1 = radians(21.0122287) lat2 = radians(52.406374) lon2 = radians(16.9251681)  dlon = lon2 - lon1 dlat = lat2 - lat1  a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2 c = 2 * atan2(sqrt(a), sqrt(1 - a))  distance = R * c  print(\"Result:\", distance) print(\"Should be:\", 278.546, \"km\")   The distance is now returning the correct value of 278.545589351 km.     ","Language":"Python","Tags":["python","geocoding","geo","geography"],"URL":"https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude","A_Votes":"98","_type":"dict","isAccepted":"Yes","Q_Content":"    I tried implementing this formula: http://andrew.hedges.name/experiments/haversine/ The aplet does good for the two points I am testing:    Yet my code is not working.  from math import sin, cos, sqrt, atan2  R = 6373.0  lat1 = 52.2296756 lon1 = 21.0122287 lat2 = 52.406374 lon2 = 16.9251681  dlon = lon2 - lon1 dlat = lat2 - lat1 a = (sin(dlat/2))**2 + cos(lat1) * cos(lat2) * (sin(dlon/2))**2 c = 2 * atan2(sqrt(a), sqrt(1-a)) distance = R * c  print \"Result\", distance print \"Should be\", 278.546   The distance it returns is 5447.05546147. Why?     ","Q_Votes":"63"},{"Q_Title":"Getting distance between two points based on latitude/longitude","A_Content":"  Update: 04/2018: Note that Vincenty distance is deprecated since GeoPy version 1.13 - you should use geopy.distance.distance() instead!    The answers above are based on the Haversine formula, which assumes the earth is a sphere, which results in errors of up to about 0.5% (according to help(geopy.distance)). Vincenty distance uses more accurate ellipsoidal models such as WGS-84, and is implemented in geopy. For example,  import geopy.distance  coords_1 = (52.2296756, 21.0122287) coords_2 = (52.406374, 16.9251681)  print geopy.distance.vincenty(coords_1, coords_2).km   will print the distance of 279.352901604 kilometers using the default ellipsoid WGS-84. (You can also choose .miles or one of several other distance units).     ","Language":"Python","Tags":["python","geocoding","geo","geography"],"URL":"https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude","A_Votes":"70","_type":"dict","isAccepted":"No","Q_Content":"    I tried implementing this formula: http://andrew.hedges.name/experiments/haversine/ The aplet does good for the two points I am testing:    Yet my code is not working.  from math import sin, cos, sqrt, atan2  R = 6373.0  lat1 = 52.2296756 lon1 = 21.0122287 lat2 = 52.406374 lon2 = 16.9251681  dlon = lon2 - lon1 dlat = lat2 - lat1 a = (sin(dlat/2))**2 + cos(lat1) * cos(lat2) * (sin(dlon/2))**2 c = 2 * atan2(sqrt(a), sqrt(1-a)) distance = R * c  print \"Result\", distance print \"Should be\", 278.546   The distance it returns is 5447.05546147. Why?     ","Q_Votes":"63"},{"Q_Title":"Getting distance between two points based on latitude/longitude","A_Content":"  For people (like me) coming here via search engine and just looking for a solution which works out of the box, I recommend installing mpu. Install it via pip install mpu --user and use it like this to get the haversine distance:  import mpu  # Point one lat1 = 52.2296756 lon1 = 21.0122287  # Point two lat2 = 52.406374 lon2 = 16.9251681  # What you were looking for dist = mpu.haversine_distance((lat1, lon1), (lat2, lon2)) print(dist)  # gives 278.45817507541943.   An alternative package is gpxpy.  If you don't want dependencies, you can use:  import math   def distance(origin, destination):     \"\"\"     Calculate the Haversine distance.      Parameters     ----------     origin : tuple of float         (lat, long)     destination : tuple of float         (lat, long)      Returns     -------     distance_in_km : float      Examples     --------     >>> origin = (48.1372, 11.5756)  # Munich     >>> destination = (52.5186, 13.4083)  # Berlin     >>> round(distance(origin, destination), 1)     504.2     \"\"\"     lat1, lon1 = origin     lat2, lon2 = destination     radius = 6371  # km      dlat = math.radians(lat2 - lat1)     dlon = math.radians(lon2 - lon1)     a = (math.sin(dlat / 2) * math.sin(dlat / 2) +          math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *          math.sin(dlon / 2) * math.sin(dlon / 2))     c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))     d = radius * c      return d   if __name__ == '__main__':     import doctest     doctest.testmod()      ","Language":"Python","Tags":["python","geocoding","geo","geography"],"URL":"https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude","A_Votes":"47","_type":"dict","isAccepted":"No","Q_Content":"    I tried implementing this formula: http://andrew.hedges.name/experiments/haversine/ The aplet does good for the two points I am testing:    Yet my code is not working.  from math import sin, cos, sqrt, atan2  R = 6373.0  lat1 = 52.2296756 lon1 = 21.0122287 lat2 = 52.406374 lon2 = 16.9251681  dlon = lon2 - lon1 dlat = lat2 - lat1 a = (sin(dlat/2))**2 + cos(lat1) * cos(lat2) * (sin(dlon/2))**2 c = 2 * atan2(sqrt(a), sqrt(1-a)) distance = R * c  print \"Result\", distance print \"Should be\", 278.546   The distance it returns is 5447.05546147. Why?     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  Here's the shortest code that will do the job:  from pandas import DataFrame df = DataFrame(resoverall.fetchall()) df.columns = resoverall.keys()   You can go fancier and parse the types as in Paul's answer.     ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"70","_type":"dict","isAccepted":"Yes","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  Edit: Mar. 2015  As noted below, pandas now uses SQLAlchemy to both read from (read_sql) and insert into (to_sql) a database. The following should work  import pandas as pd  df = pd.read_sql(sql, cnxn)   Previous answer: Via mikebmassey from a similar question  import pyodbc import pandas.io.sql as psql  cnxn = pyodbc.connect(connection_info)  cursor = cnxn.cursor() sql = \"SELECT * FROM TABLE\"  df = psql.frame_query(sql, cnxn) cnxn.close()      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"89","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  If you are using SQLAlchemy's ORM rather than the expression language, you might find yourself wanting to convert an object of type sqlalchemy.orm.query.Query to a Pandas data frame.   The cleanest approach is to get the generated SQL from the query's statement attribute, and then execute it with pandas's read_sql() method. E.g., starting with a Query object called query:  df = pd.read_sql(query.statement, query.session.bind)      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"28","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  Edit 2014-09-30:  pandas now has a read_sql function. You definitely want to use that instead.  Original answer:  I can't help you with SQLAlchemy -- I always use pyodbc, MySQLdb, or psychopg2 as needed. But when doing so, a function as simple as the one below tends to suit my needs:  import decimal  import pydobc import numpy as np import pandas  cnn, cur = myConnectToDBfunction() cmd = \"SELECT * FROM myTable\" cur.execute(cmd) dataframe = __processCursor(cur, dataframe=True)  def __processCursor(cur, dataframe=False, index=None):     '''     Processes a database cursor with data on it into either     a structured numpy array or a pandas dataframe.      input:     cur - a pyodbc cursor that has just received data     dataframe - bool. if false, a numpy record array is returned                 if true, return a pandas dataframe     index - list of column(s) to use as index in a pandas dataframe     '''     datatypes = []     colinfo = cur.description     for col in colinfo:         if col[1] == unicode:             datatypes.append((col[0], 'U%d' % col[3]))         elif col[1] == str:             datatypes.append((col[0], 'S%d' % col[3]))         elif col[1] in [float, decimal.Decimal]:             datatypes.append((col[0], 'f4'))         elif col[1] == datetime.datetime:             datatypes.append((col[0], 'O4'))         elif col[1] == int:             datatypes.append((col[0], 'i4'))      data = []     for row in cur:         data.append(tuple(row))      array = np.array(data, dtype=datatypes)     if dataframe:         output = pandas.DataFrame.from_records(array)          if index is not None:             output = output.set_index(index)      else:         output = array      return output      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  Like Nathan, I often want to dump the results of a sqlalchemy or sqlsoup Query into a Pandas data frame.  My own solution for this is:  query = session.query(tbl.Field1, tbl.Field2) DataFrame(query.all(), columns=[column['name'] for column in query.column_descriptions])      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  Simply use pandas and pyodbc together. You'll have to modify your connection string (connstr) according to your database specifications.  import pyodbc import pandas as pd  # MSSQL Connection String Example connstr = \"Server=myServerAddress;Database=myDB;User Id=myUsername;Password=myPass;\"  # Query Database and Create DataFrame Using Results df = pd.read_sql(\"select * from myTable\", pyodbc.connect(connstr))   I've used pyodbc with several enterprise databases (e.g. SQL Server, MySQL, MariaDB, IBM).     ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  resoverall is a sqlalchemy ResultProxy object. You can read more about it in the sqlalchemy docs, the latter explains basic usage of working with Engines and Connections. Important here is that resoverall is dict like.  Pandas likes dict like objects to create its data structures, see the online docs  Good luck with sqlalchemy and pandas.     ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  This question is old, but I wanted to add my two-cents. I read the question as \" I want to run a query to my [my]SQL database and store the returned data as Pandas data structure [DataFrame].\"  From the code it looks like you mean mysql database and assume you mean pandas DataFrame.  import MySQLdb as mdb import pandas.io.sql as sql from pandas import *  conn = mdb.connect('<server>','<user>','<pass>','<db>'); df = sql.read_frame('<query>', conn)   For example,  conn = mdb.connect('localhost','myname','mypass','testdb'); df = sql.read_frame('select * from testTable', conn)   This will import all rows of testTable into a DataFrame.     ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  MySQL Connector  For those that works with the mysql connector you can use this code as a start. (Thanks to @Daniel Velkov)  Used refs:   Querying Data Using Connector/Python Connecting to MYSQL with Python in 3 steps     import pandas as pd import mysql.connector  # Setup MySQL connection db = mysql.connector.connect(     host=\"<IP>\",              # your host, usually localhost     user=\"<USER>\",            # your username     password=\"<PASS>\",        # your password     database=\"<DATABASE>\"     # name of the data base )     # You must create a Cursor object. It will let you execute all the queries you need cur = db.cursor()  # Use all the SQL you like cur.execute(\"SELECT * FROM <TABLE>\")  # Put it all to a data frame sql_data = pd.DataFrame(cur.fetchall()) sql_data.columns = cur.column_names  # Close the session db.close()  # Show the data print(sql_data.head())      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  Here's the code I use. Hope this helps.  import pandas as pd from sqlalchemy import create_engine  def getData():   # Parameters   ServerName = \"my_server\"   Database = \"my_db\"   UserPwd = \"user:pwd\"   Driver = \"driver=SQL Server Native Client 11.0\"    # Create the connection   engine = create_engine('mssql+pyodbc://' + UserPwd + '@' + ServerName + '/' + Database + \"?\" + Driver)    sql = \"select * from mytable\"   df = pd.read_sql(sql, engine)   return df  df2 = getData() print(df2)      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  This is a short and crisp answer to your problem:  from __future__ import print_function import MySQLdb import numpy as np import pandas as pd import xlrd  # Connecting to MySQL Database connection = MySQLdb.connect(              host=\"hostname\",              port=0000,              user=\"userID\",              passwd=\"password\",              db=\"table_documents\",              charset='utf8'            ) print(connection) #getting data from database into a dataframe sql_for_df = 'select * from tabledata' df_from_database = pd.read_sql(sql_for_df , connection)      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  Long time from last post but maybe it helps someone...  Shorted way than Paul H:  my_dic = session.query(query.all()) my_df = pandas.DataFrame.from_dict(my_dic)      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  best way I do this  db.execute(query) where db=db_class() #database class     mydata=[x for x in db.fetchall()]     df=pd.DataFrame(data=mydata)      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  Here is mine. Just in case if you are using \"pymysql\":  import pymysql from pandas import DataFrame  host   = 'localhost' port   = 3306 user   = 'yourUserName' passwd = 'yourPassword' db     = 'yourDatabase'  cnx    = pymysql.connect(host=host, port=port, user=user, passwd=passwd, db=db) cur    = cnx.cursor()  query  = \"\"\" SELECT * FROM yourTable LIMIT 10\"\"\" cur.execute(query)  field_names = [i[0] for i in cur.description] get_data = [xx for xx in cur]  cur.close() cnx.close()  df = DataFrame(get_data) df.columns = field_names      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert SQL Query result to PANDAS Data Structure?","A_Content":"  If the result type is ResultSet, you should convert it to dictionary first. Then the DataFrame columns will be collected automatically.  This works on my case:  df = pd.DataFrame([dict(r) for r in resoverall])      ","Language":"Python","Tags":["python","mysql","data-structures","pandas"],"URL":"https://stackoverflow.com/questions/12047193/how-to-convert-sql-query-result-to-pandas-data-structure","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Any help on this problem will be greatly appreciated.  So basically I want to run a query to my SQL database and store the returned data as Pandas data structure.  I have attached code for query.  I am reading the documentation on Pandas, but I have problem to identify the return type of my query.  I tried to print the query result, but it doesn't give any useful information.  Thanks!!!!   from sqlalchemy import create_engine  engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING') connection2 = engine2.connect() dataid = 1022 resoverall = connection2.execute(\"   SELECT        sum(BLABLA) AS BLA,       sum(BLABLABLA2) AS BLABLABLA2,       sum(SOME_INT) AS SOME_INT,       sum(SOME_INT2) AS SOME_INT2,       100*sum(SOME_INT2)/sum(SOME_INT) AS ctr,       sum(SOME_INT2)/sum(SOME_INT) AS cpc    FROM daily_report_cooked    WHERE campaign_id = '%s'\", %dataid)   So I sort of want to understand what's the format/datatype of my variable \"resoverall\" and how to put it with PANDAS data structure.     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  In one of the comments, you say:     Somehow I got an Nonetype value, it supposed to be an int, but it's now a Nonetype object   If it's your code, figure out how you're getting None when you expect a number and stop that from happening.  If it's someone else's code, find out the conditions under which it gives None and determine a sensible value to use for that, with the usual conditional code:  result = could_return_none(x)  if result is None:     result = DEFAULT_VALUE   ...or even...  if x == THING_THAT_RESULTS_IN_NONE:     result = DEFAULT_VALUE else:     result = could_return_none(x) # But it won't return None, because we've restricted the domain.   There's no reason to automatically use 0 here — solutions that depend on the \"false\"-ness of None assume you will want this. The DEFAULT_VALUE (if it even exists) completely depends on your code's purpose.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"35","_type":"dict","isAccepted":"Yes","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  int(value or 0)   This will use 0 in the case when you provide any value that Python considers False, such as None, 0, [], \"\", etc. Since 0 is False, you should only use 0 as the alternative value (otherwise you will find your 0s turning into that value).  int(0 if value is None else value)   This replaces only None with 0. Since we are testing for None specifically, you can use some other value as the replacement.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"231","_type":"dict","isAccepted":"No","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  A common \"Pythonic\" way to handle this kind of situation is known as EAFP for \"It's easier to ask forgiveness than permission\". Which usually means writing code that assumes everything is fine, but then wrapping it with a try..except block just in case to handle things when it's not.   Here's that coding style applied to your problem:  try:     my_value = int(my_value) except TypeError:     my_value = 0  # or whatever you want to do  answer = my_value / divisor   Or perhaps the even simpler and slightly faster:  try:     answer = my_value / divisor except TypeError:     answer = 0   The inverse and more traditional approach is known as LBYL which stands for \"Look before you leap\" is what @Soviut and some of the others have suggested. For additional coverage of this topic see my answer and associated comments to the question Determine whether a key is present in a dictionary elsewhere on this site.  One potential problem with EAFP is that it can hide the fact that something is wrong with some other part of your code or third-party module you're using, especially when the exceptions frequently occur (and therefore aren't really \"exceptional\" cases at all).     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  That TypeError only appears when you try to pass int() None (which is the only NoneType value, as far as I know).  I would say that your real goal should not be to convert NoneType to int or str, but to figure out where/why you're getting None instead of a number as expected, and either fix it or handle the None properly.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  I've successfully used int(x or 0) for this type of error, so long as None should equate to 0 in the logic. Note that this will also resolve to 0 in other cases where testing x returns False. e.g. empty list, set, dictionary or zero length string. Sorry, Kindall already gave this answer.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  This can happen if you forget to return a value from a function: it then returns None. Look at all places where you are assigning to that variable, and see if one of them is a function call where the function lacks a return statement.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  You should check to make sure the value is not None before trying to perform any calculations on it:  my_value = None if my_value is not None:     print int(my_value) / 2   Note: my_value was intentionally set to None to prove the code works and that the check is being performed.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  I was having the same problem using the python email functions. Below is the code I was trying to retrieve email subject into a variable.  This works fine for most emails and the variable populates.  If you receive an email from Yahoo or the like and the sender did no fill out the subject line Yahoo does not create a subject line in the email and you get a NoneType returned from the function.  Martineau provided a correct answer as well as Soviut.  IMO Soviut's answer is more concise from a programming stand point; not necessarily from a Python one. Here is some code to show the technique:  import sys, email, email.Utils   afile = open(sys.argv[1], 'r')     m = email.message_from_file(afile)     subject = m[\"subject\"]  # Soviut's Concise test for unset variable.  if subject is None:          subject = \"[NO SUBJECT]\"  # Alternative way to test for No Subject created in email (Thanks for NoneThing Yahoo!)  try:         if len(subject) == 0:             subject = \"[NO SUBJECT]\"  except TypeError:         subject = \"[NO SUBJECT]\"  print subject  afile.close()      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  In some situations it is helpful to have a function to convert None to int zero:  def nz(value):      '''     Convert None to int zero else return value.     '''      if value == None:         return 0     return value      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"How to convert Nonetype to int or string?","A_Content":"  In Python 3 you can use the \"or\" keyword too. This way:  foo = bar or 0 foo2 = bar or \"\"      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3930188/how-to-convert-nonetype-to-int-or-string","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I've got an Nonetype value x, it's generally a number, but could be None. I want to divide it by a number, but Python raises:  TypeError: int() argument must be a string or a number, not 'NoneType'   How can I solve this?     ","Q_Votes":"63"},{"Q_Title":"Why can't I use a list as a dict key in python?","A_Content":"  There's a good article on the topic in the Python wiki: Why Lists Can't Be Dictionary Keys. As explained there:     What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?   It can be done without really breaking any of the requirements, but it leads to unexpected behavior. Lists are generally treated as if their value was derived from their content's values, for instance when checking (in-)equality. Many would - understandably - expect that you can use any list [1, 2] to get the same key, where you'd have to keep around exactly the same list object. But lookup by value breaks as soon as a list used as key is modified, and for lookup by identity requires you to keep around exactly the same list - which isn't requires for any other common list operation (at least none I can think of).  Other objects such as modules and object make a much bigger deal out of their object identity anyway (when was the last time you had two distinct module objects called sys?), and are compared by that anyway. Therefore, it's less surprising - or even expected - that they, when used as dict keys, compare by identity in that case as well.     ","Language":"Python","Tags":["python","list","dictionary","tuples","hashable"],"URL":"https://stackoverflow.com/questions/7257588/why-cant-i-use-a-list-as-a-dict-key-in-python","A_Votes":"21","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm a bit confused about what can/can't be used as a key for a python dict.    dicked = {} dicked[None] = 'foo'     # None ok dicked[(1,3)] = 'baz'    # tuple ok import sys dicked[sys] = 'bar'      # wow, even a module is ok ! dicked[(1,[3])] = 'qux'  # oops, not allowed   So a tuple is an immutable type but if I hide a list inside of it, then it can't be a key.. couldn't I just as easily hide a list inside a module?  I had some vague idea that that the key has to be \"hashable\" but I'm just going to admit my own ignorance about the technical details; I don't know what's really going on here.  What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?     ","Q_Votes":"64"},{"Q_Title":"Why can't I use a list as a dict key in python?","A_Content":"  Why can't I use a list as a dict key in python?  >>> d = {repr([1,2,3]): 'value'} {'[1, 2, 3]': 'value'}   (for anybody who stumbles on this question looking for a way around it)  as explained by others here, indeed you cannot. You can however use its string representation instead if you really want to use your list.     ","Language":"Python","Tags":["python","list","dictionary","tuples","hashable"],"URL":"https://stackoverflow.com/questions/7257588/why-cant-i-use-a-list-as-a-dict-key-in-python","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I'm a bit confused about what can/can't be used as a key for a python dict.    dicked = {} dicked[None] = 'foo'     # None ok dicked[(1,3)] = 'baz'    # tuple ok import sys dicked[sys] = 'bar'      # wow, even a module is ok ! dicked[(1,[3])] = 'qux'  # oops, not allowed   So a tuple is an immutable type but if I hide a list inside of it, then it can't be a key.. couldn't I just as easily hide a list inside a module?  I had some vague idea that that the key has to be \"hashable\" but I'm just going to admit my own ignorance about the technical details; I don't know what's really going on here.  What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?     ","Q_Votes":"64"},{"Q_Title":"Why can't I use a list as a dict key in python?","A_Content":"  The issue is that tuples are immutable, and lists are not. Consider the following  d = {} li = [1,2,3] d[li] = 5 li.append(4)   What should d[li] return? Is it the same list? How about d[[1,2,3]]? It has the same values, but is a different list?  Ultimately, there is no satisfactory answer. For example, if the only key that works is the original key, then if you have no reference to that key, you can never again access the value. With every other allowed key, you can construct a key without a reference to the original.  If both of my suggestions work, then you have very different keys that return the same value, which is more than a little surprising. If only the original contents work, then your key will quickly go bad, since lists are made to be modified.     ","Language":"Python","Tags":["python","list","dictionary","tuples","hashable"],"URL":"https://stackoverflow.com/questions/7257588/why-cant-i-use-a-list-as-a-dict-key-in-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm a bit confused about what can/can't be used as a key for a python dict.    dicked = {} dicked[None] = 'foo'     # None ok dicked[(1,3)] = 'baz'    # tuple ok import sys dicked[sys] = 'bar'      # wow, even a module is ok ! dicked[(1,[3])] = 'qux'  # oops, not allowed   So a tuple is an immutable type but if I hide a list inside of it, then it can't be a key.. couldn't I just as easily hide a list inside a module?  I had some vague idea that that the key has to be \"hashable\" but I'm just going to admit my own ignorance about the technical details; I don't know what's really going on here.  What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?     ","Q_Votes":"64"},{"Q_Title":"Why can't I use a list as a dict key in python?","A_Content":"  Here's an answer http://wiki.python.org/moin/DictionaryKeys     What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?   Looking up different lists with the same contents would produce different results, even though comparing lists with the same contents would indicate them as equivalent.  What about Using a list literal in a dictionary lookup?     ","Language":"Python","Tags":["python","list","dictionary","tuples","hashable"],"URL":"https://stackoverflow.com/questions/7257588/why-cant-i-use-a-list-as-a-dict-key-in-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I'm a bit confused about what can/can't be used as a key for a python dict.    dicked = {} dicked[None] = 'foo'     # None ok dicked[(1,3)] = 'baz'    # tuple ok import sys dicked[sys] = 'bar'      # wow, even a module is ok ! dicked[(1,[3])] = 'qux'  # oops, not allowed   So a tuple is an immutable type but if I hide a list inside of it, then it can't be a key.. couldn't I just as easily hide a list inside a module?  I had some vague idea that that the key has to be \"hashable\" but I'm just going to admit my own ignorance about the technical details; I don't know what's really going on here.  What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?     ","Q_Votes":"64"},{"Q_Title":"Why can't I use a list as a dict key in python?","A_Content":"  Your awnser can be found here:     Why Lists Can't Be Dictionary Keys      Newcomers to Python often wonder why, while the language includes both   a tuple and a list type, tuples are usable as a dictionary keys, while   lists are not. This was a deliberate design decision, and can best be   explained by first understanding how Python dictionaries work.   Source & more info: http://wiki.python.org/moin/DictionaryKeys     ","Language":"Python","Tags":["python","list","dictionary","tuples","hashable"],"URL":"https://stackoverflow.com/questions/7257588/why-cant-i-use-a-list-as-a-dict-key-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm a bit confused about what can/can't be used as a key for a python dict.    dicked = {} dicked[None] = 'foo'     # None ok dicked[(1,3)] = 'baz'    # tuple ok import sys dicked[sys] = 'bar'      # wow, even a module is ok ! dicked[(1,[3])] = 'qux'  # oops, not allowed   So a tuple is an immutable type but if I hide a list inside of it, then it can't be a key.. couldn't I just as easily hide a list inside a module?  I had some vague idea that that the key has to be \"hashable\" but I'm just going to admit my own ignorance about the technical details; I don't know what's really going on here.  What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?     ","Q_Votes":"64"},{"Q_Title":"Why can't I use a list as a dict key in python?","A_Content":"  The simple answer to your question is that the class list does not implement the method hash which is required for any object which wishes to be used as a key in a dictionary. However the reason why hash is not implemented the same way it is in say the tuple class (based on the content of the container) is because a list is mutable so editing the list would require the hash to be recalculated which may mean the list in now located in the wrong bucket within the underling hash table. Note that since you cannot modify a tuple (immutable) it doesn't run into this problem.   As a side note, the actual implementation of the dictobjects lookup is based on Algorithm D from Knuth Vol. 3, Sec. 6.4. If you have that book available to you it might be a worthwhile read, in addition if you're really, really interested you may like to take a peek at the developer comments on the actual implementation of dictobject here. It goes into great detail as to exactly how it works. There is also a python lecture on the implementation of dictionaries which you may be interested in. They go through the definition of a key and what a hash is in the first few minutes.     ","Language":"Python","Tags":["python","list","dictionary","tuples","hashable"],"URL":"https://stackoverflow.com/questions/7257588/why-cant-i-use-a-list-as-a-dict-key-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm a bit confused about what can/can't be used as a key for a python dict.    dicked = {} dicked[None] = 'foo'     # None ok dicked[(1,3)] = 'baz'    # tuple ok import sys dicked[sys] = 'bar'      # wow, even a module is ok ! dicked[(1,[3])] = 'qux'  # oops, not allowed   So a tuple is an immutable type but if I hide a list inside of it, then it can't be a key.. couldn't I just as easily hide a list inside a module?  I had some vague idea that that the key has to be \"hashable\" but I'm just going to admit my own ignorance about the technical details; I don't know what's really going on here.  What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?     ","Q_Votes":"64"},{"Q_Title":"Why can't I use a list as a dict key in python?","A_Content":"  Just found you can change List into tuple, then use it as keys.  d = {tuple([1,2,3]): 'value'}      ","Language":"Python","Tags":["python","list","dictionary","tuples","hashable"],"URL":"https://stackoverflow.com/questions/7257588/why-cant-i-use-a-list-as-a-dict-key-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm a bit confused about what can/can't be used as a key for a python dict.    dicked = {} dicked[None] = 'foo'     # None ok dicked[(1,3)] = 'baz'    # tuple ok import sys dicked[sys] = 'bar'      # wow, even a module is ok ! dicked[(1,[3])] = 'qux'  # oops, not allowed   So a tuple is an immutable type but if I hide a list inside of it, then it can't be a key.. couldn't I just as easily hide a list inside a module?  I had some vague idea that that the key has to be \"hashable\" but I'm just going to admit my own ignorance about the technical details; I don't know what's really going on here.  What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?     ","Q_Votes":"64"},{"Q_Title":"Why can't I use a list as a dict key in python?","A_Content":"  According to the Python 2.7.2 documentation:     An object is hashable if it has a hash value which never changes   during its lifetime (it needs a hash() method), and can be   compared to other objects (it needs an eq() or cmp() method).   Hashable objects which compare equal must have the same hash value.      Hashability makes an object usable as a dictionary key and a set   member, because these data structures use the hash value internally.      All of Python’s immutable built-in objects are hashable, while no   mutable containers (such as lists or dictionaries) are. Objects which   are instances of user-defined classes are hashable by default; they   all compare unequal, and their hash value is their id().   A tuple is immutable in the sense that you cannot add, remove or replace its elements, but the elements themselves may be mutable. List's hash value depends on the hash values of its elements, and so it changes when you change the elements.  Using id's for list hashes would imply that all lists compare differently, which would be surprising and inconvenient.     ","Language":"Python","Tags":["python","list","dictionary","tuples","hashable"],"URL":"https://stackoverflow.com/questions/7257588/why-cant-i-use-a-list-as-a-dict-key-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm a bit confused about what can/can't be used as a key for a python dict.    dicked = {} dicked[None] = 'foo'     # None ok dicked[(1,3)] = 'baz'    # tuple ok import sys dicked[sys] = 'bar'      # wow, even a module is ok ! dicked[(1,[3])] = 'qux'  # oops, not allowed   So a tuple is an immutable type but if I hide a list inside of it, then it can't be a key.. couldn't I just as easily hide a list inside a module?  I had some vague idea that that the key has to be \"hashable\" but I'm just going to admit my own ignorance about the technical details; I don't know what's really going on here.  What would go wrong if you tried to use lists as keys, with the hash as, say, their memory location?     ","Q_Votes":"64"},{"Q_Title":"Should I use encoding declaration in Python 3?","A_Content":"  Because the default is UTF-8, you only need to use that declaration when you deviate from the default, or if you rely on other tools (like your IDE or text editor) to make use of that information.  In other words, as far as Python is concerned, only when you want to use an encoding that differs do you have to use that declaration.  Other tools, such as your editor, can support similar syntax, which is why the PEP 263 specification allows for considerable flexibility in the syntax (it must be a comment, the text coding must be there, followed by either a : or = character and optional whitespace, followed by a recognised codec).  Note that it only applies to how Python reads the source code. It doesn't apply to executing that code, so not to how printing, opening files, or any other I/O operations translate between bytes and Unicode. For more details on Python, Unicode, and encodings, I strongly urge you to read the Python Unicode HOWTO, or the  very thorough Pragmatic Unicode talk by Ned Batchelder.     ","Language":"Python","Tags":["python","python-3.x","encoding","utf-8"],"URL":"https://stackoverflow.com/questions/14083111/should-i-use-encoding-declaration-in-python-3","A_Votes":"66","_type":"dict","isAccepted":"Yes","Q_Content":"    Python 3 uses UTF-8 encoding for source-code files by default. Should I still use the encoding declaration at the beginning of every source file? Like # -*- coding: utf-8 -*-     ","Q_Votes":"64"},{"Q_Title":"Python string interning","A_Content":"  This is implementation-specific, but your interpreter is probably interning compile-time constants but not the results of run-time expressions.  In what follows I use CPython 2.7.3.  In the second example, the expression \"strin\"+\"g\" is evaluated at compile time, and is replaced with \"string\". This makes the first two examples behave the same.  If we examine the bytecodes, we'll see that they are exactly the same:    # s1 = \"string\"   2           0 LOAD_CONST               1 ('string')               3 STORE_FAST               0 (s1)    # s2 = \"strin\" + \"g\"   3           6 LOAD_CONST               4 ('string')               9 STORE_FAST               1 (s2)   The third example involves a run-time concatenation, the result of which is not automatically interned:    # s3a = \"strin\"   # s3 = s3a + \"g\"   4          12 LOAD_CONST               2 ('strin')              15 STORE_FAST               2 (s3a)    5          18 LOAD_FAST                2 (s3a)              21 LOAD_CONST               3 ('g')              24 BINARY_ADD                        25 STORE_FAST               3 (s3)              28 LOAD_CONST               0 (None)              31 RETURN_VALUE           If you were to manually intern() the result of the third expression, you'd get the same object as before:  >>> s3a = \"strin\" >>> s3 = s3a + \"g\" >>> s3 is \"string\" False >>> intern(s3) is \"string\" True      ","Language":"Python","Tags":["python","string","internals"],"URL":"https://stackoverflow.com/questions/15541404/python-string-interning","A_Votes":"68","_type":"dict","isAccepted":"Yes","Q_Content":"    While this question doesn't have any real use in practise, I am curious as to how Python does string interning. I have noticed the following.  >> \"string\" is \"string\" >> True   This is as I expected.  You can also do this.  >> \"strin\"+\"g\" is \"string\" >> True   And that's pretty clever!  But you can't do this.  >> s1 = \"strin\" >> s2 = \"string\" >> s1+\"g\" is s2 >> False   Why wouldn't Python evaluate s1+\"g\", realise it is the same as s1 and point it to the same address? What is actually going on in that last block to have it return False?     ","Q_Votes":"64"},{"Q_Title":"Python string interning","A_Content":"  Case 1  >>> x = \"123\"   >>> y = \"123\"   >>> x == y   True   >>> x is y   True   >>> id(x)   50986112   >>> id(y)   50986112     Case 2  >>> x = \"12\" >>> y = \"123\" >>> x = x + \"3\" >>> x is y False >>> x == y True   Now, your question is why the id is same in case 1 and not in case 2. In case 1, you have assigned a string literal \"123\" to x and y.   Since string are immutable, it makes sense for the interpreter to store the string literal only once and point all the variables to the same object. Hence you see the id as identical.  In case 2, you are modifying x using concatenation. Both x and y has same values, but not same identity. Both points to different objects in memory. Hence they have different id and is operator returned False     ","Language":"Python","Tags":["python","string","internals"],"URL":"https://stackoverflow.com/questions/15541404/python-string-interning","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    While this question doesn't have any real use in practise, I am curious as to how Python does string interning. I have noticed the following.  >> \"string\" is \"string\" >> True   This is as I expected.  You can also do this.  >> \"strin\"+\"g\" is \"string\" >> True   And that's pretty clever!  But you can't do this.  >> s1 = \"strin\" >> s2 = \"string\" >> s1+\"g\" is s2 >> False   Why wouldn't Python evaluate s1+\"g\", realise it is the same as s1 and point it to the same address? What is actually going on in that last block to have it return False?     ","Q_Votes":"64"},{"Q_Title":"Why is looping over range() in Python faster than using a while loop?","A_Content":"  see the disassembly of python byte code, you may get a more concrete idea  use while loop:  1           0 LOAD_CONST               0 (0)             3 STORE_NAME               0 (i)  2           6 SETUP_LOOP              28 (to 37)       >>    9 LOAD_NAME                0 (i)              # <-            12 LOAD_CONST               1 (100000000)      # <-            15 COMPARE_OP               0 (<)              # <-            18 JUMP_IF_FALSE           14 (to 35)          # <-            21 POP_TOP                                     # <-  3          22 LOAD_NAME                0 (i)              # <-            25 LOAD_CONST               2 (1)              # <-            28 INPLACE_ADD                                 # <-            29 STORE_NAME               0 (i)              # <-            32 JUMP_ABSOLUTE            9                  # <-       >>   35 POP_TOP            36 POP_BLOCK   The loop body has 10 op  use range:  1           0 SETUP_LOOP              23 (to 26)             3 LOAD_NAME                0 (range)             6 LOAD_CONST               0 (0)             9 LOAD_CONST               1 (100000000)            12 CALL_FUNCTION            2            15 GET_ITER       >>   16 FOR_ITER                 6 (to 25)        # <-            19 STORE_NAME               1 (n)            # <-  2          22 JUMP_ABSOLUTE           16                # <-       >>   25 POP_BLOCK       >>   26 LOAD_CONST               2 (None)            29 RETURN_VALUE   The loop body has 3 op  The time to run C code is much shorter than intepretor and can be ignored.     ","Language":"Python","Tags":["python","performance","benchmarking"],"URL":"https://stackoverflow.com/questions/869229/why-is-looping-over-range-in-python-faster-than-using-a-while-loop","A_Votes":"125","_type":"dict","isAccepted":"Yes","Q_Content":"    The other day I was doing some Python benchmarking and I came across something interesting.  Below are two loops that do more or less the same thing.  Loop 1 takes about twice as long as loop 2 to execute.  Loop 1:  int i = 0 while i < 100000000:   i += 1   Loop 2:  for n in range(0,100000000):   pass   Why is the first loop so much slower?  I know it's a trivial example but it's piqued my interest.  Is there something special about the range() function that makes it more efficient than incrementing a variable the same way?     ","Q_Votes":"62"},{"Q_Title":"Why is looping over range() in Python faster than using a while loop?","A_Content":"  range() is implemented in C, whereas i += 1 is interpreted.  Using xrange() could make it even faster for large numbers. Starting with Python 3.0 range() is the same as previously xrange().     ","Language":"Python","Tags":["python","performance","benchmarking"],"URL":"https://stackoverflow.com/questions/869229/why-is-looping-over-range-in-python-faster-than-using-a-while-loop","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    The other day I was doing some Python benchmarking and I came across something interesting.  Below are two loops that do more or less the same thing.  Loop 1 takes about twice as long as loop 2 to execute.  Loop 1:  int i = 0 while i < 100000000:   i += 1   Loop 2:  for n in range(0,100000000):   pass   Why is the first loop so much slower?  I know it's a trivial example but it's piqued my interest.  Is there something special about the range() function that makes it more efficient than incrementing a variable the same way?     ","Q_Votes":"62"},{"Q_Title":"Why is looping over range() in Python faster than using a while loop?","A_Content":"  It must be said that there is a lot of object creation and destruction going on with the while loop.  i += 1   is the same as:  i = i + 1   But because Python ints are immutable, it doesn't modify the existing object; rather it creates a brand new object with a new value. It's basically:  i = new int(i + 1)   # Using C++ or Java-ish syntax   The garbage collector will also have a large amount of cleanup to do. \"Object creation is expensive\".     ","Language":"Python","Tags":["python","performance","benchmarking"],"URL":"https://stackoverflow.com/questions/869229/why-is-looping-over-range-in-python-faster-than-using-a-while-loop","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    The other day I was doing some Python benchmarking and I came across something interesting.  Below are two loops that do more or less the same thing.  Loop 1 takes about twice as long as loop 2 to execute.  Loop 1:  int i = 0 while i < 100000000:   i += 1   Loop 2:  for n in range(0,100000000):   pass   Why is the first loop so much slower?  I know it's a trivial example but it's piqued my interest.  Is there something special about the range() function that makes it more efficient than incrementing a variable the same way?     ","Q_Votes":"62"},{"Q_Title":"Why is looping over range() in Python faster than using a while loop?","A_Content":"  Because you are running more often in code written in C in the interpretor.  i.e. i+=1 is in Python, so slow (comparatively), whereas range(0,...) is one C call the for loop will execute mostly in C too.     ","Language":"Python","Tags":["python","performance","benchmarking"],"URL":"https://stackoverflow.com/questions/869229/why-is-looping-over-range-in-python-faster-than-using-a-while-loop","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    The other day I was doing some Python benchmarking and I came across something interesting.  Below are two loops that do more or less the same thing.  Loop 1 takes about twice as long as loop 2 to execute.  Loop 1:  int i = 0 while i < 100000000:   i += 1   Loop 2:  for n in range(0,100000000):   pass   Why is the first loop so much slower?  I know it's a trivial example but it's piqued my interest.  Is there something special about the range() function that makes it more efficient than incrementing a variable the same way?     ","Q_Votes":"62"},{"Q_Title":"Why is looping over range() in Python faster than using a while loop?","A_Content":"  Most of Python's built in method calls are run as C code. Code that has to be interpreted is much slower. In terms of memory efficiency and execution speed the difference is gigantic. The python internals have been optimized to the extreme, and it's best to take advantage of those optimizations.      ","Language":"Python","Tags":["python","performance","benchmarking"],"URL":"https://stackoverflow.com/questions/869229/why-is-looping-over-range-in-python-faster-than-using-a-while-loop","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    The other day I was doing some Python benchmarking and I came across something interesting.  Below are two loops that do more or less the same thing.  Loop 1 takes about twice as long as loop 2 to execute.  Loop 1:  int i = 0 while i < 100000000:   i += 1   Loop 2:  for n in range(0,100000000):   pass   Why is the first loop so much slower?  I know it's a trivial example but it's piqued my interest.  Is there something special about the range() function that makes it more efficient than incrementing a variable the same way?     ","Q_Votes":"62"},{"Q_Title":"Disable individual Python unit tests temporarily","A_Content":"  Individual test methods or classes can both be disabled using the unittest.skip decorator.  @unittest.skip(\"reason for skipping\") def test_foo():     print('This is foo test case.')   @unittest.skip  # no reason needed def test_bar():     print('This is bar test case.')   For other options, see the docs for Skipping tests and expected failures.     ","Language":"Python","Tags":["python","python-unittest"],"URL":"https://stackoverflow.com/questions/2066508/disable-individual-python-unit-tests-temporarily","A_Votes":"121","_type":"dict","isAccepted":"Yes","Q_Content":"    How can individual unit tests be temporarily disabled when using the unittest module in Python?     ","Q_Votes":"62"},{"Q_Title":"Disable individual Python unit tests temporarily","A_Content":"  You can use decorators to disable the test that can wrap the function and prevent the googletest or python unit test to run the testcase.  def disabled(f):     def _decorator():         print f.__name__ + ' has been disabled'     return _decorator  @disabled def testFoo():     '''Foo test case'''     print 'this is foo test case'  testFoo()   Output:  testFoo has been disabled      ","Language":"Python","Tags":["python","python-unittest"],"URL":"https://stackoverflow.com/questions/2066508/disable-individual-python-unit-tests-temporarily","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    How can individual unit tests be temporarily disabled when using the unittest module in Python?     ","Q_Votes":"62"},{"Q_Title":"Disable individual Python unit tests temporarily","A_Content":"  The latest version (2.7 - unreleased) supports test skipping/disabling like so. You could just get this module and use it on your existing Python install. It will probably work.  Before this, I used to rename the tests I wanted skipped to xtest_testname from test_testname.     Here's a quick elisp script to do this. My elisp is a little rusty so I apologise in advance for any problems it has. Untested.     (defun disable_enable_test ()   (interactive \"\")   (save-excursion     (beginning-of-line)     (search-forward \"def\")     (forward-char)     (if (looking-at \"disable_\")     (zap-to-char 1 ?_)       (insert \"disable_\"))))      ","Language":"Python","Tags":["python","python-unittest"],"URL":"https://stackoverflow.com/questions/2066508/disable-individual-python-unit-tests-temporarily","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    How can individual unit tests be temporarily disabled when using the unittest module in Python?     ","Q_Votes":"62"},{"Q_Title":"Disable individual Python unit tests temporarily","A_Content":"  Simply placing @unittest.SkipTest decorator above the test is enough.     ","Language":"Python","Tags":["python","python-unittest"],"URL":"https://stackoverflow.com/questions/2066508/disable-individual-python-unit-tests-temporarily","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    How can individual unit tests be temporarily disabled when using the unittest module in Python?     ","Q_Votes":"62"},{"Q_Title":"Disable individual Python unit tests temporarily","A_Content":"  I just rename a test case method with an underscore: test_myfunc becomes _test_myfunc.     ","Language":"Python","Tags":["python","python-unittest"],"URL":"https://stackoverflow.com/questions/2066508/disable-individual-python-unit-tests-temporarily","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    How can individual unit tests be temporarily disabled when using the unittest module in Python?     ","Q_Votes":"62"},{"Q_Title":"Disable individual Python unit tests temporarily","A_Content":"  The docs for 2.1 don't specify an ignore or skip method.  Usually though, I block comment when needed.     ","Language":"Python","Tags":["python","python-unittest"],"URL":"https://stackoverflow.com/questions/2066508/disable-individual-python-unit-tests-temporarily","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How can individual unit tests be temporarily disabled when using the unittest module in Python?     ","Q_Votes":"62"},{"Q_Title":"ipython server can't launch: No module named notebook.notebookapp","A_Content":"  This should fix the issue:  pip install jupyter      ","Language":"Python","Tags":["python","server","ipython"],"URL":"https://stackoverflow.com/questions/31397421/ipython-server-cant-launch-no-module-named-notebook-notebookapp","A_Votes":"149","_type":"dict","isAccepted":"Yes","Q_Content":"    I've been trying to setup an ipython server following several tutorials (since none was exactly my case). A couple days ago, I did manage to get it to the point where it was launching but then was not able to access it via url. Today it's not launching anymore and I can't find much about this specific error I get:  Traceback (most recent call last):   File \"/usr/local/bin/ipython\", line 9, in <module>     load_entry_point('ipython==4.0.0-dev', 'console_scripts', 'ipython')()   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/__init__.py\", line 118, in start_ipython     return launch_new_instance(argv=argv, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 591, in launch_instance     app.initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 302, in initialize     super(TerminalIPythonApp, self).initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/core/application.py\", line 386, in initialize     self.parse_command_line(argv)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 297, in parse_command_line     return super(TerminalIPythonApp, self).parse_command_line(argv)   File \"<string>\", line 2, in parse_command_line   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 487, in parse_command_line     return self.initialize_subcommand(subc, subargv)   File \"<string>\", line 2, in initialize_subcommand   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 418, in initialize_subcommand     subapp = import_item(subapp)   File \"build/bdist.linux-x86_64/egg/ipython_genutils/importstring.py\", line 31, in import_item ImportError: No module named notebook.notebookapp   So about the setup, I have installed the anaconda distrib of ipython, pyzmq & tornado libraries. I have created a profile nbserver and the config file is as follows - ipython.config.py:  c = get_config() c.IPKernalApp.pylab = 'inline' c.NotebookApp.certfile = u'/home/ludo/.ipython/profile_nbserver/mycert.pem' c.NotebookApp.ip = '*' c.NotebookApp.open_browser = False c.NotebookApp.password = u'sha1:e6cb2aa9a[...]' c.NotebookApp.port = 9999 c.NotebookManager.notebook_dir = u'/var/www/ipynb/' c.NotebookApp.base_project_url = '/ipynb/' c.NotebookApp.base_kernel_url = '/ipynb/' c.NotebookApp.webapp_settings = {'static_url_prefix':'/ipynb/static/'}   I really don't know where to look for clues anymore - and I'm probably lacking a greater understanding of how all this works to figure it out. My ultimate goal is to then use the answer to this question on SO to complete a setup behind apache and eventually connect it to colaboratory - but seems like it should launch first.  Many thanks for any help :)     ","Q_Votes":"62"},{"Q_Title":"ipython server can't launch: No module named notebook.notebookapp","A_Content":"  I received the same problem when upgrading IPython. At the moment the answer was written, it was a bug linked to the latest 4 version. If a similar problem occurs for which you wish to switch back to the stable version 3.2.1:  pip uninstall -y IPython pip install ipython==3.2.1    note: the -y option indicates \"yes I want to uninstall\" with no interaction. note 2: possible duplicate in ImportError: No module named notebook.notebookapp       ","Language":"Python","Tags":["python","server","ipython"],"URL":"https://stackoverflow.com/questions/31397421/ipython-server-cant-launch-no-module-named-notebook-notebookapp","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I've been trying to setup an ipython server following several tutorials (since none was exactly my case). A couple days ago, I did manage to get it to the point where it was launching but then was not able to access it via url. Today it's not launching anymore and I can't find much about this specific error I get:  Traceback (most recent call last):   File \"/usr/local/bin/ipython\", line 9, in <module>     load_entry_point('ipython==4.0.0-dev', 'console_scripts', 'ipython')()   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/__init__.py\", line 118, in start_ipython     return launch_new_instance(argv=argv, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 591, in launch_instance     app.initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 302, in initialize     super(TerminalIPythonApp, self).initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/core/application.py\", line 386, in initialize     self.parse_command_line(argv)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 297, in parse_command_line     return super(TerminalIPythonApp, self).parse_command_line(argv)   File \"<string>\", line 2, in parse_command_line   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 487, in parse_command_line     return self.initialize_subcommand(subc, subargv)   File \"<string>\", line 2, in initialize_subcommand   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 418, in initialize_subcommand     subapp = import_item(subapp)   File \"build/bdist.linux-x86_64/egg/ipython_genutils/importstring.py\", line 31, in import_item ImportError: No module named notebook.notebookapp   So about the setup, I have installed the anaconda distrib of ipython, pyzmq & tornado libraries. I have created a profile nbserver and the config file is as follows - ipython.config.py:  c = get_config() c.IPKernalApp.pylab = 'inline' c.NotebookApp.certfile = u'/home/ludo/.ipython/profile_nbserver/mycert.pem' c.NotebookApp.ip = '*' c.NotebookApp.open_browser = False c.NotebookApp.password = u'sha1:e6cb2aa9a[...]' c.NotebookApp.port = 9999 c.NotebookManager.notebook_dir = u'/var/www/ipynb/' c.NotebookApp.base_project_url = '/ipynb/' c.NotebookApp.base_kernel_url = '/ipynb/' c.NotebookApp.webapp_settings = {'static_url_prefix':'/ipynb/static/'}   I really don't know where to look for clues anymore - and I'm probably lacking a greater understanding of how all this works to figure it out. My ultimate goal is to then use the answer to this question on SO to complete a setup behind apache and eventually connect it to colaboratory - but seems like it should launch first.  Many thanks for any help :)     ","Q_Votes":"62"},{"Q_Title":"ipython server can't launch: No module named notebook.notebookapp","A_Content":"  So to close this thread, and in case it helps anyone, my mistake was to have installed and used the dev version of ipython blindly following a tutorial, thinking I was using the anaconda instance I installed earlier (which was not even in my PATH).  Anyhow I:   uninstalled that ipython dev instance added anaconda/bin to my zsh path (add it to ~/.zshrc - that's why it was not even in my path after install) // at this point the server was launching fine but I couldn't access it in my browser >> firewall problems. opened my port of choice in my firewall (help for linode or ubuntu in general)   And everything works fine now.     ","Language":"Python","Tags":["python","server","ipython"],"URL":"https://stackoverflow.com/questions/31397421/ipython-server-cant-launch-no-module-named-notebook-notebookapp","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I've been trying to setup an ipython server following several tutorials (since none was exactly my case). A couple days ago, I did manage to get it to the point where it was launching but then was not able to access it via url. Today it's not launching anymore and I can't find much about this specific error I get:  Traceback (most recent call last):   File \"/usr/local/bin/ipython\", line 9, in <module>     load_entry_point('ipython==4.0.0-dev', 'console_scripts', 'ipython')()   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/__init__.py\", line 118, in start_ipython     return launch_new_instance(argv=argv, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 591, in launch_instance     app.initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 302, in initialize     super(TerminalIPythonApp, self).initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/core/application.py\", line 386, in initialize     self.parse_command_line(argv)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 297, in parse_command_line     return super(TerminalIPythonApp, self).parse_command_line(argv)   File \"<string>\", line 2, in parse_command_line   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 487, in parse_command_line     return self.initialize_subcommand(subc, subargv)   File \"<string>\", line 2, in initialize_subcommand   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 418, in initialize_subcommand     subapp = import_item(subapp)   File \"build/bdist.linux-x86_64/egg/ipython_genutils/importstring.py\", line 31, in import_item ImportError: No module named notebook.notebookapp   So about the setup, I have installed the anaconda distrib of ipython, pyzmq & tornado libraries. I have created a profile nbserver and the config file is as follows - ipython.config.py:  c = get_config() c.IPKernalApp.pylab = 'inline' c.NotebookApp.certfile = u'/home/ludo/.ipython/profile_nbserver/mycert.pem' c.NotebookApp.ip = '*' c.NotebookApp.open_browser = False c.NotebookApp.password = u'sha1:e6cb2aa9a[...]' c.NotebookApp.port = 9999 c.NotebookManager.notebook_dir = u'/var/www/ipynb/' c.NotebookApp.base_project_url = '/ipynb/' c.NotebookApp.base_kernel_url = '/ipynb/' c.NotebookApp.webapp_settings = {'static_url_prefix':'/ipynb/static/'}   I really don't know where to look for clues anymore - and I'm probably lacking a greater understanding of how all this works to figure it out. My ultimate goal is to then use the answer to this question on SO to complete a setup behind apache and eventually connect it to colaboratory - but seems like it should launch first.  Many thanks for any help :)     ","Q_Votes":"62"},{"Q_Title":"ipython server can't launch: No module named notebook.notebookapp","A_Content":"  Someone mentioned this in a comment, and it (almost) worked for me:  pip install ipython[notebook]   pip gave an error about the hash not matching. However, what ultimately worked was:  sudo port install py27-notebook   And for py3:  sudo port install py35-notebook      ","Language":"Python","Tags":["python","server","ipython"],"URL":"https://stackoverflow.com/questions/31397421/ipython-server-cant-launch-no-module-named-notebook-notebookapp","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I've been trying to setup an ipython server following several tutorials (since none was exactly my case). A couple days ago, I did manage to get it to the point where it was launching but then was not able to access it via url. Today it's not launching anymore and I can't find much about this specific error I get:  Traceback (most recent call last):   File \"/usr/local/bin/ipython\", line 9, in <module>     load_entry_point('ipython==4.0.0-dev', 'console_scripts', 'ipython')()   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/__init__.py\", line 118, in start_ipython     return launch_new_instance(argv=argv, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 591, in launch_instance     app.initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 302, in initialize     super(TerminalIPythonApp, self).initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/core/application.py\", line 386, in initialize     self.parse_command_line(argv)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 297, in parse_command_line     return super(TerminalIPythonApp, self).parse_command_line(argv)   File \"<string>\", line 2, in parse_command_line   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 487, in parse_command_line     return self.initialize_subcommand(subc, subargv)   File \"<string>\", line 2, in initialize_subcommand   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 418, in initialize_subcommand     subapp = import_item(subapp)   File \"build/bdist.linux-x86_64/egg/ipython_genutils/importstring.py\", line 31, in import_item ImportError: No module named notebook.notebookapp   So about the setup, I have installed the anaconda distrib of ipython, pyzmq & tornado libraries. I have created a profile nbserver and the config file is as follows - ipython.config.py:  c = get_config() c.IPKernalApp.pylab = 'inline' c.NotebookApp.certfile = u'/home/ludo/.ipython/profile_nbserver/mycert.pem' c.NotebookApp.ip = '*' c.NotebookApp.open_browser = False c.NotebookApp.password = u'sha1:e6cb2aa9a[...]' c.NotebookApp.port = 9999 c.NotebookManager.notebook_dir = u'/var/www/ipynb/' c.NotebookApp.base_project_url = '/ipynb/' c.NotebookApp.base_kernel_url = '/ipynb/' c.NotebookApp.webapp_settings = {'static_url_prefix':'/ipynb/static/'}   I really don't know where to look for clues anymore - and I'm probably lacking a greater understanding of how all this works to figure it out. My ultimate goal is to then use the answer to this question on SO to complete a setup behind apache and eventually connect it to colaboratory - but seems like it should launch first.  Many thanks for any help :)     ","Q_Votes":"62"},{"Q_Title":"ipython server can't launch: No module named notebook.notebookapp","A_Content":"  You should not try to install from github master branch if you do not now what you are doing. Remove what you have installed and stick to stable version.  If you want to work on developpement version, ask on the developpement mailing-list. Some knowlege on how to debug this will probably be required.      ","Language":"Python","Tags":["python","server","ipython"],"URL":"https://stackoverflow.com/questions/31397421/ipython-server-cant-launch-no-module-named-notebook-notebookapp","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I've been trying to setup an ipython server following several tutorials (since none was exactly my case). A couple days ago, I did manage to get it to the point where it was launching but then was not able to access it via url. Today it's not launching anymore and I can't find much about this specific error I get:  Traceback (most recent call last):   File \"/usr/local/bin/ipython\", line 9, in <module>     load_entry_point('ipython==4.0.0-dev', 'console_scripts', 'ipython')()   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/__init__.py\", line 118, in start_ipython     return launch_new_instance(argv=argv, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 591, in launch_instance     app.initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 302, in initialize     super(TerminalIPythonApp, self).initialize(argv)   File \"<string>\", line 2, in initialize   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/core/application.py\", line 386, in initialize     self.parse_command_line(argv)   File \"/usr/local/lib/python2.7/dist-packages/ipython-4.0.0_dev-py2.7.egg/IPython/terminal/ipapp.py\", line 297, in parse_command_line     return super(TerminalIPythonApp, self).parse_command_line(argv)   File \"<string>\", line 2, in parse_command_line   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 487, in parse_command_line     return self.initialize_subcommand(subc, subargv)   File \"<string>\", line 2, in initialize_subcommand   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 75, in catch_config_error     return method(app, *args, **kwargs)   File \"/usr/local/lib/python2.7/dist-packages/traitlets-4.0.0-py2.7.egg/traitlets/config/application.py\", line 418, in initialize_subcommand     subapp = import_item(subapp)   File \"build/bdist.linux-x86_64/egg/ipython_genutils/importstring.py\", line 31, in import_item ImportError: No module named notebook.notebookapp   So about the setup, I have installed the anaconda distrib of ipython, pyzmq & tornado libraries. I have created a profile nbserver and the config file is as follows - ipython.config.py:  c = get_config() c.IPKernalApp.pylab = 'inline' c.NotebookApp.certfile = u'/home/ludo/.ipython/profile_nbserver/mycert.pem' c.NotebookApp.ip = '*' c.NotebookApp.open_browser = False c.NotebookApp.password = u'sha1:e6cb2aa9a[...]' c.NotebookApp.port = 9999 c.NotebookManager.notebook_dir = u'/var/www/ipynb/' c.NotebookApp.base_project_url = '/ipynb/' c.NotebookApp.base_kernel_url = '/ipynb/' c.NotebookApp.webapp_settings = {'static_url_prefix':'/ipynb/static/'}   I really don't know where to look for clues anymore - and I'm probably lacking a greater understanding of how all this works to figure it out. My ultimate goal is to then use the answer to this question on SO to complete a setup behind apache and eventually connect it to colaboratory - but seems like it should launch first.  Many thanks for any help :)     ","Q_Votes":"62"},{"Q_Title":"Getting current date and current time only respectively","A_Content":"  For the date, you can use datetime.date.today() or datetime.datetime.now().date().  For the time, you can use datetime.datetime.now().time().    However, why have separate fields for these in the first place? Why not use a single DateTimeField?  You can always define helper functions on the model that return the .date() or .time() later if you only want one or the other.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/12030187/getting-current-date-and-current-time-only-respectively","A_Votes":"119","_type":"dict","isAccepted":"Yes","Q_Content":"    I came across an interesting situation.  class Company(models.Model):     date = models.DateField()     time = models.TimeField()   When using this class:  c = Company(date=datetime.datetime.now(), time=datetime.datetime.now())    Django decides to use DATETIME_INPUT_FORMATS defined within the formats.py file. Which makes sense, because I am passing in a datetime.now() to both fields.  I think I could make Django to use DATE_INPUT_FORMATS and TIME_INPUT_FORMATS respectively, if I passed in only the current date and current time in.  Something like this:  c = Company(date=datetime.date.now(), time=datetime.time.now())    But this throws an exception as now doesn't exist like that.  Is there a different way to achieve this?  Many Thanks,     ","Q_Votes":"62"},{"Q_Title":"Getting current date and current time only respectively","A_Content":"  import datetime datetime.datetime.now().strftime (\"%Y%m%d\") 20151015   For the time    from time import gmtime, strftime showtime = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) print showtime 2015-10-15 07:49:18      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/12030187/getting-current-date-and-current-time-only-respectively","A_Votes":"46","_type":"dict","isAccepted":"No","Q_Content":"    I came across an interesting situation.  class Company(models.Model):     date = models.DateField()     time = models.TimeField()   When using this class:  c = Company(date=datetime.datetime.now(), time=datetime.datetime.now())    Django decides to use DATETIME_INPUT_FORMATS defined within the formats.py file. Which makes sense, because I am passing in a datetime.now() to both fields.  I think I could make Django to use DATE_INPUT_FORMATS and TIME_INPUT_FORMATS respectively, if I passed in only the current date and current time in.  Something like this:  c = Company(date=datetime.date.now(), time=datetime.time.now())    But this throws an exception as now doesn't exist like that.  Is there a different way to achieve this?  Many Thanks,     ","Q_Votes":"62"},{"Q_Title":"Getting current date and current time only respectively","A_Content":"  import datetime  datetime.date.today()  # Returns 2018-01-15  datetime.datetime.now() # Returns 2018-01-15 09:00      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/12030187/getting-current-date-and-current-time-only-respectively","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I came across an interesting situation.  class Company(models.Model):     date = models.DateField()     time = models.TimeField()   When using this class:  c = Company(date=datetime.datetime.now(), time=datetime.datetime.now())    Django decides to use DATETIME_INPUT_FORMATS defined within the formats.py file. Which makes sense, because I am passing in a datetime.now() to both fields.  I think I could make Django to use DATE_INPUT_FORMATS and TIME_INPUT_FORMATS respectively, if I passed in only the current date and current time in.  Something like this:  c = Company(date=datetime.date.now(), time=datetime.time.now())    But this throws an exception as now doesn't exist like that.  Is there a different way to achieve this?  Many Thanks,     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  The use of \"super\" (see Python Built-in, super) may be a slightly better method of calling the parent for initialization:  # Initialize using Parent # class MySubClass(MySuperClass):     def __init__(self):         MySuperClass.__init__(self)  # Better initialize using Parent (less redundant). # class MySubClassBetter(MySuperClass):     def __init__(self):         super(MySubClassBetter, self).__init__()      ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"64","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  A heroic little example:  class SuperHero(object): #superclass, inherits from default object     def getName(self):         raise NotImplementedError #you want to override this on the child classes  class SuperMan(SuperHero): #subclass, inherits from SuperHero     def getName(self):         return \"Clark Kent\"  class SuperManII(SuperHero): #another subclass     def getName(self):        return \"Clark Kent, Jr.\"  if __name__ == \"__main__\":     sm = SuperMan()     print sm.getName()     sm2 = SuperManII()     print sm2.getName()      ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"57","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  class MySubClass(MySuperClass):     def __init__(self):         MySuperClass.__init__(self)          # <the rest of your custom initialization code goes here>   The section on inheritance in the python documentation explains it in more detail     ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"34","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  class Class1(object):     pass  class Class2(Class1):     pass   Class2 is a sub-class of Class1     ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  There is another way to make subclasses in python dynamically with a function type():  SubClass = type('SubClass', (BaseClass,), {'set_x': set_x})  # Methods can be set, including __init__()   You usually want to use this method when working with metaclasses. When you want to do some lower level automations, that alters way how python creates class. Most likely you will not ever need to do it in this way, but when you do, than you already will know what you are doing.     ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  You use:  class DerivedClassName(BaseClassName):   For details, see the Python docs, section 9.5.     ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  In the answers above, the super is initialized without any (keyword) arguments. Often, however, you would like to do that, as well as pass on some 'custom' arguments of your own. Here is an example which illustrates this use case:  class SortedList(list):     def __init__(self, *args, reverse=False, **kwargs):         super().__init__(*args, **kwargs)       # Initialize the super class         self.reverse = reverse         self.sort(reverse=self.reverse)         # Do additional things with the custom keyword arguments   This is a subclass of list which, when initialized, immediately sorts itself in the direction specified by the reverse keyword argument, as the following tests illustrate:  import pytest  def test_1():     assert SortedList([5, 2, 3]) == [2, 3, 5]  def test_2():     SortedList([5, 2, 3], reverse=True) == [5, 3, 2]  def test_3():     with pytest.raises(TypeError):         sorted_list = SortedList([5, 2, 3], True)   # This doesn't work because 'reverse' must be passed as a keyword argument  if __name__ == \"__main__\":     pytest.main([__file__])   Thanks to the passing on of *args to super, the list can be initialized and populated with items instead of only being empty. (Note that reverse is a keyword-only argument in accordance with PEP 3102).     ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  class Subclass (SuperClass):       # Subclass stuff here      ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  class Mammal(object):  #mammal stuff  class Dog(Mammal):  #doggie stuff      ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  class BankAccount:    def __init__(self, balance=0):     self.balance = int(balance)    def checkBalance(self): ## Checking opening balance....     return self.balance    def deposit(self, deposit_amount=1000): ## takes in cash deposit amount and updates the balance accordingly.     self.deposit_amount = deposit_amount     self.balance += deposit_amount     return self.balance    def withdraw(self, withdraw_amount=500): ## takes in cash withdrawal amount and updates the balance accordingly     if self.balance < withdraw_amount: ## if amount is greater than balance return `\"invalid transaction\"`         return 'invalid transaction'     else:       self.balance -= withdraw_amount       return self.balance   class MinimumBalanceAccount(BankAccount): #subclass MinimumBalanceAccount of the BankAccount class      def __init__(self,balance=0, minimum_balance=500):         BankAccount.__init__(self, balance=0)         self.minimum_balance = minimum_balance         self.balance = balance - minimum_balance         #print \"Subclass MinimumBalanceAccount of the BankAccount class created!\"      def MinimumBalance(self):         return self.minimum_balance  c = BankAccount() print(c.deposit(50)) print(c.withdraw(10))  b = MinimumBalanceAccount(100, 50) print(b.deposit(50)) print(b.withdraw(10)) print(b.MinimumBalance())      ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Python: How do I make a subclass from a superclass?","A_Content":"  Subclassing in Python is done as follows:  class WindowElement:     def print(self):         pass  class Button(WindowElement):     def print(self):         pass   Here is a tutorial about Python that also contains classes and subclasses.     ","Language":"Python","Tags":["python","class"],"URL":"https://stackoverflow.com/questions/1607612/python-how-do-i-make-a-subclass-from-a-superclass","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do you make a subclass from a superclass?     ","Q_Votes":"62"},{"Q_Title":"Django csrf token + Angularjs","A_Content":"  Django and AngularJS both have CSRF support already, your part is quite simple.  First, you need to enable CSRF in Django, I believe you have already done so, if not, follow Django doc https://docs.djangoproject.com/en/1.5/ref/contrib/csrf/#ajax.  Now, Django will set a cookie named csrftoken on the first GET request and expects a custom HTTP header X-CSRFToken on later POST/PUT/DELETE requests.  For Angular, it expects the cookie named XSRF-TOKEN and will do POST/PUT/DELETE requests with X-XSRF-TOKEN header, so you need to do a little bit tweak to make the two go with each other:  $httpProvider.defaults.xsrfCookieName = 'csrftoken'; $httpProvider.defaults.xsrfHeaderName = 'X-CSRFToken';   Add above two lines somewhere in your js code, module.config() block is a good place for this.  That's it.  NOTE: This is for angular 1.1.5, older versions might need different approach.  Update:  Since the angular app isn't served by django, in order to let the cookie to be set, angular app needs to do a GET request to django first.     ","Language":"Python","Tags":["javascript","python","django","angularjs"],"URL":"https://stackoverflow.com/questions/18156452/django-csrf-token-angularjs","A_Votes":"106","_type":"dict","isAccepted":"Yes","Q_Content":"    I have django running on an apache server using mod_wsgi, as well as an angularjs app served directly by apache, not by django. I would like to make POST calls to the django server (running rest_framework) but I am having problems with the csrf token.   Is there someway to set the token from the server without putting {% csrf token %} as part of the template (since these pages aren't going through django)?    I would like to be able to get a csrf token through a GET request as a cookie. I would like to be able to then make POST requests to the django server with the csrf token cookie value.      ","Q_Votes":"62"},{"Q_Title":"Django csrf token + Angularjs","A_Content":"  var foo = angular.module('foo', ['bar']);  foo.config(['$httpProvider', function($httpProvider) {     $httpProvider.defaults.xsrfCookieName = 'csrftoken';     $httpProvider.defaults.xsrfHeaderName = 'X-CSRFToken'; }]);   And all modules services and controllers, where $http used, will send requests with csrf token.     ","Language":"Python","Tags":["javascript","python","django","angularjs"],"URL":"https://stackoverflow.com/questions/18156452/django-csrf-token-angularjs","A_Votes":"59","_type":"dict","isAccepted":"No","Q_Content":"    I have django running on an apache server using mod_wsgi, as well as an angularjs app served directly by apache, not by django. I would like to make POST calls to the django server (running rest_framework) but I am having problems with the csrf token.   Is there someway to set the token from the server without putting {% csrf token %} as part of the template (since these pages aren't going through django)?    I would like to be able to get a csrf token through a GET request as a cookie. I would like to be able to then make POST requests to the django server with the csrf token cookie value.      ","Q_Votes":"62"},{"Q_Title":"Django csrf token + Angularjs","A_Content":"  After searching around, what worked for me was from this post with the following code:  angular.module( '[your module name]',     ... [some dependencies] ...     'ngCookies',     ... [other dependencies] ... ) .run( function run( $http, $cookies ){      // For CSRF token compatibility with Django     $http.defaults.headers.post['X-CSRFToken'] = $cookies.get('csrftoken'); })   This is of course after getting the cookie through a GET request from the django server.   I also looked into some of the other answers here, including Ye Liun's but couldn't find anything in the official docs specifying changes to the defaults options for xsrf on $httpProvider, other than this pull request which didn't work for me at the time of me writing this post.     ","Language":"Python","Tags":["javascript","python","django","angularjs"],"URL":"https://stackoverflow.com/questions/18156452/django-csrf-token-angularjs","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I have django running on an apache server using mod_wsgi, as well as an angularjs app served directly by apache, not by django. I would like to make POST calls to the django server (running rest_framework) but I am having problems with the csrf token.   Is there someway to set the token from the server without putting {% csrf token %} as part of the template (since these pages aren't going through django)?    I would like to be able to get a csrf token through a GET request as a cookie. I would like to be able to then make POST requests to the django server with the csrf token cookie value.      ","Q_Votes":"62"},{"Q_Title":"Django csrf token + Angularjs","A_Content":"  I created a Django App for my AngularJS app, in the same Django project as my (REST) API Django App, that only serves the index.html file (which is just a sym.link). In this way the CSRF Cookie is set without an additional GET request.  Please see my answer here about AngularJS Single Page Web Application on Sub-domain A talking to a Django JSON (REST) API on Sub-domain B using CORS and CSRF protection     ","Language":"Python","Tags":["javascript","python","django","angularjs"],"URL":"https://stackoverflow.com/questions/18156452/django-csrf-token-angularjs","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have django running on an apache server using mod_wsgi, as well as an angularjs app served directly by apache, not by django. I would like to make POST calls to the django server (running rest_framework) but I am having problems with the csrf token.   Is there someway to set the token from the server without putting {% csrf token %} as part of the template (since these pages aren't going through django)?    I would like to be able to get a csrf token through a GET request as a cookie. I would like to be able to then make POST requests to the django server with the csrf token cookie value.      ","Q_Votes":"62"},{"Q_Title":"Django csrf token + Angularjs","A_Content":"  If you have your cookies set to disallow javascript access, you need to do the following.  In your template, before creating the django app, add this:  <script>     window.csrf_token = \"{{ csrf_token }}\"; </script>   In your angular app, add this:    angularApp.config([\"$httpProvider\", function($httpProvider) {     $httpProvider.defaults.headers.common[\"X-CSRFToken\"] = window.csrf_token; }]);   At least through Django 1.9, the CSRF token does not change with each request.  It only changes when a user logs in.  If you are doing a single page angular app, you need to make sure you reset the token on login/logout and this should work fine.  NOTE: This does not currently work in Django 1.10 or later due to the CSRF token changing on each request.  See Pass Django CSRF token to Angular with CSRF_COOKIE_HTTPONLY     ","Language":"Python","Tags":["javascript","python","django","angularjs"],"URL":"https://stackoverflow.com/questions/18156452/django-csrf-token-angularjs","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have django running on an apache server using mod_wsgi, as well as an angularjs app served directly by apache, not by django. I would like to make POST calls to the django server (running rest_framework) but I am having problems with the csrf token.   Is there someway to set the token from the server without putting {% csrf token %} as part of the template (since these pages aren't going through django)?    I would like to be able to get a csrf token through a GET request as a cookie. I would like to be able to then make POST requests to the django server with the csrf token cookie value.      ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  Convert to item pairs and check for containment.  all(item in superset.items() for item in subset.items())   Optimization is left as an exercise for the reader.     ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"72","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  Note for people that need this for unit testing: there's also an assertDictContainsSubset() method in Python's TestCase class.  http://docs.python.org/2/library/unittest.html?highlight=assertdictcontainssubset#unittest.TestCase.assertDictContainsSubset  It's however deprecated in 3.2, not sure why, maybe there's a replacement for it.     ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"30","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  In Python 3, you can use dict.items() to get a set-like view of the dict items.  You can then use the <= operator to test if one view is a \"subset\" of the other:  d1.items() <= d2.items()   In Python 2.7, use the dict.viewitems() to do the same:  d1.viewitems() <= d2.viewitems()   In Python 2.6 and below you will need a different solution, such as using all():  all(key in d2 and d2[key] == d1[key] for key in d1)      ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"30","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  for keys and values check use:  set(d1.items()).issubset(set(d2.items()))  if you need to check only keys:         set(d1).issubset(set(d2))     ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  >>> d1 = {'a':'2', 'b':'3'} >>> d2 = {'a':'2', 'b':'3','c':'4'} >>> all((k in d2 and d2[k]==v) for k,v in d1.iteritems()) True   context:  >>> d1 = {'a':'2', 'b':'3'} >>> d2 = {'a':'2', 'b':'3','c':'4'} >>> list(d1.iteritems()) [('a', '2'), ('b', '3')] >>> [(k,v) for k,v in d1.iteritems()] [('a', '2'), ('b', '3')] >>> k,v = ('a','2') >>> k 'a' >>> v '2' >>> k in d2 True >>> d2[k] '2' >>> k in d2 and d2[k]==v True >>> [(k in d2 and d2[k]==v) for k,v in d1.iteritems()] [True, True] >>> ((k in d2 and d2[k]==v) for k,v in d1.iteritems()) <generator object <genexpr> at 0x02A9D2B0> >>> ((k in d2 and d2[k]==v) for k,v in d1.iteritems()).next() True >>> all((k in d2 and d2[k]==v) for k,v in d1.iteritems()) True >>>      ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  For completeness, you can also do this:  def is_subdict(small, big):     return dict(big, **small) == big   However, I make no claims whatsoever concerning speed (or lack thereof) or readability (or lack thereof).     ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  My function for the same purpose, doing this recursively:  def dictMatch(patn, real):     \"\"\"does real dict match pattern?\"\"\"     try:         for pkey, pvalue in patn.iteritems():             if type(pvalue) is dict:                 result = dictMatch(pvalue, real[pkey])                 assert result             else:                 assert real[pkey] == pvalue                 result = True     except (AssertionError, KeyError):         result = False     return result   In your example, dictMatch(d1, d2) should return True even if d2 has other stuff in it, plus it applies also to lower levels:  d1 = {'a':'2', 'b':{3: 'iii'}} d2 = {'a':'2', 'b':{3: 'iii', 4: 'iv'},'c':'4'}  dictMatch(d1, d2)   # True   Notes:  There could be even better solution which avoids the if type(pvalue) is dict clause and applies to even wider range of cases (like lists of hashes etc).  Also recursion is not limited here so use at your own risk. ;)     ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  This seemingly straightforward issue costs me a couple hours in research to find a 100% reliable solution, so I documented what I've found in this answer.   \"Pythonic-ally\" speaking, small_dict <= big_dict would be the most intuitive way, but too bad that it won't work. {'a': 1} < {'a': 1, 'b': 2} seemingly works in Python 2, but it is not reliable because the official documention explicitly calls it out. Go search \"Outcomes other than equality are resolved consistently, but are not otherwise defined.\" in this section. Not to mention, comparing 2 dicts in Python 3 results in a TypeError exception. The second most-intuitive thing is small.viewitems() <= big.viewitems() for Python 2.7 only, and small.items() <= big.items() for Python 3. But there is one caveat: it is potentially buggy. If your program could potentially be used on Python <=2.6, its d1.items() <= d2.items() are actually comparing 2 lists of tuples, without particular order, so the final result will be unreliable and it becomes a nasty bug in your program. I am not keen to write yet another implementation for Python<=2.6, but I still don't feel comfortable that my code comes with a known bug (even if it is on an unsupported platform). So I abandon this approach. I settle down with @blubberdiblub 's answer (Credit goes to him):  def is_subdict(small, big):        return dict(big, **small) == big  It is worth pointing out that, this answer relies on the == behavior between dicts, which is clearly defined in official document, hence should work in every Python version. Go search:   \"Dictionaries compare equal if and only if they have the same (key, value) pairs.\" is the last sentence in this page \"Mappings (instances of dict) compare equal if and only if they have equal (key, value) pairs. Equality comparison of the keys and elements enforces reflexivity.\" in this page       ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  Here's a general recursive solution for the problem given:  import traceback import unittest  def is_subset(superset, subset):     for key, value in subset.items():         if key not in superset:             return False          if isinstance(value, dict):             if not is_subset(superset[key], value):                 return False          elif isinstance(value, str):             if value not in superset[key]:                 return False          elif isinstance(value, list):             if not set(value) <= set(superset[key]):                 return False         elif isinstance(value, set):             if not value <= superset[key]:                 return False          else:             if not value == superset[key]:                 return False      return True   class Foo(unittest.TestCase):      def setUp(self):         self.dct = {             'a': 'hello world',             'b': 12345,             'c': 1.2345,             'd': [1, 2, 3, 4, 5],             'e': {1, 2, 3, 4, 5},             'f': {                 'a': 'hello world',                 'b': 12345,                 'c': 1.2345,                 'd': [1, 2, 3, 4, 5],                 'e': {1, 2, 3, 4, 5},                 'g': False,                 'h': None             },             'g': False,             'h': None,             'question': 'mcve',             'metadata': {}         }      def tearDown(self):         pass      def check_true(self, superset, subset):         return self.assertEqual(is_subset(superset, subset), True)      def check_false(self, superset, subset):         return self.assertEqual(is_subset(superset, subset), False)      def test_simple_cases(self):         self.check_true(self.dct, {'a': 'hello world'})         self.check_true(self.dct, {'b': 12345})         self.check_true(self.dct, {'c': 1.2345})         self.check_true(self.dct, {'d': [1, 2, 3, 4, 5]})         self.check_true(self.dct, {'e': {1, 2, 3, 4, 5}})         self.check_true(self.dct, {'f': {             'a': 'hello world',             'b': 12345,             'c': 1.2345,             'd': [1, 2, 3, 4, 5],             'e': {1, 2, 3, 4, 5},         }})         self.check_true(self.dct, {'g': False})         self.check_true(self.dct, {'h': None})      def test_tricky_cases(self):         self.check_true(self.dct, {'a': 'hello'})         self.check_true(self.dct, {'d': [1, 2, 3]})         self.check_true(self.dct, {'e': {3, 4}})         self.check_true(self.dct, {'f': {             'a': 'hello world',             'h': None         }})         self.check_false(             self.dct, {'question': 'mcve', 'metadata': {'author': 'BPL'}})         self.check_true(             self.dct, {'question': 'mcve', 'metadata': {}})         self.check_false(             self.dct, {'question1': 'mcve', 'metadata': {}})  if __name__ == \"__main__\":     unittest.main()   NOTE: The original code would fail in certain cases, credits for the fixing goes to @olivier-melançon     ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  This function works for non-hashable values. I also think that it is clear and easy to read.  def isSubDict(subDict,dictionary):     for key in subDict.keys():         if (not key in dictionary) or (not subDict[key] == dictionary[key]):             return False     return True  In [126]: isSubDict({1:2},{3:4}) Out[126]: False  In [127]: isSubDict({1:2},{1:2,3:4}) Out[127]: True  In [128]: isSubDict({1:{2:3}},{1:{2:3},3:4}) Out[128]: True  In [129]: isSubDict({1:{2:3}},{1:{2:4},3:4}) Out[129]: False      ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Python: Check if one dictionary is a subset of another larger dictionary","A_Content":"  I know this question is old, but here is my solution for checking if one nested dictionary is a part of another nested dictionary. The solution is recursive.  def compare_dicts(a, b):     for key, value in a.items():         if key in b:             if isinstance(a[key], dict):                 if not compare_dicts(a[key], b[key]):                     return False             elif value != b[key]:                 return False         else:             return False     return True      ","Language":"Python","Tags":["python","dictionary","filter","subset"],"URL":"https://stackoverflow.com/questions/9323749/python-check-if-one-dictionary-is-a-subset-of-another-larger-dictionary","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to write a custom filter method that takes an arbitrary number of kwargs and returns a list containing the elements of a database-like list that contain those kwargs.  For example, suppose d1 = {'a':'2', 'b':'3'} and d2 = the same thing. d1 == d2 results in True. But suppose d2 = the same thing plus a bunch of other things. My method needs to be able to tell if d1 in d2, but Python can't do that with dictionaries.  Context:  I have a Word class, and each object has properties like word, definition, part_of_speech, and so on. I want to be able to call a filter method on the main list of these words, like Word.objects.filter(word='jump', part_of_speech='verb-intransitive'). I can't figure out how to manage these keys and values at the same time. But this could have larger functionality outside this context for other people.     ","Q_Votes":"62"},{"Q_Title":"Removing index column in pandas","A_Content":"  DataFrames and Series always have an index. Although it displays alongside the column(s), it is not a column, which is why del df['index'] did not work.  If you want to replace the index with simple sequential numbers, use df.reset_index(). I strongly suggest reading a little bit of the pandas documentation, like 10 minutes to Pandas to get a sense for why the index is there is how it is used.      ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/20107570/removing-index-column-in-pandas","A_Votes":"43","_type":"dict","isAccepted":"Yes","Q_Content":"    I have the following code which imports a CSV file.  There are 3 columns and I want to set the first two of them to variables.  When I set the second column to the variable \"efficiency\" the index column is also tacked on.  How can I get rid of the index column?  df = pd.DataFrame.from_csv('Efficiency_Data.csv', header=0, parse_dates=False) energy = df.index efficiency = df.Efficiency print efficiency   I tried using   del df['index']   after I set   energy = df.index   which I found in another post but that results in \"KeyError: 'index' \"     ","Q_Votes":"62"},{"Q_Title":"Removing index column in pandas","A_Content":"  When reading to and from your csv file include the argument index=False so for example   df.to_csv(filename ,  index = False)   and to read from the csv  df.read_csv(filename ,  index = False)     This should prevent the issue so you don't need to fix it later.     ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/20107570/removing-index-column-in-pandas","A_Votes":"106","_type":"dict","isAccepted":"No","Q_Content":"    I have the following code which imports a CSV file.  There are 3 columns and I want to set the first two of them to variables.  When I set the second column to the variable \"efficiency\" the index column is also tacked on.  How can I get rid of the index column?  df = pd.DataFrame.from_csv('Efficiency_Data.csv', header=0, parse_dates=False) energy = df.index efficiency = df.Efficiency print efficiency   I tried using   del df['index']   after I set   energy = df.index   which I found in another post but that results in \"KeyError: 'index' \"     ","Q_Votes":"62"},{"Q_Title":"Removing index column in pandas","A_Content":"  df.reset_index(drop = True, inplace = True)      ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/20107570/removing-index-column-in-pandas","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I have the following code which imports a CSV file.  There are 3 columns and I want to set the first two of them to variables.  When I set the second column to the variable \"efficiency\" the index column is also tacked on.  How can I get rid of the index column?  df = pd.DataFrame.from_csv('Efficiency_Data.csv', header=0, parse_dates=False) energy = df.index efficiency = df.Efficiency print efficiency   I tried using   del df['index']   after I set   energy = df.index   which I found in another post but that results in \"KeyError: 'index' \"     ","Q_Votes":"62"},{"Q_Title":"Removing index column in pandas","A_Content":"  You can set one of the columns as an index in case it is an \"id\" for example.  In this case the index column will be replaced by one of the columns you have chosen.  df.set_index('id', inplace=True)      ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/20107570/removing-index-column-in-pandas","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I have the following code which imports a CSV file.  There are 3 columns and I want to set the first two of them to variables.  When I set the second column to the variable \"efficiency\" the index column is also tacked on.  How can I get rid of the index column?  df = pd.DataFrame.from_csv('Efficiency_Data.csv', header=0, parse_dates=False) energy = df.index efficiency = df.Efficiency print efficiency   I tried using   del df['index']   after I set   energy = df.index   which I found in another post but that results in \"KeyError: 'index' \"     ","Q_Votes":"62"},{"Q_Title":"Removing index column in pandas","A_Content":"  If your problem is same as mine where you just want to reset the column headers from 0 to column size. Do  df = pd.DataFrame(df.values);   EDIT:  Not a good idea if you have heterogenous data types. Better just use   df.columns = range(len(df.columns))      ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/20107570/removing-index-column-in-pandas","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have the following code which imports a CSV file.  There are 3 columns and I want to set the first two of them to variables.  When I set the second column to the variable \"efficiency\" the index column is also tacked on.  How can I get rid of the index column?  df = pd.DataFrame.from_csv('Efficiency_Data.csv', header=0, parse_dates=False) energy = df.index efficiency = df.Efficiency print efficiency   I tried using   del df['index']   after I set   energy = df.index   which I found in another post but that results in \"KeyError: 'index' \"     ","Q_Votes":"62"},{"Q_Title":"Removing index column in pandas","A_Content":"  you can specify which column is an index in your csv file by using index_col parameter of from_csv function if this doesn't solve you problem please provide example of your data     ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/20107570/removing-index-column-in-pandas","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have the following code which imports a CSV file.  There are 3 columns and I want to set the first two of them to variables.  When I set the second column to the variable \"efficiency\" the index column is also tacked on.  How can I get rid of the index column?  df = pd.DataFrame.from_csv('Efficiency_Data.csv', header=0, parse_dates=False) energy = df.index efficiency = df.Efficiency print efficiency   I tried using   del df['index']   after I set   energy = df.index   which I found in another post but that results in \"KeyError: 'index' \"     ","Q_Votes":"62"},{"Q_Title":"Override a method at instance level","A_Content":"  Please do not do this as shown.   You code becomes unreadable when you monkeypatch an instance to be different from the class.  You cannot debug monkeypatched code.  When you find a bug in boby and print type(boby), you'll see that (a) it's a Dog, but (b) for some obscure reason it doesn't bark correctly.  This is a nightmare.  Do not do it.  Please do this instead.  class Dog:     def bark(self):         print \"WOOF\"  class BobyDog( Dog ):     def bark( self ):         print \"WoOoOoF!!\"  otherDog= Dog() otherDog.bark() # WOOF  boby = BobyDog() boby.bark() # WoOoOoF!!      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/394770/override-a-method-at-instance-level","A_Votes":"20","_type":"dict","isAccepted":"Yes","Q_Content":"    Is there a way in Python to override a class method at instance level? For example:  class Dog:     def bark(self):         print \"WOOF\"  boby = Dog() boby.bark() # WOOF # METHOD OVERRIDE boby.bark() # WoOoOoF!!      ","Q_Votes":"62"},{"Q_Title":"Override a method at instance level","A_Content":"  Yes, it's possible:  class Dog:     def bark(self):         print \"Woof\"  def new_bark(self):     print \"Woof Woof\"  foo = Dog()  funcType = type(Dog.bark)  # \"Woof\" foo.bark()  # replace bark with new_bark for this object only foo.bark = funcType(new_bark, foo, Dog)  foo.bark() # \"Woof Woof\"      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/394770/override-a-method-at-instance-level","A_Votes":"132","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way in Python to override a class method at instance level? For example:  class Dog:     def bark(self):         print \"WOOF\"  boby = Dog() boby.bark() # WOOF # METHOD OVERRIDE boby.bark() # WoOoOoF!!      ","Q_Votes":"62"},{"Q_Title":"Override a method at instance level","A_Content":"  class Dog:     def bark(self):         print \"WOOF\"  boby = Dog() boby.bark() # WOOF  # METHOD OVERRIDE def new_bark():     print \"WoOoOoF!!\" boby.bark = new_bark  boby.bark() # WoOoOoF!!   You can use the boby variable inside the function if you need. Since you are overriding the method just for this one instance object, this way is simpler and has exactly the same effect as using self.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/394770/override-a-method-at-instance-level","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way in Python to override a class method at instance level? For example:  class Dog:     def bark(self):         print \"WOOF\"  boby = Dog() boby.bark() # WOOF # METHOD OVERRIDE boby.bark() # WoOoOoF!!      ","Q_Votes":"62"},{"Q_Title":"Override a method at instance level","A_Content":"  You need to use MethodType from types module. Purpose of MethodType is overwrite instance level methods (so that self can be available in overwritten method).  see below example.  import types  class Dog:     def bark(self):         print \"WOOF\"  boby = Dog() boby.bark() # WOOF  def _bark(self):     print \"WoOoOoF!!\"  boby.bark = types.MethodType(_bark, boby)  boby.bark() # WoOoOoF!!      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/394770/override-a-method-at-instance-level","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way in Python to override a class method at instance level? For example:  class Dog:     def bark(self):         print \"WOOF\"  boby = Dog() boby.bark() # WOOF # METHOD OVERRIDE boby.bark() # WoOoOoF!!      ","Q_Votes":"62"},{"Q_Title":"Override a method at instance level","A_Content":"  To explain @codelogic's excellent answer, I propose a more explicit approach. This is the same technique that the . operator goes thorough to bind a class method when you access it as an instance attribute, except that your method will actually be a function defined outside of a class.  Working with @codelogic's code, the only difference is in how the method is bound. I am using the fact that functions and methods are non-data descriptors in Python, and invoking the __get__ method. Note particularly that both the original and the replacement have identical signatures, meaning that you can write the replacement as a full class method, accessing all the instance attributes via self.   class Dog:     def bark(self):         print \"Woof\"  def new_bark(self):     print \"Woof Woof\"  foo = Dog()  # \"Woof\" foo.bark()  # replace bark with new_bark for this object only foo.bark = new_bark.__get__(foo, Dog)  foo.bark() # \"Woof Woof\"   By assigning the bound method to an instance attribute, you have created a nearly complete simulation of overriding a method. One handy feature that is missing is access to the no-arg version of super, since you are not in a class definition. Another thing is that the __name__ attribute of your bound method will not take the name of the function it is overriding, as it would in class definition, but you can still set it manually. The third difference is that your manually-bound method is a plain attribute reference that just happens to be a function. The . operator does nothing but fetch that reference. When invoking a regular method from an instance on the other hand, the binding process creates a new bound method every time.  The only reason that this works, by the way, is that instance attributes override non-data descriptors. Data descriptors have __set__ methods, which methods (fortunately for you) do not. Data descriptors in the class actually take priority over any instance attributes. That is why you can assign to a property: their __set__ method gets invoked when you try to make an assignment. I personally like to take this a step further and hide the actual value of the underlying attribute in the instance's __dict__, where it is inaccessible by normal means exactly because the property shadows it.  You should also keep in mind that this is pointless for magic (double underscore) methods. Magic methods can of course be overridden in this way, but the operations that use them only look at the type. For example, you can set __contains__ to something special in your instance, but calling x in instance would disregard that and use type(instance).__contains__(instance, x) instead. This applies to all magic methods specified in the Python data model.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/394770/override-a-method-at-instance-level","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way in Python to override a class method at instance level? For example:  class Dog:     def bark(self):         print \"WOOF\"  boby = Dog() boby.bark() # WOOF # METHOD OVERRIDE boby.bark() # WoOoOoF!!      ","Q_Votes":"62"},{"Q_Title":"Override a method at instance level","A_Content":"  Since functions are first class objects in Python you can pass them while initializing your class object or override it anytime for a given class instance:  class Dog:     def __init__(self,  barkmethod=None):         self.bark=self.barkp         if barkmethod:            self.bark=barkmethod     def barkp(self):         print \"woof\"  d=Dog() print \"calling original bark\" d.bark()  def barknew():     print \"wooOOOoof\"  d1=Dog(barknew) print \"calling the new bark\" d1.bark()  def barknew1():     print \"nowoof\"  d1.bark=barknew1 print \"calling another new\" d1.bark()   and the results are   calling original bark woof calling the new bark wooOOOoof calling another new nowoof      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/394770/override-a-method-at-instance-level","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is there a way in Python to override a class method at instance level? For example:  class Dog:     def bark(self):         print \"WOOF\"  boby = Dog() boby.bark() # WOOF # METHOD OVERRIDE boby.bark() # WoOoOoF!!      ","Q_Votes":"62"},{"Q_Title":"ctypes - Beginner","A_Content":"  Here's a quick and dirty ctypes tutorial.  First, write your C library. Here's a simple Hello world example:  testlib.c  #include <stdio.h>  void myprint(void);  void myprint() {     printf(\"hello world\\n\"); }   Now compile it as a shared library (mac fix found here):  $ gcc -shared -Wl,-soname,testlib -o testlib.so -fPIC testlib.c  # or... for Mac OS X  $ gcc -shared -Wl,-install_name,testlib.so -o testlib.so -fPIC testlib.c   Then, write a wrapper using ctypes:  testlibwrapper.py  import ctypes  testlib = ctypes.CDLL('/full/path/to/testlib.so') testlib.myprint()   Now execute it:  $ python testlibwrapper.py   And you should see the output  Hello world $   If you already have a library in mind, you can skip the non-python part of the tutorial. Make sure ctypes can find the library by putting it in /usr/lib or another standard directory. If you do this, you don't need to specify the full path when writing the wrapper. If you choose not to do this, you must provide the full path of the library when calling ctypes.CDLL().   This isn't the place for a more comprehensive tutorial, but if you ask for help with specific problems on this site, I'm sure the community would help you out.  PS: I'm assuming you're on Linux because you've used ctypes.CDLL('libc.so.6'). If you're on another OS, things might change a little bit (or quite a lot).     ","Language":"Python","Tags":["python","python-3.x","ctypes"],"URL":"https://stackoverflow.com/questions/5081875/ctypes-beginner","A_Votes":"166","_type":"dict","isAccepted":"No","Q_Content":"    I have the task of \"wrapping\" a c library into a python class.  The docs are incredibly vague on this matter.  It seems they expect only advanced python users would implement ctypes.  Well i'm a beginner in python and need help.  Some step by step help would be wonderful.  So I have my c library.  What do I do?  What files do I put where? How do I import the library?  I read that there might be a way to \"auto wrap\" to Python?  (By the way I did the ctypes tutorial on python.net and it doesn't work. Meaning I'm thinking they are assuming I should be able to fill in the rest of the steps.  In fact this is the error I get with their code:  File \"importtest.py\", line 1    >>> from ctypes import *    SyntaxError: invalid syntax   I could really use some step by step help on this! Thanks~     ","Q_Votes":"62"},{"Q_Title":"ctypes - Beginner","A_Content":"  The answer by Chinmay Kanchi is excellent but I wanted an example of a function which passes and returns a variables/arrays to a C++ code. I though I'd include it here in case it is useful to others.   Passing and returning an integer  The C++ code for a function which takes an integer and adds one to the returned value,  extern \"C\" int add_one(int i) {     return i+1; }   Saved as file test.cpp, note the required extern \"C\" (this can be removed for C code).  This is compiled using g++, with arguments similar to Chinmay Kanchi answer,  g++ -shared -o testlib.so -fPIC test.cpp   The Python code uses load_library from the numpy.ctypeslib assuming the path to the shared library in the same directory as the Python script,  import numpy.ctypeslib as ctl import ctypes  libname = 'testlib.so' libdir = './' lib=ctl.load_library(libname, libdir)  py_add_one = lib.add_one py_add_one.argtypes = [ctypes.c_int] value = 5 results = py_add_one(value) print(results)   This prints 6 as expected.  Passing and printing an array  You can also pass arrays as follows, for a C code to print the element of an array,  extern \"C\" void print_array(double* array, int N) {     for (int i=0; i<N; i++)          cout << i << \" \" << array[i] << endl; }   which is compiled as before and the imported in the same way. The extra Python code to use this function would then be,  py_print_array = lib.print_array py_print_array.argtypes = [ctl.ndpointer(np.float64,                                           flags='aligned, c_contiguous'),                             ctypes.c_int] A = np.array([1.4,2.6,3.0], dtype=np.float64) py_print_array(A, 3)   where we specify the array, the first argument to print_array, as a pointer to a Numpy array of aligned, c_contiguous 64 bit floats and the second argument as an integer which tells the C code the number of elements in the Numpy array. This then printed by the C code as follows,   1.4 2.6 3.0      ","Language":"Python","Tags":["python","python-3.x","ctypes"],"URL":"https://stackoverflow.com/questions/5081875/ctypes-beginner","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I have the task of \"wrapping\" a c library into a python class.  The docs are incredibly vague on this matter.  It seems they expect only advanced python users would implement ctypes.  Well i'm a beginner in python and need help.  Some step by step help would be wonderful.  So I have my c library.  What do I do?  What files do I put where? How do I import the library?  I read that there might be a way to \"auto wrap\" to Python?  (By the way I did the ctypes tutorial on python.net and it doesn't work. Meaning I'm thinking they are assuming I should be able to fill in the rest of the steps.  In fact this is the error I get with their code:  File \"importtest.py\", line 1    >>> from ctypes import *    SyntaxError: invalid syntax   I could really use some step by step help on this! Thanks~     ","Q_Votes":"62"},{"Q_Title":"ctypes - Beginner","A_Content":"  Firstly: The >>> code you see in python examples is a way to indicate that it is Python code. It's used to separate Python code from output. Like this:  >>> 4+5 9   Here we see that the line that starts with >>> is the Python code, and 9 is what it results in. This is exactly how it looks if you start a Python interpreter, which is why it's done like that.  You never enter the >>> part into a .py file.  That takes care of your syntax error.  Secondly, ctypes is just one of several ways of wrapping Python libraries. Other ways are  SWIG, which will look at your Python library and generate a Python C extension module that exposes the C API. Another way is to use Cython.  They all have benefits and drawbacks.  SWIG will only expose your C API to Python. That means you don't get any objects or anything, you'll have to make a separate Python file doing that. It is however common to have a module called say \"wowza\" and a SWIG module called \"_wowza\" that is the wrapper around the C API. This is a nice and easy way of doing things.  Cython generates a C-Extension file. It has the benefit that all of the Python code you write is made into C, so the objects you write are also in C, which can be a performance improvement. But you'll have to learn how it interfaces with C so it's a little bit extra work to learn how to use it.  ctypes have the benefit that there is no C-code to compile, so it's very nice to use for wrapping standard libraries written by someone else, and already exists in binary versions for Windows and OS X.     ","Language":"Python","Tags":["python","python-3.x","ctypes"],"URL":"https://stackoverflow.com/questions/5081875/ctypes-beginner","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I have the task of \"wrapping\" a c library into a python class.  The docs are incredibly vague on this matter.  It seems they expect only advanced python users would implement ctypes.  Well i'm a beginner in python and need help.  Some step by step help would be wonderful.  So I have my c library.  What do I do?  What files do I put where? How do I import the library?  I read that there might be a way to \"auto wrap\" to Python?  (By the way I did the ctypes tutorial on python.net and it doesn't work. Meaning I'm thinking they are assuming I should be able to fill in the rest of the steps.  In fact this is the error I get with their code:  File \"importtest.py\", line 1    >>> from ctypes import *    SyntaxError: invalid syntax   I could really use some step by step help on this! Thanks~     ","Q_Votes":"62"},{"Q_Title":"cannot import name patterns","A_Content":"  You don't need those imports. The only thing you need in your urls.py (to start) is:  from django.conf.urls.defaults import *  # This two if you want to enable the Django Admin: (recommended) from django.contrib import admin admin.autodiscover()  urlpatterns = patterns('',     url(r'^admin/', include(admin.site.urls)),     # ... your url patterns )   NOTE: This solution was intended for Django <1.6. This was actually the code generated by Django itself. For newer version, see Jacob Hume's answer.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/8074955/cannot-import-name-patterns","A_Votes":"20","_type":"dict","isAccepted":"Yes","Q_Content":"    Before I wrote in urls.py, my code... everything worked perfectly. Now I have problems - can't go to my site. \"cannot import name patterns\"  My urls.py is:  from django.conf.urls import patterns, include, url   They said what error is somewhere here.     ","Q_Votes":"62"},{"Q_Title":"cannot import name patterns","A_Content":"  As of Django 1.10, the patterns module has been removed (it had been deprecated since 1.8).  Luckily, it should be a simple edit to remove the offending code, since the urlpatterns should now be stored in a plain-old list:  urlpatterns = [     url(r'^admin/', include(admin.site.urls)),     # ... your url patterns ]      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/8074955/cannot-import-name-patterns","A_Votes":"138","_type":"dict","isAccepted":"No","Q_Content":"    Before I wrote in urls.py, my code... everything worked perfectly. Now I have problems - can't go to my site. \"cannot import name patterns\"  My urls.py is:  from django.conf.urls import patterns, include, url   They said what error is somewhere here.     ","Q_Votes":"62"},{"Q_Title":"cannot import name patterns","A_Content":"  Yes:  from django.conf.urls.defaults import ... # is for django 1.3 from django.conf.urls  import ...         # is for django 1.4   I met this problem too.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/8074955/cannot-import-name-patterns","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    Before I wrote in urls.py, my code... everything worked perfectly. Now I have problems - can't go to my site. \"cannot import name patterns\"  My urls.py is:  from django.conf.urls import patterns, include, url   They said what error is somewhere here.     ","Q_Votes":"62"},{"Q_Title":"cannot import name patterns","A_Content":"  patterns module is not supported.. mine worked with this.  from django.conf.urls import * from django.contrib import admin admin.autodiscover()  urlpatterns = [     url(r'^admin/', include(admin.site.urls)),     # ... your url patterns ]      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/8074955/cannot-import-name-patterns","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    Before I wrote in urls.py, my code... everything worked perfectly. Now I have problems - can't go to my site. \"cannot import name patterns\"  My urls.py is:  from django.conf.urls import patterns, include, url   They said what error is somewhere here.     ","Q_Votes":"62"},{"Q_Title":"cannot import name patterns","A_Content":"  This is the code which worked for me. My django version is 1.10.4 final  from django.conf.urls import url, include  from django.contrib import admin admin.autodiscover()  urlpatterns = [     # Examples:     # url(r'^$', 'blog.views.home', name='home'),     # url(r'^blog/', include('blog.urls')),      url(r'^admin/', include(admin.site.urls)), ]      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/8074955/cannot-import-name-patterns","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Before I wrote in urls.py, my code... everything worked perfectly. Now I have problems - can't go to my site. \"cannot import name patterns\"  My urls.py is:  from django.conf.urls import patterns, include, url   They said what error is somewhere here.     ","Q_Votes":"62"},{"Q_Title":"cannot import name patterns","A_Content":"  Pattern module in not available from django 1.8. So you need to remove pattern from your import and do something similar to the following:  from django.conf.urls import include, url from django.contrib import admin  admin.autodiscover()  urlpatterns = [                      # here we are not using pattern module like in previous django versions     url(r'^admin/', include(admin.site.urls)), ]      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/8074955/cannot-import-name-patterns","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Before I wrote in urls.py, my code... everything worked perfectly. Now I have problems - can't go to my site. \"cannot import name patterns\"  My urls.py is:  from django.conf.urls import patterns, include, url   They said what error is somewhere here.     ","Q_Votes":"62"},{"Q_Title":"cannot import name patterns","A_Content":"  I Resolved it by cloning my project directly into Eclipse from GIT,   Initially I was cloning it at specific location on file system then importing it as existing project into Eclipse.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/8074955/cannot-import-name-patterns","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Before I wrote in urls.py, my code... everything worked perfectly. Now I have problems - can't go to my site. \"cannot import name patterns\"  My urls.py is:  from django.conf.urls import patterns, include, url   They said what error is somewhere here.     ","Q_Votes":"62"},{"Q_Title":"cannot import name patterns","A_Content":"  Seems you are using outdated version of django.. Simply update django and try again.. Following command will update your django version..  pip install --upgrade django     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/8074955/cannot-import-name-patterns","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Before I wrote in urls.py, my code... everything worked perfectly. Now I have problems - can't go to my site. \"cannot import name patterns\"  My urls.py is:  from django.conf.urls import patterns, include, url   They said what error is somewhere here.     ","Q_Votes":"62"},{"Q_Title":"Django view returning json without using template","A_Content":"  I think the issue has gotten confused regarding what you want. I imagine you're not actually trying to put the HTML in the JSON response, but rather want to alternatively return either HTML or JSON.  First, you need to understand the core difference between the two. HTML is a presentational format. It deals more with how to display data than the data itself. JSON is the opposite. It's pure data -- basically a JavaScript representation of some Python (in this case) dataset you have. It serves as merely an interchange layer, allowing you to move data from one area of your app (the view) to another area of your app (your JavaScript) which normally don't have access to each other.  With that in mind, you don't \"render\" JSON, and there's no templates involved. You merely convert whatever data is in play (most likely pretty much what you're passing as the context to your template) to JSON. Which can be done via either Django's JSON library (simplejson), if it's freeform data, or its serialization framework, if it's a queryset.  simplejson  from django.utils import simplejson  some_data_to_dump = {    'some_var_1': 'foo',    'some_var_2': 'bar', }  data = simplejson.dumps(some_data_to_dump)   Serialization  from django.core import serializers  foos = Foo.objects.all()  data = serializers.serialize('json', foos)   Either way, you then pass that data into the response:  return HttpResponse(data, content_type='application/json')   [Edit] In Django 1.6 and earlier, the code to return response was  return HttpResponse(data, mimetype='application/json')      ","Language":"Python","Tags":["python","html","django","json"],"URL":"https://stackoverflow.com/questions/9262278/django-view-returning-json-without-using-template","A_Votes":"115","_type":"dict","isAccepted":"Yes","Q_Content":"    This related to this question: Django return json and html depending on client python  I have a command line python api for a django app. When I access the app through the api it should return json and with a browser it should return html. I can use different urls to access the different versions but how do I render the html template and json in the views.py with just one template?  To render the html I would use:   return render_to_response('sample/sample.html....)   But how would I do the same for json without putting a json template? (the content-type should be application/json instead of text/html)  Edit 1:  What would determine the json and html outputs?  So in my views:   if something:       return render_to_response('html_template',.....)  else:       return HttpReponse(jsondata,mimetype='application/json')   Thank you     ","Q_Votes":"62"},{"Q_Title":"Django view returning json without using template","A_Content":"  In Django 1.7 this is even easier with the built-in JsonResponse.  https://docs.djangoproject.com/en/dev/ref/request-response/#jsonresponse-objects  # import it from django.http import JsonResponse  def my_view(request):      # do something with the your data     data = {}      # just return a JsonResponse     return JsonResponse(data)      ","Language":"Python","Tags":["python","html","django","json"],"URL":"https://stackoverflow.com/questions/9262278/django-view-returning-json-without-using-template","A_Votes":"78","_type":"dict","isAccepted":"No","Q_Content":"    This related to this question: Django return json and html depending on client python  I have a command line python api for a django app. When I access the app through the api it should return json and with a browser it should return html. I can use different urls to access the different versions but how do I render the html template and json in the views.py with just one template?  To render the html I would use:   return render_to_response('sample/sample.html....)   But how would I do the same for json without putting a json template? (the content-type should be application/json instead of text/html)  Edit 1:  What would determine the json and html outputs?  So in my views:   if something:       return render_to_response('html_template',.....)  else:       return HttpReponse(jsondata,mimetype='application/json')   Thank you     ","Q_Votes":"62"},{"Q_Title":"Django view returning json without using template","A_Content":"  In the case of the JSON response there is no template to be rendered. Templates are for generating HTML responses. The JSON is the HTTP response.  However, you can have HTML that is rendered from a template withing your JSON response.  html = render_to_string(\"some.html\", some_dictionary) serialized_data = simplejson.dumps({\"html\": html}) return HttpResponse(serialized_data, mimetype=\"application/json\")      ","Language":"Python","Tags":["python","html","django","json"],"URL":"https://stackoverflow.com/questions/9262278/django-view-returning-json-without-using-template","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    This related to this question: Django return json and html depending on client python  I have a command line python api for a django app. When I access the app through the api it should return json and with a browser it should return html. I can use different urls to access the different versions but how do I render the html template and json in the views.py with just one template?  To render the html I would use:   return render_to_response('sample/sample.html....)   But how would I do the same for json without putting a json template? (the content-type should be application/json instead of text/html)  Edit 1:  What would determine the json and html outputs?  So in my views:   if something:       return render_to_response('html_template',.....)  else:       return HttpReponse(jsondata,mimetype='application/json')   Thank you     ","Q_Votes":"62"},{"Q_Title":"Django view returning json without using template","A_Content":"  It looks like the Django REST framework uses the HTTP accept header in a Request in order to automatically determine which renderer to use:  http://www.django-rest-framework.org/api-guide/renderers/  Using the HTTP accept header may provide an alternative source for your \"if something\".     ","Language":"Python","Tags":["python","html","django","json"],"URL":"https://stackoverflow.com/questions/9262278/django-view-returning-json-without-using-template","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    This related to this question: Django return json and html depending on client python  I have a command line python api for a django app. When I access the app through the api it should return json and with a browser it should return html. I can use different urls to access the different versions but how do I render the html template and json in the views.py with just one template?  To render the html I would use:   return render_to_response('sample/sample.html....)   But how would I do the same for json without putting a json template? (the content-type should be application/json instead of text/html)  Edit 1:  What would determine the json and html outputs?  So in my views:   if something:       return render_to_response('html_template',.....)  else:       return HttpReponse(jsondata,mimetype='application/json')   Thank you     ","Q_Votes":"62"},{"Q_Title":"Django view returning json without using template","A_Content":"  For rendering my models in JSON in django 1.9 I had to do the following in my views.py:  from django.core import serializers from django.http import HttpResponse from .models import Mymodel  def index(request):     objs = Mymodel.objects.all()     jsondata = serializers.serialize('json', objs)     return HttpResponse(jsondata, content_type='application/json')      ","Language":"Python","Tags":["python","html","django","json"],"URL":"https://stackoverflow.com/questions/9262278/django-view-returning-json-without-using-template","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    This related to this question: Django return json and html depending on client python  I have a command line python api for a django app. When I access the app through the api it should return json and with a browser it should return html. I can use different urls to access the different versions but how do I render the html template and json in the views.py with just one template?  To render the html I would use:   return render_to_response('sample/sample.html....)   But how would I do the same for json without putting a json template? (the content-type should be application/json instead of text/html)  Edit 1:  What would determine the json and html outputs?  So in my views:   if something:       return render_to_response('html_template',.....)  else:       return HttpReponse(jsondata,mimetype='application/json')   Thank you     ","Q_Votes":"62"},{"Q_Title":"Django view returning json without using template","A_Content":"  You could also check the request accept content type as specified in the rfc. That way you can render by default HTML and where your client accept application/jason you can return json in your response without a template being required     ","Language":"Python","Tags":["python","html","django","json"],"URL":"https://stackoverflow.com/questions/9262278/django-view-returning-json-without-using-template","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    This related to this question: Django return json and html depending on client python  I have a command line python api for a django app. When I access the app through the api it should return json and with a browser it should return html. I can use different urls to access the different versions but how do I render the html template and json in the views.py with just one template?  To render the html I would use:   return render_to_response('sample/sample.html....)   But how would I do the same for json without putting a json template? (the content-type should be application/json instead of text/html)  Edit 1:  What would determine the json and html outputs?  So in my views:   if something:       return render_to_response('html_template',.....)  else:       return HttpReponse(jsondata,mimetype='application/json')   Thank you     ","Q_Votes":"62"},{"Q_Title":"Django view returning json without using template","A_Content":"  from django.utils import simplejson  from django.core import serializers   def pagina_json(request):     misdatos = misdatos.objects.all()    data = serializers.serialize('json', misdatos)     return HttpResponse(data, mimetype='application/json')      ","Language":"Python","Tags":["python","html","django","json"],"URL":"https://stackoverflow.com/questions/9262278/django-view-returning-json-without-using-template","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    This related to this question: Django return json and html depending on client python  I have a command line python api for a django app. When I access the app through the api it should return json and with a browser it should return html. I can use different urls to access the different versions but how do I render the html template and json in the views.py with just one template?  To render the html I would use:   return render_to_response('sample/sample.html....)   But how would I do the same for json without putting a json template? (the content-type should be application/json instead of text/html)  Edit 1:  What would determine the json and html outputs?  So in my views:   if something:       return render_to_response('html_template',.....)  else:       return HttpReponse(jsondata,mimetype='application/json')   Thank you     ","Q_Votes":"62"},{"Q_Title":"Django view returning json without using template","A_Content":"  If you want to pass the result as a rendered template you have to load and render a template, pass the result of rendering it to the json.This could look like that:  from django.template import loader, RequestContext  #render the template t=loader.get_template('sample/sample.html') context=RequestContext() html=t.render(context)  #create the json result={'html_result':html) json = simplejson.dumps(result)  return HttpResponse(json)   That way you can pass a rendered template as json to your client. This can be useful if you want to completely replace ie. a  containing lots of different elements.     ","Language":"Python","Tags":["python","html","django","json"],"URL":"https://stackoverflow.com/questions/9262278/django-view-returning-json-without-using-template","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    This related to this question: Django return json and html depending on client python  I have a command line python api for a django app. When I access the app through the api it should return json and with a browser it should return html. I can use different urls to access the different versions but how do I render the html template and json in the views.py with just one template?  To render the html I would use:   return render_to_response('sample/sample.html....)   But how would I do the same for json without putting a json template? (the content-type should be application/json instead of text/html)  Edit 1:  What would determine the json and html outputs?  So in my views:   if something:       return render_to_response('html_template',.....)  else:       return HttpReponse(jsondata,mimetype='application/json')   Thank you     ","Q_Votes":"62"},{"Q_Title":"Django view returning json without using template","A_Content":"  Here's an example I needed for conditionally rendering json or html depending on the Request's Accept header  # myapp/views.py from django.core import serializers                                                                                 from django.http import HttpResponse                                                                                   from django.shortcuts import render                                                                                    from .models import Event  def event_index(request):                                                                                                  event_list = Event.objects.all()                                                                                       if request.META['HTTP_ACCEPT'] == 'application/json':                                                                      response = serializers.serialize('json', event_list)                                                                   return HttpResponse(response, content_type='application/json')                                                     else:                                                                                                                      context = {'event_list': event_list}                                                                                   return render(request, 'polls/event_list.html', context)   you can test this with curl or httpie  $ http localhost:8000/event/ $ http localhost:8000/event/ Accept:application/json   note I opted not to use JsonReponse as that would reserialize the model unnecessarily.     ","Language":"Python","Tags":["python","html","django","json"],"URL":"https://stackoverflow.com/questions/9262278/django-view-returning-json-without-using-template","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    This related to this question: Django return json and html depending on client python  I have a command line python api for a django app. When I access the app through the api it should return json and with a browser it should return html. I can use different urls to access the different versions but how do I render the html template and json in the views.py with just one template?  To render the html I would use:   return render_to_response('sample/sample.html....)   But how would I do the same for json without putting a json template? (the content-type should be application/json instead of text/html)  Edit 1:  What would determine the json and html outputs?  So in my views:   if something:       return render_to_response('html_template',.....)  else:       return HttpReponse(jsondata,mimetype='application/json')   Thank you     ","Q_Votes":"62"},{"Q_Title":"Any way to make {% extends '…' %} conditional? - Django","A_Content":"  Use a variable.  {% extends base_template %}   and in your view, set it to \"base.html\" in your view, or a new \"ajax.html\" file which just provides the block and nothing else.     ","Language":"Python","Tags":["python","ajax","django","django-templates"],"URL":"https://stackoverflow.com/questions/5380984/any-way-to-make-extends-conditional-django","A_Votes":"78","_type":"dict","isAccepted":"Yes","Q_Content":"    I would like to share a template between AJAX and regualr HTTP calls, the only difference is that one template needs to be served with the base.html html, the other one without.  Any idea?     ","Q_Votes":"62"},{"Q_Title":"Any way to make {% extends '…' %} conditional? - Django","A_Content":"  The other answers require you to pass an additional context variable. But as long as you can access the request object, there is no need:  {% extends request.is_ajax|yesno:\"app/base_ajax.html,app/base.html\" %}   I found this to be much more convenient.     ","Language":"Python","Tags":["python","ajax","django","django-templates"],"URL":"https://stackoverflow.com/questions/5380984/any-way-to-make-extends-conditional-django","A_Votes":"115","_type":"dict","isAccepted":"No","Q_Content":"    I would like to share a template between AJAX and regualr HTTP calls, the only difference is that one template needs to be served with the base.html html, the other one without.  Any idea?     ","Q_Votes":"62"},{"Q_Title":"Any way to make {% extends '…' %} conditional? - Django","A_Content":"  {% extends override_base|default:'base.html' %}   P.s. I know this is an old question, but I found it when searching for an answer.  Maybe it'll help someone else with the same problem.     ","Language":"Python","Tags":["python","ajax","django","django-templates"],"URL":"https://stackoverflow.com/questions/5380984/any-way-to-make-extends-conditional-django","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I would like to share a template between AJAX and regualr HTTP calls, the only difference is that one template needs to be served with the base.html html, the other one without.  Any idea?     ","Q_Votes":"62"},{"Q_Title":"Any way to make {% extends '…' %} conditional? - Django","A_Content":"  You can use {% extends variable %}  Pass a variable base template name in when you create the context in the view.  http://docs.djangoproject.com/en/dev/ref/templates/builtins/?from=olddocs#extends     ","Language":"Python","Tags":["python","ajax","django","django-templates"],"URL":"https://stackoverflow.com/questions/5380984/any-way-to-make-extends-conditional-django","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I would like to share a template between AJAX and regualr HTTP calls, the only difference is that one template needs to be served with the base.html html, the other one without.  Any idea?     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  >>> import string >>> string.ascii_lowercase[:14] 'abcdefghijklmn' >>> string.ascii_lowercase[:14:2] 'acegikm'   To do the urls, you could use something like this  [i + j for i, j in zip(list_of_urls, string.ascii_lowercase[:14])]      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"133","_type":"dict","isAccepted":"Yes","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  Assuming this is a homework ;-) - no need to summon libraries etc - it probably expect you to use range() with chr/ord, like so:  for i in range(ord('a'), ord('n')+1):     print chr(i),   For the rest, just play a bit more with the range()     ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"37","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  Hints:  import string print string.ascii_lowercase   and   for i in xrange(0, 10, 2):     print i   and  \"hello{0}, world!\".format('z')      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  for one in range(97,110):     print chr(one)      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  Get a list with the desired values  small_letters = map(chr, range(ord('a'), ord('z')+1)) big_letters = map(chr, range(ord('A'), ord('Z')+1)) digits = map(chr, range(ord('0'), ord('9')+1))   or  import string string.letters string.uppercase string.digits   This solution uses the ASCII table. ord gets the ascii value from a character and chr vice versa.  Apply what you know about lists  >>> small_letters = map(chr, range(ord('a'), ord('z')+1))  >>> an = small_letters[0:(ord('n')-ord('a')+1)] >>> print(\" \".join(an)) a b c d e f g h i j k l m n  >>> print(\" \".join(small_letters[0::2])) a c e g i k m o q s u w y  >>> s = small_letters[0:(ord('n')-ord('a')+1):2] >>> print(\" \".join(s)) a c e g i k m  >>> urls = [\"hello.com/\", \"hej.com/\", \"hallo.com/\"] >>> print([x + y for x, y in zip(urls, an)]) ['hello.com/a', 'hej.com/b', 'hallo.com/c']      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  import string print list(string.ascii_lowercase) # ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  #1) print \" \".join(map(chr, range(ord('a'),ord('n')+1)))  #2) print \" \".join(map(chr, range(ord('a'),ord('n')+1,2)))  #3) urls = [\"hello.com/\", \"hej.com/\", \"hallo.com/\"] an = map(chr, range(ord('a'),ord('n')+1)) print [ x + y for x,y in zip(urls, an)]      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  The answer to this question is simple, just make a list called ABC like so:  ABC = ['abcdefghijklmnopqrstuvwxyz']   And whenever you need to refer to it, just do:  print ABC[0:9] #prints abcdefghij print ABC       #prints abcdefghijklmnopqrstuvwxyz for x in range(0,25):     if x % 2 == 0:         print ABC[x] #prints acegikmoqsuwy (all odd numbered letters)   Also try this to break ur device :D  ##Try this and call it AlphabetSoup.py:  ABC = ['abcdefghijklmnopqrstuvwxyz']   try:     while True:         for a in ABC:             for b in ABC:                 for c in ABC:                     for d in ABC:                         for e in ABC:                             for f in ABC:                                 print a, b, c, d, e, f, '    ', except KeyboardInterrupt:     pass      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  This is your 2nd question: string.lowercase[ord('a')-97:ord('n')-97:2] because 97==ord('a') -- if you want to learn a bit you should figure out the rest yourself ;-)     ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  list(string.ascii_lowercase)  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  Try:     strng = \"\" for i in range(97,123):     strng = strng + chr(i) print(strng)      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  import string print list(string.ascii_lowercase) # ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']   and  for c in list(string.ascii_lowercase)[:5]:     ...operation with the first 5 characters      ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Python: how to print range a-z?","A_Content":"  About gnibbler's answer.   Zip -function, full explanation, returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables. [...] construct is called list comprehension, very cool feature!     ","Language":"Python","Tags":["python","string","ascii"],"URL":"https://stackoverflow.com/questions/3190122/python-how-to-print-range-a-z","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    1. Print a-n: a b c d e f g h i j k l m n  2. Every second in a-n: a c e g i k m  3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n     ","Q_Votes":"62"},{"Q_Title":"Replace string within file contents","A_Content":"  with open(\"Stud.txt\", \"rt\") as fin:     with open(\"out.txt\", \"wt\") as fout:         for line in fin:             fout.write(line.replace('A', 'Orange'))      ","Language":"Python","Tags":["python","string","file-io"],"URL":"https://stackoverflow.com/questions/4128144/replace-string-within-file-contents","A_Votes":"138","_type":"dict","isAccepted":"No","Q_Content":"    How can I open a file, Stud.txt, and then replace any occurences of \"A\" with \"Orange\"?     ","Q_Votes":"62"},{"Q_Title":"Replace string within file contents","A_Content":"  If you'd like to replace the strings in the same file, you probably have to read its contents into a local variable, close it, and re-open it for writing:  I am using the with statement in this example, which closes the file after the with block is terminated - either normally when the last command finishes executing, or by an exception.  def inplace_change(filename, old_string, new_string):     # Safely read the input filename using 'with'     with open(filename) as f:         s = f.read()         if old_string not in s:             print '\"{old_string}\" not found in {filename}.'.format(**locals())             return      # Safely write the changed content, if found in the file     with open(filename, 'w') as f:         print 'Changing \"{old_string}\" to \"{new_string}\" in {filename}'.format(**locals())         s = s.replace(old_string, new_string)         f.write(s)   It is worth mentioning that if the filenames were different, we could have done this more elegantly with a single with statement.     ","Language":"Python","Tags":["python","string","file-io"],"URL":"https://stackoverflow.com/questions/4128144/replace-string-within-file-contents","A_Votes":"58","_type":"dict","isAccepted":"No","Q_Content":"    How can I open a file, Stud.txt, and then replace any occurences of \"A\" with \"Orange\"?     ","Q_Votes":"62"},{"Q_Title":"Replace string within file contents","A_Content":"    #!/usr/bin/python    with open(FileName) as f:     newText=f.read().replace('A', 'Orange')    with open(FileName, \"w\") as f:     f.write(newText)      ","Language":"Python","Tags":["python","string","file-io"],"URL":"https://stackoverflow.com/questions/4128144/replace-string-within-file-contents","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    How can I open a file, Stud.txt, and then replace any occurences of \"A\" with \"Orange\"?     ","Q_Votes":"62"},{"Q_Title":"Replace string within file contents","A_Content":"  Something like  file = open('Stud.txt') contents = file.read() replaced_contents = contents.replace('A', 'Orange')  <do stuff with the result>      ","Language":"Python","Tags":["python","string","file-io"],"URL":"https://stackoverflow.com/questions/4128144/replace-string-within-file-contents","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    How can I open a file, Stud.txt, and then replace any occurences of \"A\" with \"Orange\"?     ","Q_Votes":"62"},{"Q_Title":"Replace string within file contents","A_Content":"  with open('Stud.txt','r') as f:     newlines = []     for line in f.readlines():         newlines.append(line.replace('A', 'Orange')) with open('Stud.txt', 'w') as f:     for line in newlines:         f.write(line)      ","Language":"Python","Tags":["python","string","file-io"],"URL":"https://stackoverflow.com/questions/4128144/replace-string-within-file-contents","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    How can I open a file, Stud.txt, and then replace any occurences of \"A\" with \"Orange\"?     ","Q_Votes":"62"},{"Q_Title":"Replace string within file contents","A_Content":"  If you are on linux and just want to replace the word dog with catyou can do:  text.txt:  Hi, i am a dog and dog's are awesome, i love dogs! dog dog dogs!   Linux Command:  sed -i 's/dog/cat/g' test.txt   Output:  Hi, i am a cat and cat's are awesome, i love cats! cat cat cats!   Original Post: https://askubuntu.com/questions/20414/find-and-replace-text-within-a-file-using-commands     ","Language":"Python","Tags":["python","string","file-io"],"URL":"https://stackoverflow.com/questions/4128144/replace-string-within-file-contents","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    How can I open a file, Stud.txt, and then replace any occurences of \"A\" with \"Orange\"?     ","Q_Votes":"62"},{"Q_Title":"Replace string within file contents","A_Content":"  easiest way is to do it with regular expressions, assuming that you want to iterate over each line in the file (where 'A' would be stored) you do...  import re  input = file('C:\\full_path\\Stud.txt), 'r') #when you try and write to a file with write permissions, it clears the file and writes only #what you tell it to the file.  So we have to save the file first.  saved_input for eachLine in input:     saved_input.append(eachLine)  #now we change entries with 'A' to 'Orange' for i in range(0, len(old):     search = re.sub('A', 'Orange', saved_input[i])     if search is not None:         saved_input[i] = search #now we open the file in write mode (clearing it) and writing saved_input back to it input = file('C:\\full_path\\Stud.txt), 'w') for each in saved_input:     input.write(each)      ","Language":"Python","Tags":["python","string","file-io"],"URL":"https://stackoverflow.com/questions/4128144/replace-string-within-file-contents","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I open a file, Stud.txt, and then replace any occurences of \"A\" with \"Orange\"?     ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  I got a faster one for the hex output.  Using the same t1 and t2 as above:  >>> t1 = timeit.Timer(\"''.join(random.choice('0123456789abcdef') for n in xrange(30))\", \"import random\") >>> t2 = timeit.Timer(\"binascii.b2a_hex(os.urandom(15))\", \"import os, binascii\") >>> t3 = timeit.Timer(\"'%030x' % random.randrange(16**30)\", \"import random\") >>> for t in t1, t2, t3: ...     t.timeit() ...  28.165037870407104 9.0292739868164062 5.2836320400238037   t3 only makes one call to the random module, doesn't have to build or read a list, and then does the rest with string formatting.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"94","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  30 digit hex string:  >>> import os,binascii >>> print binascii.b2a_hex(os.urandom(15)) \"c84766ca4a3ce52c3602bbf02ad1f7\"   The advantage is that this gets randomness directly from the OS, which might be more secure and/or faster than the random(), and you don't have to seed it.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"58","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  import string import random lst = [random.choice(string.ascii_letters + string.digits) for n in xrange(30)] str = \"\".join(lst) print str ocwbKCiuAJLRJgM1bWNV1TPSH0F2Lb      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  Dramatically faster solution than those here:  timeit(\"'%0x' % getrandbits(30 * 4)\", \"from random import getrandbits\") 0.8056681156158447      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  Note: random.choice(string.hexdigits) is incorrect, because string.hexdigits returns 0123456789abcdefABCDEF (both lowercase and uppercase), so you will get a biased result, with the hex digit 'c' twice as likely to appear as the digit '7'. Instead, just use random.choice('0123456789abcdef').     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  In Py3.6+, another option is to use the new standard secrets module:  >>> import secrets >>> secrets.token_hex(15) '8d9bad5b43259c6ee27d9aadc7b832' >>> secrets.token_urlsafe(22)   # may include '_-' unclear if that is acceptable 'teRq7IqhaRU0S3euX1ji9f58WzUkrg'      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  Another Method :  from Crypto import Random import binascii  my_hex_value = binascii.hexlify(Random.get_random_bytes(30))   The point is : byte value is always equal to the value in hex.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  One-line funtion:  import random import string   def generate_random_key(length):     return ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(length))  print generate_random_key(30)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  Incidentally, this is the result of using timeit on the two approaches that have been suggested:  Using random.choice():  >>> t1 = timeit.Timer(\"''.join(random.choice(string.hexdigits) for n in xrange(30))\", \"import random, string\") >>> t1.timeit() 69.558588027954102   Using binascii.b2a_hex():  >>> t2 = timeit.Timer(\"binascii.b2a_hex(os.urandom(15))\", \"import os, binascii\") >>> t2.timeit() 16.288421154022217      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Most lightweight way to create a random string and a random hexadecimal number","A_Content":"  There's a faster one compared to what jcdyer has mentioned. This takes ~50% of his fastest  method.  from numpy.random.mtrand import RandomState import binascii rand = RandomState()  lo = 1000000000000000 hi = 999999999999999999 binascii.b2a_hex(rand.randint(lo, hi, 2).tostring())[:30]  >>> timeit.Timer(\"binascii.b2a_hex(rand.randint(lo,hi,2).tostring())[:30]\", \\ ...                 'from __main__ import lo,hi,rand,binascii').timeit() 1.648831844329834         <-- this is on python 2.6.6 2.253110885620117         <-- this on python 2.7.5   If you want in base64:  binascii.b2a_base64(rand.randint(lo, hi, 3).tostring())[:30]   You can change the size parameter passed to randint (last arg) to vary the output length based on your requirement. So, for a 60 char one:  binascii.b2a_hex(rand.randint(lo, hi, 4).tostring())[:60]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/2782229/most-lightweight-way-to-create-a-random-string-and-a-random-hexadecimal-number","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    What is the most lightweight way to create a random string of 30 characters like the following?     ufhy3skj5nca0d2dfh9hwd2tbk9sw1   And an hexadecimal number of 30 digits like the followin?     8c6f78ac23b4a7b8c0182d7a89e9b1      ","Q_Votes":"62"},{"Q_Title":"Python - How to validate a url in python ? (Malformed or not)","A_Content":"  django url validation regex:  regex = re.compile(         r'^(?:http|ftp)s?://' # http:// or https://         r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...         r'localhost|' #localhost...         r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip         r'(?::\\d+)?' # optional port         r'(?:/?|[/?]\\S+)$', re.IGNORECASE)  print re.match(regex, \"http://www.example.com\") is not None   # True print re.match(regex, \"example.com\") is not None              # False      ","Language":"Python","Tags":["python","url","malformedurlexception"],"URL":"https://stackoverflow.com/questions/7160737/python-how-to-validate-a-url-in-python-malformed-or-not","A_Votes":"50","_type":"dict","isAccepted":"Yes","Q_Content":"    I have url from the user and I have to reply with the fetched HTML.  How can I check for the URL to be malformed or not ?  For Example :  url='google'  // Malformed url='google.com'  // Malformed url='http://google.com'  // Valid url='http://google'   // Malformed   How can we achieve this ?     ","Q_Votes":"62"},{"Q_Title":"Python - How to validate a url in python ? (Malformed or not)","A_Content":"  Actually, I think this is the best way.  from django.core.validators import URLValidator from django.core.exceptions import ValidationError  val = URLValidator(verify_exists=False) try:     val('http://www.google.com') except ValidationError, e:     print e   If you set verify_exists to True, it will actually verify that the URL exists, otherwise it will just check if it's formed correctly.  edit: ah yeah, this question is a duplicate of this: How can I check if a URL exists with Django’s validators?     ","Language":"Python","Tags":["python","url","malformedurlexception"],"URL":"https://stackoverflow.com/questions/7160737/python-how-to-validate-a-url-in-python-malformed-or-not","A_Votes":"95","_type":"dict","isAccepted":"No","Q_Content":"    I have url from the user and I have to reply with the fetched HTML.  How can I check for the URL to be malformed or not ?  For Example :  url='google'  // Malformed url='google.com'  // Malformed url='http://google.com'  // Valid url='http://google'   // Malformed   How can we achieve this ?     ","Q_Votes":"62"},{"Q_Title":"Python - How to validate a url in python ? (Malformed or not)","A_Content":"  Use the validators package:  >>> import validators >>> validators.url(\"http://google.com\") True >>> validators.url(\"http://google\") ValidationFailure(func=url, args={'value': 'http://google', 'require_tld': True}) >>> if not validators.url(\"http://google\"): ...     print \"not valid\" ...  not valid >>>   Install it with pip (pip install validators).     ","Language":"Python","Tags":["python","url","malformedurlexception"],"URL":"https://stackoverflow.com/questions/7160737/python-how-to-validate-a-url-in-python-malformed-or-not","A_Votes":"77","_type":"dict","isAccepted":"No","Q_Content":"    I have url from the user and I have to reply with the fetched HTML.  How can I check for the URL to be malformed or not ?  For Example :  url='google'  // Malformed url='google.com'  // Malformed url='http://google.com'  // Valid url='http://google'   // Malformed   How can we achieve this ?     ","Q_Votes":"62"},{"Q_Title":"Python - How to validate a url in python ? (Malformed or not)","A_Content":"  A True or False version, based on @DMfll answer:  try:     # python2     from urlparse import urlparse except:     # python3     from urllib.parse import urlparse  a = 'http://www.cwi.nl:80/%7Eguido/Python.html' b = '/data/Python.html' c = 532 d = u'dkakasdkjdjakdjadjfalskdjfalk'  def uri_validator(x):     try:         result = urlparse(x)         return result.scheme and result.netloc and result.path     except:         return False  print(uri_validator(a)) print(uri_validator(b)) print(uri_validator(c)) print(uri_validator(d))   Gives:  True True False True      ","Language":"Python","Tags":["python","url","malformedurlexception"],"URL":"https://stackoverflow.com/questions/7160737/python-how-to-validate-a-url-in-python-malformed-or-not","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I have url from the user and I have to reply with the fetched HTML.  How can I check for the URL to be malformed or not ?  For Example :  url='google'  // Malformed url='google.com'  // Malformed url='http://google.com'  // Valid url='http://google'   // Malformed   How can we achieve this ?     ","Q_Votes":"62"},{"Q_Title":"Python - How to validate a url in python ? (Malformed or not)","A_Content":"  note - lepl is no longer supported, sorry (you're welcome to use it, and i think the code below works, but it's not going to get updates).  rfc 3696 http://www.faqs.org/rfcs/rfc3696.html defines how to do this (for http urls and email).  i implemented its recommendations in python using lepl (a parser library).  see http://acooke.org/lepl/rfc3696.html  to use:  > easy_install lepl ... > python ... >>> from lepl.apps.rfc3696 import HttpUrl >>> validator = HttpUrl() >>> validator('google') False >>> validator('http://google') False >>> validator('http://google.com') True      ","Language":"Python","Tags":["python","url","malformedurlexception"],"URL":"https://stackoverflow.com/questions/7160737/python-how-to-validate-a-url-in-python-malformed-or-not","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have url from the user and I have to reply with the fetched HTML.  How can I check for the URL to be malformed or not ?  For Example :  url='google'  // Malformed url='google.com'  // Malformed url='http://google.com'  // Valid url='http://google'   // Malformed   How can we achieve this ?     ","Q_Votes":"62"},{"Q_Title":"Python - How to validate a url in python ? (Malformed or not)","A_Content":"  I landed on this page trying to figure out a sane way to validate strings as \"valid\" urls. I share here my solution using python3. No extra libraries required.  See https://docs.python.org/2/library/urlparse.html if you are using python2.  See https://docs.python.org/3.0/library/urllib.parse.html if you are using python3 as I am.  import urllib from pprint import pprint  invalid_url = 'dkakasdkjdjakdjadjfalskdjfalk' valid_url = 'https://stackoverflow.com' tokens = [urllib.parse.urlparse(url) for url in (invalid_url, valid_url)]  for token in tokens:     pprint(token)  min_attributes = ('scheme', 'netloc')  # add attrs to your liking for token in tokens:     if not all([getattr(token, attr) for attr in min_attributes]):         error = \"'{url}' string has no scheme or netloc.\".format(url=token.geturl())         print(error)     else:         print(\"'{url}' is probably a valid url.\".format(url=token.geturl()))      ParseResult(scheme='', netloc='', path='dkakasdkjdjakdjadjfalskdjfalk', params='', query='', fragment='')      ParseResult(scheme='https', netloc='stackoverflow.com', path='', params='', query='', fragment='')      'dkakasdkjdjakdjadjfalskdjfalk' string has no scheme or netloc.      'https://stackoverflow.com' is probably a valid url.   Here is a more concise function:  import urllib  min_attributes = ('scheme', 'netloc')   def is_valid(url, qualifying=None):     qualifying = min_attributes if qualifying is None else qualifying     token = urllib.parse.urlparse(url)     return all([getattr(token, qualifying_attr)                 for qualifying_attr in qualifying])      ","Language":"Python","Tags":["python","url","malformedurlexception"],"URL":"https://stackoverflow.com/questions/7160737/python-how-to-validate-a-url-in-python-malformed-or-not","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have url from the user and I have to reply with the fetched HTML.  How can I check for the URL to be malformed or not ?  For Example :  url='google'  // Malformed url='google.com'  // Malformed url='http://google.com'  // Valid url='http://google'   // Malformed   How can we achieve this ?     ","Q_Votes":"62"},{"Q_Title":"Python - How to validate a url in python ? (Malformed or not)","A_Content":"  EDIT As pointed out by @Kwame , the code does validate the url even if teh .com , .co are not present.  This is simple and works:  So min_attr has the basic string that needs to be present to define the URL , i.e http:// part and google.com part.  urlparse.scheme stores http:// and   urlparse.netloc store the domain name google.com  all() returns true if all the variables inside it return true. So if result.scheme and result.netloc is present , the URL is valid and hence returns True.  from urlparse import urlparse def url_check(url):      min_attr = ('scheme' , 'netloc')     try:         result = urlparse(url)         if all([result.scheme, result.netloc]):             return True         else:             return False     except:         return False      ","Language":"Python","Tags":["python","url","malformedurlexception"],"URL":"https://stackoverflow.com/questions/7160737/python-how-to-validate-a-url-in-python-malformed-or-not","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have url from the user and I have to reply with the fetched HTML.  How can I check for the URL to be malformed or not ?  For Example :  url='google'  // Malformed url='google.com'  // Malformed url='http://google.com'  // Valid url='http://google'   // Malformed   How can we achieve this ?     ","Q_Votes":"62"},{"Q_Title":"Python MySQL Parameterized Queries","A_Content":"  Beware of using string interpolation for SQL queries, since it won't escape the input parameters correctly and will leave your application open to SQL injection vulnerabilities. The difference might seem trivial, but in reality it's huge.  Incorrect (with security issues)  c.execute(\"SELECT * FROM foo WHERE bar = %s AND baz = %s\" % (param1, param2))   Correct (with escaping)  c.execute(\"SELECT * FROM foo WHERE bar = %s AND baz = %s\", (param1, param2))   It adds to the confusion that the modifiers used to bind parameters in a SQL statement varies between different DB API implementations and that the mysql client library uses printf style syntax instead of the more commonly accepted '?' marker (used by eg. python-sqlite).     ","Language":"Python","Tags":["python","mysql"],"URL":"https://stackoverflow.com/questions/775296/python-mysql-parameterized-queries","A_Votes":"211","_type":"dict","isAccepted":"Yes","Q_Content":"    I am having a hard time using the MySQLdb module to insert information into my database.  I need to insert 6 variables into the table.    cursor.execute (\"\"\"     INSERT INTO Songs (SongName, SongArtist, SongAlbum, SongGenre, SongLength, SongLocation)     VALUES         (var1, var2, var3, var4, var5, var6)  \"\"\")   Can someone help me with the syntax here?     ","Q_Votes":"62"},{"Q_Title":"Python MySQL Parameterized Queries","A_Content":"  You have a few options available. You'll want to get comfortable with python's string iterpolation. Which is a term you might have more success searching for in the future when  you want to know stuff like this.  Better for queries:  some_dictionary_with_the_data = {     'name': 'awesome song',     'artist': 'some band',     etc... } cursor.execute (\"\"\"             INSERT INTO Songs (SongName, SongArtist, SongAlbum, SongGenre, SongLength, SongLocation)             VALUES                 (%(name)s, %(artist)s, %(album)s, %(genre)s, %(length)s, %(location)s)          \"\"\", some_dictionary_with_the_data)   Considering you probably have all of your data in an object or dictionary already, the second format will suit you better. Also it sucks to have to count \"%s\" appearances in a string when you have to come back and update this method in a year :)     ","Language":"Python","Tags":["python","mysql"],"URL":"https://stackoverflow.com/questions/775296/python-mysql-parameterized-queries","A_Votes":"33","_type":"dict","isAccepted":"No","Q_Content":"    I am having a hard time using the MySQLdb module to insert information into my database.  I need to insert 6 variables into the table.    cursor.execute (\"\"\"     INSERT INTO Songs (SongName, SongArtist, SongAlbum, SongGenre, SongLength, SongLocation)     VALUES         (var1, var2, var3, var4, var5, var6)  \"\"\")   Can someone help me with the syntax here?     ","Q_Votes":"62"},{"Q_Title":"Python MySQL Parameterized Queries","A_Content":"  The linked docs give the following example:     cursor.execute (\"\"\"          UPDATE animal SET name = %s          WHERE name = %s        \"\"\", (\"snake\", \"turtle\"))    print \"Number of rows updated: %d\" % cursor.rowcount   So you just need to adapt this to your own code - example:  cursor.execute (\"\"\"             INSERT INTO Songs (SongName, SongArtist, SongAlbum, SongGenre, SongLength, SongLocation)             VALUES                 (%s, %s, %s, %s, %s, %s)          \"\"\", (var1, var2, var3, var4, var5, var6))   (If SongLength is numeric, you may need to use %d instead of %s).     ","Language":"Python","Tags":["python","mysql"],"URL":"https://stackoverflow.com/questions/775296/python-mysql-parameterized-queries","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I am having a hard time using the MySQLdb module to insert information into my database.  I need to insert 6 variables into the table.    cursor.execute (\"\"\"     INSERT INTO Songs (SongName, SongArtist, SongAlbum, SongGenre, SongLength, SongLocation)     VALUES         (var1, var2, var3, var4, var5, var6)  \"\"\")   Can someone help me with the syntax here?     ","Q_Votes":"62"},{"Q_Title":"Python MySQL Parameterized Queries","A_Content":"  Actually, even if your variable (SongLength) is numeric, you will still have to format it with %s in order to bind the parameter correctly.  If you try to use %d, you will get an error.  Here's a small excerpt from this link http://mysql-python.sourceforge.net/MySQLdb.html:  To perform a query, you first need a cursor, and then you can execute queries on it:  c=db.cursor() max_price=5 c.execute(\"\"\"SELECT spam, eggs, sausage FROM breakfast           WHERE price < %s\"\"\", (max_price,))   In this example, max_price=5 Why, then, use %s in the string? Because MySQLdb will convert it to a SQL literal value, which is the string '5'. When it's finished, the query will actually say, \"...WHERE price < 5\".     ","Language":"Python","Tags":["python","mysql"],"URL":"https://stackoverflow.com/questions/775296/python-mysql-parameterized-queries","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am having a hard time using the MySQLdb module to insert information into my database.  I need to insert 6 variables into the table.    cursor.execute (\"\"\"     INSERT INTO Songs (SongName, SongArtist, SongAlbum, SongGenre, SongLength, SongLocation)     VALUES         (var1, var2, var3, var4, var5, var6)  \"\"\")   Can someone help me with the syntax here?     ","Q_Votes":"62"},{"Q_Title":"Python MySQL Parameterized Queries","A_Content":"  As an alternative to the chosen answer, and with the same safe semantics of Marcel's, here is a compact way of using a Python dictionary to specify the values. It has the benefit of being easy to modify as you add or remove columns to insert:    meta_cols=('SongName','SongArtist','SongAlbum','SongGenre')   insert='insert into Songs ({0}) values ({1})'.         .format(','.join(meta_cols), ','.join( ['%s']*len(meta_cols) ))   args = [ meta[i] for i in meta_cols ]   cursor=db.cursor()   cursor.execute(insert,args)   db.commit()   Where meta is the dictionary holding the values to insert. Update can be done in the same way:    meta_cols=('SongName','SongArtist','SongAlbum','SongGenre')   update='update Songs set {0} where id=%s'.         .format(','.join([ '{0}=%s'.format(c) for c in meta_cols ]))   args = [ meta[i] for i in meta_cols ]   args.append( songid )   cursor=db.cursor()   cursor.execute(update,args)   db.commit()      ","Language":"Python","Tags":["python","mysql"],"URL":"https://stackoverflow.com/questions/775296/python-mysql-parameterized-queries","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am having a hard time using the MySQLdb module to insert information into my database.  I need to insert 6 variables into the table.    cursor.execute (\"\"\"     INSERT INTO Songs (SongName, SongArtist, SongAlbum, SongGenre, SongLength, SongLocation)     VALUES         (var1, var2, var3, var4, var5, var6)  \"\"\")   Can someone help me with the syntax here?     ","Q_Votes":"62"},{"Q_Title":"Python MySQL Parameterized Queries","A_Content":"  Here is another way to do it. It's documented on the MySQL official website. https://dev.mysql.com/doc/connector-python/en/connector-python-api-mysqlcursor-execute.html  In the spirit, it's using the same mechanic of @Trey Stout's answer. However, I find this one prettier and more readable.  insert_stmt = (   \"INSERT INTO employees (emp_no, first_name, last_name, hire_date) \"   \"VALUES (%s, %s, %s, %s)\" ) data = (2, 'Jane', 'Doe', datetime.date(2012, 3, 23)) cursor.execute(insert_stmt, data)   And to better illustrate any need for variables:  NB: note the escape being done.  employee_id = 2 first_name = \"Jane\" last_name = \"Doe\"  insert_stmt = (   \"INSERT INTO employees (emp_no, first_name, last_name, hire_date) \"   \"VALUES (%s, %s, %s, %s)\" ) data = (employee_id, conn.escape_string(first_name), conn.escape_string(last_name), datetime.date(2012, 3, 23)) cursor.execute(insert_stmt, data)      ","Language":"Python","Tags":["python","mysql"],"URL":"https://stackoverflow.com/questions/775296/python-mysql-parameterized-queries","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am having a hard time using the MySQLdb module to insert information into my database.  I need to insert 6 variables into the table.    cursor.execute (\"\"\"     INSERT INTO Songs (SongName, SongArtist, SongAlbum, SongGenre, SongLength, SongLocation)     VALUES         (var1, var2, var3, var4, var5, var6)  \"\"\")   Can someone help me with the syntax here?     ","Q_Votes":"62"},{"Q_Title":"Python MySQL Parameterized Queries","A_Content":"  The first solution works well. I want to add one small detail here. Make sure the variable you are trying to replace/update it will has to be a type str. My mysql type is decimal but I had to make the parameter variable as str to be able to execute the query.   temp = \"100\" myCursor.execute(\"UPDATE testDB.UPS SET netAmount = %s WHERE auditSysNum = '42452'\",(temp,)) myCursor.execute(var)      ","Language":"Python","Tags":["python","mysql"],"URL":"https://stackoverflow.com/questions/775296/python-mysql-parameterized-queries","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am having a hard time using the MySQLdb module to insert information into my database.  I need to insert 6 variables into the table.    cursor.execute (\"\"\"     INSERT INTO Songs (SongName, SongArtist, SongAlbum, SongGenre, SongLength, SongLocation)     VALUES         (var1, var2, var3, var4, var5, var6)  \"\"\")   Can someone help me with the syntax here?     ","Q_Votes":"62"},{"Q_Title":"How do you get the process ID of a program in Unix or Linux using Python?","A_Content":"  Try pgrep.  Its output format is much simpler and therefore easier to parse.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3761639/how-do-you-get-the-process-id-of-a-program-in-unix-or-linux-using-python","A_Votes":"13","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm writing some monitoring scripts in Python and I'm trying to find the cleanest way to get the process ID of any random running program given the name of that program  something like  ps -ef | grep MyProgram   I could parse the output of that however I thought there might be a better way in python     ","Q_Votes":"62"},{"Q_Title":"How do you get the process ID of a program in Unix or Linux using Python?","A_Content":"  From the standard library:  os.getpid()      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3761639/how-do-you-get-the-process-id-of-a-program-in-unix-or-linux-using-python","A_Votes":"252","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing some monitoring scripts in Python and I'm trying to find the cleanest way to get the process ID of any random running program given the name of that program  something like  ps -ef | grep MyProgram   I could parse the output of that however I thought there might be a better way in python     ","Q_Votes":"62"},{"Q_Title":"How do you get the process ID of a program in Unix or Linux using Python?","A_Content":"  If you are not limiting yourself to the standard library, I like psutil for this.  For instance to find all \"python\" processes:  >>> import psutil >>> [p.info for p in psutil.process_iter(attrs=['pid', 'name']) if 'python' in p.info['name']] [{'name': 'python3', 'pid': 21947},  {'name': 'python', 'pid': 23835}]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3761639/how-do-you-get-the-process-id-of-a-program-in-unix-or-linux-using-python","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing some monitoring scripts in Python and I'm trying to find the cleanest way to get the process ID of any random running program given the name of that program  something like  ps -ef | grep MyProgram   I could parse the output of that however I thought there might be a better way in python     ","Q_Votes":"62"},{"Q_Title":"How do you get the process ID of a program in Unix or Linux using Python?","A_Content":"  Also: Python: How to get PID by process name?  Adaptation to previous posted answers.  def getpid(process_name):     import os     return [item.split()[1] for item in os.popen('tasklist').read().splitlines()[4:] if process_name in item.split()]  getpid('cmd.exe') ['6560', '3244', '9024', '4828']      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3761639/how-do-you-get-the-process-id-of-a-program-in-unix-or-linux-using-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing some monitoring scripts in Python and I'm trying to find the cleanest way to get the process ID of any random running program given the name of that program  something like  ps -ef | grep MyProgram   I could parse the output of that however I thought there might be a better way in python     ","Q_Votes":"62"},{"Q_Title":"How do you get the process ID of a program in Unix or Linux using Python?","A_Content":"  For Windows  A Way to get all the pids of programs on your computer without downloading any modules:  import os  pids = [] a = os.popen(\"tasklist\").readlines() for x in a:       try:          pids.append(int(x[29:34]))       except:            pass for each in pids:          print(each)   If you just wanted one program or all programs with the same name and you wanted to kill the process or something:  import os, sys, win32api  tasklistrl = os.popen(\"tasklist\").readlines() tasklistr = os.popen(\"tasklist\").read()  print(tasklistr)  def kill(process):      process_exists_forsure = False      gotpid = False      for examine in tasklistrl:             if process == examine[0:len(process)]:                 process_exists_forsure = True      if process_exists_forsure:          print(\"That process exists.\")      else:         print(\"That process does not exist.\")         raw_input()         sys.exit()      for getpid in tasklistrl:          if process == getpid[0:len(process)]:                 pid = int(getpid[29:34])                 gotpid = True                 try:                   handle = win32api.OpenProcess(1, False, pid)                   win32api.TerminateProcess(handle, 0)                   win32api.CloseHandle(handle)                   print(\"Successfully killed process %s on pid %d.\" % (getpid[0:len(prompt)], pid))                 except win32api.error as err:                   print(err)                   raw_input()                   sys.exit()     if not gotpid:        print(\"Could not get process pid.\")        raw_input()        sys.exit()     raw_input()    sys.exit()  prompt = raw_input(\"Which process would you like to kill? \") kill(prompt)   That was just a paste of my process kill program I could make it a whole lot better but it is okay.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3761639/how-do-you-get-the-process-id-of-a-program-in-unix-or-linux-using-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing some monitoring scripts in Python and I'm trying to find the cleanest way to get the process ID of any random running program given the name of that program  something like  ps -ef | grep MyProgram   I could parse the output of that however I thought there might be a better way in python     ","Q_Votes":"62"},{"Q_Title":"How do you get the process ID of a program in Unix or Linux using Python?","A_Content":"  With psutil:  (can be installed with [sudo] pip install psutil)  import psutil  # Get current process pid current_process_pid = psutil.Process().pid print(current_process_pid)  # e.g 12971  # Get pids by program name program_name = 'chrome' process_pids = [process.pid for process in psutil.process_iter() if process.name == program_name] print(process_pids)  # e.g [1059, 2343, ..., ..., 9645]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3761639/how-do-you-get-the-process-id-of-a-program-in-unix-or-linux-using-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing some monitoring scripts in Python and I'm trying to find the cleanest way to get the process ID of any random running program given the name of that program  something like  ps -ef | grep MyProgram   I could parse the output of that however I thought there might be a better way in python     ","Q_Votes":"62"},{"Q_Title":"How do you get the process ID of a program in Unix or Linux using Python?","A_Content":"  For posix (Linux, BSD, etc... only need /proc directory to be mounted) it's easier to work with os files in /proc  Works on python 2 and 3 ( The only difference is the Exception tree, therefore the \"except Exception\", which i dislike but kept to maintain compatibility. Also could've created custom exception.)  #!/usr/bin/env python  import os import sys   for dirname in os.listdir('/proc'):     if dirname == 'curproc':         continue      try:         with open('/proc/{}/cmdline'.format(dirname), mode='rb') as fd:             content = fd.read().decode().split('\\x00')     except Exception:         continue      for i in sys.argv[1:]:         if i in content[0]:             # dirname is also the number of PID             print('{0:<12} : {1}'.format(dirname, ' '.join(content)))   Sample Output (it works like pgrep):  phoemur ~/python $ ./pgrep.py bash 1487         : -bash  1779         : /bin/bash      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3761639/how-do-you-get-the-process-id-of-a-program-in-unix-or-linux-using-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing some monitoring scripts in Python and I'm trying to find the cleanest way to get the process ID of any random running program given the name of that program  something like  ps -ef | grep MyProgram   I could parse the output of that however I thought there might be a better way in python     ","Q_Votes":"62"},{"Q_Title":"How do you get the process ID of a program in Unix or Linux using Python?","A_Content":"  This is a simplified variation of Fernando's answer.  This is for Linux and either Python 2 or 3.  No external library is needed, and no external process is run.  import glob  def get_command_pid(command):     for path in glob.glob('/proc/*/comm'):         if open(path).read().rstrip() == command:             return path.split('/')[2]   Only the first matching process found will be returned, which works well for some purposes.  To get the PIDs of multiple matching processes, you could just replace the return with yield, and then get a list with pids = list(get_command_pid(command)).  Alternatively, as a single expression:  For one process:  next(path.split('/')[2] for path in glob.glob('/proc/*/comm') if open(path).read().rstrip() == command)   For multiple processes:  [path.split('/')[2] for path in glob.glob('/proc/*/comm') if open(path).read().rstrip() == command]      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3761639/how-do-you-get-the-process-id-of-a-program-in-unix-or-linux-using-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing some monitoring scripts in Python and I'm trying to find the cleanest way to get the process ID of any random running program given the name of that program  something like  ps -ef | grep MyProgram   I could parse the output of that however I thought there might be a better way in python     ","Q_Votes":"62"},{"Q_Title":"How do you get the process ID of a program in Unix or Linux using Python?","A_Content":"  The task can be solved using the following piece of code, [0:28] being interval where the name is being held, while [29:34] contains the actual pid.  import os  program_pid = 0 program_name = \"notepad.exe\"  task_manager_lines = os.popen(\"tasklist\").readlines() for line in task_manager_lines:     try:         if str(line[0:28]) == program_name + (28 - len(program_name) * ' ': #so it includes the whitespaces             program_pid = int(line[29:34])             break     except:         pass  print(program_pid)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3761639/how-do-you-get-the-process-id-of-a-program-in-unix-or-linux-using-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing some monitoring scripts in Python and I'm trying to find the cleanest way to get the process ID of any random running program given the name of that program  something like  ps -ef | grep MyProgram   I could parse the output of that however I thought there might be a better way in python     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  People seem to be over complicating this.. Just combine the two lists, then sort them:  >>> l1 = [1, 3, 4, 7] >>> l2 = [0, 2, 5, 6, 8, 9] >>> l1.extend(l2) >>> sorted(l1) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]   ..or shorter (and without modifying l1):  >>> sorted(l1 + l2) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]   ..easy! Plus, it's using only two built-in functions, so assuming the lists are of a reasonable size, it should be quicker than implementing the sorting/merging in a loop. More importantly, the above is much less code, and very readable.  If your lists are large (over a few hundred thousand, I would guess), it may be quicker to use an alternative/custom sorting method, but there are likely other optimisations to be made first (e.g not storing millions of datetime objects)  Using the timeit.Timer().repeat() (which repeats the functions 1000000 times), I loosely benchmarked it against ghoseb's solution, and sorted(l1+l2) is substantially quicker:  merge_sorted_lists took..  [9.7439379692077637, 9.8844599723815918, 9.552299976348877]   sorted(l1+l2) took..  [2.860386848449707, 2.7589840888977051, 2.7682540416717529]      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"102","_type":"dict","isAccepted":"Yes","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"     is there a smarter way to do this in Python   This hasn't been mentioned, so I'll go ahead - there is a merge stdlib function in the heapq module of python 2.6+. If all you're looking to do is getting things done, this might be a better idea. Of course, if you want to implement your own, the merge of merge-sort is the way to go.  >>> list1 = [1, 5, 8, 10, 50] >>> list2 = [3, 4, 29, 41, 45, 49] >>> from heapq import merge >>> list(merge(list1, list2)) [1, 3, 4, 5, 8, 10, 29, 41, 45, 49, 50]   Here's the documentation.     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"90","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  Long story short, unless len(l1 + l2) ~ 1000000 use:  L = l1 + l2 L.sort()     Description of the figure and source code can be found here.   The figure was generated by the following command:  $ python make-figures.py --nsublists 2 --maxn=0x100000 -s merge_funcs.merge_26 -s merge_funcs.sort_builtin      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"49","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  This is simply merging. Treat each list as if it were a stack, and continuously pop the smaller of the two stack heads, adding the item to the result list, until one of the stacks is empty. Then add all remaining items to the resulting list.     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  There is a slight flaw in ghoseb's solution, making it O(n**2), rather than O(n). The problem is that this is performing:  item = l1.pop(0)   With linked lists or deques this would be an O(1) operation, so wouldn't affect complexity, but since python lists are implemented as vectors, this copies the rest of the elements of l1 one space left, an O(n) operation.  Since this is done each pass through the list, it turns an O(n) algorithm into an O(n**2) one.  This can be corrected by using a method that doesn't alter the source lists, but just keeps track of the current position.  I've tried out benchmarking a corrected algorithm vs a simple sorted(l1+l2) as suggested by dbr  def merge(l1,l2):     if not l1:  return list(l2)     if not l2:  return list(l1)      # l2 will contain last element.     if l1[-1] > l2[-1]:         l1,l2 = l2,l1      it = iter(l2)     y = it.next()     result = []      for x in l1:         while y < x:             result.append(y)             y = it.next()         result.append(x)     result.append(y)     result.extend(it)     return result   I've tested these with lists generated with  l1 = sorted([random.random() for i in range(NITEMS)]) l2 = sorted([random.random() for i in range(NITEMS)])   For various sizes of list, I get the following timings (repeating 100 times):  # items:  1000   10000 100000 1000000 merge  :  0.079  0.798 9.763  109.044  sort   :  0.020  0.217 5.948  106.882   So in fact, it looks like dbr is right, just using sorted() is preferable unless you're expecting very large lists, though it does have worse algorithmic complexity.  The break even point being at around a million items in each source list (2 million total).  One advantage of the merge approach though is that it is trivial to rewrite as a generator, which will use substantially less memory (no need for an intermediate list).  [Edit] I've retried this with a situation closer to the question - using a list of objects containing a field \"date\" which is a datetime object. The above algorithm was changed to compare against .date instead, and the sort method was changed to:  return sorted(l1 + l2, key=operator.attrgetter('date'))   This does change things a bit.  The comparison being more expensive means that the number we perform becomes more important, relative to the constant-time speed of the implementation.  This means merge makes up lost ground, surpassing the sort() method at 100,000 items instead.  Comparing based on an even more complex object (large strings or lists for instance) would likely shift this balance even more.  # items:  1000   10000 100000  1000000[1] merge  :  0.161  2.034 23.370  253.68 sort   :  0.111  1.523 25.223  313.20   [1]: Note: I actually only did 10 repeats for 1,000,000 items and scaled up accordingly as it was pretty slow.     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  This is simple merging of two sorted lists. Take a look at the sample code below which merges two sorted lists of integers.  #!/usr/bin/env python ## merge.py -- Merge two sorted lists -*- Python -*- ## Time-stamp: \"2009-01-21 14:02:57 ghoseb\"  l1 = [1, 3, 4, 7] l2 = [0, 2, 5, 6, 8, 9]  def merge_sorted_lists(l1, l2):     \"\"\"Merge sort two sorted lists      Arguments:     - `l1`: First sorted list     - `l2`: Second sorted list     \"\"\"     sorted_list = []      # Copy both the args to make sure the original lists are not     # modified     l1 = l1[:]     l2 = l2[:]      while (l1 and l2):         if (l1[0] <= l2[0]): # Compare both heads             item = l1.pop(0) # Pop from the head             sorted_list.append(item)         else:             item = l2.pop(0)             sorted_list.append(item)      # Add the remaining of the lists     sorted_list.extend(l1 if l1 else l2)      return sorted_list  if __name__ == '__main__':     print merge_sorted_lists(l1, l2)   This should work fine with datetime objects. Hope this helps.     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  from datetime import datetime from itertools import chain from operator import attrgetter  class DT:     def __init__(self, dt):         self.dt = dt  list1 = [DT(datetime(2008, 12, 5, 2)),          DT(datetime(2009, 1, 1, 13)),          DT(datetime(2009, 1, 3, 5))]  list2 = [DT(datetime(2008, 12, 31, 23)),          DT(datetime(2009, 1, 2, 12)),          DT(datetime(2009, 1, 4, 15))]  list3 = sorted(chain(list1, list2), key=attrgetter('dt')) for item in list3:     print item.dt   The output:  2008-12-05 02:00:00 2008-12-31 23:00:00 2009-01-01 13:00:00 2009-01-02 12:00:00 2009-01-03 05:00:00 2009-01-04 15:00:00   I bet this is faster than any of the fancy pure-Python merge algorithms, even for large data. Python 2.6's heapq.merge is a whole another story.     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  Python's sort implementation \"timsort\" is specifically optimized for lists that contain ordered sections.  Plus, it's written in C.    http://bugs.python.org/file4451/timsort.txt http://en.wikipedia.org/wiki/Timsort  As people have mentioned, it may call the comparison function more times by some constant factor (but maybe call it more times in a shorter period in many cases!).     I would never rely on this, however. – Daniel Nadasi   I believe the Python developers are committed to keeping timsort, or at least keeping a sort that's O(n) in this case.     Generalized sorting (i.e. leaving apart radix sorts from limited value domains)   cannot be done in less than O(n log n) on a serial machine. – Barry Kelly   Right, sorting in the general case can't be faster than that.  But since O() is an upper bound, timsort being O(n log n) on arbitrary input doesn't contradict its being O(n) given sorted(L1) + sorted(L2).     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  Recursive implementation is below. Average performance is O(n).  def merge_sorted_lists(A, B, sorted_list = None):     if sorted_list == None:         sorted_list = []      slice_index = 0     for element in A:         if element <= B[0]:             sorted_list.append(element)             slice_index += 1         else:             return merge_sorted_lists(B, A[slice_index:], sorted_list)      return sorted_list + B   or generator with improved space complexity:  def merge_sorted_lists_as_generator(A, B):     slice_index = 0     for element in A:         if element <= B[0]:             slice_index += 1             yield element                else:             for sorted_element in merge_sorted_lists_as_generator(B, A[slice_index:]):                 yield sorted_element             return              for element in B:         yield element      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  Well, the naive approach (combine 2 lists into large one and sort) will be O(N*log(N)) complexity. On the other hand, if you implement the merge manually (i do not know about any ready code in python libs for this, but i'm no expert) the complexity will be O(N), which is clearly faster. The idea is described wery well in post by Barry Kelly.     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  Use the 'merge' step of merge sort, it runs in O(n) time.  From wikipedia (pseudo-code):  function merge(left,right)     var list result     while length(left) > 0 and length(right) > 0         if first(left) ≤ first(right)             append first(left) to result             left = rest(left)         else             append first(right) to result             right = rest(right)     end while     while length(left) > 0          append left to result     while length(right) > 0          append right to result     return result      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  If you want to do it in a manner more consistent with learning what goes on in the iteration try this  def merge_arrays(a, b):     l= []      while len(a) > 0 and len(b)>0:         if a[0] < b[0]: l.append(a.pop(0))             else:l.append(b.pop(0))      l.extend(a+b)     print( l )      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  import random      n=int(input(\"Enter size of table 1\")); #size of list 1     m=int(input(\"Enter size of table 2\")); # size of list 2     tb1=[random.randrange(1,101,1) for _ in range(n)] # filling the list with random     tb2=[random.randrange(1,101,1) for _ in range(m)] # numbers between 1 and 100     tb1.sort(); #sort the list 1      tb2.sort(); # sort the list 2     fus=[]; # creat an empty list     print(tb1); # print the list 1     print('------------------------------------');     print(tb2); # print the list 2     print('------------------------------------');     i=0;j=0;  # varialbles to cross the list     while(i<n and j<m):         if(tb1[i]<tb2[j]):             fus.append(tb1[i]);              i+=1;         else:             fus.append(tb2[j]);             j+=1;      if(i<n):         fus+=tb1[i:n];     if(j<m):         fus+=tb2[j:m];      print(fus);    # this code is used to merge two sorted lists in one sorted list (FUS) without   #sorting the (FUS)      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  Have used merge step of the merge sort. But I have used generators.  Time complexity O(n)  def merge(lst1,lst2):     len1=len(lst1)     len2=len(lst2)     i,j=0,0     while(i<len1 and j<len2):         if(lst1[i]<lst2[j]):                 yield lst1[i]                 i+=1         else:                 yield lst2[j]                 j+=1     if(i==len1):         while(j<len2):                 yield lst2[j]                 j+=1     elif(j==len2):         while(i<len1):                 yield lst1[i]                 i+=1 l1=[1,3,5,7] l2=[2,4,6,8,9] mergelst=(val for val in merge(l1,l2)) print(*mergelst)      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  def merge_sort(a,b):      pa = 0     pb = 0     result = []      while pa < len(a) and pb < len(b):         if a[pa] <= b[pb]:             result.append(a[pa])             pa += 1         else:             result.append(b[pb])             pb += 1      remained = a[pa:] + b[pb:]     result.extend(remained)   return result      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  An implementation of the merging step in Merge Sort that iterates through both lists:  def merge_lists(L1, L2):     \"\"\"     L1, L2: sorted lists of numbers, one of them could be empty.      returns a merged and sorted list of L1 and L2.     \"\"\"      # When one of them is an empty list, returns the other list     if not L1:         return L2     elif not L2:         return L1      result = []     i = 0     j = 0      for k in range(len(L1) + len(L2)):         if L1[i] <= L2[j]:             result.append(L1[i])             if i < len(L1) - 1:                 i += 1             else:                 result += L2[j:]  # When the last element in L1 is reached,                 break             # append the rest of L2 to result.         else:             result.append(L2[j])             if j < len(L2) - 1:                 j += 1             else:                 result += L1[i:]  # When the last element in L2 is reached,                 break             # append the rest of L1 to result.      return result  L1 = [1, 3, 5] L2 = [2, 4, 6, 8] merge_lists(L1, L2)               # Should return [1, 2, 3, 4, 5, 6, 8] merge_lists([], L1)               # Should return [1, 3, 5]   I'm still learning about algorithms, please let me know if the code could be improved in any aspect, your feedback is appreciated, thanks!     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  def compareDate(obj1, obj2):     if obj1.getDate() < obj2.getDate():         return -1     elif obj1.getDate() > obj2.getDate():         return 1     else:         return 0    list = list1 + list2 list.sort(compareDate)   Will sort the list in place. Define your own function for comparing two objects, and pass that function into the built in sort function.  Do NOT use bubble sort, it has horrible performance.     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  This is my solution in linear time without editing l1 and l2:  def merge(l1, l2):   m, m2 = len(l1), len(l2)   newList = []   l, r = 0, 0   while l < m and r < m2:     if l1[l] < l2[r]:       newList.append(l1[l])       l += 1     else:       newList.append(l2[r])       r += 1   return newList + l1[l:] + l2[r:]      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  This code has time complexity O(n) and can merge lists of any data type, given a quantifying function as the parameter func. It produces a new merged list and does not modify either of the lists passed as arguments.  def merge_sorted_lists(listA,listB,func):     merged = list()     iA = 0     iB = 0     while True:         hasA = iA < len(listA)         hasB = iB < len(listB)         if not hasA and not hasB:             break         valA = None if not hasA else listA[iA]         valB = None if not hasB else listB[iB]         a = None if not hasA else func(valA)         b = None if not hasB else func(valB)         if (not hasB or a<b) and hasA:             merged.append(valA)             iA += 1         elif hasB:             merged.append(valB)             iB += 1     return merged      ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"Combining two sorted lists in Python","A_Content":"  Hope this helps. Pretty Simple and straight forward:  l1 = [1, 3, 4, 7]  l2 = [0, 2, 5, 6, 8, 9]  l3 = l1 + l2  l3.sort()  print (l3)  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]     ","Language":"Python","Tags":["python","list","sorting"],"URL":"https://stackoverflow.com/questions/464342/combining-two-sorted-lists-in-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists of objects. Each list is already sorted by a property of the object that is of the datetime type. I would like to combine the two lists into one sorted list. Is the best way just to do a sort or is there a smarter way to do this in Python?     ","Q_Votes":"62"},{"Q_Title":"What SOAP libraries exist for Python 3.x? [closed]","A_Content":"  Depending on the complexity of the service, you could use ladon for the server side and mock up the client by hand until there's a better solution available.  Just call the service with suds (or similar) with logging turned on and note the SOAP wrapping on the request.  Use that to wrap your request and call the service with plain http.  It's not an ideal solution, but it can get you by until you have a package to replace it.     ","Language":"Python","Tags":["python","soap","python-3.x","suds"],"URL":"https://stackoverflow.com/questions/7817303/what-soap-libraries-exist-for-python-3-x","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I searched the web for an existing and supported SOAP library for Python 3. (both client and server)  Here the list of libraries I've found:  Python 2:   Zeep: active and well documented in Python 2.7/3 SOAPy: discontinued Python 2 project ZSI: discontinued Python 2 project soaplib: discontinued Python 2 project SUDS: discontinued Python 2 project (no activity since 02/2012) rpclib: discontinued Python 2 project (no activity since 08/2012)   Python 3:   Zeep: active and well documented Python 2/3 project SOAPy: discontinued Python 2 project pysimplesoap: active Python 2/3 project SUDS-jurko: quite inactive. Python 2/3 project ladon:  low activivty. but web services only   Does this list seems complete to you? (FYI, I used this post as starting point (The purpose of that post was the same but for Python 2))  ladon seems to me the only existing framework for Python 3 but can AFAIK only be used for implementing the server side.  NO: I don't want to migrate one of the discontinued Python 2 projects myself. I am looking for a supported project with an active team providing help if needed.  Updated on 28/09/2013     ","Q_Votes":"63"},{"Q_Title":"What SOAP libraries exist for Python 3.x? [closed]","A_Content":"  I did this same search several months ago and came to the same conclusions. There really isn't much to choose from in this space. I ended up sticking with Python 2.7 and using SOAPy for my project because it was so easy to use. It may be discontinued but it still works. I figure that sometimes you just have to get your hands a little dirty and support yourself, that is why we are called programmers.     ","Language":"Python","Tags":["python","soap","python-3.x","suds"],"URL":"https://stackoverflow.com/questions/7817303/what-soap-libraries-exist-for-python-3-x","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I searched the web for an existing and supported SOAP library for Python 3. (both client and server)  Here the list of libraries I've found:  Python 2:   Zeep: active and well documented in Python 2.7/3 SOAPy: discontinued Python 2 project ZSI: discontinued Python 2 project soaplib: discontinued Python 2 project SUDS: discontinued Python 2 project (no activity since 02/2012) rpclib: discontinued Python 2 project (no activity since 08/2012)   Python 3:   Zeep: active and well documented Python 2/3 project SOAPy: discontinued Python 2 project pysimplesoap: active Python 2/3 project SUDS-jurko: quite inactive. Python 2/3 project ladon:  low activivty. but web services only   Does this list seems complete to you? (FYI, I used this post as starting point (The purpose of that post was the same but for Python 2))  ladon seems to me the only existing framework for Python 3 but can AFAIK only be used for implementing the server side.  NO: I don't want to migrate one of the discontinued Python 2 projects myself. I am looking for a supported project with an active team providing help if needed.  Updated on 28/09/2013     ","Q_Votes":"63"},{"Q_Title":"What SOAP libraries exist for Python 3.x? [closed]","A_Content":"  rpclib: seems the only active project. In their description, they say they are looking for volunteers to test it for Python 3. So maybe you should volunteer yourself!     ","Language":"Python","Tags":["python","soap","python-3.x","suds"],"URL":"https://stackoverflow.com/questions/7817303/what-soap-libraries-exist-for-python-3-x","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I searched the web for an existing and supported SOAP library for Python 3. (both client and server)  Here the list of libraries I've found:  Python 2:   Zeep: active and well documented in Python 2.7/3 SOAPy: discontinued Python 2 project ZSI: discontinued Python 2 project soaplib: discontinued Python 2 project SUDS: discontinued Python 2 project (no activity since 02/2012) rpclib: discontinued Python 2 project (no activity since 08/2012)   Python 3:   Zeep: active and well documented Python 2/3 project SOAPy: discontinued Python 2 project pysimplesoap: active Python 2/3 project SUDS-jurko: quite inactive. Python 2/3 project ladon:  low activivty. but web services only   Does this list seems complete to you? (FYI, I used this post as starting point (The purpose of that post was the same but for Python 2))  ladon seems to me the only existing framework for Python 3 but can AFAIK only be used for implementing the server side.  NO: I don't want to migrate one of the discontinued Python 2 projects myself. I am looking for a supported project with an active team providing help if needed.  Updated on 28/09/2013     ","Q_Votes":"63"},{"Q_Title":"Standard way to create debian packages for distributing Python programs?","A_Content":"  It looks like stdeb will do what you want.  Also, for installing scripts, I strongly recommend distribute's console_scripts entry point support.     ","Language":"Python","Tags":["python","debian","packaging","distutils","debhelper"],"URL":"https://stackoverflow.com/questions/7110604/standard-way-to-create-debian-packages-for-distributing-python-programs","A_Votes":"20","_type":"dict","isAccepted":"Yes","Q_Content":"    There is a ton of information on how to do this, but since \"there is more than one way to skin a cat\", and all the tutorials/manuals that cover a bit of the process seem to make certain assumptions which are different from other tutorials, I still didn't manage to grasp it.  So far this is what I think I understood.   My final goal should be that of creating a \"binary\" .deb package. Such package will be platform independend (32/64 bit) as all python programs are such. To create a \"binary\" package I need first to create a source package. To create the source package I can use either CDBS or debhelper. Debhelper is the recommended way for beginners. The core of creating a source package is populating the DEBIAN directory in the source directory with a number of files clarifying where files need to be copied, what copyright and licensing scheme they are subject to, what dependencies they have, etc... Step #4 can be largely automated the dh_makecommand if the python source also comes with a distutils' setup.py script.   Now my questions:   Is my understanding of the process correct? Is there anything I am missing, or anything that I got wrong? Step #5 is really the more confusing to me: specifically the two points that remains most obscure to me are:   How do I write a setup.py script that install a stand-alone programme? EDIT: By standalone rogramme I mean a program intended to be used by a desktop user (as opposed to a module which I understand like a collection of functionality to be used by other software after having been imported). In my specific case I would actually need two such \"programs\": the main software and a separate utility (in effect a second \"program\" that should be in the same package with the other one). What are the specificities of such a script for DEB packages? The official documentation only seems to deal with RPM and Windows stuff...    BTW: These are the best sources of information that I could find myself so far. If you have anything better than this, please share! :)   Ubuntu's Python packaging guide Creating a .deb package from a python setup.py (it shows the steps  but doesn't explain them enough for me to follow along) ShowMeDo video on \"creating a .deb package out of a python program\" (it doesn't seem up-to-date and - if I got it right - will produce packages for personal use, without dependencies and without a signed changelog and other key data that will make it incompatible with the Debian policy).      ","Q_Votes":"63"},{"Q_Title":"Standard way to create debian packages for distributing Python programs?","A_Content":"  This article by Barry Warsaw helped me in getting quite far through the process. I still had to do a lot of searching on the side, though, and I read most of the Ubuntu packaging guide some time in the past.  Having a good setup.py is a really good advice. I found these two guides quite good:   Hitchhiker's Guide to Packaging Distribute documentation      ","Language":"Python","Tags":["python","debian","packaging","distutils","debhelper"],"URL":"https://stackoverflow.com/questions/7110604/standard-way-to-create-debian-packages-for-distributing-python-programs","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    There is a ton of information on how to do this, but since \"there is more than one way to skin a cat\", and all the tutorials/manuals that cover a bit of the process seem to make certain assumptions which are different from other tutorials, I still didn't manage to grasp it.  So far this is what I think I understood.   My final goal should be that of creating a \"binary\" .deb package. Such package will be platform independend (32/64 bit) as all python programs are such. To create a \"binary\" package I need first to create a source package. To create the source package I can use either CDBS or debhelper. Debhelper is the recommended way for beginners. The core of creating a source package is populating the DEBIAN directory in the source directory with a number of files clarifying where files need to be copied, what copyright and licensing scheme they are subject to, what dependencies they have, etc... Step #4 can be largely automated the dh_makecommand if the python source also comes with a distutils' setup.py script.   Now my questions:   Is my understanding of the process correct? Is there anything I am missing, or anything that I got wrong? Step #5 is really the more confusing to me: specifically the two points that remains most obscure to me are:   How do I write a setup.py script that install a stand-alone programme? EDIT: By standalone rogramme I mean a program intended to be used by a desktop user (as opposed to a module which I understand like a collection of functionality to be used by other software after having been imported). In my specific case I would actually need two such \"programs\": the main software and a separate utility (in effect a second \"program\" that should be in the same package with the other one). What are the specificities of such a script for DEB packages? The official documentation only seems to deal with RPM and Windows stuff...    BTW: These are the best sources of information that I could find myself so far. If you have anything better than this, please share! :)   Ubuntu's Python packaging guide Creating a .deb package from a python setup.py (it shows the steps  but doesn't explain them enough for me to follow along) ShowMeDo video on \"creating a .deb package out of a python program\" (it doesn't seem up-to-date and - if I got it right - will produce packages for personal use, without dependencies and without a signed changelog and other key data that will make it incompatible with the Debian policy).      ","Q_Votes":"63"},{"Q_Title":"Standard way to create debian packages for distributing Python programs?","A_Content":"  The right way of building a deb package is using dpkg-buildpackage but sometimes it is a little bit complicated. Instead you can use dpkg -b <folder> and it will create your Debian package.  These are the basics for creating a Debian package with dpkg -b <folder> with any binary or with any kind of script that runs automatically without needing manual compilation (Python, Bash, Pearl, Ruby):   Create the files and folders in order to recreate the following structure:         ProgramName-Version/     ProgramName-Version/DEBIAN     ProgramName-Version/DEBIAN/control     ProgramName-Version/usr/     ProgramName-Version/usr/bin/     ProgramName-Version/usr/bin/your_script   The scripts placed at /usr/bin/ are directly called from the terminal, note that I didn't add an extension to the script. Also you can notice that the structure of the deb package will be the structure of the program once it's installed. So if you follow this logic if your program has a single file, you can directly place it under ProgramName-Version/usr/bin/your_script, but if you have multiple files, you should place them under ProgramName-Version/usr/share/ProgramName/all your files and place only one file under /usr/bin/ that will call your scripts from /usr/share/ProgramName/   Change all the folder permission to root:   chown root:root -R /path/to/ProgramName-Version  Change the script's permissions:   chmod 0755 /path/to/the/script  Finally, you can run: dpkg -b /path/to/the/ProgramName-Version and your deb package will be created! (You can also add the post/pre inst scripts and everything you want, it works like a normal Debian package)     Here is an example of the control file. You only need to copy-paste it in to an empty file called \"control\" and put it in the DEBIAN folder  Package: ProgramName Version: VERSION Architecture: all Maintainer: YOUR NAME <EMAIL> Depends: python2.7, etc , etc, Installed-Size: in_kb Homepage: http://foo.com Description: Here you can put a one line description. This is the short Description.  Here you put the long description, indented by 1 space.      ","Language":"Python","Tags":["python","debian","packaging","distutils","debhelper"],"URL":"https://stackoverflow.com/questions/7110604/standard-way-to-create-debian-packages-for-distributing-python-programs","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    There is a ton of information on how to do this, but since \"there is more than one way to skin a cat\", and all the tutorials/manuals that cover a bit of the process seem to make certain assumptions which are different from other tutorials, I still didn't manage to grasp it.  So far this is what I think I understood.   My final goal should be that of creating a \"binary\" .deb package. Such package will be platform independend (32/64 bit) as all python programs are such. To create a \"binary\" package I need first to create a source package. To create the source package I can use either CDBS or debhelper. Debhelper is the recommended way for beginners. The core of creating a source package is populating the DEBIAN directory in the source directory with a number of files clarifying where files need to be copied, what copyright and licensing scheme they are subject to, what dependencies they have, etc... Step #4 can be largely automated the dh_makecommand if the python source also comes with a distutils' setup.py script.   Now my questions:   Is my understanding of the process correct? Is there anything I am missing, or anything that I got wrong? Step #5 is really the more confusing to me: specifically the two points that remains most obscure to me are:   How do I write a setup.py script that install a stand-alone programme? EDIT: By standalone rogramme I mean a program intended to be used by a desktop user (as opposed to a module which I understand like a collection of functionality to be used by other software after having been imported). In my specific case I would actually need two such \"programs\": the main software and a separate utility (in effect a second \"program\" that should be in the same package with the other one). What are the specificities of such a script for DEB packages? The official documentation only seems to deal with RPM and Windows stuff...    BTW: These are the best sources of information that I could find myself so far. If you have anything better than this, please share! :)   Ubuntu's Python packaging guide Creating a .deb package from a python setup.py (it shows the steps  but doesn't explain them enough for me to follow along) ShowMeDo video on \"creating a .deb package out of a python program\" (it doesn't seem up-to-date and - if I got it right - will produce packages for personal use, without dependencies and without a signed changelog and other key data that will make it incompatible with the Debian policy).      ","Q_Votes":"63"},{"Q_Title":"Standard way to create debian packages for distributing Python programs?","A_Content":"  There are several libraries out there which abstract away all the necessary steps and let you transform your python package into a debian package with a single command.  Assuming your python package already has the setup.py, in the directory where setup.py is located, you could use:   stdeb (Already mentioned in this answer, install with pip install stdeb). To create a debian package, run:  python setup.py --command-packages=stdeb.command bdist_deb   Output .deb file will be located in bdist_deb directory. fpm (install with gem install --no-ri --no-rdoc fpm). To create a debian package, run:  fpm -s python -t deb setup.py  py2deb (install with pip install py2deb). To create a debian package, run:  py2deb -r . .    Each of these libraries has its own caveats, so you might want to try what works best for you.      ","Language":"Python","Tags":["python","debian","packaging","distutils","debhelper"],"URL":"https://stackoverflow.com/questions/7110604/standard-way-to-create-debian-packages-for-distributing-python-programs","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    There is a ton of information on how to do this, but since \"there is more than one way to skin a cat\", and all the tutorials/manuals that cover a bit of the process seem to make certain assumptions which are different from other tutorials, I still didn't manage to grasp it.  So far this is what I think I understood.   My final goal should be that of creating a \"binary\" .deb package. Such package will be platform independend (32/64 bit) as all python programs are such. To create a \"binary\" package I need first to create a source package. To create the source package I can use either CDBS or debhelper. Debhelper is the recommended way for beginners. The core of creating a source package is populating the DEBIAN directory in the source directory with a number of files clarifying where files need to be copied, what copyright and licensing scheme they are subject to, what dependencies they have, etc... Step #4 can be largely automated the dh_makecommand if the python source also comes with a distutils' setup.py script.   Now my questions:   Is my understanding of the process correct? Is there anything I am missing, or anything that I got wrong? Step #5 is really the more confusing to me: specifically the two points that remains most obscure to me are:   How do I write a setup.py script that install a stand-alone programme? EDIT: By standalone rogramme I mean a program intended to be used by a desktop user (as opposed to a module which I understand like a collection of functionality to be used by other software after having been imported). In my specific case I would actually need two such \"programs\": the main software and a separate utility (in effect a second \"program\" that should be in the same package with the other one). What are the specificities of such a script for DEB packages? The official documentation only seems to deal with RPM and Windows stuff...    BTW: These are the best sources of information that I could find myself so far. If you have anything better than this, please share! :)   Ubuntu's Python packaging guide Creating a .deb package from a python setup.py (it shows the steps  but doesn't explain them enough for me to follow along) ShowMeDo video on \"creating a .deb package out of a python program\" (it doesn't seem up-to-date and - if I got it right - will produce packages for personal use, without dependencies and without a signed changelog and other key data that will make it incompatible with the Debian policy).      ","Q_Votes":"63"},{"Q_Title":"SystemError: Parent module '' not loaded, cannot perform relative import [duplicate]","A_Content":"  I had the same problem and I solved it by using an absolute import instead of a relative one.  for example in your case, you will write something like this:  from app.mymodule import myclass   You can see in the documentation.     Note that relative imports are based on the name of the current   module. Since the name of the main module is always \"__main__\",   modules intended for use as the main module of a Python application   must always use absolute imports.      ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/33837717/systemerror-parent-module-not-loaded-cannot-perform-relative-import","A_Votes":"39","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to fix “Attempted relative import in non-package” even with __init__.py                                        11 answers                                          I have the following directory:  myProgram └── app     ├── __init__.py     ├── main.py      └── mymodule.py   mymodule.py:  class myclass(object):  def __init__(self):     pass  def myfunc(self):     print(\"Hello!\")   main.py:  from .mymodule import myclass  print(\"Test\") testclass = myclass() testclass.myfunc()   But when I run it, then I get this error:  Traceback (most recent call last):   File \"D:/Users/Myname/Documents/PycharmProjects/myProgram/app/main.py\", line 1, in <module>     from .mymodule import myclass SystemError: Parent module '' not loaded, cannot perform relative import   This works:  from mymodule import myclass   But I get no auto completion when I type this in and there is a message: \"unresolved reference: mymodule\" and \"unresolved reference: myclass\". And in my other project, which I am working on, I get the error: \"ImportError: No module named 'mymodule'.  What can I do?     ","Q_Votes":"63"},{"Q_Title":"SystemError: Parent module '' not loaded, cannot perform relative import [duplicate]","A_Content":"  I usually use this workaround:  try:     from .mymodule import myclass except Exception: #ImportError     from mymodule import myclass   Which means your IDE should pick up the right code location and the python interpreter will manage to run your code.     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/33837717/systemerror-parent-module-not-loaded-cannot-perform-relative-import","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to fix “Attempted relative import in non-package” even with __init__.py                                        11 answers                                          I have the following directory:  myProgram └── app     ├── __init__.py     ├── main.py      └── mymodule.py   mymodule.py:  class myclass(object):  def __init__(self):     pass  def myfunc(self):     print(\"Hello!\")   main.py:  from .mymodule import myclass  print(\"Test\") testclass = myclass() testclass.myfunc()   But when I run it, then I get this error:  Traceback (most recent call last):   File \"D:/Users/Myname/Documents/PycharmProjects/myProgram/app/main.py\", line 1, in <module>     from .mymodule import myclass SystemError: Parent module '' not loaded, cannot perform relative import   This works:  from mymodule import myclass   But I get no auto completion when I type this in and there is a message: \"unresolved reference: mymodule\" and \"unresolved reference: myclass\". And in my other project, which I am working on, I get the error: \"ImportError: No module named 'mymodule'.  What can I do?     ","Q_Votes":"63"},{"Q_Title":"SystemError: Parent module '' not loaded, cannot perform relative import [duplicate]","A_Content":"  if you just run the main.py under the app, just import like   from mymodule import myclass   if you want to call main.py on other folder, use:  from .mymodule import myclass     for example:  ├── app │   ├── __init__.py │   ├── main.py │   ├── mymodule.py ├── __init__.py └── run.py   main.py  from .mymodule import myclass   run.py  from app import main print(main.myclass)   So I think the main question of you is how to call app.main.     ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/33837717/systemerror-parent-module-not-loaded-cannot-perform-relative-import","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to fix “Attempted relative import in non-package” even with __init__.py                                        11 answers                                          I have the following directory:  myProgram └── app     ├── __init__.py     ├── main.py      └── mymodule.py   mymodule.py:  class myclass(object):  def __init__(self):     pass  def myfunc(self):     print(\"Hello!\")   main.py:  from .mymodule import myclass  print(\"Test\") testclass = myclass() testclass.myfunc()   But when I run it, then I get this error:  Traceback (most recent call last):   File \"D:/Users/Myname/Documents/PycharmProjects/myProgram/app/main.py\", line 1, in <module>     from .mymodule import myclass SystemError: Parent module '' not loaded, cannot perform relative import   This works:  from mymodule import myclass   But I get no auto completion when I type this in and there is a message: \"unresolved reference: mymodule\" and \"unresolved reference: myclass\". And in my other project, which I am working on, I get the error: \"ImportError: No module named 'mymodule'.  What can I do?     ","Q_Votes":"63"},{"Q_Title":"SystemError: Parent module '' not loaded, cannot perform relative import [duplicate]","A_Content":"  If you go one level up in running the script in the command line of your bash shell, the issue will be resolved. To do this, use cd .. command to change the working directory in which your script will be running. The result should look like this:  [username@localhost myProgram]$   rather than this:  [username@localhost app]$   Once you are there, instead of running the script in the following format:  python3 mymodule.py   Change it to this:  python3 app/mymodule.py   This process can be repeated once again one level up depending on the structure of your Tree diagram. Please also include the compilation command line that is giving you that mentioned error message.      ","Language":"Python","Tags":["python","python-3.x"],"URL":"https://stackoverflow.com/questions/33837717/systemerror-parent-module-not-loaded-cannot-perform-relative-import","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to fix “Attempted relative import in non-package” even with __init__.py                                        11 answers                                          I have the following directory:  myProgram └── app     ├── __init__.py     ├── main.py      └── mymodule.py   mymodule.py:  class myclass(object):  def __init__(self):     pass  def myfunc(self):     print(\"Hello!\")   main.py:  from .mymodule import myclass  print(\"Test\") testclass = myclass() testclass.myfunc()   But when I run it, then I get this error:  Traceback (most recent call last):   File \"D:/Users/Myname/Documents/PycharmProjects/myProgram/app/main.py\", line 1, in <module>     from .mymodule import myclass SystemError: Parent module '' not loaded, cannot perform relative import   This works:  from mymodule import myclass   But I get no auto completion when I type this in and there is a message: \"unresolved reference: mymodule\" and \"unresolved reference: myclass\". And in my other project, which I am working on, I get the error: \"ImportError: No module named 'mymodule'.  What can I do?     ","Q_Votes":"63"},{"Q_Title":"yield in list comprehensions and generator expressions","A_Content":"     Note: this was a bug in the CPython's handling of yield in comprehensions and generator expressions, fixed in Python 3.8, with a deprecation warning in Python 3.7. See the Python bug report and the What's New entries for Python 3.7 and Python 3.8.   Generator expressions, and set and dict comprehensions are compiled to (generator) function objects. In Python 3, list comprehensions get the same treatment; they are all, in essence, a new nested scope.  You can see this if you try to disassemble a generator expression:  >>> dis.dis(compile(\"(i for i in range(3))\", '', 'exec'))   1           0 LOAD_CONST               0 (<code object <genexpr> at 0x10f7530c0, file \"\", line 1>)               3 LOAD_CONST               1 ('<genexpr>')               6 MAKE_FUNCTION            0               9 LOAD_NAME                0 (range)              12 LOAD_CONST               2 (3)              15 CALL_FUNCTION            1 (1 positional, 0 keyword pair)              18 GET_ITER              19 CALL_FUNCTION            1 (1 positional, 0 keyword pair)              22 POP_TOP              23 LOAD_CONST               3 (None)              26 RETURN_VALUE >>> dis.dis(compile(\"(i for i in range(3))\", '', 'exec').co_consts[0])   1           0 LOAD_FAST                0 (.0)         >>    3 FOR_ITER                11 (to 17)               6 STORE_FAST               1 (i)               9 LOAD_FAST                1 (i)              12 YIELD_VALUE              13 POP_TOP              14 JUMP_ABSOLUTE            3         >>   17 LOAD_CONST               0 (None)              20 RETURN_VALUE   The above shows that a generator expression is compiled to a code object, loaded as a function (MAKE_FUNCTION creates the function object from the code object). The .co_consts[0] reference lets us see the code object generated for the expression, and it uses YIELD_VALUE just like a generator function would.  As such, the yield expression works in that context, as the compiler sees these as functions-in-disguise.  This is a bug; yield has no place in these expressions. The Python grammar before Python 3.7 allows it (which is why the code is compilable), but the yield expression specification shows that using yield here should not actually work:     The yield expression is only used when defining a generator function and thus can only be used in the body of a function definition.   This has been confirmed to be a bug in issue 10544. The resolution of the bug is that using yield and yield from will raise a SyntaxError in Python 3.8; in Python 3.7 it raises a DeprecationWarning to ensure code stops using this construct. You'll see the same warning in Python 2.7.15 and up if you use the -3 command line switch enabling Python 3 compatibility warnings.  The 3.7.0b1 warning looks like this; turning warnings into errors gives you a SyntaxError exception, like you would in 3.8:  >>> [(yield i) for i in range(3)] <stdin>:1: DeprecationWarning: 'yield' inside list comprehension <generator object <listcomp> at 0x1092ec7c8> >>> import warnings >>> warnings.simplefilter('error') >>> [(yield i) for i in range(3)]   File \"<stdin>\", line 1 SyntaxError: 'yield' inside list comprehension   The differences between how yield in a list comprehension and yield in a generator expression operate stem from the differences in how these two expressions are implemented. In Python 3 a list comprehension uses LIST_APPEND calls to add the top of the stack to the list being built, while a generator expression instead yields that value. Adding in (yield <expr>) just adds another YIELD_VALUE opcode to either:  >>> dis.dis(compile(\"[(yield i) for i in range(3)]\", '', 'exec').co_consts[0])   1           0 BUILD_LIST               0               3 LOAD_FAST                0 (.0)         >>    6 FOR_ITER                13 (to 22)               9 STORE_FAST               1 (i)              12 LOAD_FAST                1 (i)              15 YIELD_VALUE              16 LIST_APPEND              2              19 JUMP_ABSOLUTE            6         >>   22 RETURN_VALUE >>> dis.dis(compile(\"((yield i) for i in range(3))\", '', 'exec').co_consts[0])   1           0 LOAD_FAST                0 (.0)         >>    3 FOR_ITER                12 (to 18)               6 STORE_FAST               1 (i)               9 LOAD_FAST                1 (i)              12 YIELD_VALUE              13 YIELD_VALUE              14 POP_TOP              15 JUMP_ABSOLUTE            3         >>   18 LOAD_CONST               0 (None)              21 RETURN_VALUE   The YIELD_VALUE opcode at bytecode indexes 15 and 12 respectively is extra, a cuckoo in the nest. So for the list-comprehension-turned-generator you have 1 yield producing the top of the stack each time (replacing the top of the stack with the yield return value), and for the generator expression variant you yield the top of the stack (the integer) and then yield again, but now the stack contains the return value of the yield and you get None that second time.  For the list comprehension then, the intended list object output is still returned, but Python 3 sees this as a generator so the return value is instead attached to the StopIteration exception as the value attribute:  >>> from itertools import islice >>> listgen = [(yield i) for i in range(3)] >>> list(islice(listgen, 3))  # avoid exhausting the generator [0, 1, 2] >>> try: ...     next(listgen) ... except StopIteration as si: ...     print(si.value) ...  [None, None, None]   Those None objects are the return values from the yield expressions.  And to reiterate this again; this same issue applies to dictionary and set comprehension in Python 2 and Python 3 as well; in Python 2 the yield return values are still added to the intended dictionary or set object, and the return value is 'yielded' last instead of attached to the StopIteration exception:  >>> list({(yield k): (yield v) for k, v in {'foo': 'bar', 'spam': 'eggs'}.items()}) ['bar', 'foo', 'eggs', 'spam', {None: None}] >>> list({(yield i) for i in range(3)}) [0, 1, 2, set([None])]      ","Language":"Python","Tags":["python","generator","list-comprehension","yield","generator-expression"],"URL":"https://stackoverflow.com/questions/32139885/yield-in-list-comprehensions-and-generator-expressions","A_Votes":"59","_type":"dict","isAccepted":"Yes","Q_Content":"    The following behaviour seems rather counterintuitive to me (Python 3.4):  >>> [(yield i) for i in range(3)] <generator object <listcomp> at 0x0245C148> >>> list([(yield i) for i in range(3)]) [0, 1, 2] >>> list((yield i) for i in range(3)) [0, None, 1, None, 2, None]   The intermediate values of the last line are actually not always None, they are whatever we send into the generator, equivalent (I guess) to the following generator:  def f():    for i in range(3):       yield (yield i)   It strikes me as funny that those three lines work at all. The Reference says that yield is only allowed in a function definition (though I may be reading it wrong and/or it may simply have been copied from the older version). The first two lines produce a SyntaxError in Python 2.7, but the third line doesn't.  Also, it seems odd   that a list comprehension returns a generator and not a list and that the generator expression converted to a list and the corresponding list comprehension contain different values.   Could someone provide more information?     ","Q_Votes":"63"},{"Q_Title":"Import python package from local directory into interpreter","A_Content":"  You can use relative imports only from in a module that was in turn imported as part of a package -- your script or interactive interpreter wasn't, so of course from . import (which means \"import from the same package I got imported from\") doesn't work. import mypackage will be fine once you ensure the parent directory of mypackage is in sys.path (how you managed to get your current directory away from sys.path I don't know -- do you have something strange in site.py, or...?)  To get your current directory back into sys.path there is in fact no better way than putting it there;-).     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1112618/import-python-package-from-local-directory-into-interpreter","A_Votes":"32","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm developing/testing a package in my local directory. I want to import it in the interpreter (v2.5), but sys.path does not include the current directory. Right now I type in sys.path.insert(0,'.'). Is there a better way?   Also,   from . import mypackage   fails with this error:  ValueError: Attempted relative import in non-package      ","Q_Votes":"63"},{"Q_Title":"Import python package from local directory into interpreter","A_Content":"  See the documentation for sys.path:  http://docs.python.org/library/sys.html#sys.path  To quote:     If the script directory is not available (e.g. if the interpreter is invoked interactively or if the script is read from standard input), path[0] is the empty string, which directs Python to search modules in the current directory first.   So, there's no need to monkey with sys.path if you're starting the python interpreter from the directory containing your module.  Also, to import your package, just do:  import mypackage   Since the directory containing the package is already in sys.path, it should work fine.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1112618/import-python-package-from-local-directory-into-interpreter","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I'm developing/testing a package in my local directory. I want to import it in the interpreter (v2.5), but sys.path does not include the current directory. Right now I type in sys.path.insert(0,'.'). Is there a better way?   Also,   from . import mypackage   fails with this error:  ValueError: Attempted relative import in non-package      ","Q_Votes":"63"},{"Q_Title":"Import python package from local directory into interpreter","A_Content":"  A simple way to make it work is to run your script from the parent directory using python's -m flag, e.g. python -m packagename.scriptname. Obviously in this situation you need an __init__.py file to turn your directory into a package.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1112618/import-python-package-from-local-directory-into-interpreter","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm developing/testing a package in my local directory. I want to import it in the interpreter (v2.5), but sys.path does not include the current directory. Right now I type in sys.path.insert(0,'.'). Is there a better way?   Also,   from . import mypackage   fails with this error:  ValueError: Attempted relative import in non-package      ","Q_Votes":"63"},{"Q_Title":"Import python package from local directory into interpreter","A_Content":"  Keep it simple:   try:      from . import mymodule     # \"myapp\" case  except:      import mymodule            # \"__main__\" case      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1112618/import-python-package-from-local-directory-into-interpreter","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm developing/testing a package in my local directory. I want to import it in the interpreter (v2.5), but sys.path does not include the current directory. Right now I type in sys.path.insert(0,'.'). Is there a better way?   Also,   from . import mypackage   fails with this error:  ValueError: Attempted relative import in non-package      ","Q_Votes":"63"},{"Q_Title":"Import python package from local directory into interpreter","A_Content":"  If you want to run an unmodified python script so it imports libraries from a specific local directory you can set the PYTHONPATH environment variable - e.g. in bash:  export PYTHONPATH=/home/user/my_libs python myscript.py   If you just want it to import from the current working directory use the . notation:  export PYTHONPATH=. python myscript.py      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1112618/import-python-package-from-local-directory-into-interpreter","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm developing/testing a package in my local directory. I want to import it in the interpreter (v2.5), but sys.path does not include the current directory. Right now I type in sys.path.insert(0,'.'). Is there a better way?   Also,   from . import mypackage   fails with this error:  ValueError: Attempted relative import in non-package      ","Q_Votes":"63"},{"Q_Title":"Import python package from local directory into interpreter","A_Content":"  Using sys.path should include current directory already.  Try:  import .   or:  from . import sth   however it may be not a good practice, so why not just use:  import mypackage      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1112618/import-python-package-from-local-directory-into-interpreter","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm developing/testing a package in my local directory. I want to import it in the interpreter (v2.5), but sys.path does not include the current directory. Right now I type in sys.path.insert(0,'.'). Is there a better way?   Also,   from . import mypackage   fails with this error:  ValueError: Attempted relative import in non-package      ","Q_Votes":"63"},{"Q_Title":"Most Pythonic way to provide global configuration variables in config.py?","A_Content":"  I did that once. Ultimately I found my simplified basicconfig.py adequate for my needs. You can pass in a namespace with other objects for it to reference if you need to. You can also pass in additional defaults from your code. It also maps attribute and mapping style syntax to the same configuration object.      ","Language":"Python","Tags":["global-variables","python","config","egg"],"URL":"https://stackoverflow.com/questions/6198372/most-pythonic-way-to-provide-global-configuration-variables-in-config-py","A_Votes":"5","_type":"dict","isAccepted":"Yes","Q_Content":"    In my endless quest in over-complicating simple stuff, I am researching the most 'Pythonic' way to provide global configuration variables inside the typical 'config.py' found in Python egg packages.   The traditional way (aah, good ol' #define!) is as follows:  MYSQL_PORT = 3306 MYSQL_DATABASE = 'mydb' MYSQL_DATABASE_TABLES = ['tb_users', 'tb_groups']   Therefore global variables are imported in one of the following ways:  from config import * dbname = MYSQL_DATABASE for table in MYSQL_DATABASE_TABLES:     print table   or:  import config dbname = config.MYSQL_DATABASE assert(isinstance(config.MYSQL_PORT, int))   It makes sense, but sometimes can be a little messy, especially when you're trying to remember the names of certain variables. Besides, providing a 'configuration' object, with variables as attributes, might be more flexible. So, taking a lead from bpython config.py file, I came up with:  class Struct(object):      def __init__(self, *args):         self.__header__ = str(args[0]) if args else None      def __repr__(self):         if self.__header__ is None:              return super(Struct, self).__repr__()         return self.__header__      def next(self):         \"\"\" Fake iteration functionality.         \"\"\"         raise StopIteration      def __iter__(self):         \"\"\" Fake iteration functionality.         We skip magic attribues and Structs, and return the rest.         \"\"\"         ks = self.__dict__.keys()         for k in ks:             if not k.startswith('__') and not isinstance(k, Struct):                 yield getattr(self, k)      def __len__(self):         \"\"\" Don't count magic attributes or Structs.         \"\"\"         ks = self.__dict__.keys()         return len([k for k in ks if not k.startswith('__')\\                     and not isinstance(k, Struct)])   and a 'config.py' that imports the class and reads as follows:  from _config import Struct as Section  mysql = Section(\"MySQL specific configuration\") mysql.user = 'root' mysql.pass = 'secret' mysql.host = 'localhost' mysql.port = 3306 mysql.database = 'mydb'  mysql.tables = Section(\"Tables for 'mydb'\") mysql.tables.users = 'tb_users' mysql.tables.groups =  'tb_groups'   and is used in this way:  from sqlalchemy import MetaData, Table import config as CONFIG  assert(isinstance(CONFIG.mysql.port, int))  mdata = MetaData(     \"mysql://%s:%s@%s:%d/%s\" % (          CONFIG.mysql.user,          CONFIG.mysql.pass,          CONFIG.mysql.host,          CONFIG.mysql.port,          CONFIG.mysql.database,      ) )  tables = [] for name in CONFIG.mysql.tables:     tables.append(Table(name, mdata, autoload=True))   Which seems a more readable, expressive and flexible way of storing and fetching global variables inside a package.  Lamest idea ever? What is the best practice for coping with these situations? What is your way of storing and fetching global names and variables inside your package?     ","Q_Votes":"63"},{"Q_Title":"Most Pythonic way to provide global configuration variables in config.py?","A_Content":"  How about just using the built-in types like this:  config = {     \"mysql\": {         \"user\": \"root\",         \"pass\": \"secret\",         \"tables\": {             \"users\": \"tb_users\"         }         # etc     } }   You'd access the values as follows:  config[\"mysql\"][\"tables\"][\"users\"]     If you are willing to sacrifice the potential to compute expressions inside your config tree, you could use YAML and end up with a more readable config file like this:  mysql:   - user: root   - pass: secret   - tables:     - users: tb_users   and use a library like PyYAML to conventiently parse and access the config file     ","Language":"Python","Tags":["global-variables","python","config","egg"],"URL":"https://stackoverflow.com/questions/6198372/most-pythonic-way-to-provide-global-configuration-variables-in-config-py","A_Votes":"47","_type":"dict","isAccepted":"No","Q_Content":"    In my endless quest in over-complicating simple stuff, I am researching the most 'Pythonic' way to provide global configuration variables inside the typical 'config.py' found in Python egg packages.   The traditional way (aah, good ol' #define!) is as follows:  MYSQL_PORT = 3306 MYSQL_DATABASE = 'mydb' MYSQL_DATABASE_TABLES = ['tb_users', 'tb_groups']   Therefore global variables are imported in one of the following ways:  from config import * dbname = MYSQL_DATABASE for table in MYSQL_DATABASE_TABLES:     print table   or:  import config dbname = config.MYSQL_DATABASE assert(isinstance(config.MYSQL_PORT, int))   It makes sense, but sometimes can be a little messy, especially when you're trying to remember the names of certain variables. Besides, providing a 'configuration' object, with variables as attributes, might be more flexible. So, taking a lead from bpython config.py file, I came up with:  class Struct(object):      def __init__(self, *args):         self.__header__ = str(args[0]) if args else None      def __repr__(self):         if self.__header__ is None:              return super(Struct, self).__repr__()         return self.__header__      def next(self):         \"\"\" Fake iteration functionality.         \"\"\"         raise StopIteration      def __iter__(self):         \"\"\" Fake iteration functionality.         We skip magic attribues and Structs, and return the rest.         \"\"\"         ks = self.__dict__.keys()         for k in ks:             if not k.startswith('__') and not isinstance(k, Struct):                 yield getattr(self, k)      def __len__(self):         \"\"\" Don't count magic attributes or Structs.         \"\"\"         ks = self.__dict__.keys()         return len([k for k in ks if not k.startswith('__')\\                     and not isinstance(k, Struct)])   and a 'config.py' that imports the class and reads as follows:  from _config import Struct as Section  mysql = Section(\"MySQL specific configuration\") mysql.user = 'root' mysql.pass = 'secret' mysql.host = 'localhost' mysql.port = 3306 mysql.database = 'mydb'  mysql.tables = Section(\"Tables for 'mydb'\") mysql.tables.users = 'tb_users' mysql.tables.groups =  'tb_groups'   and is used in this way:  from sqlalchemy import MetaData, Table import config as CONFIG  assert(isinstance(CONFIG.mysql.port, int))  mdata = MetaData(     \"mysql://%s:%s@%s:%d/%s\" % (          CONFIG.mysql.user,          CONFIG.mysql.pass,          CONFIG.mysql.host,          CONFIG.mysql.port,          CONFIG.mysql.database,      ) )  tables = [] for name in CONFIG.mysql.tables:     tables.append(Table(name, mdata, autoload=True))   Which seems a more readable, expressive and flexible way of storing and fetching global variables inside a package.  Lamest idea ever? What is the best practice for coping with these situations? What is your way of storing and fetching global names and variables inside your package?     ","Q_Votes":"63"},{"Q_Title":"Most Pythonic way to provide global configuration variables in config.py?","A_Content":"  Similar to blubb's answer. I suggest building them with lambda functions to reduce code. Like this:  User = lambda passwd, hair, name: {'password':passwd, 'hair':hair, 'name':name}  #Col      Username       Password      Hair Color  Real Name config = {'st3v3' : User('password',   'blonde',   'Steve Booker'),           'blubb' : User('12345678',   'black',    'Bubb Ohaal'),           'suprM' : User('kryptonite', 'black',    'Clark Kent'),           #...          } #...  config['st3v3']['password']  #> password config['blubb']['hair']      #> black   This does smell like you may want to make a class, though.  Or, as MarkM noted, you could use namedtuple  from collections import namedtuple #...  User = namedtuple('User', ['password', 'hair', 'name']}  #Col      Username       Password      Hair Color  Real Name config = {'st3v3' : User('password',   'blonde',   'Steve Booker'),           'blubb' : User('12345678',   'black',    'Bubb Ohaal'),           'suprM' : User('kryptonite', 'black',    'Clark Kent'),           #...          } #...  config['st3v3'].password   #> passwd config['blubb'].hair       #> black      ","Language":"Python","Tags":["global-variables","python","config","egg"],"URL":"https://stackoverflow.com/questions/6198372/most-pythonic-way-to-provide-global-configuration-variables-in-config-py","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    In my endless quest in over-complicating simple stuff, I am researching the most 'Pythonic' way to provide global configuration variables inside the typical 'config.py' found in Python egg packages.   The traditional way (aah, good ol' #define!) is as follows:  MYSQL_PORT = 3306 MYSQL_DATABASE = 'mydb' MYSQL_DATABASE_TABLES = ['tb_users', 'tb_groups']   Therefore global variables are imported in one of the following ways:  from config import * dbname = MYSQL_DATABASE for table in MYSQL_DATABASE_TABLES:     print table   or:  import config dbname = config.MYSQL_DATABASE assert(isinstance(config.MYSQL_PORT, int))   It makes sense, but sometimes can be a little messy, especially when you're trying to remember the names of certain variables. Besides, providing a 'configuration' object, with variables as attributes, might be more flexible. So, taking a lead from bpython config.py file, I came up with:  class Struct(object):      def __init__(self, *args):         self.__header__ = str(args[0]) if args else None      def __repr__(self):         if self.__header__ is None:              return super(Struct, self).__repr__()         return self.__header__      def next(self):         \"\"\" Fake iteration functionality.         \"\"\"         raise StopIteration      def __iter__(self):         \"\"\" Fake iteration functionality.         We skip magic attribues and Structs, and return the rest.         \"\"\"         ks = self.__dict__.keys()         for k in ks:             if not k.startswith('__') and not isinstance(k, Struct):                 yield getattr(self, k)      def __len__(self):         \"\"\" Don't count magic attributes or Structs.         \"\"\"         ks = self.__dict__.keys()         return len([k for k in ks if not k.startswith('__')\\                     and not isinstance(k, Struct)])   and a 'config.py' that imports the class and reads as follows:  from _config import Struct as Section  mysql = Section(\"MySQL specific configuration\") mysql.user = 'root' mysql.pass = 'secret' mysql.host = 'localhost' mysql.port = 3306 mysql.database = 'mydb'  mysql.tables = Section(\"Tables for 'mydb'\") mysql.tables.users = 'tb_users' mysql.tables.groups =  'tb_groups'   and is used in this way:  from sqlalchemy import MetaData, Table import config as CONFIG  assert(isinstance(CONFIG.mysql.port, int))  mdata = MetaData(     \"mysql://%s:%s@%s:%d/%s\" % (          CONFIG.mysql.user,          CONFIG.mysql.pass,          CONFIG.mysql.host,          CONFIG.mysql.port,          CONFIG.mysql.database,      ) )  tables = [] for name in CONFIG.mysql.tables:     tables.append(Table(name, mdata, autoload=True))   Which seems a more readable, expressive and flexible way of storing and fetching global variables inside a package.  Lamest idea ever? What is the best practice for coping with these situations? What is your way of storing and fetching global names and variables inside your package?     ","Q_Votes":"63"},{"Q_Title":"Most Pythonic way to provide global configuration variables in config.py?","A_Content":"  I like this solution for small applications:  class App:   __conf = {     \"username\": \"\",     \"password\": \"\",     \"MYSQL_PORT\": 3306,     \"MYSQL_DATABASE\": 'mydb',     \"MYSQL_DATABASE_TABLES\": ['tb_users', 'tb_groups']   }   __setters = [\"username\", \"password\"]    @staticmethod   def config(name):     return App.__conf[name]    @staticmethod   def set(name, value):     if name in App.__setters:       App.__conf[name] = value     else:       raise NameError(\"Name not accepted in set() method\")   And then usage is:  if __name__ == \"__main__\":    # from config import App    App.config(\"MYSQL_PORT\")     # return 3306    App.set(\"username\", \"hi\")    # set new username value    App.config(\"username\")       # return \"hi\"    App.set(\"MYSQL_PORT\", \"abc\") # this raises NameError   .. you should like it because:   uses class variables (no object to pass around/ no singleton required), uses encapsulated built-in types and looks like (is) a method call on App,  has control over individual config immutability, mutable globals are the worst kind of globals. promotes conventional and well named access / readability in your source code is a simple class but enforces structured access, an alternative is to use @property, but that requires more variable handling code per item and is object-based. requires minimal changes to add new config items and set its mutability.   --Edit--:  For large applications, storing values in a YAML (i.e. properties) file and reading that in as immutable data is a better approach (i.e. blubb/ohaal's answer).  For small applications, this solution above is simpler.     ","Language":"Python","Tags":["global-variables","python","config","egg"],"URL":"https://stackoverflow.com/questions/6198372/most-pythonic-way-to-provide-global-configuration-variables-in-config-py","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    In my endless quest in over-complicating simple stuff, I am researching the most 'Pythonic' way to provide global configuration variables inside the typical 'config.py' found in Python egg packages.   The traditional way (aah, good ol' #define!) is as follows:  MYSQL_PORT = 3306 MYSQL_DATABASE = 'mydb' MYSQL_DATABASE_TABLES = ['tb_users', 'tb_groups']   Therefore global variables are imported in one of the following ways:  from config import * dbname = MYSQL_DATABASE for table in MYSQL_DATABASE_TABLES:     print table   or:  import config dbname = config.MYSQL_DATABASE assert(isinstance(config.MYSQL_PORT, int))   It makes sense, but sometimes can be a little messy, especially when you're trying to remember the names of certain variables. Besides, providing a 'configuration' object, with variables as attributes, might be more flexible. So, taking a lead from bpython config.py file, I came up with:  class Struct(object):      def __init__(self, *args):         self.__header__ = str(args[0]) if args else None      def __repr__(self):         if self.__header__ is None:              return super(Struct, self).__repr__()         return self.__header__      def next(self):         \"\"\" Fake iteration functionality.         \"\"\"         raise StopIteration      def __iter__(self):         \"\"\" Fake iteration functionality.         We skip magic attribues and Structs, and return the rest.         \"\"\"         ks = self.__dict__.keys()         for k in ks:             if not k.startswith('__') and not isinstance(k, Struct):                 yield getattr(self, k)      def __len__(self):         \"\"\" Don't count magic attributes or Structs.         \"\"\"         ks = self.__dict__.keys()         return len([k for k in ks if not k.startswith('__')\\                     and not isinstance(k, Struct)])   and a 'config.py' that imports the class and reads as follows:  from _config import Struct as Section  mysql = Section(\"MySQL specific configuration\") mysql.user = 'root' mysql.pass = 'secret' mysql.host = 'localhost' mysql.port = 3306 mysql.database = 'mydb'  mysql.tables = Section(\"Tables for 'mydb'\") mysql.tables.users = 'tb_users' mysql.tables.groups =  'tb_groups'   and is used in this way:  from sqlalchemy import MetaData, Table import config as CONFIG  assert(isinstance(CONFIG.mysql.port, int))  mdata = MetaData(     \"mysql://%s:%s@%s:%d/%s\" % (          CONFIG.mysql.user,          CONFIG.mysql.pass,          CONFIG.mysql.host,          CONFIG.mysql.port,          CONFIG.mysql.database,      ) )  tables = [] for name in CONFIG.mysql.tables:     tables.append(Table(name, mdata, autoload=True))   Which seems a more readable, expressive and flexible way of storing and fetching global variables inside a package.  Lamest idea ever? What is the best practice for coping with these situations? What is your way of storing and fetching global names and variables inside your package?     ","Q_Votes":"63"},{"Q_Title":"Most Pythonic way to provide global configuration variables in config.py?","A_Content":"  How about using classes?  # config.py class MYSQL:     PORT = 3306     DATABASE = 'mydb'     DATABASE_TABLES = ['tb_users', 'tb_groups']  # main.py from config import MYSQL  print(MYSQL.PORT) # 3306      ","Language":"Python","Tags":["global-variables","python","config","egg"],"URL":"https://stackoverflow.com/questions/6198372/most-pythonic-way-to-provide-global-configuration-variables-in-config-py","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    In my endless quest in over-complicating simple stuff, I am researching the most 'Pythonic' way to provide global configuration variables inside the typical 'config.py' found in Python egg packages.   The traditional way (aah, good ol' #define!) is as follows:  MYSQL_PORT = 3306 MYSQL_DATABASE = 'mydb' MYSQL_DATABASE_TABLES = ['tb_users', 'tb_groups']   Therefore global variables are imported in one of the following ways:  from config import * dbname = MYSQL_DATABASE for table in MYSQL_DATABASE_TABLES:     print table   or:  import config dbname = config.MYSQL_DATABASE assert(isinstance(config.MYSQL_PORT, int))   It makes sense, but sometimes can be a little messy, especially when you're trying to remember the names of certain variables. Besides, providing a 'configuration' object, with variables as attributes, might be more flexible. So, taking a lead from bpython config.py file, I came up with:  class Struct(object):      def __init__(self, *args):         self.__header__ = str(args[0]) if args else None      def __repr__(self):         if self.__header__ is None:              return super(Struct, self).__repr__()         return self.__header__      def next(self):         \"\"\" Fake iteration functionality.         \"\"\"         raise StopIteration      def __iter__(self):         \"\"\" Fake iteration functionality.         We skip magic attribues and Structs, and return the rest.         \"\"\"         ks = self.__dict__.keys()         for k in ks:             if not k.startswith('__') and not isinstance(k, Struct):                 yield getattr(self, k)      def __len__(self):         \"\"\" Don't count magic attributes or Structs.         \"\"\"         ks = self.__dict__.keys()         return len([k for k in ks if not k.startswith('__')\\                     and not isinstance(k, Struct)])   and a 'config.py' that imports the class and reads as follows:  from _config import Struct as Section  mysql = Section(\"MySQL specific configuration\") mysql.user = 'root' mysql.pass = 'secret' mysql.host = 'localhost' mysql.port = 3306 mysql.database = 'mydb'  mysql.tables = Section(\"Tables for 'mydb'\") mysql.tables.users = 'tb_users' mysql.tables.groups =  'tb_groups'   and is used in this way:  from sqlalchemy import MetaData, Table import config as CONFIG  assert(isinstance(CONFIG.mysql.port, int))  mdata = MetaData(     \"mysql://%s:%s@%s:%d/%s\" % (          CONFIG.mysql.user,          CONFIG.mysql.pass,          CONFIG.mysql.host,          CONFIG.mysql.port,          CONFIG.mysql.database,      ) )  tables = [] for name in CONFIG.mysql.tables:     tables.append(Table(name, mdata, autoload=True))   Which seems a more readable, expressive and flexible way of storing and fetching global variables inside a package.  Lamest idea ever? What is the best practice for coping with these situations? What is your way of storing and fetching global names and variables inside your package?     ","Q_Votes":"63"},{"Q_Title":"Most Pythonic way to provide global configuration variables in config.py?","A_Content":"  A small variation on Husky's idea that I use.  Make a file called 'globals' (or whatever you like) and then define multiple classes in it, as such:  #globals.py  class dbinfo :      # for database globals     username = 'abcd'     password = 'xyz'  class runtime :     debug = False     output = 'stdio'   Then, if you have two code files c1.py and c2.py, both can have at the top  import globals as gl   Now all code can access and set values, as such:  gl.runtime.debug = False print(gl.dbinfo.username)   People forget classes exist, even if no object is ever instantiated that is a member of that class.  And variables in a class that aren't preceded by 'self.' are shared across all instances of the class, even if there are none. Once 'debug' is changed by any code, all other code sees the change.   By importing it as gl, you can have multiple such files and variables that lets you access and set values across code files, functions, etc., but with no danger of namespace collision.   This lacks some of the clever error checking of other approaches, but is simple and easy to follow.     ","Language":"Python","Tags":["global-variables","python","config","egg"],"URL":"https://stackoverflow.com/questions/6198372/most-pythonic-way-to-provide-global-configuration-variables-in-config-py","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    In my endless quest in over-complicating simple stuff, I am researching the most 'Pythonic' way to provide global configuration variables inside the typical 'config.py' found in Python egg packages.   The traditional way (aah, good ol' #define!) is as follows:  MYSQL_PORT = 3306 MYSQL_DATABASE = 'mydb' MYSQL_DATABASE_TABLES = ['tb_users', 'tb_groups']   Therefore global variables are imported in one of the following ways:  from config import * dbname = MYSQL_DATABASE for table in MYSQL_DATABASE_TABLES:     print table   or:  import config dbname = config.MYSQL_DATABASE assert(isinstance(config.MYSQL_PORT, int))   It makes sense, but sometimes can be a little messy, especially when you're trying to remember the names of certain variables. Besides, providing a 'configuration' object, with variables as attributes, might be more flexible. So, taking a lead from bpython config.py file, I came up with:  class Struct(object):      def __init__(self, *args):         self.__header__ = str(args[0]) if args else None      def __repr__(self):         if self.__header__ is None:              return super(Struct, self).__repr__()         return self.__header__      def next(self):         \"\"\" Fake iteration functionality.         \"\"\"         raise StopIteration      def __iter__(self):         \"\"\" Fake iteration functionality.         We skip magic attribues and Structs, and return the rest.         \"\"\"         ks = self.__dict__.keys()         for k in ks:             if not k.startswith('__') and not isinstance(k, Struct):                 yield getattr(self, k)      def __len__(self):         \"\"\" Don't count magic attributes or Structs.         \"\"\"         ks = self.__dict__.keys()         return len([k for k in ks if not k.startswith('__')\\                     and not isinstance(k, Struct)])   and a 'config.py' that imports the class and reads as follows:  from _config import Struct as Section  mysql = Section(\"MySQL specific configuration\") mysql.user = 'root' mysql.pass = 'secret' mysql.host = 'localhost' mysql.port = 3306 mysql.database = 'mydb'  mysql.tables = Section(\"Tables for 'mydb'\") mysql.tables.users = 'tb_users' mysql.tables.groups =  'tb_groups'   and is used in this way:  from sqlalchemy import MetaData, Table import config as CONFIG  assert(isinstance(CONFIG.mysql.port, int))  mdata = MetaData(     \"mysql://%s:%s@%s:%d/%s\" % (          CONFIG.mysql.user,          CONFIG.mysql.pass,          CONFIG.mysql.host,          CONFIG.mysql.port,          CONFIG.mysql.database,      ) )  tables = [] for name in CONFIG.mysql.tables:     tables.append(Table(name, mdata, autoload=True))   Which seems a more readable, expressive and flexible way of storing and fetching global variables inside a package.  Lamest idea ever? What is the best practice for coping with these situations? What is your way of storing and fetching global names and variables inside your package?     ","Q_Votes":"63"},{"Q_Title":"Most Pythonic way to provide global configuration variables in config.py?","A_Content":"  please check out the IPython configuration system, implemented via traitlets for the type enforcement you are doing manually.  Cut and pasted here to comply with SO guidelines for not just dropping links as the content of links changes over time.  traitlets documentation     Here are the main requirements we wanted our configuration system to have:      Support for hierarchical configuration information.      Full integration with command line option parsers. Often, you want to read a configuration file, but then override some of the values with command line options. Our configuration system automates this process and allows each command line option to be linked to a particular attribute in the configuration hierarchy that it will override.      Configuration files that are themselves valid Python code. This accomplishes many things. First, it becomes possible to put logic in your configuration files that sets attributes based on your operating system, network setup, Python version, etc. Second, Python has a super simple syntax for accessing hierarchical data structures, namely regular attribute access (Foo.Bar.Bam.name). Third, using Python makes it easy for users to import configuration attributes from one configuration file to another.    Fourth, even though Python is dynamically typed, it does have types that can be checked at runtime. Thus, a 1 in a config file is the integer ‘1’, while a '1' is a string.      A fully automated method for getting the configuration information to the classes that need it at runtime. Writing code that walks a configuration hierarchy to extract a particular attribute is painful. When you have complex configuration information with hundreds of attributes, this makes you want to cry.      Type checking and validation that doesn’t require the entire configuration hierarchy to be specified statically before runtime. Python is a very dynamic language and you don’t always know everything that needs to be configured when a program starts.   To acheive this they basically define 3 object classes and their relations to each other:  1) Configuration - basically a ChainMap / basic dict with some enhancements for merging.  2) Configurable - base class to subclass all things you'd wish to configure.  3) Application - object that is instantiated to perform a specific application function, or your main application for single purpose software.  In their words:     Application: Application      An application is a process that does a specific job. The most obvious application is the ipython command line program. Each application reads one or more configuration files and a single set of command line options and then produces a master configuration object for the application. This configuration object is then passed to the configurable objects that the application creates. These configurable objects implement the actual logic of the application and know how to configure themselves given the configuration object.      Applications always have a log attribute that is a configured Logger. This allows centralized logging configuration per-application.   Configurable: Configurable      A configurable is a regular Python class that serves as a base class for all main classes in an application. The Configurable base class is lightweight and only does one things.      This Configurable is a subclass of HasTraits that knows how to configure itself. Class level traits with the metadata config=True become values that can be configured from the command line and configuration files.      Developers create Configurable subclasses that implement all of the logic in the application. Each of these subclasses has its own configuration information that controls how instances are created.      ","Language":"Python","Tags":["global-variables","python","config","egg"],"URL":"https://stackoverflow.com/questions/6198372/most-pythonic-way-to-provide-global-configuration-variables-in-config-py","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    In my endless quest in over-complicating simple stuff, I am researching the most 'Pythonic' way to provide global configuration variables inside the typical 'config.py' found in Python egg packages.   The traditional way (aah, good ol' #define!) is as follows:  MYSQL_PORT = 3306 MYSQL_DATABASE = 'mydb' MYSQL_DATABASE_TABLES = ['tb_users', 'tb_groups']   Therefore global variables are imported in one of the following ways:  from config import * dbname = MYSQL_DATABASE for table in MYSQL_DATABASE_TABLES:     print table   or:  import config dbname = config.MYSQL_DATABASE assert(isinstance(config.MYSQL_PORT, int))   It makes sense, but sometimes can be a little messy, especially when you're trying to remember the names of certain variables. Besides, providing a 'configuration' object, with variables as attributes, might be more flexible. So, taking a lead from bpython config.py file, I came up with:  class Struct(object):      def __init__(self, *args):         self.__header__ = str(args[0]) if args else None      def __repr__(self):         if self.__header__ is None:              return super(Struct, self).__repr__()         return self.__header__      def next(self):         \"\"\" Fake iteration functionality.         \"\"\"         raise StopIteration      def __iter__(self):         \"\"\" Fake iteration functionality.         We skip magic attribues and Structs, and return the rest.         \"\"\"         ks = self.__dict__.keys()         for k in ks:             if not k.startswith('__') and not isinstance(k, Struct):                 yield getattr(self, k)      def __len__(self):         \"\"\" Don't count magic attributes or Structs.         \"\"\"         ks = self.__dict__.keys()         return len([k for k in ks if not k.startswith('__')\\                     and not isinstance(k, Struct)])   and a 'config.py' that imports the class and reads as follows:  from _config import Struct as Section  mysql = Section(\"MySQL specific configuration\") mysql.user = 'root' mysql.pass = 'secret' mysql.host = 'localhost' mysql.port = 3306 mysql.database = 'mydb'  mysql.tables = Section(\"Tables for 'mydb'\") mysql.tables.users = 'tb_users' mysql.tables.groups =  'tb_groups'   and is used in this way:  from sqlalchemy import MetaData, Table import config as CONFIG  assert(isinstance(CONFIG.mysql.port, int))  mdata = MetaData(     \"mysql://%s:%s@%s:%d/%s\" % (          CONFIG.mysql.user,          CONFIG.mysql.pass,          CONFIG.mysql.host,          CONFIG.mysql.port,          CONFIG.mysql.database,      ) )  tables = [] for name in CONFIG.mysql.tables:     tables.append(Table(name, mdata, autoload=True))   Which seems a more readable, expressive and flexible way of storing and fetching global variables inside a package.  Lamest idea ever? What is the best practice for coping with these situations? What is your way of storing and fetching global names and variables inside your package?     ","Q_Votes":"63"},{"Q_Title":"Pros and cons to use Celery vs. RQ [closed]","A_Content":"  Here is what I have found while trying to answer this exact same question. It's probably not comprehensive, and may even be inaccurate on some points.   In short, RQ is designed to be simpler all around. Celery is designed to be more robust. They are both excellent.    Documentation. RQ's documentation is comprehensive without being complex, and mirrors the project's overall simplicity - you never feel lost or confused. Celery's documentation is also comprehensive, but expect to be re-visiting it quite a lot when you're first setting things up as there are too many options to internalize  Monitoring. Celery's Flower and the RQ dashboard are both very simple to setup and give you at least 90% of all information you would ever want Broker support. Celery is the clear winner, RQ only supports Redis. This means less documentation on \"what is a broker\", but also means you cannot switch brokers in the future if Redis no longer works for you. For example, Instagram considered both Redis and RabbitMQ with Celery. This is important because different brokers have different guarantees e.g. Redis cannot (as of writing) guarantee 100% that your messages are delivered.  Priority queues. RQs priority queue model is simple and effective - workers read from queues in order. Celery requires spinning up multiple workers to consume from different queues. Both approaches work OS Support. Celery is the clear winner here, as RQ only runs on systems that support fork e.g.  Unix systems Language support. RQ only supports Python, whereas Celery lets you send tasks from one language to a different language API. Celery is extremely flexible (multiple result backends, nice config format, workflow canvas support) but naturally this power can be confusing. By contrast, the RQ api is simple.  Subtask support. Celery supports subtasks (e.g. creating new tasks from within existing tasks). I don't know if RQ does Community and Stability. Celery is probably more established, but they are both active projects. As of writing, Celery has ~3500 stars on Github while RQ has ~2000 and both projects show active development   In my opinion, Celery is not as complex as its reputation might lead you to believe, but you will have to RTFM.   So, why would anyone be willing to trade the (arguably more full-featured) Celery for RQ? In my mind, it all comes down to the simplicity. By restricting itself to Redis+Unix, RQ provides simpler documentation, simpler codebase, and a simpler API. This means you (and potential contributors to your project) can focus on the code you care about, instead of having to keep details about the task queue system in your working memory. We all have a limit on how many details can be in our head at once, and by removing the need to keep task queue details in there RQ lets get back to the code you care about. That simplicity comes at the expense of features like inter-language task queues, wide OS support, 100% reliable message guarantees, and ability to switch message brokers easily.      ","Language":"Python","Tags":["python","web-applications","redis","scheduled-tasks","celery"],"URL":"https://stackoverflow.com/questions/13440875/pros-and-cons-to-use-celery-vs-rq","A_Votes":"75","_type":"dict","isAccepted":"Yes","Q_Content":"    Currently I'm working on python project that requires implement some background jobs (mostly for email sending and heavily database updates). I use Redis for task broker. So in this point I have two candidates: Celery and RQ. I had some experience with these job queues, but I want to ask you guys to share you experience of using this tools. So.   What pros and cons to use Celery vs. RQ. Any examples of projects/task suitable to use Celery vs. RQ.   Celery looks pretty complicated but it's full featured solution. Actually I don't think that I need all these features. From other side RQ is very simple (e.g configuration, integration), but it seems that it lacks some useful features (e.g task revoking, code auto-reloading)     ","Q_Votes":"63"},{"Q_Title":"Pros and cons to use Celery vs. RQ [closed]","A_Content":"  Celery is not that complicated. At its core, you do the step by step configuration from the tutorials, create a celery instance, decorate your function with @celery.task then run the task with my_task.delay(*args, **kwargs).  Judging from your own assessment, it seems you have to choose between lacking (key) features or having some excess hanging around. That is not too hard of a choice in my book.     ","Language":"Python","Tags":["python","web-applications","redis","scheduled-tasks","celery"],"URL":"https://stackoverflow.com/questions/13440875/pros-and-cons-to-use-celery-vs-rq","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Currently I'm working on python project that requires implement some background jobs (mostly for email sending and heavily database updates). I use Redis for task broker. So in this point I have two candidates: Celery and RQ. I had some experience with these job queues, but I want to ask you guys to share you experience of using this tools. So.   What pros and cons to use Celery vs. RQ. Any examples of projects/task suitable to use Celery vs. RQ.   Celery looks pretty complicated but it's full featured solution. Actually I don't think that I need all these features. From other side RQ is very simple (e.g configuration, integration), but it seems that it lacks some useful features (e.g task revoking, code auto-reloading)     ","Q_Votes":"63"},{"Q_Title":"What is the most efficient graph data structure in Python? [closed]","A_Content":"  I would strongly advocate you look at NetworkX. It's a battle-tested war horse and the first tool most 'research' types reach for when they need to do analysis of network based data. I have manipulated graphs with 100s of thousands of edges without problem on a notebook. Its feature rich and very easy to use. You will find yourself focusing more on the problem at hand rather than the details in the underlying implementation.  Example of Erdős-Rényi random graph generation and analysis   \"\"\" Create an G{n,m} random graph with n nodes and m edges and report some properties.  This graph is sometimes called the Erd##[m~Qs-Rényi graph but is different from G{n,p} or binomial_graph which is also sometimes called the Erd##[m~Qs-Rényi graph. \"\"\" __author__ = \"\"\"Aric Hagberg (hagberg@lanl.gov)\"\"\" __credits__ = \"\"\"\"\"\" #    Copyright (C) 2004-2006 by  #    Aric Hagberg  #    Dan Schult  #    Pieter Swart  #    Distributed under the terms of the GNU Lesser General Public License #    http://www.gnu.org/copyleft/lesser.html  from networkx import * import sys  n=10 # 10 nodes m=20 # 20 edges  G=gnm_random_graph(n,m)  # some properties print \"node degree clustering\" for v in nodes(G):     print v,degree(G,v),clustering(G,v)  # print the adjacency list to terminal  write_adjlist(G,sys.stdout)   Visualizations are also straightforward:    More visualization: http://jonschull.blogspot.com/2008/08/graph-visualization.html     ","Language":"Python","Tags":["python","performance","data-structures","graph-theory"],"URL":"https://stackoverflow.com/questions/1171/what-is-the-most-efficient-graph-data-structure-in-python","A_Votes":"51","_type":"dict","isAccepted":"Yes","Q_Content":"    I need to be able to manipulate a large (10^7 nodes) graph in python. The data corresponding to each node/edge is minimal, say, a small number of strings. What is the most efficient, in terms of memory and speed, way of doing this?   A dict of dicts is more flexible and simpler to implement, but I intuitively expect a list of lists to be faster. The list option would also require that I keep the data separate from the structure, while dicts would allow for something of the sort:  graph[I][J][\"Property\"]=\"value\"   What would you suggest?    Yes, I should have been a bit clearer on what I mean by efficiency. In this particular case I mean it in terms of random access retrieval.  Loading the data in to memory isn't a huge problem. That's done once and for all. The time consuming part is visiting the nodes so I can extract the information and measure the metrics I'm interested in.  I hadn't considered making each node a class (properties are the same for all nodes) but it seems like that would add an extra layer of overhead? I was hoping someone would have some direct experience with a similar case that they could share. After all, graphs are one of the most common abstractions in CS.     ","Q_Votes":"63"},{"Q_Title":"What is the most efficient graph data structure in Python? [closed]","A_Content":"  Even though this question is now quite old, I think it is worthwhile to mention my own python module for graph manipulation called graph-tool. It is very efficient, since the data structures and algorithms are implemented in C++, with template metaprograming, using the Boost Graph Library. Therefore its performance (both in memory usage and runtime) is comparable to a pure C++ library, and can be orders of magnitude better than typical python code, without sacrificing ease of use. I use it myself constantly to work with very large graphs.     ","Language":"Python","Tags":["python","performance","data-structures","graph-theory"],"URL":"https://stackoverflow.com/questions/1171/what-is-the-most-efficient-graph-data-structure-in-python","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I need to be able to manipulate a large (10^7 nodes) graph in python. The data corresponding to each node/edge is minimal, say, a small number of strings. What is the most efficient, in terms of memory and speed, way of doing this?   A dict of dicts is more flexible and simpler to implement, but I intuitively expect a list of lists to be faster. The list option would also require that I keep the data separate from the structure, while dicts would allow for something of the sort:  graph[I][J][\"Property\"]=\"value\"   What would you suggest?    Yes, I should have been a bit clearer on what I mean by efficiency. In this particular case I mean it in terms of random access retrieval.  Loading the data in to memory isn't a huge problem. That's done once and for all. The time consuming part is visiting the nodes so I can extract the information and measure the metrics I'm interested in.  I hadn't considered making each node a class (properties are the same for all nodes) but it seems like that would add an extra layer of overhead? I was hoping someone would have some direct experience with a similar case that they could share. After all, graphs are one of the most common abstractions in CS.     ","Q_Votes":"63"},{"Q_Title":"What is the most efficient graph data structure in Python? [closed]","A_Content":"  As already mentioned, NetworkX is very good, with another option being igraph. Both modules will have most (if not all) the analysis tools you're likely to need, and both libraries are routinely used with large networks.     ","Language":"Python","Tags":["python","performance","data-structures","graph-theory"],"URL":"https://stackoverflow.com/questions/1171/what-is-the-most-efficient-graph-data-structure-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I need to be able to manipulate a large (10^7 nodes) graph in python. The data corresponding to each node/edge is minimal, say, a small number of strings. What is the most efficient, in terms of memory and speed, way of doing this?   A dict of dicts is more flexible and simpler to implement, but I intuitively expect a list of lists to be faster. The list option would also require that I keep the data separate from the structure, while dicts would allow for something of the sort:  graph[I][J][\"Property\"]=\"value\"   What would you suggest?    Yes, I should have been a bit clearer on what I mean by efficiency. In this particular case I mean it in terms of random access retrieval.  Loading the data in to memory isn't a huge problem. That's done once and for all. The time consuming part is visiting the nodes so I can extract the information and measure the metrics I'm interested in.  I hadn't considered making each node a class (properties are the same for all nodes) but it seems like that would add an extra layer of overhead? I was hoping someone would have some direct experience with a similar case that they could share. After all, graphs are one of the most common abstractions in CS.     ","Q_Votes":"63"},{"Q_Title":"What is the most efficient graph data structure in Python? [closed]","A_Content":"  A dictionary may also contain overhead, depending on the actual implementation. A hashtable usually contain some prime number of available nodes to begin with, even though you might only use a couple of the nodes.  Judging by your example, \"Property\", would you be better of with a class approach for the final level and real properties? Or is the names of the properties changing a lot from node to node?  I'd say that what \"efficient\" means depends on a lot of things, like:   speed of updates (insert, update, delete) speed of random access retrieval speed of sequential retrieval memory used   I think that you'll find that a data structure that is speedy will generally consume more memory than one that is slow. This isn't always the case, but most data structures seems to follow this.  A dictionary might be easy to use, and give you relatively uniformly fast access, it will most likely use more memory than, as you suggest, lists. Lists, however, generally tend to contain more overhead when you insert data into it, unless they preallocate X nodes, in which they will again use more memory.  My suggestion, in general, would be to just use the method that seems the most natural to you, and then do a \"stress test\" of the system, adding a substantial amount of data to it and see if it becomes a problem.  You might also consider adding a layer of abstraction to your system, so that you don't have to change the programming interface if you later on need to change the internal data structure.     ","Language":"Python","Tags":["python","performance","data-structures","graph-theory"],"URL":"https://stackoverflow.com/questions/1171/what-is-the-most-efficient-graph-data-structure-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I need to be able to manipulate a large (10^7 nodes) graph in python. The data corresponding to each node/edge is minimal, say, a small number of strings. What is the most efficient, in terms of memory and speed, way of doing this?   A dict of dicts is more flexible and simpler to implement, but I intuitively expect a list of lists to be faster. The list option would also require that I keep the data separate from the structure, while dicts would allow for something of the sort:  graph[I][J][\"Property\"]=\"value\"   What would you suggest?    Yes, I should have been a bit clearer on what I mean by efficiency. In this particular case I mean it in terms of random access retrieval.  Loading the data in to memory isn't a huge problem. That's done once and for all. The time consuming part is visiting the nodes so I can extract the information and measure the metrics I'm interested in.  I hadn't considered making each node a class (properties are the same for all nodes) but it seems like that would add an extra layer of overhead? I was hoping someone would have some direct experience with a similar case that they could share. After all, graphs are one of the most common abstractions in CS.     ","Q_Votes":"63"},{"Q_Title":"What is the most efficient graph data structure in Python? [closed]","A_Content":"  As I understand it, random access is in constant time for both Python's dicts and lists, the difference is that you can only do random access of integer indexes with lists.  I'm assuming that you need to lookup a node by its label, so you want a dict of dicts.  However, on the performance front, loading it into memory may not be a problem, but if you use too much you'll end up swapping to disk, which will kill the performance of even Python's highly efficient dicts.  Try to keep memory usage down as much as possible.  Also, RAM is amazingly cheap right now; if you do this kind of thing a lot, there's no reason not to have at least 4GB.  If you'd like advice on keeping memory usage down, give some more information about the kind of information you're tracking for each node.     ","Language":"Python","Tags":["python","performance","data-structures","graph-theory"],"URL":"https://stackoverflow.com/questions/1171/what-is-the-most-efficient-graph-data-structure-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I need to be able to manipulate a large (10^7 nodes) graph in python. The data corresponding to each node/edge is minimal, say, a small number of strings. What is the most efficient, in terms of memory and speed, way of doing this?   A dict of dicts is more flexible and simpler to implement, but I intuitively expect a list of lists to be faster. The list option would also require that I keep the data separate from the structure, while dicts would allow for something of the sort:  graph[I][J][\"Property\"]=\"value\"   What would you suggest?    Yes, I should have been a bit clearer on what I mean by efficiency. In this particular case I mean it in terms of random access retrieval.  Loading the data in to memory isn't a huge problem. That's done once and for all. The time consuming part is visiting the nodes so I can extract the information and measure the metrics I'm interested in.  I hadn't considered making each node a class (properties are the same for all nodes) but it seems like that would add an extra layer of overhead? I was hoping someone would have some direct experience with a similar case that they could share. After all, graphs are one of the most common abstractions in CS.     ","Q_Votes":"63"},{"Q_Title":"What is the most efficient graph data structure in Python? [closed]","A_Content":"  Making a class-based structure would probably have more overhead than the dict-based structure, since in python classes actually use dicts when they are implemented.     ","Language":"Python","Tags":["python","performance","data-structures","graph-theory"],"URL":"https://stackoverflow.com/questions/1171/what-is-the-most-efficient-graph-data-structure-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I need to be able to manipulate a large (10^7 nodes) graph in python. The data corresponding to each node/edge is minimal, say, a small number of strings. What is the most efficient, in terms of memory and speed, way of doing this?   A dict of dicts is more flexible and simpler to implement, but I intuitively expect a list of lists to be faster. The list option would also require that I keep the data separate from the structure, while dicts would allow for something of the sort:  graph[I][J][\"Property\"]=\"value\"   What would you suggest?    Yes, I should have been a bit clearer on what I mean by efficiency. In this particular case I mean it in terms of random access retrieval.  Loading the data in to memory isn't a huge problem. That's done once and for all. The time consuming part is visiting the nodes so I can extract the information and measure the metrics I'm interested in.  I hadn't considered making each node a class (properties are the same for all nodes) but it seems like that would add an extra layer of overhead? I was hoping someone would have some direct experience with a similar case that they could share. After all, graphs are one of the most common abstractions in CS.     ","Q_Votes":"63"},{"Q_Title":"What is the most efficient graph data structure in Python? [closed]","A_Content":"  No doubt NetworkX is the best data structure till now for graph. It comes with utilities like Helper Functions, Data Structures and Algorithms, Random Sequence Generators, Decorators, Cuthill-Mckee Ordering, Context Managers  NetworkX is great because it wowrs for graphs, digraphs, and multigraphs. It can write graph with multiple ways: Adjacency List, Multiline Adjacency List, Edge List, GEXF, GML. It works with Pickle, GraphML, JSON, SparseGraph6 etc.   It has implimentation of various radimade algorithms including: Approximation, Bipartite, Boundary, Centrality, Clique, Clustering,    Coloring, Components, Connectivity, Cycles,  Directed Acyclic Graphs, Distance Measures,  Dominating Sets, Eulerian, Isomorphism,  Link Analysis,  Link Prediction, Matching, Minimum Spanning Tree, Rich Club, Shortest Paths, Traversal, Tree.     ","Language":"Python","Tags":["python","performance","data-structures","graph-theory"],"URL":"https://stackoverflow.com/questions/1171/what-is-the-most-efficient-graph-data-structure-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to be able to manipulate a large (10^7 nodes) graph in python. The data corresponding to each node/edge is minimal, say, a small number of strings. What is the most efficient, in terms of memory and speed, way of doing this?   A dict of dicts is more flexible and simpler to implement, but I intuitively expect a list of lists to be faster. The list option would also require that I keep the data separate from the structure, while dicts would allow for something of the sort:  graph[I][J][\"Property\"]=\"value\"   What would you suggest?    Yes, I should have been a bit clearer on what I mean by efficiency. In this particular case I mean it in terms of random access retrieval.  Loading the data in to memory isn't a huge problem. That's done once and for all. The time consuming part is visiting the nodes so I can extract the information and measure the metrics I'm interested in.  I hadn't considered making each node a class (properties are the same for all nodes) but it seems like that would add an extra layer of overhead? I was hoping someone would have some direct experience with a similar case that they could share. After all, graphs are one of the most common abstractions in CS.     ","Q_Votes":"63"},{"Q_Title":"How do I type a floating point infinity literal in python","A_Content":"  In python 2.6 it is portable if the CPU supports it     The float() function will now turn the   string nan into an IEEE 754 Not A   Number value, and +inf and -inf into   positive or negative infinity. This   works on any platform with IEEE 754   semantics.      ","Language":"Python","Tags":["python","floating-point","portability","numerical"],"URL":"https://stackoverflow.com/questions/2919754/how-do-i-type-a-floating-point-infinity-literal-in-python","A_Votes":"57","_type":"dict","isAccepted":"Yes","Q_Content":"    How do I type a floating point infinity literal in python?  I have heard    inf = float('inf')   is non portable.  Thus, I have had the following recommended:   inf = 1e400   Is either of these standard, or portable?  What is best practice?     ","Q_Votes":"63"},{"Q_Title":"How do I type a floating point infinity literal in python","A_Content":"  float('inf') is non portable as in not portable back to Python 2.5 when the string output varies between platforms. From 2.6 and onwards float('inf') is guaranteed to work on IEEE-754-compliance platforms (ref: http://www.python.org/dev/peps/pep-0754/).  (And the recommendation seems to be in the range 1e30000, not just 1e400.)     ","Language":"Python","Tags":["python","floating-point","portability","numerical"],"URL":"https://stackoverflow.com/questions/2919754/how-do-i-type-a-floating-point-infinity-literal-in-python","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    How do I type a floating point infinity literal in python?  I have heard    inf = float('inf')   is non portable.  Thus, I have had the following recommended:   inf = 1e400   Is either of these standard, or portable?  What is best practice?     ","Q_Votes":"63"},{"Q_Title":"How do I type a floating point infinity literal in python","A_Content":"  Perhaps you could do something like this  try:     inf = float('inf') except:  # check for a particular exception here?     inf = 1e30000      ","Language":"Python","Tags":["python","floating-point","portability","numerical"],"URL":"https://stackoverflow.com/questions/2919754/how-do-i-type-a-floating-point-infinity-literal-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    How do I type a floating point infinity literal in python?  I have heard    inf = float('inf')   is non portable.  Thus, I have had the following recommended:   inf = 1e400   Is either of these standard, or portable?  What is best practice?     ","Q_Votes":"63"},{"Q_Title":"Python TypeError: non-empty format string passed to object.__format__","A_Content":"  bytes objects do not have a __format__ method of their own, so the default from object is used:  >>> bytes.__format__ is object.__format__ True >>> '{:20}'.format(object()) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: non-empty format string passed to object.__format__   It just means that you cannot use anything other than straight up, unformatted unaligned formatting on these. Explicitly convert to a string object (as you did by decoding bytes to str) to get format spec support.  You can make the conversion explicit by using the !s string conversion:  >>> '{!s:20s}'.format(b\"Hi\") \"b'Hi'               \" >>> '{!s:20s}'.format(object()) '<object object at 0x1100b9080>'   object.__format__ explicitly rejects format strings to avoid implicit string conversions, specifically because formatting instructions are type specific.     ","Language":"Python","Tags":["python","python-3.x","string-formatting"],"URL":"https://stackoverflow.com/questions/24170519/python-typeerror-non-empty-format-string-passed-to-object-format","A_Votes":"59","_type":"dict","isAccepted":"Yes","Q_Content":"    I hit this TypeError exception recently, which I found very difficult to debug. I eventually reduced it to this small test case:  >>> \"{:20}\".format(b\"hi\") Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: non-empty format string passed to object.__format__   This is very non-obvious, to me anyway. The workaround for my code was to decode the byte string into unicode:   >>> \"{:20}\".format(b\"hi\".decode(\"ascii\"))  'hi                  '   What is the meaning of this exception? Is there a way it can be made more clear?     ","Q_Votes":"63"},{"Q_Title":"Python TypeError: non-empty format string passed to object.__format__","A_Content":"  This also happens when trying to format None:  >>> '{:.0f}'.format(None) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: non-empty format string passed to object.__format__   That took a moment to work out (in my case, when None was being returned by an instance variable)!     ","Language":"Python","Tags":["python","python-3.x","string-formatting"],"URL":"https://stackoverflow.com/questions/24170519/python-typeerror-non-empty-format-string-passed-to-object-format","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I hit this TypeError exception recently, which I found very difficult to debug. I eventually reduced it to this small test case:  >>> \"{:20}\".format(b\"hi\") Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: non-empty format string passed to object.__format__   This is very non-obvious, to me anyway. The workaround for my code was to decode the byte string into unicode:   >>> \"{:20}\".format(b\"hi\".decode(\"ascii\"))  'hi                  '   What is the meaning of this exception? Is there a way it can be made more clear?     ","Q_Votes":"63"},{"Q_Title":"Virtualenv and source version control","A_Content":"  You generate a \"requirements\" file (usually requirements.txt) that you commit with your project:  pip freeze > requirements.txt   Then, each developer will set up their own virtualenv and run:  pip install -r requirements.txt      ","Language":"Python","Tags":["python","django","mercurial","virtualenv"],"URL":"https://stackoverflow.com/questions/9586346/virtualenv-and-source-version-control","A_Votes":"78","_type":"dict","isAccepted":"Yes","Q_Content":"    I recently started a Django project and I quickly realized that virtualenv will be really useful for many reasons. I set up the virtualenv and my project, but now I wonder what file I should add to my source control (in my case, Mercurial). Should I add all the files under the venv folder? How do I make sure a colleague can clone and get started to work immediately withou having to setup the env again?     ","Q_Votes":"63"},{"Q_Title":"Virtualenv and source version control","A_Content":"  All these environment hassles are kind of common when you are doing python/django development! I went through all these problem, and I have tested some solutions! Things that I have tested:   Project running local Project running in virtualenv Project running in a VM Project running in a VM, using vagrant   The best solution I found was #4! because the company that I used to work, each person in the team has a different OS, all sort of windows, mac and linux, and to install all dependencies for each environment it takes time! So we decided to try virtualenv, which is really good! but still each person has to setup his own enviroument. The problem in virtualenv is that all python sources are within the environment that u create! So I would not push those files to a source version control!  Best solution was #4, because that was exactly what I needed, Vagrant uses Chef to setup your environment, so you just have to write some recipes, and let vagrant run them for u! Then u push those recipes to SCM, then when the next person get the files from SCM and reloads the VM all dependencies will be automatically install!   I have a blog post explaining more about the subject as well as I have created a Django Blank project in github so you can get that to have a start point of your project using vagrant.  http://arthurnn.com/blog/2011/11/25/easy-django-quickstart/ (link no longer active, so linked to Wayback Machine)  EDIT  Solution from Chris Pratt is a good one as well, however some libraries are not so straightforward to install in all OS, for instance, a lot people on Mac get problems when they want to install MySQLdb-python. which is a really common library, but if everyone in your team has to spend time solving this issues, is not good at all!     ","Language":"Python","Tags":["python","django","mercurial","virtualenv"],"URL":"https://stackoverflow.com/questions/9586346/virtualenv-and-source-version-control","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I recently started a Django project and I quickly realized that virtualenv will be really useful for many reasons. I set up the virtualenv and my project, but now I wonder what file I should add to my source control (in my case, Mercurial). Should I add all the files under the venv folder? How do I make sure a colleague can clone and get started to work immediately withou having to setup the env again?     ","Q_Votes":"63"},{"Q_Title":"Difference in boto3 between resource, client, and session?","A_Content":"  To add to the other answer, specifically when comparing Client vs. Resource.  Client:   low-level service access generated from service description exposes botocore client to the developer typically maps 1:1 with the service API snake-cased method names (e.g. ListBuckets API => list_buckets method)   Here's an example of client-level access to an S3 bucket's objects (at most 1000**):  import boto3  client = boto3.client('s3') response = client.list_objects(Bucket='mybucket') for content in response['Contents']:     obj_dict = client.get_object(Bucket='mybucket', Key=content['Key'])     print(content['Key'], obj_dict['LastModified'])   ** you would have to use a paginator, or implement your own loop, calling list_objects() repeatedly with a continuation marker if there were more than 1000.  Resource:   higher-level, object-oriented API generated from resource description uses identifiers and attributes has actions (operations on resources) exposes subresources and collections   Here's the equivalent example using resource-level access to an S3 bucket's objects (all):  import boto3  s3 = boto3.resource('s3') bucket = s3.Bucket('mybucket') for obj in bucket.objects.all():     print(obj.key, obj.last_modified)   Note that in this case you do not have to make a second API call to get the objects; they're available to you as a collection on the bucket. These collections of subresources are lazily-loaded.  Session:   stores configuration information (primarily credentials and selected region) allows you to create service clients and resources   A useful resource to learn more about these boto3 concepts is the introductory re:Invent video.     ","Language":"Python","Tags":["python","boto3"],"URL":"https://stackoverflow.com/questions/42809096/difference-in-boto3-between-resource-client-and-session","A_Votes":"47","_type":"dict","isAccepted":"Yes","Q_Content":"    I am using Python 2.7.12 in Ubuntu 16.04 LTS. I'm learning how to use boto3 in python from the following link   https://boto3.readthedocs.io/en/latest/guide/quickstart.html#using-boto-3. My doubt is when to use resource,client,session and their functionality.     ","Q_Votes":"63"},{"Q_Title":"Difference in boto3 between resource, client, and session?","A_Content":"  I'll try and explain it as simple as possible. So there is no guarantee of the accuracy of the actual terms.   Session is where initiate the connectivity to AWS services. E.g. following is default session that use the default credential profile(e.g. ~/.aws/credentials, or assume your EC2 using IAM instance profile )  sqs = boto3.client('sqs') s3 = boto3.resource('s3')   Because default session is limit to the profile or instance profile used, sometime you need to use the custom session to override the default session configuration (e.g. region_name, endpoint_url, etc. )  e.g.   # custom resource session must use boto3.Session to do the override my_west_session = boto3.Session(region_name = 'us-west-2') my_east_sesison = boto3.Session(region_name = 'us-east-1') backup_s3 = my_west_session.resource('s3') video_s3 = my_east_sesison.resource('s3')  # you have two choices of create custom client session.  backup_s3c = my_west_session.client('s3') video_s3c = boto3.client(\"s3\", region_name = 'us-east-1')   Resource : This is the high level service class recommended to be used. This allow you to tied particular AWS resources and pass it along, so you just use this abstraction than worry which target services is pointed to. As you notice from the session part, if you have a custom session, you just pass this abstract object than worrying of all custom region,etc to pass along. Following is a complicate example E.g.   import boto3  my_west_session = boto3.Session(region_name = 'us-west-2') my_east_sesison = boto3.Session(region_name = 'us-east-1') backup_s3 = my_west_session.resource(\"s3\") video_s3 = my_east_sesison.resource(\"s3\") backup_bucket = backup_s3.Bucket('backupbucket')  video_bucket = video_s3.Bucket('videobucket')  # just pass the instantiated bucket object def list_bucket_contents(bucket):    for object in bucket.objects.all():       print(object.key)  list_bucket_contents(backup_bucket) list_bucket_contents(video_bucket)   Client is a low level class object. For each client call, you need to explicitly specify the targeting resources, the designated service target name must be pass long. You will lost the abstraction ability.  For example, if you only deal with default session, this looks similar to boto3.resource.   import boto3  s3 = boto3.client('s3')  def list_bucket_contents(bucket_name):    for object in s3.list_objects_v2(Bucket=bucket_name) :       print(object.key)  list_bucket_contents('Mybucket')    However, if you want to list objects from bucket in different region, you need to specify explicit bucket parameter required for client.   import boto3  backup_s3 = my_west_session.client('s3',region_name = 'us-west-2') video_s3 = my_east_sesison.client('s3',region_name = 'us-east-1')  # you must pass boto3.Session.client and the bucket name  def list_bucket_contents(s3session, bucket_name):    for object in s3session.list_objects_v2(Bucket=bucket_name) :       print(object.key)  list_bucket_contents(backup_s3, 'backupbucket') list_bucket_contents(video_s3 , 'videobucket')       ","Language":"Python","Tags":["python","boto3"],"URL":"https://stackoverflow.com/questions/42809096/difference-in-boto3-between-resource-client-and-session","A_Votes":"42","_type":"dict","isAccepted":"No","Q_Content":"    I am using Python 2.7.12 in Ubuntu 16.04 LTS. I'm learning how to use boto3 in python from the following link   https://boto3.readthedocs.io/en/latest/guide/quickstart.html#using-boto-3. My doubt is when to use resource,client,session and their functionality.     ","Q_Votes":"63"},{"Q_Title":"PyPi download counts seem unrealistic","A_Content":"  This is kind of an old question at this point, but I noticed the same thing about a package I have on PyPI and investigated further. It turns out PyPI keeps reasonably detailed download statistics, including (apparently slightly anonymised) user agents. From that, it was apparent that most people downloading my package were things like \"z3c.pypimirror/1.0.15.1\" and \"pep381client/1.5\". (PEP 381 describes a mirroring infrastructure for PyPI.)  I wrote a quick script to tally everything up, first including all of them and then leaving out the most obvious bots, and it turns out that literally 99% of the download activity for my package was caused by mirrorbots: 14,335 downloads total, compared to only 146 downloads with the bots filtered. And that's just leaving out the very obvious ones, so it's probably still an overestimate.  It looks like the main reason PyPI needs mirrors is because it has them.     ","Language":"Python","Tags":["python","web-crawler","pypi"],"URL":"https://stackoverflow.com/questions/9648015/pypi-download-counts-seem-unrealistic","A_Votes":"72","_type":"dict","isAccepted":"Yes","Q_Content":"    I put a package on PyPi for the first time ~2 months ago, and have made some version updates since then. I noticed this week the download count recording, and was surprised to see it had been downloaded hundreds of times. Over the next few days, I was more surprised to see the download count increasing by sometimes hundreds per day, even though this is a niche statistical test toolbox. In particular, older versions of package are continuing to be downloaded, sometimes at higher rates than the newest version.  What is going on here?  Is there a bug in PyPi's downloaded counting, or is there an abundance of crawlers grabbing open source code (as mine is)?     ","Q_Votes":"63"},{"Q_Title":"PyPi download counts seem unrealistic","A_Content":"  Starting with Cairnarvon's summarizing statement:      \"It looks like the main reason PyPI needs mirrors is because it has them.\"   I would slightly modify this:      It might be more the way PyPI actually works and thus has to be mirrored, that might contribute an additional bit (or two :-) to the real traffic.    At the moment I think you MUST interact with the main index to know what to update in your repository. State is not simply accesible through timestamps on some publicly accessible folder hierarchy. So, the bad thing is, rsync is out of the equation. The good thing is, you MAY talk to the index through JSON, OAuth, XML-RPC or HTTP interfaces.  For XML-RPC:  $> python >>> import xmlrpclib >>> import pprint >>> client = xmlrpclib.ServerProxy('http://pypi.python.org/pypi') >>> client.package_releases('PartitionSets') ['0.1.1']   For JSON eg.:  $> curl https://pypi.python.org/pypi/PartitionSets/0.1.1/json   If there are approx. 30.000 packages hosted [1] with some being downloaded 50.000 to 300.000 times a week [2] (like distribute, pip, requests, paramiko, lxml, boto, paramike, redis and others) you really need mirrors at least from an accessibilty perspective. Just imagine what a user does when pip install NeedThisPackage fails: Wait? Also company wide PyPI mirrors are quite common acting as proxies for otherwise unrouteable networks. Finally not to forget the wonderful multi version checking enabled through virtualenv and friends. These all are IMO legitimate and potentially wonderful uses of packages ...  In the end, you never know what an agent really does with a downloaded package: Have N users really use it or just overwrite it next time ... and after all, IMHO package authors should care more for number and nature of uses, than the pure number of potential users ;-)     Refs: The guestimated numbers are from https://pypi.python.org/pypi (29303 packages) and http://pypi-ranking.info/week (for the weekly numbers, requested 2013-03-23).      ","Language":"Python","Tags":["python","web-crawler","pypi"],"URL":"https://stackoverflow.com/questions/9648015/pypi-download-counts-seem-unrealistic","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I put a package on PyPi for the first time ~2 months ago, and have made some version updates since then. I noticed this week the download count recording, and was surprised to see it had been downloaded hundreds of times. Over the next few days, I was more surprised to see the download count increasing by sometimes hundreds per day, even though this is a niche statistical test toolbox. In particular, older versions of package are continuing to be downloaded, sometimes at higher rates than the newest version.  What is going on here?  Is there a bug in PyPi's downloaded counting, or is there an abundance of crawlers grabbing open source code (as mine is)?     ","Q_Votes":"63"},{"Q_Title":"PyPi download counts seem unrealistic","A_Content":"  You also have to take into account that virtualenv is getting more popular. If your package is something like a core library that people use in many of their projects, they will usually download it multiple times.  Consider a single user has 5 projects where he uses your package and each lives in its own virtualenv. Using pip to meet the requirements, your package is already downloaded 5 times this way. Then these projects might be set up on different machines, like work, home and laptop computers, in addition there might be a staging and a live server in case of a web application. Summing this up, you end up with many downloads by a single person.  Just a thought... perhaps your package is simply good. ;)     ","Language":"Python","Tags":["python","web-crawler","pypi"],"URL":"https://stackoverflow.com/questions/9648015/pypi-download-counts-seem-unrealistic","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I put a package on PyPi for the first time ~2 months ago, and have made some version updates since then. I noticed this week the download count recording, and was surprised to see it had been downloaded hundreds of times. Over the next few days, I was more surprised to see the download count increasing by sometimes hundreds per day, even though this is a niche statistical test toolbox. In particular, older versions of package are continuing to be downloaded, sometimes at higher rates than the newest version.  What is going on here?  Is there a bug in PyPi's downloaded counting, or is there an abundance of crawlers grabbing open source code (as mine is)?     ","Q_Votes":"63"},{"Q_Title":"PyPi download counts seem unrealistic","A_Content":"  Hypothesis: CI tools like Travis CI and Appveyor also contribute quite a bit. It might mean that each commit/push leads to a build of a package and the installation of everything in requirements.txt     ","Language":"Python","Tags":["python","web-crawler","pypi"],"URL":"https://stackoverflow.com/questions/9648015/pypi-download-counts-seem-unrealistic","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I put a package on PyPi for the first time ~2 months ago, and have made some version updates since then. I noticed this week the download count recording, and was surprised to see it had been downloaded hundreds of times. Over the next few days, I was more surprised to see the download count increasing by sometimes hundreds per day, even though this is a niche statistical test toolbox. In particular, older versions of package are continuing to be downloaded, sometimes at higher rates than the newest version.  What is going on here?  Is there a bug in PyPi's downloaded counting, or is there an abundance of crawlers grabbing open source code (as mine is)?     ","Q_Votes":"63"},{"Q_Title":"PyPi download counts seem unrealistic","A_Content":"  Results from PyPI-Stats.com seem reasonable.     ","Language":"Python","Tags":["python","web-crawler","pypi"],"URL":"https://stackoverflow.com/questions/9648015/pypi-download-counts-seem-unrealistic","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I put a package on PyPi for the first time ~2 months ago, and have made some version updates since then. I noticed this week the download count recording, and was surprised to see it had been downloaded hundreds of times. Over the next few days, I was more surprised to see the download count increasing by sometimes hundreds per day, even though this is a niche statistical test toolbox. In particular, older versions of package are continuing to be downloaded, sometimes at higher rates than the newest version.  What is going on here?  Is there a bug in PyPi's downloaded counting, or is there an abundance of crawlers grabbing open source code (as mine is)?     ","Q_Votes":"63"},{"Q_Title":"Python/Matplotlib - Is there a way to make a discontinuous axis?","A_Content":"  Paul's answer is a perfectly fine method of doing this.   However, if you don't want to make a custom transform, you can just use two subplots to create the same effect.  Rather than put together an example from scratch, there's an excellent example of this written by Paul Ivanov in the matplotlib examples (It's only in the current git tip, as it was only committed a few months ago. It's not on the webpage yet.).    This is just a simple modification of this example to have a discontinuous x-axis instead of the y-axis. (Which is why I'm making this post a CW)  Basically, you just do something like this:  import matplotlib.pylab as plt import numpy as np  # If you're not familiar with np.r_, don't worry too much about this. It's just  # a series with points from 0 to 1 spaced at 0.1, and 9 to 10 with the same spacing. x = np.r_[0:1:0.1, 9:10:0.1] y = np.sin(x)  fig,(ax,ax2) = plt.subplots(1, 2, sharey=True)  # plot the same data on both axes ax.plot(x, y, 'bo') ax2.plot(x, y, 'bo')  # zoom-in / limit the view to different portions of the data ax.set_xlim(0,1) # most of the data ax2.set_xlim(9,10) # outliers only  # hide the spines between ax and ax2 ax.spines['right'].set_visible(False) ax2.spines['left'].set_visible(False) ax.yaxis.tick_left() ax.tick_params(labeltop='off') # don't put tick labels at the top ax2.yaxis.tick_right()  # Make the spacing between the two axes a bit smaller plt.subplots_adjust(wspace=0.15)  plt.show()     To add the broken axis lines // effect, we can do this (again, modified from Paul Ivanov's example):  import matplotlib.pylab as plt import numpy as np  # If you're not familiar with np.r_, don't worry too much about this. It's just  # a series with points from 0 to 1 spaced at 0.1, and 9 to 10 with the same spacing. x = np.r_[0:1:0.1, 9:10:0.1] y = np.sin(x)  fig,(ax,ax2) = plt.subplots(1, 2, sharey=True)  # plot the same data on both axes ax.plot(x, y, 'bo') ax2.plot(x, y, 'bo')  # zoom-in / limit the view to different portions of the data ax.set_xlim(0,1) # most of the data ax2.set_xlim(9,10) # outliers only  # hide the spines between ax and ax2 ax.spines['right'].set_visible(False) ax2.spines['left'].set_visible(False) ax.yaxis.tick_left() ax.tick_params(labeltop='off') # don't put tick labels at the top ax2.yaxis.tick_right()  # Make the spacing between the two axes a bit smaller plt.subplots_adjust(wspace=0.15)  # This looks pretty good, and was fairly painless, but you can get that # cut-out diagonal lines look with just a bit more work. The important # thing to know here is that in axes coordinates, which are always # between 0-1, spine endpoints are at these locations (0,0), (0,1), # (1,0), and (1,1). Thus, we just need to put the diagonals in the # appropriate corners of each of our axes, and so long as we use the # right transform and disable clipping.  d = .015 # how big to make the diagonal lines in axes coordinates # arguments to pass plot, just so we don't keep repeating them kwargs = dict(transform=ax.transAxes, color='k', clip_on=False) ax.plot((1-d,1+d),(-d,+d), **kwargs) # top-left diagonal ax.plot((1-d,1+d),(1-d,1+d), **kwargs) # bottom-left diagonal  kwargs.update(transform=ax2.transAxes) # switch to the bottom axes ax2.plot((-d,d),(-d,+d), **kwargs) # top-right diagonal ax2.plot((-d,d),(1-d,1+d), **kwargs) # bottom-right diagonal  # What's cool about this is that now if we vary the distance between # ax and ax2 via f.subplots_adjust(hspace=...) or plt.subplot_tool(), # the diagonal lines will move accordingly, and stay right at the tips # of the spines they are 'breaking'  plt.show()        ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/5656798/python-matplotlib-is-there-a-way-to-make-a-discontinuous-axis","A_Votes":"63","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to create a plot using pyplot that has a discontinuous x-axis.  The usual way this is drawn is that the axis will have something like this:  (values)----//----(later values)  where the // indicates that you're skipping everything between (values) and (later values).  I haven't been able to find any examples of this, so I'm wondering if it's even possible.  I know you can join data over a discontinuity for, eg, financial data, but I'd like to make the jump in the axis more explicit.  At the moment I'm just using subplots but I'd really like to have everything end up on the same graph in the end.     ","Q_Votes":"63"},{"Q_Title":"Python/Matplotlib - Is there a way to make a discontinuous axis?","A_Content":"  I see many suggestions for this feature but no indication that it's been implemented.  Here is a workable solution for the time-being.  It applies a step-function transform to the x-axis. It's a lot of code, but it's fairly simple since most of it is boilerplate custom scale stuff.  I have not added any graphics to indicate the location of the break, since that is a matter of style.  Good luck finishing the job.  from matplotlib import pyplot as plt from matplotlib import scale as mscale from matplotlib import transforms as mtransforms import numpy as np  def CustomScaleFactory(l, u):     class CustomScale(mscale.ScaleBase):         name = 'custom'          def __init__(self, axis, **kwargs):             mscale.ScaleBase.__init__(self)             self.thresh = None #thresh          def get_transform(self):             return self.CustomTransform(self.thresh)          def set_default_locators_and_formatters(self, axis):             pass          class CustomTransform(mtransforms.Transform):             input_dims = 1             output_dims = 1             is_separable = True             lower = l             upper = u             def __init__(self, thresh):                 mtransforms.Transform.__init__(self)                 self.thresh = thresh              def transform(self, a):                 aa = a.copy()                 aa[a>self.lower] = a[a>self.lower]-(self.upper-self.lower)                 aa[(a>self.lower)&(a<self.upper)] = self.lower                 return aa              def inverted(self):                 return CustomScale.InvertedCustomTransform(self.thresh)          class InvertedCustomTransform(mtransforms.Transform):             input_dims = 1             output_dims = 1             is_separable = True             lower = l             upper = u              def __init__(self, thresh):                 mtransforms.Transform.__init__(self)                 self.thresh = thresh              def transform(self, a):                 aa = a.copy()                 aa[a>self.lower] = a[a>self.lower]+(self.upper-self.lower)                 return aa              def inverted(self):                 return CustomScale.CustomTransform(self.thresh)      return CustomScale  mscale.register_scale(CustomScaleFactory(1.12, 8.88))  x = np.concatenate((np.linspace(0,1,10), np.linspace(9,10,10))) xticks = np.concatenate((np.linspace(0,1,6), np.linspace(9,10,6))) y = np.sin(x) plt.plot(x, y, '.') ax = plt.gca() ax.set_xscale('custom') ax.set_xticks(xticks) plt.show()        ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/5656798/python-matplotlib-is-there-a-way-to-make-a-discontinuous-axis","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to create a plot using pyplot that has a discontinuous x-axis.  The usual way this is drawn is that the axis will have something like this:  (values)----//----(later values)  where the // indicates that you're skipping everything between (values) and (later values).  I haven't been able to find any examples of this, so I'm wondering if it's even possible.  I know you can join data over a discontinuity for, eg, financial data, but I'd like to make the jump in the axis more explicit.  At the moment I'm just using subplots but I'd really like to have everything end up on the same graph in the end.     ","Q_Votes":"63"},{"Q_Title":"Python/Matplotlib - Is there a way to make a discontinuous axis?","A_Content":"  Check the brokenaxes package:  import matplotlib.pyplot as plt from brokenaxes import brokenaxes import numpy as np  fig = plt.figure(figsize=(5,2)) bax = brokenaxes(xlims=((0, .1), (.4, .7)), ylims=((-1, .7), (.79, 1)), hspace=.05) x = np.linspace(0, 1, 100) bax.plot(x, np.sin(10 * x), label='sin') bax.plot(x, np.cos(10 * x), label='cos') bax.legend(loc=3) bax.set_xlabel('time') bax.set_ylabel('value')        ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/5656798/python-matplotlib-is-there-a-way-to-make-a-discontinuous-axis","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to create a plot using pyplot that has a discontinuous x-axis.  The usual way this is drawn is that the axis will have something like this:  (values)----//----(later values)  where the // indicates that you're skipping everything between (values) and (later values).  I haven't been able to find any examples of this, so I'm wondering if it's even possible.  I know you can join data over a discontinuity for, eg, financial data, but I'd like to make the jump in the axis more explicit.  At the moment I'm just using subplots but I'd really like to have everything end up on the same graph in the end.     ","Q_Votes":"63"},{"Q_Title":"Python/Matplotlib - Is there a way to make a discontinuous axis?","A_Content":"  Adressing Frederick Nord's question how to enable parallel orientation of the diagonal \"breaking\" lines when using a gridspec with ratios unequal 1:1, the following changes based on the proposals of Paul Ivanov and Joe Kingtons may be helpful. Width ratio can be varied using variables n and m.  import matplotlib.pylab as plt import numpy as np import matplotlib.gridspec as gridspec  x = np.r_[0:1:0.1, 9:10:0.1] y = np.sin(x)  n = 5; m = 1; gs = gridspec.GridSpec(1,2, width_ratios = [n,m])  plt.figure(figsize=(10,8))  ax = plt.subplot(gs[0,0]) ax2 = plt.subplot(gs[0,1], sharey = ax) plt.setp(ax2.get_yticklabels(), visible=False) plt.subplots_adjust(wspace = 0.1)  ax.plot(x, y, 'bo') ax2.plot(x, y, 'bo')  ax.set_xlim(0,1) ax2.set_xlim(10,8)  # hide the spines between ax and ax2 ax.spines['right'].set_visible(False) ax2.spines['left'].set_visible(False) ax.yaxis.tick_left() ax.tick_params(labeltop='off') # don't put tick labels at the top ax2.yaxis.tick_right()  d = .015 # how big to make the diagonal lines in axes coordinates # arguments to pass plot, just so we don't keep repeating them kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)  on = (n+m)/n; om = (n+m)/m; ax.plot((1-d*on,1+d*on),(-d,d), **kwargs) # bottom-left diagonal ax.plot((1-d*on,1+d*on),(1-d,1+d), **kwargs) # top-left diagonal kwargs.update(transform=ax2.transAxes) # switch to the bottom axes ax2.plot((-d*om,d*om),(-d,d), **kwargs) # bottom-right diagonal ax2.plot((-d*om,d*om),(1-d,1+d), **kwargs) # top-right diagonal  plt.show()      ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/5656798/python-matplotlib-is-there-a-way-to-make-a-discontinuous-axis","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to create a plot using pyplot that has a discontinuous x-axis.  The usual way this is drawn is that the axis will have something like this:  (values)----//----(later values)  where the // indicates that you're skipping everything between (values) and (later values).  I haven't been able to find any examples of this, so I'm wondering if it's even possible.  I know you can join data over a discontinuity for, eg, financial data, but I'd like to make the jump in the axis more explicit.  At the moment I'm just using subplots but I'd really like to have everything end up on the same graph in the end.     ","Q_Votes":"63"},{"Q_Title":"Is there an equivalent to CTRL+C in IPython Notebook in Firefox to break cells that are running?","A_Content":"  I could be wrong, but I'm pretty sure that the \"interrupt kernel\" button just sends a SIGINT signal to the code that you're currently running (this idea is supported by Fernando's comment here), which is the same thing that hitting CTRL+C would do. Some processes within python handle SIGINTs more abruptly than others.   If you desperately need to stop something that is running in iPython Notebook and you started iPython Notebook from a terminal, you can hit CTRL+C twice in that terminal to interrupt the entire iPython Notebook server. This will stop iPython Notebook alltogether, which means it won't be possible to restart or save your work, so this is obviously not a great solution (you need to hit CTRL+C twice because it's a safety feature so that people don't do it by accident). In case of emergency, however, it generally kills the process more quickly than the \"interrupt kernel\" button.     ","Language":"Python","Tags":["python","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/17561212/is-there-an-equivalent-to-ctrlc-in-ipython-notebook-in-firefox-to-break-cells-t","A_Votes":"41","_type":"dict","isAccepted":"Yes","Q_Content":"    I've started to use the IPython Notebook and am enjoying it. Sometimes, I write buggy code that takes massive memory requirements or has an infinite loop. I find the \"interrupt kernel\" option sluggish or unreliable, and sometimes I have to restart the kernel, losing everything in memory.  I also sometimes write scripts that cause OS X to run out of memory, and I have to do a hard reboot. I'm not 100% sure, but when I've written bugs like this before and ran Python in the terminal, I can usually CTRL+C my scripts.  I am using the Anaconda distribution of IPython notebook with Firefox on Mac OS X.      ","Q_Votes":"63"},{"Q_Title":"Is there an equivalent to CTRL+C in IPython Notebook in Firefox to break cells that are running?","A_Content":"  You can press I twice to interrupt the kernel.     ","Language":"Python","Tags":["python","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/17561212/is-there-an-equivalent-to-ctrlc-in-ipython-notebook-in-firefox-to-break-cells-t","A_Votes":"42","_type":"dict","isAccepted":"No","Q_Content":"    I've started to use the IPython Notebook and am enjoying it. Sometimes, I write buggy code that takes massive memory requirements or has an infinite loop. I find the \"interrupt kernel\" option sluggish or unreliable, and sometimes I have to restart the kernel, losing everything in memory.  I also sometimes write scripts that cause OS X to run out of memory, and I have to do a hard reboot. I'm not 100% sure, but when I've written bugs like this before and ran Python in the terminal, I can usually CTRL+C my scripts.  I am using the Anaconda distribution of IPython notebook with Firefox on Mac OS X.      ","Q_Votes":"63"},{"Q_Title":"Is there an equivalent to CTRL+C in IPython Notebook in Firefox to break cells that are running?","A_Content":"  While inside the jupyter press \"esc\" to enter escape mode. Then tap \"i\" two times to stop the script that is running.      ","Language":"Python","Tags":["python","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/17561212/is-there-an-equivalent-to-ctrlc-in-ipython-notebook-in-firefox-to-break-cells-t","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I've started to use the IPython Notebook and am enjoying it. Sometimes, I write buggy code that takes massive memory requirements or has an infinite loop. I find the \"interrupt kernel\" option sluggish or unreliable, and sometimes I have to restart the kernel, losing everything in memory.  I also sometimes write scripts that cause OS X to run out of memory, and I have to do a hard reboot. I'm not 100% sure, but when I've written bugs like this before and ran Python in the terminal, I can usually CTRL+C my scripts.  I am using the Anaconda distribution of IPython notebook with Firefox on Mac OS X.      ","Q_Votes":"63"},{"Q_Title":"Is there an equivalent to CTRL+C in IPython Notebook in Firefox to break cells that are running?","A_Content":"  To add to the above: If interrupt is not working, you can restart the kernel.   Go to the kernel dropdown >> restart >> restart and clear output. This usually does the trick. If this still doesn't work, kill the kernel in the terminal (or task manager) and then restart.  Interrupt doesn't work well for all processes. I especially have this problem using the R kernel.     ","Language":"Python","Tags":["python","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/17561212/is-there-an-equivalent-to-ctrlc-in-ipython-notebook-in-firefox-to-break-cells-t","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I've started to use the IPython Notebook and am enjoying it. Sometimes, I write buggy code that takes massive memory requirements or has an infinite loop. I find the \"interrupt kernel\" option sluggish or unreliable, and sometimes I have to restart the kernel, losing everything in memory.  I also sometimes write scripts that cause OS X to run out of memory, and I have to do a hard reboot. I'm not 100% sure, but when I've written bugs like this before and ran Python in the terminal, I can usually CTRL+C my scripts.  I am using the Anaconda distribution of IPython notebook with Firefox on Mac OS X.      ","Q_Votes":"63"},{"Q_Title":"Is there an equivalent to CTRL+C in IPython Notebook in Firefox to break cells that are running?","A_Content":"  Here are shortcuts for the IPython Notebook.   Ctrl-m i interrupts the kernel. (that is, the sole letter i after Ctrl-m)  According to this answer, I twice works as well.     ","Language":"Python","Tags":["python","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/17561212/is-there-an-equivalent-to-ctrlc-in-ipython-notebook-in-firefox-to-break-cells-t","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I've started to use the IPython Notebook and am enjoying it. Sometimes, I write buggy code that takes massive memory requirements or has an infinite loop. I find the \"interrupt kernel\" option sluggish or unreliable, and sometimes I have to restart the kernel, losing everything in memory.  I also sometimes write scripts that cause OS X to run out of memory, and I have to do a hard reboot. I'm not 100% sure, but when I've written bugs like this before and ran Python in the terminal, I can usually CTRL+C my scripts.  I am using the Anaconda distribution of IPython notebook with Firefox on Mac OS X.      ","Q_Votes":"63"},{"Q_Title":"Is there an equivalent to CTRL+C in IPython Notebook in Firefox to break cells that are running?","A_Content":"  A faster alternative will be to simply copy the localhost address, Ctrl C on cmd to stop the server, restart server then paste the address to a new tab.      ","Language":"Python","Tags":["python","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/17561212/is-there-an-equivalent-to-ctrlc-in-ipython-notebook-in-firefox-to-break-cells-t","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I've started to use the IPython Notebook and am enjoying it. Sometimes, I write buggy code that takes massive memory requirements or has an infinite loop. I find the \"interrupt kernel\" option sluggish or unreliable, and sometimes I have to restart the kernel, losing everything in memory.  I also sometimes write scripts that cause OS X to run out of memory, and I have to do a hard reboot. I'm not 100% sure, but when I've written bugs like this before and ran Python in the terminal, I can usually CTRL+C my scripts.  I am using the Anaconda distribution of IPython notebook with Firefox on Mac OS X.      ","Q_Votes":"63"},{"Q_Title":"redis-py : What's the difference between StrictRedis() and Redis()?","A_Content":"  This seems pretty clear:   redis-py exposes two client classes that implement these commands  The StrictRedis class attempts to adhere to the official command syntax.   and  In addition to the changes above, the Redis class, a subclass of StrictRedis, overrides several other commands to provide backwards compatibility with older versions of redis-py   Do you need backwards compatibility? Use Redis. Don't care? Use StrictRedis.    2017-03-31  Here are the specifics of the backwards compatibility, from the github.com link cited:     In addition to the changes above, the Redis class, a subclass of StrictRedis, overrides several other commands to provide backwards compatibility with older versions of redis-py:      LREM: Order of 'num' and 'value' arguments reversed such that 'num' can provide a default value of zero.      ZADD: Redis specifies the 'score' argument before 'value'. These were swapped accidentally when being implemented and not discovered until after people were already using it. The Redis class expects *args in the form of: name1, score1, name2, score2, ...      SETEX: Order of 'time' and 'value' arguments reversed.        ","Language":"Python","Tags":["python","redis"],"URL":"https://stackoverflow.com/questions/19021765/redis-py-whats-the-difference-between-strictredis-and-redis","A_Votes":"100","_type":"dict","isAccepted":"Yes","Q_Content":"    I want using redis-py for caching some data. I can't find a suitable explain about difference between redis.StrictRedis() and redis.Redis() ! Is the Redis() equivalent to StrictRedis() ?  In addition, i can't find any clear documentation about redis.StrictRedis() arguments in Redis Python Docs Any idea?     ","Q_Votes":"63"},{"Q_Title":"Send log messages from all celery tasks to a single file","A_Content":"  Note: This answer is outdated as of Celery 3.0, where you now use get_task_logger() to get your per-task logger set up. Please see the Logging section of the What's new in Celery 3.0 document for details.    Celery has dedicated support for logging, per task. See the Task documentation on the subject:     You can use the workers logger to add diagnostic output to the worker log:      @celery.task() def add(x, y):     logger = add.get_logger()     logger.info(\"Adding %s + %s\" % (x, y))     return x + y       There are several logging levels available, and the workers loglevel setting decides    whether or not they will be written to the log file.      Of course, you can also simply use print as anything written to standard out/-err will be    written to the log file as well.   Under the hood this is all still the standard python logging module. You can set the CELERYD_HIJACK_ROOT_LOGGER option to False to allow your own logging setup to work, otherwise Celery will configure the handling for you.  However, for tasks, the .get_logger() call does allow you to set up a separate log file per individual task. Simply pass in a logfile argument and it'll route log messages to that separate file:  @celery.task() def add(x, y):     logger = add.get_logger(logfile='tasks.log')     logger.info(\"Adding %s + %s\" % (x, y))     return x + y    Last but not least, you can just configure your top-level package in the python logging module and give it a file handler of it's own. I'd set this up using the celery.signals.after_setup_task_logger signal; here I assume all your modules live in a package called foo.tasks (as in foo.tasks.email and foo.tasks.scaling):  from celery.signals import after_setup_task_logger import logging  def foo_tasks_setup_logging(**kw):     logger = logging.getLogger('foo.tasks')     if not logger.handlers:         handler = logging.FileHandler('tasks.log')         formatter = logging.Formatter(logging.BASIC_FORMAT) # you may want to customize this.         handler.setFormatter(formatter)         logger.addHandler(handler)         logger.propagate = False  after_setup_task_logger.connect(foo_tasks_setup_logging)   Now any logger whose name starts with foo.tasks will have all it's messages sent to tasks.log instead of to the root logger (which doesn't see any of these messages because .propagate is False).     ","Language":"Python","Tags":["python","logging","celery"],"URL":"https://stackoverflow.com/questions/6192265/send-log-messages-from-all-celery-tasks-to-a-single-file","A_Votes":"96","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm wondering how to setup a more specific logging system. All my tasks use  logger = logging.getLogger(__name__)   as a module-wide logger.  I want celery to log to \"celeryd.log\" and my tasks to \"tasks.log\" but I got no idea how to get this working. Using CELERYD_LOG_FILE from django-celery I can route all celeryd related log messages to celeryd.log but there is no trace of the log messages created in my tasks.     ","Q_Votes":"63"},{"Q_Title":"Send log messages from all celery tasks to a single file","A_Content":"  Just a hint: Celery has its own logging handler:  from celery.utils.log import get_task_logger logger = get_task_logger(__name__)   Also, Celery logs all output from the task. More details at Celery docs for Task Logging     ","Language":"Python","Tags":["python","logging","celery"],"URL":"https://stackoverflow.com/questions/6192265/send-log-messages-from-all-celery-tasks-to-a-single-file","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm wondering how to setup a more specific logging system. All my tasks use  logger = logging.getLogger(__name__)   as a module-wide logger.  I want celery to log to \"celeryd.log\" and my tasks to \"tasks.log\" but I got no idea how to get this working. Using CELERYD_LOG_FILE from django-celery I can route all celeryd related log messages to celeryd.log but there is no trace of the log messages created in my tasks.     ","Q_Votes":"63"},{"Q_Title":"matplotlib get ylim values","A_Content":"  Just use axes.get_ylim(), it is very similar to set_ylim. From the docs:     get_ylim()      Get the y-axis range [bottom, top]      ","Language":"Python","Tags":["python","matplotlib","plot"],"URL":"https://stackoverflow.com/questions/26131607/matplotlib-get-ylim-values","A_Votes":"82","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm using matplotlib to plot data (using plot and errorbar functions) from Python.  I have to plot a set of totally separate and independent plots, and then adjust they're ylim values so they can be easily visually compared.  How can I retrieve the ylim values from each plot, so that I can take the min and max of the lower and upper ylim values, respectively, and adjust the plots so they can be visually compared?  Of course, I could just analyze the data and come up with my own custom ylim values... but I'd like to use matplotlib to do that for me.  Any suggestions on how to easily (and efficiently) do this?  Here's my Python function that plots using matplotlib:  import matplotlib.pyplot as plt  def myplotfunction(title, values, errors, plot_file_name):      # plot errorbars     indices = range(0, len(values))     fig = plt.figure()     plt.errorbar(tuple(indices), tuple(values), tuple(errors), marker='.')      # axes     axes = plt.gca()     axes.set_xlim([-0.5, len(values) - 0.5])     axes.set_xlabel('My x-axis title')     axes.set_ylabel('My y-axis title')      # title     plt.title(title)      # save as file     plt.savefig(plot_file_name)      # close figure     plt.close(fig)      ","Q_Votes":"63"},{"Q_Title":"matplotlib get ylim values","A_Content":"   ymin, ymax = axes.get_ylim()   If you are using the plt structure, why even bother with the axes?  This should work:  def myplotfunction(title, values, errors, plot_file_name):      # plot errorbars     indices = range(0, len(values))     fig = plt.figure()     plt.errorbar(tuple(indices), tuple(values), tuple(errors), marker='.')      plt.xlim([-0.5, len(values) - 0.5])     plt.xlabel('My x-axis title')     plt.ylabel('My y-axis title')      # title     plt.title(title)      # save as file     plt.savefig(plot_file_name)     # close figure     plt.close(fig)   Or is this not the case?     ","Language":"Python","Tags":["python","matplotlib","plot"],"URL":"https://stackoverflow.com/questions/26131607/matplotlib-get-ylim-values","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I'm using matplotlib to plot data (using plot and errorbar functions) from Python.  I have to plot a set of totally separate and independent plots, and then adjust they're ylim values so they can be easily visually compared.  How can I retrieve the ylim values from each plot, so that I can take the min and max of the lower and upper ylim values, respectively, and adjust the plots so they can be visually compared?  Of course, I could just analyze the data and come up with my own custom ylim values... but I'd like to use matplotlib to do that for me.  Any suggestions on how to easily (and efficiently) do this?  Here's my Python function that plots using matplotlib:  import matplotlib.pyplot as plt  def myplotfunction(title, values, errors, plot_file_name):      # plot errorbars     indices = range(0, len(values))     fig = plt.figure()     plt.errorbar(tuple(indices), tuple(values), tuple(errors), marker='.')      # axes     axes = plt.gca()     axes.set_xlim([-0.5, len(values) - 0.5])     axes.set_xlabel('My x-axis title')     axes.set_ylabel('My y-axis title')      # title     plt.title(title)      # save as file     plt.savefig(plot_file_name)      # close figure     plt.close(fig)      ","Q_Votes":"63"},{"Q_Title":"Running bash script from within python","A_Content":"  Making sleep.sh executable and adding shell=True to the parameter list (as suggested in previous answers) works ok. Depending on the search path, you may also need to add ./ or some other appropriate path.  (Ie, change \"sleep.sh\" to \"./sleep.sh\".)  The shell=True parameter is not needed (under a Posix system like Linux) if the first line of the bash script is a path to a shell; for example, #!/bin/bash.     ","Language":"Python","Tags":["python","bash","call"],"URL":"https://stackoverflow.com/questions/13745648/running-bash-script-from-within-python","A_Votes":"55","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a problem with the following code:  callBash.py:  import subprocess print \"start\" subprocess.call(\"sleep.sh\") print \"end\"   sleep.sh:  sleep 10   I want the \"end\" to be printed after 10s. (I know that this is a dumb example, I could simply sleep within python, but this simple sleep.sh file was just as a test)     ","Q_Votes":"63"},{"Q_Title":"Running bash script from within python","A_Content":"  Actually, you just have to add the shell=True argument:  subprocess.call(\"sleep.sh\", shell=True)   But beware -      Warning Invoking the system shell with shell=True can be a security hazard if combined with untrusted input. See the warning under Frequently Used Arguments for details.   source     ","Language":"Python","Tags":["python","bash","call"],"URL":"https://stackoverflow.com/questions/13745648/running-bash-script-from-within-python","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I have a problem with the following code:  callBash.py:  import subprocess print \"start\" subprocess.call(\"sleep.sh\") print \"end\"   sleep.sh:  sleep 10   I want the \"end\" to be printed after 10s. (I know that this is a dumb example, I could simply sleep within python, but this simple sleep.sh file was just as a test)     ","Q_Votes":"63"},{"Q_Title":"Running bash script from within python","A_Content":"  If sleep.sh has the shebang #!/bin/sh and it has appropriate file permissions  -- run chmod u+rx sleep.sh to make sure and it is in $PATH then your code should work as is:  import subprocess  rc = subprocess.call(\"sleep.sh\")   If the script is not in the PATH then specify the full path to it e.g., if it is in the current working directory:  from subprocess import call  rc = call(\"./sleep.sh\")   If the script has no shebang then you need to specify shell=True:  rc = call(\"./sleep.sh\", shell=True)   If the script has no executable permissions and you can't change it e.g., by running os.chmod('sleep.sh', 0o755) then you could read the script as a text file and pass the string to subprocess module instead:  with open('sleep.sh', 'rb') as file:     script = file.read() rc = call(script, shell=True)      ","Language":"Python","Tags":["python","bash","call"],"URL":"https://stackoverflow.com/questions/13745648/running-bash-script-from-within-python","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I have a problem with the following code:  callBash.py:  import subprocess print \"start\" subprocess.call(\"sleep.sh\") print \"end\"   sleep.sh:  sleep 10   I want the \"end\" to be printed after 10s. (I know that this is a dumb example, I could simply sleep within python, but this simple sleep.sh file was just as a test)     ","Q_Votes":"63"},{"Q_Title":"Running bash script from within python","A_Content":"  Make sure that sleep.sh has execution permissions, and run it with shell=True:  #!/usr/bin/python  import subprocess print \"start\" subprocess.call(\"./sleep.sh\", shell=True) print \"end\"      ","Language":"Python","Tags":["python","bash","call"],"URL":"https://stackoverflow.com/questions/13745648/running-bash-script-from-within-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have a problem with the following code:  callBash.py:  import subprocess print \"start\" subprocess.call(\"sleep.sh\") print \"end\"   sleep.sh:  sleep 10   I want the \"end\" to be printed after 10s. (I know that this is a dumb example, I could simply sleep within python, but this simple sleep.sh file was just as a test)     ","Q_Votes":"63"},{"Q_Title":"Running bash script from within python","A_Content":"  If someone looking for calling a script with arguments   import subprocess  val = subprocess.check_call(\"./script.sh '%s'\" % arg,   shell=True)   remember to convert the args to string before passing, using str(arg).  This can be used to pass as many arguments as required   subprocess.check_call(\"./script.ksh %s %s %s\" % (agr1, str(arg2), arg3),   shell=True)      ","Language":"Python","Tags":["python","bash","call"],"URL":"https://stackoverflow.com/questions/13745648/running-bash-script-from-within-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a problem with the following code:  callBash.py:  import subprocess print \"start\" subprocess.call(\"sleep.sh\") print \"end\"   sleep.sh:  sleep 10   I want the \"end\" to be printed after 10s. (I know that this is a dumb example, I could simply sleep within python, but this simple sleep.sh file was just as a test)     ","Q_Votes":"63"},{"Q_Title":"Running bash script from within python","A_Content":"  Adding an answer because I was directed here after asking how to run a bash script from python. You receive an error OSError: [Errno 2] file not found if your script takes in parameters. Lets say for instance your script took in a sleep time parameter: subprocess.call(\"sleep.sh 10\") will not work, you must pass it as an array: subprocess.call([\"sleep.sh\", 10])     ","Language":"Python","Tags":["python","bash","call"],"URL":"https://stackoverflow.com/questions/13745648/running-bash-script-from-within-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a problem with the following code:  callBash.py:  import subprocess print \"start\" subprocess.call(\"sleep.sh\") print \"end\"   sleep.sh:  sleep 10   I want the \"end\" to be printed after 10s. (I know that this is a dumb example, I could simply sleep within python, but this simple sleep.sh file was just as a test)     ","Q_Votes":"63"},{"Q_Title":"Running bash script from within python","A_Content":"  If chmod not working then you also try  import os os.system('sh script.sh') #you can also use bash instead of sh   test by me thanks      ","Language":"Python","Tags":["python","bash","call"],"URL":"https://stackoverflow.com/questions/13745648/running-bash-script-from-within-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a problem with the following code:  callBash.py:  import subprocess print \"start\" subprocess.call(\"sleep.sh\") print \"end\"   sleep.sh:  sleep 10   I want the \"end\" to be printed after 10s. (I know that this is a dumb example, I could simply sleep within python, but this simple sleep.sh file was just as a test)     ","Q_Votes":"63"},{"Q_Title":"How view() method works for tensor in torch","A_Content":"  The view function is meant to reshape the tensor.   Say you have a tensor  import torch a = torch.range(1, 16)   a is a tensor that has 16 elements from 1 to 16(included). If you want to reshape this tensor to make it a 4 x 4 tensor then you can use   a = a.view(4, 4)   Now a will be a 4 x 4 tensor.(Note that after the reshape the total number of elements need to remain the same. Reshaping the tensor a to a 3 x 5 tensor would not be appropriate)  What is the meaning of parameter -1?  If there is any situation that you don't know how many rows you want but are sure of the number of columns then you can mention it as -1(You can extend this to tensors with more dimensions. Only one of the axis value can be -1). This is a way of telling the library; give me a tensor that has these many columns and you compute the appropriate number of rows that is necessary to make this happen.  This can be seen in the neural network code that you have given above. After the line x = self.pool(F.relu(self.conv2(x))) in the forward function, you will have a 16 depth feature map. You have to flatten this to give it to the fully connected layer. So you tell pytorch to reshape the tensor you obtained to have specific number of columns and tell it to decide the number of rows by itself.  Drawing a similarity between numpy and pytorch, view is similar to numpy's reshape function.      ","Language":"Python","Tags":["python","torch","pytorch"],"URL":"https://stackoverflow.com/questions/42479902/how-view-method-works-for-tensor-in-torch","A_Votes":"97","_type":"dict","isAccepted":"Yes","Q_Content":"    I have confusion about the method view() in the following code snippet.  class Net(nn.Module):     def __init__(self):         super(Net, self).__init__()         self.conv1 = nn.Conv2d(3, 6, 5)         self.pool  = nn.MaxPool2d(2,2)         self.conv2 = nn.Conv2d(6, 16, 5)         self.fc1   = nn.Linear(16*5*5, 120)         self.fc2   = nn.Linear(120, 84)         self.fc3   = nn.Linear(84, 10)      def forward(self, x):         x = self.pool(F.relu(self.conv1(x)))         x = self.pool(F.relu(self.conv2(x)))         x = x.view(-1, 16*5*5)         x = F.relu(self.fc1(x))         x = F.relu(self.fc2(x))         x = self.fc3(x)         return x  net = Net()   My confusion is regarding the following line.  x = x.view(-1, 16*5*5)   What does tensor.view() function do? I have seen its usage in many places but I can't understand how it interprets its' parameters.   What happens if I give negative values as parameters to the view() function? For example, what happens if I call, tensor_variable.view(1, 1, -1)?  Can anyone explain the main principle of view() function with some examples?     ","Q_Votes":"63"},{"Q_Title":"How view() method works for tensor in torch","A_Content":"  Let's do some examples, from simpler to more difficult.   The view method returns a tensor with the same data as the self tensor (which means that the returned tensor has the same number of elements), but with a different shape.  For example:  a = torch.arange(1, 17)  # a's shape is (16,)  a.view(4, 4) # output below   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16 [torch.FloatTensor of size 4x4]  a.view(2, 2, 4) # output below (0 ,.,.) =  1   2   3   4 5   6   7   8  (1 ,.,.) =   9  10  11  12 13  14  15  16 [torch.FloatTensor of size 2x2x4]  Assuming that -1 is not one of the parameters, when you multiply them together, the result must be equal to the number of elements in the tensor.  If you do: a.view(3, 3), it will raise a RuntimeError because shape (3 x 3) is invalid for input with 16 elements. In other words: 3 x 3 does not equal 16 but 9. You can use -1 as one of the parameters that you pass to the function, but only once. All that happens is that the method will do the math for you on how to fill that dimension.  For example a.view(2, -1, 4) is equivalent to a.view(2, 2, 4). [16 / (2 x 4) = 2] Notice that the returned tensor shares the same data. If you make a change in the \"view\" you are changing the original tensor's data:  b = a.view(4, 4) b[0, 2] = 2 a[2] == 3.0 False  Now, for a more complex use case.  The documentation says that each new view dimension must either be a subspace of an original dimension, or only span d, d + 1, ..., d + k that satisfy the following contiguity-like condition that for all i = 0, ..., k - 1, stride[i] = stride[i + 1] x size[i + 1]. Otherwise, contiguous() needs to be called before the tensor can be viewed.  For example:  a = torch.rand(5, 4, 3, 2) # size (5, 4, 3, 2) a_t = a.permute(0, 2, 3, 1) # size (5, 3, 2, 4)  # The commented line below will raise a RuntimeError, because one dimension # spans across two contiguous subspaces # a_t.view(-1, 4)  # instead do: a_t.contiguous().view(-1, 4)  # To see why the first one does not work and the second does, # compare a.stride() and a_t.stride() a.stride() # (24, 6, 2, 1) a_t.stride() # (24, 2, 1, 6)   Notice that for a_t, stride[0] != stride[1] x size[1] since 24 != 2 x 3      ","Language":"Python","Tags":["python","torch","pytorch"],"URL":"https://stackoverflow.com/questions/42479902/how-view-method-works-for-tensor-in-torch","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I have confusion about the method view() in the following code snippet.  class Net(nn.Module):     def __init__(self):         super(Net, self).__init__()         self.conv1 = nn.Conv2d(3, 6, 5)         self.pool  = nn.MaxPool2d(2,2)         self.conv2 = nn.Conv2d(6, 16, 5)         self.fc1   = nn.Linear(16*5*5, 120)         self.fc2   = nn.Linear(120, 84)         self.fc3   = nn.Linear(84, 10)      def forward(self, x):         x = self.pool(F.relu(self.conv1(x)))         x = self.pool(F.relu(self.conv2(x)))         x = x.view(-1, 16*5*5)         x = F.relu(self.fc1(x))         x = F.relu(self.fc2(x))         x = self.fc3(x)         return x  net = Net()   My confusion is regarding the following line.  x = x.view(-1, 16*5*5)   What does tensor.view() function do? I have seen its usage in many places but I can't understand how it interprets its' parameters.   What happens if I give negative values as parameters to the view() function? For example, what happens if I call, tensor_variable.view(1, 1, -1)?  Can anyone explain the main principle of view() function with some examples?     ","Q_Votes":"63"},{"Q_Title":"Howto get all methods of a python class with given decorator","A_Content":"  Method 1: Basic registering decorator  I already answered this question here: Calling functions by array index in Python =)    Method 2: Sourcecode parsing  If you do not have control over the class definition, which is one interpretation of what you'd like to suppose, this is impossible (without code-reading-reflection), since for example the decorator could be a no-op decorator (like in my linked example) that merely returns the function unmodified. (Nevertheless if you allow yourself to wrap/redefine the decorators, see Method 3: Converting decorators to be \"self-aware\", then you will find an elegant solution)  It is a terrible terrible hack, but you could use the inspect module to read the sourcecode itself, and parse it. This will not work in an interactive interpreter, because the inspect module will refuse to give sourcecode in interactive mode. However, below is a proof of concept.  #!/usr/bin/python3  import inspect  def deco(func):     return func  def deco2():     def wrapper(func):         pass     return wrapper  class Test(object):     @deco     def method(self):         pass      @deco2()     def method2(self):         pass  def methodsWithDecorator(cls, decoratorName):     sourcelines = inspect.getsourcelines(cls)[0]     for i,line in enumerate(sourcelines):         line = line.strip()         if line.split('(')[0].strip() == '@'+decoratorName: # leaving a bit out             nextLine = sourcelines[i+1]             name = nextLine.split('def')[1].split('(')[0].strip()             yield(name)   It works!:  >>> print(list(  methodsWithDecorator(Test, 'deco')  )) ['method']   Note that one has to pay attention to parsing and the python syntax, e.g. @deco and @deco(... are valid results, but @deco2 should not be returned if we merely ask for 'deco'. We notice that according to the official python syntax at http://docs.python.org/reference/compound_stmts.html decorators are as follows:  decorator      ::=  \"@\" dotted_name [\"(\" [argument_list [\",\"]] \")\"] NEWLINE   We breathe a sigh of relief at not having to deal with cases like @(deco). But note that this still doesn't really help you if you have really really complicated decorators, such as @getDecorator(...), e.g.  def getDecorator():     return deco   Thus, this best-that-you-can-do strategy of parsing code cannot detect cases like this. Though if you are using this method, what you're really after is what is written on top of the method in the definition, which in this case is getDecorator.  According to the spec, it is also valid to have @foo1.bar2.baz3(...) as a decorator. You can extend this method to work with that. You might also be able to extend this method to return a <function object ...> rather than the function's name, with lots of effort. This method however is hackish and terrible.    Method 3: Converting decorators to be \"self-aware\"  If you do not have control over the decorator definition (which is another interpretation of what you'd like), then all these issues go away because you have control over how the decorator is applied. Thus, you can modify the decorator by wrapping it, to create your own decorator, and use that to decorate your functions. Let me say that yet again: you can make a decorator that decorates the decorator you have no control over, \"enlightening\" it, which in our case makes it do what it was doing before but also append a .decorator metadata property to the callable it returns, allowing you to keep track of \"was this function decorated or not? let's check function.decorator!\". And then you can iterate over the methods of the class, and just check to see if the decorator has the appropriate .decorator property! =) As demonstrated here:  def makeRegisteringDecorator(foreignDecorator):     \"\"\"         Returns a copy of foreignDecorator, which is identical in every         way(*), except also appends a .decorator property to the callable it         spits out.     \"\"\"     def newDecorator(func):         # Call to newDecorator(method)         # Exactly like old decorator, but output keeps track of what decorated it         R = foreignDecorator(func) # apply foreignDecorator, like call to foreignDecorator(method) would have done         R.decorator = newDecorator # keep track of decorator         #R.original = func         # might as well keep track of everything!         return R      newDecorator.__name__ = foreignDecorator.__name__     newDecorator.__doc__ = foreignDecorator.__doc__     # (*)We can be somewhat \"hygienic\", but newDecorator still isn't signature-preserving, i.e. you will not be able to get a runtime list of parameters. For that, you need hackish libraries...but in this case, the only argument is func, so it's not a big issue      return newDecorator   Demonstration for @decorator:  deco = makeRegisteringDecorator(deco)  class Test2(object):     @deco     def method(self):         pass      @deco2()     def method2(self):         pass  def methodsWithDecorator(cls, decorator):     \"\"\"          Returns all methods in CLS with DECORATOR as the         outermost decorator.          DECORATOR must be a \"registering decorator\"; one         can make any decorator \"registering\" via the         makeRegisteringDecorator function.     \"\"\"     for maybeDecorated in cls.__dict__.values():         if hasattr(maybeDecorated, 'decorator'):             if maybeDecorated.decorator == decorator:                 print(maybeDecorated)                 yield maybeDecorated   It works!:  >>> print(list(   methodsWithDecorator(Test2, deco)   )) [<function method at 0x7d62f8>]   However, a \"registered decorator\" must be the outermost decorator, otherwise the .decorator attribute annotation will be lost. For example in a train of  @decoOutermost @deco @decoInnermost def func(): ...   you can only see metadata that decoOutermost exposes, unless we keep references to \"more-inner\" wrappers.  sidenote: the above method can also build up a .decorator that keeps track of the entire stack of applied decorators and input functions and decorator-factory arguments. =) For example if you consider the commented-out line R.original = func, it is feasible to use a method like this to keep track of all wrapper layers. This is personally what I'd do if I wrote a decorator library, because it allows for deep introspection.  There is also a difference between @foo and @bar(...). While they are both \"decorator expressons\" as defined in the spec, note that foo is a decorator, while bar(...) returns a dynamically-created decorator, which is then applied. Thus you'd need a separate function makeRegisteringDecoratorFactory, that is somewhat like makeRegisteringDecorator but even MORE META:  def makeRegisteringDecoratorFactory(foreignDecoratorFactory):     def newDecoratorFactory(*args, **kw):         oldGeneratedDecorator = foreignDecoratorFactory(*args, **kw)         def newGeneratedDecorator(func):             modifiedFunc = oldGeneratedDecorator(func)             modifiedFunc.decorator = newDecoratorFactory # keep track of decorator             return modifiedFunc         return newGeneratedDecorator     newDecoratorFactory.__name__ = foreignDecoratorFactory.__name__     newDecoratorFactory.__doc__ = foreignDecoratorFactory.__doc__     return newDecoratorFactory   Demonstration for @decorator(...):  def deco2():     def simpleDeco(func):         return func     return simpleDeco  deco2 = makeRegisteringDecoratorFactory(deco2)  print(deco2.__name__) # RESULT: 'deco2'  @deco2() def f():     pass   This generator-factory wrapper also works:  >>> print(f.decorator) <function deco2 at 0x6a6408>   bonus Let's even try the following with Method #3:  def getDecorator(): # let's do some dispatching!     return deco  class Test3(object):     @getDecorator()     def method(self):         pass      @deco2()     def method2(self):         pass   Result:  >>> print(list(   methodsWithDecorator(Test3, deco)   )) [<function method at 0x7d62f8>]   As you can see, unlike method2, @deco is correctly recognized even though it was never explicitly written in the class. Unlike method2, this will also work if the method is added at runtime (manually, via a metaclass, etc.) or inherited.  Be aware that you can also decorate a class, so if you \"enlighten\" a decorator that is used to both decorate methods and classes, and then write a class within the body of the class you want to analyze, then methodsWithDecorator will return decorated classes as well as decorated methods. One could consider this a feature, but you can easily write logic to ignore those by examining the argument to the decorator, i.e. .original, to achieve the desired semantics.     ","Language":"Python","Tags":["python","class","methods","decorator","inspect"],"URL":"https://stackoverflow.com/questions/5910703/howto-get-all-methods-of-a-python-class-with-given-decorator","A_Votes":"94","_type":"dict","isAccepted":"Yes","Q_Content":"    How to get all methods of a given class A that are decorated with the @decorator2?  class A():     def method_a(self):       pass      @decorator1     def method_b(self, b):       pass      @decorator2     def method_c(self, t=5):       pass      ","Q_Votes":"63"},{"Q_Title":"Howto get all methods of a python class with given decorator","A_Content":"  To expand upon @ninjagecko's excellent answer in Method 2: Source code parsing, you can use the ast module introduced in Python 2.6 to perform self-inspection as long as the inspect module has access to the source code.  def findDecorators(target):     import ast, inspect     res = {}     def visit_FunctionDef(node):         res[node.name] = [ast.dump(e) for e in node.decorator_list]      V = ast.NodeVisitor()     V.visit_FunctionDef = visit_FunctionDef     V.visit(compile(inspect.getsource(target), '?', 'exec', ast.PyCF_ONLY_AST))     return res   I added a slightly more complicated decorated method:  @x.y.decorator2 def method_d(self, t=5): pass   Results:  > findDecorators(A) {'method_a': [],  'method_b': [\"Name(id='decorator1', ctx=Load())\"],  'method_c': [\"Name(id='decorator2', ctx=Load())\"],  'method_d': [\"Attribute(value=Attribute(value=Name(id='x', ctx=Load()), attr='y', ctx=Load()), attr='decorator2', ctx=Load())\"]}      ","Language":"Python","Tags":["python","class","methods","decorator","inspect"],"URL":"https://stackoverflow.com/questions/5910703/howto-get-all-methods-of-a-python-class-with-given-decorator","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    How to get all methods of a given class A that are decorated with the @decorator2?  class A():     def method_a(self):       pass      @decorator1     def method_b(self, b):       pass      @decorator2     def method_c(self, t=5):       pass      ","Q_Votes":"63"},{"Q_Title":"Howto get all methods of a python class with given decorator","A_Content":"  Maybe, if the decorators are not too complex (but I don't know if there is a less hacky way).  def decorator1(f):     def new_f():         print \"Entering decorator1\", f.__name__         f()     new_f.__name__ = f.__name__     return new_f  def decorator2(f):     def new_f():         print \"Entering decorator2\", f.__name__         f()     new_f.__name__ = f.__name__     return new_f   class A():     def method_a(self):       pass      @decorator1     def method_b(self, b):       pass      @decorator2     def method_c(self, t=5):       pass  print A.method_a.im_func.func_code.co_firstlineno print A.method_b.im_func.func_code.co_firstlineno print A.method_c.im_func.func_code.co_firstlineno      ","Language":"Python","Tags":["python","class","methods","decorator","inspect"],"URL":"https://stackoverflow.com/questions/5910703/howto-get-all-methods-of-a-python-class-with-given-decorator","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How to get all methods of a given class A that are decorated with the @decorator2?  class A():     def method_a(self):       pass      @decorator1     def method_b(self, b):       pass      @decorator2     def method_c(self, t=5):       pass      ","Q_Votes":"63"},{"Q_Title":"What is the purpose of the colon before a block in Python?","A_Content":"  The colon is there to declare the start of an indented block.  Technically, it's not necessary; you could just indent and de-indent when the block is done. However, based on the Python koan “explicit is better than implicit” (EIBTI), I believe that Guido deliberately made the colon obligatory, so any statement that should be followed by indented code ends in a colon. (It also allows one-liners if you continue after the colon, but this style is not in wide use.)  It also makes the work of syntax-aware auto-indenting editors easier, which also counted in the decision.    This question turns out to be a Python FAQ, and I found one of its answers by Guido here:     Why are colons required for the if/while/def/class statements?      The colon is required primarily to enhance readability (one of the results of the experimental ABC language). Consider this:  if a == b      print a       versus   if a == b:      print a       Notice how the second one is slightly easier to read. Notice further how a colon sets off the example in this FAQ answer; it’s a standard usage in English.      Another minor reason is that the colon makes it easier for editors with syntax highlighting; they can look for colons to decide when indentation needs to be increased instead of having to do a more elaborate parsing of the program text.      ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/215581/what-is-the-purpose-of-the-colon-before-a-block-in-python","A_Votes":"69","_type":"dict","isAccepted":"Yes","Q_Content":"    What is the purpose of the colon before a block in Python?  Example:  if n == 0:     print \"The end\"      ","Q_Votes":"63"},{"Q_Title":"What is the purpose of the colon before a block in Python?","A_Content":"  Consider the following list of things to buy from the grocery store, written in Pewprikanese.  pewkah lalala     chunkykachoo     pewpewpew skunkybacon   When I read that, I'm confused, Are chunkykachoo and pewpewpew a kind of lalala? Or what if chunkykachoo and pewpewpew are indented just because they are special items?  Now see what happens when my Pewprikanese friend add a colon to help me parse the list better: (<-- like this)  pewkah lalala:   (<-- see this colon)     chunkykachoo     pewpewpew skunkybacon   Now it's clear that chunkykachoo and pewpewpew are a kind of lalala.  Let's say there is a person who's starting to learn Python, which happens to be her first programming language to learn. Without colons, there's a considerable probability that she's going to keep thinking \"this lines are indented because this lines are like special items.\", and it could take a while to realize that that's not the best way to think about indentation.     ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/215581/what-is-the-purpose-of-the-colon-before-a-block-in-python","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    What is the purpose of the colon before a block in Python?  Example:  if n == 0:     print \"The end\"      ","Q_Votes":"63"},{"Q_Title":"What is the purpose of the colon before a block in Python?","A_Content":"  Three reasons:   To increase readability. The colon helps the code flow into the following indented block. To help text editors/IDEs, they can automatically indent the next line if the previous line ended with a colon. To make parsing by python slightly easier.      ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/215581/what-is-the-purpose-of-the-colon-before-a-block-in-python","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    What is the purpose of the colon before a block in Python?  Example:  if n == 0:     print \"The end\"      ","Q_Votes":"63"},{"Q_Title":"What is the purpose of the colon before a block in Python?","A_Content":"  As far as I know, it's an intentional design to make it more obvious, that the reader should expect an indentation after the colon.  It also makes constructs like this possible:  if expression: action() code_continues()   Note (as a commenter did) that this is not exactly the shining gold standard of good Python style. It would be far better to have a blank, there:  if expression: action()  code_continues()   to avoid confusion. I just wanted to make it clear, with the first example, that it's possible to write like that, since having the code for the if immediately following the colon makes it possible for the compiler to understand that the next line should not be indented.     ","Language":"Python","Tags":["python","syntax"],"URL":"https://stackoverflow.com/questions/215581/what-is-the-purpose-of-the-colon-before-a-block-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    What is the purpose of the colon before a block in Python?  Example:  if n == 0:     print \"The end\"      ","Q_Votes":"63"},{"Q_Title":"Are locks unnecessary in multi-threaded Python code because of the GIL?","A_Content":"  You will still need locks if you share state between threads. The GIL only protects the interpreter internally. You can still have inconsistent updates in your own code.  For example:  #!/usr/bin/env python import threading  shared_balance = 0  class Deposit(threading.Thread):     def run(self):         for _ in xrange(1000000):             global shared_balance             balance = shared_balance             balance += 100             shared_balance = balance  class Withdraw(threading.Thread):     def run(self):         for _ in xrange(1000000):             global shared_balance             balance = shared_balance             balance -= 100             shared_balance = balance  threads = [Deposit(), Withdraw()]  for thread in threads:     thread.start()  for thread in threads:     thread.join()  print shared_balance   Here, your code can be interrupted between reading the shared state (balance = shared_balance) and writing the changed result back (shared_balance = balance), causing a lost update. The result is a random value for the shared state.  To make the updates consistent, run methods would need to lock the shared state around the read-modify-write sections (inside the loops) or have some way to detect when the shared state had changed since it was read.     ","Language":"Python","Tags":["python","multithreading","locking"],"URL":"https://stackoverflow.com/questions/105095/are-locks-unnecessary-in-multi-threaded-python-code-because-of-the-gil","A_Votes":"63","_type":"dict","isAccepted":"Yes","Q_Content":"    If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?  If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?  sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.    same thing would apply to any other language implementation that has a GIL.     ","Q_Votes":"63"},{"Q_Title":"Are locks unnecessary in multi-threaded Python code because of the GIL?","A_Content":"  No - the GIL just protects python internals from multiple threads altering their state.  This is a very low-level of locking, sufficient only to keep python's own structures in a consistent state.  It doesn't cover the application level locking you'll need to do to cover thread safety in your own code.  The essence of locking is to ensure that a particular block of code is only executed by one thread.  The GIL enforces this for blocks the size of a single bytecode, but usually you want the lock to span a larger block of code than this.     ","Language":"Python","Tags":["python","multithreading","locking"],"URL":"https://stackoverflow.com/questions/105095/are-locks-unnecessary-in-multi-threaded-python-code-because-of-the-gil","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?  If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?  sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.    same thing would apply to any other language implementation that has a GIL.     ","Q_Votes":"63"},{"Q_Title":"Are locks unnecessary in multi-threaded Python code because of the GIL?","A_Content":"  Adding to the discussion:  Because the GIL exists, some operations are atomic in Python and do not need a lock.   http://www.python.org/doc/faq/library/#what-kinds-of-global-value-mutation-are-thread-safe  As stated by the other answers, however, you still need to use locks whenever the application logic requires them (such as in a Producer/Consumer problem).     ","Language":"Python","Tags":["python","multithreading","locking"],"URL":"https://stackoverflow.com/questions/105095/are-locks-unnecessary-in-multi-threaded-python-code-because-of-the-gil","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?  If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?  sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.    same thing would apply to any other language implementation that has a GIL.     ","Q_Votes":"63"},{"Q_Title":"Are locks unnecessary in multi-threaded Python code because of the GIL?","A_Content":"  The Global Interpreter Lock prevents threads from accessing the interpreter simultaneously (thus CPython only ever uses one core). However, as I understand it, the threads are still interrupted and scheduled preemptively, which means you still need locks on shared data structures, lest your threads stomp on each other's toes.  The answer I've encountered time and time again is that multithreading in Python is rarely worth the overhead, because of this. I've heard good things about the PyProcessing project, which makes running multiple processes as \"simple\" as multithreading, with shared data structures, queues, etc. (PyProcessing will be introduced into the standard library of the upcoming Python 2.6 as the multiprocessing module.) This gets you around the GIL, as each process has its own interpreter.     ","Language":"Python","Tags":["python","multithreading","locking"],"URL":"https://stackoverflow.com/questions/105095/are-locks-unnecessary-in-multi-threaded-python-code-because-of-the-gil","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?  If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?  sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.    same thing would apply to any other language implementation that has a GIL.     ","Q_Votes":"63"},{"Q_Title":"Are locks unnecessary in multi-threaded Python code because of the GIL?","A_Content":"  This post describes the GIL at a fairly high-level:   https://web.archive.org/web/20080516010343/http://www.pyzine.com/Issue001/Section_Articles/article_ThreadingGlobalInterpreter.html   Of particular interest are these quotes:     Every ten instructions (this default   can be changed), the core releases the   GIL for the current thread. At that   point, the OS chooses a thread from   all the threads competing for the lock   (possibly choosing the same thread   that just released the GIL – you don't   have any control over which thread   gets chosen); that thread acquires the   GIL and then runs for another ten   bytecodes.   and      Note carefully that the GIL only   restricts pure Python code. Extensions   (external Python libraries usually   written in C) can be written that   release the lock, which then allows   the Python interpreter to run   separately from the extension until   the extension reacquires the lock.   It sounds like the GIL just provides fewer possible instances for a context switch, and makes multi-core/processor systems behave as a single core, with respect to each python interpreter instance, so yes, you still need to use synchronization mechanisms.     ","Language":"Python","Tags":["python","multithreading","locking"],"URL":"https://stackoverflow.com/questions/105095/are-locks-unnecessary-in-multi-threaded-python-code-because-of-the-gil","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?  If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?  sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.    same thing would apply to any other language implementation that has a GIL.     ","Q_Votes":"63"},{"Q_Title":"Are locks unnecessary in multi-threaded Python code because of the GIL?","A_Content":"  Think of it this way:  On a single processor computer, multithreading happens by suspending one thread and starting another fast enough to make it appear to be running at the same time. This is like Python with the GIL: only one thread is ever actually running.  The problem is that the thread can be suspended anywhere, for example, if I want to compute b = (a + b) * 3, this might produce instructions something like this:  1    a += b 2    a *= 3 3    b = a   Now, lets say that is running in a thread and that thread is suspended after either line 1 or 2 and then another thread kicks in and runs:  b = 5   Then when the other thread resumes, b is overwritten by the old computed values, which is probably not what was expected.  So you can see that even though they're not ACTUALLY running at the same time, you still need locking.     ","Language":"Python","Tags":["python","multithreading","locking"],"URL":"https://stackoverflow.com/questions/105095/are-locks-unnecessary-in-multi-threaded-python-code-because-of-the-gil","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?  If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?  sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.    same thing would apply to any other language implementation that has a GIL.     ","Q_Votes":"63"},{"Q_Title":"Are locks unnecessary in multi-threaded Python code because of the GIL?","A_Content":"  You still need to use locks (your code could be interrupted at any time to execute another thread and this can cause data inconsistencies). The problem with GIL is that it prevents Python code from using more cores at the same time (or multiple processors if they are available).     ","Language":"Python","Tags":["python","multithreading","locking"],"URL":"https://stackoverflow.com/questions/105095/are-locks-unnecessary-in-multi-threaded-python-code-because-of-the-gil","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?  If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?  sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.    same thing would apply to any other language implementation that has a GIL.     ","Q_Votes":"63"},{"Q_Title":"Are locks unnecessary in multi-threaded Python code because of the GIL?","A_Content":"  Locks are still needed. I will try explaining why they are needed.  Any operation/instruction is executed in the interpreter. GIL ensures that interpreter is held by a single thread at a particular instant of time. And your program with multiple threads works in a single interpreter. At any particular instant of time, this interpreter is held by a single thread. It means that only thread which is holding the interpreter is running at any instant of time.  Suppose there are two threads,say t1 and t2, and both want to execute two instructions which is reading the value of a global variable and incrementing it.  #increment value global var read_var = var var = read_var + 1   As put above, GIL only ensures that two threads can't execute an instruction simultaneously, which means both threads can't execute read_var = var at any particular instant of time. But they can execute instruction one after another and you can still have problem. Consider this situation:   Suppose read_var is 0. GIL is held by thread t1. t1 executes read_var = var. So, read_var in t1 is 0. GIL will only ensure that this read operation will not be executed for any other thread at this instant. GIL is given to thread t2. t2 executes read_var = var. But read_var is still 0. So, read_var in t2 is 0. GIL is given to t1. t1 executes var = read_var+1 and var becomes 1. GIL is given to t2. t2 thinks read_var=0, because that's what it read. t2 executes var = read_var+1 and var becomes 1. Our expectation was that var should become 2. So, a lock must be used to keep both reading and incrementing as an atomic operation. Will Harris' answer explains it through a code example.      ","Language":"Python","Tags":["python","multithreading","locking"],"URL":"https://stackoverflow.com/questions/105095/are-locks-unnecessary-in-multi-threaded-python-code-because-of-the-gil","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?  If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?  sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.    same thing would apply to any other language implementation that has a GIL.     ","Q_Votes":"63"},{"Q_Title":"Are locks unnecessary in multi-threaded Python code because of the GIL?","A_Content":"  A little bit of update from Will Harris's example:  class Withdraw(threading.Thread):   def run(self):                 for _ in xrange(1000000):           global shared_balance           if shared_balance >= 100:           balance = shared_balance           balance -= 100             shared_balance = balance   Put a value check statement in the withdraw and I don't see negative anymore and updates seems consistent. My question is:  If GIL prevents only one thread can be executed at any atomic time, then where would be the stale value? If no stale value, why we need lock? (Assuming we only talk about pure python code)  If I understand correctly, the above condition check wouldn't work in a real threading environment. When more than one threads are executing concurrently, stale value can be created hence the inconsistency of the share state, then you really need a lock. But if python really only allows just one thread at any time (time slicing threading), then there shouldn't be possible for stale value to exist, right?     ","Language":"Python","Tags":["python","multithreading","locking"],"URL":"https://stackoverflow.com/questions/105095/are-locks-unnecessary-in-multi-threaded-python-code-because-of-the-gil","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?  If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?  sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.    same thing would apply to any other language implementation that has a GIL.     ","Q_Votes":"63"},{"Q_Title":"How to use inspect to get the caller's info from callee in Python?","A_Content":"  The caller's frame is one frame higher than the current frame. You can use inspect.currentframe().f_back to find the caller's frame. Then use inspect.getframeinfo to get the caller's filename and line number.  import inspect  def hello():     previous_frame = inspect.currentframe().f_back     (filename, line_number,       function_name, lines, index) = inspect.getframeinfo(previous_frame)     return (filename, line_number, function_name, lines, index)  print(hello())  # (<frame object at 0x8ba7254>, '/home/unutbu/pybin/test.py', 10, '<module>', ['hello()\\n'], 0)      ","Language":"Python","Tags":["python","inspect"],"URL":"https://stackoverflow.com/questions/3711184/how-to-use-inspect-to-get-the-callers-info-from-callee-in-python","A_Votes":"75","_type":"dict","isAccepted":"Yes","Q_Content":"    I need to get the caller info (what file/what line) from callee. I learned that I can use inpect module for that for purposes, but not exactly how.  How to get those info with inspect? Or is there any other way to get the info?  import inspect  print __file__ c=inspect.currentframe() print c.f_lineno  def hello():     print inspect.stack     ?? what file called me in what line?  hello()      ","Q_Votes":"63"},{"Q_Title":"How to use inspect to get the caller's info from callee in Python?","A_Content":"  I would suggest to use inspect.stack instead:  import inspect  def hello():     frame,filename,line_number,function_name,lines,index = inspect.stack()[1]     print(frame,filename,line_number,function_name,lines,index) hello()      ","Language":"Python","Tags":["python","inspect"],"URL":"https://stackoverflow.com/questions/3711184/how-to-use-inspect-to-get-the-callers-info-from-callee-in-python","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    I need to get the caller info (what file/what line) from callee. I learned that I can use inpect module for that for purposes, but not exactly how.  How to get those info with inspect? Or is there any other way to get the info?  import inspect  print __file__ c=inspect.currentframe() print c.f_lineno  def hello():     print inspect.stack     ?? what file called me in what line?  hello()      ","Q_Votes":"63"},{"Q_Title":"How to use inspect to get the caller's info from callee in Python?","A_Content":"  I published a wrapper for inspect with simple stackframe addressing covering the stack frame by a single parameter spos:    https://pypi.python.org/pypi/pysourceinfo/ https://pythonhosted.org/pysourceinfo/   E.g. pysourceinfo.PySourceInfo.getCallerLinenumber(spos=1)  where spos=0 is the lib-function, spos=1 is the caller, spos=2 the caller-of-the-caller, etc.     ","Language":"Python","Tags":["python","inspect"],"URL":"https://stackoverflow.com/questions/3711184/how-to-use-inspect-to-get-the-callers-info-from-callee-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I need to get the caller info (what file/what line) from callee. I learned that I can use inpect module for that for purposes, but not exactly how.  How to get those info with inspect? Or is there any other way to get the info?  import inspect  print __file__ c=inspect.currentframe() print c.f_lineno  def hello():     print inspect.stack     ?? what file called me in what line?  hello()      ","Q_Votes":"63"},{"Q_Title":"Modifying a Python dict while iterating over it","A_Content":"  It is explicitly mentioned on the Python doc page (for Python 2.7) that     Using iteritems() while adding or deleting entries in the dictionary may raise a RuntimeError or fail to iterate over all entries.   Similarly for Python 3.  The same holds for iter(d), d.iterkeys() and d.itervalues(), and I'll go as far as saying that it does for for k, v in d.items(): (I can't remember exactly what for does, but I would not be surprised if the implementation called iter(d)).     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/6777485/modifying-a-python-dict-while-iterating-over-it","A_Votes":"42","_type":"dict","isAccepted":"Yes","Q_Content":"    Let's say we have a Python dictionary d, and we're iterating over it like so:  for k,v in d.iteritems():     del d[f(k)] # remove some item     d[g(k)] = v # add a new item   (f and g are just some black-box transformations.)  In other words, we try to add/remove items to d while iterating over it using iteritems.  Is this well defined? Could you provide some references to support your answer?  (It's pretty obvious how to fix this if it's broken, so this isn't the angle I am after.)     ","Q_Votes":"63"},{"Q_Title":"Modifying a Python dict while iterating over it","A_Content":"  Alex Martelli weighs in on this here.  It may not be safe to change the container (e.g. dict) while looping over the container. So del d[f(k)] may not be safe. As you know, the workaround is to use d.items() (to loop over an independent copy of the container) instead of d.iteritems() (which uses the same underlying container).  It is okay to modify the value at an existing index of the dict, but inserting values at new indices (e.g. d[g(k)]=v) may not work.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/6777485/modifying-a-python-dict-while-iterating-over-it","A_Votes":"43","_type":"dict","isAccepted":"No","Q_Content":"    Let's say we have a Python dictionary d, and we're iterating over it like so:  for k,v in d.iteritems():     del d[f(k)] # remove some item     d[g(k)] = v # add a new item   (f and g are just some black-box transformations.)  In other words, we try to add/remove items to d while iterating over it using iteritems.  Is this well defined? Could you provide some references to support your answer?  (It's pretty obvious how to fix this if it's broken, so this isn't the angle I am after.)     ","Q_Votes":"63"},{"Q_Title":"Modifying a Python dict while iterating over it","A_Content":"  You cannot do that, at least with d.iteritems(). I tried it, and Python fails with  RuntimeError: dictionary changed size during iteration   If you instead use d.items(), then it works.  In Python 3, d.items() is a view into the dictionary, like d.iteritems() in Python 2. To do this in Python 3, instead use d.copy().items(). This will similarly allow us to iterate over a copy of the dictionary in order to avoid modifying the data structure we are iterating over.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/6777485/modifying-a-python-dict-while-iterating-over-it","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    Let's say we have a Python dictionary d, and we're iterating over it like so:  for k,v in d.iteritems():     del d[f(k)] # remove some item     d[g(k)] = v # add a new item   (f and g are just some black-box transformations.)  In other words, we try to add/remove items to d while iterating over it using iteritems.  Is this well defined? Could you provide some references to support your answer?  (It's pretty obvious how to fix this if it's broken, so this isn't the angle I am after.)     ","Q_Votes":"63"},{"Q_Title":"Modifying a Python dict while iterating over it","A_Content":"  The following code shows that this is not well defined:  def f(x):     return x  def g(x):     return x+1  def h(x):     return x+10  try:     d = {1:\"a\", 2:\"b\", 3:\"c\"}     for k, v in d.iteritems():         del d[f(k)]         d[g(k)] = v+\"x\"     print d except Exception as e:     print \"Exception:\", e  try:     d = {1:\"a\", 2:\"b\", 3:\"c\"}     for k, v in d.iteritems():         del d[f(k)]         d[h(k)] = v+\"x\"     print d except Exception as e:     print \"Exception:\", e   The first example calls g(k), and throws an exception (dictionary changed size during iteration).  The second example calls h(k) and throws no exception, but outputs:  {21: 'axx', 22: 'bxx', 23: 'cxx'}   Which, looking at the code, seems wrong - I would have expected something like:  {11: 'ax', 12: 'bx', 13: 'cx'}      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/6777485/modifying-a-python-dict-while-iterating-over-it","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Let's say we have a Python dictionary d, and we're iterating over it like so:  for k,v in d.iteritems():     del d[f(k)] # remove some item     d[g(k)] = v # add a new item   (f and g are just some black-box transformations.)  In other words, we try to add/remove items to d while iterating over it using iteritems.  Is this well defined? Could you provide some references to support your answer?  (It's pretty obvious how to fix this if it's broken, so this isn't the angle I am after.)     ","Q_Votes":"63"},{"Q_Title":"Modifying a Python dict while iterating over it","A_Content":"  I have a large dictionary containing Numpy arrays, so the dict.copy().keys() thing suggested by @murgatroid99 was not feasible (though it worked).  Instead, I just converted the keys_view to a list and it worked fine (in Python 3.4):  for item in list(dict_d.keys()):     temp = dict_d.pop(item)     dict_d['some_key'] = 1  # Some value   I realize this doesn't dive into the philosophical realm of Python's inner workings like the answers above, but it does provide a practical solution to the stated problem.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/6777485/modifying-a-python-dict-while-iterating-over-it","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Let's say we have a Python dictionary d, and we're iterating over it like so:  for k,v in d.iteritems():     del d[f(k)] # remove some item     d[g(k)] = v # add a new item   (f and g are just some black-box transformations.)  In other words, we try to add/remove items to d while iterating over it using iteritems.  Is this well defined? Could you provide some references to support your answer?  (It's pretty obvious how to fix this if it's broken, so this isn't the angle I am after.)     ","Q_Votes":"63"},{"Q_Title":"Modifying a Python dict while iterating over it","A_Content":"  I got the same problem  and I used following procedure to solve this issue.  Python List can be iterate even if you modify during iterating over it. so for following code it will print 1's infinitely.  for i in list:    list.append(1)    print 1   So using list and dict collaboratively you can solve this problem.  d_list=[]  d_dict = {}   for k in d_list:     if d_dict[k] is not -1:        d_dict[f(k)] = -1 # rather than deleting it mark it with -1 or other value to specify that it will be not considered further(deleted)        d_dict[g(k)] = v # add a new item         d_list.append(g(k))      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/6777485/modifying-a-python-dict-while-iterating-over-it","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Let's say we have a Python dictionary d, and we're iterating over it like so:  for k,v in d.iteritems():     del d[f(k)] # remove some item     d[g(k)] = v # add a new item   (f and g are just some black-box transformations.)  In other words, we try to add/remove items to d while iterating over it using iteritems.  Is this well defined? Could you provide some references to support your answer?  (It's pretty obvious how to fix this if it's broken, so this isn't the angle I am after.)     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  Sorry for posting to such an old thread -- but as someone who also shares a passion for pythonic 'best', I thought I'd share our solution.  The solution is to build SQL statements using python's String Literal Concatenation (http://docs.python.org/), which could be qualified a somewhere between Option 2 and Option 4  Code Sample:  sql = ('select field1, field2, field3, field4 '        'from table '        'where condition1=1 '        'and condition2=2 ')   Pros:   It retains the pythonic 'well tabulated' format, but does not add extraneous space characters (which pollutes logging).  It avoids the backslash continuation ugliness of Option 4, which makes it difficult to add statements (not to mention white-space blindness). And further, it's really simple to expand the statement in VIM (just position the cursor to the insert point, and press SHIFT-O to open a new line).      ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"94","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  You've obviously considered lots of ways to write the SQL such that it prints out okay, but how about changing the 'print' statement you use for debug logging, rather than writing your SQL in ways you don't like?  Using your favourite option above, how about a logging function such as this:  def debugLogSQL(sql):      print ' '.join([line.strip() for line in sql.splitlines()]).strip()  sql = \"\"\"     select field1, field2, field3, field4     from table\"\"\" if debug:     debugLogSQL(sql)   This would also make it trivial to add additional logic to split the logged string across multiple lines if the line is longer than your desired length.     ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  Cleanest way I have come across is inspired by the sql style guide.  sql = \"\"\"     SELECT field1, field2, field3, field4       FROM table      WHERE condition1 = 1        AND condition2 = 2; \"\"\"   Essentially, the keywords that begin a clause should be right-aligned and the field names etc, should be left aligned. This looks very neat and is easier to debug as well.     ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  sql = (\"select field1, field2, field3, field4 \"        \"from table \"        \"where condition1={} \"        \"and condition2={}\").format(1, 2)  Output: 'select field1, field2, field3, field4 from table           where condition1=1 and condition2=2'   if the value of condition should be a string, you can do like this:  sql = (\"select field1, field2, field3, field4 \"        \"from table \"        \"where condition1='{0}' \"        \"and condition2='{1}'\").format('2016-10-12', '2017-10-12')  Output: \"select field1, field2, field3, field4 from table where          condition1='2016-10-12' and condition2='2017-10-12'\"      ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  you could put the field names into an array \"fields\", and then:   sql = 'select %s from table where condition1=1 and condition2=2' % (  ', '.join(fields))      ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  I would suggest sticking to option 2 (I'm always using it for queries any more complex than SELECT * FROM table) and if you want to print it in a nice way you may always use a separate module.     ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  sql = \"\"\"\\ select field1, field2, field3, field4 from table where condition1=1 and condition2=2 \"\"\"   [edit in responese to comment] Having an SQL string inside a method does NOT mean that you have to \"tabulate\" it:  >>> class Foo: ...     def fubar(self): ...         sql = \"\"\"\\ ... select * ... from frobozz ... where zorkmids > 10 ... ;\"\"\" ...         print sql ... >>> Foo().fubar() select * from frobozz where zorkmids > 10 ; >>>      ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  For short queries that can fit on one or two lines, I use the string literal solution in the top-voted solution above. For longer queries, I break them out to .sql files. I then use a wrapper function to load the file and execute the script, something like:  script_cache = {} def execute_script(cursor,script,*args,**kwargs):     if not script in script_cache:         with open(script,'r') as s:             script_cache[script] = s     return cursor.execute(script_cache[script],*args,**kwargs)   Of course this often lives inside a class so I don't usually have to pass cursor explicitly. I also generally use codecs.open(), but this gets the general idea across. Then SQL scripts are completely self-contained in their own files with their own syntax highlighting.     ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  In Addition to @user590028 :   Using format was helpful for what I was working on like so:  statement = (ins             \"(name,standard_price,list_price,mes_type,uom_id,uom_po_id,type,procure_method,cost_method_categ_id,supply_method,sale_ok) \"             \"VALUE ('{0}','{1}','{2}'\".format(row[1],str(row[2]),str(row[2])) + \",'fixed',1,1,'product','make_to_stock','standard',1,'buy',True) RETURNING id\"             )   And:  statement = (\"INSERT INTO product_product \"              \"(product_tmpl_id,default_code,active,valuation) \"              \"VALUE \"              \"('{0}','{1}',True,'manual_periodic')\".format(str(row[0]), row[1])              )      ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Python SQL query string formatting","A_Content":"  I would suggest a very easy option. just put an r before the string You can use it like below:  query=(r'SELECT f1,f2,f3 '      r'FROM table1 '      r'WHERE f4=cond1 '      r'AND f5=cond2 ') cursor.execute(str(query)) results=cursor.fetchall() cursor.close()      ","Language":"Python","Tags":["python","sql","string-formatting"],"URL":"https://stackoverflow.com/questions/5243596/python-sql-query-string-formatting","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to find the best way to format an sql query string. When I'm debugging  my application I'd like to log to file all the sql query strings, and it is important that the string is properly formated.  Option 1  def myquery():     sql = \"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"     con = mymodule.get_connection()     ...    This is good for printing the sql string. It is not a good solution if the string is long and not fits the standard width  of 80 characters.   Option 2  def query():     sql = \"\"\"         select field1, field2, field3, field4         from table         where condition1=1         and condition2=2\"\"\"     con = mymodule.get_connection()     ...    Here the code is clear but when you print the sql query string you get all these annoying white spaces.     u'\\nselect field1, field2, field3, field4\\n_____from table\\n____where condition1=1 \\n_____and condition2=2'    Note: I have replaced white spaces with underscore _, because they are trimmed by the editor  Option 3  def query():     sql = \"\"\"select field1, field2, field3, field4 from table where condition1=1 and condition2=2\"\"\"     con = mymodule.get_connection()     ...    I don't like this option because it breaks the clearness of the well tabulated code.   Option 4  def query():     sql = \"select field1, field2, field3, field4 \" \\           \"from table \" \\           \"where condition1=1 \" \\           \"and condition2=2 \"     con = mymodule.get_connection()         ...    I don't like this option because all the extra typing in each line and is difficult to edit the query also.   For me the best solution would be Option 2 but I don't like the extra whitespaces when I print the sql string.  Do you know of any other options?     ","Q_Votes":"63"},{"Q_Title":"Matplotlib connect scatterplot points with line - Python","A_Content":"  I think @Evert has the right answer:  plt.scatter(dates,values) plt.plot(dates, values) plt.show()   Which is pretty much the same as   plt.plot(dates, values, '-o') plt.show()   or whatever linestyle you prefer.     ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/20130227/matplotlib-connect-scatterplot-points-with-line-python","A_Votes":"86","_type":"dict","isAccepted":"Yes","Q_Content":"    I have two lists, dates and values. I want to plot them using matplotlib. The following creates a scatter plot of my data.  import matplotlib.pyplot as plt  plt.scatter(dates,values) plt.show()   plt.plot(dates, values) creates a line graph.  But what I really want is a scatterplot where the points are connected by a line.  Similar to in R:  plot(dates, values) lines(dates, value, type=\"l\")   , which gives me a scatterplot of points overlaid with a line connecting the points.  How do I do this in python?     ","Q_Votes":"63"},{"Q_Title":"Matplotlib connect scatterplot points with line - Python","A_Content":"  For red lines an points  plt.plot(dates, values, '.r-')    or for x markers and blue lines  plt.plot(dates, values, 'xb-')      ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/20130227/matplotlib-connect-scatterplot-points-with-line-python","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists, dates and values. I want to plot them using matplotlib. The following creates a scatter plot of my data.  import matplotlib.pyplot as plt  plt.scatter(dates,values) plt.show()   plt.plot(dates, values) creates a line graph.  But what I really want is a scatterplot where the points are connected by a line.  Similar to in R:  plot(dates, values) lines(dates, value, type=\"l\")   , which gives me a scatterplot of points overlaid with a line connecting the points.  How do I do this in python?     ","Q_Votes":"63"},{"Q_Title":"Matplotlib connect scatterplot points with line - Python","A_Content":"  In addition to what provided in the other answers, the keyword \"zorder\" allows one to decide the order in which different objects are plotted vertically. E.g.:  plt.plot(x,y,zorder=1)  plt.scatter(x,y,zorder=2)   plots the scatter symbols on top of the line, while  plt.plot(x,y,zorder=2) plt.scatter(x,y,zorder=1)   plots the line over the scatter symbols.  See, e.g., the zorder demo     ","Language":"Python","Tags":["python","matplotlib"],"URL":"https://stackoverflow.com/questions/20130227/matplotlib-connect-scatterplot-points-with-line-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I have two lists, dates and values. I want to plot them using matplotlib. The following creates a scatter plot of my data.  import matplotlib.pyplot as plt  plt.scatter(dates,values) plt.show()   plt.plot(dates, values) creates a line graph.  But what I really want is a scatterplot where the points are connected by a line.  Similar to in R:  plot(dates, values) lines(dates, value, type=\"l\")   , which gives me a scatterplot of points overlaid with a line connecting the points.  How do I do this in python?     ","Q_Votes":"63"},{"Q_Title":"Python: does it have a argc argument?","A_Content":"  In python a list knows its length, so you can just do len(sys.argv) to get the number of elements in argv.     ","Language":"Python","Tags":["python","linux","file-io","error-handling","arguments"],"URL":"https://stackoverflow.com/questions/8201955/python-does-it-have-a-argc-argument","A_Votes":"101","_type":"dict","isAccepted":"Yes","Q_Content":"    I have written the same program (open text file and display contents) in C and C++. Now am doing the same in Python (on a Linux machine).  In the C programs I used the code if (argc!=2) {//exit program}  Question: What is used in Python to check the number of arguments  #!/usr/bin/python import sys try:     in_file = open(sys.argv[1], \"r\") except:     sys.exit(\"ERROR. Did you make a mistake in the spelling\") text = in_file.read() print text in_file.close()   Current output:  ./python names.txt = Displays text file (correct) ./python nam = error message: stated from the sys.ext line (correct) ./python = error message: stated from the sys.ext line (wrong: want it to be a separate error message stating no file name input)     ","Q_Votes":"63"},{"Q_Title":"Python: does it have a argc argument?","A_Content":"  I often use a quick-n-dirty trick to read a fixed number of arguments from the command-line:  [filename] = sys.argv[1:]  in_file = open(filename)   # Don't need the \"r\"   This will assign the one argument to filename and raise an exception if there isn't exactly one argument.     ","Language":"Python","Tags":["python","linux","file-io","error-handling","arguments"],"URL":"https://stackoverflow.com/questions/8201955/python-does-it-have-a-argc-argument","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I have written the same program (open text file and display contents) in C and C++. Now am doing the same in Python (on a Linux machine).  In the C programs I used the code if (argc!=2) {//exit program}  Question: What is used in Python to check the number of arguments  #!/usr/bin/python import sys try:     in_file = open(sys.argv[1], \"r\") except:     sys.exit(\"ERROR. Did you make a mistake in the spelling\") text = in_file.read() print text in_file.close()   Current output:  ./python names.txt = Displays text file (correct) ./python nam = error message: stated from the sys.ext line (correct) ./python = error message: stated from the sys.ext line (wrong: want it to be a separate error message stating no file name input)     ","Q_Votes":"63"},{"Q_Title":"Python: does it have a argc argument?","A_Content":"  You're better off looking at argparse for argument parsing.   http://docs.python.org/dev/library/argparse.html  Just makes it easy, no need to do the heavy lifting yourself.      ","Language":"Python","Tags":["python","linux","file-io","error-handling","arguments"],"URL":"https://stackoverflow.com/questions/8201955/python-does-it-have-a-argc-argument","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have written the same program (open text file and display contents) in C and C++. Now am doing the same in Python (on a Linux machine).  In the C programs I used the code if (argc!=2) {//exit program}  Question: What is used in Python to check the number of arguments  #!/usr/bin/python import sys try:     in_file = open(sys.argv[1], \"r\") except:     sys.exit(\"ERROR. Did you make a mistake in the spelling\") text = in_file.read() print text in_file.close()   Current output:  ./python names.txt = Displays text file (correct) ./python nam = error message: stated from the sys.ext line (correct) ./python = error message: stated from the sys.ext line (wrong: want it to be a separate error message stating no file name input)     ","Q_Votes":"63"},{"Q_Title":"Python: does it have a argc argument?","A_Content":"  dir(sys) says no. len(sys.argv) works, but in Python it is better to ask for forgiveness than permission, so   #!/usr/bin/python import sys try:     in_file = open(sys.argv[1], \"r\") except:     sys.exit(\"ERROR. Can't read supplied filename.\") text = in_file.read() print(text) in_file.close()   works fine and is shorter.  If you're going to exit anyway, this would be better:  #!/usr/bin/python import sys text = open(sys.argv[1], \"r\").read() print(text)   I'm using print() so it works in 2.7 as well as Python 3.     ","Language":"Python","Tags":["python","linux","file-io","error-handling","arguments"],"URL":"https://stackoverflow.com/questions/8201955/python-does-it-have-a-argc-argument","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I have written the same program (open text file and display contents) in C and C++. Now am doing the same in Python (on a Linux machine).  In the C programs I used the code if (argc!=2) {//exit program}  Question: What is used in Python to check the number of arguments  #!/usr/bin/python import sys try:     in_file = open(sys.argv[1], \"r\") except:     sys.exit(\"ERROR. Did you make a mistake in the spelling\") text = in_file.read() print text in_file.close()   Current output:  ./python names.txt = Displays text file (correct) ./python nam = error message: stated from the sys.ext line (correct) ./python = error message: stated from the sys.ext line (wrong: want it to be a separate error message stating no file name input)     ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  This can also happen if you have an application (subdirectory to the project with an init file in it) named the same thing as the project.  Your settings.py file may be in your project folder, but it seems that a part of the django system looks first for a module inside the project by the same name as the project and when it can't find a settings.py in there, it fails with a misleading message.  -uniquename1  ---settings.py  ---manage.py  ---application1  -----file.py  -----file2.py  ---uniquename1  (problem, rename this to some other unique name)  -----file.py  -----file2.py   Just something else to check for anyone else having this problem.  Applies to Django 1.3 and probably others.     ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"48","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  I had a similar permissions problem, and although my settings.py had the right permissions, the .pyc's did not!!! So watch out for this.     ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  Hey, just adding an additional answer to this problem. I had the exact same issue, but it wasn't file permissions. I was appending \"path/to/project\", but not also appending \"path/to\". Linked   is mod_wsgi's Django integration explanation that showed me the answer.     ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  I found the answer... file permissions. /home/django was set to 700. i.e. only django can view the contents. apache runs as Apache and so can't get past /home/django.      ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  I think you need to have a trailing forward slash on that its what I have to do in my wsgi script in apache before I load up django.  import os import sys sys.path.append('/home/django/mofin/trunk/') sys.path.append('/home/django/mofin/trunk/mofin/') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   In my case  import os import sys if os.uname()[1] == 'vivien':     sys.path.append('/home/www/sitebuilder.blacknight.ie/web/')     os.environ['DJANGO_SETTINGS_MODULE'] = 'gibo.dev_settings' elif os.uname()[1] == 'thingy':     sys.path.append('/home/www/sitebuilder.blacknight.ie/web/')     os.environ['DJANGO_SETTINGS_MODULE'] = 'gibo.dev_settings' else:     sys.path.append('/home/www/sitebuilder.blacknight.ie/web/')     os.environ['DJANGO_SETTINGS_MODULE'] = 'gibo.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()      ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  Another cause of this problem is that you can't name your application the same as another python module. For example I called mine site, little realising that site is already a python module.  You can check this by starting python, and running import site, help(site), and it will show you it isn't using your module. This of course gives you errors when django tries to import site.settings which doesn't exist.     ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  Possible problem:  you forgot the __init__.py file, which must be in your project and in all directories which you consider a python module for import.  Other thing you could try is to add the path directly into the manage.py file, like :  import sys  ... ...  sys.path.insert(0, '/home/django/mofin/trunk')   I hope it helps     ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  I had the same problem but another solution :  My project folder was named exactly as one of my application.  I had :  /home/myApp /home/myApp/settings.py /home/myApp/manage.py /home/myApp/rights.py /home/myApp/static/ /home/myApp/static/ /home/myApp/myApp/model.py /home/myApp/myApp/admin.py /home/myApp/myApp/views.py  This kind of tree doesn't seems to be possible easily. I changed the name of my project root folder and the problem was solved!     ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  (I wrote up this same answer for Django deployment problem in Apache/mod_wsgi. ImportError: Could not import settings 'site.settings' in case someone only finds this question.)  This doesn't appear to be the problem in your case, but I ran smack into the same ImportError when I used the WSGIPythonPath directive (instead of the .wsgi file) to set up sys.path. That worked fine until I switched to running WSGI in daemon mode. Once you do that, you have to use the python-path argument to the WSGIDaemonProcess directive instead.     ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  In my case, I had a circular import that was causing this error. From settings.py I was importing one function in another module, and from that module I was importing a settings variable. To fix it, instead of directly importing from settings, I did this:  from django.conf import settings      ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  Let me add and my experience for that issue. After head banging for few hours and try all from the above answers I found that few lines in settings.py file  cause the problem:  from south.modelsinspector import add_introspection_rules add_introspection_rules([], [\"^dynamicsites.fields.FolderNameField\"]) add_introspection_rules([], [\"^dynamicsites.fields.SubdomainListField\"])   After that I made copy of the settings.py, named scripts_settings.py whithout that lines, and used that file and everything is ok now.     ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  At first look I'd say the python path is wrong but compared to interactive shell it looks ok. So maybe try this:  from django.core.management import setup_environ from mofin import settings  setup_environ(settings)      ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  I was going to say that you can just insert/append your project directory to your sys.path in your wsgi file but if your settings file is at  /home/django/mofin/trunk/mofin/settings.py   Then you should be good there.  Is it on sys.path? Does it have syntax errors?   That pretty much sums up what you are looking for.  Interesting that the error propagates though:  for middleware_path in settings.MIDDLEWARE_CLASSES:   but you have what appears to be the exact default.  You might want to check which python interpreter is pointed to by wsgi.  Are you intending to use a virtualenv but wsgi is looking at your system install?  You can also set the user and group that wsgi is running under.  I use something like:  WSGIDaemonProcess mysite.com user=skyl group=skyl processes=n threads=N python-path=/home/skyl/pinax/pinax-env2/lib/python2.6/site-packages     ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  Add two more lines of code   sys.path.append('/home/django/mofin/mofin') sys.path.append('/home/django/mofin/trunk/mofin/mofin')   to your wsgi file under the line:  sys.path.append('/home/django/mofin/trunk/mofin/')      ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  I had a similar problem, solved it with the following snippet in my python:  ALLDIRS = ['/var/www/MarkerDB/']  import sys  import site   # Remember original sys.path. prev_sys_path = list(sys.path)   # Add each new site-packages directory. for directory in ALLDIRS:   site.addsitedir(directory)  # Reorder sys.path so new directories at the front. new_sys_path = []  for item in list(sys.path):      if item not in prev_sys_path:          new_sys_path.append(item)          sys.path.remove(item)  sys.path[:0] = new_sys_pat   Source: http://code.google.com/p/modwsgi/wiki/VirtualEnvironments#Application_Environments      ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"How do I stop getting ImportError: Could not import settings 'mofin.settings' when using django with wsgi?","A_Content":"  I just had this error and the solution was to enable my virtual environment via myvenv/source/activate.      ","Language":"Python","Tags":["python","django","apache","wsgi"],"URL":"https://stackoverflow.com/questions/1411417/how-do-i-stop-getting-importerror-could-not-import-settings-mofin-settings-wh","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I can't get wsgi to import my settings file for my project 'mofin'.  The list of errors from the apache error log are as follows  mod_wsgi (pid=4001): Exception occurred within WSGI script '/var/www/wsgi-scripts/django.wsgi'. Traceback (most recent call last):   File \"/usr/lib/python2.5/site-packages/django/core/handlers/wsgi.py\", line 228, in __call__     self.load_middleware()   File \"/usr/lib/python2.5/site-packages/django/core/handlers/base.py\", line 31, in load_middleware     for middleware_path in settings.MIDDLEWARE_CLASSES:   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 28, in __getattr__     self._import_settings()   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 59, in _import_settings     self._target = Settings(settings_module)   File \"/usr/lib/python2.5/site-packages/django/conf/__init__.py\", line 94, in __init__     raise ImportError, \"Could not import settings '%s' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e) ImportError: Could not import settings 'mofin.settings' (Is it on sys.path? Does it have syntax errors?): No module named mofin.settings   I got the \"hello world!\" wsgi app listed here(http://code.google.com/p/modwsgi/wiki/QuickConfigurationGuide) to work fine.   The settings.py file loads fine with python manage.py (runserver|shell|syncdb|test store) as does the application.  Here is my wsgi file:  import os import sys sys.path.append('/home/django/mofin/trunk') sys.path.append('/home/django/mofin/trunk/mofin') print >> sys.stderr, sys.path os.environ['DJANGO_SETTINGS_MODULE'] = 'mofin.settings'  import django.core.handlers.wsgi application = django.core.handlers.wsgi.WSGIHandler()   the sys.path as printed in the error log is     ['/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0', '/home/django/mofin/trunk', '/home/django/mofin/trunk/mofin']   if I open an interactive shell with manage.py, sys.path is     ['/home/django/mofin/trunk/mofin', '/usr/lib/python25.zip', '/usr/lib/python2.5', '/usr/lib/python2.5/plat-linux2', '/usr/lib/python2.5/lib-tk', '/usr/lib/python2.5/lib-dynload', '/usr/lib/python2.5/site-packages', '/usr/lib/python2.5/site-packages/gtk-2.0']   My django settings file looks like this:     # Django settings for mofin project.  DEBUG = True TEMPLATE_DEBUG = DEBUG  ADMINS = (     # ('Dan xxxx', 'xxxx@yyyyyyyyyy.com'), )  MANAGERS = ADMINS  DATABASE_ENGINE = 'mysql'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'. DATABASE_NAME = 'mofin'             # Or path to database file if using sqlite3. DATABASE_USER = 'aaaaaa'             # Not used with sqlite3. DATABASE_PASSWORD = 'bbbbbb'         # Not used with sqlite3. DATABASE_HOST = ''             # Set to empty string for localhost. Not used with sqlite3. DATABASE_PORT = ''             # Set to empty string for default. Not used with sqlite3.  # Local time zone for this installation. Choices can be found here: # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name # although not all choices may be available on all operating systems. # If running in a Windows environment this must be set to the same as your # system time zone. TIME_ZONE = 'Europe/London'  # Language code for this installation. All choices can be found here: # http://www.i18nguy.com/unicode/language-identifiers.html LANGUAGE_CODE = 'en-GB'  SITE_ID = 1  # If you set this to False, Django will make some optimizations so as not # to load the internationalization machinery. USE_I18N = True  # Absolute path to the directory that holds media. # Example: \"/home/media/media.lawrence.com/\" MEDIA_ROOT = '/home/django/media/'  # URL that handles the media served from MEDIA_ROOT. Make sure to use a # trailing slash if there is a path component (optional in other cases). # Examples: \"http://media.lawrence.com\", \"http://example.com/media/\" MEDIA_URL = 'http://mofin.mywebsite.co.uk/media/'  # URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a # trailing slash. # Examples: \"http://foo.com/media/\", \"/media/\". ADMIN_MEDIA_PREFIX = '/admin_media/'  # Make this unique, and don't share it with anybody. SECRET_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'  # List of callables that know how to import templates from various sources. TEMPLATE_LOADERS = (     'django.template.loaders.filesystem.load_template_source',     'django.template.loaders.app_directories.load_template_source', #     'django.template.loaders.eggs.load_template_source', )  MIDDLEWARE_CLASSES = (     'django.middleware.common.CommonMiddleware',     'django.contrib.sessions.middleware.SessionMiddleware',     'django.contrib.auth.middleware.AuthenticationMiddleware', )  ROOT_URLCONF = 'mofin.urls'  TEMPLATE_DIRS = (     # Put strings here, like \"/home/html/django_templates\" or \"C:/www/django/templates\".     # Always use forward slashes, even on Windows.     # Don't forget to use absolute paths, not relative paths. )  INSTALLED_APPS = (     'django.contrib.auth',     'django.contrib.contenttypes',     'django.contrib.sessions',     'django.contrib.sites',     'django.contrib.admin',     'mofin.store' )      ","Q_Votes":"63"},{"Q_Title":"ImportError: No module named - Python","A_Content":"  Your modification of sys.path assumes the current working directory is always in main/. This is not the case. Instead, just add the parent directory to sys.path:  import sys import os.path  sys.path.append(os.path.join(os.path.dirname(__file__), '..')) import gen_py.lib   Don't forget to include a file __init__.py in gen_py and lib - otherwise, they won't be recognized as Python modules.     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/7587457/importerror-no-module-named-python","A_Votes":"71","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a python application with the following directory structure:  src  |  +---- main  |  +---- util  |  +---- gen_py          |          +---- lib   In the package main, I have a python module named MyServer.py which has an import statement like:   from gen_py.lib import MyService   In order for this statement to work, I placed the following line at the beginning of MyServer.py:  import sys sys.path.append('../gen_py/lib')   When I run MyServer.py in the terminal, I get the following error:     ImportError: No module named gen_py.lib   What I am missing here?     ","Q_Votes":"62"},{"Q_Title":"ImportError: No module named - Python","A_Content":"  For the Python module import to work, you must have \"src\" in your path, not \"gen_py/lib\".  When processing an import like import gen_py.lib, it looks for a module gen_py, then looks for a submodule lib.  As the module gen_py won't be in \"../gen_py/lib\" (it'll be in \"..\"), the path you added will do nothing to help the import process.  Depending on where you're running it from, try adding the relative path to the \"src\" folder. Perhaps it's sys.path.append('..'). You might also have success running the script while inside the src folder directly, via relative paths like python main/MyServer.py     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/7587457/importerror-no-module-named-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have a python application with the following directory structure:  src  |  +---- main  |  +---- util  |  +---- gen_py          |          +---- lib   In the package main, I have a python module named MyServer.py which has an import statement like:   from gen_py.lib import MyService   In order for this statement to work, I placed the following line at the beginning of MyServer.py:  import sys sys.path.append('../gen_py/lib')   When I run MyServer.py in the terminal, I get the following error:     ImportError: No module named gen_py.lib   What I am missing here?     ","Q_Votes":"62"},{"Q_Title":"ImportError: No module named - Python","A_Content":"  from ..gen_py.lib import MyService   or  from main.gen_py.lib import MyService   Make sure you have a (at least empty) __init__.py file on each directory.     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/7587457/importerror-no-module-named-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have a python application with the following directory structure:  src  |  +---- main  |  +---- util  |  +---- gen_py          |          +---- lib   In the package main, I have a python module named MyServer.py which has an import statement like:   from gen_py.lib import MyService   In order for this statement to work, I placed the following line at the beginning of MyServer.py:  import sys sys.path.append('../gen_py/lib')   When I run MyServer.py in the terminal, I get the following error:     ImportError: No module named gen_py.lib   What I am missing here?     ","Q_Votes":"62"},{"Q_Title":"ImportError: No module named - Python","A_Content":"  make sure to include __init__.py, which makes Python know that those directories containpackages     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/7587457/importerror-no-module-named-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a python application with the following directory structure:  src  |  +---- main  |  +---- util  |  +---- gen_py          |          +---- lib   In the package main, I have a python module named MyServer.py which has an import statement like:   from gen_py.lib import MyService   In order for this statement to work, I placed the following line at the beginning of MyServer.py:  import sys sys.path.append('../gen_py/lib')   When I run MyServer.py in the terminal, I get the following error:     ImportError: No module named gen_py.lib   What I am missing here?     ","Q_Votes":"62"},{"Q_Title":"ImportError: No module named - Python","A_Content":"  This is if you are building a package and you are finding error in imports. I learnt it the hard way.The answer isn't to add the package to python path or to do it programatically (what if your module gets installed and your command adds it again?) thats a bad way.   The right thing to do is: 1) Use virtualenv pyvenv-3.4 or something similar 2) Activate the development mode - $python setup.py develop      ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/7587457/importerror-no-module-named-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a python application with the following directory structure:  src  |  +---- main  |  +---- util  |  +---- gen_py          |          +---- lib   In the package main, I have a python module named MyServer.py which has an import statement like:   from gen_py.lib import MyService   In order for this statement to work, I placed the following line at the beginning of MyServer.py:  import sys sys.path.append('../gen_py/lib')   When I run MyServer.py in the terminal, I get the following error:     ImportError: No module named gen_py.lib   What I am missing here?     ","Q_Votes":"62"},{"Q_Title":"ImportError: No module named - Python","A_Content":"  Make sure if root project directory is coming up in sys.path output. If not, please add path of root project directory to sys.path.     ","Language":"Python","Tags":["python","import"],"URL":"https://stackoverflow.com/questions/7587457/importerror-no-module-named-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a python application with the following directory structure:  src  |  +---- main  |  +---- util  |  +---- gen_py          |          +---- lib   In the package main, I have a python module named MyServer.py which has an import statement like:   from gen_py.lib import MyService   In order for this statement to work, I placed the following line at the beginning of MyServer.py:  import sys sys.path.append('../gen_py/lib')   When I run MyServer.py in the terminal, I get the following error:     ImportError: No module named gen_py.lib   What I am missing here?     ","Q_Votes":"62"},{"Q_Title":"Python: finding uid/gid for a given username/groupname (for os.chown)","A_Content":"  Use the pwd and grp modules:  from pwd import getpwnam    print getpwnam('someuser')[2] # or print getpwnam('someuser').pw_uid      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/826082/python-finding-uid-gid-for-a-given-username-groupname-for-os-chown","A_Votes":"92","_type":"dict","isAccepted":"Yes","Q_Content":"    What's a good way to find the uid/gid for a given username or groupname using Python? I need to set file ownership with os.chown and need the integer ids instead of the alphabetic.  [Quick note]: getpwnam works great but is not available on windows, so here's some code that creates stubs to allow you to run the same code on windows and unix.  try:     from pwd import getpwnam except:     getpwnam = lambda x: (0,0,0)     os.chown = lambda x, y, z: True     os.chmod = lambda x, y: True     os.fchown = os.chown     os.fchmod = os.chmod      ","Q_Votes":"62"},{"Q_Title":"Find the column name which has the maximum value for each row","A_Content":"  You can use idxmax with axis=1 to find the column with the greatest value on each row:  >>> df.idxmax(axis=1) 0    Communications 1          Business 2    Communications 3    Communications 4          Business dtype: object   To create the new column 'Max', use df['Max'] = df.idxmax(axis=1).  To find the row index at which the maximum value occurs in each column, use df.idxmax() (or equivalently df.idxmax(axis=0)).     ","Language":"Python","Tags":["python","pandas","dataframe","max"],"URL":"https://stackoverflow.com/questions/29919306/find-the-column-name-which-has-the-maximum-value-for-each-row","A_Votes":"84","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a DataFrame like this one:  In [7]: frame.head() Out[7]: Communications and Search   Business    General Lifestyle 0   0.745763    0.050847    0.118644    0.084746 0   0.333333    0.000000    0.583333    0.083333 0   0.617021    0.042553    0.297872    0.042553 0   0.435897    0.000000    0.410256    0.153846 0   0.358974    0.076923    0.410256    0.153846   In here, I want to ask how to get column name which has maximum value for each row, the desired output is like this:  In [7]:     frame.head()     Out[7]:     Communications and Search   Business    General Lifestyle   Max     0   0.745763    0.050847    0.118644    0.084746           Communications      0   0.333333    0.000000    0.583333    0.083333           Business       0   0.617021    0.042553    0.297872    0.042553           Communications      0   0.435897    0.000000    0.410256    0.153846           Communications      0   0.358974    0.076923    0.410256    0.153846           Business       ","Q_Votes":"62"},{"Q_Title":"Find the column name which has the maximum value for each row","A_Content":"  And if you want to produce a column containing the name of the column with the maximum value but considering only a subset of columns then you use a variation of @ajcr's answer:  df['Max'] = df[['Communications','Business']].idxmax(axis=1)      ","Language":"Python","Tags":["python","pandas","dataframe","max"],"URL":"https://stackoverflow.com/questions/29919306/find-the-column-name-which-has-the-maximum-value-for-each-row","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I have a DataFrame like this one:  In [7]: frame.head() Out[7]: Communications and Search   Business    General Lifestyle 0   0.745763    0.050847    0.118644    0.084746 0   0.333333    0.000000    0.583333    0.083333 0   0.617021    0.042553    0.297872    0.042553 0   0.435897    0.000000    0.410256    0.153846 0   0.358974    0.076923    0.410256    0.153846   In here, I want to ask how to get column name which has maximum value for each row, the desired output is like this:  In [7]:     frame.head()     Out[7]:     Communications and Search   Business    General Lifestyle   Max     0   0.745763    0.050847    0.118644    0.084746           Communications      0   0.333333    0.000000    0.583333    0.083333           Business       0   0.617021    0.042553    0.297872    0.042553           Communications      0   0.435897    0.000000    0.410256    0.153846           Communications      0   0.358974    0.076923    0.410256    0.153846           Business       ","Q_Votes":"62"},{"Q_Title":"Find the column name which has the maximum value for each row","A_Content":"  You could apply on dataframe and get argmax() of each row via axis=1  In [144]: df.apply(lambda x: x.argmax(), axis=1) Out[144]: 0    Communications 1          Business 2    Communications 3    Communications 4          Business dtype: object     Here's a benchmark to compare how slow apply method is to idxmax() for len(df) ~ 20K  In [146]: %timeit df.apply(lambda x: x.argmax(), axis=1) 1 loops, best of 3: 479 ms per loop  In [147]: %timeit df.idxmax(axis=1) 10 loops, best of 3: 47.3 ms per loop      ","Language":"Python","Tags":["python","pandas","dataframe","max"],"URL":"https://stackoverflow.com/questions/29919306/find-the-column-name-which-has-the-maximum-value-for-each-row","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a DataFrame like this one:  In [7]: frame.head() Out[7]: Communications and Search   Business    General Lifestyle 0   0.745763    0.050847    0.118644    0.084746 0   0.333333    0.000000    0.583333    0.083333 0   0.617021    0.042553    0.297872    0.042553 0   0.435897    0.000000    0.410256    0.153846 0   0.358974    0.076923    0.410256    0.153846   In here, I want to ask how to get column name which has maximum value for each row, the desired output is like this:  In [7]:     frame.head()     Out[7]:     Communications and Search   Business    General Lifestyle   Max     0   0.745763    0.050847    0.118644    0.084746           Communications      0   0.333333    0.000000    0.583333    0.083333           Business       0   0.617021    0.042553    0.297872    0.042553           Communications      0   0.435897    0.000000    0.410256    0.153846           Communications      0   0.358974    0.076923    0.410256    0.153846           Business       ","Q_Votes":"62"},{"Q_Title":"Is there a Python equivalent to Ruby symbols?","A_Content":"  No, python doesn't have a symbol type.  However string literals are interned by default and other strings can be interned using the intern function. So using string literals as keys in dictionaries is not less performant than using symbols in ruby.     ","Language":"Python","Tags":["python","ruby","dictionary","symbols","language-comparisons"],"URL":"https://stackoverflow.com/questions/3743532/is-there-a-python-equivalent-to-ruby-symbols","A_Votes":"66","_type":"dict","isAccepted":"Yes","Q_Content":"    Is there a Python equivalent to Ruby symbols?    If so then what is it? If not then are we stuck with using strings as our keys in dictionaries only?      ","Q_Votes":"62"},{"Q_Title":"Is there a Python equivalent to Ruby symbols?","A_Content":"  As others have said, there is no symbol in Python, but strings work well.  To avoid quoting strings as keys, use the dict() constructor syntax:  d = dict(     a = 1,     b = 2,     c = \"Hello there\",     )      ","Language":"Python","Tags":["python","ruby","dictionary","symbols","language-comparisons"],"URL":"https://stackoverflow.com/questions/3743532/is-there-a-python-equivalent-to-ruby-symbols","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    Is there a Python equivalent to Ruby symbols?    If so then what is it? If not then are we stuck with using strings as our keys in dictionaries only?      ","Q_Votes":"62"},{"Q_Title":"Is there a Python equivalent to Ruby symbols?","A_Content":"  Also for those interested: symbols in Ruby when used in a hash are very similar to empty objects in python. For example you could do:  some_var = object()   and then set a dictionary key as some_var:  some_dict = { some_var : 'some value' }   and then do a standard retrieval:  some_dict[some_var]   However, as sepp2k noted there is no performance benefit in doing this. In fact I did a quick test and noted little to no performance boost:   a, b, c, d, e = [object() for _ in range(5)] dict_symbols = {a : 'a', b : 'b', c : 'c', d : 'd', e : 'e'} dict_strings = {'a' : 'a', 'b' : 'b', 'c' : 'c', 'd' : 'd', 'e' : 'e'}  def run_symbols():     for key in dict_symbols.keys():         dict_symbols[key]  def run_strings():     for key in dict_strings.keys():         dict_strings[key]   Speed tested in ipython:  In [3]: %timeit run_symbols 10000000 loops, best of 3: 33.2 ns per loop  In [4]: %timeit run_strings 10000000 loops, best of 3: 28.3 ns per loop   So in my case the 'symbols' run slower! (for fun numbers, not accurate). However it is to note that there are probably memory advantages to doing it this way. If you don't care about the key type objects have a smaller footprint than strings.   import sys sys.getsizeof('some_var') # 45 some_var = object()  sys.getsizeof(some_var) # 0   Although that raises the question of how python treats the memory of the variable name some_var.      ","Language":"Python","Tags":["python","ruby","dictionary","symbols","language-comparisons"],"URL":"https://stackoverflow.com/questions/3743532/is-there-a-python-equivalent-to-ruby-symbols","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    Is there a Python equivalent to Ruby symbols?    If so then what is it? If not then are we stuck with using strings as our keys in dictionaries only?      ","Q_Votes":"62"},{"Q_Title":"Is there a Python equivalent to Ruby symbols?","A_Content":"   No, there is no equivalent. No you can use every hashable object as dictionary key.      ","Language":"Python","Tags":["python","ruby","dictionary","symbols","language-comparisons"],"URL":"https://stackoverflow.com/questions/3743532/is-there-a-python-equivalent-to-ruby-symbols","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Is there a Python equivalent to Ruby symbols?    If so then what is it? If not then are we stuck with using strings as our keys in dictionaries only?      ","Q_Votes":"62"},{"Q_Title":"Is there a Python equivalent to Ruby symbols?","A_Content":"  Not as a first-class type but there does exist https://pypi.python.org/pypi/SymbolType.     ","Language":"Python","Tags":["python","ruby","dictionary","symbols","language-comparisons"],"URL":"https://stackoverflow.com/questions/3743532/is-there-a-python-equivalent-to-ruby-symbols","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is there a Python equivalent to Ruby symbols?    If so then what is it? If not then are we stuck with using strings as our keys in dictionaries only?      ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  Funny you brought this up, I just had the exact same problem. I solved it eventually, but I'm still unsure as to what caused it.  Try checking your bin/pip and bin/activate scripts. In bin/pip, look at the shebang. Is it correct? If not, correct it. Then on line ~42 in your bin/activate, check to see if your virtualenv path is right. It'll look something like this  VIRTUAL_ENV=\"/Users/me/path/to/virtual/environment\"   If it's wrong, correct it, deactivate, then . bin/activate, and if our mutual problem had the same cause, it should work. If it still doesn't, you're on the right track, anyway. I went through the same problem solving routine as you did, which piping over and over, following the stack trace, etc.  Make absolutely sure that  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   is what you want, and not referring to another similarly-named test project (I had that problem, and have no idea how it started. My suspicion is running multiple virtualenvs at the same time).  If none of this works, a temporary solution may be to, as Joe Holloway said,     Just run the virtualenv's pip with its full path (i.e. don't rely on searching the executable path) and you don't even need to activate the environment. It will do the right thing.   Perhaps not ideal, but it ought to work in a pinch.  Link to my original question:  VirtualEnv/Pip trying to install packages globally     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"63","_type":"dict","isAccepted":"Yes","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  For me this was not a pip or virtualenv problem. It was a python problem. I had set my $PYTHONPATH manually in ~/.bash_profile (or ~/.bashrc) after following some tutorial online. This manually set $PYTHONPATH was available in the virtualenv as it probably should be allowed.  Additionally add2virtualenv was not adding my project path to my $PYTHONPATH for some reason within the virtualenv.  Just some forking paths for those who might still be stuck! Cheers!     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  I hit into the same issue while installing a python package from within a virtualenv. The root cause in my case was different. From within the virtualenv, I was (out of habit on Ubuntu), doing:  sudo easy_install -Z <package>   This caused the bin/pip shebang to be ignored and it used the root's non virtualenv python to install it in the global site-packages. Since we have a virtual environment, we should install the package without \"sudo\"     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  I had the same problem, I solved it by removing venv directory and recreating it!  deactivate (if venv is activated first deactivate it) rm -rf venv virtualenv -p python3 venv . ENV/bin/activate pip3 install -r requirements.txt   Now everything works like a charm.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  I had this problem too.  Calling pip install <package_name> from the /bin directory within my Python 3.3 virtual environment on my Mavericks Mac caused the Python package to be installed in the Python 2.7 global site packages directory.  This was despite the fact that my $PATH started with the directory containing pip.  Weird. This doesn't happen on CentOS.  For me, the solution was calling pip3 instead of pip.  When I had installed pip within the virtual environment via ez_setup, three \"pip\" executables had been installed in the /bin directory - pip, pip3, and pip3.3. Curiously, all three files were exactly the same.  Calling pip3 install <package_name> caused the Python package to be installed correctly into the local site-packages directory.  Calling pip with the full pathname into the virtual environment also worked correctly.  I'd be interested to know why my Mac isn't using $PATH the way I would expect it to.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  I had a similar problem after updating to pip==8.0.0. Had to resort to debugging pip to trace out the bad path.  As it turns out my profile directory had a distutils configuration file with some empty path values. This was causing all packages to be installed to the same root directory instead of the appropriate virtual environment (in my case /lib/site-packages).  I'm unsure how the config file got there or how it had empty values but it started after updating pip.  In case anyone else stumbles upon this same problem, simply deleting the file ~/.pydistutils.cfg (or removing the empty config path) fixed the problem in my environment because pip went back to the default distributed configuration.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  The first thing to check is which location pip is resolving to:  which pip   if you are in a virtualenv you would expect this to give you something like:     /path/to/virtualenv/.name_of_virtualenv/bin/pip   However it may be the case that it's resolving to your system pip for some reason. For example you may see this from within your virtualenv (this is bad):     /usr/local/bin/pip   (or anything that isn't in your virtualenv path).   To solve this check your pipconfig in:  ~/.pipconf ~/.conf/pip /etc/pip.conf   and make sure that there is nothing that is coercing your Python path or your pip path (this fixed it for me).  Then try starting a new terminal and rebuild your virtualenv (delete then create it again)     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  Came across the same issue today. I simply reinstalled pip globally with sudo easy_install pip (OSX/ Max), then created my virtualenv again with sudo virtualenv nameOfVEnv. Then after activating the new virtualenv the pip command worked as expected.  I don't think I used sudo on the first virtualenv creation and that may have been the reason for not having access to pip from within the virtualenv, I was able to get access to pip2 before this fix though which was odd.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  Here are some practices that could avoid headaches when using Virtual Environments:   Create a folder for your projects. Create your Virtualenv projects inside of this folder.  After activating the environment of your project, never use \"sudo pip install package\". After finishing your work, always \"deactivate\" your environment. Avoid renaming your project folder.      For a better representation of this practices, here is a simulation:    creating a folder for your projects/environments  $ mkdir venv   creating environment  $ cd venv/   $ virtualenv google_drive New python executable in google_drive/bin/python Installing setuptools, pip...done.   activating environment  $ source google_drive/bin/activate   installing packages  (google_drive) $ pip install PyDrive Downloading/unpacking PyDrive Downloading PyDrive-1.3.1-py2-none-any.whl ... ... ...     Successfully installed PyDrive PyYAML google-api-python-client oauth2client six uritemplate httplib2 pyasn1 rsa pyasn1-modules Cleaning up...   package available inside the environment  (google_drive) $ python Python 2.7.6 (default, Oct 26 2016, 20:30:19)  [GCC 4.8.4] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> >>> import pydrive.auth >>>   >>> gdrive = pydrive.auth.GoogleAuth() >>>   deactivate environment  (google_drive) $ deactivate   $    package NOT AVAILABLE outside the environment  (google_drive) $ python Python 2.7.6 (default, Oct 26 2016, 20:32:10)  [GCC 4.8.4] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> >>> import pydrive.auth Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ImportError: No module named pydrive.auth >>>      Notes:  Why not sudo?      Virtualenv creates a whole new environment for you, defining $PATH and some other variables and settings. When you use sudo pip install package, you are running Virtualenv as root, escaping the whole environment which was created, and then, installing  the package on global site-packages, and not inside the project folder where you have a Virtual Environment, although you have activated the environment.   If you rename the folder of your project (as mentioned in the accepted answer)...     ...you'll have to adjust some variables from some files inside the bin directory of your project.      For example:      bin/pip, line 1 (She Bang)      bin/activate, line 42 (VIRTUAL_ENV)      ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  I had this problem. It turned out there was a space in one of my folder names that caused the problem. I removed the space, deleted and reinstantiated using venv, and all was well.      ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  This problem occurs when create a virtualenv instance and then change the parent folder name.      ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  None of the above solutions worked for me.   My venv was active.  pip -V and which pip gave me the correct virtualenv path, but when I pip install-ed packages with activated venv, my pip freeze stayed empty.   All the environment variables were correct too.  Finally, I just changed pip and removed virtualenv:  easy_install pip==7.0.2  pip install pip==10  sudo pip uninstall virtualenv   Reinstall venv:  sudo pip install virtualenv   Create venv:  python -m virtualenv venv_name_here   And all packages installed correctly into my venv again.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  I had this problem too. Calling sudo pip install caused Python packages to be installed in the global site-packages diretory and calling pip install just worked fine. So no use sudo in virtualenv.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  The same problem. Python3.5 and pip 8.0.2 installed from Linux rpm's.  I did not find a primary cause and cannot give a proper answer. It looks like there are multiple possible causes.  However, I hope I can help with sharing my observation and a workaround.   pyvenv with --system-site-packages   ./bin does not contain pip, pip is available from system site packages packages are installed globally (BUG?)  pyvenv without --system-site-packages   pip gets installed into ./bin, but it's a different version (from ensurepip) packages are installed within the virtual environment (OK)    Obvious workaround for pyvenv with --system-site-packages:   create it without the --system-site-packages option change include-system-site-packages = false to true in pyvenv.cfg file      ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  It's also worth checking that you didn't modify somehow the path to your virtualenv.   In that case the first line in bin/pip (and the rest of the executables) would have an incorrect path.  You can either edit these files and fix the path or remove and install again the virtualenv.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  For Python 3ers  Try updating. I had this exact same problem and tried Chases' answer, however no success. The quickest way to refactor this is to update your Python Minor / Patch version if possible. I noticed that I was running 3.5.1 and updated to 3.5.2. Pyvenv once again works.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  This happened to me when I created the virtualenv in the wrong location. I then thought I could move the dir to another location without it mattering. It mattered.  mkdir ~/projects virtualenv myenv cd myenv git clone [my repository]   Oh crap, I forgot to cd into projects before creating the virtualenv and cloning the rep. Oh well, I'm too lazy to destroy and recreate. I'll just move the dir with no issues.  cd ~ mv myenv projects cd projects/myenv/myrepo pip install -r requirements   Nope, wants more permissions, what the? I thought it was strange but SUDO AWAY! It then installed the packages into a global location.  The lesson I learned was, just delete the virtualenv dir. Don't move it.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  Had this issue after installing Divio: it had changed my PATH or environment in some way, as it launches a terminal.    The solution in this case was just to do source ~/.bash_profile which should already be setup to get you back to your original pyenv/pyenv-virtualenv state.     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  Somehow a setup.cfg file with a prefix=\"\" in the project folder  running pip install on the virtualenv outside the porject folder worked so from the inside it was telling pip to use an empty prefix  which defaults to \"/\"  removing the file fixed it     ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"pip installing in global site-packages instead of virtualenv","A_Content":"  It happened to me when I installed virtualenv with --python=python3.6 flag but afterwards tried to use pip2 install. Creating virtualenv with flag of the version that you'll use solves permission problems. To check, try which pip or which pip2 or which pip3 (depends on your choice). If any pip you use shows path not to venv here is your problem.      ","Language":"Python","Tags":["python","macos","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/20952797/pip-installing-in-global-site-packages-instead-of-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Using pip to install a package in a virtualenv causes the package to be installed in the global site-packages folder instead of the one in the virtualenv folder. Here's how I set up Python3 and virtualenv on OS X Mavericks (10.9.1):  I installed python3 using Homebrew:  ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\" brew install python3 --with-brewed-openssl   Changed the $PATH variable in .bash_profile; added the following line:  export PATH=/usr/local/bin:$PATH   Running which python3 returns /usr/local/bin/python3 (after restarting the shell).  Note: which python3 still returns /usr/bin/python though.  Installed virtualenv using pip3:  pip3 install virtualenv   Next, create a new virtualenv and activate it:  virtualenv testpy3 -p python3 cd testpy3 source bin/activate   Note: if I don't specify -p python3, pip will be missing from the bin folder in the virtualenv.  Running which pip and which pip3 both return the virtualenv folder:  /Users/kristof/VirtualEnvs/testpy3/bin/pip3   Now, when I try to install e.g. Markdown using pip in the activated virtualenv, pip will install in the global site-packages folder instead of the site-packages folder of the virtualenv.  pip install markdown   Running pip list returns:  Markdown (2.3.1) pip (1.4.1) setuptools (2.0.1) virtualenv (1.11)   Contents of /Users/kristof/VirtualEnvs/testpy3/lib/python3.3/site-packages:  __pycache__/ _markerlib/ easy_install.py pip/ pip-1.5.dist-info/ pkg_resources.py setuptools/ setuptools-2.0.2.dist-info/   Contents of /usr/local/lib/python3.3/site-packages:  Markdown-2.3.1-py3.3.egg-info/ __pycache__/ easy-install.pth markdown/ pip-1.4.1-py3.3.egg/ setuptools-2.0.1-py3.3.egg setuptools.pth virtualenv-1.11-py3.3.egg-info/ virtualenv.py virtualenv_support/   As you can see, the global site-packages folder contains Markdown, the virtualenv folder doesn't.  Note: I had Python2 and Python3 installed before on a different VM (followed these instructions) and had the same issue with Python3; installing packages in a Python2 based virtualenv worked flawlessly though.  Any tips, hints, … would be very much appreciated.     ","Q_Votes":"62"},{"Q_Title":"What is the __dict__.__dict__ attribute of a Python class?","A_Content":"  First of all A.__dict__.__dict__ is  different from A.__dict__['__dict__'], and the former doesn't exist. The latter is the __dict__ attribute that the instances of the class would have. It's a descriptor object that returns the internal dictionary of attributes for the specific instance. In short, the __dict__ attribute of an object can't be stored in object's __dict__, so it's accessed through a descriptor defined in the class.  To understand this, you'd have to read the documentation of the descriptor protocol.  The short version:   For an instance of class A, access to instance.__dict__ is provided by A.__dict__['__dict__'] which is the same as vars(A)['__dict__']. For the class A, access to A.__dict__ is provided by type.__dict__['__dict__'] (in theory) which is the same as vars(type)['__dict__'].     The long version:  Both classes and objects provide access to attributes both through the attribute operator (implemented via the class or metaclass's __getattribute__), and the __dict__ attribute/protocol which is used by vars(ob).  For normal objects, the __dict__ object creates a separate dict object, which stores the attributes, and __getattribute__ first tries to access it and get the attributes from there (before attempting to look for the attribute in the class by utilizing the descriptor protocol, and before calling __getattr__). The __dict__ descriptor on the class implements the access to this dictionary.   x.name is equivalent to trying those in order: x.__dict__['name'], type(x).name.__get__(x, type(x)), type(x).name x.__dict__ does the same but skips the first one for obvious reasons   As it's impossible for the __dict__ of instance to be stored in __dict__ of the instance, it is accessed through the descriptor protocol directly instead, and is stored in a special field in the instance.  A similar scenario is true for classes, although their __dict__ is a special proxy object that pretends to be a dictionary (but might not be internally), and doesn't allow you to change it or replace it with another one. This proxy allows you, among all else, to access the attributes of a class that are specific to it, and not defined in one of its bases.  By default, a vars(cls) of an empty class carries three descriptors - __dict__ for storing the attributes of the instances, __weakref__ which is used internally by weakref, and the docstring of the class. The first two might be gone if you define __slots__. Then you wouldn't have __dict__ and __weakref__ attributes, but instead you'd have a single class attribute for each slot. The attributes of the instance then wouldn't be stored in a dictionary, and access to them will be provided by the respective descriptors in the class.    And lastly, the inconsistency that A.__dict__ is different from A.__dict__['__dict__'] is because the attribute __dict__ is, by exception, never looked up in vars(A), so what is true for it isn't true for practically any other attribute you'd use. For example, A.__weakref__ is the same thing as A.__dict__['__weakref__']. If this inconsistency didn't exist, using A.__dict__ would not work, and you'd have to always use vars(A) instead.     ","Language":"Python","Tags":["python","class","metaprogramming","magic-methods"],"URL":"https://stackoverflow.com/questions/4877290/what-is-the-dict-dict-attribute-of-a-python-class","A_Votes":"84","_type":"dict","isAccepted":"Yes","Q_Content":"    >>> class A(object): pass ...  >>> A.__dict__ <dictproxy object at 0x173ef30> >>> A.__dict__.__dict__ Traceback (most recent call last):   File \"<string>\", line 1, in <fragment> AttributeError: 'dictproxy' object has no attribute '__dict__' >>> A.__dict__.copy() {'__dict__': <attribute '__dict__' of 'A' objects> ... } >>> A.__dict__['__dict__'] <attribute '__dict__' of 'A' objects> # What is this object?   If I do A.something = 10, this goes into A.__dict__. What is this <attribute '__dict__' of 'A' objects> found in A.__dict__.__dict__, and when does it contain something?     ","Q_Votes":"62"},{"Q_Title":"What is the __dict__.__dict__ attribute of a Python class?","A_Content":"  Since A.__dict__ is a dictionary storing A attributes, A.__dict__['__dict__'] is the direct reference to that same A.__dict__ attribute.  A.__dict__ contains a (kind-of) reference to itself. The \"kind-of\" part is why the expression A.__dict__ returns a dictproxy instead of a normal dict.  >>> class B(object): ...     \"Documentation of B class\" ...     pass ... >>> B.__doc__ 'Documentation of B class' >>> B.__dict__ <dictproxy object at 0x00B83590> >>> B.__dict__['__doc__'] 'Documentation of B class'      ","Language":"Python","Tags":["python","class","metaprogramming","magic-methods"],"URL":"https://stackoverflow.com/questions/4877290/what-is-the-dict-dict-attribute-of-a-python-class","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    >>> class A(object): pass ...  >>> A.__dict__ <dictproxy object at 0x173ef30> >>> A.__dict__.__dict__ Traceback (most recent call last):   File \"<string>\", line 1, in <fragment> AttributeError: 'dictproxy' object has no attribute '__dict__' >>> A.__dict__.copy() {'__dict__': <attribute '__dict__' of 'A' objects> ... } >>> A.__dict__['__dict__'] <attribute '__dict__' of 'A' objects> # What is this object?   If I do A.something = 10, this goes into A.__dict__. What is this <attribute '__dict__' of 'A' objects> found in A.__dict__.__dict__, and when does it contain something?     ","Q_Votes":"62"},{"Q_Title":"What is the __dict__.__dict__ attribute of a Python class?","A_Content":"  Lets do some exploring!  >>> A.__dict__['__dict__'] <attribute '__dict__' of 'A' objects>   I wonder what that is?  >>> type(A.__dict__['__dict__']) <type 'getset_descriptor'>   What attributes does a getset_descriptor object have?  >>> type(A.__dict__[\"__dict__\"]).__dict__ <dictproxy object at 0xb7efc4ac>   By making a copy of that dictproxy we can find some interesting attributes, specifically __objclass__ and __name__.  >>> A.__dict__['__dict__'].__objclass__, A.__dict__['__dict__'].__name__ (<class '__main__.A'>, '__dict__')   So __objclass__ is a reference to A and __name__ is just the string '__dict__', name of an attribute perhaps?  >>> getattr(A.__dict__['__dict__'].__objclass__, A.__dict__['__dict__'].__name__) == A.__dict__ True   There we have it!  A.__dict__['__dict__'] is an object that can refer back to A.__dict__.     ","Language":"Python","Tags":["python","class","metaprogramming","magic-methods"],"URL":"https://stackoverflow.com/questions/4877290/what-is-the-dict-dict-attribute-of-a-python-class","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    >>> class A(object): pass ...  >>> A.__dict__ <dictproxy object at 0x173ef30> >>> A.__dict__.__dict__ Traceback (most recent call last):   File \"<string>\", line 1, in <fragment> AttributeError: 'dictproxy' object has no attribute '__dict__' >>> A.__dict__.copy() {'__dict__': <attribute '__dict__' of 'A' objects> ... } >>> A.__dict__['__dict__'] <attribute '__dict__' of 'A' objects> # What is this object?   If I do A.something = 10, this goes into A.__dict__. What is this <attribute '__dict__' of 'A' objects> found in A.__dict__.__dict__, and when does it contain something?     ","Q_Votes":"62"},{"Q_Title":"What is the __dict__.__dict__ attribute of a Python class?","A_Content":"  You can try the following simple example to understand more of this:  >>> class A(object): pass ...  >>> a = A() >>> type(A) <type 'type'> >>> type(a) <class '__main__.A'> >>> type(a.__dict__) <type 'dict'> >>> type(A.__dict__) <type 'dictproxy'> >>> type(type.__dict__) <type 'dictproxy'> >>> type(A.__dict__['__dict__']) <type 'getset_descriptor'> >>> type(type.__dict__['__dict__']) <type 'getset_descriptor'> >>> a.__dict__ == A.__dict__['__dict__'].__get__(a) True >>> A.__dict__ == type.__dict__['__dict__'].__get__(A) True >>> a.__dict__ == type.__dict__['__dict__'].__get__(A)['__dict__'].__get__(a) True   From the above example, it seems that class objects attributes are stored by their class, class's attributes are stored by their class, which are metaclasses. This is also validated by:  >>> a.__dict__ == A.__getattribute__(a, '__dict__') True >>> A.__dict__ == type.__getattribute__(A, '__dict__') True      ","Language":"Python","Tags":["python","class","metaprogramming","magic-methods"],"URL":"https://stackoverflow.com/questions/4877290/what-is-the-dict-dict-attribute-of-a-python-class","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    >>> class A(object): pass ...  >>> A.__dict__ <dictproxy object at 0x173ef30> >>> A.__dict__.__dict__ Traceback (most recent call last):   File \"<string>\", line 1, in <fragment> AttributeError: 'dictproxy' object has no attribute '__dict__' >>> A.__dict__.copy() {'__dict__': <attribute '__dict__' of 'A' objects> ... } >>> A.__dict__['__dict__'] <attribute '__dict__' of 'A' objects> # What is this object?   If I do A.something = 10, this goes into A.__dict__. What is this <attribute '__dict__' of 'A' objects> found in A.__dict__.__dict__, and when does it contain something?     ","Q_Votes":"62"},{"Q_Title":"Python argparse mutual exclusive group","A_Content":"  add_mutually_exclusive_group doesn't make an entire group mutually exclusive. It makes options within the group mutually exclusive.  What you're looking for is subcommands. Instead of prog [ -a xxxx | [-b yyy -c zzz]], you'd have:  prog    command 1      -a: ...   command 2     -b: ...     -c: ...   To invoke with the first set of arguments:  prog command_1 -a xxxx   To invoke with the second set of arguments:  prog command_2 -b yyyy -c zzzz   You can also set the sub command arguments as positional.  prog command_1 xxxx   Kind of like git or svn:  git commit -am git merge develop   Working Example  # create the top-level parser parser = argparse.ArgumentParser(prog='PROG') parser.add_argument('--foo', action='store_true', help='help for foo arg.') subparsers = parser.add_subparsers(help='help for subcommand')  # create the parser for the \"command_1\" command parser_a = subparsers.add_parser('command_1', help='command_1 help') parser_a.add_argument('a', type=str, help='help for bar, positional')  # create the parser for the \"command_2\" command parser_b = subparsers.add_parser('command_2', help='help for command_2') parser_b.add_argument('-b', type=str, help='help for b') parser_b.add_argument('-c', type=str, action='store', default='', help='test')   Test it  >>> parser.print_help() usage: PROG [-h] [--foo] {command_1,command_2} ...  positional arguments:   {command_1,command_2}                         help for subcommand     command_1           command_1 help     command_2           help for command_2  optional arguments:   -h, --help            show this help message and exit   --foo                 help for foo arg. >>>  >>> parser.parse_args(['command_1', 'working']) Namespace(a='working', foo=False) >>> parser.parse_args(['command_1', 'wellness', '-b x']) usage: PROG [-h] [--foo] {command_1,command_2} ... PROG: error: unrecognized arguments: -b x   Good luck.     ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/17909294/python-argparse-mutual-exclusive-group","A_Votes":"75","_type":"dict","isAccepted":"Yes","Q_Content":"    What I need is:  pro [-a xxx | [-b yyy -c zzz]]   I tried this but does not work. Could someone help me out?  group= parser.add_argument_group('Model 2') group_ex = group.add_mutually_exclusive_group() group_ex.add_argument(\"-a\", type=str, action = \"store\", default = \"\", help=\"test\") group_ex_2 = group_ex.add_argument_group(\"option 2\") group_ex_2.add_argument(\"-b\", type=str, action = \"store\", default = \"\", help=\"test\") group_ex_2.add_argument(\"-c\", type=str, action = \"store\", default = \"\", help=\"test\")   Thanks!     ","Q_Votes":"62"},{"Q_Title":"Python argparse mutual exclusive group","A_Content":"  While Jonathan's answer is perfectly fine for complex options, there is a very simple solution which will work for the simple cases, e.g. 1 option excludes 2 other options like in   command [- a xxx | [ -b yyy | -c zzz ]]    or even as in the original question:  pro [-a xxx | [-b yyy -c zzz]]   Here is how I would do it:  parser = argparse.ArgumentParser()  # group 1  parser.add_argument(\"-q\", \"--query\", help=\"query\", required=False) parser.add_argument(\"-f\", \"--fields\", help=\"field names\", required=False)  # group 2  parser.add_argument(\"-a\", \"--aggregation\", help=\"aggregation\",                     required=False)   I am using here options given to a command line wrapper for querying a mongodb. The collection instance can either call the method aggregate or the method find with to optional arguments query and fields, hence you see why the first two arguments are compatible and the last one isn't.   So now I run parser.parse_args() and check it's content:  args = parser().parse_args()  print args.aggregation if args.aggregation and (args.query or args.fields):     print \"-a and -q|-f are mutually exclusive ...\"     sys.exit(2)   Of course, this little hack is only working for simple cases and it would become a nightmare to check all the possible options if you have many mutually exclusive options and groups. In that case you should break your options in to command groups like Jonathan suggested.     ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/17909294/python-argparse-mutual-exclusive-group","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    What I need is:  pro [-a xxx | [-b yyy -c zzz]]   I tried this but does not work. Could someone help me out?  group= parser.add_argument_group('Model 2') group_ex = group.add_mutually_exclusive_group() group_ex.add_argument(\"-a\", type=str, action = \"store\", default = \"\", help=\"test\") group_ex_2 = group_ex.add_argument_group(\"option 2\") group_ex_2.add_argument(\"-b\", type=str, action = \"store\", default = \"\", help=\"test\") group_ex_2.add_argument(\"-c\", type=str, action = \"store\", default = \"\", help=\"test\")   Thanks!     ","Q_Votes":"62"},{"Q_Title":"Python argparse mutual exclusive group","A_Content":"  There is a python patch (in development) that would allow you to do this. http://bugs.python.org/issue10984  The idea is to allow overlapping mutually exclusive groups.  So usage might look like:  pro [-a xxx | -b yyy] [-a xxx | -c zzz]   Changing the argparse code so you can create two groups like this was the easy part.  Changing the usage formatting code required writing a custom HelpFormatter.  In argparse, action groups don't affect the parsing.  They are just a help formatting tool.  In the help, mutually exclusive groups only affect the usage line.  When parsing, the parser uses the mutually exclusive groups to construct a dictionary of potential conflicts (a can't occur with b or c, b can't occur with a, etc), and then raises an error if a conflict arises.  Without that argparse patch, I think your best choice is to test the namespace produced by parse_args yourself (e.g. if both a and b have nondefault values), and raise your own error.  You could even use the parser's own error mechanism.  parser.error('custom error message')      ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/17909294/python-argparse-mutual-exclusive-group","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What I need is:  pro [-a xxx | [-b yyy -c zzz]]   I tried this but does not work. Could someone help me out?  group= parser.add_argument_group('Model 2') group_ex = group.add_mutually_exclusive_group() group_ex.add_argument(\"-a\", type=str, action = \"store\", default = \"\", help=\"test\") group_ex_2 = group_ex.add_argument_group(\"option 2\") group_ex_2.add_argument(\"-b\", type=str, action = \"store\", default = \"\", help=\"test\") group_ex_2.add_argument(\"-c\", type=str, action = \"store\", default = \"\", help=\"test\")   Thanks!     ","Q_Votes":"62"},{"Q_Title":"Filter by property","A_Content":"  Nope.  Django filters operate at the database level, generating SQL.  To filter based on Python properties, you have to load the object into Python to evaluate the property--and at that point, you've already done all the work to load it.     ","Language":"Python","Tags":["python","django","orm"],"URL":"https://stackoverflow.com/questions/1205375/filter-by-property","A_Votes":"50","_type":"dict","isAccepted":"Yes","Q_Content":"    Is it possible to filter by property?  i have a method in my model:  @property def myproperty(self):     [..]   and now i want to filter by this property like:  MyModel.objects.filter(myproperty=[..])   is this somehow possible?     ","Q_Votes":"62"},{"Q_Title":"Filter by property","A_Content":"  I might be misunderstanding your original question, but there is a filter builtin in python.  filtered = filter(myproperty, MyModel.objects)   But it's better to use a list comprehension:  filtered = [x for x in MyModel.objects if x.myproperty()]   or even better, a generator expression:  filtered = (x for x in MyModel.objects if x.myproperty())      ","Language":"Python","Tags":["python","django","orm"],"URL":"https://stackoverflow.com/questions/1205375/filter-by-property","A_Votes":"32","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to filter by property?  i have a method in my model:  @property def myproperty(self):     [..]   and now i want to filter by this property like:  MyModel.objects.filter(myproperty=[..])   is this somehow possible?     ","Q_Votes":"62"},{"Q_Title":"Filter by property","A_Content":"  Looks like using F() with annotations will be my solution to this.  It's not going to filter by @property, since F talks to the databse before objects are brought into python.  But still putting it here as an answer since my reason for wanting filter by property was really wanting to filter objects by the result of simple arithmetic on two different fields.  so, something along the lines of:  companies = Company.objects\\     .annotate(chairs_needed=F('num_employees') - F('num_chairs'))\\     .filter(chairs_needed__lt=4)   rather than defining the property to be:  @property def chairs_needed(self):     return self.num_employees - self.num_chairs   then doing a list comprehension across all objects.     ","Language":"Python","Tags":["python","django","orm"],"URL":"https://stackoverflow.com/questions/1205375/filter-by-property","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to filter by property?  i have a method in my model:  @property def myproperty(self):     [..]   and now i want to filter by this property like:  MyModel.objects.filter(myproperty=[..])   is this somehow possible?     ","Q_Votes":"62"},{"Q_Title":"Filter by property","A_Content":"  Riffing off @TheGrimmScientist's suggested workaround, you can make these \"sql properties\" by defining them on the Manager or the QuerySet, and reuse/chain/compose them:  With a Manager:  class CompanyManager(models.Manager):     def with_chairs_needed(self):         return self.annotate(chairs_needed=F('num_employees') - F('num_chairs'))  class Company(models.Model):     # ...     objects = CompanyManager()  Company.objects.with_chairs_needed().filter(chairs_needed__lt=4)   With a QuerySet:   class CompanyQuerySet(models.QuerySet):     def many_employees(self, n=50):         return self.filter(num_employees__gte=n)      def needs_fewer_chairs_than(self, n=5):         return self.with_chairs_needed().filter(chairs_needed__lt=n)      def with_chairs_needed(self):         return self.annotate(chairs_needed=F('num_employees') - F('num_chairs'))  class Company(models.Model):     # ...     objects = CompanyQuerySet.as_manager()  Company.objects.needs_fewer_chairs_than(4).many_employees()   See https://docs.djangoproject.com/en/1.9/topics/db/managers/ for more.  Note that I am going off the documentation and have not tested the above.      ","Language":"Python","Tags":["python","django","orm"],"URL":"https://stackoverflow.com/questions/1205375/filter-by-property","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to filter by property?  i have a method in my model:  @property def myproperty(self):     [..]   and now i want to filter by this property like:  MyModel.objects.filter(myproperty=[..])   is this somehow possible?     ","Q_Votes":"62"},{"Q_Title":"Filter by property","A_Content":"  PLEASE someone correct me, but I guess I have found a solution, at least for my own case.  I want to work on all those elements whose properties are exactly equal to ... whatever.   But I have several models, and this routine should work for all models. And it does:  def selectByProperties(modelType, specify):     clause = \"SELECT * from %s\" % modelType._meta.db_table      if len(specify) > 0:         clause += \" WHERE \"         for field, eqvalue in specify.items():             clause += \"%s = '%s' AND \" % (field, eqvalue)         clause = clause [:-5]  # remove last AND      print clause     return modelType.objects.raw(clause)   With this universal subroutine, I can select all those elements which exactly equal my dictionary of 'specify' (propertyname,propertyvalue) combinations.  The first parameter takes a (models.Model),   the second a dictionary like: {\"property1\" : \"77\" , \"property2\" : \"12\"}  And it creates an SQL statement like  SELECT * from appname_modelname WHERE property1 = '77' AND property2 = '12'   and returns a QuerySet on those elements.  This is a test function:  from myApp.models import myModel  def testSelectByProperties ():      specify = {\"property1\" : \"77\" , \"property2\" : \"12\"}     subset = selectByProperties(myModel, specify)      nameField = \"property0\"     ## checking if that is what I expected:     for i in subset:         print i.__dict__[nameField],          for j in specify.keys():              print i.__dict__[j],          print    And? What do you think?     ","Language":"Python","Tags":["python","django","orm"],"URL":"https://stackoverflow.com/questions/1205375/filter-by-property","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to filter by property?  i have a method in my model:  @property def myproperty(self):     [..]   and now i want to filter by this property like:  MyModel.objects.filter(myproperty=[..])   is this somehow possible?     ","Q_Votes":"62"},{"Q_Title":"Filter by property","A_Content":"  i know it is an old question, but for the sake of those jumping here i think it is useful to read the question below and the relative answer:  How to customize admin filter in Django 1.4     ","Language":"Python","Tags":["python","django","orm"],"URL":"https://stackoverflow.com/questions/1205375/filter-by-property","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to filter by property?  i have a method in my model:  @property def myproperty(self):     [..]   and now i want to filter by this property like:  MyModel.objects.filter(myproperty=[..])   is this somehow possible?     ","Q_Votes":"62"},{"Q_Title":"Check if List of Objects contain an object with a certain attribute value","A_Content":"  As you can easily see from the documentation, the any() function short-circuits an returns True as soon as a match has been found.  any(x.name == \"t2\" for x in l)      ","Language":"Python","Tags":["python","search","python-3.x"],"URL":"https://stackoverflow.com/questions/9371114/check-if-list-of-objects-contain-an-object-with-a-certain-attribute-value","A_Votes":"102","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to check if my list of objects contain an object with a certain attribute value.   class Test:     def __init__(self, name):         self.name = name  # in main() l = [] l.append(Test(\"t1\")) l.append(Test(\"t2\")) l.append(Test(\"t2\"))   I want a way of checking if list contains an object with name t1 for example. How can it be done? I found https://stackoverflow.com/a/598415/292291,   [x for x in myList if x.n == 30]               # list of all matches any(x.n == 30 for x in myList)                 # if there is any matches [i for i,x in enumerate(myList) if x.n == 30]  # indices of all matches  def first(iterable, default=None):   for item in iterable:     return item   return default  first(x for x in myList if x.n == 30)          # the first match, if any   I dont want to go through the whole list everytime, I just need to know if theres 1 instance  which matches. will first(...) or any(...) or something else do that?     ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  While it's ugly, it appears to work  sudo ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future pip install --upgrade numpy   Note that if you are getting this error for a package other than numpy, (such as lxml) specify that package name instead of numpy at the end of the commnd.  I saw a similar issue someone was having with installing a gem  Ruby Gem install Json fails on Mavericks and Xcode 5.1 - unknown argument: '-multiply_definedsuppress'  This is only a temporary fix, at some point the compiler options will have to be fixed     ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"69","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  The problem is that you are unable to compile.   First, make sure that you have accepted the new Terms and Conditions with Xcode. To do this, just open up xCode and accept.   Then, try installing gcc with   brew install gcc   Finally, try to install Numpy with   pip install numpy   Hope this helps.      ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  If you don't want to use sudo (so permissions and things like that are preserved when using venv), you can add the ARCHFLAGS declaration to your .bash_profile, and run as normal. This worked for me with Mavericks and Xcode 5.1 using with venv:  In ~/.bash_profile:     export ARCHFLAGS=-Wno-error=unused-command-line-argument-hard-error-in-future   Then, just run the command:     pip install --upgrade numpy      ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  I simply had to open XCode and accept the agreement and let it install the tools.  I then went back to PyCharm and installed numpy again with no issues.     ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  For fedora users that are having a similar problem try installing these packeges:  (if not using python3 use python-devel and pip instead of pip3)  sudo dnf install python3-devel sudo dnf install make automake gcc gcc-c++ gcc-gfortran sudo dnf install redhat-rpm-config sudo dnf install subversion   then try  sudo pip3 install numpy      ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  In some cases after OS X upgrades XCode, XCode will require the user (with administrative privileges) to accept a new license. Until the license is accepted, clang and gcc will issue an error when attempting to compile and link code. Or at least python packages.  If you launch XCode and accept the license, the errors no longer appear.   At least, this was the case for me.     ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  If you are running a linux distribution, you may need a C compiler, especially if you see telltale log lines like sh: gcc: command not found.  You can follow the instructions here, which I've summarized below:   Fedora, Red Hat, CentOS, or Scientific Linux  # yum groupinstall 'Development Tools' Debian or Ubuntu Linux  $ sudo apt-get update  $ sudo apt-get install build-essential manpages-dev   Then you can try rerunning:  sudo pip install numpy      ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  For Docker (Alpine) and Python 3.x this worked for me:  RUN apk add make automake gcc g++ subversion python3-dev      ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  The above worked for me only after installing python3-dev.     ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  This means it can't find your C compiler. Try installing the gcc compiler if linking other compiler fails.     ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"Problems with pip install numpy - RuntimeError: Broken toolchain: cannot link a simple C program","A_Content":"  On Fedora 22 this was resolved by updating pip itself: sudo pip install --upgrade pip     ","Language":"Python","Tags":["python","numpy","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/22388519/problems-with-pip-install-numpy-runtimeerror-broken-toolchain-cannot-link-a","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install numpy (and scipy and matplotlib) into a virturalenv.  I keep getting these errors though:  RuntimeError: Broken toolchain: cannot link a simple C program  ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1   I have the command line tools for xcode installed  $ which gcc /usr/bin/gcc $ which cc /usr/bin/cc   I'm on Mac OSX 10.9 Using a brew installed python  Edit Yes, trying to install with pip. The whole traceback is huge (>400 lines)  Here is a section of it:   C compiler: cc -fno-strict-aliasing -fno-common -dynamic -arch x86_64 -arch i386 -g -Os -pipe -fno-common -fno-strict-aliasing -fwrapv -mno-fused-madd -DENABLE_DTRACE -DMACOSX -DNDEBUG -Wall -Wstrict-prototypes -Wshorten-64-to-32 -DNDEBUG -g -fwrapv -Os -Wall -Wstrict-prototypes -DENABLE_DTRACE -arch x86_64 -arch i386 -pipe    compile options: '-Inumpy/core/src/private -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/include -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c'  cc: _configtest.c  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  clang: error: unknown argument: '-mno-fused-madd' [-Wunused-command-line-argument-hard-error-in-future]  clang: note: this will be a hard error (cannot be downgraded to a warning) in the future  failure.  removing: _configtest.c _configtest.o  Traceback (most recent call last):    File \"<string>\", line 17, in <module>    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 192, in <module>      setup_package()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/setup.py\", line 185, in setup_package      configuration=configuration )    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/core.py\", line 169, in setup      return old_setup(**new_attr)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/core.py\", line 152, in setup      dist.run_commands()    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 953, in run_commands      self.run_command(cmd)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/egg_info.py\", line 10, in run      self.run_command(\"build_src\")    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/cmd.py\", line 326, in run_command      self.distribution.run_command(command)    File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py\", line 972, in run_command      cmd_obj.run()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 153, in run      self.build_sources()    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 164, in build_sources      self.build_library_sources(*libname_info)    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 299, in build_library_sources      sources = self.generate_sources(sources, (lib_name, build_info))    File \"/Users/bdhammel/Documents/research_programming/julia_env/build/numpy/numpy/distutils/command/build_src.py\", line 386, in generate_sources      source = func(extension, build_dir)    File \"numpy/core/setup.py\", line 674, in get_mathlib_info      raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")  RuntimeError: Broken toolchain: cannot link a simple C program      ","Q_Votes":"62"},{"Q_Title":"How can I save an image with PIL?","A_Content":"  The error regarding the file extension has been handled, you either use bmp (without the dot), or pass the output name with the extension already. Now to handle the error you need to properly modify your data in frequency domain to be saved as an integer image, PIL is telling you that it doesn't accept float data to save as bmp.  Here is a suggestion (with other minor modifications, like using fftshift and numpy.array instead of numpy.asarray) for doing the conversion for proper visualization:  import sys import numpy from PIL import Image  img = Image.open(sys.argv[1]).convert('L')  im = numpy.array(img) fft_mag = numpy.abs(numpy.fft.fftshift(numpy.fft.fft2(im)))  visual = numpy.log(fft_mag) visual = (visual - visual.min()) / (visual.max() - visual.min())  result = Image.fromarray((visual * 255).astype(numpy.uint8)) result.save('out.bmp')      ","Language":"Python","Tags":["python","save","python-imaging-library"],"URL":"https://stackoverflow.com/questions/14452824/how-can-i-save-an-image-with-pil","A_Votes":"78","_type":"dict","isAccepted":"Yes","Q_Content":"    I have just done some image processing using the Python image library (PIL) using a post I found earlier to perform fourier transforms of images and I can't get the save function to work. The whole code works fine but it just wont save the resulting image:  from PIL import Image import numpy as np  i = Image.open(\"C:/Users/User/Desktop/mesh.bmp\") i = i.convert(\"L\") a = np.asarray(i) b = np.abs(np.fft.rfft2(a)) j = Image.fromarray(b) j.save(\"C:/Users/User/Desktop/mesh_trans\",\".bmp\")   The error I get is the following:  save_handler = SAVE[string.upper(format)] # unknown format     KeyError: '.BMP'   How can I save an image with Pythons PIL?     ","Q_Votes":"62"},{"Q_Title":"How can I save an image with PIL?","A_Content":"  You should be able to simply let PIL get the filetype from extension, i.e. use:  j.save(\"C:/Users/User/Desktop/mesh_trans.bmp\")      ","Language":"Python","Tags":["python","save","python-imaging-library"],"URL":"https://stackoverflow.com/questions/14452824/how-can-i-save-an-image-with-pil","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I have just done some image processing using the Python image library (PIL) using a post I found earlier to perform fourier transforms of images and I can't get the save function to work. The whole code works fine but it just wont save the resulting image:  from PIL import Image import numpy as np  i = Image.open(\"C:/Users/User/Desktop/mesh.bmp\") i = i.convert(\"L\") a = np.asarray(i) b = np.abs(np.fft.rfft2(a)) j = Image.fromarray(b) j.save(\"C:/Users/User/Desktop/mesh_trans\",\".bmp\")   The error I get is the following:  save_handler = SAVE[string.upper(format)] # unknown format     KeyError: '.BMP'   How can I save an image with Pythons PIL?     ","Q_Votes":"62"},{"Q_Title":"How can I save an image with PIL?","A_Content":"  Try removing the . before the .bmp (it isn't matching BMP as expected). As you can see from the error, the save_handler is upper-casing the format you provided and then looking for a match in SAVE. However the corresponding key in that object is BMP (instead of .BMP).  I don't know a great deal about PIL, but from some quick searching around it seems that it is a problem with the mode of the image. Changing the definition of j to:  j = Image.fromarray(b, mode='RGB')   Seemed to work for me (however note that I have very little knowledge of PIL, so I would suggest using @mmgp's solution as s/he clearly knows what they are doing :) ). For the types of mode, I used this page - hopefully one of the choices there will work for you.     ","Language":"Python","Tags":["python","save","python-imaging-library"],"URL":"https://stackoverflow.com/questions/14452824/how-can-i-save-an-image-with-pil","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have just done some image processing using the Python image library (PIL) using a post I found earlier to perform fourier transforms of images and I can't get the save function to work. The whole code works fine but it just wont save the resulting image:  from PIL import Image import numpy as np  i = Image.open(\"C:/Users/User/Desktop/mesh.bmp\") i = i.convert(\"L\") a = np.asarray(i) b = np.abs(np.fft.rfft2(a)) j = Image.fromarray(b) j.save(\"C:/Users/User/Desktop/mesh_trans\",\".bmp\")   The error I get is the following:  save_handler = SAVE[string.upper(format)] # unknown format     KeyError: '.BMP'   How can I save an image with Pythons PIL?     ","Q_Votes":"62"},{"Q_Title":"How can I save an image with PIL?","A_Content":"  I know that this is old, but I've found that (while using Pillow) opening the file by using open(fp, 'w') and then saving the file will work. E.g:  with open(fp, 'w') as f:     result.save(f)   fp being the file path, of course.     ","Language":"Python","Tags":["python","save","python-imaging-library"],"URL":"https://stackoverflow.com/questions/14452824/how-can-i-save-an-image-with-pil","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have just done some image processing using the Python image library (PIL) using a post I found earlier to perform fourier transforms of images and I can't get the save function to work. The whole code works fine but it just wont save the resulting image:  from PIL import Image import numpy as np  i = Image.open(\"C:/Users/User/Desktop/mesh.bmp\") i = i.convert(\"L\") a = np.asarray(i) b = np.abs(np.fft.rfft2(a)) j = Image.fromarray(b) j.save(\"C:/Users/User/Desktop/mesh_trans\",\".bmp\")   The error I get is the following:  save_handler = SAVE[string.upper(format)] # unknown format     KeyError: '.BMP'   How can I save an image with Pythons PIL?     ","Q_Votes":"62"},{"Q_Title":"Is it possible for a unit test to assert that a method calls sys.exit()","A_Content":"  Yes. sys.exit raises SystemExit, so you can check it with assertRaises:  with self.assertRaises(SystemExit):     your_method()   Instances of SystemExit have an attribute code which is set to the proposed exit status, and the context manager returned by assertRaises has the caught exception instance as exception, so checking the exit status is easy:  with self.assertRaises(SystemExit) as cm:     your_method()  self.assertEqual(cm.exception.code, 1)      sys.exit Documentation:     Exit from Python. This is implemented by raising the SystemExit exception ... it is possible to intercept the exit attempt at an outer level.      ","Language":"Python","Tags":["python","unit-testing"],"URL":"https://stackoverflow.com/questions/15672151/is-it-possible-for-a-unit-test-to-assert-that-a-method-calls-sys-exit","A_Votes":"100","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a python 2.7 method that sometimes calls  sys.exit(1)    Is it possible to make a unit test that verifies this line of code is called when the right conditions are met?     ","Q_Votes":"62"},{"Q_Title":"Is it possible for a unit test to assert that a method calls sys.exit()","A_Content":"  Here's a complete working example.  In spite of Pavel's excellent answer it took me a while to figure this out, so I'm including it here in the hope that it will be helpful.  import unittest from glf.logtype.grinder.mapping_reader import MapReader  INCOMPLETE_MAPPING_FILE=\"test/data/incomplete.http.mapping\"  class TestMapReader(unittest.TestCase):      def test_get_tx_names_incomplete_mapping_file(self):         map_reader = MapReader()         with self.assertRaises(SystemExit) as cm:             tx_names = map_reader.get_tx_names(INCOMPLETE_MAPPING_FILE)         self.assertEqual(cm.exception.code, 1)      ","Language":"Python","Tags":["python","unit-testing"],"URL":"https://stackoverflow.com/questions/15672151/is-it-possible-for-a-unit-test-to-assert-that-a-method-calls-sys-exit","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I have a python 2.7 method that sometimes calls  sys.exit(1)    Is it possible to make a unit test that verifies this line of code is called when the right conditions are met?     ","Q_Votes":"62"},{"Q_Title":"Is it possible for a unit test to assert that a method calls sys.exit()","A_Content":"  As an additional note to Pavel's excellent answer you can also check for specific statuses if they're provided in the function you're testing. For example if your_method() contained the following sys.exit(\"Error\") it would be possible to test for \"Error\" specifically:   with self.assertRaises(SystemExit) as cm:     your_method()     self.assertEqual(cm.exception, \"Error\")      ","Language":"Python","Tags":["python","unit-testing"],"URL":"https://stackoverflow.com/questions/15672151/is-it-possible-for-a-unit-test-to-assert-that-a-method-calls-sys-exit","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a python 2.7 method that sometimes calls  sys.exit(1)    Is it possible to make a unit test that verifies this line of code is called when the right conditions are met?     ","Q_Votes":"62"},{"Q_Title":"Is it possible for a unit test to assert that a method calls sys.exit()","A_Content":"  I found the answer to your question in the Python Unit Testing documentation search for \"Testing for Exceptions\".  Using your example, the unit test would look like the following:  self.assertRaises(SystemExit, your_function, argument 1, argument 2)   Remember to include all arguments needed to test your function.       ","Language":"Python","Tags":["python","unit-testing"],"URL":"https://stackoverflow.com/questions/15672151/is-it-possible-for-a-unit-test-to-assert-that-a-method-calls-sys-exit","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a python 2.7 method that sometimes calls  sys.exit(1)    Is it possible to make a unit test that verifies this line of code is called when the right conditions are met?     ","Q_Votes":"62"},{"Q_Title":"How to test Python 3.4 asyncio code?","A_Content":"  async_test, suggested by Marvin Killing, definitely can help -- as well as direct calling loop.run_until_complete()  But I also strongly recommend to recreate new event loop for every test and directly pass loop to API calls (at least asyncio itself accepts loop keyword-only parameter for every call that need it).  Like  class Test(unittest.TestCase):     def setUp(self):         self.loop = asyncio.new_event_loop()         asyncio.set_event_loop(None)      def test_xxx(self):         @asyncio.coroutine         def go():             reader, writer = yield from asyncio.open_connection(                 '127.0.0.1', 8888, loop=self.loop)             yield from asyncio.sleep(0.01, loop=self.loop)         self.loop.run_until_complete(go())   that isolates tests in test case and prevents strange errors like longstanding coroutine that has been created in test_a but finished only on test_b execution time.     ","Language":"Python","Tags":["python","unit-testing","python-3.x","python-unittest","python-asyncio"],"URL":"https://stackoverflow.com/questions/23033939/how-to-test-python-3-4-asyncio-code","A_Votes":"45","_type":"dict","isAccepted":"No","Q_Content":"    What's the best way to write unit tests for code using the Python 3.4 asyncio library? Assume I want to test a TCP client (SocketConnection):  import asyncio import unittest  class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @asyncio.coroutine     def test_sends_handshake_after_connect(self):         yield from self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())   When running this test case with the default test runner, the test will always succeed as the method executes only up until the first yield from instruction, after which it returns before executing any assertions. This causes tests to always succeed.  Is there a prebuilt test runner that is able to handle asynchronous code like this?     ","Q_Votes":"62"},{"Q_Title":"How to test Python 3.4 asyncio code?","A_Content":"  I temporarily solved the problem using a decorator inspired by Tornado's gen_test:  def async_test(f):     def wrapper(*args, **kwargs):         coro = asyncio.coroutine(f)         future = coro(*args, **kwargs)         loop = asyncio.get_event_loop()         loop.run_until_complete(future)     return wrapper   Like J.F. Sebastian suggested, this decorator will block until the test method coroutine has finished. This allows me to write test cases like this:  class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @async_test     def test_sends_handshake_after_connect(self):         yield from self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())   This solution probably misses some edge cases.  I think a facility like this should added to Python's standard library to make asyncio and unittest interaction more convenient out of the box.     ","Language":"Python","Tags":["python","unit-testing","python-3.x","python-unittest","python-asyncio"],"URL":"https://stackoverflow.com/questions/23033939/how-to-test-python-3-4-asyncio-code","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    What's the best way to write unit tests for code using the Python 3.4 asyncio library? Assume I want to test a TCP client (SocketConnection):  import asyncio import unittest  class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @asyncio.coroutine     def test_sends_handshake_after_connect(self):         yield from self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())   When running this test case with the default test runner, the test will always succeed as the method executes only up until the first yield from instruction, after which it returns before executing any assertions. This causes tests to always succeed.  Is there a prebuilt test runner that is able to handle asynchronous code like this?     ","Q_Votes":"62"},{"Q_Title":"How to test Python 3.4 asyncio code?","A_Content":"  pytest-asyncio looks promising:  @pytest.mark.asyncio async def test_some_asyncio_code():     res = await library.do_something()     assert b'expected result' == res      ","Language":"Python","Tags":["python","unit-testing","python-3.x","python-unittest","python-asyncio"],"URL":"https://stackoverflow.com/questions/23033939/how-to-test-python-3-4-asyncio-code","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    What's the best way to write unit tests for code using the Python 3.4 asyncio library? Assume I want to test a TCP client (SocketConnection):  import asyncio import unittest  class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @asyncio.coroutine     def test_sends_handshake_after_connect(self):         yield from self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())   When running this test case with the default test runner, the test will always succeed as the method executes only up until the first yield from instruction, after which it returns before executing any assertions. This causes tests to always succeed.  Is there a prebuilt test runner that is able to handle asynchronous code like this?     ","Q_Votes":"62"},{"Q_Title":"How to test Python 3.4 asyncio code?","A_Content":"  Use this class instead of unittest.TestCase base class:  import asyncio import unittest   class AioTestCase(unittest.TestCase):      # noinspection PyPep8Naming     def __init__(self, methodName='runTest', loop=None):         self.loop = loop or asyncio.get_event_loop()         self._function_cache = {}         super(AioTestCase, self).__init__(methodName=methodName)      def coroutine_function_decorator(self, func):         def wrapper(*args, **kw):             return self.loop.run_until_complete(func(*args, **kw))         return wrapper      def __getattribute__(self, item):         attr = object.__getattribute__(self, item)         if asyncio.iscoroutinefunction(attr):             if item not in self._function_cache:                 self._function_cache[item] = self.coroutine_function_decorator(attr)             return self._function_cache[item]         return attr   class TestMyCase(AioTestCase):      async def test_dispatch(self):         self.assertEqual(1, 1)      ","Language":"Python","Tags":["python","unit-testing","python-3.x","python-unittest","python-asyncio"],"URL":"https://stackoverflow.com/questions/23033939/how-to-test-python-3-4-asyncio-code","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    What's the best way to write unit tests for code using the Python 3.4 asyncio library? Assume I want to test a TCP client (SocketConnection):  import asyncio import unittest  class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @asyncio.coroutine     def test_sends_handshake_after_connect(self):         yield from self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())   When running this test case with the default test runner, the test will always succeed as the method executes only up until the first yield from instruction, after which it returns before executing any assertions. This causes tests to always succeed.  Is there a prebuilt test runner that is able to handle asynchronous code like this?     ","Q_Votes":"62"},{"Q_Title":"How to test Python 3.4 asyncio code?","A_Content":"  Really like the async_test wrapper mentioned in https://stackoverflow.com/a/23036785/350195, here is an updated version for Python 3.5+  def async_test(coro):     def wrapper(*args, **kwargs):         loop = asyncio.new_event_loop()         return loop.run_until_complete(coro(*args, **kwargs))     return wrapper    class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @async_test     async def test_sends_handshake_after_connect(self):         await self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())      ","Language":"Python","Tags":["python","unit-testing","python-3.x","python-unittest","python-asyncio"],"URL":"https://stackoverflow.com/questions/23033939/how-to-test-python-3-4-asyncio-code","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    What's the best way to write unit tests for code using the Python 3.4 asyncio library? Assume I want to test a TCP client (SocketConnection):  import asyncio import unittest  class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @asyncio.coroutine     def test_sends_handshake_after_connect(self):         yield from self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())   When running this test case with the default test runner, the test will always succeed as the method executes only up until the first yield from instruction, after which it returns before executing any assertions. This causes tests to always succeed.  Is there a prebuilt test runner that is able to handle asynchronous code like this?     ","Q_Votes":"62"},{"Q_Title":"How to test Python 3.4 asyncio code?","A_Content":"  You can also use aiounittest that takes similar approach as @Andrew Svetlov, @Marvin Killing answers and wrap it in easy to use AsyncTestCase class:  import asyncio import aiounittest   async def add(x, y):     await asyncio.sleep(0.1)     return x + y  class MyTest(aiounittest.AsyncTestCase):      async def test_async_add(self):         ret = await add(5, 6)         self.assertEqual(ret, 11)      # or 3.4 way     @asyncio.coroutine     def test_sleep(self):         ret = yield from add(5, 6)         self.assertEqual(ret, 11)      # some regular test code     def test_something(self):         self.assertTrue(true)   As you can see the async case is handled by AsyncTestCase. It supports also synchronous test. There is a possibility to provide custom event loop, just override AsyncTestCase.get_event_loop.  If you prefer (for some reason) the other TestCase class (eg unittest.TestCase), you might use async_test decorator:  import asyncio import unittest from aiounittest import async_test   async def add(x, y):     await asyncio.sleep(0.1)     return x + y  class MyTest(unittest.TestCase):      @async_test     async def test_async_add(self):         ret = await add(5, 6)         self.assertEqual(ret, 11)      ","Language":"Python","Tags":["python","unit-testing","python-3.x","python-unittest","python-asyncio"],"URL":"https://stackoverflow.com/questions/23033939/how-to-test-python-3-4-asyncio-code","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    What's the best way to write unit tests for code using the Python 3.4 asyncio library? Assume I want to test a TCP client (SocketConnection):  import asyncio import unittest  class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @asyncio.coroutine     def test_sends_handshake_after_connect(self):         yield from self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())   When running this test case with the default test runner, the test will always succeed as the method executes only up until the first yield from instruction, after which it returns before executing any assertions. This causes tests to always succeed.  Is there a prebuilt test runner that is able to handle asynchronous code like this?     ","Q_Votes":"62"},{"Q_Title":"How to test Python 3.4 asyncio code?","A_Content":"  I usually define my async tests as coroutines and use a decorator for \"syncing\" them:  import asyncio import unittest  def sync(coro):     def wrapper(*args, **kwargs):         loop = asyncio.get_event_loop()         loop.run_until_complete(coro(*args, **kwargs))     return wrapper  class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @sync     async def test_sends_handshake_after_connect(self):         await self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())      ","Language":"Python","Tags":["python","unit-testing","python-3.x","python-unittest","python-asyncio"],"URL":"https://stackoverflow.com/questions/23033939/how-to-test-python-3-4-asyncio-code","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    What's the best way to write unit tests for code using the Python 3.4 asyncio library? Assume I want to test a TCP client (SocketConnection):  import asyncio import unittest  class TestSocketConnection(unittest.TestCase):     def setUp(self):         self.mock_server = MockServer(\"localhost\", 1337)         self.socket_connection = SocketConnection(\"localhost\", 1337)      @asyncio.coroutine     def test_sends_handshake_after_connect(self):         yield from self.socket_connection.connect()         self.assertTrue(self.mock_server.received_handshake())   When running this test case with the default test runner, the test will always succeed as the method executes only up until the first yield from instruction, after which it returns before executing any assertions. This causes tests to always succeed.  Is there a prebuilt test runner that is able to handle asynchronous code like this?     ","Q_Votes":"62"},{"Q_Title":"Dead simple example of using Multiprocessing Queue, Pool and Locking","A_Content":"  The best solution for your problem is to utilize a Pool. Using Queues and having a separate \"queue feeding\" functionality is probably overkill.  Here's a slightly rearranged version of your program, this time with only 2 processes coralled in a Pool. I believe it's the easiest way to go, with minimal changes to original code:   import multiprocessing import time  data = (     ['a', '2'], ['b', '4'], ['c', '6'], ['d', '8'],     ['e', '1'], ['f', '3'], ['g', '5'], ['h', '7'] )  def mp_worker((inputs, the_time)):     print \" Processs %s\\tWaiting %s seconds\" % (inputs, the_time)     time.sleep(int(the_time))     print \" Process %s\\tDONE\" % inputs  def mp_handler():     p = multiprocessing.Pool(2)     p.map(mp_worker, data)  if __name__ == '__main__':     mp_handler()   Note that mp_worker() function now accepts a single argument (a tuple of the two previous arguments) because the map() function chunks up your input data into sublists, each sublist given as a single argument to your worker function.  Output:  Processs a  Waiting 2 seconds Processs b  Waiting 4 seconds Process a   DONE Processs c  Waiting 6 seconds Process b   DONE Processs d  Waiting 8 seconds Process c   DONE Processs e  Waiting 1 seconds Process e   DONE Processs f  Waiting 3 seconds Process d   DONE Processs g  Waiting 5 seconds Process f   DONE Processs h  Waiting 7 seconds Process g   DONE Process h   DONE     Edit as per @Thales comment below:  If you want \"a lock for each pool limit\" so that your processes run in tandem pairs, ala:  A waiting B waiting | A done , B done | C waiting , D waiting | C done, D done | ...  then change the handler function to launch pools (of 2 processes) for each pair of data:  def mp_handler():     subdata = zip(data[0::2], data[1::2])     for task1, task2 in subdata:         p = multiprocessing.Pool(2)         p.map(mp_worker, (task1, task2))   Now your output is:   Processs a Waiting 2 seconds  Processs b Waiting 4 seconds  Process a  DONE  Process b  DONE  Processs c Waiting 6 seconds  Processs d Waiting 8 seconds  Process c  DONE  Process d  DONE  Processs e Waiting 1 seconds  Processs f Waiting 3 seconds  Process e  DONE  Process f  DONE  Processs g Waiting 5 seconds  Processs h Waiting 7 seconds  Process g  DONE  Process h  DONE      ","Language":"Python","Tags":["python","python-2.7","multiprocessing"],"URL":"https://stackoverflow.com/questions/20887555/dead-simple-example-of-using-multiprocessing-queue-pool-and-locking","A_Votes":"95","_type":"dict","isAccepted":"Yes","Q_Content":"    I tried to read the documentation at http://docs.python.org/dev/library/multiprocessing.html but I'm  still struggling with multiprocessing Queue, Pool and Locking. And for now I was able to build the example below.  Regarding Queue and Pool, I'm not sure if I understood the concept in the right way, so correct me if I'm wrong.  What I'm trying to achieve is to  process 2 requests at time ( data list have 8 in this example ) so, what should I use? Pool to create 2 processes that can handle two different queues ( 2 at max ) or should I just use Queue to process 2 inputs each time? The lock would be to print the outputs correctly.  import multiprocessing import time  data = (['a', '2'], ['b', '4'], ['c', '6'], ['d', '8'],         ['e', '1'], ['f', '3'], ['g', '5'], ['h', '7'] )   def mp_handler(var1):     for indata in var1:         p = multiprocessing.Process(target=mp_worker, args=(indata[0], indata[1]))         p.start()   def mp_worker(inputs, the_time):     print \" Processs %s\\tWaiting %s seconds\" % (inputs, the_time)     time.sleep(int(the_time))     print \" Process %s\\tDONE\" % inputs  if __name__ == '__main__':     mp_handler(data)      ","Q_Votes":"62"},{"Q_Title":"Dead simple example of using Multiprocessing Queue, Pool and Locking","A_Content":"  Here is my personal goto for this topic:  Gist here, (pull requests welcome!): https://gist.github.com/thorsummoner/b5b1dfcff7e7fdd334ec  import multiprocessing import sys  THREADS = 3  # Used to prevent multiple threads from mixing thier output GLOBALLOCK = multiprocessing.Lock()   def func_worker(args):     \"\"\"This function will be called by each thread.     This function can not be a class method.     \"\"\"     # Expand list of args into named args.     str1, str2 = args     del args      # Work     # ...        # Serial-only Portion     GLOBALLOCK.acquire()     print(str1)     print(str2)     GLOBALLOCK.release()   def main(argp=None):     \"\"\"Multiprocessing Spawn Example     \"\"\"     # Create the number of threads you want     pool = multiprocessing.Pool(THREADS)      # Define two jobs, each with two args.     func_args = [         ('Hello', 'World',),          ('Goodbye', 'World',),      ]       try:         # Spawn up to 9999999 jobs, I think this is the maximum possible.         # I do not know what happens if you exceed this.         pool.map_async(func_worker, func_args).get(9999999)     except KeyboardInterrupt:         # Allow ^C to interrupt from any thread.         sys.stdout.write('\\033[0m')         sys.stdout.write('User Interupt\\n')     pool.close()  if __name__ == '__main__':     main()      ","Language":"Python","Tags":["python","python-2.7","multiprocessing"],"URL":"https://stackoverflow.com/questions/20887555/dead-simple-example-of-using-multiprocessing-queue-pool-and-locking","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I tried to read the documentation at http://docs.python.org/dev/library/multiprocessing.html but I'm  still struggling with multiprocessing Queue, Pool and Locking. And for now I was able to build the example below.  Regarding Queue and Pool, I'm not sure if I understood the concept in the right way, so correct me if I'm wrong.  What I'm trying to achieve is to  process 2 requests at time ( data list have 8 in this example ) so, what should I use? Pool to create 2 processes that can handle two different queues ( 2 at max ) or should I just use Queue to process 2 inputs each time? The lock would be to print the outputs correctly.  import multiprocessing import time  data = (['a', '2'], ['b', '4'], ['c', '6'], ['d', '8'],         ['e', '1'], ['f', '3'], ['g', '5'], ['h', '7'] )   def mp_handler(var1):     for indata in var1:         p = multiprocessing.Process(target=mp_worker, args=(indata[0], indata[1]))         p.start()   def mp_worker(inputs, the_time):     print \" Processs %s\\tWaiting %s seconds\" % (inputs, the_time)     time.sleep(int(the_time))     print \" Process %s\\tDONE\" % inputs  if __name__ == '__main__':     mp_handler(data)      ","Q_Votes":"62"},{"Q_Title":"Dead simple example of using Multiprocessing Queue, Pool and Locking","A_Content":"  This might be not 100% related to the question, but on my search for an example of using multiprocessing with a queue this shows up first on google.  This is a basic example class that you can instantiate and put items in a queue and can wait until queue is finished. That's all I needed.  from multiprocessing import JoinableQueue from multiprocessing.context import Process   class Renderer:     queue = None      def __init__(self, nb_workers=2):         self.queue = JoinableQueue()         self.processes = [Process(target=self.upload) for i in range(nb_workers)]         for p in self.processes:             p.start()      def render(self, item):         self.queue.put(item)      def upload(self):         while True:             item = self.queue.get()             if item is None:                 break              # process your item here              self.queue.task_done()      def terminate(self):         \"\"\" wait until queue is empty and terminate processes \"\"\"         self.queue.join()         for p in self.processes:             p.terminate()  r = Renderer() r.render(item1) r.render(item2) r.terminate()      ","Language":"Python","Tags":["python","python-2.7","multiprocessing"],"URL":"https://stackoverflow.com/questions/20887555/dead-simple-example-of-using-multiprocessing-queue-pool-and-locking","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I tried to read the documentation at http://docs.python.org/dev/library/multiprocessing.html but I'm  still struggling with multiprocessing Queue, Pool and Locking. And for now I was able to build the example below.  Regarding Queue and Pool, I'm not sure if I understood the concept in the right way, so correct me if I'm wrong.  What I'm trying to achieve is to  process 2 requests at time ( data list have 8 in this example ) so, what should I use? Pool to create 2 processes that can handle two different queues ( 2 at max ) or should I just use Queue to process 2 inputs each time? The lock would be to print the outputs correctly.  import multiprocessing import time  data = (['a', '2'], ['b', '4'], ['c', '6'], ['d', '8'],         ['e', '1'], ['f', '3'], ['g', '5'], ['h', '7'] )   def mp_handler(var1):     for indata in var1:         p = multiprocessing.Process(target=mp_worker, args=(indata[0], indata[1]))         p.start()   def mp_worker(inputs, the_time):     print \" Processs %s\\tWaiting %s seconds\" % (inputs, the_time)     time.sleep(int(the_time))     print \" Process %s\\tDONE\" % inputs  if __name__ == '__main__':     mp_handler(data)      ","Q_Votes":"62"},{"Q_Title":"Dead simple example of using Multiprocessing Queue, Pool and Locking","A_Content":"  For everyone using editors like Komodo Edit (win10) add sys.stdout.flush() to:  def mp_worker((inputs, the_time)):     print \" Process %s\\tWaiting %s seconds\" % (inputs, the_time)     time.sleep(int(the_time))     print \" Process %s\\tDONE\" % inputs     sys.stdout.flush()   or as first line to:      if __name__ == '__main__':        sys.stdout.flush()   This helps to see what goes on during the run of the script; in stead of having to look at the black command line box.     ","Language":"Python","Tags":["python","python-2.7","multiprocessing"],"URL":"https://stackoverflow.com/questions/20887555/dead-simple-example-of-using-multiprocessing-queue-pool-and-locking","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I tried to read the documentation at http://docs.python.org/dev/library/multiprocessing.html but I'm  still struggling with multiprocessing Queue, Pool and Locking. And for now I was able to build the example below.  Regarding Queue and Pool, I'm not sure if I understood the concept in the right way, so correct me if I'm wrong.  What I'm trying to achieve is to  process 2 requests at time ( data list have 8 in this example ) so, what should I use? Pool to create 2 processes that can handle two different queues ( 2 at max ) or should I just use Queue to process 2 inputs each time? The lock would be to print the outputs correctly.  import multiprocessing import time  data = (['a', '2'], ['b', '4'], ['c', '6'], ['d', '8'],         ['e', '1'], ['f', '3'], ['g', '5'], ['h', '7'] )   def mp_handler(var1):     for indata in var1:         p = multiprocessing.Process(target=mp_worker, args=(indata[0], indata[1]))         p.start()   def mp_worker(inputs, the_time):     print \" Processs %s\\tWaiting %s seconds\" % (inputs, the_time)     time.sleep(int(the_time))     print \" Process %s\\tDONE\" % inputs  if __name__ == '__main__':     mp_handler(data)      ","Q_Votes":"62"},{"Q_Title":"Dead simple example of using Multiprocessing Queue, Pool and Locking","A_Content":"  Here is an example from my code (for threaded pool, but just change class name and you'll have process pool):   def execute_run(rp):     ... do something   pool = ThreadPoolExecutor(6) for mat in TESTED_MATERIAL:     for en in TESTED_ENERGIES:         for ecut in TESTED_E_CUT:             rp = RunParams(                 simulations, DEST_DIR,                 PARTICLE, mat, 960, 0.125, ecut, en             )             pool.submit(execute_run, rp) pool.join()   Basically:    pool = ThreadPoolExecutor(6) creates a pool for 6 threads Then you have bunch of for's that add tasks to the pool pool.submit(execute_run, rp) adds a task to pool, first arogument is a function called in in a thread/process, rest of the arguments are passed to the called function.  pool.join waits until all tasks are done.       ","Language":"Python","Tags":["python","python-2.7","multiprocessing"],"URL":"https://stackoverflow.com/questions/20887555/dead-simple-example-of-using-multiprocessing-queue-pool-and-locking","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I tried to read the documentation at http://docs.python.org/dev/library/multiprocessing.html but I'm  still struggling with multiprocessing Queue, Pool and Locking. And for now I was able to build the example below.  Regarding Queue and Pool, I'm not sure if I understood the concept in the right way, so correct me if I'm wrong.  What I'm trying to achieve is to  process 2 requests at time ( data list have 8 in this example ) so, what should I use? Pool to create 2 processes that can handle two different queues ( 2 at max ) or should I just use Queue to process 2 inputs each time? The lock would be to print the outputs correctly.  import multiprocessing import time  data = (['a', '2'], ['b', '4'], ['c', '6'], ['d', '8'],         ['e', '1'], ['f', '3'], ['g', '5'], ['h', '7'] )   def mp_handler(var1):     for indata in var1:         p = multiprocessing.Process(target=mp_worker, args=(indata[0], indata[1]))         p.start()   def mp_worker(inputs, the_time):     print \" Processs %s\\tWaiting %s seconds\" % (inputs, the_time)     time.sleep(int(the_time))     print \" Process %s\\tDONE\" % inputs  if __name__ == '__main__':     mp_handler(data)      ","Q_Votes":"62"},{"Q_Title":"How to prevent numbers being changed to exponential form in Python matplotlib figure","A_Content":"  The formatting of tick labels is controlled by a Formatter object, which assuming you haven't done anything fancy will be a ScalerFormatterby default.  This formatter will use a constant shift if the fractional change of the values visible is very small.  To avoid this, simply turn it off:  plt.plot(arange(0,100,10) + 1000, arange(0,100,10)) ax = plt.gca() ax.get_xaxis().get_major_formatter().set_useOffset(False) plt.draw()   If you want to avoid scientific notation in general,   ax.get_xaxis().get_major_formatter().set_scientific(False)   Can control this with globally via the axes.formatter.useoffset rcparam.     ","Language":"Python","Tags":["python","graph","matplotlib","figure"],"URL":"https://stackoverflow.com/questions/14711655/how-to-prevent-numbers-being-changed-to-exponential-form-in-python-matplotlib-fi","A_Votes":"83","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm using Matplotlib in Python to plot simple x-y datasets. This produces nice-looking graphs, although when I \"zoom in\" too close on various sections of the plotted graph using the Figure View (which appears when you execute plt.show() ), the x-axis values change from standard number form (1050, 1060, 1070 etc.) to scientific form with exponential notation (e.g. 1, 1.5, 2.0 with the x-axis label given as +1.057e3).  I'd prefer my figures to retain the simple numbering of the axis, rather than using exponential form. Is there a way I can force Matplotlib to do this?     ","Q_Votes":"62"},{"Q_Title":"How to prevent numbers being changed to exponential form in Python matplotlib figure","A_Content":"  You can use a simpler command to turn it off:  plt.ticklabel_format(useOffset=False)      ","Language":"Python","Tags":["python","graph","matplotlib","figure"],"URL":"https://stackoverflow.com/questions/14711655/how-to-prevent-numbers-being-changed-to-exponential-form-in-python-matplotlib-fi","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I'm using Matplotlib in Python to plot simple x-y datasets. This produces nice-looking graphs, although when I \"zoom in\" too close on various sections of the plotted graph using the Figure View (which appears when you execute plt.show() ), the x-axis values change from standard number form (1050, 1060, 1070 etc.) to scientific form with exponential notation (e.g. 1, 1.5, 2.0 with the x-axis label given as +1.057e3).  I'd prefer my figures to retain the simple numbering of the axis, rather than using exponential form. Is there a way I can force Matplotlib to do this?     ","Q_Votes":"62"},{"Q_Title":"How to prevent numbers being changed to exponential form in Python matplotlib figure","A_Content":"  You can use something like:  from matplotlib.ticker import ScalarFormatter, FormatStrFormatter  ax.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))      ","Language":"Python","Tags":["python","graph","matplotlib","figure"],"URL":"https://stackoverflow.com/questions/14711655/how-to-prevent-numbers-being-changed-to-exponential-form-in-python-matplotlib-fi","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I'm using Matplotlib in Python to plot simple x-y datasets. This produces nice-looking graphs, although when I \"zoom in\" too close on various sections of the plotted graph using the Figure View (which appears when you execute plt.show() ), the x-axis values change from standard number form (1050, 1060, 1070 etc.) to scientific form with exponential notation (e.g. 1, 1.5, 2.0 with the x-axis label given as +1.057e3).  I'd prefer my figures to retain the simple numbering of the axis, rather than using exponential form. Is there a way I can force Matplotlib to do this?     ","Q_Votes":"62"},{"Q_Title":"Should I use a class or dictionary?","A_Content":"  Why on earth would you make this a dictionary? What's the advantage? What happens if you later want to add some code? Where would your __init__ code go?  Classes are for bundling related data (and usually code).  Dictionaries are for storing key-value relationships, where usually the keys are all of the same type, and all the values are also of one type. Occasionally they can be useful for bundling data when the key/attribute names are not all known up front, but often this a sign that something's wrong with your design.  Keep this a class.     ","Language":"Python","Tags":["python","oop","class","dictionary"],"URL":"https://stackoverflow.com/questions/4045161/should-i-use-a-class-or-dictionary","A_Votes":"19","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a class that contains only fields and no methods, like this:  class Request(object):      def __init__(self, environ):         self.environ = environ         self.request_method = environ.get('REQUEST_METHOD', None)         self.url_scheme = environ.get('wsgi.url_scheme', None)         self.request_uri = wsgiref.util.request_uri(environ)         self.path = environ.get('PATH_INFO', None)         # ...   This could easily be translated to a dict. The class is more flexible for future additions and could be fast with __slots__. So would there be a benefit of using a dict instead? Would a dict be faster than a class? And faster than a class with slots?     ","Q_Votes":"62"},{"Q_Title":"Should I use a class or dictionary?","A_Content":"  Use a dictionary unless you need the extra mechanism of a class. You could also use a namedtuple for a hybrid approach:  >>> from collections import namedtuple >>> request = namedtuple(\"Request\", \"environ request_method url_scheme\") >>> request <class '__main__.Request'> >>> request.environ = \"foo\" >>> request.environ 'foo'   Performance differences here will be minimal, although I would be surprised if the dictionary wasn't faster.     ","Language":"Python","Tags":["python","oop","class","dictionary"],"URL":"https://stackoverflow.com/questions/4045161/should-i-use-a-class-or-dictionary","A_Votes":"31","_type":"dict","isAccepted":"No","Q_Content":"    I have a class that contains only fields and no methods, like this:  class Request(object):      def __init__(self, environ):         self.environ = environ         self.request_method = environ.get('REQUEST_METHOD', None)         self.url_scheme = environ.get('wsgi.url_scheme', None)         self.request_uri = wsgiref.util.request_uri(environ)         self.path = environ.get('PATH_INFO', None)         # ...   This could easily be translated to a dict. The class is more flexible for future additions and could be fast with __slots__. So would there be a benefit of using a dict instead? Would a dict be faster than a class? And faster than a class with slots?     ","Q_Votes":"62"},{"Q_Title":"Should I use a class or dictionary?","A_Content":"  A class in python is a dict underneath.  You do get some overhead with the class behavior, but you won't be able to notice it without a profiler.  In this case, I believe you benefit from the class because:   All your logic lives in a single function It is easy to update and stays encapsulated If you change anything later, you can easily keep the interface the same      ","Language":"Python","Tags":["python","oop","class","dictionary"],"URL":"https://stackoverflow.com/questions/4045161/should-i-use-a-class-or-dictionary","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I have a class that contains only fields and no methods, like this:  class Request(object):      def __init__(self, environ):         self.environ = environ         self.request_method = environ.get('REQUEST_METHOD', None)         self.url_scheme = environ.get('wsgi.url_scheme', None)         self.request_uri = wsgiref.util.request_uri(environ)         self.path = environ.get('PATH_INFO', None)         # ...   This could easily be translated to a dict. The class is more flexible for future additions and could be fast with __slots__. So would there be a benefit of using a dict instead? Would a dict be faster than a class? And faster than a class with slots?     ","Q_Votes":"62"},{"Q_Title":"Should I use a class or dictionary?","A_Content":"  I think that the usage of each one is way too subjective for me to get in on that, so i'll just stick to numbers.  I compared the time it takes to create and to change a variable in a dict, a new_style class and a new_style class with slots.  Here's the code i used to test it(it's a bit messy but it does the job.)  import timeit  class Foo(object):      def __init__(self):          self.foo1 = 'test'         self.foo2 = 'test'         self.foo3 = 'test'  def create_dict():      foo_dict = {}     foo_dict['foo1'] = 'test'     foo_dict['foo2'] = 'test'     foo_dict['foo3'] = 'test'      return foo_dict  class Bar(object):     __slots__ = ['foo1', 'foo2', 'foo3']      def __init__(self):          self.foo1 = 'test'         self.foo2 = 'test'         self.foo3 = 'test'  tmit = timeit.timeit  print 'Creating...\\n' print 'Dict: ' + str(tmit('create_dict()', 'from __main__ import create_dict')) print 'Class: ' + str(tmit('Foo()', 'from __main__ import Foo')) print 'Class with slots: ' + str(tmit('Bar()', 'from __main__ import Bar'))  print '\\nChanging a variable...\\n'  print 'Dict: ' + str((tmit('create_dict()[\\'foo3\\'] = \"Changed\"', 'from __main__ import create_dict') - tmit('create_dict()', 'from __main__ import create_dict'))) print 'Class: ' + str((tmit('Foo().foo3 = \"Changed\"', 'from __main__ import Foo') - tmit('Foo()', 'from __main__ import Foo'))) print 'Class with slots: ' + str((tmit('Bar().foo3 = \"Changed\"', 'from __main__ import Bar') - tmit('Bar()', 'from __main__ import Bar')))   And here is the output...  Creating...  Dict: 0.817466186345 Class: 1.60829183597 Class_with_slots: 1.28776730003   Changing a variable...  Dict: 0.0735140918748 Class: 0.111714198313 Class_with_slots: 0.10618612142   So, if you're just storing variables, you need speed, and it won't require you to do many calculations, i recommend using a dict(you could always just make a function that looks like a method). But, if you really need classes, remember - always use __slots__.  Note:  I tested the 'Class' with both new_style and old_style classes. It turns out that old_style classes are faster to create but slower to modify(not by much but significant if you're creating lots of classes in a tight loop (tip: you're doing it wrong)).  Also the times for creating and changing variables may differ on your computer since mine is old and slow. Make sure you test it yourself to see the 'real' results.  Edit:  I later tested the namedtuple: i can't modify it but to create the 10000 samples (or something like that) it took 1.4 seconds so the dictionary is indeed the fastest.  If i change the dict function to include the keys and values and to return the dict instead of the variable containing the dict when i create it it gives me 0.65 instead of 0.8 seconds.  class Foo(dict):     pass   Creating is like a class with slots and changing the variable is the slowest (0.17 seconds) so do not use these classes. go for a dict (speed) or for the class derived from object ('syntax candy')     ","Language":"Python","Tags":["python","oop","class","dictionary"],"URL":"https://stackoverflow.com/questions/4045161/should-i-use-a-class-or-dictionary","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    I have a class that contains only fields and no methods, like this:  class Request(object):      def __init__(self, environ):         self.environ = environ         self.request_method = environ.get('REQUEST_METHOD', None)         self.url_scheme = environ.get('wsgi.url_scheme', None)         self.request_uri = wsgiref.util.request_uri(environ)         self.path = environ.get('PATH_INFO', None)         # ...   This could easily be translated to a dict. The class is more flexible for future additions and could be fast with __slots__. So would there be a benefit of using a dict instead? Would a dict be faster than a class? And faster than a class with slots?     ","Q_Votes":"62"},{"Q_Title":"Should I use a class or dictionary?","A_Content":"  I agree with @adw. I would never represent an \"object\" (in an OO sense) with a dictionary. Dictionaries aggregate name/value pairs. Classes represent objects. I've seen code where the objects are represented with dictionaries and it's unclear what the actual shape of the thing is. What happens when certain name/values aren't there? What restricts the client from putting anything at all in. Or trying to get anything at all out. The shape of the thing should always be clearly defined.   When using Python it is important to build with discipline as the language allows many ways for the author to shoot him/herself in the foot.     ","Language":"Python","Tags":["python","oop","class","dictionary"],"URL":"https://stackoverflow.com/questions/4045161/should-i-use-a-class-or-dictionary","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a class that contains only fields and no methods, like this:  class Request(object):      def __init__(self, environ):         self.environ = environ         self.request_method = environ.get('REQUEST_METHOD', None)         self.url_scheme = environ.get('wsgi.url_scheme', None)         self.request_uri = wsgiref.util.request_uri(environ)         self.path = environ.get('PATH_INFO', None)         # ...   This could easily be translated to a dict. The class is more flexible for future additions and could be fast with __slots__. So would there be a benefit of using a dict instead? Would a dict be faster than a class? And faster than a class with slots?     ","Q_Votes":"62"},{"Q_Title":"Should I use a class or dictionary?","A_Content":"  I would recommend a class, as it is all sorts of information involved with a request. Were one to use a dictionary, I'd expect the data stored to be far more similar in nature. A guideline I tend to follow myself is that if I may want to loop over the entire set of key->value pairs and do something, I use a dictionary. Otherwise, the data apparently has far more structure than a basic key->value mapping, meaning a class would likely be a better alternative.  Hence, stick with the class.     ","Language":"Python","Tags":["python","oop","class","dictionary"],"URL":"https://stackoverflow.com/questions/4045161/should-i-use-a-class-or-dictionary","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have a class that contains only fields and no methods, like this:  class Request(object):      def __init__(self, environ):         self.environ = environ         self.request_method = environ.get('REQUEST_METHOD', None)         self.url_scheme = environ.get('wsgi.url_scheme', None)         self.request_uri = wsgiref.util.request_uri(environ)         self.path = environ.get('PATH_INFO', None)         # ...   This could easily be translated to a dict. The class is more flexible for future additions and could be fast with __slots__. So would there be a benefit of using a dict instead? Would a dict be faster than a class? And faster than a class with slots?     ","Q_Votes":"62"},{"Q_Title":"Should I use a class or dictionary?","A_Content":"  It may be possible to have your cake and eat it, too. In other words you can create something that provides the functionality of both a class and dictionary instance. See the ActiveState's Dictionary with attribute-style access recipe and comments on ways of doing that.  If you decide to use a regular class rather than a subclass, I've found the 'simple but handy \"collector of a bunch of named stuff\" class' recipe to be very flexible and useful for the sort of thing it looks like you're doing (i.e. create a relative simple aggregator of information). Since it's a class you can easily extend its functionality later by adding methods.  Lastly it should be noted that the names of class members must be legal Python identifiers, but dictionary keys do not -- so a dictionary would provide greater freedom in that regard because keys can be anything hashable (even something that's not a string).     ","Language":"Python","Tags":["python","oop","class","dictionary"],"URL":"https://stackoverflow.com/questions/4045161/should-i-use-a-class-or-dictionary","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a class that contains only fields and no methods, like this:  class Request(object):      def __init__(self, environ):         self.environ = environ         self.request_method = environ.get('REQUEST_METHOD', None)         self.url_scheme = environ.get('wsgi.url_scheme', None)         self.request_uri = wsgiref.util.request_uri(environ)         self.path = environ.get('PATH_INFO', None)         # ...   This could easily be translated to a dict. The class is more flexible for future additions and could be fast with __slots__. So would there be a benefit of using a dict instead? Would a dict be faster than a class? And faster than a class with slots?     ","Q_Votes":"62"},{"Q_Title":"Should I use a class or dictionary?","A_Content":"  If all that you want to achive is syntax candy like obj.bla = 5 instead of obj['bla'] = 5, especially if you have to repeat that a lot, you maybe want to use some plain container class as in martineaus suggestion. Nevertheless, the code there is quite bloated and unnecessarily slow. You can keep it simple like that:  class AttrDict(dict):     \"\"\" Syntax candy \"\"\"     __getattr__ = dict.__getitem__     __setattr__ = dict.__setitem__     __delattr__ = dict.__delitem__   Another reason to switch to namedtuples or a class with __slots__ could be memory usage. Dicts require significantly more memory than list types, so this could be a point to think about.   Anyways, in your specific case, there doesn't seem to be any motivation to switch away from your current implementation. You don't seem to maintain millions of these objects, so no list-derived-types required. And it's actually containing some functional logic within the __init__, so you also shouldn't got with AttrDict.     ","Language":"Python","Tags":["python","oop","class","dictionary"],"URL":"https://stackoverflow.com/questions/4045161/should-i-use-a-class-or-dictionary","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a class that contains only fields and no methods, like this:  class Request(object):      def __init__(self, environ):         self.environ = environ         self.request_method = environ.get('REQUEST_METHOD', None)         self.url_scheme = environ.get('wsgi.url_scheme', None)         self.request_uri = wsgiref.util.request_uri(environ)         self.path = environ.get('PATH_INFO', None)         # ...   This could easily be translated to a dict. The class is more flexible for future additions and could be fast with __slots__. So would there be a benefit of using a dict instead? Would a dict be faster than a class? And faster than a class with slots?     ","Q_Votes":"62"},{"Q_Title":"Should I use a class or dictionary?","A_Content":"  class ClassWithSlotBase:     __slots__ = ('a', 'b',)  def __init__(self):     self.a: str = \"test\"     self.b: float = 0.0   def test_type_hint(_b: float) -> None:     print(_b)   class_tmp = ClassWithSlotBase()  test_type_hint(class_tmp.a)   I recommend a class. If you use a class, you can get type hint as shown. And Class support auto complete when class is argument of function.       ","Language":"Python","Tags":["python","oop","class","dictionary"],"URL":"https://stackoverflow.com/questions/4045161/should-i-use-a-class-or-dictionary","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a class that contains only fields and no methods, like this:  class Request(object):      def __init__(self, environ):         self.environ = environ         self.request_method = environ.get('REQUEST_METHOD', None)         self.url_scheme = environ.get('wsgi.url_scheme', None)         self.request_uri = wsgiref.util.request_uri(environ)         self.path = environ.get('PATH_INFO', None)         # ...   This could easily be translated to a dict. The class is more flexible for future additions and could be fast with __slots__. So would there be a benefit of using a dict instead? Would a dict be faster than a class? And faster than a class with slots?     ","Q_Votes":"62"},{"Q_Title":"Is there an analysis speed or memory usage advantage to using HDF5 for large array storage (instead of flat binary files)?","A_Content":"  HDF5 Advantages: Organization, flexibility, interoperability  Some of the main advantages of HDF5 are its hierarchical structure (similar to folders/files), optional arbitrary metadata stored with each item, and its flexibility (e.g. compression).  This organizational structure and metadata storage may sound trivial, but it's very useful in practice.    Another advantage of HDF is that the datasets can be either fixed-size or flexibly sized. Therefore, it's easy to append data to a large dataset without having to create an entire new copy.  Additionally, HDF5 is a standardized format with libraries available for almost any language, so sharing your on-disk data between, say Matlab, Fortran, R, C, and Python is very easy with HDF. (To be fair, it's not too hard with a big binary array, too, as long as you're aware of the C vs. F ordering and know the shape, dtype, etc of the stored array.)  HDF advantages for a large array: Faster I/O of an arbitrary slice  Just as the TL/DR: For an ~8GB 3D array, reading a \"full\" slice along any axis took ~20 seconds with a chunked HDF5 dataset, and 0.3 seconds (best-case) to over three hours (worst case) for a memmapped array of the same data.    Beyond the things listed above, there's another big advantage to a \"chunked\"* on-disk data format such as HDF5: Reading an arbitrary slice (emphasis on arbitrary) will typically be much faster, as the on-disk data is more contiguous on average.   *(HDF5 doesn't have to be a chunked data format. It supports chunking, but doesn't require it. In fact, the default for creating a dataset in h5py is not to chunk, if I recall correctly.)  Basically, your best case disk-read speed and your worst case disk read speed for a given slice of your dataset will be fairly close with a chunked HDF dataset (assuming you chose a reasonable chunk size or let a library choose one for you).  With a simple binary array, the best-case is faster, but the worst-case is much worse.  One caveat, if you have an SSD, you likely won't notice a huge difference in read/write speed.  With a regular hard drive, though, sequential reads are much, much faster than random reads.  (i.e. A regular hard drive has long seek time.) HDF still has an advantage on an SSD, but it's more due its other features (e.g. metadata, organization, etc) than due to raw speed.    First off, to clear up confusion, accessing an h5py dataset returns an object that behaves fairly similarly to a numpy array, but does not load the data into memory until it's sliced.  (Similar to memmap, but not identical.)  Have a look at the h5py introduction for more information.  Slicing the dataset will load a subset of the data into memory, but presumably you want to do something with it, at which point you'll need it in memory anyway.    If you do want to do out-of-core computations, you can fairly easily for tabular data with pandas or pytables. It is possible with h5py (nicer for big N-D arrays), but you need to drop down to a touch lower level and handle the iteration yourself.  However, the future of numpy-like out-of-core computations is Blaze. Have a look at it if you really want to take that route.    The \"unchunked\" case  First off, consider a  3D C-ordered array written to disk (I'll simulate it by calling arr.ravel() and printing the result, to make things more visible):  In [1]: import numpy as np  In [2]: arr = np.arange(4*6*6).reshape(4,6,6)  In [3]: arr Out[3]: array([[[  0,   1,   2,   3,   4,   5],         [  6,   7,   8,   9,  10,  11],         [ 12,  13,  14,  15,  16,  17],         [ 18,  19,  20,  21,  22,  23],         [ 24,  25,  26,  27,  28,  29],         [ 30,  31,  32,  33,  34,  35]],         [[ 36,  37,  38,  39,  40,  41],         [ 42,  43,  44,  45,  46,  47],         [ 48,  49,  50,  51,  52,  53],         [ 54,  55,  56,  57,  58,  59],         [ 60,  61,  62,  63,  64,  65],         [ 66,  67,  68,  69,  70,  71]],         [[ 72,  73,  74,  75,  76,  77],         [ 78,  79,  80,  81,  82,  83],         [ 84,  85,  86,  87,  88,  89],         [ 90,  91,  92,  93,  94,  95],         [ 96,  97,  98,  99, 100, 101],         [102, 103, 104, 105, 106, 107]],         [[108, 109, 110, 111, 112, 113],         [114, 115, 116, 117, 118, 119],         [120, 121, 122, 123, 124, 125],         [126, 127, 128, 129, 130, 131],         [132, 133, 134, 135, 136, 137],         [138, 139, 140, 141, 142, 143]]])   The values would be stored on-disk sequentially as shown on line 4 below. (Let's ignore filesystem details and fragmentation for the moment.)  In [4]: arr.ravel(order='C') Out[4]: array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143])   In the best case scenario, let's take a slice along the first axis.  Notice that these are just the first 36 values of the array.  This will be a very fast read! (one seek, one read)    In [5]: arr[0,:,:] Out[5]: array([[ 0,  1,  2,  3,  4,  5],        [ 6,  7,  8,  9, 10, 11],        [12, 13, 14, 15, 16, 17],        [18, 19, 20, 21, 22, 23],        [24, 25, 26, 27, 28, 29],        [30, 31, 32, 33, 34, 35]])   Similarly, the next slice along the first axis will just be the next 36 values. To read a complete slice along this axis, we only need one seek operation. If all we're going to be reading is various slices along this axis, then this is the perfect file structure.  However, let's consider the worst-case scenario: A slice along the last axis.  In [6]: arr[:,:,0] Out[6]: array([[  0,   6,  12,  18,  24,  30],        [ 36,  42,  48,  54,  60,  66],        [ 72,  78,  84,  90,  96, 102],        [108, 114, 120, 126, 132, 138]])   To read this slice in, we need 36 seeks and 36 reads, as all of the values are separated on disk. None of them are adjacent!  This may seem pretty minor, but as we get to larger and larger arrays, the number and size of the seek operations grows rapidly. For a large-ish (~10Gb) 3D array stored in this way and read in via memmap, reading a full slice along the \"worst\" axis can easily take tens of minutes, even with modern hardware. At the same time, a slice along the best axis can take less than a second.  For simplicity, I'm only showing \"full\" slices along a single axis, but the exact same thing happens with arbitrary slices of any subset of the data.  Incidentally there are several file formats that take advantage of this and basically store three copies of huge 3D arrays on disk: one in C-order, one in F-order, and one in the intermediate between the two.  (An example of this is Geoprobe's D3D format, though I'm not sure it's documented anywhere.)  Who cares if the final file size is 4TB, storage is cheap!  The crazy thing about that is that because the main use case is extracting a single sub-slice in each direction, the reads you want to make are very, very fast. It works very well!      The simple \"chunked\" case  Let's say we store 2x2x2 \"chunks\" of the 3D array as contiguous blocks on disk.  In other words, something like:  nx, ny, nz = arr.shape slices = [] for i in range(0, nx, 2):     for j in range(0, ny, 2):         for k in range(0, nz, 2):             slices.append((slice(i, i+2), slice(j, j+2), slice(k, k+2)))  chunked = np.hstack([arr[chunk].ravel() for chunk in slices])   So the data on disk would look like chunked:  array([  0,   1,   6,   7,  36,  37,  42,  43,   2,   3,   8,   9,  38,         39,  44,  45,   4,   5,  10,  11,  40,  41,  46,  47,  12,  13,         18,  19,  48,  49,  54,  55,  14,  15,  20,  21,  50,  51,  56,         57,  16,  17,  22,  23,  52,  53,  58,  59,  24,  25,  30,  31,         60,  61,  66,  67,  26,  27,  32,  33,  62,  63,  68,  69,  28,         29,  34,  35,  64,  65,  70,  71,  72,  73,  78,  79, 108, 109,        114, 115,  74,  75,  80,  81, 110, 111, 116, 117,  76,  77,  82,         83, 112, 113, 118, 119,  84,  85,  90,  91, 120, 121, 126, 127,         86,  87,  92,  93, 122, 123, 128, 129,  88,  89,  94,  95, 124,        125, 130, 131,  96,  97, 102, 103, 132, 133, 138, 139,  98,  99,        104, 105, 134, 135, 140, 141, 100, 101, 106, 107, 136, 137, 142, 143])   And just to show that they're 2x2x2 blocks of arr, notice that these are the first 8 values of chunked:  In [9]: arr[:2, :2, :2] Out[9]: array([[[ 0,  1],         [ 6,  7]],         [[36, 37],         [42, 43]]])   To read in any slice along an axis, we'd read in either 6 or 9 contiguous chunks (twice as much data as we need) and then only keep the portion we wanted. That's a worst-case maximum of 9 seeks vs a maximum of 36 seeks for the non-chunked version. (But the best case is still 6 seeks vs 1 for the memmapped array.) Because sequential reads are very fast compared to seeks, this significantly reduces the amount of time it takes to read an arbitrary subset into memory. Once again, this effect becomes larger with larger arrays.  HDF5 takes this a few steps farther.  The chunks don't have to be stored contiguously, and they're indexed by a B-Tree.  Furthermore, they don't have to be the same size on disk, so compression can be applied to each chunk.      Chunked arrays with h5py  By default, h5py doesn't created chunked HDF files on disk (I think pytables does, by contrast).  If you specify chunks=True when creating the dataset, however, you'll get a chunked array on disk.  As a quick, minimal example:  import numpy as np import h5py  data = np.random.random((100, 100, 100))  with h5py.File('test.hdf', 'w') as outfile:     dset = outfile.create_dataset('a_descriptive_name', data=data, chunks=True)     dset.attrs['some key'] = 'Did you want some metadata?'   Note that chunks=True tells h5py to automatically pick a chunk size for us.  If you know more about your most common use-case, you can optimize the chunk size/shape by specifying a shape tuple (e.g. (2,2,2) in the simple example above).  This allows you to make reads along a particular axis more efficient or optimize for reads/writes of a certain size.      I/O Performance comparison  Just to emphasize the point, let's compare reading in slices from a chunked HDF5 dataset and a large (~8GB), Fortran-ordered 3D array containing the same exact data.  I've cleared all OS caches between each run, so we're seeing the \"cold\" performance.  For each file type, we'll test reading in a \"full\" x-slice along the first axis and a \"full\" z-slize along the last axis.  For the Fortran-ordered memmapped array, the \"x\" slice is the worst case, and the \"z\" slice is the best case.  The code used is in a gist (including creating the hdf file).  I can't easily share the data used here, but you could simulate it by an array of zeros of the same shape (621, 4991, 2600) and type np.uint8.  The chunked_hdf.py looks like this:  import sys import h5py  def main():     data = read()      if sys.argv[1] == 'x':         x_slice(data)     elif sys.argv[1] == 'z':         z_slice(data)  def read():     f = h5py.File('/tmp/test.hdf5', 'r')     return f['seismic_volume']  def z_slice(data):     return data[:,:,0]  def x_slice(data):     return data[0,:,:]  main()   memmapped_array.py is similar, but has a touch more complexity to ensure the slices are actually loaded into memory (by default, another memmapped array would be returned, which wouldn't be an apples-to-apples comparison).  import numpy as np import sys  def main():     data = read()      if sys.argv[1] == 'x':         x_slice(data)     elif sys.argv[1] == 'z':         z_slice(data)  def read():     big_binary_filename = '/data/nankai/data/Volumes/kumdep01_flipY.3dv.vol'     shape = 621, 4991, 2600     header_len = 3072      data = np.memmap(filename=big_binary_filename, mode='r', offset=header_len,                      order='F', shape=shape, dtype=np.uint8)     return data  def z_slice(data):     dat = np.empty(data.shape[:2], dtype=data.dtype)     dat[:] = data[:,:,0]     return dat  def x_slice(data):     dat = np.empty(data.shape[1:], dtype=data.dtype)     dat[:] = data[0,:,:]     return dat  main()   Let's have a look at the HDF performance first:  jofer at cornbread in ~  $ sudo ./clear_cache.sh  jofer at cornbread in ~  $ time python chunked_hdf.py z python chunked_hdf.py z  0.64s user 0.28s system 3% cpu 23.800 total  jofer at cornbread in ~  $ sudo ./clear_cache.sh  jofer at cornbread in ~  $ time python chunked_hdf.py x python chunked_hdf.py x  0.12s user 0.30s system 1% cpu 21.856 total   A \"full\" x-slice and a \"full\" z-slice take about the same amount of time (~20sec).  Considering this is an 8GB array, that's not too bad.  Most of the time  And if we compare this to the memmapped array times (it's Fortran-ordered: A \"z-slice\" is the best case and an \"x-slice\" is the worst case.):  jofer at cornbread in ~  $ sudo ./clear_cache.sh  jofer at cornbread in ~  $ time python memmapped_array.py z python memmapped_array.py z  0.07s user 0.04s system 28% cpu 0.385 total  jofer at cornbread in ~  $ sudo ./clear_cache.sh  jofer at cornbread in ~  $ time python memmapped_array.py x python memmapped_array.py x  2.46s user 37.24s system 0% cpu 3:35:26.85 total   Yes, you read that right. 0.3 seconds for one slice direction and ~3.5 hours for the other.  The time to slice in the \"x\" direction is far longer than the amount of time it would take to load the entire 8GB array into memory and select the slice we wanted! (Again, this is a Fortran-ordered array.  The opposite x/z slice timing would be the case for a C-ordered array.)  However, if we're always wanting to take a slice along the best-case direction, the big binary array on disk is very good. (~0.3 sec!)   With a memmapped array, you're stuck with this I/O discrepancy (or perhaps anisotropy is a better term).  However, with a chunked HDF dataset, you can choose the chunksize such that access is either equal or is optimized for a particular use-case.  It gives you a lot more flexibility.  In summary  Hopefully that helps clear up one part of your question, at any rate.  HDF5 has many other advantages over \"raw\" memmaps, but I don't have room to expand on all of them here.  Compression can speed some things up (the data I work with doesn't benefit much from compression, so I rarely use it), and OS-level caching often plays more nicely with HDF5 files than with \"raw\" memmaps.  Beyond that, HDF5 is a really fantastic container format. It gives you a lot of flexibility in managing your data, and can be used from more or less any programming language.  Overall, try it and see if it works well for your use case.  I think you might be surprised.     ","Language":"Python","Tags":["python","numpy","hdf5","pytables","h5py"],"URL":"https://stackoverflow.com/questions/27710245/is-there-an-analysis-speed-or-memory-usage-advantage-to-using-hdf5-for-large-arr","A_Votes":"113","_type":"dict","isAccepted":"Yes","Q_Content":"    I am processing large 3D arrays, which I often need to slice in various ways to do a variety of data analysis. A typical \"cube\" can be ~100GB (and will likely get larger in the future)  It seems that the typical recommended file format for large datasets in python is to use HDF5 (either h5py or pytables). My question is: is there any speed or memory usage benefit to using HDF5 to store and analyze these cubes over storing them in simple flat binary files? Is HDF5 more appropriate for tabular data, as opposed to large arrays like what I am working with? I see that HDF5 can provide nice compression, but I am more interested in processing speed and dealing with memory overflow.  I frequently want to analyze only one large subset of the cube. One drawback of both pytables and h5py is it seems is that when I take a slice of the array, I always get a numpy array back, using up memory. However, if I slice a numpy memmap of a flat binary file, I can get a view, which keeps the data on disk. So, it seems that I can more easily analyze specific sectors of my data without overrunning my memory.  I have explored both pytables and h5py, and haven't seen the benefit of either so far for my purpose.      ","Q_Votes":"62"},{"Q_Title":"Which JSON module can I use in Python 2.5?","A_Content":"  You can use simplejson.  As shown by the answer form pkoch you can use the following import statement to  get a json library depending on the installed python version:  try:     import json except ImportError:     import simplejson as json       ","Language":"Python","Tags":["python","json"],"URL":"https://stackoverflow.com/questions/791561/which-json-module-can-i-use-in-python-2-5","A_Votes":"62","_type":"dict","isAccepted":"Yes","Q_Content":"    I would like to use Python's JSON module. It was only introduced in Python 2.6 and I'm stuck with 2.5 for now. Is the particular JSON module provided with Python 2.6 available as a separate module that can be used with 2.5?     ","Q_Votes":"62"},{"Q_Title":"Which JSON module can I use in Python 2.5?","A_Content":"  To Wells and others:     Way late here, but how can you write a script to import either json or simplejson depending on the installed python version?   Here's how:  try:     import json except ImportError:     import simplejson as json       ","Language":"Python","Tags":["python","json"],"URL":"https://stackoverflow.com/questions/791561/which-json-module-can-i-use-in-python-2-5","A_Votes":"49","_type":"dict","isAccepted":"No","Q_Content":"    I would like to use Python's JSON module. It was only introduced in Python 2.6 and I'm stuck with 2.5 for now. Is the particular JSON module provided with Python 2.6 available as a separate module that can be used with 2.5?     ","Q_Votes":"62"},{"Q_Title":"Which JSON module can I use in Python 2.5?","A_Content":"  I wrote the cjson 1.0.6 patch and my advice is don't use cjson -- there are other problems with cjson in how it handles unicode etc.  I don't think the speed of cjson is worth dealing with the bugs -- encoding/decoding json is usually a very small bit of the time needed to process a typical web request...  json in python 2.6+ is basically simplejson brought into the standard library I believe...     ","Language":"Python","Tags":["python","json"],"URL":"https://stackoverflow.com/questions/791561/which-json-module-can-i-use-in-python-2-5","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I would like to use Python's JSON module. It was only introduced in Python 2.6 and I'm stuck with 2.5 for now. Is the particular JSON module provided with Python 2.6 available as a separate module that can be used with 2.5?     ","Q_Votes":"62"},{"Q_Title":"Which JSON module can I use in Python 2.5?","A_Content":"  I prefer cjson since it's much faster: http://www.vazor.com/cjson.html     ","Language":"Python","Tags":["python","json"],"URL":"https://stackoverflow.com/questions/791561/which-json-module-can-i-use-in-python-2-5","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I would like to use Python's JSON module. It was only introduced in Python 2.6 and I'm stuck with 2.5 for now. Is the particular JSON module provided with Python 2.6 available as a separate module that can be used with 2.5?     ","Q_Votes":"62"},{"Q_Title":"Which JSON module can I use in Python 2.5?","A_Content":"  I am programming in Python 2.5 as well and wanted a suitable library. Here is how I did it.  donwloaded the simplejson egg file called  simplejson-2.0.6-py2.5-linux-i686.egg from http://pypi.python.org/simple/simplejson/  installed it using the command :  sudo python ./ez_setup.py ./simplejson-2.0.6-py2.5-linux-i686.egg  Then imported the json library into the script file by doing :  import sys sys.path.append(\"/home/coolkid/Android/simplejson/simplejson-2.0.6-py2.5-linux-i686.egg\") try: import simplejson as json except ImportError: print (\"import error\")      ","Language":"Python","Tags":["python","json"],"URL":"https://stackoverflow.com/questions/791561/which-json-module-can-i-use-in-python-2-5","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I would like to use Python's JSON module. It was only introduced in Python 2.6 and I'm stuck with 2.5 for now. Is the particular JSON module provided with Python 2.6 available as a separate module that can be used with 2.5?     ","Q_Votes":"62"},{"Q_Title":"WSGI vs uWSGi with Nginx [closed]","A_Content":"  Ok, guys this confusion is because of lack of detail from several sources, and the naming of these protocols, and what WSGI actually is.  Summary:   WSGI and uwsgi both ARE protocols, not servers.  It is used to communicate with web servers for load balancing and especially to take advantage of extra features that pure HTTP can not provide.  So far Nginx and Cherokee have implemented this protocol. uWSGI is a server and one of the protocols it implements is WSGI (do not confuse the uwsgi protocol with the uWSGI server).  WSGI is a Python specification.  There are several implementations of the WSGI specification and it's intended to be used for more than just application servers/web servers, but there are quite a few WSGI application servers (ie. CherryPy, which also happens to have a production ready WSGI compliant web server, if you weren't confused enough already!).  Comparing uwsgi to WSGI is comparing oranges to apples.      ","Language":"Python","Tags":["python","django","nginx","wsgi","uwsgi"],"URL":"https://stackoverflow.com/questions/7739810/wsgi-vs-uwsgi-with-nginx","A_Votes":"77","_type":"dict","isAccepted":"No","Q_Content":"    Could anyone please explain pros/cons when using WSGI VS uWSGI with Nginx.  Currently i am building up a production server for the Django website which i have prepared but unable to decide whether should i go with WSGI or uWSGI. Could you please explain in detail what differentiates each configuration? Which configuration should scale the best?  Thanks in advance     ","Q_Votes":"62"},{"Q_Title":"WSGI vs uWSGi with Nginx [closed]","A_Content":"  It is generally best to run Python in a separate process from your main web server. That way, the web server can have lots of tiny threads that serve static content really fast, while your separate Python processes will be big and heavyweight and each be running their own Python interpreter. So plain WSGI is bad, because it bloats every single one of your nginx threads with a big Python interpreter. Using flup or gunicorn or uWSGI behind nginx is much better, because that frees up nginx to simply serve content, and lets you choose how many tiny light nginx threads to run, independently of your choice of how many heavyweight Python threads you bring up to serve dynamic content. People seem very happy with gunicorn at the moment, but any of those three options should work fine.  Going forward, it also frees you up to move the Python to another server when load starts to get serious.     ","Language":"Python","Tags":["python","django","nginx","wsgi","uwsgi"],"URL":"https://stackoverflow.com/questions/7739810/wsgi-vs-uwsgi-with-nginx","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    Could anyone please explain pros/cons when using WSGI VS uWSGI with Nginx.  Currently i am building up a production server for the Django website which i have prepared but unable to decide whether should i go with WSGI or uWSGI. Could you please explain in detail what differentiates each configuration? Which configuration should scale the best?  Thanks in advance     ","Q_Votes":"62"},{"Q_Title":"WSGI vs uWSGi with Nginx [closed]","A_Content":"  I believe this right here http://flask.pocoo.org/docs/deploying/uwsgi/ is a good answer to clear up the confusion. The question isnt silly, happens to anyone who sees the two terms and has no prior info on how things work outside of mod_PHP world (for e.g. nothing against php or folks)  The site does well to explain in practical terms what is needed and what is the difference as well as a good deployment example for nginx.     ","Language":"Python","Tags":["python","django","nginx","wsgi","uwsgi"],"URL":"https://stackoverflow.com/questions/7739810/wsgi-vs-uwsgi-with-nginx","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    Could anyone please explain pros/cons when using WSGI VS uWSGI with Nginx.  Currently i am building up a production server for the Django website which i have prepared but unable to decide whether should i go with WSGI or uWSGI. Could you please explain in detail what differentiates each configuration? Which configuration should scale the best?  Thanks in advance     ","Q_Votes":"62"},{"Q_Title":"WSGI vs uWSGi with Nginx [closed]","A_Content":"  This blog post is a very detailed comparison of alot of Python WSGI servers, with a summary and some recommendations at the end.     ","Language":"Python","Tags":["python","django","nginx","wsgi","uwsgi"],"URL":"https://stackoverflow.com/questions/7739810/wsgi-vs-uwsgi-with-nginx","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Could anyone please explain pros/cons when using WSGI VS uWSGI with Nginx.  Currently i am building up a production server for the Django website which i have prepared but unable to decide whether should i go with WSGI or uWSGI. Could you please explain in detail what differentiates each configuration? Which configuration should scale the best?  Thanks in advance     ","Q_Votes":"62"},{"Q_Title":"How to check if all of the following items are in a list?","A_Content":"  Operators like <= in Python are generally not overriden to mean something significantly different than \"less than or equal to\".  It's unusual for the standard library does this--it smells like legacy API to me.  Use the equivalent and more clearly-named method, set.issubset.  Note that you don't need to convert the argument to a set; it'll do that for you if needed.  set(['a', 'b']).issubset(['a', 'b', 'c'])      ","Language":"Python","Tags":["list","python","inclusion"],"URL":"https://stackoverflow.com/questions/3931541/how-to-check-if-all-of-the-following-items-are-in-a-list","A_Votes":"59","_type":"dict","isAccepted":"Yes","Q_Content":"    I found, that there is related question, about how to find if at least one item exists in a list: How to check if one of the following items is in a list?  But what is the best and pythonic way to find whether all items exists in a list?  Searching through the docs I found this solution:  >>> l = ['a', 'b', 'c'] >>> set(['a', 'b']) <= set(l) True >>> set(['a', 'x']) <= set(l) False   Other solution would be this:  >>> l = ['a', 'b', 'c'] >>> all(x in l for x in ['a', 'b']) True >>> all(x in l for x in ['a', 'x']) False   But here you must do more typing.  Is there any other solutions?     ","Q_Votes":"62"},{"Q_Title":"How to check if all of the following items are in a list?","A_Content":"  I would probably use set in the following manner :   set(l).issuperset(set(['a','b']))    or the other way round :   set(['a','b']).issubset(set(l))    I find it a bit more readable, but it may be over-kill. Sets are particularly useful to compute union/intersection/differences between collections, but it may not be the best option in this situation ...     ","Language":"Python","Tags":["list","python","inclusion"],"URL":"https://stackoverflow.com/questions/3931541/how-to-check-if-all-of-the-following-items-are-in-a-list","A_Votes":"53","_type":"dict","isAccepted":"No","Q_Content":"    I found, that there is related question, about how to find if at least one item exists in a list: How to check if one of the following items is in a list?  But what is the best and pythonic way to find whether all items exists in a list?  Searching through the docs I found this solution:  >>> l = ['a', 'b', 'c'] >>> set(['a', 'b']) <= set(l) True >>> set(['a', 'x']) <= set(l) False   Other solution would be this:  >>> l = ['a', 'b', 'c'] >>> all(x in l for x in ['a', 'b']) True >>> all(x in l for x in ['a', 'x']) False   But here you must do more typing.  Is there any other solutions?     ","Q_Votes":"62"},{"Q_Title":"How to check if all of the following items are in a list?","A_Content":"  I like these two because they seem the most logical, the latter being shorter and probably fastest (shown here using new Set Literals which were backported to Python 2.7):  all(x in {'a', 'b', 'c'} for x in ['a', 'b']) # or {'a', 'b'}.issubset({'a', 'b', 'c'})      ","Language":"Python","Tags":["list","python","inclusion"],"URL":"https://stackoverflow.com/questions/3931541/how-to-check-if-all-of-the-following-items-are-in-a-list","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I found, that there is related question, about how to find if at least one item exists in a list: How to check if one of the following items is in a list?  But what is the best and pythonic way to find whether all items exists in a list?  Searching through the docs I found this solution:  >>> l = ['a', 'b', 'c'] >>> set(['a', 'b']) <= set(l) True >>> set(['a', 'x']) <= set(l) False   Other solution would be this:  >>> l = ['a', 'b', 'c'] >>> all(x in l for x in ['a', 'b']) True >>> all(x in l for x in ['a', 'x']) False   But here you must do more typing.  Is there any other solutions?     ","Q_Votes":"62"},{"Q_Title":"How to check if all of the following items are in a list?","A_Content":"  What if your lists contain duplicates like this:  v1 = ['s', 'h', 'e', 'e', 'p'] v2 = ['s', 's', 'h']   Sets do not contain duplicates. So, the following line returns True.  set(v2).issubset(v1)   To count for duplicates, you can use the code:  v1 = sorted(v1) v2 = sorted(v2)   def is_subseq(v2, v1):     \"\"\"Check whether v2 is a subsequence of v1.\"\"\"     it = iter(v1)     return all(c in it for c in v2)    So, the following line returns False.  is_subseq(v2, v1)      ","Language":"Python","Tags":["list","python","inclusion"],"URL":"https://stackoverflow.com/questions/3931541/how-to-check-if-all-of-the-following-items-are-in-a-list","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I found, that there is related question, about how to find if at least one item exists in a list: How to check if one of the following items is in a list?  But what is the best and pythonic way to find whether all items exists in a list?  Searching through the docs I found this solution:  >>> l = ['a', 'b', 'c'] >>> set(['a', 'b']) <= set(l) True >>> set(['a', 'x']) <= set(l) False   Other solution would be this:  >>> l = ['a', 'b', 'c'] >>> all(x in l for x in ['a', 'b']) True >>> all(x in l for x in ['a', 'x']) False   But here you must do more typing.  Is there any other solutions?     ","Q_Votes":"62"},{"Q_Title":"How to embed HTML into iPython output?","A_Content":"  This seems to work for me:  from IPython.core.display import display, HTML display(HTML('<h1>Hello, world!</h1>'))   The trick is to wrap it in \"display\" as well.  Source: http://python.6.x6.nabble.com/Printing-HTML-within-IPython-Notebook-IPython-specific-prettyprint-tp5016624p5016631.html     ","Language":"Python","Tags":["python","html","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/25698448/how-to-embed-html-into-ipython-output","A_Votes":"113","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to embed rendered HTML output into iPython output?  One way is to use  from IPython.core.display import HTML HTML('<a href=\"http://example.com\">link</a>')   or (IPython multiline cell alias)  %%html <a href=\"http://example.com\">link</a>   Which return a formatted link, but   This link doesn't open a browser with the webpage itself from the console. IPython notebooks support honest rendering, though. I'm unaware about how to render HTML() object within, say, a list or pandas printed table. You can do df.to_html(), but without making links inside cells. This output isn't interactive in the PyCharm Python console (because it's not QT).   How can I overcome thes shortcomings and make iPython output a bit more interactive?     ","Q_Votes":"62"},{"Q_Title":"How to embed HTML into iPython output?","A_Content":"  Expanding on @Harmon above, looks like you can combine the display and print statements together ... if you need. Or, maybe it's easier to just format your entire HTML as one string and then use display. Either way, nice feature.  display(HTML('<h1>Hello, world!</h1>')) print(\"Here's a link:\") display(HTML(\"<a href='http://www.google.com' target='_blank'>www.google.com</a>\")) print(\"some more printed text ...\") display(HTML('<p>Paragraph text here ...</p>'))   Outputs something like this:    Hello, world!  Here's a link:  www.google.com  some more printed text ...  Paragraph text here ...       ","Language":"Python","Tags":["python","html","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/25698448/how-to-embed-html-into-ipython-output","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to embed rendered HTML output into iPython output?  One way is to use  from IPython.core.display import HTML HTML('<a href=\"http://example.com\">link</a>')   or (IPython multiline cell alias)  %%html <a href=\"http://example.com\">link</a>   Which return a formatted link, but   This link doesn't open a browser with the webpage itself from the console. IPython notebooks support honest rendering, though. I'm unaware about how to render HTML() object within, say, a list or pandas printed table. You can do df.to_html(), but without making links inside cells. This output isn't interactive in the PyCharm Python console (because it's not QT).   How can I overcome thes shortcomings and make iPython output a bit more interactive?     ","Q_Votes":"62"},{"Q_Title":"How to embed HTML into iPython output?","A_Content":"  Related: While constructing a class, def _reper_html_(self): ... can be used to create a custom HTML representation of its instances:  class Foo:     def _repr_html_(self):         return \"Hello <b>World</b>!\"  o = Foo() o   will render as:     Hello World!   For more info refer to IPython's docs.  An advanced example:  from html import escape # Python 3 only :-)  class Todo:     def __init__(self):         self.items = []      def add(self, text, completed):         self.items.append({'text': text, 'completed': completed})      def _repr_html_(self):         return \"<ol>{}</ol>\".format(\"\".join(\"<li>{} {}</li>\".format(             \"☑\" if item['completed'] else \"☐\",             escape(item['text'])         ) for item in self.items))  my_todo = Todo() my_todo.add(\"Buy milk\", False) my_todo.add(\"Do homework\", False) my_todo.add(\"Play video games\", True)  my_todo   Will render:          ☐ Buy milk     ☐ Do homework     ☑ Play video games         ","Language":"Python","Tags":["python","html","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/25698448/how-to-embed-html-into-ipython-output","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to embed rendered HTML output into iPython output?  One way is to use  from IPython.core.display import HTML HTML('<a href=\"http://example.com\">link</a>')   or (IPython multiline cell alias)  %%html <a href=\"http://example.com\">link</a>   Which return a formatted link, but   This link doesn't open a browser with the webpage itself from the console. IPython notebooks support honest rendering, though. I'm unaware about how to render HTML() object within, say, a list or pandas printed table. You can do df.to_html(), but without making links inside cells. This output isn't interactive in the PyCharm Python console (because it's not QT).   How can I overcome thes shortcomings and make iPython output a bit more interactive?     ","Q_Votes":"62"},{"Q_Title":"How to embed HTML into iPython output?","A_Content":"  I was looking for a Jupyter notebook specific answer and couldn't find one, so I'll just leave this here:   Jupyter notebook markdown cells render html tags:  <a href=\"your_link_here.com\">Your text here!</a>      ","Language":"Python","Tags":["python","html","ipython","jupyter-notebook"],"URL":"https://stackoverflow.com/questions/25698448/how-to-embed-html-into-ipython-output","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to embed rendered HTML output into iPython output?  One way is to use  from IPython.core.display import HTML HTML('<a href=\"http://example.com\">link</a>')   or (IPython multiline cell alias)  %%html <a href=\"http://example.com\">link</a>   Which return a formatted link, but   This link doesn't open a browser with the webpage itself from the console. IPython notebooks support honest rendering, though. I'm unaware about how to render HTML() object within, say, a list or pandas printed table. You can do df.to_html(), but without making links inside cells. This output isn't interactive in the PyCharm Python console (because it's not QT).   How can I overcome thes shortcomings and make iPython output a bit more interactive?     ","Q_Votes":"62"},{"Q_Title":"Django: How should I store a money value?","A_Content":"  You might want to use the .quantize() method. This will round a decimal value to a certain number of places, the argument you provide specifies the number of places:  >>> from decimal import Decimal >>> Decimal(\"12.234\").quantize(Decimal(\"0.00\")) Decimal(\"12.23\")   It can also take an argument to specify what rounding approach you want (different accounting systems might want different rounding). More info in the Python docs.  Below is a custom field that automatically produces the correct value. Note that this is only when it is retrieved from the database, and wont help you when you set it yourself (until you save it to the db and retrieve it again!).  from django.db import models from decimal import Decimal class CurrencyField(models.DecimalField):     __metaclass__ = models.SubfieldBase      def to_python(self, value):         try:            return super(CurrencyField, self).to_python(value).quantize(Decimal(\"0.01\"))         except AttributeError:            return None   [edit]  added __metaclass__, see Django: Why does this custom model field not behave as expected?     ","Language":"Python","Tags":["python","django","django-models","decimal","currency"],"URL":"https://stackoverflow.com/questions/2013835/django-how-should-i-store-a-money-value","A_Votes":"61","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm running into a paradigm problem here. I don't know whether I should store money as a Decimal(), or if I should store it as a string and convert it to a decimal myself. My reasoning is this:  PayPal requires 2 decimal places, so if I have a product that is 49 dollars even, PayPal wants to see 49.00 come across the wire. Django's DecimalField() doesn't set a decimal amount. It only stores a maximum decimal places amount. So, if you have 49 in there, and you have the field set to 2 decimal places, it'll still store it as 49. I know that Django is basically type casting when it deserializes back from the database into a Decimal (since Databases don't have decimal fields), so I'm not completely concerned with the speed issues as much as I am with the design issues of this problem. I want to do what's best for extensibility.  Or, better yet, does anyone know how to configure a django DecimalField() to always format with the TWO_PLACES formatting style.     ","Q_Votes":"62"},{"Q_Title":"Django: How should I store a money value?","A_Content":"  I think you should store it in a decimal format and format it to 00.00 format only then sending it to PayPal, like this:  pricestr = \"%01.2f\" % price   If you want, you can add a method to your model:  def formattedprice(self):     return \"%01.2f\" % self.price      ","Language":"Python","Tags":["python","django","django-models","decimal","currency"],"URL":"https://stackoverflow.com/questions/2013835/django-how-should-i-store-a-money-value","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    I'm running into a paradigm problem here. I don't know whether I should store money as a Decimal(), or if I should store it as a string and convert it to a decimal myself. My reasoning is this:  PayPal requires 2 decimal places, so if I have a product that is 49 dollars even, PayPal wants to see 49.00 come across the wire. Django's DecimalField() doesn't set a decimal amount. It only stores a maximum decimal places amount. So, if you have 49 in there, and you have the field set to 2 decimal places, it'll still store it as 49. I know that Django is basically type casting when it deserializes back from the database into a Decimal (since Databases don't have decimal fields), so I'm not completely concerned with the speed issues as much as I am with the design issues of this problem. I want to do what's best for extensibility.  Or, better yet, does anyone know how to configure a django DecimalField() to always format with the TWO_PLACES formatting style.     ","Q_Votes":"62"},{"Q_Title":"Django: How should I store a money value?","A_Content":"  My late to the party version that adds South migrations.  from decimal import Decimal from django.db import models  try:     from south.modelsinspector import add_introspection_rules except ImportError:     SOUTH = False else:     SOUTH = True  class CurrencyField(models.DecimalField):     __metaclass__ = models.SubfieldBase      def __init__(self, verbose_name=None, name=None, **kwargs):         decimal_places = kwargs.pop('decimal_places', 2)         max_digits = kwargs.pop('max_digits', 10)          super(CurrencyField, self). __init__(             verbose_name=verbose_name, name=name, max_digits=max_digits,             decimal_places=decimal_places, **kwargs)      def to_python(self, value):         try:             return super(CurrencyField, self).to_python(value).quantize(Decimal(\"0.01\"))         except AttributeError:             return None  if SOUTH:     add_introspection_rules([         (             [CurrencyField],             [],             {                 \"decimal_places\": [\"decimal_places\", { \"default\": \"2\" }],                 \"max_digits\": [\"max_digits\", { \"default\": \"10\" }],             },         ),     ], ['^application\\.fields\\.CurrencyField'])      ","Language":"Python","Tags":["python","django","django-models","decimal","currency"],"URL":"https://stackoverflow.com/questions/2013835/django-how-should-i-store-a-money-value","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I'm running into a paradigm problem here. I don't know whether I should store money as a Decimal(), or if I should store it as a string and convert it to a decimal myself. My reasoning is this:  PayPal requires 2 decimal places, so if I have a product that is 49 dollars even, PayPal wants to see 49.00 come across the wire. Django's DecimalField() doesn't set a decimal amount. It only stores a maximum decimal places amount. So, if you have 49 in there, and you have the field set to 2 decimal places, it'll still store it as 49. I know that Django is basically type casting when it deserializes back from the database into a Decimal (since Databases don't have decimal fields), so I'm not completely concerned with the speed issues as much as I am with the design issues of this problem. I want to do what's best for extensibility.  Or, better yet, does anyone know how to configure a django DecimalField() to always format with the TWO_PLACES formatting style.     ","Q_Votes":"62"},{"Q_Title":"Django: How should I store a money value?","A_Content":"  Money should be stored in money field, which sadly does not exist. Since money is two dimensional value (amount, currency).  There is python-money lib, that has many forks, yet I haven't found working one.    Recommendations:  python-money probably the best fork https://bitbucket.org/acoobe/python-money  django-money recommended by akumria: http://pypi.python.org/pypi/django-money/ (havent tried that one yet).     ","Language":"Python","Tags":["python","django","django-models","decimal","currency"],"URL":"https://stackoverflow.com/questions/2013835/django-how-should-i-store-a-money-value","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I'm running into a paradigm problem here. I don't know whether I should store money as a Decimal(), or if I should store it as a string and convert it to a decimal myself. My reasoning is this:  PayPal requires 2 decimal places, so if I have a product that is 49 dollars even, PayPal wants to see 49.00 come across the wire. Django's DecimalField() doesn't set a decimal amount. It only stores a maximum decimal places amount. So, if you have 49 in there, and you have the field set to 2 decimal places, it'll still store it as 49. I know that Django is basically type casting when it deserializes back from the database into a Decimal (since Databases don't have decimal fields), so I'm not completely concerned with the speed issues as much as I am with the design issues of this problem. I want to do what's best for extensibility.  Or, better yet, does anyone know how to configure a django DecimalField() to always format with the TWO_PLACES formatting style.     ","Q_Votes":"62"},{"Q_Title":"Django: How should I store a money value?","A_Content":"  I suggest to avoid mixing representation with storage. Store the data as a decimal value with 2 places.  In the UI layer, display it in a form which is suitable for the user (so maybe omit the \".00\").  When you send the data to PayPal, format it as the interface requires.     ","Language":"Python","Tags":["python","django","django-models","decimal","currency"],"URL":"https://stackoverflow.com/questions/2013835/django-how-should-i-store-a-money-value","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I'm running into a paradigm problem here. I don't know whether I should store money as a Decimal(), or if I should store it as a string and convert it to a decimal myself. My reasoning is this:  PayPal requires 2 decimal places, so if I have a product that is 49 dollars even, PayPal wants to see 49.00 come across the wire. Django's DecimalField() doesn't set a decimal amount. It only stores a maximum decimal places amount. So, if you have 49 in there, and you have the field set to 2 decimal places, it'll still store it as 49. I know that Django is basically type casting when it deserializes back from the database into a Decimal (since Databases don't have decimal fields), so I'm not completely concerned with the speed issues as much as I am with the design issues of this problem. I want to do what's best for extensibility.  Or, better yet, does anyone know how to configure a django DecimalField() to always format with the TWO_PLACES formatting style.     ","Q_Votes":"62"},{"Q_Title":"Django: How should I store a money value?","A_Content":"  Building on @Will_Hardy's answer, here it is so you don't have to specify max_digits and decimal_places every time:  from django.db import models from decimal import Decimal   class CurrencyField(models.DecimalField):   __metaclass__ = models.SubfieldBase    def __init__(self, verbose_name=None, name=None, **kwargs):     super(CurrencyField, self). __init__(         verbose_name=verbose_name, name=name, max_digits=10,         decimal_places=2, **kwargs)    def to_python(self, value):     try:       return super(CurrencyField, self).to_python(value).quantize(Decimal(\"0.01\"))     except AttributeError:       return None      ","Language":"Python","Tags":["python","django","django-models","decimal","currency"],"URL":"https://stackoverflow.com/questions/2013835/django-how-should-i-store-a-money-value","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm running into a paradigm problem here. I don't know whether I should store money as a Decimal(), or if I should store it as a string and convert it to a decimal myself. My reasoning is this:  PayPal requires 2 decimal places, so if I have a product that is 49 dollars even, PayPal wants to see 49.00 come across the wire. Django's DecimalField() doesn't set a decimal amount. It only stores a maximum decimal places amount. So, if you have 49 in there, and you have the field set to 2 decimal places, it'll still store it as 49. I know that Django is basically type casting when it deserializes back from the database into a Decimal (since Databases don't have decimal fields), so I'm not completely concerned with the speed issues as much as I am with the design issues of this problem. I want to do what's best for extensibility.  Or, better yet, does anyone know how to configure a django DecimalField() to always format with the TWO_PLACES formatting style.     ","Q_Votes":"62"},{"Q_Title":"Django: How should I store a money value?","A_Content":"  In my experience and also from others, money is best stored as combination of currency and the amount in cents.   It's very easy to handle and calculate with it.     ","Language":"Python","Tags":["python","django","django-models","decimal","currency"],"URL":"https://stackoverflow.com/questions/2013835/django-how-should-i-store-a-money-value","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I'm running into a paradigm problem here. I don't know whether I should store money as a Decimal(), or if I should store it as a string and convert it to a decimal myself. My reasoning is this:  PayPal requires 2 decimal places, so if I have a product that is 49 dollars even, PayPal wants to see 49.00 come across the wire. Django's DecimalField() doesn't set a decimal amount. It only stores a maximum decimal places amount. So, if you have 49 in there, and you have the field set to 2 decimal places, it'll still store it as 49. I know that Django is basically type casting when it deserializes back from the database into a Decimal (since Databases don't have decimal fields), so I'm not completely concerned with the speed issues as much as I am with the design issues of this problem. I want to do what's best for extensibility.  Or, better yet, does anyone know how to configure a django DecimalField() to always format with the TWO_PLACES formatting style.     ","Q_Votes":"62"},{"Q_Title":"Django: How should I store a money value?","A_Content":"  You store it as a DecimalField and manually add the decimals if you need to, as Valya said, using basic formatting techniques.  You can even add a Model Method to you product or transaction model that will spit out the DecimalField as an appropriately formatted string.     ","Language":"Python","Tags":["python","django","django-models","decimal","currency"],"URL":"https://stackoverflow.com/questions/2013835/django-how-should-i-store-a-money-value","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm running into a paradigm problem here. I don't know whether I should store money as a Decimal(), or if I should store it as a string and convert it to a decimal myself. My reasoning is this:  PayPal requires 2 decimal places, so if I have a product that is 49 dollars even, PayPal wants to see 49.00 come across the wire. Django's DecimalField() doesn't set a decimal amount. It only stores a maximum decimal places amount. So, if you have 49 in there, and you have the field set to 2 decimal places, it'll still store it as 49. I know that Django is basically type casting when it deserializes back from the database into a Decimal (since Databases don't have decimal fields), so I'm not completely concerned with the speed issues as much as I am with the design issues of this problem. I want to do what's best for extensibility.  Or, better yet, does anyone know how to configure a django DecimalField() to always format with the TWO_PLACES formatting style.     ","Q_Votes":"62"},{"Q_Title":"Negative list index? [duplicate]","A_Content":"  Negative numbers mean that you count from the right instead of the left. So, list[-1] refers to the last element, list[-2] is the second-last, and so on.     ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/11367902/negative-list-index","A_Votes":"118","_type":"dict","isAccepted":"Yes","Q_Content":"       Possible Duplicate:   Explain slice notation       I'm trying to understand the following piece of code:  # node list n = [] for i in xrange(1, numnodes + 1):     tmp = session.newobject();     n.append(tmp) link(n[0], n[-1])   Specifically, I don't understand what the index -1 refers to. If the index 0 refers to the first element, then what does -1 refer to?     ","Q_Votes":"62"},{"Q_Title":"Negative list index? [duplicate]","A_Content":"  List indexes of -x mean the xth item from the end of the list, so n[-1] means the last item in the list n. Any good Python tutorial should have told you this.  It's an unusual convention that few languages other than Python have adopted, but it is extraordinarily useful; in any other language you'll spend a lot of time writing n[n.length-1] to access the last item of a list.     ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/11367902/negative-list-index","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"       Possible Duplicate:   Explain slice notation       I'm trying to understand the following piece of code:  # node list n = [] for i in xrange(1, numnodes + 1):     tmp = session.newobject();     n.append(tmp) link(n[0], n[-1])   Specifically, I don't understand what the index -1 refers to. If the index 0 refers to the first element, then what does -1 refer to?     ","Q_Votes":"62"},{"Q_Title":"list comprehension filtering - “the set() trap”","A_Content":"  In order to optimize set(list_2), the interpreter needs to prove that list_2 (and all of its elements) does not change between iterations. This is a hard problem in the general case, and it would not surprise me if the interpreter does not even attempt to tackle it.  On the other hand a set literal cannot change its value between iterations, so the optimization is known to be safe.     ","Language":"Python","Tags":["python","python-3.x","python-internals"],"URL":"https://stackoverflow.com/questions/20056458/list-comprehension-filtering-the-set-trap","A_Votes":"48","_type":"dict","isAccepted":"Yes","Q_Content":"    A reasonably common operation is to filter one list based on another list.  People quickly find that this:  [x for x in list_1 if x in list_2]   is slow for large inputs - it's O(n*m).  Yuck.  How do we speed this up?  Use a set to make filtering lookups O(1):  s = set(list_2) [x for x in list_1 if x in s]   This gives nice overall O(n) behavior.  I however often see even veteran coders fall into The Trap™:  [x for x in list_1 if x in set(list_2)]   Ack!  This is again O(n*m) since python builds set(list_2) every time, not just once.    I thought that was the end of the story - python can't optimize it away to only build the set once.  Just be aware of the pitfall.  Gotta live with it.  Hmm.  #python 3.3.2+ list_2 = list(range(20)) #small for demonstration purposes s = set(list_2) list_1 = list(range(100000)) def f():     return [x for x in list_1 if x in s] def g():     return [x for x in list_1 if x in set(list_2)] def h():     return [x for x in list_1 if x in {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19}]  %timeit f() 100 loops, best of 3: 7.31 ms per loop  %timeit g() 10 loops, best of 3: 77.4 ms per loop  %timeit h() 100 loops, best of 3: 6.66 ms per loop   Huh, python (3.3) can optimize away a set literal.  It's even faster than f() in this case, presumably because it gets to replace a LOAD_GLOBAL with a LOAD_FAST.  #python 2.7.5+ %timeit h() 10 loops, best of 3: 72.5 ms per loop   Python 2 notably doesn't do this optimization.  I've tried investigating further what python3 is doing but unfortunately dis.dis cannot probe the innards of comprehension expressions.  Basically everything interesting turns into MAKE_FUNCTION.  So now I'm wondering - why can python 3.x optimize away the set literal to only build once, but not set(list_2)?     ","Q_Votes":"62"},{"Q_Title":"list comprehension filtering - “the set() trap”","A_Content":"  From What’s New In Python 3.2:     Python’s peephole optimizer now recognizes patterns such x in {1, 2,   3} as being a test for membership in a set of constants. The optimizer   recasts the set as a frozenset and stores the pre-built constant.      ","Language":"Python","Tags":["python","python-3.x","python-internals"],"URL":"https://stackoverflow.com/questions/20056458/list-comprehension-filtering-the-set-trap","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    A reasonably common operation is to filter one list based on another list.  People quickly find that this:  [x for x in list_1 if x in list_2]   is slow for large inputs - it's O(n*m).  Yuck.  How do we speed this up?  Use a set to make filtering lookups O(1):  s = set(list_2) [x for x in list_1 if x in s]   This gives nice overall O(n) behavior.  I however often see even veteran coders fall into The Trap™:  [x for x in list_1 if x in set(list_2)]   Ack!  This is again O(n*m) since python builds set(list_2) every time, not just once.    I thought that was the end of the story - python can't optimize it away to only build the set once.  Just be aware of the pitfall.  Gotta live with it.  Hmm.  #python 3.3.2+ list_2 = list(range(20)) #small for demonstration purposes s = set(list_2) list_1 = list(range(100000)) def f():     return [x for x in list_1 if x in s] def g():     return [x for x in list_1 if x in set(list_2)] def h():     return [x for x in list_1 if x in {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19}]  %timeit f() 100 loops, best of 3: 7.31 ms per loop  %timeit g() 10 loops, best of 3: 77.4 ms per loop  %timeit h() 100 loops, best of 3: 6.66 ms per loop   Huh, python (3.3) can optimize away a set literal.  It's even faster than f() in this case, presumably because it gets to replace a LOAD_GLOBAL with a LOAD_FAST.  #python 2.7.5+ %timeit h() 10 loops, best of 3: 72.5 ms per loop   Python 2 notably doesn't do this optimization.  I've tried investigating further what python3 is doing but unfortunately dis.dis cannot probe the innards of comprehension expressions.  Basically everything interesting turns into MAKE_FUNCTION.  So now I'm wondering - why can python 3.x optimize away the set literal to only build once, but not set(list_2)?     ","Q_Votes":"62"},{"Q_Title":"list comprehension filtering - “the set() trap”","A_Content":"     So now I'm wondering - why can python 3.x optimize away the set   literal to only build once, but not set(list_2)?   No one's mentioned this issue yet: how do you know set([1,2,3]) and {1, 2, 3} are the same thing?  >>> import random >>> def set(arg): ...     return [random.choice(range(5))] ...  >>> list1 = list(range(5)) >>> [x for x in list1 if x in set(list1)] [0, 4] >>> [x for x in list1 if x in set(list1)] [0]   You can't shadow a literal; you can shadow set.  So before you can consider hoisting, you need to know not just that list1 isn't being affected, you need to be sure that set is what you think it is.  Sometimes you can do that, either under restrictive conditions at compile time or more conveniently at runtime, but it's definitely nontrivial.   It's kind of funny: often when the suggestion of doing optimizations like this comes up, one pushback is that as nice as they are, it makes it harder to reason about what Python performance is going to be like, even algorithmically.  Your question provides some evidence for this objection.     ","Language":"Python","Tags":["python","python-3.x","python-internals"],"URL":"https://stackoverflow.com/questions/20056458/list-comprehension-filtering-the-set-trap","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    A reasonably common operation is to filter one list based on another list.  People quickly find that this:  [x for x in list_1 if x in list_2]   is slow for large inputs - it's O(n*m).  Yuck.  How do we speed this up?  Use a set to make filtering lookups O(1):  s = set(list_2) [x for x in list_1 if x in s]   This gives nice overall O(n) behavior.  I however often see even veteran coders fall into The Trap™:  [x for x in list_1 if x in set(list_2)]   Ack!  This is again O(n*m) since python builds set(list_2) every time, not just once.    I thought that was the end of the story - python can't optimize it away to only build the set once.  Just be aware of the pitfall.  Gotta live with it.  Hmm.  #python 3.3.2+ list_2 = list(range(20)) #small for demonstration purposes s = set(list_2) list_1 = list(range(100000)) def f():     return [x for x in list_1 if x in s] def g():     return [x for x in list_1 if x in set(list_2)] def h():     return [x for x in list_1 if x in {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19}]  %timeit f() 100 loops, best of 3: 7.31 ms per loop  %timeit g() 10 loops, best of 3: 77.4 ms per loop  %timeit h() 100 loops, best of 3: 6.66 ms per loop   Huh, python (3.3) can optimize away a set literal.  It's even faster than f() in this case, presumably because it gets to replace a LOAD_GLOBAL with a LOAD_FAST.  #python 2.7.5+ %timeit h() 10 loops, best of 3: 72.5 ms per loop   Python 2 notably doesn't do this optimization.  I've tried investigating further what python3 is doing but unfortunately dis.dis cannot probe the innards of comprehension expressions.  Basically everything interesting turns into MAKE_FUNCTION.  So now I'm wondering - why can python 3.x optimize away the set literal to only build once, but not set(list_2)?     ","Q_Votes":"62"},{"Q_Title":"list comprehension filtering - “the set() trap”","A_Content":"  Too long for a comment  This won't speak to the optimization details or v2 vs. v3 differences. But when I encounter this in some situations, I find making a context manager out of the data object is useful:  class context_set(set):     def __enter__(self):         return self     def __exit__(self, *args):         pass  def context_version():     with context_set(list_2) as s:         return [x for x in list_1 if x in s]   Using this I see:  In [180]: %timeit context_version() 100 loops, best of 3: 17.8 ms per loop   and in some cases, it provides a nice stop-gap between creating the object before the comprehension vs. creating it within the comprehension, and allows custom tear-down code if you want it.  A more generic version can be made using contextlib.contextmanager. Here's a quick-and-dirty version of what I mean.  def context(some_type):     from contextlib import contextmanager     generator_apply_type = lambda x: (some_type(y) for y in (x,))     return contextmanager(generator_apply_type)   Then one can do:  with context(set)(list_2) as s:     # ...   or just as easily  with context(tuple)(list_2) as t:     # ...      ","Language":"Python","Tags":["python","python-3.x","python-internals"],"URL":"https://stackoverflow.com/questions/20056458/list-comprehension-filtering-the-set-trap","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    A reasonably common operation is to filter one list based on another list.  People quickly find that this:  [x for x in list_1 if x in list_2]   is slow for large inputs - it's O(n*m).  Yuck.  How do we speed this up?  Use a set to make filtering lookups O(1):  s = set(list_2) [x for x in list_1 if x in s]   This gives nice overall O(n) behavior.  I however often see even veteran coders fall into The Trap™:  [x for x in list_1 if x in set(list_2)]   Ack!  This is again O(n*m) since python builds set(list_2) every time, not just once.    I thought that was the end of the story - python can't optimize it away to only build the set once.  Just be aware of the pitfall.  Gotta live with it.  Hmm.  #python 3.3.2+ list_2 = list(range(20)) #small for demonstration purposes s = set(list_2) list_1 = list(range(100000)) def f():     return [x for x in list_1 if x in s] def g():     return [x for x in list_1 if x in set(list_2)] def h():     return [x for x in list_1 if x in {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19}]  %timeit f() 100 loops, best of 3: 7.31 ms per loop  %timeit g() 10 loops, best of 3: 77.4 ms per loop  %timeit h() 100 loops, best of 3: 6.66 ms per loop   Huh, python (3.3) can optimize away a set literal.  It's even faster than f() in this case, presumably because it gets to replace a LOAD_GLOBAL with a LOAD_FAST.  #python 2.7.5+ %timeit h() 10 loops, best of 3: 72.5 ms per loop   Python 2 notably doesn't do this optimization.  I've tried investigating further what python3 is doing but unfortunately dis.dis cannot probe the innards of comprehension expressions.  Basically everything interesting turns into MAKE_FUNCTION.  So now I'm wondering - why can python 3.x optimize away the set literal to only build once, but not set(list_2)?     ","Q_Votes":"62"},{"Q_Title":"list comprehension filtering - “the set() trap”","A_Content":"  The basic reason is that a literal really can't change, whereas if it's an expression like set(list_2), it's possible that evaluating the target expression or the iterable of the comprehension could change the value of set(list_2).  For instance, if you have  [f(x) for x in list_1 if x in set(list_2)]   It is possible that f modifies list_2.  Even for a simple [x for x in blah ...] expression, it's theoretically possible that the __iter__ method of blah could modify list_2.  I would imagine there is some scope for optimizations, but the current behavior keeps things simpler.  If you start adding optimizations for things like \"it is only evaluated once if the target expression is a single bare name and the iterable is a builtin list or dict...\" you make it much more complicated to figure out what will happen in any given situation.     ","Language":"Python","Tags":["python","python-3.x","python-internals"],"URL":"https://stackoverflow.com/questions/20056458/list-comprehension-filtering-the-set-trap","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    A reasonably common operation is to filter one list based on another list.  People quickly find that this:  [x for x in list_1 if x in list_2]   is slow for large inputs - it's O(n*m).  Yuck.  How do we speed this up?  Use a set to make filtering lookups O(1):  s = set(list_2) [x for x in list_1 if x in s]   This gives nice overall O(n) behavior.  I however often see even veteran coders fall into The Trap™:  [x for x in list_1 if x in set(list_2)]   Ack!  This is again O(n*m) since python builds set(list_2) every time, not just once.    I thought that was the end of the story - python can't optimize it away to only build the set once.  Just be aware of the pitfall.  Gotta live with it.  Hmm.  #python 3.3.2+ list_2 = list(range(20)) #small for demonstration purposes s = set(list_2) list_1 = list(range(100000)) def f():     return [x for x in list_1 if x in s] def g():     return [x for x in list_1 if x in set(list_2)] def h():     return [x for x in list_1 if x in {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19}]  %timeit f() 100 loops, best of 3: 7.31 ms per loop  %timeit g() 10 loops, best of 3: 77.4 ms per loop  %timeit h() 100 loops, best of 3: 6.66 ms per loop   Huh, python (3.3) can optimize away a set literal.  It's even faster than f() in this case, presumably because it gets to replace a LOAD_GLOBAL with a LOAD_FAST.  #python 2.7.5+ %timeit h() 10 loops, best of 3: 72.5 ms per loop   Python 2 notably doesn't do this optimization.  I've tried investigating further what python3 is doing but unfortunately dis.dis cannot probe the innards of comprehension expressions.  Basically everything interesting turns into MAKE_FUNCTION.  So now I'm wondering - why can python 3.x optimize away the set literal to only build once, but not set(list_2)?     ","Q_Votes":"62"},{"Q_Title":"Python threading.timer - repeat function every 'n' seconds","A_Content":"  The best way is to start the timer thread once. Inside your timer thread you'd code the following  class MyThread(Thread):     def __init__(self, event):         Thread.__init__(self)         self.stopped = event      def run(self):         while not self.stopped.wait(0.5):             print(\"my thread\")             # call a function   In the code that started the timer, you can then set the stopped event to stop the timer.  stopFlag = Event() thread = MyThread(stopFlag) thread.start() # this will stop the timer stopFlag.set()      ","Language":"Python","Tags":["python","python-3.x","python-2.7"],"URL":"https://stackoverflow.com/questions/12435211/python-threading-timer-repeat-function-every-n-seconds","A_Votes":"77","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm having difficulties with the python timer and would greatly appreciate some advice or help :D  I'm not too knowledgeable of how threads work, but I just want to fire off a function every 0.5 seconds and be able to start and stop and reset the timer.  However, I keep getting RuntimeError: threads can only be started once when I execute threading.timer.start() twice. Is there a work around for this? I tried applying threading.timer.cancel() before each start.  Pseudo code:  t=threading.timer(0.5,function) while True:     t.cancel()     t.start()      ","Q_Votes":"62"},{"Q_Title":"Python threading.timer - repeat function every 'n' seconds","A_Content":"  Using timer threads-  from threading import Timer,Thread,Event   class perpetualTimer():     def __init__(self,t,hFunction):       self.t=t       self.hFunction = hFunction       self.thread = Timer(self.t,self.handle_function)     def handle_function(self):       self.hFunction()       self.thread = Timer(self.t,self.handle_function)       self.thread.start()     def start(self):       self.thread.start()     def cancel(self):       self.thread.cancel()  def printer():     print 'ipsem lorem'  t = perpetualTimer(5,printer) t.start()   this can be stopped by t.cancel()     ","Language":"Python","Tags":["python","python-3.x","python-2.7"],"URL":"https://stackoverflow.com/questions/12435211/python-threading-timer-repeat-function-every-n-seconds","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I'm having difficulties with the python timer and would greatly appreciate some advice or help :D  I'm not too knowledgeable of how threads work, but I just want to fire off a function every 0.5 seconds and be able to start and stop and reset the timer.  However, I keep getting RuntimeError: threads can only be started once when I execute threading.timer.start() twice. Is there a work around for this? I tried applying threading.timer.cancel() before each start.  Pseudo code:  t=threading.timer(0.5,function) while True:     t.cancel()     t.start()      ","Q_Votes":"62"},{"Q_Title":"Python threading.timer - repeat function every 'n' seconds","A_Content":"  From Equivalent of setInterval in python:  import threading  def setInterval(interval):     def decorator(function):         def wrapper(*args, **kwargs):             stopped = threading.Event()              def loop(): # executed in another thread                 while not stopped.wait(interval): # until stopped                     function(*args, **kwargs)              t = threading.Thread(target=loop)             t.daemon = True # stop if the program exits             t.start()             return stopped         return wrapper     return decorator   Usage:  @setInterval(.5) def function():     \"...\"  stop = function() # start timer, the first call is in .5 seconds stop.set() # stop the loop stop = function() # start new timer # ... stop.set()    Or here's the same functionality but as a standalone function instead of a decorator:  cancel_future_calls = call_repeatedly(60, print, \"Hello, World\") # ... cancel_future_calls()    Here's how to do it without using threads.     ","Language":"Python","Tags":["python","python-3.x","python-2.7"],"URL":"https://stackoverflow.com/questions/12435211/python-threading-timer-repeat-function-every-n-seconds","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I'm having difficulties with the python timer and would greatly appreciate some advice or help :D  I'm not too knowledgeable of how threads work, but I just want to fire off a function every 0.5 seconds and be able to start and stop and reset the timer.  However, I keep getting RuntimeError: threads can only be started once when I execute threading.timer.start() twice. Is there a work around for this? I tried applying threading.timer.cancel() before each start.  Pseudo code:  t=threading.timer(0.5,function) while True:     t.cancel()     t.start()      ","Q_Votes":"62"},{"Q_Title":"Python threading.timer - repeat function every 'n' seconds","A_Content":"  In the interest of providing a correct answer using Timer as the OP requested, I'll improve upon swapnil jariwala's answer:  from threading import Timer import time   class InfiniteTimer():     \"\"\"A Timer class that does not stop, unless you want it to.\"\"\"      def __init__(self, seconds, target):         self._should_continue = False         self.is_running = False         self.seconds = seconds         self.target = target         self.thread = None      def _handle_target(self):         self.is_running = True         self.target()         self.is_running = False         self._start_timer()      def _start_timer(self):         if self._should_continue: # Code could have been running when cancel was called.             self.thread = Timer(self.seconds, self._handle_target)             self.thread.start()      def start(self):         if not self._should_continue and not self.is_running:             self._should_continue = True             self._start_timer()         else:             print(\"Timer already started or running, please wait if you're restarting.\")      def cancel(self):         if self.thread is not None:             self._should_continue = False # Just in case thread is running and cancel fails.             self.thread.cancel()         else:             print(\"Timer never started or failed to initialize.\")   def tick():     print('ipsem lorem')  # Example Usage t = InfiniteTimer(0.5, tick) t.start()   The import time is optional without the example usage.     ","Language":"Python","Tags":["python","python-3.x","python-2.7"],"URL":"https://stackoverflow.com/questions/12435211/python-threading-timer-repeat-function-every-n-seconds","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm having difficulties with the python timer and would greatly appreciate some advice or help :D  I'm not too knowledgeable of how threads work, but I just want to fire off a function every 0.5 seconds and be able to start and stop and reset the timer.  However, I keep getting RuntimeError: threads can only be started once when I execute threading.timer.start() twice. Is there a work around for this? I tried applying threading.timer.cancel() before each start.  Pseudo code:  t=threading.timer(0.5,function) while True:     t.cancel()     t.start()      ","Q_Votes":"62"},{"Q_Title":"Python threading.timer - repeat function every 'n' seconds","A_Content":"  I have changed some code in swapnil-jariwala code to make a little console clock.  from threading import Timer, Thread, Event from datetime import datetime   class perpetualTimer():      def __init__(self, t, hFunction):         self.t = t         self.hFunction = hFunction         self.thread = Timer(self.t, self.handle_function)      def handle_function(self):         self.hFunction()         self.thread = Timer(self.t, self.handle_function)         self.thread.start()      def start(self):         self.thread.start()      def cancel(self):         self.thread.cancel()   def printer():     tempo = datetime.today()     print(\"{}:{}:{}\".format(tempo.hour, tempo.minute, tempo.second))   t = perpetualTimer(1, printer) t.start()      OUTPUT   >>> 11:39:11 11:39:12 11:39:13 11:39:14 11:39:15 11:39:16 ...   Timer with a tkinter Graphic interface  This code puts the clock timer in a little window with tkinter  from threading import Timer, Thread, Event from datetime import datetime import tkinter as tk  app = tk.Tk() lab = tk.Label(app, text=\"Timer will start in a sec\") lab.pack()   class perpetualTimer():      def __init__(self, t, hFunction):         self.t = t         self.hFunction = hFunction         self.thread = Timer(self.t, self.handle_function)      def handle_function(self):         self.hFunction()         self.thread = Timer(self.t, self.handle_function)         self.thread.start()      def start(self):         self.thread.start()      def cancel(self):         self.thread.cancel()   def printer():     tempo = datetime.today()     clock = \"{}:{}:{}\".format(tempo.hour, tempo.minute, tempo.second)     try:         lab['text'] = clock     except RuntimeError:         exit()   t = perpetualTimer(1, printer) t.start() app.mainloop()   An example of flashcards game (sort of)  from threading import Timer, Thread, Event from datetime import datetime   class perpetualTimer():      def __init__(self, t, hFunction):         self.t = t         self.hFunction = hFunction         self.thread = Timer(self.t, self.handle_function)      def handle_function(self):         self.hFunction()         self.thread = Timer(self.t, self.handle_function)         self.thread.start()      def start(self):         self.thread.start()      def cancel(self):         self.thread.cancel()   x = datetime.today() start = x.second   def printer():     global questions, counter, start     x = datetime.today()     tempo = x.second     if tempo - 3 > start:         show_ans()     #print(\"\\n{}:{}:{}\".format(tempo.hour, tempo.minute, tempo.second), end=\"\")     print()     print(\"-\" + questions[counter])     counter += 1     if counter == len(answers):         counter = 0   def show_ans():     global answers, c2     print(\"It is {}\".format(answers[c2]))     c2 += 1     if c2 == len(answers):         c2 = 0   questions = [\"What is the capital of Italy?\",              \"What is the capital of France?\",              \"What is the capital of England?\",              \"What is the capital of Spain?\"]  answers = \"Rome\", \"Paris\", \"London\", \"Madrid\"  counter = 0 c2 = 0 print(\"Get ready to answer\") t = perpetualTimer(3, printer) t.start()   output:  Get ready to answer >>>  -What is the capital of Italy? It is Rome  -What is the capital of France? It is Paris  -What is the capital of England? ...      ","Language":"Python","Tags":["python","python-3.x","python-2.7"],"URL":"https://stackoverflow.com/questions/12435211/python-threading-timer-repeat-function-every-n-seconds","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm having difficulties with the python timer and would greatly appreciate some advice or help :D  I'm not too knowledgeable of how threads work, but I just want to fire off a function every 0.5 seconds and be able to start and stop and reset the timer.  However, I keep getting RuntimeError: threads can only be started once when I execute threading.timer.start() twice. Is there a work around for this? I tried applying threading.timer.cancel() before each start.  Pseudo code:  t=threading.timer(0.5,function) while True:     t.cancel()     t.start()      ","Q_Votes":"62"},{"Q_Title":"Python threading.timer - repeat function every 'n' seconds","A_Content":"  I had to do this for a project. What I ended up doing was start a separate thread for the function  t = threading.Thread(target =heartbeat, args=(worker,)) t.start()   ****heartbeat is my function, worker is one of my arguments****  inside of my heartbeat function:  def heartbeat(worker):      while True:         time.sleep(5)         #all of my code   So when I start the thread the function will repeatedly wait 5 seconds, run all of my code, and do that indefinitely. If you want to kill the process just kill the thread.     ","Language":"Python","Tags":["python","python-3.x","python-2.7"],"URL":"https://stackoverflow.com/questions/12435211/python-threading-timer-repeat-function-every-n-seconds","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm having difficulties with the python timer and would greatly appreciate some advice or help :D  I'm not too knowledgeable of how threads work, but I just want to fire off a function every 0.5 seconds and be able to start and stop and reset the timer.  However, I keep getting RuntimeError: threads can only be started once when I execute threading.timer.start() twice. Is there a work around for this? I tried applying threading.timer.cancel() before each start.  Pseudo code:  t=threading.timer(0.5,function) while True:     t.cancel()     t.start()      ","Q_Votes":"62"},{"Q_Title":"Python threading.timer - repeat function every 'n' seconds","A_Content":"  I have implemented a class that works as a timer.  I leave the link here in case anyone needs it: https://github.com/ivanhalencp/python/tree/master/xTimer     ","Language":"Python","Tags":["python","python-3.x","python-2.7"],"URL":"https://stackoverflow.com/questions/12435211/python-threading-timer-repeat-function-every-n-seconds","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm having difficulties with the python timer and would greatly appreciate some advice or help :D  I'm not too knowledgeable of how threads work, but I just want to fire off a function every 0.5 seconds and be able to start and stop and reset the timer.  However, I keep getting RuntimeError: threads can only be started once when I execute threading.timer.start() twice. Is there a work around for this? I tried applying threading.timer.cancel() before each start.  Pseudo code:  t=threading.timer(0.5,function) while True:     t.cancel()     t.start()      ","Q_Votes":"62"},{"Q_Title":"Python threading.timer - repeat function every 'n' seconds","A_Content":"  Improving a little on Hans Then's answer, we can just subclass the Timer function. The following becomes our entire \"repeat timer\" code, and it can be used as a drop-in replacement for threading.Timer with all the same arguments:  from threading import Timer  class RepeatTimer(Timer):     def run(self):         while not self.finished.wait(self.interval):             self.function(*self.args, **self.kwargs)   Usage example:  def dummyfn(msg=\"foo\"):     print(msg)  timer = RepeatTimer(1, dummyfn) timer.start() time.sleep(5) timer.cancel()   produces the following output:  foo foo foo foo   and  timer = RepeatTimer(1, dummyfn, args=(\"bar\",)) timer.start() time.sleep(5) timer.cancel()   produces  bar bar bar bar      ","Language":"Python","Tags":["python","python-3.x","python-2.7"],"URL":"https://stackoverflow.com/questions/12435211/python-threading-timer-repeat-function-every-n-seconds","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm having difficulties with the python timer and would greatly appreciate some advice or help :D  I'm not too knowledgeable of how threads work, but I just want to fire off a function every 0.5 seconds and be able to start and stop and reset the timer.  However, I keep getting RuntimeError: threads can only be started once when I execute threading.timer.start() twice. Is there a work around for this? I tried applying threading.timer.cancel() before each start.  Pseudo code:  t=threading.timer(0.5,function) while True:     t.cancel()     t.start()      ","Q_Votes":"62"},{"Q_Title":"Python threading.timer - repeat function every 'n' seconds","A_Content":"  from threading import Timer def TaskManager():     #do stuff     t = Timer( 1, TaskManager )     t.start()  TaskManager()   Here is small sample, it will help beter understanding how it runs. function taskManager() at the end create delayed function call to it self.  Try to change \"dalay\" variable and you will able to see difference  from threading import Timer, _sleep  # ------------------------------------------ DATA = [] dalay = 0.25 # sec counter = 0 allow_run = True FIFO = True  def taskManager():      global counter, DATA, delay, allow_run     counter += 1      if len(DATA) > 0:         if FIFO:             print(\"[\"+str(counter)+\"] new data: [\"+str(DATA.pop(0))+\"]\")         else:             print(\"[\"+str(counter)+\"] new data: [\"+str(DATA.pop())+\"]\")      else:         print(\"[\"+str(counter)+\"] no data\")      if allow_run:         #delayed method/function call to it self         t = Timer( dalay, taskManager )         t.start()      else:         print(\" END task-manager: disabled\")  # ------------------------------------------ def main():      DATA.append(\"data from main(): 0\")     _sleep(2)     DATA.append(\"data from main(): 1\")     _sleep(2)   # ------------------------------------------ print(\" START task-manager:\") taskManager()  _sleep(2) DATA.append(\"first data\")  _sleep(2) DATA.append(\"second data\")  print(\" START main():\") main() print(\" END main():\")  _sleep(2) DATA.append(\"last data\")  allow_run = False      ","Language":"Python","Tags":["python","python-3.x","python-2.7"],"URL":"https://stackoverflow.com/questions/12435211/python-threading-timer-repeat-function-every-n-seconds","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm having difficulties with the python timer and would greatly appreciate some advice or help :D  I'm not too knowledgeable of how threads work, but I just want to fire off a function every 0.5 seconds and be able to start and stop and reset the timer.  However, I keep getting RuntimeError: threads can only be started once when I execute threading.timer.start() twice. Is there a work around for this? I tried applying threading.timer.cancel() before each start.  Pseudo code:  t=threading.timer(0.5,function) while True:     t.cancel()     t.start()      ","Q_Votes":"62"},{"Q_Title":"How exactly does a generator comprehension work?","A_Content":"  Do you understand list comprehensions? If so, a generator expression is like a list comprehension, but instead of finding all the items you're interested and packing them into list, it waits, and yields each item out of the expression, one by one.  python2 version:  >>> my_list = [1, 3, 5, 9, 2, 6] >>> filtered_list = [item for item in my_list if item > 3] >>> print filtered_list [5, 9, 6] >>> len(filtered_list) 3 >>> # compare to generator expression ...  >>> filtered_gen = (item for item in my_list if item > 3) >>> print filtered_gen  # notice it's a generator object <generator object at 0xb7d5e02c> >>> len(filtered_gen) # So technically, it has no length Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: object of type 'generator' has no len() >>> # We extract each item out individually. We'll do it manually first. ...  >>> filtered_gen.next() 5 >>> filtered_gen.next() 9 >>> filtered_gen.next() 6 >>> filtered_gen.next() # Should be all out of items and give an error Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> StopIteration >>> # Yup, the generator is spent. No values for you! ...  >>> # Let's prove it gives the same results as our list comprehension ...  >>> filtered_gen = (item for item in my_list if item > 3) >>> gen_to_list = list(filtered_gen) >>> print gen_to_list [5, 9, 6] >>> filtered_list == gen_to_list True >>>    python3 version:  change next() to __next__()  Because a generator expression only has to yield one item at a time, it can lead to big savings in memory usage. Generator expressions make the most sense in scenarios where you need to take one item at a time, do a lot of calculations based on that item, and then move on to the next item. If you need more than one value, you can also use a generator expression and grab a few at a time. If you need all the values before your program proceeds, use a list comprehension instead.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/364802/how-exactly-does-a-generator-comprehension-work","A_Votes":"107","_type":"dict","isAccepted":"Yes","Q_Content":"    What does generator comprehension do? How does it work? I couldn't find a tutorial about it.     ","Q_Votes":"62"},{"Q_Title":"How exactly does a generator comprehension work?","A_Content":"  A generator comprehension is the lazy version of a list comprehension.  It is just like a list comprehension except that it returns an iterator instead of the list ie an object with a next() method that will yield the next element.  If you are not familiar with list comprehensions see here and for generators see here.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/364802/how-exactly-does-a-generator-comprehension-work","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    What does generator comprehension do? How does it work? I couldn't find a tutorial about it.     ","Q_Votes":"62"},{"Q_Title":"How exactly does a generator comprehension work?","A_Content":"  List/generator comprehension is a construct which you can use to create a new list/generator from an existing one.  Let's say you want to generate the list of squares of each number from 1 to 10. You can do this in Python:  >>> [x**2 for x in range(1,11)] [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]   here, range(1,11) generates the list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], but the range function is not a generator before Python 3.0, and therefore the construct I've used is a list comprehension.  If I wanted to create a generator that does the same thing, I could do it like this:  >>> (x**2 for x in xrange(1,11)) <generator object at 0x7f0a79273488>   In Python 3, however, range is a generator, so the outcome depends only on the syntax you use (square brackets or round brackets).     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/364802/how-exactly-does-a-generator-comprehension-work","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What does generator comprehension do? How does it work? I couldn't find a tutorial about it.     ","Q_Votes":"62"},{"Q_Title":"How exactly does a generator comprehension work?","A_Content":"  Generator comprehension is an easy way of creating generators with a certain structure. Lets say you want a generator that outputs one by one all the even numbers in your_list. If you create it by using the function style it would be like this:  def allEvens( L ):     for number in L:         if number % 2 is 0:             yield number  evens = allEvens( yourList )   You could achieve the same result with this generator comprehension expression:  evens = ( number for number in your_list if number % 2 == 0 )   In both cases, when you call next(evens) you get the next even number in your_list.      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/364802/how-exactly-does-a-generator-comprehension-work","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    What does generator comprehension do? How does it work? I couldn't find a tutorial about it.     ","Q_Votes":"62"},{"Q_Title":"How exactly does a generator comprehension work?","A_Content":"  Generator comprehension is an approach to create iterables, something like a cursor which moves on a resource.  If you know mysql cursor or mongodb cursor, you may be aware of that the whole actual data never gets loaded into the memory at once, but one at a time. Your cursor moves back and forth, but there is always a one row/list element in memory.   In short, by using generators comprehension you can easily create cursors in python.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/364802/how-exactly-does-a-generator-comprehension-work","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    What does generator comprehension do? How does it work? I couldn't find a tutorial about it.     ","Q_Votes":"62"},{"Q_Title":"How exactly does a generator comprehension work?","A_Content":"  Another example of Generator comprehension:  print 'Generator comprehensions'  def sq_num(n):     for num in (x**2 for x in range(n)):             yield num  for x in sq_num(10):     print x       ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/364802/how-exactly-does-a-generator-comprehension-work","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    What does generator comprehension do? How does it work? I couldn't find a tutorial about it.     ","Q_Votes":"62"},{"Q_Title":"How do I use Python to convert a string to a number if it has commas in it as thousands separators?","A_Content":"  import locale locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' )  locale.atoi('1,000,000') # 1000000 locale.atof('1,000,000.53') # 1000000.53      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1779288/how-do-i-use-python-to-convert-a-string-to-a-number-if-it-has-commas-in-it-as-th","A_Votes":"84","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a string that represents a number which uses commas to separate thousands.  How can I convert this to a number in python?  >>> int(\"1,000,000\")   Generates a ValueError.  I could replace the commas with empty strings before I try to convert it, but that feels wrong somehow.  Is there a better way?     ","Q_Votes":"62"},{"Q_Title":"How do I use Python to convert a string to a number if it has commas in it as thousands separators?","A_Content":"  There are several ways to parse numbers with thousands separators. And I doubt that the way described by ~ubuntu is the best in all cases. That's why I list other ways too.   The proper place to call setlocale() is in __main__ module. It's global setting and will affect the whole program and even C extensions (although note that LC_NUMERIC setting is not set at system level, but is emulated by Python). Read caveats in documentation and think twice before going this way. It's probably OK in single application, but never use it in libraries for wide audience. Probably you shoud avoid requesting locale with some particular charset encoding, since it might not be available on some systems. Use one of third party libraries for internationalization. For example PyICU allows using any available locale wihtout affecting the whole process (and even parsing numbers with particular thousands separators without using locales):  NumberFormat.createInstance(Locale('en_US')).parse(\"1,000,000\").getLong() Write your own parsing function, if you don't what to install third party libraries to do it \"right way\". It can be as simple as int(data.replace(',', '')) when strict validation is not needed.      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1779288/how-do-i-use-python-to-convert-a-string-to-a-number-if-it-has-commas-in-it-as-th","A_Votes":"32","_type":"dict","isAccepted":"No","Q_Content":"    I have a string that represents a number which uses commas to separate thousands.  How can I convert this to a number in python?  >>> int(\"1,000,000\")   Generates a ValueError.  I could replace the commas with empty strings before I try to convert it, but that feels wrong somehow.  Is there a better way?     ","Q_Votes":"62"},{"Q_Title":"How do I use Python to convert a string to a number if it has commas in it as thousands separators?","A_Content":"  Replace the commas with empty strings, and turn the resulting string into an int or a float.  >>> a = '1,000,000' >>> int(a.replace(',' , '')) 1000000 >>> float(a.replace(',' , '')) 1000000.0      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1779288/how-do-i-use-python-to-convert-a-string-to-a-number-if-it-has-commas-in-it-as-th","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a string that represents a number which uses commas to separate thousands.  How can I convert this to a number in python?  >>> int(\"1,000,000\")   Generates a ValueError.  I could replace the commas with empty strings before I try to convert it, but that feels wrong somehow.  Is there a better way?     ","Q_Votes":"62"},{"Q_Title":"How do I use Python to convert a string to a number if it has commas in it as thousands separators?","A_Content":"  I got locale error from accepted answer, but the following change works here in Finland (Windows XP):  import locale locale.setlocale( locale.LC_ALL, 'english_USA' ) print locale.atoi('1,000,000') # 1000000 print locale.atof('1,000,000.53') # 1000000.53      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1779288/how-do-i-use-python-to-convert-a-string-to-a-number-if-it-has-commas-in-it-as-th","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a string that represents a number which uses commas to separate thousands.  How can I convert this to a number in python?  >>> int(\"1,000,000\")   Generates a ValueError.  I could replace the commas with empty strings before I try to convert it, but that feels wrong somehow.  Is there a better way?     ","Q_Votes":"62"},{"Q_Title":"How do I use Python to convert a string to a number if it has commas in it as thousands separators?","A_Content":"  This works:  (A dirty but quick way)  >>> a='-1,234,567,89.0123' >>> \"\".join(a.split(\",\")) '-123456789.0123'      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1779288/how-do-i-use-python-to-convert-a-string-to-a-number-if-it-has-commas-in-it-as-th","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a string that represents a number which uses commas to separate thousands.  How can I convert this to a number in python?  >>> int(\"1,000,000\")   Generates a ValueError.  I could replace the commas with empty strings before I try to convert it, but that feels wrong somehow.  Is there a better way?     ","Q_Votes":"62"},{"Q_Title":"How do I use Python to convert a string to a number if it has commas in it as thousands separators?","A_Content":"  I tried this. It goes a bit beyond the question: You get an input. It will be converted to string first (if it is a list, for example from Beautiful soup); then to int,  then to float.  It goes as far as it can get. In worst case, it returns everything unconverted as string.  def to_normal(soupCell): ''' converts a html cell from beautiful soup to text, then to int, then to float: as far as it gets. US thousands separators are taken into account. needs import locale'''  locale.setlocale( locale.LC_ALL, 'english_USA' )   output = unicode(soupCell.findAll(text=True)[0].string) try:      return locale.atoi(output) except ValueError:      try: return locale.atof(output)     except ValueError:         return output      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1779288/how-do-i-use-python-to-convert-a-string-to-a-number-if-it-has-commas-in-it-as-th","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a string that represents a number which uses commas to separate thousands.  How can I convert this to a number in python?  >>> int(\"1,000,000\")   Generates a ValueError.  I could replace the commas with empty strings before I try to convert it, but that feels wrong somehow.  Is there a better way?     ","Q_Votes":"62"},{"Q_Title":"How do I use Python to convert a string to a number if it has commas in it as thousands separators?","A_Content":"  #python3 tenzin def changenum(data):     foo = \"\"     for i in list(data):         if i == \",\":             continue         else:             foo += i     return  float(int(foo))      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1779288/how-do-i-use-python-to-convert-a-string-to-a-number-if-it-has-commas-in-it-as-th","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a string that represents a number which uses commas to separate thousands.  How can I convert this to a number in python?  >>> int(\"1,000,000\")   Generates a ValueError.  I could replace the commas with empty strings before I try to convert it, but that feels wrong somehow.  Is there a better way?     ","Q_Votes":"62"},{"Q_Title":"How do I use Python to convert a string to a number if it has commas in it as thousands separators?","A_Content":"  >>> import locale >>> locale.setlocale(locale.LC_ALL, \"\") 'en_US.UTF-8' >>> print locale.atoi('1,000,000') 1000000 >>> print locale.atof('1,000,000.53') 1000000.53   this is done on Linux in US.  -Suresh     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1779288/how-do-i-use-python-to-convert-a-string-to-a-number-if-it-has-commas-in-it-as-th","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    I have a string that represents a number which uses commas to separate thousands.  How can I convert this to a number in python?  >>> int(\"1,000,000\")   Generates a ValueError.  I could replace the commas with empty strings before I try to convert it, but that feels wrong somehow.  Is there a better way?     ","Q_Votes":"62"},{"Q_Title":"Python: BeautifulSoup - get an attribute value based on the name attribute","A_Content":"  It's pretty simple, use the following -  >>> soup = BeautifulSoup('<META NAME=\"City\" content=\"Austin\">') >>> soup.find(\"meta\", {\"name\":\"City\"}) <meta name=\"City\" content=\"Austin\" /> >>> soup.find(\"meta\", {\"name\":\"City\"})['content'] u'Austin'   Leave a comment if anything is not clear.     ","Language":"Python","Tags":["python","beautifulsoup"],"URL":"https://stackoverflow.com/questions/11205386/python-beautifulsoup-get-an-attribute-value-based-on-the-name-attribute","A_Votes":"102","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to print an attribute value based on its name, take for example  <META NAME=\"City\" content=\"Austin\">   I want to do something like this  soup = BeautifulSoup(f) //f is some HTML containing the above meta tag for meta_tag in soup('meta'):     if meta_tag['name'] == 'City':          print meta_tag['content']   The above code give a KeyError: 'name', I believe this is because name is used by BeatifulSoup so it can't be used as a keyword argument.     ","Q_Votes":"62"},{"Q_Title":"Python: BeautifulSoup - get an attribute value based on the name attribute","A_Content":"  theharshest answered the question but here is another way to do the same thing. Also, In your example you have NAME in caps and in your code you have name in lowercase.   s = '<div class=\"question\" id=\"get attrs\" name=\"python\" x=\"something\">Hello World</div>' soup = BeautifulSoup(s)  attributes_dictionary = soup.find('div').attrs print attributes_dictionary # prints: {'id': 'get attrs', 'x': 'something', 'class': ['question'], 'name': 'python'}  print attributes_dictionary['class'][0] # prints: question  print soup.find('div').get_text() # prints: Hello World      ","Language":"Python","Tags":["python","beautifulsoup"],"URL":"https://stackoverflow.com/questions/11205386/python-beautifulsoup-get-an-attribute-value-based-on-the-name-attribute","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    I want to print an attribute value based on its name, take for example  <META NAME=\"City\" content=\"Austin\">   I want to do something like this  soup = BeautifulSoup(f) //f is some HTML containing the above meta tag for meta_tag in soup('meta'):     if meta_tag['name'] == 'City':          print meta_tag['content']   The above code give a KeyError: 'name', I believe this is because name is used by BeatifulSoup so it can't be used as a keyword argument.     ","Q_Votes":"62"},{"Q_Title":"Python: BeautifulSoup - get an attribute value based on the name attribute","A_Content":"  theharshest's answer is the best solution, but FYI the problem you were encountering has to do with the fact that a Tag object in Beautiful Soup acts like a Python dictionary. If you access tag['name'] on a tag that doesn't have a 'name' attribute, you'll get a KeyError.     ","Language":"Python","Tags":["python","beautifulsoup"],"URL":"https://stackoverflow.com/questions/11205386/python-beautifulsoup-get-an-attribute-value-based-on-the-name-attribute","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I want to print an attribute value based on its name, take for example  <META NAME=\"City\" content=\"Austin\">   I want to do something like this  soup = BeautifulSoup(f) //f is some HTML containing the above meta tag for meta_tag in soup('meta'):     if meta_tag['name'] == 'City':          print meta_tag['content']   The above code give a KeyError: 'name', I believe this is because name is used by BeatifulSoup so it can't be used as a keyword argument.     ","Q_Votes":"62"},{"Q_Title":"Python: BeautifulSoup - get an attribute value based on the name attribute","A_Content":"  The following works:   from bs4 import BeautifulSoup  soup = BeautifulSoup('<META NAME=\"City\" content=\"Austin\">', 'html.parser')  metas = soup.find_all(\"meta\")  for meta in metas:     print meta.attrs['content'], meta.attrs['name']      ","Language":"Python","Tags":["python","beautifulsoup"],"URL":"https://stackoverflow.com/questions/11205386/python-beautifulsoup-get-an-attribute-value-based-on-the-name-attribute","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I want to print an attribute value based on its name, take for example  <META NAME=\"City\" content=\"Austin\">   I want to do something like this  soup = BeautifulSoup(f) //f is some HTML containing the above meta tag for meta_tag in soup('meta'):     if meta_tag['name'] == 'City':          print meta_tag['content']   The above code give a KeyError: 'name', I believe this is because name is used by BeatifulSoup so it can't be used as a keyword argument.     ","Q_Votes":"62"},{"Q_Title":"Python: BeautifulSoup - get an attribute value based on the name attribute","A_Content":"  6 years late to the party but I've been searching for how to extract an html element's tag attribute value, so for:  <span property=\"addressLocality\">Ayr</span>   I want \"addressLocality\". I kept being directed back here, but the answers didn't really solve my problem.  How I managed to do it eventually:  >>> from bs4 import BeautifulSoup as bs  >>> soup = bs('<span property=\"addressLocality\">Ayr</span>', 'html.parser') >>> my_attributes = soup.find().attrs >>> my_attributes {u'property': u'addressLocality'}   As it's a dict, you can then also use keys and 'values'  >>> my_attributes.keys() [u'property'] >>> my_attributes.values() [u'addressLocality']   Hopefully it helps someone else!     ","Language":"Python","Tags":["python","beautifulsoup"],"URL":"https://stackoverflow.com/questions/11205386/python-beautifulsoup-get-an-attribute-value-based-on-the-name-attribute","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want to print an attribute value based on its name, take for example  <META NAME=\"City\" content=\"Austin\">   I want to do something like this  soup = BeautifulSoup(f) //f is some HTML containing the above meta tag for meta_tag in soup('meta'):     if meta_tag['name'] == 'City':          print meta_tag['content']   The above code give a KeyError: 'name', I believe this is because name is used by BeatifulSoup so it can't be used as a keyword argument.     ","Q_Votes":"62"},{"Q_Title":"Python: BeautifulSoup - get an attribute value based on the name attribute","A_Content":"  One can also try this solution :   To find the value, which is written in span of table  htmlContent    <table>     <tr>         <th>             ID         </th>         <th>             Name         </th>     </tr>       <tr>         <td>             <span name=\"spanId\" class=\"spanclass\">ID123</span>         </td>          <td>             <span>Bonny</span>         </td>     </tr> </table>   Python code    soup = BeautifulSoup(htmlContent, \"lxml\") soup.prettify()  tables = soup.find_all(\"table\")  for table in tables:    storeValueRows = table.find_all(\"tr\")    thValue = storeValueRows[0].find_all(\"th\")[0].string     if (thValue == \"ID\"): # with this condition I am verifying that this html is correct, that I wanted.       value = storeValueRows[1].find_all(\"span\")[0].string       value = value.strip()        # storeValueRows[1] will represent <tr> tag of table located at first index and find_all(\"span\")[0] will give me <span> tag and '.string' will give me value        # value.strip() - will remove space from start and end of the string.       # find using attribute :       value = storeValueRows[1].find(\"span\", {\"name\":\"spanId\"})['class']      print value      # this will print spanclass      ","Language":"Python","Tags":["python","beautifulsoup"],"URL":"https://stackoverflow.com/questions/11205386/python-beautifulsoup-get-an-attribute-value-based-on-the-name-attribute","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to print an attribute value based on its name, take for example  <META NAME=\"City\" content=\"Austin\">   I want to do something like this  soup = BeautifulSoup(f) //f is some HTML containing the above meta tag for meta_tag in soup('meta'):     if meta_tag['name'] == 'City':          print meta_tag['content']   The above code give a KeyError: 'name', I believe this is because name is used by BeatifulSoup so it can't be used as a keyword argument.     ","Q_Votes":"62"},{"Q_Title":"How do I update a Mongo document after inserting it?","A_Content":"  In pymongo you can update with: mycollection.update({'_id':mongo_id}, {\"$set\": post}, upsert=False) Upsert parameter will insert instead of updating if the post is not found in the database. Documentation is available at mongodb site.  UPDATE For version > 3 use update_one instead of update:  mycollection.update_one({'_id':mongo_id}, {\"$set\": post}, upsert=False)     ","Language":"Python","Tags":["python","mongodb","pymongo","database"],"URL":"https://stackoverflow.com/questions/4372797/how-do-i-update-a-mongo-document-after-inserting-it","A_Votes":"87","_type":"dict","isAccepted":"Yes","Q_Content":"    Let's say I insert the document.  post = { some dictionary } mongo_id = mycollection.insert(post)   Now, let's say I want to add a field and update it. How do I do that? This doesn't seem to work.....  post = mycollection.find_one({\"_id\":mongo_id})  post['newfield'] = \"abc\" mycollection.save(post)      ","Q_Votes":"62"},{"Q_Title":"How do I update a Mongo document after inserting it?","A_Content":"  I will use collection.save(the_changed_dict) this way. I've just tested this, and it still works for me. The following is quoted directly from pymongo doc.:  save(to_save[, manipulate=True[, safe=False[, **kwargs]]])     Save a document in this collection.      If to_save already has an \"_id\" then    an update() (upsert) operation is performed and    any existing document with that \"_id\" is   overwritten. Otherwise an insert() operation is performed. In this   case if manipulate is True an \"_id\" will be added to to_save and this   method returns the \"_id\" of the saved document. If manipulate is False   the \"_id\" will be added by the server but this method will return   None.      ","Language":"Python","Tags":["python","mongodb","pymongo","database"],"URL":"https://stackoverflow.com/questions/4372797/how-do-i-update-a-mongo-document-after-inserting-it","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    Let's say I insert the document.  post = { some dictionary } mongo_id = mycollection.insert(post)   Now, let's say I want to add a field and update it. How do I do that? This doesn't seem to work.....  post = mycollection.find_one({\"_id\":mongo_id})  post['newfield'] = \"abc\" mycollection.save(post)      ","Q_Votes":"62"},{"Q_Title":"How do I update a Mongo document after inserting it?","A_Content":"  mycollection.find_one_and_update({\"_id\": mongo_id},                                   {\"$set\": {\"newfield\": \"abc\"}})   should work splendidly for you. If there is no document of id mongo_id, it will fail, unless you also use upsert=True. This returns the old document by default. To get the new one, pass return_document=ReturnDocument.AFTER. All parameters are described in the API.  The method was introduced for MongoDB 3.0. It was extended for 3.2, 3.4, and 3.6.     ","Language":"Python","Tags":["python","mongodb","pymongo","database"],"URL":"https://stackoverflow.com/questions/4372797/how-do-i-update-a-mongo-document-after-inserting-it","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    Let's say I insert the document.  post = { some dictionary } mongo_id = mycollection.insert(post)   Now, let's say I want to add a field and update it. How do I do that? This doesn't seem to work.....  post = mycollection.find_one({\"_id\":mongo_id})  post['newfield'] = \"abc\" mycollection.save(post)      ","Q_Votes":"62"},{"Q_Title":"How do I update a Mongo document after inserting it?","A_Content":"  This is an old question, but I stumbled onto this when looking for the answer so I wanted to give the update to the answer for reference.  The methods save and update are deprecated.     save(to_save, manipulate=True, check_keys=True, **kwargs)¶ Save a   document in this collection.      DEPRECATED - Use insert_one() or replace_one() instead.      Changed in version 3.0: Removed the safe parameter. Pass w=0 for   unacknowledged write operations.      update(spec, document, upsert=False, manipulate=False, multi=False,   check_keys=True, **kwargs) Update a document(s) in this collection.      DEPRECATED - Use replace_one(), update_one(), or update_many()   instead.      Changed in version 3.0: Removed the safe parameter. Pass w=0 for   unacknowledged write operations.   in the OPs particular case, it's better to use replace_one.     ","Language":"Python","Tags":["python","mongodb","pymongo","database"],"URL":"https://stackoverflow.com/questions/4372797/how-do-i-update-a-mongo-document-after-inserting-it","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    Let's say I insert the document.  post = { some dictionary } mongo_id = mycollection.insert(post)   Now, let's say I want to add a field and update it. How do I do that? This doesn't seem to work.....  post = mycollection.find_one({\"_id\":mongo_id})  post['newfield'] = \"abc\" mycollection.save(post)      ","Q_Votes":"62"},{"Q_Title":"How do I update a Mongo document after inserting it?","A_Content":"  According to the latest documentation about PyMongo titled Insert a Document (insert is deprecated) and following defensive approach, you should insert and update as follows:  result = mycollection.insert_one(post) post = mycollection.find_one({'_id': result.inserted_id})  if post is not None:     post['newfield'] = \"abc\"     mycollection.save(post)      ","Language":"Python","Tags":["python","mongodb","pymongo","database"],"URL":"https://stackoverflow.com/questions/4372797/how-do-i-update-a-mongo-document-after-inserting-it","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    Let's say I insert the document.  post = { some dictionary } mongo_id = mycollection.insert(post)   Now, let's say I want to add a field and update it. How do I do that? This doesn't seem to work.....  post = mycollection.find_one({\"_id\":mongo_id})  post['newfield'] = \"abc\" mycollection.save(post)      ","Q_Votes":"62"},{"Q_Title":"How do I merge a list of dicts into a single dict?","A_Content":"  This works for dictionaries of any length:  >>> result = {} >>> for d in L: ...    result.update(d) ...  >>> result {'a':1,'c':2,'b':1,'d':2}   And as generator-oneliner:  dict(pair for d in L for pair in d.items())   In Python 2.7 and 3.x this can and should be written as dict comprehension (thanks, @katrielalex):  { k: v for d in L for k, v in d.items() }      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict","A_Votes":"96","_type":"dict","isAccepted":"Yes","Q_Content":"    How can I turn a list of dicts like this  [{'a':1}, {'b':2}, {'c':1}, {'d':2}]   Into a single dict like this  {'a':1, 'b':2, 'c':1, 'd':2}      ","Q_Votes":"62"},{"Q_Title":"How do I merge a list of dicts into a single dict?","A_Content":"  In case of Python 3.3+, there is a ChainMap collection:  >>> from collections import ChainMap >>> a = [{'a':1},{'b':2},{'c':1},{'d':2}] >>> dict(ChainMap(*a)) {'b': 2, 'c': 1, 'a': 1, 'd': 2}   Also see:   What is the purpose of collections.ChainMap?      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    How can I turn a list of dicts like this  [{'a':1}, {'b':2}, {'c':1}, {'d':2}]   Into a single dict like this  {'a':1, 'b':2, 'c':1, 'd':2}      ","Q_Votes":"62"},{"Q_Title":"How do I merge a list of dicts into a single dict?","A_Content":"  >>> L=[{'a': 1}, {'b': 2}, {'c': 1}, {'d': 2}]     >>> dict(i.items()[0] for i in L) {'a': 1, 'c': 1, 'b': 2, 'd': 2}   Note: the order of 'b' and 'c' doesn't match your output because dicts are unordered  if the dicts can have more than one key/value  >>> dict(j for i in L for j in i.items())      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    How can I turn a list of dicts like this  [{'a':1}, {'b':2}, {'c':1}, {'d':2}]   Into a single dict like this  {'a':1, 'b':2, 'c':1, 'd':2}      ","Q_Votes":"62"},{"Q_Title":"How do I merge a list of dicts into a single dict?","A_Content":"  For flat dictionaries you can do this:  from functools import reduce reduce(lambda a, b: dict(a, **b), list_of_dicts)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How can I turn a list of dicts like this  [{'a':1}, {'b':2}, {'c':1}, {'d':2}]   Into a single dict like this  {'a':1, 'b':2, 'c':1, 'd':2}      ","Q_Votes":"62"},{"Q_Title":"How do I merge a list of dicts into a single dict?","A_Content":"  >>> dictlist = [{'a':1},{'b':2},{'c':1},{'d':2, 'e':3}] >>> dict(kv for d in dictlist for kv in d.iteritems()) {'a': 1, 'c': 1, 'b': 2, 'e': 3, 'd': 2} >>>   Note I added a second key/value pair to the last dictionary to show it works with multiple entries. Also keys from dicts later in the list will overwrite the same key from an earlier dict.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How can I turn a list of dicts like this  [{'a':1}, {'b':2}, {'c':1}, {'d':2}]   Into a single dict like this  {'a':1, 'b':2, 'c':1, 'd':2}      ","Q_Votes":"62"},{"Q_Title":"How do I merge a list of dicts into a single dict?","A_Content":"  dict1.update( dict2 )   This is asymmetrical because you need to choose what to do with duplicate keys; in this case, dict2 will overwrite dict1. Exchange them for the other way.  EDIT: Ah, sorry, didn't see that.  It is possible to do this in a single expression:  >>> from itertools import chain >>> dict( chain( *map( dict.items, theDicts ) ) ) {'a': 1, 'c': 1, 'b': 2, 'd': 2}   No credit to me for this last!  However, I'd argue that it might be more Pythonic (explicit > implicit, flat > nested ) to do this with a simple for loop. YMMV.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How can I turn a list of dicts like this  [{'a':1}, {'b':2}, {'c':1}, {'d':2}]   Into a single dict like this  {'a':1, 'b':2, 'c':1, 'd':2}      ","Q_Votes":"62"},{"Q_Title":"How do I merge a list of dicts into a single dict?","A_Content":"  You can use join function from funcy library:  from funcy import join join(list_of_dicts)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I turn a list of dicts like this  [{'a':1}, {'b':2}, {'c':1}, {'d':2}]   Into a single dict like this  {'a':1, 'b':2, 'c':1, 'd':2}      ","Q_Votes":"62"},{"Q_Title":"How do I merge a list of dicts into a single dict?","A_Content":"  dic1 = {'Maria':12, 'Paco':22, 'Jose':23} dic2 = {'Patricia':25, 'Marcos':22 'Tomas':36}  dic2 = dict(dic1.items() + dic2.items())  and this will be the outcome:  dic2 {'Jose': 23, 'Marcos': 22, 'Patricia': 25, 'Tomas': 36, 'Paco': 22, 'Maria': 12}     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I turn a list of dicts like this  [{'a':1}, {'b':2}, {'c':1}, {'d':2}]   Into a single dict like this  {'a':1, 'b':2, 'c':1, 'd':2}      ","Q_Votes":"62"},{"Q_Title":"Do I need to pass the full path of a file in another directory to open()?","A_Content":"  Yes, you need the full path.    log = open(os.path.join(root, f), 'r')   Is the quick fix.  As the comment pointed out, os.walk decends into subdirs so you do need to use the current directory root rather than indir as the base for the path join.     ","Language":"Python","Tags":["python","file-io","absolute-path"],"URL":"https://stackoverflow.com/questions/11801309/do-i-need-to-pass-the-full-path-of-a-file-in-another-directory-to-open","A_Votes":"26","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a folder with ten files in it which I want to loop through. When I print out the name of the file my code works fine:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         print(f)   Which prints:  1 2 3 4 5 6 7 8 9 10   But if I try to open the file in the loop I get an IO error:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         log = open(f, 'r')  Traceback (most recent call last): File \"/home/des/my_python_progs/loop_over_dir.py\", line 6, in <module> log = open(f, 'r') IOError: [Errno 2] No such file or directory: '1' >>>    Do I need to pass the full path of the file even inside the loop to open() them?     ","Q_Votes":"62"},{"Q_Title":"How do I merge a list of dicts into a single dict?","A_Content":"  This is similar to @delnan but offers the option to modify the k/v (key/value) items and I believe is more readable:  new_dict = {k:v for list_item in list_of_dicts for (k,v) in list_item.items()}   for instance, replace k/v elems as follows:  new_dict = {str(k).replace(\" \",\"_\"):v for list_item in list_of_dicts for (k,v) in list_item.items()}   unpacks the k,v tuple from the dictionary .items() generator after pulling the dict object out of the list     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I turn a list of dicts like this  [{'a':1}, {'b':2}, {'c':1}, {'d':2}]   Into a single dict like this  {'a':1, 'b':2, 'c':1, 'd':2}      ","Q_Votes":"62"},{"Q_Title":"Do I need to pass the full path of a file in another directory to open()?","A_Content":"  If you are just looking for the files in a single directory (ie you are not trying to traverse a directory tree, which it doesn't look like), why not simply use os.listdir():  import os   for fn in os.listdir('.'):      if os.path.isfile(fn):         print (fn)   in place of os.walk(). You can specify a directory path as a parameter for os.listdir(). os.path.isfile() will determine if the given filename is for a file.     ","Language":"Python","Tags":["python","file-io","absolute-path"],"URL":"https://stackoverflow.com/questions/11801309/do-i-need-to-pass-the-full-path-of-a-file-in-another-directory-to-open","A_Votes":"92","_type":"dict","isAccepted":"No","Q_Content":"    I have a folder with ten files in it which I want to loop through. When I print out the name of the file my code works fine:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         print(f)   Which prints:  1 2 3 4 5 6 7 8 9 10   But if I try to open the file in the loop I get an IO error:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         log = open(f, 'r')  Traceback (most recent call last): File \"/home/des/my_python_progs/loop_over_dir.py\", line 6, in <module> log = open(f, 'r') IOError: [Errno 2] No such file or directory: '1' >>>    Do I need to pass the full path of the file even inside the loop to open() them?     ","Q_Votes":"62"},{"Q_Title":"Do I need to pass the full path of a file in another directory to open()?","A_Content":"  You have to specify the path that you are working on:  source = '/home/test/py_test/' for root, dirs, filenames in os.walk(source):     for f in filenames:         print f         fullpath = os.path.join(source, f)         log = open(fullpath, 'r')      ","Language":"Python","Tags":["python","file-io","absolute-path"],"URL":"https://stackoverflow.com/questions/11801309/do-i-need-to-pass-the-full-path-of-a-file-in-another-directory-to-open","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a folder with ten files in it which I want to loop through. When I print out the name of the file my code works fine:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         print(f)   Which prints:  1 2 3 4 5 6 7 8 9 10   But if I try to open the file in the loop I get an IO error:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         log = open(f, 'r')  Traceback (most recent call last): File \"/home/des/my_python_progs/loop_over_dir.py\", line 6, in <module> log = open(f, 'r') IOError: [Errno 2] No such file or directory: '1' >>>    Do I need to pass the full path of the file even inside the loop to open() them?     ","Q_Votes":"62"},{"Q_Title":"Do I need to pass the full path of a file in another directory to open()?","A_Content":"  The examples to os.walk in the documentation show how to do this:  for root, dirs, filenames in os.walk(indir):     for f in filenames:         log = open(os.path.join(root, f),'r')   How did you expect the \"open\" function to know that the string \"1\" is supposed to mean \"/home/des/test/1\" (unless \"/home/des/test\" happens to be your current working directory)?     ","Language":"Python","Tags":["python","file-io","absolute-path"],"URL":"https://stackoverflow.com/questions/11801309/do-i-need-to-pass-the-full-path-of-a-file-in-another-directory-to-open","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have a folder with ten files in it which I want to loop through. When I print out the name of the file my code works fine:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         print(f)   Which prints:  1 2 3 4 5 6 7 8 9 10   But if I try to open the file in the loop I get an IO error:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         log = open(f, 'r')  Traceback (most recent call last): File \"/home/des/my_python_progs/loop_over_dir.py\", line 6, in <module> log = open(f, 'r') IOError: [Errno 2] No such file or directory: '1' >>>    Do I need to pass the full path of the file even inside the loop to open() them?     ","Q_Votes":"62"},{"Q_Title":"Do I need to pass the full path of a file in another directory to open()?","A_Content":"  Here's a snippet that will walk the file tree for you:  indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         print(f)         log = open(indir + f, 'r')      ","Language":"Python","Tags":["python","file-io","absolute-path"],"URL":"https://stackoverflow.com/questions/11801309/do-i-need-to-pass-the-full-path-of-a-file-in-another-directory-to-open","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have a folder with ten files in it which I want to loop through. When I print out the name of the file my code works fine:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         print(f)   Which prints:  1 2 3 4 5 6 7 8 9 10   But if I try to open the file in the loop I get an IO error:  import os indir = '/home/des/test' for root, dirs, filenames in os.walk(indir):     for f in filenames:         log = open(f, 'r')  Traceback (most recent call last): File \"/home/des/my_python_progs/loop_over_dir.py\", line 6, in <module> log = open(f, 'r') IOError: [Errno 2] No such file or directory: '1' >>>    Do I need to pass the full path of the file even inside the loop to open() them?     ","Q_Votes":"62"},{"Q_Title":"Python argparse: Make at least one argument required","A_Content":"  if not (args.process or args.upload):     parser.error('No action requested, add -process or -upload')      ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/6722936/python-argparse-make-at-least-one-argument-required","A_Votes":"69","_type":"dict","isAccepted":"Yes","Q_Content":"    I've been using argparse for a Python program that can -prepare, -upload or both:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('-process', action='store_true') parser.add_argument('-upload',  action='store_true') args = parser.parse_args()   The program is meaningless without at least one parameter. How can I configure argparse to force at least one parameter to be chosen?  UPDATE:  Following the comments: What's the Pythonic way to parametrize a program with at least one option?     ","Q_Votes":"62"},{"Q_Title":"Python argparse: Make at least one argument required","A_Content":"  args = vars(parser.parse_args()) if not any(args.values()):     parser.error('No arguments provided.')      ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/6722936/python-argparse-make-at-least-one-argument-required","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I've been using argparse for a Python program that can -prepare, -upload or both:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('-process', action='store_true') parser.add_argument('-upload',  action='store_true') args = parser.parse_args()   The program is meaningless without at least one parameter. How can I configure argparse to force at least one parameter to be chosen?  UPDATE:  Following the comments: What's the Pythonic way to parametrize a program with at least one option?     ","Q_Votes":"62"},{"Q_Title":"Python argparse: Make at least one argument required","A_Content":"  If not the 'or both' part (I have initially missed this) you could use something like this:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('--process', action='store_const', const='process', dest='mode') parser.add_argument('--upload',  action='store_const', const='upload', dest='mode') args = parser.parse_args() if not args.mode:     parser.error(\"One of --process or --upload must be given\")   Though, probably it would be a better idea to use subcommands instead.     ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/6722936/python-argparse-make-at-least-one-argument-required","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I've been using argparse for a Python program that can -prepare, -upload or both:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('-process', action='store_true') parser.add_argument('-upload',  action='store_true') args = parser.parse_args()   The program is meaningless without at least one parameter. How can I configure argparse to force at least one parameter to be chosen?  UPDATE:  Following the comments: What's the Pythonic way to parametrize a program with at least one option?     ","Q_Votes":"62"},{"Q_Title":"Python argparse: Make at least one argument required","A_Content":"  I know this is old as dirt, but the way to require one option but forbid more than one (XOR) is like this:  parser = argparse.ArgumentParser() group = parser.add_mutually_exclusive_group(required=True) group.add_argument('-process', action='store_true') group.add_argument('-upload',  action='store_true') args = parser.parse_args() print args   Output:    >opt.py   usage: multiplot.py [-h] (-process | -upload)   multiplot.py: error: one of the arguments -process -upload is required    >opt.py -upload   Namespace(process=False, upload=True)    >opt.py -process   Namespace(process=True, upload=False)    >opt.py -upload -process   usage: multiplot.py [-h] (-process | -upload)   multiplot.py: error: argument -process: not allowed with argument -upload        ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/6722936/python-argparse-make-at-least-one-argument-required","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I've been using argparse for a Python program that can -prepare, -upload or both:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('-process', action='store_true') parser.add_argument('-upload',  action='store_true') args = parser.parse_args()   The program is meaningless without at least one parameter. How can I configure argparse to force at least one parameter to be chosen?  UPDATE:  Following the comments: What's the Pythonic way to parametrize a program with at least one option?     ","Q_Votes":"62"},{"Q_Title":"Python argparse: Make at least one argument required","A_Content":"  Requirements Review   use argparse (I will ignore this one) allow one or two actions to be called (at least one required). try to by Pythonic (I would rather call it \"POSIX\"-like)   There are also some implicit requirements when living on command line:   explain the usage to the user in a way which is easy to understand options shall be optional allow specifying flags and options allow combining with other parameters (like file name or names).   Sample solution using docopt (file managelog.py):  \"\"\"Manage logfiles Usage:     managelog.py [options] process -- <logfile>...     managelog.py [options] upload -- <logfile>...     managelog.py [options] process upload -- <logfile>...     managelog.py -h  Options:     -V, --verbose      Be verbose     -U, --user <user>  Username     -P, --pswd <pswd>  Password  Manage log file by processing and/or uploading it. If upload requires authentication, you shall specify <user> and <password> \"\"\" if __name__ == \"__main__\":     from docopt import docopt     args = docopt(__doc__)     print args   Try to run it:  $ python managelog.py Usage:     managelog.py [options] process -- <logfile>...     managelog.py [options] upload -- <logfile>...     managelog.py [options] process upload -- <logfile>...     managelog.py -h   Show the help:  $ python managelog.py -h Manage logfiles Usage:     managelog.py [options] process -- <logfile>...     managelog.py [options] upload -- <logfile>...     managelog.py [options] process upload -- <logfile>...     managelog.py -h  Options:     -V, --verbose      Be verbose     -U, --user <user>  Username     -P, --pswd <pswd>  P    managelog.py [options] upload -- <logfile>...  Manage log file by processing and/or uploading it. If upload requires authentication, you shall specify <user> and <password>   And use it:  $ python managelog.py -V -U user -P secret upload -- alfa.log beta.log {'--': True,  '--pswd': 'secret',  '--user': 'user',  '--verbose': True,  '-h': False,  '<logfile>': ['alfa.log', 'beta.log'],  'process': False,  'upload': True}   Short alternative short.py  There can be even shorter variant:  \"\"\"Manage logfiles Usage:     short.py [options] (process|upload)... -- <logfile>...     short.py -h  Options:     -V, --verbose      Be verbose     -U, --user <user>  Username     -P, --pswd <pswd>  Password  Manage log file by processing and/or uploading it. If upload requires authentication, you shall specify <user> and <password> \"\"\" if __name__ == \"__main__\":     from docopt import docopt     args = docopt(__doc__)     print args   Usage looks like this:  $ python short.py -V process upload  -- alfa.log beta.log {'--': True,  '--pswd': None,  '--user': None,  '--verbose': True,  '-h': False,  '<logfile>': ['alfa.log', 'beta.log'],  'process': 1,  'upload': 1}   Note, that instead of boolean values for \"process\" and \"upload\" keys there are counters.  It turns out, we cannot prevent duplication of these words:  $ python short.py -V process process upload  -- alfa.log beta.log {'--': True,  '--pswd': None,  '--user': None,  '--verbose': True,  '-h': False,  '<logfile>': ['alfa.log', 'beta.log'],  'process': 2,  'upload': 1}   Conclusions  Designing good command line interface can be challenging sometime.  There are multiple aspects of command line based program:   good design of command line selecting/using proper parser   argparse offers a lot, but restricts possible scenarios and can become very complex.  With docopt things go much shorter while preserving readability and offering high degree of flexibility. If you manage getting parsed arguments from dictionary and do some of conversions (to integer, opening files..) manually (or by other library called schema), you may find docopt good fit for command line parsing.     ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/6722936/python-argparse-make-at-least-one-argument-required","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I've been using argparse for a Python program that can -prepare, -upload or both:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('-process', action='store_true') parser.add_argument('-upload',  action='store_true') args = parser.parse_args()   The program is meaningless without at least one parameter. How can I configure argparse to force at least one parameter to be chosen?  UPDATE:  Following the comments: What's the Pythonic way to parametrize a program with at least one option?     ","Q_Votes":"62"},{"Q_Title":"Python argparse: Make at least one argument required","A_Content":"  If you require a python program to run with at least one parameter, add an argument that doesn't have the option prefix  (- or -- by default) and set nargs=+ (Minimum of one argument required). The problem with this method I found is that if you do not specify the argument, argparse will generate a \"too few arguments\" error and not print out the help menu. If you don't need that functionality, here's how to do it in code:  import argparse  parser = argparse.ArgumentParser(description='Your program description') parser.add_argument('command', nargs=\"+\", help='describe what a command is') args = parser.parse_args()   I think that when you add an argument with the option prefixes, nargs governs the entire argument parser and not just the option. (What I mean is, if you have an --option flag with nargs=\"+\", then --option flag expects at least one argument. If you have option with nargs=\"+\", it expects at least one argument overall.)     ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/6722936/python-argparse-make-at-least-one-argument-required","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I've been using argparse for a Python program that can -prepare, -upload or both:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('-process', action='store_true') parser.add_argument('-upload',  action='store_true') args = parser.parse_args()   The program is meaningless without at least one parameter. How can I configure argparse to force at least one parameter to be chosen?  UPDATE:  Following the comments: What's the Pythonic way to parametrize a program with at least one option?     ","Q_Votes":"62"},{"Q_Title":"Python argparse: Make at least one argument required","A_Content":"  For http://bugs.python.org/issue11588 I am exploring ways of generalizing the mutually_exclusive_group concept to handle cases like this.  With this development argparse.py, https://github.com/hpaulj/argparse_issues/blob/nested/argparse.py  I am able to write:  parser = argparse.ArgumentParser(prog='PROG',      description='Log archiver arguments.') group = parser.add_usage_group(kind='any', required=True,     title='possible actions (at least one is required)') group.add_argument('-p', '--process', action='store_true') group.add_argument('-u', '--upload',  action='store_true') args = parser.parse_args() print(args)   which produces the following help:  usage: PROG [-h] (-p | -u)  Log archiver arguments.  optional arguments:   -h, --help     show this help message and exit  possible actions (at least one is required):   -p, --process   -u, --upload   This accepts inputs like '-u',  '-up', '--proc --up' etc.  It ends up running a test similar to https://stackoverflow.com/a/6723066/901925, though the error message needs to be clearer:  usage: PROG [-h] (-p | -u) PROG: error: some of the arguments process upload is required   I wonder:   are the parameters kind='any', required=True clear enough (accept any of the group; at least one is required)? is usage (-p | -u) clear?  A required mutually_exclusive_group produces the same thing.  Is there some alternative notation? is using a group like this more intuitive than phihag's simple test?      ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/6722936/python-argparse-make-at-least-one-argument-required","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I've been using argparse for a Python program that can -prepare, -upload or both:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('-process', action='store_true') parser.add_argument('-upload',  action='store_true') args = parser.parse_args()   The program is meaningless without at least one parameter. How can I configure argparse to force at least one parameter to be chosen?  UPDATE:  Following the comments: What's the Pythonic way to parametrize a program with at least one option?     ","Q_Votes":"62"},{"Q_Title":"Python argparse: Make at least one argument required","A_Content":"  The best way to do this is by using python inbuilt module add_mutually_exclusive_group.  parser = argparse.ArgumentParser(description='Log archiver arguments.') group = parser.add_mutually_exclusive_group() group.add_argument('-process', action='store_true') group.add_argument('-upload',  action='store_true') args = parser.parse_args()   If you want only one argument to be selected by command line just use required=True as an argument for group   group = parser.add_mutually_exclusive_group(required=True)      ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/6722936/python-argparse-make-at-least-one-argument-required","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I've been using argparse for a Python program that can -prepare, -upload or both:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('-process', action='store_true') parser.add_argument('-upload',  action='store_true') args = parser.parse_args()   The program is meaningless without at least one parameter. How can I configure argparse to force at least one parameter to be chosen?  UPDATE:  Following the comments: What's the Pythonic way to parametrize a program with at least one option?     ","Q_Votes":"62"},{"Q_Title":"Python argparse: Make at least one argument required","A_Content":"  Use append_const to a list of actions and then check that the list is populated:  parser.add_argument('-process', dest=actions, const=\"process\", action='append_const') parser.add_argument('-upload',  dest=actions, const=\"upload\", action='append_const')  args = parser.parse_args()  if(args.actions == None):     parser.error('Error: No actions requested')   You can even specify the methods directly within the constants.  def upload:     ...  parser.add_argument('-upload',  dest=actions, const=upload, action='append_const') args = parser.parse_args()  if(args.actions == None):     parser.error('Error: No actions requested')  else:     for action in args.actions:         action()      ","Language":"Python","Tags":["python","argparse"],"URL":"https://stackoverflow.com/questions/6722936/python-argparse-make-at-least-one-argument-required","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've been using argparse for a Python program that can -prepare, -upload or both:  parser = argparse.ArgumentParser(description='Log archiver arguments.') parser.add_argument('-process', action='store_true') parser.add_argument('-upload',  action='store_true') args = parser.parse_args()   The program is meaningless without at least one parameter. How can I configure argparse to force at least one parameter to be chosen?  UPDATE:  Following the comments: What's the Pythonic way to parametrize a program with at least one option?     ","Q_Votes":"62"},{"Q_Title":"How can I login to a website with Python?","A_Content":"  Maybe you want to use twill (it's based on mechanize). It's quite easy to use and should be able to do what you want.  It will look like the following:  from twill.commands import * go('http://mysite.org')  fv(\"1\", \"email-email\", \"blabla.com\") fv(\"1\", \"password-clear\", \"testpass\")  submit('0')   You can use showforms() to list all forms once you used go(...) to browse to the site you want to login. Just try it from the python interpreter.     ","Language":"Python","Tags":["python","automation","httpclient","webautomation"],"URL":"https://stackoverflow.com/questions/2910221/how-can-i-login-to-a-website-with-python","A_Votes":"54","_type":"dict","isAccepted":"Yes","Q_Content":"    How can I do it?  I was trying to enter some specified link (with urllib), but to do it, I need to log in.  I have this source from the site:  <form id=\"login-form\" action=\"auth/login\" method=\"post\">     <div>     <!--label for=\"rememberme\">Remember me</label><input type=\"checkbox\" class=\"remember\" checked=\"checked\" name=\"remember me\" /-->     <label for=\"email\" id=\"email-label\" class=\"no-js\">Email</label>     <input id=\"email-email\" type=\"text\" name=\"handle\" value=\"\" autocomplete=\"off\" />     <label for=\"combination\" id=\"combo-label\" class=\"no-js\">Combination</label>     <input id=\"password-clear\" type=\"text\" value=\"Combination\" autocomplete=\"off\" />     <input id=\"password-password\" type=\"password\" name=\"password\" value=\"\" autocomplete=\"off\" />     <input id=\"sumbitLogin\" class=\"signin\" type=\"submit\" value=\"Sign In\" />   Is this possible?     ","Q_Votes":"62"},{"Q_Title":"How can I login to a website with Python?","A_Content":"  Let me try to make it simple, suppose URL of the site is www.example.com and you need to sign up by filling username and password, so we go to the login page say http://www.example.com/login.php now and view it's source code and search for the action URL it will be in form tag something like    <form name=\"loginform\" method=\"post\" action=\"userinfo.php\">   now take userinfo.php to make absolute URL which will be 'http://example.com/userinfo.php', now run a simple python script   import requests url = 'http://example.com/userinfo.php' values = {'username': 'user',           'password': 'pass'}  r = requests.post(url, data=values) print r.content   I Hope that this helps someone somewhere someday.     ","Language":"Python","Tags":["python","automation","httpclient","webautomation"],"URL":"https://stackoverflow.com/questions/2910221/how-can-i-login-to-a-website-with-python","A_Votes":"37","_type":"dict","isAccepted":"No","Q_Content":"    How can I do it?  I was trying to enter some specified link (with urllib), but to do it, I need to log in.  I have this source from the site:  <form id=\"login-form\" action=\"auth/login\" method=\"post\">     <div>     <!--label for=\"rememberme\">Remember me</label><input type=\"checkbox\" class=\"remember\" checked=\"checked\" name=\"remember me\" /-->     <label for=\"email\" id=\"email-label\" class=\"no-js\">Email</label>     <input id=\"email-email\" type=\"text\" name=\"handle\" value=\"\" autocomplete=\"off\" />     <label for=\"combination\" id=\"combo-label\" class=\"no-js\">Combination</label>     <input id=\"password-clear\" type=\"text\" value=\"Combination\" autocomplete=\"off\" />     <input id=\"password-password\" type=\"password\" name=\"password\" value=\"\" autocomplete=\"off\" />     <input id=\"sumbitLogin\" class=\"signin\" type=\"submit\" value=\"Sign In\" />   Is this possible?     ","Q_Votes":"62"},{"Q_Title":"How can I login to a website with Python?","A_Content":"  Typically you'll need cookies to log into a site, which means cookielib, urllib and urllib2. Here's a class which I wrote back when I was playing Facebook web games:  import cookielib import urllib import urllib2  # set these to whatever your fb account is fb_username = \"your@facebook.login\" fb_password = \"secretpassword\"  class WebGamePlayer(object):      def __init__(self, login, password):         \"\"\" Start up... \"\"\"         self.login = login         self.password = password          self.cj = cookielib.CookieJar()         self.opener = urllib2.build_opener(             urllib2.HTTPRedirectHandler(),             urllib2.HTTPHandler(debuglevel=0),             urllib2.HTTPSHandler(debuglevel=0),             urllib2.HTTPCookieProcessor(self.cj)         )         self.opener.addheaders = [             ('User-agent', ('Mozilla/4.0 (compatible; MSIE 6.0; '                            'Windows NT 5.2; .NET CLR 1.1.4322)'))         ]          # need this twice - once to set cookies, once to log in...         self.loginToFacebook()         self.loginToFacebook()      def loginToFacebook(self):         \"\"\"         Handle login. This should populate our cookie jar.         \"\"\"         login_data = urllib.urlencode({             'email' : self.login,             'pass' : self.password,         })         response = self.opener.open(\"https://login.facebook.com/login.php\", login_data)         return ''.join(response.readlines())   You won't necessarily need the HTTPS or Redirect handlers, but they don't hurt, and it makes the opener much more robust. You also might not need cookies, but it's hard to tell just from the form that you've posted. I suspect that you might, purely from the 'Remember me' input that's been commented out.     ","Language":"Python","Tags":["python","automation","httpclient","webautomation"],"URL":"https://stackoverflow.com/questions/2910221/how-can-i-login-to-a-website-with-python","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    How can I do it?  I was trying to enter some specified link (with urllib), but to do it, I need to log in.  I have this source from the site:  <form id=\"login-form\" action=\"auth/login\" method=\"post\">     <div>     <!--label for=\"rememberme\">Remember me</label><input type=\"checkbox\" class=\"remember\" checked=\"checked\" name=\"remember me\" /-->     <label for=\"email\" id=\"email-label\" class=\"no-js\">Email</label>     <input id=\"email-email\" type=\"text\" name=\"handle\" value=\"\" autocomplete=\"off\" />     <label for=\"combination\" id=\"combo-label\" class=\"no-js\">Combination</label>     <input id=\"password-clear\" type=\"text\" value=\"Combination\" autocomplete=\"off\" />     <input id=\"password-password\" type=\"password\" name=\"password\" value=\"\" autocomplete=\"off\" />     <input id=\"sumbitLogin\" class=\"signin\" type=\"submit\" value=\"Sign In\" />   Is this possible?     ","Q_Votes":"62"},{"Q_Title":"How can I login to a website with Python?","A_Content":"  import cookielib import urllib import urllib2  url = 'http://www.someserver.com/auth/login' values = {'email-email' : 'john@example.com',           'password-clear' : 'Combination',           'password-password' : 'mypassword' }  data = urllib.urlencode(values) cookies = cookielib.CookieJar()  opener = urllib2.build_opener(     urllib2.HTTPRedirectHandler(),     urllib2.HTTPHandler(debuglevel=0),     urllib2.HTTPSHandler(debuglevel=0),     urllib2.HTTPCookieProcessor(cookies))  response = opener.open(url, data) the_page = response.read() http_headers = response.info() # The login cookies should be contained in the cookies variable   For more information visit: https://docs.python.org/2/library/urllib2.html     ","Language":"Python","Tags":["python","automation","httpclient","webautomation"],"URL":"https://stackoverflow.com/questions/2910221/how-can-i-login-to-a-website-with-python","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    How can I do it?  I was trying to enter some specified link (with urllib), but to do it, I need to log in.  I have this source from the site:  <form id=\"login-form\" action=\"auth/login\" method=\"post\">     <div>     <!--label for=\"rememberme\">Remember me</label><input type=\"checkbox\" class=\"remember\" checked=\"checked\" name=\"remember me\" /-->     <label for=\"email\" id=\"email-label\" class=\"no-js\">Email</label>     <input id=\"email-email\" type=\"text\" name=\"handle\" value=\"\" autocomplete=\"off\" />     <label for=\"combination\" id=\"combo-label\" class=\"no-js\">Combination</label>     <input id=\"password-clear\" type=\"text\" value=\"Combination\" autocomplete=\"off\" />     <input id=\"password-password\" type=\"password\" name=\"password\" value=\"\" autocomplete=\"off\" />     <input id=\"sumbitLogin\" class=\"signin\" type=\"submit\" value=\"Sign In\" />   Is this possible?     ","Q_Votes":"62"},{"Q_Title":"How can I login to a website with Python?","A_Content":"  Websites in general can check authorization in many different ways, but the one you're targeting seems to make it reasonably easy for you.  All you need is to POST to the auth/login URL a form-encoded blob with the various fields you see there (forget the labels for, they're decoration for human visitors).  handle=whatever&password-clear=pwd and so on, as long as you know the values for the handle (AKA email) and password you should be fine.  Presumably that POST will redirect you to some \"you've successfully logged in\" page with a Set-Cookie header validating your session (be sure to save that cookie and send it back on further interaction along the session!).     ","Language":"Python","Tags":["python","automation","httpclient","webautomation"],"URL":"https://stackoverflow.com/questions/2910221/how-can-i-login-to-a-website-with-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    How can I do it?  I was trying to enter some specified link (with urllib), but to do it, I need to log in.  I have this source from the site:  <form id=\"login-form\" action=\"auth/login\" method=\"post\">     <div>     <!--label for=\"rememberme\">Remember me</label><input type=\"checkbox\" class=\"remember\" checked=\"checked\" name=\"remember me\" /-->     <label for=\"email\" id=\"email-label\" class=\"no-js\">Email</label>     <input id=\"email-email\" type=\"text\" name=\"handle\" value=\"\" autocomplete=\"off\" />     <label for=\"combination\" id=\"combo-label\" class=\"no-js\">Combination</label>     <input id=\"password-clear\" type=\"text\" value=\"Combination\" autocomplete=\"off\" />     <input id=\"password-password\" type=\"password\" name=\"password\" value=\"\" autocomplete=\"off\" />     <input id=\"sumbitLogin\" class=\"signin\" type=\"submit\" value=\"Sign In\" />   Is this possible?     ","Q_Votes":"62"},{"Q_Title":"How can I login to a website with Python?","A_Content":"  For HTTP things, the current choice should be: Requests- HTTP for Humans     ","Language":"Python","Tags":["python","automation","httpclient","webautomation"],"URL":"https://stackoverflow.com/questions/2910221/how-can-i-login-to-a-website-with-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    How can I do it?  I was trying to enter some specified link (with urllib), but to do it, I need to log in.  I have this source from the site:  <form id=\"login-form\" action=\"auth/login\" method=\"post\">     <div>     <!--label for=\"rememberme\">Remember me</label><input type=\"checkbox\" class=\"remember\" checked=\"checked\" name=\"remember me\" /-->     <label for=\"email\" id=\"email-label\" class=\"no-js\">Email</label>     <input id=\"email-email\" type=\"text\" name=\"handle\" value=\"\" autocomplete=\"off\" />     <label for=\"combination\" id=\"combo-label\" class=\"no-js\">Combination</label>     <input id=\"password-clear\" type=\"text\" value=\"Combination\" autocomplete=\"off\" />     <input id=\"password-password\" type=\"password\" name=\"password\" value=\"\" autocomplete=\"off\" />     <input id=\"sumbitLogin\" class=\"signin\" type=\"submit\" value=\"Sign In\" />   Is this possible?     ","Q_Votes":"62"},{"Q_Title":"How can I login to a website with Python?","A_Content":"  Web page automation ? Definitely \"webbot\"  webbot even works web pages which have dynamically changing id and classnames and has more methods and features than selenium or mechanize.     Here's a snippet :)   from webbot import Browser  web = Browser() web.go_to('google.com')  web.click('Sign in') web.type('mymail@gmail.com' , into='Email') web.click('NEXT' , tag='span') web.type('mypassword' , into='Password' , id='passwordFieldId') # specific selection web.click('NEXT' , tag='span') # you are logged in ^_^   The docs are also pretty straight forward and simple to  use : https://webbot.readthedocs.io     ","Language":"Python","Tags":["python","automation","httpclient","webautomation"],"URL":"https://stackoverflow.com/questions/2910221/how-can-i-login-to-a-website-with-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    How can I do it?  I was trying to enter some specified link (with urllib), but to do it, I need to log in.  I have this source from the site:  <form id=\"login-form\" action=\"auth/login\" method=\"post\">     <div>     <!--label for=\"rememberme\">Remember me</label><input type=\"checkbox\" class=\"remember\" checked=\"checked\" name=\"remember me\" /-->     <label for=\"email\" id=\"email-label\" class=\"no-js\">Email</label>     <input id=\"email-email\" type=\"text\" name=\"handle\" value=\"\" autocomplete=\"off\" />     <label for=\"combination\" id=\"combo-label\" class=\"no-js\">Combination</label>     <input id=\"password-clear\" type=\"text\" value=\"Combination\" autocomplete=\"off\" />     <input id=\"password-password\" type=\"password\" name=\"password\" value=\"\" autocomplete=\"off\" />     <input id=\"sumbitLogin\" class=\"signin\" type=\"submit\" value=\"Sign In\" />   Is this possible?     ","Q_Votes":"62"},{"Q_Title":"How should I declare default values for instance variables in Python?","A_Content":"  Extending bp's answer, I wanted to show you what he meant by immutable types.  First, this is okay:  >>> class TestB(): ...     def __init__(self, attr=1): ...         self.attr = attr ...      >>> a = TestB() >>> b = TestB() >>> a.attr = 2 >>> a.attr 2 >>> b.attr 1   However, this only works for immutable (unchangable) types. If the default value was mutable (meaning it can be replaced), this would happen instead:  >>> class Test(): ...     def __init__(self, attr=[]): ...         self.attr = attr ...      >>> a = Test() >>> b = Test() >>> a.attr.append(1) >>> a.attr [1] >>> b.attr [1] >>>    Note both a and b have a shared attribute. This is often unwanted.  This is the Pythonic way of defining default values for instance variables, when the type is mutable:  >>> class TestC(): ...     def __init__(self, attr=None): ...         if attr is None: ...             attr = [] ...         self.attr = attr ...      >>> a = TestC() >>> b = TestC() >>> a.attr.append(1) >>> a.attr [1] >>> b.attr []   The reason my first snippet of code works is because, with immutable types, Python creates a new instance of it whenever you want one. If you needed to add 1 to 1, Python makes a new 2 for you, because the old 1 cannot be changed. The reason is mostly for hashing, I believe.     ","Language":"Python","Tags":["python","class","oop"],"URL":"https://stackoverflow.com/questions/2681243/how-should-i-declare-default-values-for-instance-variables-in-python","A_Votes":"94","_type":"dict","isAccepted":"Yes","Q_Content":"    Should I give my class members default values like this:  class Foo:     num = 1   or like this?  class Foo:     def __init__(self):         self.num = 1   In this question I discovered that in both cases,  bar = Foo() bar.num += 1   is a well-defined operation.  I understand that the first method will give me a class variable while the second one will not. However, if I do not require a class variable, but only need to set a default value for my instance variables, are both methods equally good? Or one of them more 'pythonic' than the other?  One thing I've noticed is that in the Django tutorial, they use the second method to declare Models. Personally I think the second method is more elegant, but I'd like to know what the 'standard' way is.     ","Q_Votes":"62"},{"Q_Title":"How should I declare default values for instance variables in Python?","A_Content":"  The two snippets do different things, so it's not a matter of taste but a matter of what's the right behaviour in your context. Python documentation explains the difference, but here are some examples:  Exhibit A  class Foo:   def __init__(self):     self.num = 1   This binds num to the Foo instances. Change to this field is not propagated to other instances.  Thus:  >>> foo1 = Foo() >>> foo2 = Foo() >>> foo1.num = 2 >>> foo2.num 1   Exhibit B  class Bar:   num = 1   This binds num to the Bar class. Changes are propagated!  >>> bar1 = Bar() >>> bar2 = Bar() >>> bar1.num = 2 #this creates an INSTANCE variable that HIDES the propagation >>> bar2.num 1 >>> Bar.num = 3 >>> bar2.num 3 >>> bar1.num 2 >>> bar1.__class__.num 3   Actual answer     If I do not require a class variable, but only need to set a default value for my instance variables, are both methods equally good? Or one of them more 'pythonic' than the other?   The code in exhibit B is plain wrong for this: why would you want to bind a class attribute (default value on instance creation) to the single instance?  The code in exhibit A is okay.  If you want to give defaults for instance variables in your constructor I would however do this:  class Foo:   def __init__(num = None):     self.num = num if num is not None else 1   ...or even:  class Foo:   DEFAULT_NUM = 1   def __init__(num = None):     self.num = num if num is not None else DEFAULT_NUM   ...or even: (preferrable, but if and only if you are dealing with immutable types!)  class Foo:   def __init__(num = 1):     self.num = num   This way you can do:  foo1 = Foo(4) foo2 = Foo() #use default      ","Language":"Python","Tags":["python","class","oop"],"URL":"https://stackoverflow.com/questions/2681243/how-should-i-declare-default-values-for-instance-variables-in-python","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    Should I give my class members default values like this:  class Foo:     num = 1   or like this?  class Foo:     def __init__(self):         self.num = 1   In this question I discovered that in both cases,  bar = Foo() bar.num += 1   is a well-defined operation.  I understand that the first method will give me a class variable while the second one will not. However, if I do not require a class variable, but only need to set a default value for my instance variables, are both methods equally good? Or one of them more 'pythonic' than the other?  One thing I've noticed is that in the Django tutorial, they use the second method to declare Models. Personally I think the second method is more elegant, but I'd like to know what the 'standard' way is.     ","Q_Votes":"62"},{"Q_Title":"How should I declare default values for instance variables in Python?","A_Content":"  Using class members for default values of instance variables is not a good idea, and it's the first time I've seen this idea mentioned at all. It works in your example, but it may fail in a lot of cases. E.g., if the value is mutable, mutating it on an unmodified instance will alter the default:  >>> class c: ...     l = [] ...  >>> x = c() >>> y = c() >>> x.l [] >>> y.l [] >>> x.l.append(10) >>> y.l [10] >>> c.l [10]      ","Language":"Python","Tags":["python","class","oop"],"URL":"https://stackoverflow.com/questions/2681243/how-should-i-declare-default-values-for-instance-variables-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Should I give my class members default values like this:  class Foo:     num = 1   or like this?  class Foo:     def __init__(self):         self.num = 1   In this question I discovered that in both cases,  bar = Foo() bar.num += 1   is a well-defined operation.  I understand that the first method will give me a class variable while the second one will not. However, if I do not require a class variable, but only need to set a default value for my instance variables, are both methods equally good? Or one of them more 'pythonic' than the other?  One thing I've noticed is that in the Django tutorial, they use the second method to declare Models. Personally I think the second method is more elegant, but I'd like to know what the 'standard' way is.     ","Q_Votes":"62"},{"Q_Title":"How should I declare default values for instance variables in Python?","A_Content":"  Using class members to give default values works very well just so long as you are careful only to do it with immutable values. If you try to do it with a list or a dict that would be pretty deadly. It also works where the instance attribute is a reference to a class just so long as the default value is None.  I've seen this technique used very successfully in repoze which is a framework that runs on top of Zope. The advantage here is not just that when your class is persisted to the database only the non-default attributes need to be saved, but also when you need to add a new field into the schema all the existing objects see the new field with its default value without any need to actually change the stored data.  I find it also works well in more general coding, but it's a style thing. Use whatever you are happiest with.     ","Language":"Python","Tags":["python","class","oop"],"URL":"https://stackoverflow.com/questions/2681243/how-should-i-declare-default-values-for-instance-variables-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Should I give my class members default values like this:  class Foo:     num = 1   or like this?  class Foo:     def __init__(self):         self.num = 1   In this question I discovered that in both cases,  bar = Foo() bar.num += 1   is a well-defined operation.  I understand that the first method will give me a class variable while the second one will not. However, if I do not require a class variable, but only need to set a default value for my instance variables, are both methods equally good? Or one of them more 'pythonic' than the other?  One thing I've noticed is that in the Django tutorial, they use the second method to declare Models. Personally I think the second method is more elegant, but I'd like to know what the 'standard' way is.     ","Q_Votes":"62"},{"Q_Title":"How should I declare default values for instance variables in Python?","A_Content":"  You can also declare class variables as None which will prevent propagation. This is useful when you need a well defined class and want to prevent AttributeErrors. For example:  >>> class TestClass(object): ...     t = None ...  >>> test = TestClass() >>> test.t >>> test2 = TestClass() >>> test.t = 'test' >>> test.t 'test' >>> test2.t >>>   Also if you need defaults:  >>> class TestClassDefaults(object): ...    t = None ...    def __init__(self, t=None): ...       self.t = t ...  >>> test = TestClassDefaults() >>> test.t >>> test2 = TestClassDefaults([]) >>> test2.t [] >>> test.t >>>   Of course still follow the info in the other answers about using mutable vs immutable types as the default in __init__.     ","Language":"Python","Tags":["python","class","oop"],"URL":"https://stackoverflow.com/questions/2681243/how-should-i-declare-default-values-for-instance-variables-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Should I give my class members default values like this:  class Foo:     num = 1   or like this?  class Foo:     def __init__(self):         self.num = 1   In this question I discovered that in both cases,  bar = Foo() bar.num += 1   is a well-defined operation.  I understand that the first method will give me a class variable while the second one will not. However, if I do not require a class variable, but only need to set a default value for my instance variables, are both methods equally good? Or one of them more 'pythonic' than the other?  One thing I've noticed is that in the Django tutorial, they use the second method to declare Models. Personally I think the second method is more elegant, but I'd like to know what the 'standard' way is.     ","Q_Votes":"62"},{"Q_Title":"Some built-in to pad a list in python","A_Content":"  a += [''] * (N - len(a))   or if you don't want to change a in place  new_a = a + [''] * (N - len(a))   you can always create a subclass of list and call the method whatever you please  class MyList(list):     def ljust(self, n, fillvalue=''):         return self + [fillvalue] * (n - len(self))  a = MyList(['1']) b = a.ljust(5, '')      ","Language":"Python","Tags":["python","list","list-manipulation"],"URL":"https://stackoverflow.com/questions/3438756/some-built-in-to-pad-a-list-in-python","A_Votes":"101","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a list of size < N and I want to pad it up to the size N with a value.  Certainly, I can use something like the following, but I feel that there should be something I missed:  >>> N = 5 >>> a = [1] >>> map(lambda x, y: y if x is None else x, a, ['']*N) [1, '', '', '', '']      ","Q_Votes":"62"},{"Q_Title":"Some built-in to pad a list in python","A_Content":"  There is no built-in function for this. But you could compose the built-ins for your task (or anything :p).  (Modified from itertool's padnone and take recipes)  from itertools import chain, repeat, islice  def pad_infinite(iterable, padding=None):    return chain(iterable, repeat(padding))  def pad(iterable, size, padding=None):    return islice(pad_infinite(iterable, padding), size)   Usage:  >>> list(pad([1,2,3], 7, '')) [1, 2, 3, '', '', '', '']      ","Language":"Python","Tags":["python","list","list-manipulation"],"URL":"https://stackoverflow.com/questions/3438756/some-built-in-to-pad-a-list-in-python","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of size < N and I want to pad it up to the size N with a value.  Certainly, I can use something like the following, but I feel that there should be something I missed:  >>> N = 5 >>> a = [1] >>> map(lambda x, y: y if x is None else x, a, ['']*N) [1, '', '', '', '']      ","Q_Votes":"62"},{"Q_Title":"Some built-in to pad a list in python","A_Content":"  I think this approach is more visual and pythonic.  a = (a + N * [''])[:N]      ","Language":"Python","Tags":["python","list","list-manipulation"],"URL":"https://stackoverflow.com/questions/3438756/some-built-in-to-pad-a-list-in-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of size < N and I want to pad it up to the size N with a value.  Certainly, I can use something like the following, but I feel that there should be something I missed:  >>> N = 5 >>> a = [1] >>> map(lambda x, y: y if x is None else x, a, ['']*N) [1, '', '', '', '']      ","Q_Votes":"62"},{"Q_Title":"Some built-in to pad a list in python","A_Content":"  gnibbler's answer is nicer, but if you need a builtin, you could use itertools.izip_longest (zip_longest in Py3k):  itertools.izip_longest( xrange( N ), list )   which will return a list of tuples ( i, list[ i ] ) filled-in to None. If you need to get rid of the counter, do something like:  map( itertools.itemgetter( 1 ), itertools.izip_longest( xrange( N ), list ) )      ","Language":"Python","Tags":["python","list","list-manipulation"],"URL":"https://stackoverflow.com/questions/3438756/some-built-in-to-pad-a-list-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of size < N and I want to pad it up to the size N with a value.  Certainly, I can use something like the following, but I feel that there should be something I missed:  >>> N = 5 >>> a = [1] >>> map(lambda x, y: y if x is None else x, a, ['']*N) [1, '', '', '', '']      ","Q_Votes":"62"},{"Q_Title":"Some built-in to pad a list in python","A_Content":"  You could also use a simple generator without any build ins. But I would not pad the list, but let the application logic deal with an empty list.  Anyhow, iterator without buildins  def pad(iterable, padding='.', length=7):     '''     >>> iterable = [1,2,3]     >>> list(pad(iterable))     [1, 2, 3, '.', '.', '.', '.']     '''     for count, i in enumerate(iterable):         yield i     while count < length - 1:         count += 1         yield padding  if __name__ == '__main__':     import doctest     doctest.testmod()      ","Language":"Python","Tags":["python","list","list-manipulation"],"URL":"https://stackoverflow.com/questions/3438756/some-built-in-to-pad-a-list-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of size < N and I want to pad it up to the size N with a value.  Certainly, I can use something like the following, but I feel that there should be something I missed:  >>> N = 5 >>> a = [1] >>> map(lambda x, y: y if x is None else x, a, ['']*N) [1, '', '', '', '']      ","Q_Votes":"62"},{"Q_Title":"Some built-in to pad a list in python","A_Content":"  If you want to pad with None instead of '', map() does the job:  >>> map(None,[1,2,3],xrange(7))  [(1, 0), (2, 1), (3, 2), (None, 3), (None, 4), (None, 5), (None, 6)]  >>> zip(*map(None,[1,2,3],xrange(7)))[0]  (1, 2, 3, None, None, None, None)      ","Language":"Python","Tags":["python","list","list-manipulation"],"URL":"https://stackoverflow.com/questions/3438756/some-built-in-to-pad-a-list-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of size < N and I want to pad it up to the size N with a value.  Certainly, I can use something like the following, but I feel that there should be something I missed:  >>> N = 5 >>> a = [1] >>> map(lambda x, y: y if x is None else x, a, ['']*N) [1, '', '', '', '']      ","Q_Votes":"62"},{"Q_Title":"Some built-in to pad a list in python","A_Content":"  To go off of kennytm:  def pad(l, size, padding):     return l + [padding] * abs((len(l)-size))  >>> l = [1,2,3] >>> pad(l, 7, 0) [1, 2, 3, 0, 0, 0, 0]      ","Language":"Python","Tags":["python","list","list-manipulation"],"URL":"https://stackoverflow.com/questions/3438756/some-built-in-to-pad-a-list-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of size < N and I want to pad it up to the size N with a value.  Certainly, I can use something like the following, but I feel that there should be something I missed:  >>> N = 5 >>> a = [1] >>> map(lambda x, y: y if x is None else x, a, ['']*N) [1, '', '', '', '']      ","Q_Votes":"62"},{"Q_Title":"Some built-in to pad a list in python","A_Content":"  more-itertools is a library that includes a special padded tool for this kind of problem:  import more_itertools as mit  list(mit.padded(a, \"\", N)) # [1, '', '', '', '']     Alternatively, more_itertools also implements Python itertools recipes including padnone and take as mentioned by @kennytm, so they don't have to be reimplemented:  list(mit.take(N, mit.padnone(a))) # [1, None, None, None, None]   If you wish to replace the default None padding, use a list comprehension:  [\"\" if i is None else i for i in mit.take(N, mit.padnone(a))] # [1, '', '', '', '']      ","Language":"Python","Tags":["python","list","list-manipulation"],"URL":"https://stackoverflow.com/questions/3438756/some-built-in-to-pad-a-list-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a list of size < N and I want to pad it up to the size N with a value.  Certainly, I can use something like the following, but I feel that there should be something I missed:  >>> N = 5 >>> a = [1] >>> map(lambda x, y: y if x is None else x, a, ['']*N) [1, '', '', '', '']      ","Q_Votes":"62"},{"Q_Title":"Why does pylint object to single character variable names?","A_Content":"  PyLint checks not only PEP8 recommendations. It has also its own recommendations, one of which is that a variable name should be descriptive and not too short.  You can use this to avoid such short names:  my_list.extend(x_values)   Or tweak PyLint's configuration to tell PyLint what variable name are good.     ","Language":"Python","Tags":["python","pylint","naming-conventions"],"URL":"https://stackoverflow.com/questions/21833872/why-does-pylint-object-to-single-character-variable-names","A_Votes":"41","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm still getting used to python conventions and using pylint to make my code more pythonic, but I'm puzzled by the fact that pylint doesn't like single character variable names. I have a few loops like this:  for x in x_values:    my_list.append(x)   and when I run pylint, I'm getting Invalid name \"x\" for type variable (should match [a-z_][a-z0-9_]{2,30} -- that suggests that a valid variable name must be between 3 and 31 characters long, but I've looked through the PEP8 naming conventions and I don't see anything explicit regarding single lower case letters, and I do see a lot of examples that use them.   Is there something I'm missing in PEP8 or is this a standard that is unique to pylint?     ","Q_Votes":"62"},{"Q_Title":"Why does pylint object to single character variable names?","A_Content":"  A little more detail on what gurney alex noted: you can tell PyLint to make exceptions for variable names which (you pinky swear) are perfectly clear even though less than three characters.  Find in or add to your pylintrc file, under the [FORMAT] header:  # Good variable names which should always be accepted, separated by a comma good-names=i,j,k,ex,Run,_,pk,x,y   Here pk (for primary key), x, and y are variable names i've added.     ","Language":"Python","Tags":["python","pylint","naming-conventions"],"URL":"https://stackoverflow.com/questions/21833872/why-does-pylint-object-to-single-character-variable-names","A_Votes":"70","_type":"dict","isAccepted":"No","Q_Content":"    I'm still getting used to python conventions and using pylint to make my code more pythonic, but I'm puzzled by the fact that pylint doesn't like single character variable names. I have a few loops like this:  for x in x_values:    my_list.append(x)   and when I run pylint, I'm getting Invalid name \"x\" for type variable (should match [a-z_][a-z0-9_]{2,30} -- that suggests that a valid variable name must be between 3 and 31 characters long, but I've looked through the PEP8 naming conventions and I don't see anything explicit regarding single lower case letters, and I do see a lot of examples that use them.   Is there something I'm missing in PEP8 or is this a standard that is unique to pylint?     ","Q_Votes":"62"},{"Q_Title":"Why does pylint object to single character variable names?","A_Content":"  In strongly typed languages, 1 letter name variables can be ok-ish, because you generally get the type next to the name in the declaration of the variable or in the function / method prototype:  bool check_modality(string a, Mode b, OptionList c) {     ModalityChecker v = build_checker(a, b);     return v.check_option(c); }   In Python, you don't get this information, so if you write:  def check_modality(a, b, c):     v = build_checker(a, b)     return v.check_option(c)   you're leaving absolutely no clue for the maintenance team as to what the function could be doing, and how it is called, and what it returns. So in Python, you tend to use descriptive names:  def check_modality(name, mode, option_list):     checker = build_checker(name, mode)     return checker.check_option(option_list)   and you even add a docstring explaining what the stuff does and what types are expected.      ","Language":"Python","Tags":["python","pylint","naming-conventions"],"URL":"https://stackoverflow.com/questions/21833872/why-does-pylint-object-to-single-character-variable-names","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I'm still getting used to python conventions and using pylint to make my code more pythonic, but I'm puzzled by the fact that pylint doesn't like single character variable names. I have a few loops like this:  for x in x_values:    my_list.append(x)   and when I run pylint, I'm getting Invalid name \"x\" for type variable (should match [a-z_][a-z0-9_]{2,30} -- that suggests that a valid variable name must be between 3 and 31 characters long, but I've looked through the PEP8 naming conventions and I don't see anything explicit regarding single lower case letters, and I do see a lot of examples that use them.   Is there something I'm missing in PEP8 or is this a standard that is unique to pylint?     ","Q_Votes":"62"},{"Q_Title":"Why does pylint object to single character variable names?","A_Content":"  The deeper reason is that you may remember what you intended a, b, c, x, y, and z to mean when you wrote your code, but when others read it, or even when you come back to your code, the code becomes much more readable when you give it a semantic name. We're not writing stuff once on a chalkboard and then erasing it. We're writing code that might stick around for a decade or more, and be read many, many times.  Use semantic names. Semantic names I've used have been like ratio, denominator, obj_generator, path, etc. It may take an extra second or two to type them out, but the time you save trying to figure out what you wrote even half an hour from then is well worth it.     ","Language":"Python","Tags":["python","pylint","naming-conventions"],"URL":"https://stackoverflow.com/questions/21833872/why-does-pylint-object-to-single-character-variable-names","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    I'm still getting used to python conventions and using pylint to make my code more pythonic, but I'm puzzled by the fact that pylint doesn't like single character variable names. I have a few loops like this:  for x in x_values:    my_list.append(x)   and when I run pylint, I'm getting Invalid name \"x\" for type variable (should match [a-z_][a-z0-9_]{2,30} -- that suggests that a valid variable name must be between 3 and 31 characters long, but I've looked through the PEP8 naming conventions and I don't see anything explicit regarding single lower case letters, and I do see a lot of examples that use them.   Is there something I'm missing in PEP8 or is this a standard that is unique to pylint?     ","Q_Votes":"62"},{"Q_Title":"Why does pylint object to single character variable names?","A_Content":"  Nowadays there is also a option to override regexp. I.e. if you want to allow single characters as variables:  pylint --variable-rgx=\"[a-z0-9_]{1,30}$\" <filename>   So, pylint will match PEP8 and will not bring additional violations on top. Also you can add it to .pylintrc.     ","Language":"Python","Tags":["python","pylint","naming-conventions"],"URL":"https://stackoverflow.com/questions/21833872/why-does-pylint-object-to-single-character-variable-names","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I'm still getting used to python conventions and using pylint to make my code more pythonic, but I'm puzzled by the fact that pylint doesn't like single character variable names. I have a few loops like this:  for x in x_values:    my_list.append(x)   and when I run pylint, I'm getting Invalid name \"x\" for type variable (should match [a-z_][a-z0-9_]{2,30} -- that suggests that a valid variable name must be between 3 and 31 characters long, but I've looked through the PEP8 naming conventions and I don't see anything explicit regarding single lower case letters, and I do see a lot of examples that use them.   Is there something I'm missing in PEP8 or is this a standard that is unique to pylint?     ","Q_Votes":"62"},{"Q_Title":"How to avoid “Permission denied” when using pip with virtualenv","A_Content":"  virtualenv permission problems might occur when you create the virtualenv as sudo and then operate without sudo in the virtualenv.  As found out in your question's comment, the solution here is to create the virtualenv without sudo to be able to work (esp. write) in it without sudo.     ","Language":"Python","Tags":["python","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/19471972/how-to-avoid-permission-denied-when-using-pip-with-virtualenv","A_Votes":"75","_type":"dict","isAccepted":"Yes","Q_Content":"    I attempt to deploy a Python package with pip in a virtual environment on an Ubuntu machine, but encounter a permission-related issue. For example:  (TestVirtualEnv)test@testServer:~$ pip install markdown2   terminates by:     error: could not create '/home/test/virtualenvs/TestVirtualEnv/lib/python3.3/site-packages/markdown2.py': Permission denied   I can't sudo, since it will install the package globally, and not within the virtual environment. I chowned site-packages; ls shows only directories related to easy_install, pip and setuptools, and nothing related to Markdown.  How to deploy a package in a virtual environment with pip without encountering permission-related errors?     ","Q_Votes":"62"},{"Q_Title":"How to avoid “Permission denied” when using pip with virtualenv","A_Content":"  Solution:  If you created the virtualenv as root, run the following command:  sudo chown -R your_username:your_username path/to/virtuaelenv/   This will probably fix your problem.  Cheers     ","Language":"Python","Tags":["python","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/19471972/how-to-avoid-permission-denied-when-using-pip-with-virtualenv","A_Votes":"64","_type":"dict","isAccepted":"No","Q_Content":"    I attempt to deploy a Python package with pip in a virtual environment on an Ubuntu machine, but encounter a permission-related issue. For example:  (TestVirtualEnv)test@testServer:~$ pip install markdown2   terminates by:     error: could not create '/home/test/virtualenvs/TestVirtualEnv/lib/python3.3/site-packages/markdown2.py': Permission denied   I can't sudo, since it will install the package globally, and not within the virtual environment. I chowned site-packages; ls shows only directories related to easy_install, pip and setuptools, and nothing related to Markdown.  How to deploy a package in a virtual environment with pip without encountering permission-related errors?     ","Q_Votes":"62"},{"Q_Title":"How to avoid “Permission denied” when using pip with virtualenv","A_Content":"  I didn't create my virtualenv using sudo. So Sebastian's answer didn't apply to me. My project is called utils. I checked utils directory and saw this:  -rw-r--r--   1 macuser  staff   983  6 Jan 15:17 README.md drwxr-xr-x   6 root     staff   204  6 Jan 14:36 utils.egg-info -rw-r--r--   1 macuser  staff    31  6 Jan 15:09 requirements.txt   As you can see, utils.egg-info is owned by root not macuser. That is why it was giving me permission denied error. I also had to remove /Users/macuser/.virtualenvs/armoury/lib/python2.7/site-packages/utils.egg-link as it was created by root as well. I did pip install -e . again after removing those, and it worked.     ","Language":"Python","Tags":["python","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/19471972/how-to-avoid-permission-denied-when-using-pip-with-virtualenv","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I attempt to deploy a Python package with pip in a virtual environment on an Ubuntu machine, but encounter a permission-related issue. For example:  (TestVirtualEnv)test@testServer:~$ pip install markdown2   terminates by:     error: could not create '/home/test/virtualenvs/TestVirtualEnv/lib/python3.3/site-packages/markdown2.py': Permission denied   I can't sudo, since it will install the package globally, and not within the virtual environment. I chowned site-packages; ls shows only directories related to easy_install, pip and setuptools, and nothing related to Markdown.  How to deploy a package in a virtual environment with pip without encountering permission-related errors?     ","Q_Votes":"62"},{"Q_Title":"How to avoid “Permission denied” when using pip with virtualenv","A_Content":"  In my case, I was using mkvirtualenv, but didn't tell it I was going to be using python3.  I got this error:  mkvirtualenv hug pip3 install hug -U  .... error: could not create '/usr/lib/python3.4/site-packages': Permission denied   It worked after specifying python3:  mkvirtualenv --python=/usr/bin/python3 hug pip3 install hug -U      ","Language":"Python","Tags":["python","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/19471972/how-to-avoid-permission-denied-when-using-pip-with-virtualenv","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I attempt to deploy a Python package with pip in a virtual environment on an Ubuntu machine, but encounter a permission-related issue. For example:  (TestVirtualEnv)test@testServer:~$ pip install markdown2   terminates by:     error: could not create '/home/test/virtualenvs/TestVirtualEnv/lib/python3.3/site-packages/markdown2.py': Permission denied   I can't sudo, since it will install the package globally, and not within the virtual environment. I chowned site-packages; ls shows only directories related to easy_install, pip and setuptools, and nothing related to Markdown.  How to deploy a package in a virtual environment with pip without encountering permission-related errors?     ","Q_Votes":"62"},{"Q_Title":"How to avoid “Permission denied” when using pip with virtualenv","A_Content":"  You did not activate the virtual environment before using pip.  Try it with:   $(your venv path) . bin/activate   And then use pip -r requirements.txt on your main folder     ","Language":"Python","Tags":["python","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/19471972/how-to-avoid-permission-denied-when-using-pip-with-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I attempt to deploy a Python package with pip in a virtual environment on an Ubuntu machine, but encounter a permission-related issue. For example:  (TestVirtualEnv)test@testServer:~$ pip install markdown2   terminates by:     error: could not create '/home/test/virtualenvs/TestVirtualEnv/lib/python3.3/site-packages/markdown2.py': Permission denied   I can't sudo, since it will install the package globally, and not within the virtual environment. I chowned site-packages; ls shows only directories related to easy_install, pip and setuptools, and nothing related to Markdown.  How to deploy a package in a virtual environment with pip without encountering permission-related errors?     ","Q_Votes":"62"},{"Q_Title":"How to avoid “Permission denied” when using pip with virtualenv","A_Content":"  While creating virtualenv if you use sudo the directory is created with root privileges.So when you try to install a package with non-sudo user you won't have permission to install into it. So always create virtualenv without sudo and install without sudo.  You can also copy packages installed on global python to virtualenv.   cp -r /lib/python/site-packages/* virtualenv/lib/python/site-packages/      ","Language":"Python","Tags":["python","virtualenv","pip"],"URL":"https://stackoverflow.com/questions/19471972/how-to-avoid-permission-denied-when-using-pip-with-virtualenv","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I attempt to deploy a Python package with pip in a virtual environment on an Ubuntu machine, but encounter a permission-related issue. For example:  (TestVirtualEnv)test@testServer:~$ pip install markdown2   terminates by:     error: could not create '/home/test/virtualenvs/TestVirtualEnv/lib/python3.3/site-packages/markdown2.py': Permission denied   I can't sudo, since it will install the package globally, and not within the virtual environment. I chowned site-packages; ls shows only directories related to easy_install, pip and setuptools, and nothing related to Markdown.  How to deploy a package in a virtual environment with pip without encountering permission-related errors?     ","Q_Votes":"62"},{"Q_Title":"How do I find numeric columns in Pandas?","A_Content":"  You could use select_dtypes method of DataFrame. It includes two parameters include and exclude. So isNumeric would look like:  numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']  newdf = df.select_dtypes(include=numerics)      ","Language":"Python","Tags":["python","types","pandas"],"URL":"https://stackoverflow.com/questions/25039626/how-do-i-find-numeric-columns-in-pandas","A_Votes":"70","_type":"dict","isAccepted":"No","Q_Content":"    Let's say df is a pandas DataFrame. I would like to find all columns of numeric type. Something like:  isNumeric = is_numeric(df)      ","Q_Votes":"62"},{"Q_Title":"How do I find numeric columns in Pandas?","A_Content":"  You can use the following command to filter only numeric columns  df._get_numeric_data()   Example  In [32]: data Out[32]:    A  B 0  1  s 1  2  s 2  3  s 3  4  s  In [33]: data._get_numeric_data() Out[33]:    A 0  1 1  2 2  3 3  4      ","Language":"Python","Tags":["python","types","pandas"],"URL":"https://stackoverflow.com/questions/25039626/how-do-i-find-numeric-columns-in-pandas","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    Let's say df is a pandas DataFrame. I would like to find all columns of numeric type. Something like:  isNumeric = is_numeric(df)      ","Q_Votes":"62"},{"Q_Title":"How do I find numeric columns in Pandas?","A_Content":"  Simple one-line answer to create a new dataframe with only numeric columns:  df.select_dtypes(include=[np.number])   If you want the names of numeric columns:  df.select_dtypes(include=[np.number]).columns.tolist()   Complete code:  import pandas as pd import numpy as np  df = pd.DataFrame({'A': range(7, 10),                    'B': np.random.rand(3),                    'C': ['foo','bar','baz'],                    'D': ['who','what','when']}) df #    A         B    C     D # 0  7  0.704021  foo   who # 1  8  0.264025  bar  what # 2  9  0.230671  baz  when  df_numerics_only = df.select_dtypes(include=[np.number]) df_numerics_only #    A         B # 0  7  0.704021 # 1  8  0.264025 # 2  9  0.230671  colnames_numerics_only = df.select_dtypes(include=[np.number]).columns.tolist() colnames_numerics_only # ['A', 'B']      ","Language":"Python","Tags":["python","types","pandas"],"URL":"https://stackoverflow.com/questions/25039626/how-do-i-find-numeric-columns-in-pandas","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    Let's say df is a pandas DataFrame. I would like to find all columns of numeric type. Something like:  isNumeric = is_numeric(df)      ","Q_Votes":"62"},{"Q_Title":"How do I find numeric columns in Pandas?","A_Content":"  df.select_dtypes(exclude=['object'])      ","Language":"Python","Tags":["python","types","pandas"],"URL":"https://stackoverflow.com/questions/25039626/how-do-i-find-numeric-columns-in-pandas","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    Let's say df is a pandas DataFrame. I would like to find all columns of numeric type. Something like:  isNumeric = is_numeric(df)      ","Q_Votes":"62"},{"Q_Title":"How do I find numeric columns in Pandas?","A_Content":"  def is_type(df, baseType):     import numpy as np     import pandas as pd     test = [issubclass(np.dtype(d).type, baseType) for d in df.dtypes]     return pd.DataFrame(data = test, index = df.columns, columns = [\"test\"]) def is_float(df):     import numpy as np     return is_type(df, np.float) def is_number(df):     import numpy as np     return is_type(df, np.number) def is_integer(df):     import numpy as np     return is_type(df, np.integer)      ","Language":"Python","Tags":["python","types","pandas"],"URL":"https://stackoverflow.com/questions/25039626/how-do-i-find-numeric-columns-in-pandas","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Let's say df is a pandas DataFrame. I would like to find all columns of numeric type. Something like:  isNumeric = is_numeric(df)      ","Q_Votes":"62"},{"Q_Title":"How do I find numeric columns in Pandas?","A_Content":"  Adapting this answer, you could do  df.ix[:,df.applymap(np.isreal).all(axis=0)]   Here, np.applymap(np.isreal) shows whether every cell in the data frame is numeric, and .axis(all=0) checks if all values in a column are True and returns a series of Booleans that can be used to index the desired columns.     ","Language":"Python","Tags":["python","types","pandas"],"URL":"https://stackoverflow.com/questions/25039626/how-do-i-find-numeric-columns-in-pandas","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Let's say df is a pandas DataFrame. I would like to find all columns of numeric type. Something like:  isNumeric = is_numeric(df)      ","Q_Votes":"62"},{"Q_Title":"How do I find numeric columns in Pandas?","A_Content":"  This is another simple code for finding numeric column in pandas data frame,        numeric_clmns = df.dtypes[df.dtypes != \"object\"].index       ","Language":"Python","Tags":["python","types","pandas"],"URL":"https://stackoverflow.com/questions/25039626/how-do-i-find-numeric-columns-in-pandas","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Let's say df is a pandas DataFrame. I would like to find all columns of numeric type. Something like:  isNumeric = is_numeric(df)      ","Q_Votes":"62"},{"Q_Title":"How do I find numeric columns in Pandas?","A_Content":"  Please see the below code:  if(dataset.select_dtypes(include=[np.number]).shape[1] > 0): display(dataset.select_dtypes(include=[np.number]).describe()) if(dataset.select_dtypes(include=[np.object]).shape[1] > 0): display(dataset.select_dtypes(include=[np.object]).describe())   This way you can check whether the value are numeric such as float and int or the srting values. the second if statement is used for checking the string values which is referred by the object.      ","Language":"Python","Tags":["python","types","pandas"],"URL":"https://stackoverflow.com/questions/25039626/how-do-i-find-numeric-columns-in-pandas","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Let's say df is a pandas DataFrame. I would like to find all columns of numeric type. Something like:  isNumeric = is_numeric(df)      ","Q_Votes":"62"},{"Q_Title":"Celery - Get task id for current task","A_Content":"  Celery does set some default keyword arguments if the task accepts them. (you can accept them by either using **kwargs, or list them specifically)  @task def do_job(path, task_id=None):     cache.set(task_id, operation_results)   The list of default keyword arguments is documented here: http://ask.github.com/celery/userguide/tasks.html#default-keyword-arguments     ","Language":"Python","Tags":["python","django","celery"],"URL":"https://stackoverflow.com/questions/3302320/celery-get-task-id-for-current-task","A_Votes":"8","_type":"dict","isAccepted":"Yes","Q_Content":"    How can I get the task_id value for a task from within the task? Here's my code:  from celery.decorators import task from django.core.cache import cache  @task def do_job(path):     \"Performs an operation on a file\"      # ... Code to perform the operation ...      cache.set(current_task_id, operation_results)   The idea is that when I create a new instance of the task, I retrieve the task_id from the  task object. I then use the task id to determine whether the task has completed. I don't want to keep track of the task by the path value because the file is \"cleaned up\" after the task completes, and may or may not exist.  In the above example, how would I get the value of current_task_id?     ","Q_Votes":"62"},{"Q_Title":"Celery - Get task id for current task","A_Content":"  Since Celery 2.2.0, information related to the currently executed task is saved to task.request (it's called «the context»). So you should get task id from this context (not from keyword arguments, which are deprecated):  @task def do_job(path):     cache.set(do_job.request.id, operation_results)   The list of all available fields is documented here: http://celery.readthedocs.org/en/latest/userguide/tasks.html?highlight=requestcontext#context     ","Language":"Python","Tags":["python","django","celery"],"URL":"https://stackoverflow.com/questions/3302320/celery-get-task-id-for-current-task","A_Votes":"102","_type":"dict","isAccepted":"No","Q_Content":"    How can I get the task_id value for a task from within the task? Here's my code:  from celery.decorators import task from django.core.cache import cache  @task def do_job(path):     \"Performs an operation on a file\"      # ... Code to perform the operation ...      cache.set(current_task_id, operation_results)   The idea is that when I create a new instance of the task, I retrieve the task_id from the  task object. I then use the task id to determine whether the task has completed. I don't want to keep track of the task by the path value because the file is \"cleaned up\" after the task completes, and may or may not exist.  In the above example, how would I get the value of current_task_id?     ","Q_Votes":"62"},{"Q_Title":"Celery - Get task id for current task","A_Content":"  As of celery 3.1, you can use the bind decorator argument, and have access to the current request:  @task(bind=True) def do_job(self, path):     cache.set(self.request.id, operation_results)      ","Language":"Python","Tags":["python","django","celery"],"URL":"https://stackoverflow.com/questions/3302320/celery-get-task-id-for-current-task","A_Votes":"39","_type":"dict","isAccepted":"No","Q_Content":"    How can I get the task_id value for a task from within the task? Here's my code:  from celery.decorators import task from django.core.cache import cache  @task def do_job(path):     \"Performs an operation on a file\"      # ... Code to perform the operation ...      cache.set(current_task_id, operation_results)   The idea is that when I create a new instance of the task, I retrieve the task_id from the  task object. I then use the task id to determine whether the task has completed. I don't want to keep track of the task by the path value because the file is \"cleaned up\" after the task completes, and may or may not exist.  In the above example, how would I get the value of current_task_id?     ","Q_Votes":"62"},{"Q_Title":"Python - Extract folder path from file path","A_Content":"  You were almost there with your use of the split function. You just needed to join the strings, like follows.  >>> '\\\\'.join(existGDBPath.split('\\\\')[0:-1]) 'T:\\\\Data\\\\DBDesign'   Although, I would recommend using the os.path.dirname function to do this, you just need to pass the string, and it'll do the work for you. Since, you seem to be on windows, consider using the abspath function too. An example -  >>> os.path.dirname(os.path.abspath(existGDBPath)) 'T:\\\\Data\\\\DBDesign'   If you want both the file name and the directory path after being split, you can use the os.path.split function which returns a tuple, as follows.  >>> os.path.split(os.path.abspath(existGDBPath)) ('T:\\\\Data\\\\DBDesign', 'DBDesign_93_v141b.mdb')      ","Language":"Python","Tags":["python","file","path","folder","extract"],"URL":"https://stackoverflow.com/questions/17057544/python-extract-folder-path-from-file-path","A_Votes":"82","_type":"dict","isAccepted":"Yes","Q_Content":"    I have seen this solution but not for Python specifically.  I would like to get just the folder path from the full path to a file.  For example T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb and I would like to get just T:\\Data\\DBDesign (excluding the \\DBDesign_93_v141b.mdb).  I have tried something like this:  existGDBPath = r'T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb' wkspFldr = str(existGDBPath.split('\\\\')[0:-1]) print wkspFldr    but it gave me a result like this:  ['T:', 'Data', 'DBDesign']   which is not the result that I require (being T:\\Data\\DBDesign).  Any ideas on how I can get the the path to my file?  Thanks.     ","Q_Votes":"62"},{"Q_Title":"Python - Extract folder path from file path","A_Content":"  Use the os.path module:  >>> import os >>> existGDBPath = r'T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb' >>> wkspFldr = os.path.dirname(existGDBPath) >>> print wkspFldr  'T:\\Data\\DBDesign'   You can go ahead and assume that if you need to do some sort of filename manipulation it's already been implemented in os.path.  If not, you'll still probably need to use this module as the building block.  UPDATE  One should consider using pathlib for new development.  It is in the stdlib for Python3.4, but available on PyPI for earlier versions.  This library provides a more object-orented method to manipulate paths <opinion> and is much easier read and program with </opinion>.  >>> import pathlib >>> existGDBPath = pathlib.Path(r'T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb') >>> wkspFldr = existGDBPath.parent >>> print wkspFldr Path('T:\\Data\\DBDesign')      ","Language":"Python","Tags":["python","file","path","folder","extract"],"URL":"https://stackoverflow.com/questions/17057544/python-extract-folder-path-from-file-path","A_Votes":"45","_type":"dict","isAccepted":"No","Q_Content":"    I have seen this solution but not for Python specifically.  I would like to get just the folder path from the full path to a file.  For example T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb and I would like to get just T:\\Data\\DBDesign (excluding the \\DBDesign_93_v141b.mdb).  I have tried something like this:  existGDBPath = r'T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb' wkspFldr = str(existGDBPath.split('\\\\')[0:-1]) print wkspFldr    but it gave me a result like this:  ['T:', 'Data', 'DBDesign']   which is not the result that I require (being T:\\Data\\DBDesign).  Any ideas on how I can get the the path to my file?  Thanks.     ","Q_Votes":"62"},{"Q_Title":"Python - Extract folder path from file path","A_Content":"  The built-in submodule os.path has a function for that very task.  import os os.path.dirname('T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb')      ","Language":"Python","Tags":["python","file","path","folder","extract"],"URL":"https://stackoverflow.com/questions/17057544/python-extract-folder-path-from-file-path","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    I have seen this solution but not for Python specifically.  I would like to get just the folder path from the full path to a file.  For example T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb and I would like to get just T:\\Data\\DBDesign (excluding the \\DBDesign_93_v141b.mdb).  I have tried something like this:  existGDBPath = r'T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb' wkspFldr = str(existGDBPath.split('\\\\')[0:-1]) print wkspFldr    but it gave me a result like this:  ['T:', 'Data', 'DBDesign']   which is not the result that I require (being T:\\Data\\DBDesign).  Any ideas on how I can get the the path to my file?  Thanks.     ","Q_Votes":"62"},{"Q_Title":"Python - Extract folder path from file path","A_Content":"  Here is the code:   import os existGDBPath = r'T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb' wkspFldr = os.path.dirname(existGDBPath) print wkspFldr # T:\\Data\\DBDesign      ","Language":"Python","Tags":["python","file","path","folder","extract"],"URL":"https://stackoverflow.com/questions/17057544/python-extract-folder-path-from-file-path","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have seen this solution but not for Python specifically.  I would like to get just the folder path from the full path to a file.  For example T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb and I would like to get just T:\\Data\\DBDesign (excluding the \\DBDesign_93_v141b.mdb).  I have tried something like this:  existGDBPath = r'T:\\Data\\DBDesign\\DBDesign_93_v141b.mdb' wkspFldr = str(existGDBPath.split('\\\\')[0:-1]) print wkspFldr    but it gave me a result like this:  ['T:', 'Data', 'DBDesign']   which is not the result that I require (being T:\\Data\\DBDesign).  Any ideas on how I can get the the path to my file?  Thanks.     ","Q_Votes":"62"},{"Q_Title":"Use scikit-learn to classify into multiple categories","A_Content":"  What you want is called multi-label classification. Scikits-learn can do that. See here: http://scikit-learn.org/dev/modules/multiclass.html.  I'm not sure what's going wrong in your example, my version of sklearn apparently doesn't have WordNGramAnalyzer. Perhaps it's a question of using more training examples or trying a different classifier? Though note that the multi-label classifier expects the target to be a list of tuples/lists of labels.  The following works for me:  import numpy as np from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import CountVectorizer from sklearn.svm import LinearSVC from sklearn.feature_extraction.text import TfidfTransformer from sklearn.multiclass import OneVsRestClassifier  X_train = np.array([\"new york is a hell of a town\",                     \"new york was originally dutch\",                     \"the big apple is great\",                     \"new york is also called the big apple\",                     \"nyc is nice\",                     \"people abbreviate new york city as nyc\",                     \"the capital of great britain is london\",                     \"london is in the uk\",                     \"london is in england\",                     \"london is in great britain\",                     \"it rains a lot in london\",                     \"london hosts the british museum\",                     \"new york is great and so is london\",                     \"i like london better than new york\"]) y_train = [[0],[0],[0],[0],[0],[0],[1],[1],[1],[1],[1],[1],[0,1],[0,1]] X_test = np.array(['nice day in nyc',                    'welcome to london',                    'hello welcome to new york. enjoy it here and london too'])    target_names = ['New York', 'London']  classifier = Pipeline([     ('vectorizer', CountVectorizer(min_n=1,max_n=2)),     ('tfidf', TfidfTransformer()),     ('clf', OneVsRestClassifier(LinearSVC()))]) classifier.fit(X_train, y_train) predicted = classifier.predict(X_test) for item, labels in zip(X_test, predicted):     print '%s => %s' % (item, ', '.join(target_names[x] for x in labels))   For me, this produces the output:  nice day in nyc => New York welcome to london => London hello welcome to new york. enjoy it here and london too => New York, London   Hope this helps.     ","Language":"Python","Tags":["python","classification","scikit-learn"],"URL":"https://stackoverflow.com/questions/10526579/use-scikit-learn-to-classify-into-multiple-categories","A_Votes":"93","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to use one of scikit-learn's supervised learning methods to classify pieces of text into one or more categories. The predict function of all the algorithms I tried just returns one match.  For example I have a piece of text:  \"Theaters in New York compared to those in London\"   And I have trained the algorithm to pick a place for every text snippet I feed it.  In the above example I would want it to return New York and London, but it only returns New York.  Is it possible to use scikit-learn to return multiple results? Or even return the label with the next highest probability?   Thanks for your help.  ---Update   I tried using OneVsRestClassifier but I still only get one option back  per piece of text. Below is the sample code I am using  y_train = ('New York','London')   train_set = (\"new york nyc big apple\", \"london uk great britain\") vocab = {'new york' :0,'nyc':1,'big apple':2,'london' : 3, 'uk': 4, 'great britain' : 5} count = CountVectorizer(analyzer=WordNGramAnalyzer(min_n=1, max_n=2),vocabulary=vocab) test_set = ('nice day in nyc','london town','hello welcome to the big apple. enjoy it here and london too')  X_vectorized = count.transform(train_set).todense() smatrix2  = count.transform(test_set).todense()   base_clf = MultinomialNB(alpha=1)  clf = OneVsRestClassifier(base_clf).fit(X_vectorized, y_train) Y_pred = clf.predict(smatrix2) print Y_pred   Result: ['New York' 'London' 'London']     ","Q_Votes":"62"},{"Q_Title":"Use scikit-learn to classify into multiple categories","A_Content":"  EDIT: Updated for Python 3, scikit-learn 0.18.1 using MultiLabelBinarizer as suggested.  I've been working on this as well, and made a slight enhancement to mwv's excellent answer that may be useful. It takes text labels as the input rather than binary labels and encodes them using MultiLabelBinarizer.   import numpy as np from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import CountVectorizer from sklearn.svm import LinearSVC from sklearn.feature_extraction.text import TfidfTransformer from sklearn.multiclass import OneVsRestClassifier from sklearn.preprocessing import MultiLabelBinarizer  X_train = np.array([\"new york is a hell of a town\",                     \"new york was originally dutch\",                     \"the big apple is great\",                     \"new york is also called the big apple\",                     \"nyc is nice\",                     \"people abbreviate new york city as nyc\",                     \"the capital of great britain is london\",                     \"london is in the uk\",                     \"london is in england\",                     \"london is in great britain\",                     \"it rains a lot in london\",                     \"london hosts the british museum\",                     \"new york is great and so is london\",                     \"i like london better than new york\"]) y_train_text = [[\"new york\"],[\"new york\"],[\"new york\"],[\"new york\"],[\"new york\"],                 [\"new york\"],[\"london\"],[\"london\"],[\"london\"],[\"london\"],                 [\"london\"],[\"london\"],[\"new york\",\"london\"],[\"new york\",\"london\"]]  X_test = np.array(['nice day in nyc',                    'welcome to london',                    'london is rainy',                    'it is raining in britian',                    'it is raining in britian and the big apple',                    'it is raining in britian and nyc',                    'hello welcome to new york. enjoy it here and london too']) target_names = ['New York', 'London']  mlb = MultiLabelBinarizer() Y = mlb.fit_transform(y_train_text)  classifier = Pipeline([     ('vectorizer', CountVectorizer()),     ('tfidf', TfidfTransformer()),     ('clf', OneVsRestClassifier(LinearSVC()))])  classifier.fit(X_train, Y) predicted = classifier.predict(X_test) all_labels = mlb.inverse_transform(predicted)  for item, labels in zip(X_test, all_labels):     print('{0} => {1}'.format(item, ', '.join(labels)))   This gives me the following output:  nice day in nyc => new york welcome to london => london london is rainy => london it is raining in britian => london it is raining in britian and the big apple => new york it is raining in britian and nyc => london, new york hello welcome to new york. enjoy it here and london too => london, new york      ","Language":"Python","Tags":["python","classification","scikit-learn"],"URL":"https://stackoverflow.com/questions/10526579/use-scikit-learn-to-classify-into-multiple-categories","A_Votes":"47","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to use one of scikit-learn's supervised learning methods to classify pieces of text into one or more categories. The predict function of all the algorithms I tried just returns one match.  For example I have a piece of text:  \"Theaters in New York compared to those in London\"   And I have trained the algorithm to pick a place for every text snippet I feed it.  In the above example I would want it to return New York and London, but it only returns New York.  Is it possible to use scikit-learn to return multiple results? Or even return the label with the next highest probability?   Thanks for your help.  ---Update   I tried using OneVsRestClassifier but I still only get one option back  per piece of text. Below is the sample code I am using  y_train = ('New York','London')   train_set = (\"new york nyc big apple\", \"london uk great britain\") vocab = {'new york' :0,'nyc':1,'big apple':2,'london' : 3, 'uk': 4, 'great britain' : 5} count = CountVectorizer(analyzer=WordNGramAnalyzer(min_n=1, max_n=2),vocabulary=vocab) test_set = ('nice day in nyc','london town','hello welcome to the big apple. enjoy it here and london too')  X_vectorized = count.transform(train_set).todense() smatrix2  = count.transform(test_set).todense()   base_clf = MultinomialNB(alpha=1)  clf = OneVsRestClassifier(base_clf).fit(X_vectorized, y_train) Y_pred = clf.predict(smatrix2) print Y_pred   Result: ['New York' 'London' 'London']     ","Q_Votes":"62"},{"Q_Title":"Use scikit-learn to classify into multiple categories","A_Content":"  I just ran into this as well, and the problem for me was that my y_Train was a sequence of Strings, rather than a sequence of sequences of String. Apparently, OneVsRestClassifier will decide based on the input label format whether to use multi-class vs. multi-label. So change:  y_train = ('New York','London')   to  y_train = (['New York'],['London'])   Apparently this will disappear in the future, since it breaks of all the labels are the same: https://github.com/scikit-learn/scikit-learn/pull/1987     ","Language":"Python","Tags":["python","classification","scikit-learn"],"URL":"https://stackoverflow.com/questions/10526579/use-scikit-learn-to-classify-into-multiple-categories","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to use one of scikit-learn's supervised learning methods to classify pieces of text into one or more categories. The predict function of all the algorithms I tried just returns one match.  For example I have a piece of text:  \"Theaters in New York compared to those in London\"   And I have trained the algorithm to pick a place for every text snippet I feed it.  In the above example I would want it to return New York and London, but it only returns New York.  Is it possible to use scikit-learn to return multiple results? Or even return the label with the next highest probability?   Thanks for your help.  ---Update   I tried using OneVsRestClassifier but I still only get one option back  per piece of text. Below is the sample code I am using  y_train = ('New York','London')   train_set = (\"new york nyc big apple\", \"london uk great britain\") vocab = {'new york' :0,'nyc':1,'big apple':2,'london' : 3, 'uk': 4, 'great britain' : 5} count = CountVectorizer(analyzer=WordNGramAnalyzer(min_n=1, max_n=2),vocabulary=vocab) test_set = ('nice day in nyc','london town','hello welcome to the big apple. enjoy it here and london too')  X_vectorized = count.transform(train_set).todense() smatrix2  = count.transform(test_set).todense()   base_clf = MultinomialNB(alpha=1)  clf = OneVsRestClassifier(base_clf).fit(X_vectorized, y_train) Y_pred = clf.predict(smatrix2) print Y_pred   Result: ['New York' 'London' 'London']     ","Q_Votes":"62"},{"Q_Title":"Use scikit-learn to classify into multiple categories","A_Content":"  Change this line to make it work in new versions of python  # lb = preprocessing.LabelBinarizer() lb = preprocessing.MultiLabelBinarizer()      ","Language":"Python","Tags":["python","classification","scikit-learn"],"URL":"https://stackoverflow.com/questions/10526579/use-scikit-learn-to-classify-into-multiple-categories","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to use one of scikit-learn's supervised learning methods to classify pieces of text into one or more categories. The predict function of all the algorithms I tried just returns one match.  For example I have a piece of text:  \"Theaters in New York compared to those in London\"   And I have trained the algorithm to pick a place for every text snippet I feed it.  In the above example I would want it to return New York and London, but it only returns New York.  Is it possible to use scikit-learn to return multiple results? Or even return the label with the next highest probability?   Thanks for your help.  ---Update   I tried using OneVsRestClassifier but I still only get one option back  per piece of text. Below is the sample code I am using  y_train = ('New York','London')   train_set = (\"new york nyc big apple\", \"london uk great britain\") vocab = {'new york' :0,'nyc':1,'big apple':2,'london' : 3, 'uk': 4, 'great britain' : 5} count = CountVectorizer(analyzer=WordNGramAnalyzer(min_n=1, max_n=2),vocabulary=vocab) test_set = ('nice day in nyc','london town','hello welcome to the big apple. enjoy it here and london too')  X_vectorized = count.transform(train_set).todense() smatrix2  = count.transform(test_set).todense()   base_clf = MultinomialNB(alpha=1)  clf = OneVsRestClassifier(base_clf).fit(X_vectorized, y_train) Y_pred = clf.predict(smatrix2) print Y_pred   Result: ['New York' 'London' 'London']     ","Q_Votes":"62"},{"Q_Title":"Use scikit-learn to classify into multiple categories","A_Content":"  Few Multi classification Examples are as under :-  Example 1:-  import numpy as np from sklearn.preprocessing import LabelBinarizer encoder = LabelBinarizer()  arr2d = np.array([1, 2, 3,4,5,6,7,8,9,10,11,12,13,14,1]) transfomed_label = encoder.fit_transform(arr2d) print(transfomed_label)   Output is   [[1 0 0 0 0 0 0 0 0 0 0 0 0 0]  [0 1 0 0 0 0 0 0 0 0 0 0 0 0]  [0 0 1 0 0 0 0 0 0 0 0 0 0 0]  [0 0 0 1 0 0 0 0 0 0 0 0 0 0]  [0 0 0 0 1 0 0 0 0 0 0 0 0 0]  [0 0 0 0 0 1 0 0 0 0 0 0 0 0]  [0 0 0 0 0 0 1 0 0 0 0 0 0 0]  [0 0 0 0 0 0 0 1 0 0 0 0 0 0]  [0 0 0 0 0 0 0 0 1 0 0 0 0 0]  [0 0 0 0 0 0 0 0 0 1 0 0 0 0]  [0 0 0 0 0 0 0 0 0 0 1 0 0 0]  [0 0 0 0 0 0 0 0 0 0 0 1 0 0]  [0 0 0 0 0 0 0 0 0 0 0 0 1 0]  [0 0 0 0 0 0 0 0 0 0 0 0 0 1]  [1 0 0 0 0 0 0 0 0 0 0 0 0 0]]   Example 2:-  import numpy as np from sklearn.preprocessing import LabelBinarizer encoder = LabelBinarizer()  arr2d = np.array(['Leopard','Lion','Tiger', 'Lion']) transfomed_label = encoder.fit_transform(arr2d) print(transfomed_label)   Output is  [[1 0 0]  [0 1 0]  [0 0 1]  [0 1 0]]      ","Language":"Python","Tags":["python","classification","scikit-learn"],"URL":"https://stackoverflow.com/questions/10526579/use-scikit-learn-to-classify-into-multiple-categories","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to use one of scikit-learn's supervised learning methods to classify pieces of text into one or more categories. The predict function of all the algorithms I tried just returns one match.  For example I have a piece of text:  \"Theaters in New York compared to those in London\"   And I have trained the algorithm to pick a place for every text snippet I feed it.  In the above example I would want it to return New York and London, but it only returns New York.  Is it possible to use scikit-learn to return multiple results? Or even return the label with the next highest probability?   Thanks for your help.  ---Update   I tried using OneVsRestClassifier but I still only get one option back  per piece of text. Below is the sample code I am using  y_train = ('New York','London')   train_set = (\"new york nyc big apple\", \"london uk great britain\") vocab = {'new york' :0,'nyc':1,'big apple':2,'london' : 3, 'uk': 4, 'great britain' : 5} count = CountVectorizer(analyzer=WordNGramAnalyzer(min_n=1, max_n=2),vocabulary=vocab) test_set = ('nice day in nyc','london town','hello welcome to the big apple. enjoy it here and london too')  X_vectorized = count.transform(train_set).todense() smatrix2  = count.transform(test_set).todense()   base_clf = MultinomialNB(alpha=1)  clf = OneVsRestClassifier(base_clf).fit(X_vectorized, y_train) Y_pred = clf.predict(smatrix2) print Y_pred   Result: ['New York' 'London' 'London']     ","Q_Votes":"62"},{"Q_Title":"Python NameError: name 'include' is not defined [closed]","A_Content":"  Guessing on the basis of whatever little information provided in the question, i think you might have forget to add the following import in your urls.py file.  from django.conf.urls import include      ","Language":"Python","Tags":["python","django","nameerror"],"URL":"https://stackoverflow.com/questions/34471102/python-nameerror-name-include-is-not-defined","A_Votes":"152","_type":"dict","isAccepted":"Yes","Q_Content":"    i'm currently developing a website with the framework django (i'm very beginner) but i have a problem with python : since i have created my templates, i can't run server anymore for this reason : NameError: name 'include' is not defined What do you think about that ? Thank you     ","Q_Votes":"62"},{"Q_Title":"Extract elements of list at odd positions","A_Content":"  Solution  Yes, you can:  l = L[1::2]   And this is all. The result will contain the elements placed on the following positions (0-based, so first element is at position 0, second at 1 etc.):  1, 3, 5   so the result (actual numbers) will be:  2, 4, 6   Explanation  The [1::2] at the end is just a notation for list slicing. Usually it is in the following form:  some_list[start:stop:step]   If we omitted start, the default (0) would be used. So the first element (at position 0, because the indexes are 0-based) would be selected. In this case the second element will be selected.  Because the second element is omitted, the default is being used (the end of the list). So the list is being iterated from the second element to the end.  We also provided third argument (step) which is 2. Which means that one element will be selected, the next will be skipped, and so on...  So, to sum up, in this case [1::2] means:   take the second element (which, by the way, is an odd element, if you judge from the index), skip one element (because we have step=2, so we are skipping one, as a contrary to step=1 which is default), take the next element, Repeat steps 2.-3. until the end of the list is reached,   EDIT: @PreetKukreti gave a link for another explanation on Python's list slicing notation. See here: Explain Python's slice notation  Extras - replacing counter with enumerate()  In your code, you explicitly create and increase the counter. In Python this is not necessary, as you can enumerate through some iterable using enumerate():  for count, i in enumerate(L):     if count % 2 == 1:         l.append(i)   The above serves exactly the same purpose as the code you were using:  count = 0 for i in L:     if count % 2 == 1:         l.append(i)     count += 1   More on emulating for loops with counter in Python: Accessing the index in Python 'for' loops     ","Language":"Python","Tags":["python","list","slice"],"URL":"https://stackoverflow.com/questions/12433695/extract-elements-of-list-at-odd-positions","A_Votes":"145","_type":"dict","isAccepted":"Yes","Q_Content":"    So I want to create a list which is a sublist of some existing list.  For example,  L = [1, 2, 3, 4, 5, 6, 7], I want to create a sublist li such that li contains all the elements in L at odd positions.  While I can do it by  L = [1, 2, 3, 4, 5, 6, 7] li = [] count = 0 for i in L:     if count % 2 == 1:         li.append(i)     count += 1   But I want to know if there is another way to do the same efficiently and in fewer number of steps.      ","Q_Votes":"62"},{"Q_Title":"Extract elements of list at odd positions","A_Content":"  For the odd positions, you probably want:  >>>> list_ = list(range(10)) >>>> print list_[1::2] [1, 3, 5, 7, 9] >>>>      ","Language":"Python","Tags":["python","list","slice"],"URL":"https://stackoverflow.com/questions/12433695/extract-elements-of-list-at-odd-positions","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    So I want to create a list which is a sublist of some existing list.  For example,  L = [1, 2, 3, 4, 5, 6, 7], I want to create a sublist li such that li contains all the elements in L at odd positions.  While I can do it by  L = [1, 2, 3, 4, 5, 6, 7] li = [] count = 0 for i in L:     if count % 2 == 1:         li.append(i)     count += 1   But I want to know if there is another way to do the same efficiently and in fewer number of steps.      ","Q_Votes":"62"},{"Q_Title":"Extract elements of list at odd positions","A_Content":"  I like List comprehensions because of their Math (Set) syntax. So how about this:  L = [1, 2, 3, 4, 5, 6, 7] odd_numbers = [y for x,y in enumerate(items) if x%2 != 0] even_numbers = [y for x,y in enumerate(items) if x%2 == 0]   Basically, if you enumerate over a list, you'll get the index x and the value y. What I'm doing here is putting the value y into the output list (even or odd) and using the index x to find out if that point is odd (x%2 != 0).     ","Language":"Python","Tags":["python","list","slice"],"URL":"https://stackoverflow.com/questions/12433695/extract-elements-of-list-at-odd-positions","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    So I want to create a list which is a sublist of some existing list.  For example,  L = [1, 2, 3, 4, 5, 6, 7], I want to create a sublist li such that li contains all the elements in L at odd positions.  While I can do it by  L = [1, 2, 3, 4, 5, 6, 7] li = [] count = 0 for i in L:     if count % 2 == 1:         li.append(i)     count += 1   But I want to know if there is another way to do the same efficiently and in fewer number of steps.      ","Q_Votes":"62"},{"Q_Title":"Python function pointer","A_Content":"  funcdict = {   'mypackage.mymodule.myfunction': mypackage.mymodule.myfunction,     .... }  funcdict[myvar](parameter1, parameter2)      ","Language":"Python","Tags":["python","function-pointers"],"URL":"https://stackoverflow.com/questions/2283210/python-function-pointer","A_Votes":"92","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a function name stored in a variable like this:  myvar = 'mypackage.mymodule.myfunction'   and I now want to call myfunction like this  myvar(parameter1, parameter2)   What's the easiest way to achieve this?     ","Q_Votes":"62"},{"Q_Title":"Python function pointer","A_Content":"  It's much nicer to be able to just store the function itself, since they're first-class objects in python.  import mypackage  myfunc = mypackage.mymodule.myfunction myfunc(parameter1, parameter2)   But, if you have to import the package dynamically, then you can achieve this through:  mypackage = __import__('mypackage') mymodule = getattr(mypackage, 'mymodule') myfunction = getattr(mymodule, 'myfunction')  myfunction(parameter1, parameter2)   Bear in mind however, that all of that work applies to whatever scope you're currently in. If you don't persist them somehow, you can't count on them staying around if you leave the local scope.     ","Language":"Python","Tags":["python","function-pointers"],"URL":"https://stackoverflow.com/questions/2283210/python-function-pointer","A_Votes":"34","_type":"dict","isAccepted":"No","Q_Content":"    I have a function name stored in a variable like this:  myvar = 'mypackage.mymodule.myfunction'   and I now want to call myfunction like this  myvar(parameter1, parameter2)   What's the easiest way to achieve this?     ","Q_Votes":"62"},{"Q_Title":"Python function pointer","A_Content":"  def f(a,b):     return a+b  xx = 'f' print eval('%s(%s,%s)'%(xx,2,3))   OUTPUT   5      ","Language":"Python","Tags":["python","function-pointers"],"URL":"https://stackoverflow.com/questions/2283210/python-function-pointer","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I have a function name stored in a variable like this:  myvar = 'mypackage.mymodule.myfunction'   and I now want to call myfunction like this  myvar(parameter1, parameter2)   What's the easiest way to achieve this?     ","Q_Votes":"62"},{"Q_Title":"Python function pointer","A_Content":"  Easiest  eval(myvar)(parameter1, parameter2)   You don't have a function \"pointer\".  You have a function \"name\".  While this works well, you will have a large number of folks telling you it's \"insecure\" or a \"security risk\".       ","Language":"Python","Tags":["python","function-pointers"],"URL":"https://stackoverflow.com/questions/2283210/python-function-pointer","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I have a function name stored in a variable like this:  myvar = 'mypackage.mymodule.myfunction'   and I now want to call myfunction like this  myvar(parameter1, parameter2)   What's the easiest way to achieve this?     ","Q_Votes":"62"},{"Q_Title":"Python function pointer","A_Content":"  Why not store the function itself? myvar = mypackage.mymodule.myfunction is much cleaner.     ","Language":"Python","Tags":["python","function-pointers"],"URL":"https://stackoverflow.com/questions/2283210/python-function-pointer","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I have a function name stored in a variable like this:  myvar = 'mypackage.mymodule.myfunction'   and I now want to call myfunction like this  myvar(parameter1, parameter2)   What's the easiest way to achieve this?     ","Q_Votes":"62"},{"Q_Title":"Python function pointer","A_Content":"  modname, funcname = myvar.rsplit('.', 1) getattr(sys.modules[modname], funcname)(parameter1, parameter2)      ","Language":"Python","Tags":["python","function-pointers"],"URL":"https://stackoverflow.com/questions/2283210/python-function-pointer","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have a function name stored in a variable like this:  myvar = 'mypackage.mymodule.myfunction'   and I now want to call myfunction like this  myvar(parameter1, parameter2)   What's the easiest way to achieve this?     ","Q_Votes":"62"},{"Q_Title":"Python function pointer","A_Content":"  I ran into a similar problem while creating a library to handle authentication. I want the app owner using my library to be able to register a callback with the library for checking authorization against LDAP groups the authenticated person is in. The configuration is getting passed in as a config.py file that gets imported and contains a dict with all the config parameters.  I got this to work:  >>> class MyClass(object): ...     def target_func(self): ...         print \"made it!\" ...     ...     def __init__(self,config): ...         self.config = config ...         self.config['funcname'] = getattr(self,self.config['funcname']) ...         self.config['funcname']() ...  >>> instance = MyClass({'funcname':'target_func'}) made it!   Is there a pythonic-er way to do this?     ","Language":"Python","Tags":["python","function-pointers"],"URL":"https://stackoverflow.com/questions/2283210/python-function-pointer","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a function name stored in a variable like this:  myvar = 'mypackage.mymodule.myfunction'   and I now want to call myfunction like this  myvar(parameter1, parameter2)   What's the easiest way to achieve this?     ","Q_Votes":"62"},{"Q_Title":"Python function pointer","A_Content":"  eval(compile(myvar,'<str>','eval'))(myargs)  compile(...,'eval') allows only a single statement, so that there can't be arbitrary commands after a call, or there will be a SyntaxError. Then a tiny bit of validation can at least constrain the expression to something in your power, like testing for 'mypackage' to start.     ","Language":"Python","Tags":["python","function-pointers"],"URL":"https://stackoverflow.com/questions/2283210/python-function-pointer","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a function name stored in a variable like this:  myvar = 'mypackage.mymodule.myfunction'   and I now want to call myfunction like this  myvar(parameter1, parameter2)   What's the easiest way to achieve this?     ","Q_Votes":"62"},{"Q_Title":"Absolute vs. explicit relative import of Python module","A_Content":"  Absolute imports. From PEP 8:     Relative imports for intra-package imports are highly   discouraged.         Always use the absolute package path for all imports.         Even now that PEP 328 [7] is fully implemented in Python 2.5,         its style of explicit relative imports is actively discouraged;         absolute imports are more portable and usually more readable.   Explicit relative imports are a nice language feature (I guess), but they're not nearly as explicit as absolute imports. The more readable form is:  import A.A import A.B.B   especially if you import several different namespaces. If you look at some well written projects/tutorials that include imports from within packages, they usually follow this style.  The few extra keystrokes you take to be more explicit will save others (and perhaps you) plenty of time in the future when they're trying to figure out your namespace (especially if you migrate to 3.x, in which some of the package names have changed).     ","Language":"Python","Tags":["python","package","python-import"],"URL":"https://stackoverflow.com/questions/4209641/absolute-vs-explicit-relative-import-of-python-module","A_Votes":"36","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm wondering about the preferred way to import packages in a Python application. I have a package structure like this:  project.app1.models project.app1.views project.app2.models   project.app1.views imports project.app1.models and project.app2.models. There are two ways to do this that come to mind.  With absolute imports:  import A.A import A.B.B   or with explicit relative imports, as introduced in Python 2.5 with PEP 328:  # explicit relative import ..A import .B   What is the most pythonic way to do this?     ","Q_Votes":"62"},{"Q_Title":"Absolute vs. explicit relative import of Python module","A_Content":"  Python relative imports are no longer strongly discouraged, but using absolute_import is strongly suggested in that case.  Please see this discussion citing Guido himself:     \"Isn't this mostly historical? Until the new relative-import syntax   was implemented there were various problems with relative imports. The   short-term solution was to recommend not using them. The long-term   solution was to implement an unambiguous syntax. Now it is time to   withdraw the anti-recommendation. Of course, without going overboard   -- I still find them an acquired taste; but they have their place.\"   The OP correctly links the PEP 328 that says:     Several use cases were presented, the most important of which is being   able to rearrange the structure of large packages without having to   edit sub-packages. In addition, a module inside a package can't easily   import itself without relative imports.   Also see almost duplicate question When or why to use relative imports in Python  Of course it still stands as a matter of taste. While it's easier to move code around with relative imports, that might also unexpectedly break things; and renaming the imports is not that difficult.  To force the new behaviour from PEP 328 use:  from __future__ import absolute_import   In this case, implicit relative import will no longer be possible (eg. import localfile will not work anymore, only from . import localfile). For clean and future proof behaviour, using absolute_import is advisable.  An important caveat is that because of  PEP 338 and PEP 366, relative imports require the python file to be imported as a module - you cannot execute a file.py that has a relative import or you'll get a ValueError: Attempted relative import in non-package.  This limitation should be taken into account when evaluating the best approach. Guido is against running scripts from a module in any case:     I'm -1 on this and on any other proposed twiddlings of the __main__ machinery.    The only use case seems to be running scripts that happen to be living inside a module's directory, which I've always seen as an antipattern.    To make me change my mind you'd have to convince me that it isn't.   Exhaustive discussions on the matter can be found on SO; re. Python 3 this is quite comprehensive:   Relative imports in Python 3      ","Language":"Python","Tags":["python","package","python-import"],"URL":"https://stackoverflow.com/questions/4209641/absolute-vs-explicit-relative-import-of-python-module","A_Votes":"95","_type":"dict","isAccepted":"No","Q_Content":"    I'm wondering about the preferred way to import packages in a Python application. I have a package structure like this:  project.app1.models project.app1.views project.app2.models   project.app1.views imports project.app1.models and project.app2.models. There are two ways to do this that come to mind.  With absolute imports:  import A.A import A.B.B   or with explicit relative imports, as introduced in Python 2.5 with PEP 328:  # explicit relative import ..A import .B   What is the most pythonic way to do this?     ","Q_Votes":"62"},{"Q_Title":"Absolute vs. explicit relative import of Python module","A_Content":"  Relative imports not only leave you free to rename your package later without changing dozens of internal imports, but I have also had success with them in solving certain problems involving things like circular imports or namespace packages, because they do not send Python \"back to the top\" to start the search for the next module all over again from the top-level namespace.     ","Language":"Python","Tags":["python","package","python-import"],"URL":"https://stackoverflow.com/questions/4209641/absolute-vs-explicit-relative-import-of-python-module","A_Votes":"30","_type":"dict","isAccepted":"No","Q_Content":"    I'm wondering about the preferred way to import packages in a Python application. I have a package structure like this:  project.app1.models project.app1.views project.app2.models   project.app1.views imports project.app1.models and project.app2.models. There are two ways to do this that come to mind.  With absolute imports:  import A.A import A.B.B   or with explicit relative imports, as introduced in Python 2.5 with PEP 328:  # explicit relative import ..A import .B   What is the most pythonic way to do this?     ","Q_Votes":"62"},{"Q_Title":"How do I use vi keys in ipython under *nix?","A_Content":"  In case someone's wandering in here recently, IPython 5.0 switched from readline to prompt_toolkit, so an updated answer to this question is to pass an option:  $ ipython --TerminalInteractiveShell.editing_mode=vi   ... or to set it globally in the profile configuration (~/.ipython/profile_default/ipython_config.py; create it with ipython profile create if you don't have it) with:  c.TerminalInteractiveShell.editing_mode = 'vi'      ","Language":"Python","Tags":["python","bash","vi","ipython","readline"],"URL":"https://stackoverflow.com/questions/10394302/how-do-i-use-vi-keys-in-ipython-under-nix","A_Votes":"109","_type":"dict","isAccepted":"Yes","Q_Content":"    Currently in Bash I use set -o vi to enable vi mode in my bash prompt.  How do I get this going in ipython?  Note: If an answer applies to all *nix, I'll remove the OS X from the title :)     ","Q_Votes":"62"},{"Q_Title":"How do I use vi keys in ipython under *nix?","A_Content":"  Looks like a solution works for many other readline compatible apps:  Set the following in your ~/.inputrc file:  set editing-mode vi set keymap vi set convert-meta on   Source: http://www.jukie.net/bart/blog/20040326082602     ","Language":"Python","Tags":["python","bash","vi","ipython","readline"],"URL":"https://stackoverflow.com/questions/10394302/how-do-i-use-vi-keys-in-ipython-under-nix","A_Votes":"30","_type":"dict","isAccepted":"No","Q_Content":"    Currently in Bash I use set -o vi to enable vi mode in my bash prompt.  How do I get this going in ipython?  Note: If an answer applies to all *nix, I'll remove the OS X from the title :)     ","Q_Votes":"62"},{"Q_Title":"How do I use vi keys in ipython under *nix?","A_Content":"  You can also interactively switch between Vi-mode and Emacs mode. According to the the readline docs to switch between them you are supposed to be able to use the M-C-j key combination but that only seems to allow me to switch to vi-mode - on my Mac (where ESC is used as the 'Meta' key) it is: ESC+CTRL+j. To switch back to Emacs mode one can use C-e but that didn't appear to work for me - I had to instead do M-C-e - on my Mac it is: ESC+CTRL+e.  FYI my ~/.inputrc is set up as follows:  set meta-flag on set input-meta on set convert-meta off set output-meta on      ","Language":"Python","Tags":["python","bash","vi","ipython","readline"],"URL":"https://stackoverflow.com/questions/10394302/how-do-i-use-vi-keys-in-ipython-under-nix","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    Currently in Bash I use set -o vi to enable vi mode in my bash prompt.  How do I get this going in ipython?  Note: If an answer applies to all *nix, I'll remove the OS X from the title :)     ","Q_Votes":"62"},{"Q_Title":"How do I use vi keys in ipython under *nix?","A_Content":"  ipython uses the readline library and this is configurable using the ~/.inputrc file. You can add   set editing-mode vi   to that file to make all readline based applications use vi style keybindings instead of Emacs.      ","Language":"Python","Tags":["python","bash","vi","ipython","readline"],"URL":"https://stackoverflow.com/questions/10394302/how-do-i-use-vi-keys-in-ipython-under-nix","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    Currently in Bash I use set -o vi to enable vi mode in my bash prompt.  How do I get this going in ipython?  Note: If an answer applies to all *nix, I'll remove the OS X from the title :)     ","Q_Votes":"62"},{"Q_Title":"How do I use vi keys in ipython under *nix?","A_Content":"  I needed to be able to switch modes interactively in IPython 5 and I found you can do so by recreating the prompt manager on the fly:  a = get_ipython().configurables[0]; a.editing_mode='vi'; a.init_prompt_toolkit_cli()      ","Language":"Python","Tags":["python","bash","vi","ipython","readline"],"URL":"https://stackoverflow.com/questions/10394302/how-do-i-use-vi-keys-in-ipython-under-nix","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Currently in Bash I use set -o vi to enable vi mode in my bash prompt.  How do I get this going in ipython?  Note: If an answer applies to all *nix, I'll remove the OS X from the title :)     ","Q_Votes":"62"},{"Q_Title":"How to prevent my site page to be loaded via 3rd party site frame of iFrame","A_Content":"  You cannot check it from the server's side, but you can use javascript to detect it after the page has loaded. Compare top and self, if they're not identical, you are in a frame.  Additionally, some modern browsers respect the X-FRAME-OPTIONS header, that can have two values:   DENY – prevents the page from being rendered if it is contained in a frame SAMEORIGIN – same as above, unless the page belongs to the same domain as the top-level frameset holder.   Users include Google's Picasa, that cannot be embedded in a frame.  Browsers that support the header, with the minimum version:   IE8 and IE9 Opera 10.50 Safari 4 Chrome 4.1.249.1042 Firefox 3.6.9 (older versions with NoScript)      ","Language":"Python","Tags":["php","python","iframe","http-headers","frame"],"URL":"https://stackoverflow.com/questions/2896623/how-to-prevent-my-site-page-to-be-loaded-via-3rd-party-site-frame-of-iframe","A_Votes":"86","_type":"dict","isAccepted":"Yes","Q_Content":"    How can I find out that my page is embedded as a frame to other site during page loading? I guess referrer request header can't help me here? Thanks.      ","Q_Votes":"62"},{"Q_Title":"How to prevent my site page to be loaded via 3rd party site frame of iFrame","A_Content":"  Stackoverflow includes some JS to test it (master.js). This is the relevant part of it:  if(top!=self){     top.location.replace(document.location);     alert(\"For security reasons, framing is not allowed; click OK to remove the frames.\") }   But keep in mind that JS can be disabled.     ","Language":"Python","Tags":["php","python","iframe","http-headers","frame"],"URL":"https://stackoverflow.com/questions/2896623/how-to-prevent-my-site-page-to-be-loaded-via-3rd-party-site-frame-of-iframe","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    How can I find out that my page is embedded as a frame to other site during page loading? I guess referrer request header can't help me here? Thanks.      ","Q_Votes":"62"},{"Q_Title":"How to prevent my site page to be loaded via 3rd party site frame of iFrame","A_Content":"  For modern browsers, you can use CSP (Content Security Policy), which is a standard. The following header will prevent the document from loading in a frame anywhere:  Content-Security-Policy: frame-ancestors 'none'   (IE 11 needs the X- prefix, though). You can also change 'none' to the origin on which framing is allowed, such as your own site.  To cover the older browsers, this is best used together with @Maerlyn's answer.     ","Language":"Python","Tags":["php","python","iframe","http-headers","frame"],"URL":"https://stackoverflow.com/questions/2896623/how-to-prevent-my-site-page-to-be-loaded-via-3rd-party-site-frame-of-iframe","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    How can I find out that my page is embedded as a frame to other site during page loading? I guess referrer request header can't help me here? Thanks.      ","Q_Votes":"62"},{"Q_Title":"How to prevent my site page to be loaded via 3rd party site frame of iFrame","A_Content":"  you can prevent loading you page in an iframe with javascript  <script type=\"text/javascript\"> if ( window.self !== window.top ) {     window.top.location.href=window.location.href; } </script>   this code change address of container of your page's iframe to your page address and force container to show your page.     ","Language":"Python","Tags":["php","python","iframe","http-headers","frame"],"URL":"https://stackoverflow.com/questions/2896623/how-to-prevent-my-site-page-to-be-loaded-via-3rd-party-site-frame-of-iframe","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    How can I find out that my page is embedded as a frame to other site during page loading? I guess referrer request header can't help me here? Thanks.      ","Q_Votes":"62"},{"Q_Title":"How to prevent my site page to be loaded via 3rd party site frame of iFrame","A_Content":"  Or you can block a specific domain if you don't mind your content in some locations but don't want it on a certain site.  For example, if offendingdomain.com was embedding your content, you could do this:  <script type=\"text/javascript\">     if(document.referrer.indexOf(\"offendingdomain.com\") != -1) {         window.location = \"http://www.youtube.com/watch_popup?v=oHg5SJYRHA0\";     } </script>   This would check the parent document's location and see if it's the offendingdomain.com that is embedding your content.  This script will then send that iframe to a certain famous youtube video as punishment.  In effect they just Rick-Rolled themselves.       ","Language":"Python","Tags":["php","python","iframe","http-headers","frame"],"URL":"https://stackoverflow.com/questions/2896623/how-to-prevent-my-site-page-to-be-loaded-via-3rd-party-site-frame-of-iframe","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    How can I find out that my page is embedded as a frame to other site during page loading? I guess referrer request header can't help me here? Thanks.      ","Q_Votes":"62"},{"Q_Title":"How to prevent my site page to be loaded via 3rd party site frame of iFrame","A_Content":"  Use javascript to check if it was loaded on iframe by placing the following script at the end of your php file and redirect to a page that displays warning or notice that your page should not be loaded using iframe.  <script type=\"text/javascript\"> if(top.location != window.location) {     window.location = '/error_iframe.php'; } </script>      ","Language":"Python","Tags":["php","python","iframe","http-headers","frame"],"URL":"https://stackoverflow.com/questions/2896623/how-to-prevent-my-site-page-to-be-loaded-via-3rd-party-site-frame-of-iframe","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    How can I find out that my page is embedded as a frame to other site during page loading? I guess referrer request header can't help me here? Thanks.      ","Q_Votes":"62"},{"Q_Title":"Python - Visibility of global variables in imported modules","A_Content":"  Globals in Python are global to a module, not across all modules. (Many people are confused by this, because in, say, C, a global is the same across all implementation files unless you explicitly make it static.)  There are different ways to solve this, depending on your actual use case.    Before even going down this path, ask yourself whether this really needs to be global. Maybe you really want a class, with f as an instance method, rather than just a free function? Then you could do something like this:  import module1 thingy1 = module1.Thingy(a=3) thingy1.f()     If you really do want a global, but it's just there to be used by module1, set it in that module.  import module1 module1.a=3 module1.f()     On the other hand, if a is shared by a whole lot of modules, put it somewhere else, and have everyone import it:  import shared_stuff import module1 shared_stuff.a = 3 module1.f()   … and, in module1.py:  import shared_stuff def f():     print shared_stuff.a   Don't use a from import unless the variable is intended to be a constant. from shared_stuff import a would create a new a variable initialized to whatever shared_stuff.a referred to at the time of the import, and this new a variable would not be affected by assignments to shared_stuff.a.    Or, in the rare case that you really do need it to be truly global everywhere, like a builtin, add it to the builtin module. The exact details differ between Python 2.x and 3.x. In 3.x, it works like this:  import builtins import module1 builtins.a = 3 module1.f()      ","Language":"Python","Tags":["python","namespaces","mysql-python","python-2.6","python-import"],"URL":"https://stackoverflow.com/questions/15959534/python-visibility-of-global-variables-in-imported-modules","A_Votes":"156","_type":"dict","isAccepted":"Yes","Q_Content":"    I've run into a bit of a wall importing modules in a Python script. I'll do my best to describe the error, why I run into it, and why I'm tying this particular approach to solve my problem (which I will describe in a second):  Let's suppose I have a module in which I've defined some utility functions/classes, which refer to entities defined in the namespace into which this auxiliary module will be imported (let \"a\" be such an entity):  module1:  def f():     print a   And then I have the main program, where \"a\" is defined, into which I want to import those utilities:  import module1 a=3 module1.f()   Executing the program will trigger the following error:  Traceback (most recent call last):   File \"Z:\\Python\\main.py\", line 10, in <module>     module1.f()   File \"Z:\\Python\\module1.py\", line 3, in f     print a NameError: global name 'a' is not defined   Similar questions have been asked in the past (two days ago, d'uh) and several solutions have been suggested, however I don't really think these fit my requirements. Here's my particular context:  I'm trying to make a Python program which connects to a MySQL database server and displays/modifies data with a GUI. For cleanliness sake, I've defined the bunch of auxiliary/utility MySQL-related functions in a separate file. However they all have a common variable, which I had originally defined inside the utilities module, and which is the cursor object from MySQLdb module. I later realised that the cursor object (which is used to communicate with the db server) should be defined in the main module, so that both the main module and anything that is imported into it can access that object.  End result would be something like this:  utilities_module.py:  def utility_1(args):     code which references a variable named \"cur\" def utility_n(args):     etcetera   And my main module:  program.py:  import MySQLdb, Tkinter db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   And then, as soon as I try to call any of the utilities functions, it triggers the aforementioned \"global name not defined\" error.  A particular suggestion was to have a \"from program import cur\" statement in the utilities file, such as this:  utilities_module.py:  from program import cur #rest of function definitions   program.py:  import Tkinter, MySQLdb db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   But that's cyclic import or something like that and, bottom line, it crashes too. So my question is:  How in hell can I make the \"cur\" object, defined in the main module, visible to those auxiliary functions which are imported into it?  Thanks for your time and my deepest apologies if the solution has been posted elsewhere. I just can't find the answer myself and I've got no more tricks in my book.     ","Q_Votes":"62"},{"Q_Title":"Python - Visibility of global variables in imported modules","A_Content":"  As a workaround, you could consider setting environment variables in the outer layer, like this.    main.py:  import os os.environ['MYVAL'] = str(myintvariable)   mymodule.py:  import os print os.environ['MYVAL']   As an extra precaution, handle the case when MYVAL is not defined inside the module.      ","Language":"Python","Tags":["python","namespaces","mysql-python","python-2.6","python-import"],"URL":"https://stackoverflow.com/questions/15959534/python-visibility-of-global-variables-in-imported-modules","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I've run into a bit of a wall importing modules in a Python script. I'll do my best to describe the error, why I run into it, and why I'm tying this particular approach to solve my problem (which I will describe in a second):  Let's suppose I have a module in which I've defined some utility functions/classes, which refer to entities defined in the namespace into which this auxiliary module will be imported (let \"a\" be such an entity):  module1:  def f():     print a   And then I have the main program, where \"a\" is defined, into which I want to import those utilities:  import module1 a=3 module1.f()   Executing the program will trigger the following error:  Traceback (most recent call last):   File \"Z:\\Python\\main.py\", line 10, in <module>     module1.f()   File \"Z:\\Python\\module1.py\", line 3, in f     print a NameError: global name 'a' is not defined   Similar questions have been asked in the past (two days ago, d'uh) and several solutions have been suggested, however I don't really think these fit my requirements. Here's my particular context:  I'm trying to make a Python program which connects to a MySQL database server and displays/modifies data with a GUI. For cleanliness sake, I've defined the bunch of auxiliary/utility MySQL-related functions in a separate file. However they all have a common variable, which I had originally defined inside the utilities module, and which is the cursor object from MySQLdb module. I later realised that the cursor object (which is used to communicate with the db server) should be defined in the main module, so that both the main module and anything that is imported into it can access that object.  End result would be something like this:  utilities_module.py:  def utility_1(args):     code which references a variable named \"cur\" def utility_n(args):     etcetera   And my main module:  program.py:  import MySQLdb, Tkinter db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   And then, as soon as I try to call any of the utilities functions, it triggers the aforementioned \"global name not defined\" error.  A particular suggestion was to have a \"from program import cur\" statement in the utilities file, such as this:  utilities_module.py:  from program import cur #rest of function definitions   program.py:  import Tkinter, MySQLdb db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   But that's cyclic import or something like that and, bottom line, it crashes too. So my question is:  How in hell can I make the \"cur\" object, defined in the main module, visible to those auxiliary functions which are imported into it?  Thanks for your time and my deepest apologies if the solution has been posted elsewhere. I just can't find the answer myself and I've got no more tricks in my book.     ","Q_Votes":"62"},{"Q_Title":"Python - Visibility of global variables in imported modules","A_Content":"  A function uses the globals of the module it's defined in. Instead of setting a = 3, for example, you should be setting module1.a = 3. So, if you want cur available as a global in utilities_module, set utilities_module.cur.  A better solution: don't use globals. Pass the variables you need into the functions that need it, or create a class to bundle all the data together, and pass it when initializing the instance.     ","Language":"Python","Tags":["python","namespaces","mysql-python","python-2.6","python-import"],"URL":"https://stackoverflow.com/questions/15959534/python-visibility-of-global-variables-in-imported-modules","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I've run into a bit of a wall importing modules in a Python script. I'll do my best to describe the error, why I run into it, and why I'm tying this particular approach to solve my problem (which I will describe in a second):  Let's suppose I have a module in which I've defined some utility functions/classes, which refer to entities defined in the namespace into which this auxiliary module will be imported (let \"a\" be such an entity):  module1:  def f():     print a   And then I have the main program, where \"a\" is defined, into which I want to import those utilities:  import module1 a=3 module1.f()   Executing the program will trigger the following error:  Traceback (most recent call last):   File \"Z:\\Python\\main.py\", line 10, in <module>     module1.f()   File \"Z:\\Python\\module1.py\", line 3, in f     print a NameError: global name 'a' is not defined   Similar questions have been asked in the past (two days ago, d'uh) and several solutions have been suggested, however I don't really think these fit my requirements. Here's my particular context:  I'm trying to make a Python program which connects to a MySQL database server and displays/modifies data with a GUI. For cleanliness sake, I've defined the bunch of auxiliary/utility MySQL-related functions in a separate file. However they all have a common variable, which I had originally defined inside the utilities module, and which is the cursor object from MySQLdb module. I later realised that the cursor object (which is used to communicate with the db server) should be defined in the main module, so that both the main module and anything that is imported into it can access that object.  End result would be something like this:  utilities_module.py:  def utility_1(args):     code which references a variable named \"cur\" def utility_n(args):     etcetera   And my main module:  program.py:  import MySQLdb, Tkinter db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   And then, as soon as I try to call any of the utilities functions, it triggers the aforementioned \"global name not defined\" error.  A particular suggestion was to have a \"from program import cur\" statement in the utilities file, such as this:  utilities_module.py:  from program import cur #rest of function definitions   program.py:  import Tkinter, MySQLdb db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   But that's cyclic import or something like that and, bottom line, it crashes too. So my question is:  How in hell can I make the \"cur\" object, defined in the main module, visible to those auxiliary functions which are imported into it?  Thanks for your time and my deepest apologies if the solution has been posted elsewhere. I just can't find the answer myself and I've got no more tricks in my book.     ","Q_Votes":"62"},{"Q_Title":"Python - Visibility of global variables in imported modules","A_Content":"  This post is just an observation for Python behaviour I encountered. Maybe the advices you read above don't work for you if you made the same thing I did below.  Namely, I have a module which contains global/shared variables (as suggested above):  #sharedstuff.py  globaltimes_randomnode=[] globalist_randomnode=[]   Then I had the main module which imports the shared stuff with:  import sharedstuff as shared   and some other modules that actually populated these arrays. These are called by the main module. When exiting these other modules I can clearly see that the arrays are populated. But when reading them back in the main module, they were empty. This was rather strange for me (well, I am new to Python). However, when I change the way I import the sharedstuff.py in the main module to:  from globals import *   it worked (the arrays were populated).  Just sayin'     ","Language":"Python","Tags":["python","namespaces","mysql-python","python-2.6","python-import"],"URL":"https://stackoverflow.com/questions/15959534/python-visibility-of-global-variables-in-imported-modules","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I've run into a bit of a wall importing modules in a Python script. I'll do my best to describe the error, why I run into it, and why I'm tying this particular approach to solve my problem (which I will describe in a second):  Let's suppose I have a module in which I've defined some utility functions/classes, which refer to entities defined in the namespace into which this auxiliary module will be imported (let \"a\" be such an entity):  module1:  def f():     print a   And then I have the main program, where \"a\" is defined, into which I want to import those utilities:  import module1 a=3 module1.f()   Executing the program will trigger the following error:  Traceback (most recent call last):   File \"Z:\\Python\\main.py\", line 10, in <module>     module1.f()   File \"Z:\\Python\\module1.py\", line 3, in f     print a NameError: global name 'a' is not defined   Similar questions have been asked in the past (two days ago, d'uh) and several solutions have been suggested, however I don't really think these fit my requirements. Here's my particular context:  I'm trying to make a Python program which connects to a MySQL database server and displays/modifies data with a GUI. For cleanliness sake, I've defined the bunch of auxiliary/utility MySQL-related functions in a separate file. However they all have a common variable, which I had originally defined inside the utilities module, and which is the cursor object from MySQLdb module. I later realised that the cursor object (which is used to communicate with the db server) should be defined in the main module, so that both the main module and anything that is imported into it can access that object.  End result would be something like this:  utilities_module.py:  def utility_1(args):     code which references a variable named \"cur\" def utility_n(args):     etcetera   And my main module:  program.py:  import MySQLdb, Tkinter db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   And then, as soon as I try to call any of the utilities functions, it triggers the aforementioned \"global name not defined\" error.  A particular suggestion was to have a \"from program import cur\" statement in the utilities file, such as this:  utilities_module.py:  from program import cur #rest of function definitions   program.py:  import Tkinter, MySQLdb db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   But that's cyclic import or something like that and, bottom line, it crashes too. So my question is:  How in hell can I make the \"cur\" object, defined in the main module, visible to those auxiliary functions which are imported into it?  Thanks for your time and my deepest apologies if the solution has been posted elsewhere. I just can't find the answer myself and I've got no more tricks in my book.     ","Q_Votes":"62"},{"Q_Title":"Python - Visibility of global variables in imported modules","A_Content":"  The easiest solution to this particular problem would have been to add another function within the module that would have stored the cursor in a variable global to the module. Then all the other functions could use it as well.  module1:  cursor = None  def setCursor(cur):     global cursor     cursor = cur  def method(some, args):     global cursor     do_stuff(cursor, some, args)   main program:  import module1  cursor = get_a_cursor() module1.setCursor(cursor) module1.method()      ","Language":"Python","Tags":["python","namespaces","mysql-python","python-2.6","python-import"],"URL":"https://stackoverflow.com/questions/15959534/python-visibility-of-global-variables-in-imported-modules","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I've run into a bit of a wall importing modules in a Python script. I'll do my best to describe the error, why I run into it, and why I'm tying this particular approach to solve my problem (which I will describe in a second):  Let's suppose I have a module in which I've defined some utility functions/classes, which refer to entities defined in the namespace into which this auxiliary module will be imported (let \"a\" be such an entity):  module1:  def f():     print a   And then I have the main program, where \"a\" is defined, into which I want to import those utilities:  import module1 a=3 module1.f()   Executing the program will trigger the following error:  Traceback (most recent call last):   File \"Z:\\Python\\main.py\", line 10, in <module>     module1.f()   File \"Z:\\Python\\module1.py\", line 3, in f     print a NameError: global name 'a' is not defined   Similar questions have been asked in the past (two days ago, d'uh) and several solutions have been suggested, however I don't really think these fit my requirements. Here's my particular context:  I'm trying to make a Python program which connects to a MySQL database server and displays/modifies data with a GUI. For cleanliness sake, I've defined the bunch of auxiliary/utility MySQL-related functions in a separate file. However they all have a common variable, which I had originally defined inside the utilities module, and which is the cursor object from MySQLdb module. I later realised that the cursor object (which is used to communicate with the db server) should be defined in the main module, so that both the main module and anything that is imported into it can access that object.  End result would be something like this:  utilities_module.py:  def utility_1(args):     code which references a variable named \"cur\" def utility_n(args):     etcetera   And my main module:  program.py:  import MySQLdb, Tkinter db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   And then, as soon as I try to call any of the utilities functions, it triggers the aforementioned \"global name not defined\" error.  A particular suggestion was to have a \"from program import cur\" statement in the utilities file, such as this:  utilities_module.py:  from program import cur #rest of function definitions   program.py:  import Tkinter, MySQLdb db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   But that's cyclic import or something like that and, bottom line, it crashes too. So my question is:  How in hell can I make the \"cur\" object, defined in the main module, visible to those auxiliary functions which are imported into it?  Thanks for your time and my deepest apologies if the solution has been posted elsewhere. I just can't find the answer myself and I've got no more tricks in my book.     ","Q_Votes":"62"},{"Q_Title":"Python - Visibility of global variables in imported modules","A_Content":"  Since globals are module specific, you can add the following function to all imported modules, and then use it to:   Add singular variables (in dictionary format) as globals for those  Transfer your main module globals to it .      addglobals = lambda x: globals().update(x)   Then all you need to pass on current globals is:      import module      module.addglobals(globals())      ","Language":"Python","Tags":["python","namespaces","mysql-python","python-2.6","python-import"],"URL":"https://stackoverflow.com/questions/15959534/python-visibility-of-global-variables-in-imported-modules","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've run into a bit of a wall importing modules in a Python script. I'll do my best to describe the error, why I run into it, and why I'm tying this particular approach to solve my problem (which I will describe in a second):  Let's suppose I have a module in which I've defined some utility functions/classes, which refer to entities defined in the namespace into which this auxiliary module will be imported (let \"a\" be such an entity):  module1:  def f():     print a   And then I have the main program, where \"a\" is defined, into which I want to import those utilities:  import module1 a=3 module1.f()   Executing the program will trigger the following error:  Traceback (most recent call last):   File \"Z:\\Python\\main.py\", line 10, in <module>     module1.f()   File \"Z:\\Python\\module1.py\", line 3, in f     print a NameError: global name 'a' is not defined   Similar questions have been asked in the past (two days ago, d'uh) and several solutions have been suggested, however I don't really think these fit my requirements. Here's my particular context:  I'm trying to make a Python program which connects to a MySQL database server and displays/modifies data with a GUI. For cleanliness sake, I've defined the bunch of auxiliary/utility MySQL-related functions in a separate file. However they all have a common variable, which I had originally defined inside the utilities module, and which is the cursor object from MySQLdb module. I later realised that the cursor object (which is used to communicate with the db server) should be defined in the main module, so that both the main module and anything that is imported into it can access that object.  End result would be something like this:  utilities_module.py:  def utility_1(args):     code which references a variable named \"cur\" def utility_n(args):     etcetera   And my main module:  program.py:  import MySQLdb, Tkinter db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   And then, as soon as I try to call any of the utilities functions, it triggers the aforementioned \"global name not defined\" error.  A particular suggestion was to have a \"from program import cur\" statement in the utilities file, such as this:  utilities_module.py:  from program import cur #rest of function definitions   program.py:  import Tkinter, MySQLdb db=MySQLdb.connect(#blahblah) ; cur=db.cursor()  #cur is defined! from utilities_module import *   But that's cyclic import or something like that and, bottom line, it crashes too. So my question is:  How in hell can I make the \"cur\" object, defined in the main module, visible to those auxiliary functions which are imported into it?  Thanks for your time and my deepest apologies if the solution has been posted elsewhere. I just can't find the answer myself and I've got no more tricks in my book.     ","Q_Votes":"62"},{"Q_Title":"Add missing dates to pandas dataframe","A_Content":"  You could use Series.reindex:  import pandas as pd  idx = pd.date_range('09-01-2013', '09-30-2013')  s = pd.Series({'09-02-2013': 2,                '09-03-2013': 10,                '09-06-2013': 5,                '09-07-2013': 1}) s.index = pd.DatetimeIndex(s.index)  s = s.reindex(idx, fill_value=0) print(s)   yields  2013-09-01     0 2013-09-02     2 2013-09-03    10 2013-09-04     0 2013-09-05     0 2013-09-06     5 2013-09-07     1 2013-09-08     0 ...      ","Language":"Python","Tags":["python","date","plot","pandas","dataframe"],"URL":"https://stackoverflow.com/questions/19324453/add-missing-dates-to-pandas-dataframe","A_Votes":"138","_type":"dict","isAccepted":"Yes","Q_Content":"    My data can have multiple events on a given date or NO events on a date. I take these events, get a count by date and plot them.  However, when I plot them, my two series don't always match.      idx = pd.date_range(df['simpleDate'].min(), df['simpleDate'].max()) s = df.groupby(['simpleDate']).size()   In the above code idx becomes a range of say 30 dates. 09-01-2013 to 09-30-2013 However S may only have 25 or 26 days because no events happened for a given date. I then get an AssertionError as the sizes dont match when I try to plot:  fig, ax = plt.subplots()     ax.bar(idx.to_pydatetime(), s, color='green')   What's the proper way to tackle this? Do I want to remove dates with no values from IDX or (which I'd rather do) is add to the series the missing date with a count of 0. I'd rather have a full graph of 30 days with 0 values. If this approach is right, any suggestions on how to get started? Do I need some sort of dynamic reindex function?  Here's a snippet of S ( df.groupby(['simpleDate']).size()  ), notice no entries for 04 and 05.  09-02-2013     2 09-03-2013    10 09-06-2013     5 09-07-2013     1      ","Q_Votes":"62"},{"Q_Title":"Add missing dates to pandas dataframe","A_Content":"  One issue is that reindex will fail if there are duplicate values. Say we're working with timestamped data, which we want to index by date:  df = pd.DataFrame({     'timestamps': pd.to_datetime(         ['2016-11-15 1:00','2016-11-16 2:00','2016-11-16 3:00','2016-11-18 4:00']),     'values':['a','b','c','d']}) df.index = pd.DatetimeIndex(df['timestamps']).floor('D') df   yields              timestamps             values 2016-11-15  \"2016-11-15 01:00:00\"  a 2016-11-16  \"2016-11-16 02:00:00\"  b 2016-11-16  \"2016-11-16 03:00:00\"  c 2016-11-18  \"2016-11-18 04:00:00\"  d   Due to the duplicate 2016-11-16 date, an attempt to reindex:  all_days = pd.date_range(df.index.min(), df.index.max(), freq='D') df.reindex(all_days)   fails with:  ... ValueError: cannot reindex from a duplicate axis   (by this it means the index has duplicates, not that it is itself a dup)  Instead, we can use .loc to look up entries for all dates in range:  df.loc[all_days]   yields              timestamps             values 2016-11-15  \"2016-11-15 01:00:00\"  a 2016-11-16  \"2016-11-16 02:00:00\"  b 2016-11-16  \"2016-11-16 03:00:00\"  c 2016-11-17  NaN                    NaN 2016-11-18  \"2016-11-18 04:00:00\"  d   fillna can be used on the column series to fill blanks if needed.     ","Language":"Python","Tags":["python","date","plot","pandas","dataframe"],"URL":"https://stackoverflow.com/questions/19324453/add-missing-dates-to-pandas-dataframe","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    My data can have multiple events on a given date or NO events on a date. I take these events, get a count by date and plot them.  However, when I plot them, my two series don't always match.      idx = pd.date_range(df['simpleDate'].min(), df['simpleDate'].max()) s = df.groupby(['simpleDate']).size()   In the above code idx becomes a range of say 30 dates. 09-01-2013 to 09-30-2013 However S may only have 25 or 26 days because no events happened for a given date. I then get an AssertionError as the sizes dont match when I try to plot:  fig, ax = plt.subplots()     ax.bar(idx.to_pydatetime(), s, color='green')   What's the proper way to tackle this? Do I want to remove dates with no values from IDX or (which I'd rather do) is add to the series the missing date with a count of 0. I'd rather have a full graph of 30 days with 0 values. If this approach is right, any suggestions on how to get started? Do I need some sort of dynamic reindex function?  Here's a snippet of S ( df.groupby(['simpleDate']).size()  ), notice no entries for 04 and 05.  09-02-2013     2 09-03-2013    10 09-06-2013     5 09-07-2013     1      ","Q_Votes":"62"},{"Q_Title":"Add missing dates to pandas dataframe","A_Content":"  A quicker workaround is to use .asfreq().  This doesn't require creation of a new index to call within .reindex().  # \"broken\" (staggered) dates dates = pd.Index([pd.Timestamp('2012-05-01'),                    pd.Timestamp('2012-05-04'),                    pd.Timestamp('2012-05-06')]) s = pd.Series([1, 2, 3], dates)  print(s.asfreq('D')) 2012-05-01    1.0 2012-05-02    NaN 2012-05-03    NaN 2012-05-04    2.0 2012-05-05    NaN 2012-05-06    3.0 Freq: D, dtype: float64      ","Language":"Python","Tags":["python","date","plot","pandas","dataframe"],"URL":"https://stackoverflow.com/questions/19324453/add-missing-dates-to-pandas-dataframe","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    My data can have multiple events on a given date or NO events on a date. I take these events, get a count by date and plot them.  However, when I plot them, my two series don't always match.      idx = pd.date_range(df['simpleDate'].min(), df['simpleDate'].max()) s = df.groupby(['simpleDate']).size()   In the above code idx becomes a range of say 30 dates. 09-01-2013 to 09-30-2013 However S may only have 25 or 26 days because no events happened for a given date. I then get an AssertionError as the sizes dont match when I try to plot:  fig, ax = plt.subplots()     ax.bar(idx.to_pydatetime(), s, color='green')   What's the proper way to tackle this? Do I want to remove dates with no values from IDX or (which I'd rather do) is add to the series the missing date with a count of 0. I'd rather have a full graph of 30 days with 0 values. If this approach is right, any suggestions on how to get started? Do I need some sort of dynamic reindex function?  Here's a snippet of S ( df.groupby(['simpleDate']).size()  ), notice no entries for 04 and 05.  09-02-2013     2 09-03-2013    10 09-06-2013     5 09-07-2013     1      ","Q_Votes":"62"},{"Q_Title":"Add missing dates to pandas dataframe","A_Content":"  Here's a nice method to fill in missing dates into a dataframe, with your choice of fill_value, days_back to fill in, and sort order (date_order) by which to sort the dataframe:  def fill_in_missing_dates(df, date_col_name = 'date',date_order = 'asc', fill_value = 0, days_back = 30):      df.set_index(date_col_name,drop=True,inplace=True)     df.index = pd.DatetimeIndex(df.index)     d = datetime.now().date()     d2 = d - timedelta(days = days_back)     idx = pd.date_range(d2, d, freq = \"D\")     df = df.reindex(idx,fill_value=fill_value)     df[date_col_name] = pd.DatetimeIndex(df.index)      return df      ","Language":"Python","Tags":["python","date","plot","pandas","dataframe"],"URL":"https://stackoverflow.com/questions/19324453/add-missing-dates-to-pandas-dataframe","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    My data can have multiple events on a given date or NO events on a date. I take these events, get a count by date and plot them.  However, when I plot them, my two series don't always match.      idx = pd.date_range(df['simpleDate'].min(), df['simpleDate'].max()) s = df.groupby(['simpleDate']).size()   In the above code idx becomes a range of say 30 dates. 09-01-2013 to 09-30-2013 However S may only have 25 or 26 days because no events happened for a given date. I then get an AssertionError as the sizes dont match when I try to plot:  fig, ax = plt.subplots()     ax.bar(idx.to_pydatetime(), s, color='green')   What's the proper way to tackle this? Do I want to remove dates with no values from IDX or (which I'd rather do) is add to the series the missing date with a count of 0. I'd rather have a full graph of 30 days with 0 values. If this approach is right, any suggestions on how to get started? Do I need some sort of dynamic reindex function?  Here's a snippet of S ( df.groupby(['simpleDate']).size()  ), notice no entries for 04 and 05.  09-02-2013     2 09-03-2013    10 09-06-2013     5 09-07-2013     1      ","Q_Votes":"62"},{"Q_Title":"Add missing dates to pandas dataframe","A_Content":"  In many cases, resample (see documentation here) offers a general solution that can handle both missing and duplicate dates.  For example:  df.resample('D').mean()   resample is a deferred operation like groupby so you need to follow it with another operation.  In this case mean works well, but you can also use many standard pandas method there like max, sum, etc.  Here is the original data, but with an extra entry for '2013-09-03':              val date            2013-09-02    2 2013-09-03   10 2013-09-03   20 2013-09-06    5 2013-09-07    1   And here are the results:               val date             2013-09-02   2.0 2013-09-03  15.0    <- mean of original values for 2013-09-03 2013-09-04   NaN    <- NaN b/c date not present in orig 2013-09-05   NaN    <- NaN b/c date not present in orig 2013-09-06   5.0 2013-09-07   1.0   Note that after this you could use methods like fillna or interpolate to fill the missing values as desired.     ","Language":"Python","Tags":["python","date","plot","pandas","dataframe"],"URL":"https://stackoverflow.com/questions/19324453/add-missing-dates-to-pandas-dataframe","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    My data can have multiple events on a given date or NO events on a date. I take these events, get a count by date and plot them.  However, when I plot them, my two series don't always match.      idx = pd.date_range(df['simpleDate'].min(), df['simpleDate'].max()) s = df.groupby(['simpleDate']).size()   In the above code idx becomes a range of say 30 dates. 09-01-2013 to 09-30-2013 However S may only have 25 or 26 days because no events happened for a given date. I then get an AssertionError as the sizes dont match when I try to plot:  fig, ax = plt.subplots()     ax.bar(idx.to_pydatetime(), s, color='green')   What's the proper way to tackle this? Do I want to remove dates with no values from IDX or (which I'd rather do) is add to the series the missing date with a count of 0. I'd rather have a full graph of 30 days with 0 values. If this approach is right, any suggestions on how to get started? Do I need some sort of dynamic reindex function?  Here's a snippet of S ( df.groupby(['simpleDate']).size()  ), notice no entries for 04 and 05.  09-02-2013     2 09-03-2013    10 09-06-2013     5 09-07-2013     1      ","Q_Votes":"62"},{"Q_Title":"Sorting a set of values [closed]","A_Content":"  From a comment:     I want to sort each set.   That's easy. For any set s (or anything else iterable), sorted(s) returns a list of the elements of s in sorted order:  >>> s = set(['0.000000000', '0.009518000', '10.277200999', '0.030810999', '0.018384000', '4.918560000']) >>> sorted(s) ['0.000000000', '0.009518000', '0.018384000', '0.030810999', '10.277200999', '4.918560000']     Note that sorted is giving you a list, not a set. That's because the whole point of a set, both in mathematics and in almost every programming language,* is that it's not ordered: the sets {1, 2} and {2, 1} are the same set.    You probably don't really want to sort those elements as strings, but as numbers (so 4.918560000 will come before 10.277200999 rather than after).  The best solution is most likely to store the numbers as numbers rather than strings in the first place. But if not, you just need to use a key function:  >>> sorted(s, key=float) ['0.000000000', '0.009518000', '0.018384000', '0.030810999', '4.918560000', '10.277200999']     For more information, see the Sorting HOWTO in the official docs.    * See the comments for exceptions.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/17457793/sorting-a-set-of-values","A_Votes":"126","_type":"dict","isAccepted":"Yes","Q_Content":"    I have values like this:  set(['0.000000000', '0.009518000', '10.277200999', '0.030810999', '0.018384000', '4.918560000']) set(['4.918859000', '0.060758000', '4.917336999', '0.003949999', '0.013945000', '10.281522000', '0.025082999'])     I want to sort the values in each set in increasing order. I don't want to sort between the sets, but the values in each set.     ","Q_Votes":"61"},{"Q_Title":"Is there a way to change effective process name in Python?","A_Content":"  Simply put, there's no portable way.  You'll have to test for the system and use the preferred method for that system.  Further, I'm confused about what you mean by process names on Windows.  Do you mean a service name?  I presume so, because nothing else really makes any sense (at least to my non-Windows using brain).  If so, you need to use Tim Golden's WMI interface and call the .Change method on the service... at least according to his tutorial.  For Linux none of the methods I found worked except for this poorly packaged module that sets argv[0] for you.  I don't even know if this will work on BSD variants (which does have a setproctitle system call).  I'm pretty sure argv[0] won't work on Solaris.     ","Language":"Python","Tags":["python","process","arguments","hide","ps"],"URL":"https://stackoverflow.com/questions/564695/is-there-a-way-to-change-effective-process-name-in-python","A_Votes":"10","_type":"dict","isAccepted":"Yes","Q_Content":"    Can I change effective process name of a Python script? I want to show a different name instead of the real name of the process when I get the system process list. In C I can set  strcpy(argv[0],\"othername\");   But in Python   argv[0] = \"othername\"   doesn't seem to work. When i get process list (with ps ax in my linux box) the real name doesn't change. I prefer a portable solution (or else one solution for posix and another for windows environments), if it exists.  Thanks in advance     ","Q_Votes":"61"},{"Q_Title":"Is there a way to change effective process name in Python?","A_Content":"  I've recently written a Python module to change the process title in a portable way: check https://github.com/dvarrazzo/py-setproctitle  It is a wrapper around the code used by PostgreSQL to perform the title change. It is currently tested against Linux and Mac OS X: Windows (with limited functionality) and BSD portings are on the way.  Edit: as of July 2010, the module works with BSD and with limited functionality on Windows, and has been ported to Python 3.x.     ","Language":"Python","Tags":["python","process","arguments","hide","ps"],"URL":"https://stackoverflow.com/questions/564695/is-there-a-way-to-change-effective-process-name-in-python","A_Votes":"69","_type":"dict","isAccepted":"No","Q_Content":"    Can I change effective process name of a Python script? I want to show a different name instead of the real name of the process when I get the system process list. In C I can set  strcpy(argv[0],\"othername\");   But in Python   argv[0] = \"othername\"   doesn't seem to work. When i get process list (with ps ax in my linux box) the real name doesn't change. I prefer a portable solution (or else one solution for posix and another for windows environments), if it exists.  Thanks in advance     ","Q_Votes":"61"},{"Q_Title":"Is there a way to change effective process name in Python?","A_Content":"  actually you need 2 things on linux: modify argv[0] from C (for ps auxf and friends) and call prctl with PR_SET_NAME flag.  There is absolutely no way to do first piece from python itself. Although, you can just change process name by calling prctl.  def set_proc_name(newname):     from ctypes import cdll, byref, create_string_buffer     libc = cdll.LoadLibrary('libc.so.6')     buff = create_string_buffer(len(newname)+1)     buff.value = newname     libc.prctl(15, byref(buff), 0, 0, 0)  def get_proc_name():     from ctypes import cdll, byref, create_string_buffer     libc = cdll.LoadLibrary('libc.so.6')     buff = create_string_buffer(128)     # 16 == PR_GET_NAME from <linux/prctl.h>     libc.prctl(16, byref(buff), 0, 0, 0)     return buff.value  import sys # sys.argv[0] == 'python'  # outputs 'python' get_proc_name()  set_proc_name('testing yeah')  # outputs 'testing yeah' get_proc_name()   ps auxf will show just 'python' after that :(. But top and ps -A will show new 'testing yeah' process name :). Also killall and pkill will work with new name.  btw, procname from googlecode also changes argv[0], thus, even, changes ps auxf output.  UPDATE: The solution posted in this answer does not play nice sometimes on FreeBSD. I'm now using py-setproctitle stated in this answer for a year or so on various linux and freebsd boxes. No fails so far! Everybody should too! :). It uses almost the same code as PostgreSQL uses in its main database and child processes.     ","Language":"Python","Tags":["python","process","arguments","hide","ps"],"URL":"https://stackoverflow.com/questions/564695/is-there-a-way-to-change-effective-process-name-in-python","A_Votes":"46","_type":"dict","isAccepted":"No","Q_Content":"    Can I change effective process name of a Python script? I want to show a different name instead of the real name of the process when I get the system process list. In C I can set  strcpy(argv[0],\"othername\");   But in Python   argv[0] = \"othername\"   doesn't seem to work. When i get process list (with ps ax in my linux box) the real name doesn't change. I prefer a portable solution (or else one solution for posix and another for windows environments), if it exists.  Thanks in advance     ","Q_Votes":"61"},{"Q_Title":"Is there a way to change effective process name in Python?","A_Content":"  Have a look on setproctitle package  This is quite a portable version and works on many platforms.     ","Language":"Python","Tags":["python","process","arguments","hide","ps"],"URL":"https://stackoverflow.com/questions/564695/is-there-a-way-to-change-effective-process-name-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Can I change effective process name of a Python script? I want to show a different name instead of the real name of the process when I get the system process list. In C I can set  strcpy(argv[0],\"othername\");   But in Python   argv[0] = \"othername\"   doesn't seem to work. When i get process list (with ps ax in my linux box) the real name doesn't change. I prefer a portable solution (or else one solution for posix and another for windows environments), if it exists.  Thanks in advance     ","Q_Votes":"61"},{"Q_Title":"Is there a way to change effective process name in Python?","A_Content":"  First, I'm not sure that simply settings argv[0] in a C program portably changes the name shown in ps.  Maybe it does in some unixen, but my understanding is that it's not expected to.  Second, since Windows is specifically non-POSIX compliant, only a few things are \"portable\" between POSIX and non-POSIX.  Since you specifically say 'ps', I'll assume that POSIX is your priority and Windows may not work.  More importantly, my understanding of changing argv[0] is that it requires a call to exec to make these changes.  Specifically, the exec call has both a path to an executable and a separate argv list.  Making your own call allows you to break the shell convention of putting the executable name in argv[0].  You have OS library process management which gives you direct access to the OS library for doing this.  You should consider breaking your script into two parts -- a starter and the \"real work\".  The starter establishes the run-time environment and exec's the real work with the desired parameters.    In C, you're replacing your own process with another.  In Python, you're replacing the old Python interpreter with a new one that has a different argv[0].  Hopefully, it won't balk at this.  Some programs check argv[0] to decide what they're doing.  You also have subprocess.popen that you can use to set your desired args and executable.   In this case, however, the parent process should lingers around to collect the child when the child finishes.  The parent may not be doing anything more than a Popen.wait     ","Language":"Python","Tags":["python","process","arguments","hide","ps"],"URL":"https://stackoverflow.com/questions/564695/is-there-a-way-to-change-effective-process-name-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Can I change effective process name of a Python script? I want to show a different name instead of the real name of the process when I get the system process list. In C I can set  strcpy(argv[0],\"othername\");   But in Python   argv[0] = \"othername\"   doesn't seem to work. When i get process list (with ps ax in my linux box) the real name doesn't change. I prefer a portable solution (or else one solution for posix and another for windows environments), if it exists.  Thanks in advance     ","Q_Votes":"61"},{"Q_Title":"Is there a way to change effective process name in Python?","A_Content":"  My answer to similar question marked as duplicate:  There is simplier (you don't need import any libs) but maybe not so elegant way. You have to do not use \"env\" inside the shebang line.  In other words, this will be named as \"python\" in process list:  #!/usr/bin/env python   But this will be named with your scriptname:  #!/usr/bin/python   So you'll be able to find it with something like pidof -x scriptname or ps -C scriptname     ","Language":"Python","Tags":["python","process","arguments","hide","ps"],"URL":"https://stackoverflow.com/questions/564695/is-there-a-way-to-change-effective-process-name-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    Can I change effective process name of a Python script? I want to show a different name instead of the real name of the process when I get the system process list. In C I can set  strcpy(argv[0],\"othername\");   But in Python   argv[0] = \"othername\"   doesn't seem to work. When i get process list (with ps ax in my linux box) the real name doesn't change. I prefer a portable solution (or else one solution for posix and another for windows environments), if it exists.  Thanks in advance     ","Q_Votes":"61"},{"Q_Title":"Is there a way to change effective process name in Python?","A_Content":"  I have found python-prctl to work very well under Linux. You will have to find something else for Windows.     ","Language":"Python","Tags":["python","process","arguments","hide","ps"],"URL":"https://stackoverflow.com/questions/564695/is-there-a-way-to-change-effective-process-name-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Can I change effective process name of a Python script? I want to show a different name instead of the real name of the process when I get the system process list. In C I can set  strcpy(argv[0],\"othername\");   But in Python   argv[0] = \"othername\"   doesn't seem to work. When i get process list (with ps ax in my linux box) the real name doesn't change. I prefer a portable solution (or else one solution for posix and another for windows environments), if it exists.  Thanks in advance     ","Q_Votes":"61"},{"Q_Title":"How to save a figure remotely with pylab? [duplicate]","A_Content":"  By default, matplotlib will use something like the TkAgg backend.  This requires an X-server to be running.  While you can just use X-forwarding, there will be a noticeable lag as matplotlib tries to connect with the remote X-server.  If you don't need to interact with the plot, it's often nicer to speed things up by avoiding an X-connection entirely.  If you want to make a plot without needing an X-server at all, use the Agg backend  instead.  E.g. do something like this:  import matplotlib matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab! import matplotlib.pyplot as plt  fig = plt.figure() plt.plot(range(10)) fig.savefig('temp.png')   If you want this to be the default behavior, you can modify your matplotlibrc file to use the Agg backend by default.  See this article for more information.     ","Language":"Python","Tags":["python","matplotlib","figure"],"URL":"https://stackoverflow.com/questions/4706451/how-to-save-a-figure-remotely-with-pylab","A_Votes":"125","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              Generating a PNG with matplotlib when DISPLAY is undefined                                        11 answers                                          I'm trying to generate a figure at a remote computer with the command pylab.savefig. But I got such error:  Unable to access the X Display, is $DISPLAY set properly?   How can I save the figure properly?     ","Q_Votes":"61"},{"Q_Title":"How to save a figure remotely with pylab? [duplicate]","A_Content":"  Umm, set the DISPLAY variable properly?   Graphics over the network using X11 work by the client (remote) computer having a DISPLAY environment variable that says where to draw the graphics. Typically it would be something like mydesktop.example.com:0.0 - then when an X11 program tries to draw something, it gets whizzed over the network to mydesktop.example.com, which is the machine you are sitting in front of (the X server) and up it pops.  Now, if the machine in front of you is Windows, then you'll need to get an X server from somewhere - cygwin/X11 or commercial eXceed will do nicely.  You also need to make sure security is handled - you cant just have anyone writing to your screen over the network.  How are you connecting to the remote machine? Because if you are going from a Linux box to another Linux box with ssh then the simple solution is probably 'Use ssh -X foo.example.com' to connect - this pipes the X11 connection over a local socket.  So, if ssh -X isnt the answer, can we have some more info on the operating systems involved please?     ","Language":"Python","Tags":["python","matplotlib","figure"],"URL":"https://stackoverflow.com/questions/4706451/how-to-save-a-figure-remotely-with-pylab","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Generating a PNG with matplotlib when DISPLAY is undefined                                        11 answers                                          I'm trying to generate a figure at a remote computer with the command pylab.savefig. But I got such error:  Unable to access the X Display, is $DISPLAY set properly?   How can I save the figure properly?     ","Q_Votes":"61"},{"Q_Title":"python: how to terminate a thread when main program ends","A_Content":"  Check this question. The correct answer has great explanation on how to terminate threads the right way: Is there any way to kill a Thread in Python?  To make the thread stop on Keyboard Interrupt signal (ctrl+c) you can catch the exception \"KeyboardInterrupt\" and cleanup before exiting. Like this:  try:     start_thread()   except (KeyboardInterrupt, SystemExit):     cleanup_stop_thread()     sys.exit()   This way you can control what to do whenever the program is abruptly terminated.  You can also use the built-in signal module that lets you setup signal handlers (in your specific case the SIGINT signal): http://docs.python.org/library/signal.html     ","Language":"Python","Tags":["python","multithreading","python-multithreading"],"URL":"https://stackoverflow.com/questions/2564137/python-how-to-terminate-a-thread-when-main-program-ends","A_Votes":"38","_type":"dict","isAccepted":"Yes","Q_Content":"    If I have a thread in an infinite loop, is there a way to terminate it when the main program ends (for example, when I press Ctrl+C)?     ","Q_Votes":"61"},{"Q_Title":"python: how to terminate a thread when main program ends","A_Content":"  If you make your worker threads daemon threads, they will die when all your non-daemon threads (e.g. the main thread) have exited.  http://docs.python.org/library/threading.html#threading.Thread.daemon     ","Language":"Python","Tags":["python","multithreading","python-multithreading"],"URL":"https://stackoverflow.com/questions/2564137/python-how-to-terminate-a-thread-when-main-program-ends","A_Votes":"73","_type":"dict","isAccepted":"No","Q_Content":"    If I have a thread in an infinite loop, is there a way to terminate it when the main program ends (for example, when I press Ctrl+C)?     ","Q_Votes":"61"},{"Q_Title":"python: how to terminate a thread when main program ends","A_Content":"  Use the atexit module of Python's standard library to register \"termination\" functions that get called (on the main thread) on any reasonably \"clean\" termination of the main thread, including an uncaught exception such as KeyboardInterrupt.  Such termination functions may (though inevitably in the main thread!) call any stop function you require; together with the possibility of setting a thread as daemon, that gives you the  tools to properly design the system functionality you need.     ","Language":"Python","Tags":["python","multithreading","python-multithreading"],"URL":"https://stackoverflow.com/questions/2564137/python-how-to-terminate-a-thread-when-main-program-ends","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    If I have a thread in an infinite loop, is there a way to terminate it when the main program ends (for example, when I press Ctrl+C)?     ","Q_Votes":"61"},{"Q_Title":"python: how to terminate a thread when main program ends","A_Content":"  If you spawn a Thread like so - myThread = Thread(target = function) - and then do myThread.start(); myThread.join(). When CTRL-C is initiated, the main thread doesn't exit because it is waiting on that blocking myThread.join() call. To fix this, simply put in a timeout on the .join() call. The timeout can be as long as you wish. If you want it to wait indefinitely, just put in a really long timeout, like 99999. It's also good practice to do myThread.daemon = True so all the threads exit when the main thread(non-daemon) exits.     ","Language":"Python","Tags":["python","multithreading","python-multithreading"],"URL":"https://stackoverflow.com/questions/2564137/python-how-to-terminate-a-thread-when-main-program-ends","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    If I have a thread in an infinite loop, is there a way to terminate it when the main program ends (for example, when I press Ctrl+C)?     ","Q_Votes":"61"},{"Q_Title":"python: how to terminate a thread when main program ends","A_Content":"  Try with enabling the sub-thread as daemon-thread.  For Example:  from threading import Thread  threaded = Thread(target=<your-method>) threaded.daemon = True  # This thread dies when main thread (only non-daemon thread) exits. threaded.start()   Or (in a line):  from threading import Thread  threaded = Thread(target=<your-method>, daemon=True).start()     When your main thread terminates (\"for example, when I press Ctrl+C\") that other threads kills with above instruction.     ","Language":"Python","Tags":["python","multithreading","python-multithreading"],"URL":"https://stackoverflow.com/questions/2564137/python-how-to-terminate-a-thread-when-main-program-ends","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    If I have a thread in an infinite loop, is there a way to terminate it when the main program ends (for example, when I press Ctrl+C)?     ","Q_Votes":"61"},{"Q_Title":"What is 'print' in Python?","A_Content":"  In 2.7 and down, print is a statement. In python 3, print is a function. To use the print function in Python 2.6 or 2.7, you can do   >>> from __future__ import print_function >>> print(print) <built-in function print>   See this section from the Python Language Reference, as well as PEP 3105 for why it changed.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7020417/what-is-print-in-python","A_Votes":"63","_type":"dict","isAccepted":"Yes","Q_Content":"    I understand what print does, but of what \"type\" is that language element? I think it's a function, but why does this fail?  >>> print print SyntaxError: invalid syntax   Isn't print a function? Shouldn't it print something like this?  >>> print print <function print at ...>      ","Q_Votes":"61"},{"Q_Title":"What is 'print' in Python?","A_Content":"  In Python 3, print() is a built-in function (object)  Before this, print was a statement. Demonstration...  Python 2.x:  % pydoc2.6 print  The ``print`` statement ***********************     print_stmt ::= \"print\" ([expression (\",\" expression)* [\",\"]]                   | \">>\" expression [(\",\" expression)+ [\",\"]])  ``print`` evaluates each expression in turn and writes the resulting object to standard output (see below).  If an object is not a string, it is first converted to a string using the rules for string conversions.  The (resulting or original) string is then written.  A space is written before each object is (converted and) written, unless the output system believes it is positioned at the beginning of a line.  This is the case (1) when no characters have yet been written to standard output, (2) when the last character written to standard output is a whitespace character except ``' '``, or (3) when the last write operation on standard output was not a ``print`` statement. (In some cases it may be functional to write an empty string to standard output for this reason.)  -----8<-----   Python 3.x:  % pydoc3.1 print  Help on built-in function print in module builtins:  print(...)     print(value, ..., sep=' ', end='\\n', file=sys.stdout)      Prints the values to a stream, or to sys.stdout by default.     Optional keyword arguments:     file: a file-like object (stream); defaults to the current sys.stdout.     sep:  string inserted between values, default a space.     end:  string appended after the last value, default a newline.      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7020417/what-is-print-in-python","A_Votes":"35","_type":"dict","isAccepted":"No","Q_Content":"    I understand what print does, but of what \"type\" is that language element? I think it's a function, but why does this fail?  >>> print print SyntaxError: invalid syntax   Isn't print a function? Shouldn't it print something like this?  >>> print print <function print at ...>      ","Q_Votes":"61"},{"Q_Title":"What is 'print' in Python?","A_Content":"  print is a mistake that has been rectified in Python 3. In Python 3 it is a function. In Python 1.x and 2.x it is not a function, it is a special form like if or while, but unlike those two it is not a control structure.  So, I guess the most accurate thing to call it is a statement.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7020417/what-is-print-in-python","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    I understand what print does, but of what \"type\" is that language element? I think it's a function, but why does this fail?  >>> print print SyntaxError: invalid syntax   Isn't print a function? Shouldn't it print something like this?  >>> print print <function print at ...>      ","Q_Votes":"61"},{"Q_Title":"What is 'print' in Python?","A_Content":"  In Python all statements (except assignment) are expressed with reserved words, not addressible objects.  That is why you cannot simply print print and you get a SyntaxError for trying.  It's a reserved word, not an object.  Confusingly, you can have a variable named print.  You can't address it in the normal way, but you can setattr(locals(), 'print', somevalue) and then print locals()['print'].  Other reserved words that might be desirable as variable names but are nonetheless verboten:  class import return raise except try pass lambda      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7020417/what-is-print-in-python","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I understand what print does, but of what \"type\" is that language element? I think it's a function, but why does this fail?  >>> print print SyntaxError: invalid syntax   Isn't print a function? Shouldn't it print something like this?  >>> print print <function print at ...>      ","Q_Votes":"61"},{"Q_Title":"What is 'print' in Python?","A_Content":"  In Python 2, print is a statement, which is a whole different kind of thing from a variable or function. Statements are not Python objects that can be passed to type(); they're just part of the language itself, even more so than built-in functions. For example, you could do sum = 5 (even though you shouldn't), but you can't do print = 5 or if = 7 because print and if are statements.  In Python 3, the print statement was replaced with the print() function. So if you do type(print), it'll return <class 'builtin_function_or_method'>.  BONUS:  In Python 2.6+, you can put from __future__ import print_function at the top of your script (as the first line of code), and the print statement will be replaced with the print() function.  >>> # Python 2 >>> from __future__ import print_function >>> type(print) <type 'builtin_function_or_method'>      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/7020417/what-is-print-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I understand what print does, but of what \"type\" is that language element? I think it's a function, but why does this fail?  >>> print print SyntaxError: invalid syntax   Isn't print a function? Shouldn't it print something like this?  >>> print print <function print at ...>      ","Q_Votes":"61"},{"Q_Title":"What is the purpose of __str__ and __repr__?","A_Content":"  __repr__      Called by the repr() built-in function and by string conversions (reverse quotes) to compute the \"official\" string representation of an object. If at all possible, this should look like a valid Python expression that could be used to recreate an object with the same value (given an appropriate environment).   __str__     Called by the str() built-in function and by the print statement to compute the \"informal\" string representation of an object.    Use __str__ if you have a class, and you'll want an informative/informal output, whenever you use this object as part of string. E.g. you can define __str__ methods for Django models, which then gets rendered in the Django administration interface. Instead of something like <Model object> you'll get like first and last name of a person, the name and date of an event, etc.    __repr__ and __str__ are similar, in fact sometimes equal (Example from BaseSet class in sets.py from the standard library):  def __repr__(self):     \"\"\"Return string representation of a set.      This looks like 'Set([<list of elements>])'.     \"\"\"     return self._repr()  # __str__ is the same as __repr__ __str__ = __repr__      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3691101/what-is-the-purpose-of-str-and-repr","A_Votes":"64","_type":"dict","isAccepted":"Yes","Q_Content":"    I really don't understand where are __str__ and __repr__ used in Python. I mean, I get that __str__ returns the string representation of an object. But why would I need that? In what use case scenario? Also, I read about the usage of __repr__  But what I don't understand is, where would I use them?     ","Q_Votes":"61"},{"Q_Title":"What is the purpose of __str__ and __repr__?","A_Content":"  The one place where you use them both a lot is in an interactive session. If you print an object then its __str__ method will get called, whereas if you just use an object by itself then its __repr__ is shown:  >>> from decimal import Decimal >>> a = Decimal(1.25) >>> print(a) 1.25                  <---- this is from __str__ >>> a Decimal('1.25')       <---- this is from __repr__   The __str__ is intended to be as human-readable as possible, whereas the __repr__ should aim to be something that could be used to recreate the object, although it often won't be exactly how it was created, as in this case.  It's also not unusual for both __str__ and __repr__ to return the same value (certainly for built-in types).     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3691101/what-is-the-purpose-of-str-and-repr","A_Votes":"45","_type":"dict","isAccepted":"No","Q_Content":"    I really don't understand where are __str__ and __repr__ used in Python. I mean, I get that __str__ returns the string representation of an object. But why would I need that? In what use case scenario? Also, I read about the usage of __repr__  But what I don't understand is, where would I use them?     ","Q_Votes":"61"},{"Q_Title":"What is the purpose of __str__ and __repr__?","A_Content":"  Grasshopper, when in doubt go to the mountain and read the Ancient Texts. In them you will find that __repr__() should:      If at all possible, this should look like a valid Python expression that could be used to recreate an object with the same value.      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3691101/what-is-the-purpose-of-str-and-repr","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    I really don't understand where are __str__ and __repr__ used in Python. I mean, I get that __str__ returns the string representation of an object. But why would I need that? In what use case scenario? Also, I read about the usage of __repr__  But what I don't understand is, where would I use them?     ","Q_Votes":"61"},{"Q_Title":"What is the purpose of __str__ and __repr__?","A_Content":"  Building up and on the previous answers and showing some more examples. If used properly, the difference between str and repr is clear. In short repr should return a string that can be copy-pasted to rebuilt the exact state of the object, whereas str is useful for logging and observing debugging results. Here are some examples to see the different outputs for some known libraries.  Datetime  print repr(datetime.now())    #datetime.datetime(2017, 12, 12, 18, 49, 27, 134411) print str(datetime.now())     #2017-12-12 18:49:27.134452   The str is good to print into a log file, where as repr can be re-purposed if you want to run it directly or dump it as commands into a file.   x = datetime.datetime(2017, 12, 12, 18, 49, 27, 134411)   Numpy  print repr(np.array([1,2,3,4,5])) #array([1, 2, 3, 4, 5]) print str(np.array([1,2,3,4,5]))  #[1 2 3 4 5]   in Numpy the repr is again directly consumable.   Custom Vector3 example  class Vector3(object):     def __init__(self, args):         self.x = args[0]         self.y = args[1]         self.z = args[2]      def __repr__(self):         return \"x: {0}, y: {1}, z: {2}\".format(self.x, self.y, self.z)      def __str__(self):         return \"Vector3([{0},{1},{2}])\".format(self.x, self.y, self.z)   In this example, repr returns again a string that can be directly consumed/executed, whereas str is more useful as a debug output.   v = Vector3([1,2,3]) print repr(v)    #Vector3([1,2,3]) print str(v)     #Vector(x:1, y:2, z:3)      One thing to keep in mind, if str isn't defined but repr, str will automatically call repr. So, it's always good to at least define repr      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3691101/what-is-the-purpose-of-str-and-repr","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I really don't understand where are __str__ and __repr__ used in Python. I mean, I get that __str__ returns the string representation of an object. But why would I need that? In what use case scenario? Also, I read about the usage of __repr__  But what I don't understand is, where would I use them?     ","Q_Votes":"61"},{"Q_Title":"What is the purpose of __str__ and __repr__?","A_Content":"  str will be informal and readable format whereas repr will give official object representation.  class Complex:     # Constructor     def __init__(self, real, imag):         self.real = real         self.imag = imag      # \"official\" string representation of an object     def __repr__(self):         return 'Rational(%s, %s)' % (self.real, self.imag)      # \"informal\" string representation of an object (readable)     def __str__(self):         return '%s + i%s' % (self.real, self.imag)      t = Complex(10, 20)      print (t)     # this is usual way we print the object     print (str(t))  # this is str representation of object      print (repr(t))  # this is repr representation of object     Answers :   Rational(10, 20) # usual representation 10 + i20      # str representation Rational(10, 20)  # repr representation      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3691101/what-is-the-purpose-of-str-and-repr","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I really don't understand where are __str__ and __repr__ used in Python. I mean, I get that __str__ returns the string representation of an object. But why would I need that? In what use case scenario? Also, I read about the usage of __repr__  But what I don't understand is, where would I use them?     ","Q_Votes":"61"},{"Q_Title":"How do I manage third-party Python libraries with Google App Engine? (virtualenv? pip?)","A_Content":"  What about simply:  $ pip install -r requirements.txt -t <your_app_directory/lib>   Create/edit <your_app_directory>/appengine_config.py:  \"\"\"This file is loaded when starting a new application instance.\"\"\" import sys import os.path  # add `lib` subdirectory to `sys.path`, so our `main` module can load # third-party libraries. sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'lib'))   UPDATE:  Google updated their sample to appengine_config.py, like:      from google.appengine.ext import vendor     vendor.add('lib')   Note: Even though their example has .gitignore ignoring lib/ directory you still need to keep that directory under source control if you use git-push deployment method.     ","Language":"Python","Tags":["python","google-app-engine","deployment","pip","egg"],"URL":"https://stackoverflow.com/questions/4863557/how-do-i-manage-third-party-python-libraries-with-google-app-engine-virtualenv","A_Votes":"45","_type":"dict","isAccepted":"Yes","Q_Content":"    What's the best strategy for managing third-party Python libraries with Google App Engine?  Say I want to use Flask, a webapp framework. A blog entry says to do this, which doesn't seem right:  $ cd /tmp/ $ wget http://pypi.python.org/packages/source/F/Flask/Flask-0.6.1.tar.gz $ tar zxf Flask-0.6.1.tar.gz $ cp -r Flask-0.6.1/flask ~/path/to/project/ (... repeat for other packages ...)   There must be a better way to manage third-party code, especially if I want to track versions, test upgrades or if two libraries share a subdirectory. I know that Python can import modules from zipfiles and that pip can work with a wonderful REQUIREMENTS file, and I've seen that pip has a zip command for use with GAE.  (Note: There's a handful of similar questions — 1, 2, 3, 4, 5 — but they're case-specific and don't really answer my question.)     ","Q_Votes":"61"},{"Q_Title":"How do I manage third-party Python libraries with Google App Engine? (virtualenv? pip?)","A_Content":"  Here's how I do it:   project  .Python bin lib  python2.5   site-packages  < pip install packages here >    include src  app.yaml  index.yaml main.yaml < symlink the pip installed packages in ../lib/python2.5/site-packages      The project directory is the top level directory where the virtualenv sits. I get the virtualenv using the following commands:  cd project virtualenv -p /usr/bin/python2.5 --no-site-packages --distribute .   The src directory is where all your code goes. When you deploy your code to GAE, *only* deploy those in the src directory and nothing else. The appcfg.py will resolve the symlinks and copy the library files to GAE for you.  I don't install my libraries as zip files mainly for convenience in case I need to read the source code, which I happen to do a lot just out of curiosity. However, if you really want to zip the libraries, put the following code snippet into your main.py  import sys for p in ['librarie.zip', 'package.egg'...]:     sys.path.insert(0, p)   After this you can import your zipped up packages as usual.  One thing to watch out for is setuptools' pkg_resources.py. I copied that directly into my src directory so my other symlinked packages can use it. Watch out for anything that uses entry_points. In my case I'm using Toscawidgets2 and I had to dig into the source code to manually wire up the pieces. It can become annoying if you had a lot of libraries that rely on entry_point.     ","Language":"Python","Tags":["python","google-app-engine","deployment","pip","egg"],"URL":"https://stackoverflow.com/questions/4863557/how-do-i-manage-third-party-python-libraries-with-google-app-engine-virtualenv","A_Votes":"70","_type":"dict","isAccepted":"No","Q_Content":"    What's the best strategy for managing third-party Python libraries with Google App Engine?  Say I want to use Flask, a webapp framework. A blog entry says to do this, which doesn't seem right:  $ cd /tmp/ $ wget http://pypi.python.org/packages/source/F/Flask/Flask-0.6.1.tar.gz $ tar zxf Flask-0.6.1.tar.gz $ cp -r Flask-0.6.1/flask ~/path/to/project/ (... repeat for other packages ...)   There must be a better way to manage third-party code, especially if I want to track versions, test upgrades or if two libraries share a subdirectory. I know that Python can import modules from zipfiles and that pip can work with a wonderful REQUIREMENTS file, and I've seen that pip has a zip command for use with GAE.  (Note: There's a handful of similar questions — 1, 2, 3, 4, 5 — but they're case-specific and don't really answer my question.)     ","Q_Votes":"61"},{"Q_Title":"How do I manage third-party Python libraries with Google App Engine? (virtualenv? pip?)","A_Content":"  I prefer buildout.  You set up dependencies in setup.py in your project or buildout.cfg, pin the versions in buildout.cfg, and specify which packages are not available on GAE and should be included in packages.zip. rod.recipe.appengine will copy required packages into packages.zip, and as long as you insert packages.zip into the sys.path, they can be imported anywhere.  You can also use forks from github if the package you need is not on pypi  find-links =     https://github.com/tesdal/pusher_client_python/tarball/rewrite#egg=pusher-2.0dev2  [versions] pusher = 2.0dev2   and all of these settings and dependencies are versioned in git.  Instead of wondering which copy of Flask is currently included in your source tree and perhaps copied into your version control (or requiring new developers to manually unpack and upgrade), you simply check the version in buildout.cfg. If you want a new version, change buildout.cfg and rerun buildout.  You can also use it to insert variables into config file templates, like setting the appspot id and version in app.yaml if you have staging server with staging.cfg and so on.     ","Language":"Python","Tags":["python","google-app-engine","deployment","pip","egg"],"URL":"https://stackoverflow.com/questions/4863557/how-do-i-manage-third-party-python-libraries-with-google-app-engine-virtualenv","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    What's the best strategy for managing third-party Python libraries with Google App Engine?  Say I want to use Flask, a webapp framework. A blog entry says to do this, which doesn't seem right:  $ cd /tmp/ $ wget http://pypi.python.org/packages/source/F/Flask/Flask-0.6.1.tar.gz $ tar zxf Flask-0.6.1.tar.gz $ cp -r Flask-0.6.1/flask ~/path/to/project/ (... repeat for other packages ...)   There must be a better way to manage third-party code, especially if I want to track versions, test upgrades or if two libraries share a subdirectory. I know that Python can import modules from zipfiles and that pip can work with a wonderful REQUIREMENTS file, and I've seen that pip has a zip command for use with GAE.  (Note: There's a handful of similar questions — 1, 2, 3, 4, 5 — but they're case-specific and don't really answer my question.)     ","Q_Votes":"61"},{"Q_Title":"How do I manage third-party Python libraries with Google App Engine? (virtualenv? pip?)","A_Content":"  I recently created a tool for this called gaenv. It follows a requirements.txt format, but doesn't install it, you can install with pip install -r requirements.txt then run the command line tool gaenv.  $ pip install -r requirements.txt $ gaenv   This creates symlinks automatically, you could install gaenv in your virtualenv too and run the binary from there. Here is a blog post about it:   http://blog.altlimit.com/2013/06/google-app-engine-virtualenv-tool-that.html  also on github  https://github.com/faisalraja/gaenv     ","Language":"Python","Tags":["python","google-app-engine","deployment","pip","egg"],"URL":"https://stackoverflow.com/questions/4863557/how-do-i-manage-third-party-python-libraries-with-google-app-engine-virtualenv","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What's the best strategy for managing third-party Python libraries with Google App Engine?  Say I want to use Flask, a webapp framework. A blog entry says to do this, which doesn't seem right:  $ cd /tmp/ $ wget http://pypi.python.org/packages/source/F/Flask/Flask-0.6.1.tar.gz $ tar zxf Flask-0.6.1.tar.gz $ cp -r Flask-0.6.1/flask ~/path/to/project/ (... repeat for other packages ...)   There must be a better way to manage third-party code, especially if I want to track versions, test upgrades or if two libraries share a subdirectory. I know that Python can import modules from zipfiles and that pip can work with a wonderful REQUIREMENTS file, and I've seen that pip has a zip command for use with GAE.  (Note: There's a handful of similar questions — 1, 2, 3, 4, 5 — but they're case-specific and don't really answer my question.)     ","Q_Votes":"61"},{"Q_Title":"How do I manage third-party Python libraries with Google App Engine? (virtualenv? pip?)","A_Content":"  Wernight's solution is the closest to current practice in the official Flask example app, which I've already improved by changing the sys.path.insert() call to site.addsitedir() in order to allow for namespace packages by processing their attendant .pth files (which are important for frameworks like Pyramid).  So far so good, but that appends the directory to the path, and so loses the opportunity to override the included libraries (like WebOb and requests) with newer versions.  What is needed then in appengine_config.py (and I am trying to get this change accepted into the official repos as well) is the following:  \"\"\"This file is loaded when starting a new application instance.\"\"\" import os.path import site.addsitedir import sys.path  dirname = 'lib' dirpath = os.path.join(os.path.dirname(__file__), dirname)  # split path after 1st element ('.') so local modules are always found first sys.path, remainder = sys.path[:1], sys.path[1:]  # add `lib` subdirectory as a site directory, so our `main` module can load # third-party libraries. site.addsitedir(dirpath)  # append the rest of the path sys.path.extend(remainder)   The final version of this code may end up hidden away in a vendor.py module and called like insertsitedir(index, path) or some other variation, as you can see in the discussion attending this pull request, but the logic is more or less how it will work regardless, to allow a simple pip install -r requirements.txt -t lib/ to work for all packages including namespace ones, and to still allow overriding the included libraries with new versions, as I have so far been unable to find a simpler alternative.     ","Language":"Python","Tags":["python","google-app-engine","deployment","pip","egg"],"URL":"https://stackoverflow.com/questions/4863557/how-do-i-manage-third-party-python-libraries-with-google-app-engine-virtualenv","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    What's the best strategy for managing third-party Python libraries with Google App Engine?  Say I want to use Flask, a webapp framework. A blog entry says to do this, which doesn't seem right:  $ cd /tmp/ $ wget http://pypi.python.org/packages/source/F/Flask/Flask-0.6.1.tar.gz $ tar zxf Flask-0.6.1.tar.gz $ cp -r Flask-0.6.1/flask ~/path/to/project/ (... repeat for other packages ...)   There must be a better way to manage third-party code, especially if I want to track versions, test upgrades or if two libraries share a subdirectory. I know that Python can import modules from zipfiles and that pip can work with a wonderful REQUIREMENTS file, and I've seen that pip has a zip command for use with GAE.  (Note: There's a handful of similar questions — 1, 2, 3, 4, 5 — but they're case-specific and don't really answer my question.)     ","Q_Votes":"61"},{"Q_Title":"How do I manage third-party Python libraries with Google App Engine? (virtualenv? pip?)","A_Content":"  Note: this answer is specific for Flask on Google App Engine.  See the flask-appengine-template project for an example of how to get Flask extensions to work on App Engine. https://github.com/kamalgill/flask-appengine-template  Drop the extension into the namespace package folder at src/packages/flaskext and you're all set. https://github.com/kamalgill/flask-appengine-template/tree/master/src/lib/flaskext  Non-Flask packages can be dropped into the src/packages folder as zip files, eggs, or unzipped packages, as the project template includes the sys.path.insert() snippet posted above.     ","Language":"Python","Tags":["python","google-app-engine","deployment","pip","egg"],"URL":"https://stackoverflow.com/questions/4863557/how-do-i-manage-third-party-python-libraries-with-google-app-engine-virtualenv","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    What's the best strategy for managing third-party Python libraries with Google App Engine?  Say I want to use Flask, a webapp framework. A blog entry says to do this, which doesn't seem right:  $ cd /tmp/ $ wget http://pypi.python.org/packages/source/F/Flask/Flask-0.6.1.tar.gz $ tar zxf Flask-0.6.1.tar.gz $ cp -r Flask-0.6.1/flask ~/path/to/project/ (... repeat for other packages ...)   There must be a better way to manage third-party code, especially if I want to track versions, test upgrades or if two libraries share a subdirectory. I know that Python can import modules from zipfiles and that pip can work with a wonderful REQUIREMENTS file, and I've seen that pip has a zip command for use with GAE.  (Note: There's a handful of similar questions — 1, 2, 3, 4, 5 — but they're case-specific and don't really answer my question.)     ","Q_Votes":"61"},{"Q_Title":"Replace console output in Python","A_Content":"  An easy solution is just writing \"\\r\" before the string and not adding a newline; if the string never gets shorter this is sufficient...  sys.stdout.write(\"\\rDoing thing %i\" % i) sys.stdout.flush()   Slightly more sophisticated is a progress bar... this is something I am using:  def startProgress(title):     global progress_x     sys.stdout.write(title + \": [\" + \"-\"*40 + \"]\" + chr(8)*41)     sys.stdout.flush()     progress_x = 0  def progress(x):     global progress_x     x = int(x * 40 // 100)     sys.stdout.write(\"#\" * (x - progress_x))     sys.stdout.flush()     progress_x = x  def endProgress():     sys.stdout.write(\"#\" * (40 - progress_x) + \"]\\n\")     sys.stdout.flush()   You call startProgress passing the description of the operation, then progress(x) where x is the percentage and finally endProgress()     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6169217/replace-console-output-in-python","A_Votes":"89","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm wondering how I could create one of those nifty console counters in Python as in certain C/C++-programs.  I've got a loop doing things and the current output is along the lines of:  Doing thing 0 Doing thing 1 Doing thing 2 ...   what would be neater would be to just have the last line update;  X things done.   I've seen this in a number of console programs and am wondering if/how I'd do this in Python.     ","Q_Votes":"61"},{"Q_Title":"Replace console output in Python","A_Content":"  A more elegant solution could be:  def progressBar(value, endvalue, bar_length=20):          percent = float(value) / endvalue         arrow = '-' * int(round(percent * bar_length)-1) + '>'         spaces = ' ' * (bar_length - len(arrow))          sys.stdout.write(\"\\rPercent: [{0}] {1}%\".format(arrow + spaces, int(round(percent * 100))))         sys.stdout.flush()   call this function with value and endvalue, result should be  Percent: [------------->      ] 69%      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6169217/replace-console-output-in-python","A_Votes":"20","_type":"dict","isAccepted":"No","Q_Content":"    I'm wondering how I could create one of those nifty console counters in Python as in certain C/C++-programs.  I've got a loop doing things and the current output is along the lines of:  Doing thing 0 Doing thing 1 Doing thing 2 ...   what would be neater would be to just have the last line update;  X things done.   I've seen this in a number of console programs and am wondering if/how I'd do this in Python.     ","Q_Votes":"61"},{"Q_Title":"Replace console output in Python","A_Content":"  The other answer may be better, but here's what I was doing. First, I made a function called progress which prints off the backspace character:  def progress(x):     out = '%s things done' % x  # The output     bs = '\\b' * 1000            # The backspace     print bs,     print out,   Then I called it in a loop in my main function like so:  def main():     for x in range(20):         progress(x)     return   This will of course erase the entire line, but you can mess with it to do exactly what you want. I ended up make a progress bar using this method.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6169217/replace-console-output-in-python","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I'm wondering how I could create one of those nifty console counters in Python as in certain C/C++-programs.  I've got a loop doing things and the current output is along the lines of:  Doing thing 0 Doing thing 1 Doing thing 2 ...   what would be neater would be to just have the last line update;  X things done.   I've seen this in a number of console programs and am wondering if/how I'd do this in Python.     ","Q_Votes":"61"},{"Q_Title":"Replace console output in Python","A_Content":"  For anyone who stumbles upon this years later (like I did), I tweaked 6502's methods a little bit to allow the progress bar to decrease as well as increase. Useful in slightly more cases. Thanks 6502 for a great tool!  Basically, the only difference is that the whole line of #s and -s is written each time progress(x) is called, and the cursor is always returned to the start of the bar.   def startprogress(title):     \"\"\"Creates a progress bar 40 chars long on the console     and moves cursor back to beginning with BS character\"\"\"     global progress_x     sys.stdout.write(title + \": [\" + \"-\" * 40 + \"]\" + chr(8) * 41)     sys.stdout.flush()     progress_x = 0   def progress(x):     \"\"\"Sets progress bar to a certain percentage x.     Progress is given as whole percentage, i.e. 50% done     is given by x = 50\"\"\"     global progress_x     x = int(x * 40 // 100)                           sys.stdout.write(\"#\" * x + \"-\" * (40 - x) + \"]\" + chr(8) * 41)     sys.stdout.flush()     progress_x = x   def endprogress():     \"\"\"End of progress bar;     Write full bar, then move to next line\"\"\"     sys.stdout.write(\"#\" * 40 + \"]\\n\")     sys.stdout.flush()      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6169217/replace-console-output-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I'm wondering how I could create one of those nifty console counters in Python as in certain C/C++-programs.  I've got a loop doing things and the current output is along the lines of:  Doing thing 0 Doing thing 1 Doing thing 2 ...   what would be neater would be to just have the last line update;  X things done.   I've seen this in a number of console programs and am wondering if/how I'd do this in Python.     ","Q_Votes":"61"},{"Q_Title":"Replace console output in Python","A_Content":"  If I understood well (not sure) you want to print using <CR> and not <LR>?  If so this is possible, as long the console terminal allows this (it will break when output si redirected to a file).  from __future__ import print_function print(\"count x\\r\", file=sys.stdout, end=\" \")      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6169217/replace-console-output-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm wondering how I could create one of those nifty console counters in Python as in certain C/C++-programs.  I've got a loop doing things and the current output is along the lines of:  Doing thing 0 Doing thing 1 Doing thing 2 ...   what would be neater would be to just have the last line update;  X things done.   I've seen this in a number of console programs and am wondering if/how I'd do this in Python.     ","Q_Votes":"61"},{"Q_Title":"Replace console output in Python","A_Content":"  In python 3 you can do this to print on the same line:   print('', end='\\r')   Especially useful to keep track of the latest update and progress.   I would also recommend tqdm from here if one wants to see the progress of a loop. It prints the current iteration and total iterations as a progression bar with an expected time of finishing. Super useful and quick. Works for python2 and python3.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6169217/replace-console-output-in-python","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm wondering how I could create one of those nifty console counters in Python as in certain C/C++-programs.  I've got a loop doing things and the current output is along the lines of:  Doing thing 0 Doing thing 1 Doing thing 2 ...   what would be neater would be to just have the last line update;  X things done.   I've seen this in a number of console programs and am wondering if/how I'd do this in Python.     ","Q_Votes":"61"},{"Q_Title":"Replace console output in Python","A_Content":"  Added a little bit more functionality to the example of Aravind Voggu:   def progressBar(name, value, endvalue, bar_length = 50, width = 20):          percent = float(value) / endvalue          arrow = '-' * int(round(percent*bar_length) - 1) + '>'          spaces = ' ' * (bar_length - len(arrow))          sys.stdout.write(\"\\r{0: <{1}} : [{2}]{3}%\".format(\\                          name, width, arrow + spaces, int(round(percent*100))))          sys.stdout.flush()          if value == endvalue:                       sys.stdout.write('\\n\\n')   Now you are able to generate multiple progressbars without replacing the once before.  I´ve also added name as a value with a fixed width.     For two loops and two times the use of progressBar() the result will look like:          ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/6169217/replace-console-output-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm wondering how I could create one of those nifty console counters in Python as in certain C/C++-programs.  I've got a loop doing things and the current output is along the lines of:  Doing thing 0 Doing thing 1 Doing thing 2 ...   what would be neater would be to just have the last line update;  X things done.   I've seen this in a number of console programs and am wondering if/how I'd do this in Python.     ","Q_Votes":"61"},{"Q_Title":"What is the equivalent of “none” in django templates?","A_Content":"  None, False and True all are available within template tags and filters. None, False, the empty string ('', \"\", \"\"\"\"\"\") and empty lists/tuples all evaluate to False when evaluated by if, so you can easily do  {% if profile.user.first_name == None %} {% if not profile.user.first_name %}   A hint: @fabiocerqueira is right, leave logic to models, limit templates to be the only presentation layer and calculate stuff like that in you model. An example:  # someapp/models.py class UserProfile(models.Model):     user = models.OneToOneField('auth.User')     # other fields      def get_full_name(self):         if not self.user.first_name:             return         return ' '.join([self.user.first_name, self.user.last_name])  # template {{ user.get_profile.get_full_name }}   Hope this helps :)     ","Language":"Python","Tags":["python","django","django-forms","django-templates","django-views"],"URL":"https://stackoverflow.com/questions/11945321/what-is-the-equivalent-of-none-in-django-templates","A_Votes":"87","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to see if a field/variable is none within a Django template. What is the correct syntax for that?  This is what I currently have:  {% if profile.user.first_name is null %}   <p> -- </p> {% elif %}   {{ profile.user.first_name }} {{ profile.user.last_name }} {% endif%}   In the example above, what would I use to replace \"null\"?     ","Q_Votes":"61"},{"Q_Title":"What is the equivalent of “none” in django templates?","A_Content":"  You can also use another built-in template default_if_none  {{ profile.user.first_name|default_if_none:\"--\" }}      ","Language":"Python","Tags":["python","django","django-forms","django-templates","django-views"],"URL":"https://stackoverflow.com/questions/11945321/what-is-the-equivalent-of-none-in-django-templates","A_Votes":"29","_type":"dict","isAccepted":"No","Q_Content":"    I want to see if a field/variable is none within a Django template. What is the correct syntax for that?  This is what I currently have:  {% if profile.user.first_name is null %}   <p> -- </p> {% elif %}   {{ profile.user.first_name }} {{ profile.user.last_name }} {% endif%}   In the example above, what would I use to replace \"null\"?     ","Q_Votes":"61"},{"Q_Title":"What is the equivalent of “none” in django templates?","A_Content":"  Look at the yesno helper  Eg:  {{ myValue|yesno:\"itwasTrue,itWasFalse,itWasNone\" }}      ","Language":"Python","Tags":["python","django","django-forms","django-templates","django-views"],"URL":"https://stackoverflow.com/questions/11945321/what-is-the-equivalent-of-none-in-django-templates","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I want to see if a field/variable is none within a Django template. What is the correct syntax for that?  This is what I currently have:  {% if profile.user.first_name is null %}   <p> -- </p> {% elif %}   {{ profile.user.first_name }} {{ profile.user.last_name }} {% endif%}   In the example above, what would I use to replace \"null\"?     ","Q_Votes":"61"},{"Q_Title":"What is the equivalent of “none” in django templates?","A_Content":"  {% if profile.user.first_name %} works (assuming you also don't want to accept '').  if in Python in general treats None, False, '', [], {}, ... all as false.     ","Language":"Python","Tags":["python","django","django-forms","django-templates","django-views"],"URL":"https://stackoverflow.com/questions/11945321/what-is-the-equivalent-of-none-in-django-templates","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I want to see if a field/variable is none within a Django template. What is the correct syntax for that?  This is what I currently have:  {% if profile.user.first_name is null %}   <p> -- </p> {% elif %}   {{ profile.user.first_name }} {{ profile.user.last_name }} {% endif%}   In the example above, what would I use to replace \"null\"?     ","Q_Votes":"61"},{"Q_Title":"What is the equivalent of “none” in django templates?","A_Content":"  You can also use the built-in template filter default:  If value evaluates to False (e.g. None, an empty string, 0, False); the default \"--\" is displayed.  {{ profile.user.first_name|default:\"--\" }}   Documentation: https://docs.djangoproject.com/en/dev/ref/templates/builtins/#default     ","Language":"Python","Tags":["python","django","django-forms","django-templates","django-views"],"URL":"https://stackoverflow.com/questions/11945321/what-is-the-equivalent-of-none-in-django-templates","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I want to see if a field/variable is none within a Django template. What is the correct syntax for that?  This is what I currently have:  {% if profile.user.first_name is null %}   <p> -- </p> {% elif %}   {{ profile.user.first_name }} {{ profile.user.last_name }} {% endif%}   In the example above, what would I use to replace \"null\"?     ","Q_Votes":"61"},{"Q_Title":"What is the equivalent of “none” in django templates?","A_Content":"  You don't need do this 'if', use: {{ profile.user.get_full_name }}     ","Language":"Python","Tags":["python","django","django-forms","django-templates","django-views"],"URL":"https://stackoverflow.com/questions/11945321/what-is-the-equivalent-of-none-in-django-templates","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want to see if a field/variable is none within a Django template. What is the correct syntax for that?  This is what I currently have:  {% if profile.user.first_name is null %}   <p> -- </p> {% elif %}   {{ profile.user.first_name }} {{ profile.user.last_name }} {% endif%}   In the example above, what would I use to replace \"null\"?     ","Q_Votes":"61"},{"Q_Title":"What is the equivalent of “none” in django templates?","A_Content":"  isoperator : New in Django 1.10  {% if somevar is None %}   This appears if somevar is None, or if somevar is not found in the context. {% endif %}      ","Language":"Python","Tags":["python","django","django-forms","django-templates","django-views"],"URL":"https://stackoverflow.com/questions/11945321/what-is-the-equivalent-of-none-in-django-templates","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want to see if a field/variable is none within a Django template. What is the correct syntax for that?  This is what I currently have:  {% if profile.user.first_name is null %}   <p> -- </p> {% elif %}   {{ profile.user.first_name }} {{ profile.user.last_name }} {% endif%}   In the example above, what would I use to replace \"null\"?     ","Q_Votes":"61"},{"Q_Title":"How to get UTC time in Python?","A_Content":"  Try this code that uses datetime.utcnow():  from datetime import datetime datetime.utcnow()   For your purposes when you need to calculate an amount of time spent between two dates all that you need is to substract end and start dates. The results of such substraction is a timedelta object.  From the python docs:  class datetime.timedelta([days[, seconds[, microseconds[, milliseconds[, minutes[, hours[, weeks]]]]]]])   And this means that by default you can get any of the fields mentioned in it's definition -  days, seconds, microseconds, milliseconds, minutes, hours, weeks. Also timedelta instance has total_seconds() method that:     Return the total number of seconds contained in the duration.   Equivalent to (td.microseconds + (td.seconds + td.days * 24 * 3600) *   10*6) / 10*6 computed with true division enabled.      ","Language":"Python","Tags":["python","datetime"],"URL":"https://stackoverflow.com/questions/15940280/how-to-get-utc-time-in-python","A_Votes":"103","_type":"dict","isAccepted":"No","Q_Content":"    I've search a bunch on StackExchange for a solution but nothing does quite what I need.  In JavaScript, I'm using the following to calculate UTC time since Jan 1st 1970:  function UtcNow() {     var now = new Date();     var utc = Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), now.getUTCDate(), now.getUTCHours(), now.getUTCMinutes(), now.getUTCSeconds(), now.getUTCMilliseconds());     return utc; }   What would be the equivalent Python code?     ","Q_Votes":"61"},{"Q_Title":"How to get UTC time in Python?","A_Content":"  In the form closest to your original:  import datetime  def UtcNow():     now = datetime.datetime.utcnow()     return now   If you need to know the number of seconds from 1970-01-01 rather than a native Python datetime, use this instead:  return (now - datetime.datetime(1970, 1, 1)).total_seconds()   Python has naming conventions that are at odds with what you might be used to in Javascript, see PEP 8. Also, a function that simply returns the result of another function is rather silly; if it's just a matter of making it more accessible, you can create another name for a function by simply assigning it. The first example above could be replaced with:  utc_now = datetime.datetime.utcnow      ","Language":"Python","Tags":["python","datetime"],"URL":"https://stackoverflow.com/questions/15940280/how-to-get-utc-time-in-python","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I've search a bunch on StackExchange for a solution but nothing does quite what I need.  In JavaScript, I'm using the following to calculate UTC time since Jan 1st 1970:  function UtcNow() {     var now = new Date();     var utc = Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), now.getUTCDate(), now.getUTCHours(), now.getUTCMinutes(), now.getUTCSeconds(), now.getUTCMilliseconds());     return utc; }   What would be the equivalent Python code?     ","Q_Votes":"61"},{"Q_Title":"How to get UTC time in Python?","A_Content":"  From datetime.datetime you already can export to timestamps with method strftime. Following your function example:  import datetime def UtcNow():     now = datetime.datetime.utcnow()     return int(now.strftime(\"%s\"))   If you want microseconds, you need to change the export string and cast to float like: return float(now.strftime(\"%s.%f\"))         ","Language":"Python","Tags":["python","datetime"],"URL":"https://stackoverflow.com/questions/15940280/how-to-get-utc-time-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I've search a bunch on StackExchange for a solution but nothing does quite what I need.  In JavaScript, I'm using the following to calculate UTC time since Jan 1st 1970:  function UtcNow() {     var now = new Date();     var utc = Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), now.getUTCDate(), now.getUTCHours(), now.getUTCMinutes(), now.getUTCSeconds(), now.getUTCMilliseconds());     return utc; }   What would be the equivalent Python code?     ","Q_Votes":"61"},{"Q_Title":"How to get UTC time in Python?","A_Content":"  import datetime import pytz  # datetime object with timezone awareness: datetime.datetime.now(tz=pytz.utc)  # seconds from epoch: datetime.datetime.now(tz=pytz.utc).timestamp()   # ms from epoch: int(datetime.datetime.now(tz=pytz.utc).timestamp() * 1000)       ","Language":"Python","Tags":["python","datetime"],"URL":"https://stackoverflow.com/questions/15940280/how-to-get-utc-time-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I've search a bunch on StackExchange for a solution but nothing does quite what I need.  In JavaScript, I'm using the following to calculate UTC time since Jan 1st 1970:  function UtcNow() {     var now = new Date();     var utc = Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), now.getUTCDate(), now.getUTCHours(), now.getUTCMinutes(), now.getUTCSeconds(), now.getUTCMilliseconds());     return utc; }   What would be the equivalent Python code?     ","Q_Votes":"61"},{"Q_Title":"python: getting only 1 decimal place [duplicate]","A_Content":"  Are you trying to represent it with only one digit:  print \"%.1f\" % number   or actually round off the other decimal places?  round(number,1)   or even round strictly down?  math.floor(number*10)/10      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3400965/python-getting-only-1-decimal-place","A_Votes":"111","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              Limiting floats to two decimal points                                        19 answers                                          How do I convert 45.34531 to 45.3?     ","Q_Votes":"61"},{"Q_Title":"python: getting only 1 decimal place [duplicate]","A_Content":"  >>> \"{0:0.1f}\".format(45.34531) '45.3'   Or use the builtin round:  >>> round(45.34531, 1) 45.299999999999997      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3400965/python-getting-only-1-decimal-place","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Limiting floats to two decimal points                                        19 answers                                          How do I convert 45.34531 to 45.3?     ","Q_Votes":"61"},{"Q_Title":"python: getting only 1 decimal place [duplicate]","A_Content":"  round(number, 1)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/3400965/python-getting-only-1-decimal-place","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              Limiting floats to two decimal points                                        19 answers                                          How do I convert 45.34531 to 45.3?     ","Q_Votes":"61"},{"Q_Title":"Move an item inside a list?","A_Content":"  Use the insert method of a list:  l = list(...) l.insert(index, item)   Alternatively, you can use a slice notation:  l[index:index] = [item]   If you want to move an item that's already in the list to the specified position, you would have to delete it and insert it at the new position:  l.insert(newindex, l.pop(oldindex))      ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/3173154/move-an-item-inside-a-list","A_Votes":"101","_type":"dict","isAccepted":"Yes","Q_Content":"    In Python, how do I move an item to a definite index in a list?     ","Q_Votes":"61"},{"Q_Title":"Move an item inside a list?","A_Content":"  A slightly shorter solution, that only moves the item to the end, not anywhere is this:  l += [l.pop(0)]   For example:  >>> l = [1,2,3,4,5] >>> l += [l.pop(0)] >>> l [2, 3, 4, 5, 1]      ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/3173154/move-an-item-inside-a-list","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do I move an item to a definite index in a list?     ","Q_Votes":"61"},{"Q_Title":"Move an item inside a list?","A_Content":"  If you don't know the position of the item, you may need to find the index first:  old_index = list1.index(item)   then move it:  list1.insert(new_index, list1.pop(old_index))   or IMHO a cleaner way:  try:   list1.remove(item)   list1.insert(new_index, item) except ValueError:   pass      ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/3173154/move-an-item-inside-a-list","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do I move an item to a definite index in a list?     ","Q_Votes":"61"},{"Q_Title":"Move an item inside a list?","A_Content":"  A solution very simple, but you have to know the index of the original position and the index of the new position:  list1[index1],list1[index2]=list1[index2],list1[index1]      ","Language":"Python","Tags":["python","list"],"URL":"https://stackoverflow.com/questions/3173154/move-an-item-inside-a-list","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    In Python, how do I move an item to a definite index in a list?     ","Q_Votes":"61"},{"Q_Title":"ValueError: unsupported pickle protocol: 3, python2 pickle can not load the file dumped by python 3 pickle?","A_Content":"  You should write the pickled data with a lower protocol number in Python 3. Python 3 introduced a new protocol with the number 3 (and uses it as default), so switch back to a value of 2 which can be read by Python 2.  Check the protocolparameter in pickle.dump. Your resulting code will look like this.  pickle.dump(your_object, your_file, protocol=2)   There is no protocolparameter in pickle.load because pickle can determine the protocol from the file.     ","Language":"Python","Tags":["python","python-2.7","python-3.x","pickle"],"URL":"https://stackoverflow.com/questions/25843698/valueerror-unsupported-pickle-protocol-3-python2-pickle-can-not-load-the-file","A_Votes":"97","_type":"dict","isAccepted":"Yes","Q_Content":"    I use pickle to dump a file on python 3, and I use pickle to load the file on python 2, the ValueError appears.   So, python 2 pickle can not load the file dumped by python 3 pickle?  If I want it? How to do?     ","Q_Votes":"61"},{"Q_Title":"ValueError: unsupported pickle protocol: 3, python2 pickle can not load the file dumped by python 3 pickle?","A_Content":"  Pickle uses different protocols to convert your data to a binary stream.   In python 2 there are 3 different protocols (0, 1, 2) and the default is 0. In python 3 there are 5 different protocols (0, 1, 2, 3, 4) and the default is 3.   You must specify in python 3 a protocol lower than 3 in order to be able to load the data in python 2. You can specify the protocol parameter when invoking pickle.dump.     ","Language":"Python","Tags":["python","python-2.7","python-3.x","pickle"],"URL":"https://stackoverflow.com/questions/25843698/valueerror-unsupported-pickle-protocol-3-python2-pickle-can-not-load-the-file","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    I use pickle to dump a file on python 3, and I use pickle to load the file on python 2, the ValueError appears.   So, python 2 pickle can not load the file dumped by python 3 pickle?  If I want it? How to do?     ","Q_Votes":"61"},{"Q_Title":"How to add a constant column in a Spark DataFrame?","A_Content":"  Spark 2.2+  Spark 2.2 introduces typedLit to support  Seq, Map, and Tuples (SPARK-19254) and following calls should be supported (Scala):  import org.apache.spark.sql.functions.typedLit  df.withColumn(\"some_array\", typedLit(Seq(1, 2, 3))) df.withColumn(\"some_struct\", typedLit((\"foo\", 1, .0.3))) df.withColumn(\"some_map\", typedLit(Map(\"key1\" -> 1, \"key2\" -> 2)))   Spark 1.3+ (lit), 1.4+ (array, struct), 2.0+ (map):  The second argument for DataFrame.withColumn should be a Column so you have to use a literal:  from pyspark.sql.functions import lit  df.withColumn('new_column', lit(10))   If you need complex columns you can build these using blocks like array:  from pyspark.sql.functions import array, create_map, struct  df.withColumn(\"some_array\", array(lit(1), lit(2), lit(3))) df.withColumn(\"some_struct\", struct(lit(\"foo\"), lit(1), lit(.3))) df.withColumn(\"some_map\", create_map(lit(\"key1\"), lit(1), lit(\"key2\"), lit(2)))   Exactly the same methods can be used in Scala.  import org.apache.spark.sql.functions.{array, lit, map, struct}  df.withColumn(\"new_column\", lit(10)) df.withColumn(\"map\", map(lit(\"key1\"), lit(1), lit(\"key2\"), lit(2)))   It is also possible, although slower, to use an UDF.     ","Language":"Python","Tags":["python","apache-spark","dataframe","pyspark","spark-dataframe"],"URL":"https://stackoverflow.com/questions/32788322/how-to-add-a-constant-column-in-a-spark-dataframe","A_Votes":"130","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to add a column in a DataFrame with some arbitrary value (that is the same for each row). I get an error when I use withColumn as follows:  dt.withColumn('new_column', 10).head(5)  --------------------------------------------------------------------------- AttributeError                            Traceback (most recent call last) <ipython-input-50-a6d0257ca2be> in <module>()       1 dt = (messages       2     .select(messages.fromuserid, messages.messagetype, floor(messages.datetime/(1000*60*5)).alias(\"dt\"))) ----> 3 dt.withColumn('new_column', 10).head(5)  /Users/evanzamir/spark-1.4.1/python/pyspark/sql/dataframe.pyc in withColumn(self, colName, col)    1166         [Row(age=2, name=u'Alice', age2=4), Row(age=5, name=u'Bob', age2=7)]    1167         \"\"\" -> 1168         return self.select('*', col.alias(colName))    1169     1170     @ignore_unicode_prefix  AttributeError: 'int' object has no attribute 'alias'   It seems that I can trick the function into working as I want by adding and subtracting one of the other columns (so they add to zero) and then adding the number I want (10 in this case):  dt.withColumn('new_column', dt.messagetype - dt.messagetype + 10).head(5)  [Row(fromuserid=425, messagetype=1, dt=4809600.0, new_column=10),  Row(fromuserid=47019141, messagetype=1, dt=4809600.0, new_column=10),  Row(fromuserid=49746356, messagetype=1, dt=4809600.0, new_column=10),  Row(fromuserid=93506471, messagetype=1, dt=4809600.0, new_column=10),  Row(fromuserid=80488242, messagetype=1, dt=4809600.0, new_column=10)]   This is supremely hacky, right? I assume there is a more legit way to do this?     ","Q_Votes":"61"},{"Q_Title":"How to add a constant column in a Spark DataFrame?","A_Content":"  In spark 2.2 there are two ways to add constant value in a column in DataFrame:   1) Using lit   2) Using typedLit.   The difference between the two is that typedLit can also handle parameterized scala types e.g. List, Seq, and Map  Sample DataFrame:  val df = spark.createDataFrame(Seq((0,\"a\"),(1,\"b\"),(2,\"c\"))).toDF(\"id\", \"col1\")  +---+----+ | id|col1| +---+----+ |  0|   a| |  1|   b| +---+----+   1) Using lit: Adding constant string value in new column named newcol:  import org.apache.spark.sql.functions.lit val newdf = df.withColumn(\"newcol\",lit(\"myval\"))   Result:  +---+----+------+ | id|col1|newcol| +---+----+------+ |  0|   a| myval| |  1|   b| myval| +---+----+------+   2) Using typedLit:  import org.apache.spark.sql.functions.typedLit df.withColumn(\"newcol\", typedLit((\"sample\", 10, .044)))   Result:  +---+----+-----------------+ | id|col1|           newcol| +---+----+-----------------+ |  0|   a|[sample,10,0.044]| |  1|   b|[sample,10,0.044]| |  2|   c|[sample,10,0.044]| +---+----+-----------------+      ","Language":"Python","Tags":["python","apache-spark","dataframe","pyspark","spark-dataframe"],"URL":"https://stackoverflow.com/questions/32788322/how-to-add-a-constant-column-in-a-spark-dataframe","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I want to add a column in a DataFrame with some arbitrary value (that is the same for each row). I get an error when I use withColumn as follows:  dt.withColumn('new_column', 10).head(5)  --------------------------------------------------------------------------- AttributeError                            Traceback (most recent call last) <ipython-input-50-a6d0257ca2be> in <module>()       1 dt = (messages       2     .select(messages.fromuserid, messages.messagetype, floor(messages.datetime/(1000*60*5)).alias(\"dt\"))) ----> 3 dt.withColumn('new_column', 10).head(5)  /Users/evanzamir/spark-1.4.1/python/pyspark/sql/dataframe.pyc in withColumn(self, colName, col)    1166         [Row(age=2, name=u'Alice', age2=4), Row(age=5, name=u'Bob', age2=7)]    1167         \"\"\" -> 1168         return self.select('*', col.alias(colName))    1169     1170     @ignore_unicode_prefix  AttributeError: 'int' object has no attribute 'alias'   It seems that I can trick the function into working as I want by adding and subtracting one of the other columns (so they add to zero) and then adding the number I want (10 in this case):  dt.withColumn('new_column', dt.messagetype - dt.messagetype + 10).head(5)  [Row(fromuserid=425, messagetype=1, dt=4809600.0, new_column=10),  Row(fromuserid=47019141, messagetype=1, dt=4809600.0, new_column=10),  Row(fromuserid=49746356, messagetype=1, dt=4809600.0, new_column=10),  Row(fromuserid=93506471, messagetype=1, dt=4809600.0, new_column=10),  Row(fromuserid=80488242, messagetype=1, dt=4809600.0, new_column=10)]   This is supremely hacky, right? I assume there is a more legit way to do this?     ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  Some rules of thumb for subprocess.   Never use shell=True. It needlessly invokes an extra shell process to call your program. When calling processes, arguments are passed around as lists. sys.argv in python is a list, and so is argv in C. So you pass a list to Popen to call subprocesses, not a string. Don't redirect stderr to a PIPE when you're not reading it.  Don't redirect stdin when you're not writing to it.   Example:  import subprocess, time, os, sys cmd = [\"rsync.exe\", \"-vaz\", \"-P\", \"source/\" ,\"dest/\"]  p = subprocess.Popen(cmd,                      stdout=subprocess.PIPE,                      stderr=subprocess.STDOUT)  for line in iter(p.stdout.readline, b''):     print(\">>> \" + line.rstrip())   That said, it is probable that rsync buffers its output when it detects that it is connected to a pipe instead of a terminal. This is the default behavior - when connected to a pipe, programs must explicitly flush stdout for realtime results, otherwise standard C library will buffer.  To test for that, try running this instead:  cmd = [sys.executable, 'test_out.py']   and create a test_out.py file with the contents:  import sys import time print (\"Hello\") sys.stdout.flush() time.sleep(10) print (\"World\")   Executing that subprocess should give you \"Hello\" and wait 10 seconds before giving \"World\". If that happens with the python code above and not with rsync, that means rsync itself is buffering output, so you are out of luck.  A solution would be to connect direct to a pty, using something like pexpect.     ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"77","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  I know this is an old topic, but there is a solution now. Call the rsync with option --outbuf=L. Example:  cmd=['rsync', '-arzv','--backup','--outbuf=L','source/','dest'] p = subprocess.Popen(cmd,                      stdout=subprocess.PIPE) for line in iter(p.stdout.readline, b''):     print '>>> {}'.format(line.rstrip())      ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"25","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  On Linux, I had the same problem of getting rid of the buffering.  I finally used \"stdbuf -o0\" (or, unbuffer from expect) to get rid of the PIPE buffering.  proc = Popen(['stdbuf', '-o0'] + cmd, stdout=PIPE, stderr=PIPE) stdout = proc.stdout   I could then use select.select on stdout.  See also https://unix.stackexchange.com/questions/25372/     ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  You cannot get stdout to print unbuffered to a pipe (unless you can rewrite the program that prints to stdout), so here is my solution:  Redirect stdout to sterr, which is not buffered.  '<cmd> 1>&2' should do it.  Open the process as follows: myproc = subprocess.Popen('<cmd> 1>&2', stderr=subprocess.PIPE) You cannot distinguish from stdout or stderr, but you get all output immediately.  Hope this helps anyone tackling this problem.     ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  for line in p.stdout:   ...   always blocks until the next line-feed.  For \"real-time\" behaviour you have to do something like this:  while True:   inchar = p.stdout.read(1)   if inchar: #neither empty string nor None     print(str(inchar), end='') #or end=None to flush immediately   else:     print('') #flush for implicit line-buffering     break   The while-loop is left when the child process closes its stdout or exits. read()/read(-1) would block until the child process closed its stdout or exited.     ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  Your problem is:  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()   the iterator itself has extra buffering.  Try doing like this:  while True:   line = p.stdout.readline()   if not line:      break   print line      ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  Change the stdout from the rsync process to be unbuffered.  p = subprocess.Popen(cmd,                      shell=True,                      bufsize=0,  # 0=unbuffered, 1=line-buffered, else buffer-size                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)      ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"      p = subprocess.Popen(command,                                 bufsize=0,                                 universal_newlines=True)   I am writing a GUI for rsync in python, and have the same probelms. This problem has troubled me for several days until i find this in pyDoc.     If universal_newlines is True, the file objects stdout and stderr are opened as text files in universal newlines mode. Lines may be terminated by any of '\\n', the Unix end-of-line convention, '\\r', the old Macintosh convention or '\\r\\n', the Windows convention. All of these external representations are seen as '\\n' by the Python program.   It seems that rsync will output '\\r' when translate is going on.     ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  To avoid caching of output you might wanna try pexpect,   child = pexpect.spawn(launchcmd,args,timeout=None) while True:     try:         child.expect('\\n')         print(child.before)     except pexpect.EOF:         break   PS : I know this question is pretty old, still providing the solution which worked for me.  PPS: got this answer from another question     ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  I've noticed that there is no mention of using a temporary file as intermediate.  The following gets around the buffering issues by outputting to a temporary file and allows you to parse the data coming from rsync without connecting to a pty.  I tested the following on a linux box, and the output of rsync tends to differ across platforms, so the regular expressions to parse the output may vary:  import subprocess, time, tempfile, re  pipe_output, file_name = tempfile.TemporaryFile() cmd = [\"rsync\", \"-vaz\", \"-P\", \"/src/\" ,\"/dest\"]  p = subprocess.Popen(cmd, stdout=pipe_output,                       stderr=subprocess.STDOUT) while p.poll() is None:     # p.poll() returns None while the program is still running     # sleep for 1 second     time.sleep(1)     last_line =  open(file_name).readlines()     # it's possible that it hasn't output yet, so continue     if len(last_line) == 0: continue     last_line = last_line[-1]     # Matching to \"[bytes downloaded]  number%  [speed] number:number:number\"     match_it = re.match(\".* ([0-9]*)%.* ([0-9]*:[0-9]*:[0-9]*).*\", last_line)     if not match_it: continue     # in this case, the percentage is stored in match_it.group(1),      # time in match_it.group(2).  We could do something with it here...      ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"catching stdout in realtime from subprocess","A_Content":"  Use | tee to redirect the stdout to a file named out.txt while displaying stdout in realtime on terminal  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/ | tee out.txt\"  p, line = True, 'start'  p = subprocess.Popen(cmd,                  shell=True)  p.wait()   You can get the stdout from the file out.txt after subprocess.  # Get stdout from file out.txt f = open('out.txt') out = f.read() f.close()      ","Language":"Python","Tags":["python","subprocess","stdout"],"URL":"https://stackoverflow.com/questions/1606795/catching-stdout-in-realtime-from-subprocess","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to subprocess.Popen() rsync.exe in Windows, and print the stdout in Python.  My code works, but it doesn't catch the progress until a file transfer is done! I want to print the progress for each file in real time.  Using Python 3.1 now since I heard it should be better at handling IO.  import subprocess, time, os, sys  cmd = \"rsync.exe -vaz -P source/ dest/\" p, line = True, 'start'   p = subprocess.Popen(cmd,                      shell=True,                      bufsize=64,                      stdin=subprocess.PIPE,                      stderr=subprocess.PIPE,                      stdout=subprocess.PIPE)  for line in p.stdout:     print(\">>> \" + str(line.rstrip()))     p.stdout.flush()      ","Q_Votes":"61"},{"Q_Title":"Django: Model Form “object has no attribute 'cleaned_data'”","A_Content":"  For some reason, you're re-instantiating the form after you check is_valid(). Forms only get a cleaned_data attribute when is_valid() has been called, and you haven't called it on this new, second instance.  Just get rid of the second form = SearchForm(request.POST) and all should be well.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/4308527/django-model-form-object-has-no-attribute-cleaned-data","A_Votes":"132","_type":"dict","isAccepted":"Yes","Q_Content":"    I am trying to make a search form for one of my classes. The model of the form is:  from django import forms from django.forms import CharField, ModelMultipleChoiceField, ModelChoiceField from books.models import Book, Author, Category  class SearchForm(forms.ModelForm):     authors = ModelMultipleChoiceField(queryset=Author.objects.all(),required=False)         category = ModelChoiceField (queryset=Category.objects.all(),required=False)     class Meta:         model = Book         fields = [\"title\"]   And the view I'm using is:  from django.shortcuts import render_to_response, redirect, get_object_or_404 from django.template import RequestContext from books.models import Book,Author from books.forms import BookForm, SearchForm from users.models import User  def search_book(request):     if request.method == \"POST\":         form = SearchForm(request.POST)         if form.is_valid():             form = SearchForm(request.POST)             stitle = form.cleaned_data['title']             sauthor = form.cleaned_data['author']             scategory = form.cleaned_data['category']     else:         form = SearchForm()     return render_to_response(\"books/create.html\", {         \"form\": form,     }, context_instance=RequestContext(request))   The form shows up fine, but when I submit it I get an error: 'SearchForm' object has no attribute 'cleaned_data'  I'm not sure what's going on, can someone help me out? Thanks!     ","Q_Votes":"61"},{"Q_Title":"Django: Model Form “object has no attribute 'cleaned_data'”","A_Content":"  I would write the code like this:  def search_book(request):     form = SearchForm(request.POST or None)     if request.method == \"POST\" and form.is_valid():         stitle = form.cleaned_data['title']         sauthor = form.cleaned_data['author']         scategory = form.cleaned_data['category']         return HttpResponseRedirect('/thanks/')     return render_to_response(\"books/create.html\", {         \"form\": form,     }, context_instance=RequestContext(request))   Pretty much like the documentation.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/4308527/django-model-form-object-has-no-attribute-cleaned-data","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to make a search form for one of my classes. The model of the form is:  from django import forms from django.forms import CharField, ModelMultipleChoiceField, ModelChoiceField from books.models import Book, Author, Category  class SearchForm(forms.ModelForm):     authors = ModelMultipleChoiceField(queryset=Author.objects.all(),required=False)         category = ModelChoiceField (queryset=Category.objects.all(),required=False)     class Meta:         model = Book         fields = [\"title\"]   And the view I'm using is:  from django.shortcuts import render_to_response, redirect, get_object_or_404 from django.template import RequestContext from books.models import Book,Author from books.forms import BookForm, SearchForm from users.models import User  def search_book(request):     if request.method == \"POST\":         form = SearchForm(request.POST)         if form.is_valid():             form = SearchForm(request.POST)             stitle = form.cleaned_data['title']             sauthor = form.cleaned_data['author']             scategory = form.cleaned_data['category']     else:         form = SearchForm()     return render_to_response(\"books/create.html\", {         \"form\": form,     }, context_instance=RequestContext(request))   The form shows up fine, but when I submit it I get an error: 'SearchForm' object has no attribute 'cleaned_data'  I'm not sure what's going on, can someone help me out? Thanks!     ","Q_Votes":"61"},{"Q_Title":"Django: Model Form “object has no attribute 'cleaned_data'”","A_Content":"  At times,  if we forget the  return self.cleaned_data    in the clean function of django forms, we will not have any data though the form.is_valid() will return True.     ","Language":"Python","Tags":["python","django","django-forms"],"URL":"https://stackoverflow.com/questions/4308527/django-model-form-object-has-no-attribute-cleaned-data","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am trying to make a search form for one of my classes. The model of the form is:  from django import forms from django.forms import CharField, ModelMultipleChoiceField, ModelChoiceField from books.models import Book, Author, Category  class SearchForm(forms.ModelForm):     authors = ModelMultipleChoiceField(queryset=Author.objects.all(),required=False)         category = ModelChoiceField (queryset=Category.objects.all(),required=False)     class Meta:         model = Book         fields = [\"title\"]   And the view I'm using is:  from django.shortcuts import render_to_response, redirect, get_object_or_404 from django.template import RequestContext from books.models import Book,Author from books.forms import BookForm, SearchForm from users.models import User  def search_book(request):     if request.method == \"POST\":         form = SearchForm(request.POST)         if form.is_valid():             form = SearchForm(request.POST)             stitle = form.cleaned_data['title']             sauthor = form.cleaned_data['author']             scategory = form.cleaned_data['category']     else:         form = SearchForm()     return render_to_response(\"books/create.html\", {         \"form\": form,     }, context_instance=RequestContext(request))   The form shows up fine, but when I submit it I get an error: 'SearchForm' object has no attribute 'cleaned_data'  I'm not sure what's going on, can someone help me out? Thanks!     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  In ruby, system('git rev-parse') will return true if the current directory is in a git repo, and false otherwise.  I imagine the pythonic equivalent should work similarly.  EDIT: Sure enough:  # in a git repo, running ipython >>> system('git rev-parse') 0  # not in a git repo >>> system('git rev-parse') 32768   Note that there is some output on STDERR when you aren't in a repo, if that matters to you.     ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"42","_type":"dict","isAccepted":"Yes","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  Just found this in git help rev-parse  git rev-parse --is-inside-work-tree   prints true if it is in the work tree, false if it's in the '.git' tree, and fatal error if it's neither. Both 'true' and 'false' are printed on stdout with an exit status of 0, the fatal error is printed on stderr with an exit status of 128.     ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"80","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  With gitpython, you can make a function like this:  import git  ...  def is_git_repo(path):     try:         _ = git.Repo(path).git_dir         return True     except git.exc.InvalidGitRepositoryError:         return False      ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  Well, the directory can also be ignored by the .gitignore file - so you need to check for a .git repository, and if there is one, parse the .gitignore to see whether that directory is indeed in the git repository.  What exactly do you want to do? There may be a simpler way to do this.  EDIT: Do you mean \"Is this directory the root of a GIT repository\" or, do you mean \"Is this directory part of a GIT repository\" ?  For the first one, then just check if there is a .git -- since that's at the root, and you're done. For the second one, once you've determined that you're inside a GIT repository, you need to check .gitignore for the subdirectory in question.     ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  For the record, use git status or similar, this is just for completeness: :)  Searching upward a tree is no biggie really, in bash you can do this simple one-liner (if you put it on one line...) ;) Returns 0 if one is found, 1 otherwise.  d=`pwd` while [ \"$d\" != \"\" ]; do   [ -d \"$d\"/.git ] && exit 0   d=${d%/*} done exit 1   will search upward looking for a .git folder.     ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  It is hard to define what a .git/ repository is  I did a bit of experimenting to see what Git considers as a Git repository.  As of 1.9.1, the minimal directory structure that must be inside a .git directory for Git to consider it is:  mkdir objects refs printf 'ref: refs/' > HEAD   as recognized by rev-parse.  It is also obviously a corrupt repository in which most useful commands will fail.  The morale is: like any other format detection, false positives are inevitable, specially here that the minimal repo is so simple.  If you want something robust, instead of detecting if it is a Git repo, try to do whatever you want to do, and raise errors and deal with them if it fails.     It's easier to ask forgiveness than it is to get permission.      ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  From git help rev-parse again, I think you can do something like :   git rev-parse --resolve-git-dir <directory>    and check if the command returns the directory path itself. According to the manual git rev-parse returns the path to the directory if the argument contains a git repo or is a file which contains the path to a git repo.     ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  Add this to your .bash_profile, and your prompt will always show the active git branch and whether you have uncommitted changes.  function parse_git_dirty {   [[ $(git status 2> /dev/null | tail -n1) != \"nothing to commit (working directory clean)\" ]] && echo \"*\" } function parse_git_branch {   git branch --no-color 2> /dev/null | sed -e '/^[^*]/d' -e \"s/* \\(.*\\)/[\\1$(parse_git_dirty)]/\" }  export PS1=' \\[\\033[0;33m\\]\\w\\[\\033[00m\\]\\[\\033[01;00m\\]$(parse_git_branch): ' #PS1='\\w> '   You'll see this:   ~:   ~: cd code/scala-plugin/  ~/code/scala-plugin[master*]:       ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  If you'd prefer to look for a .gitdirectory, here's a cute way of doing that in Ruby:  require 'pathname'  def gitcheck()   Pathname.pwd.ascend {|p| return true if (p + \".git\").directory? }   false end   I'm unable to find something similar to ascend in Python.      ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"Determine if directory is under git control","A_Content":"  Using git rev-parse --is-inside-work-tree along with subprocess.Popen, you can check if \"true\" is printed from the output indicating the directory does have a git repo:  import subprocess  repo_dir = \"../path/to/check/\"   command = ['git', 'rev-parse', '--is-inside-work-tree'] process = subprocess.Popen(command, stdout=subprocess.PIPE, cwd=repo_dir,                            universal_newlines=True) process_output = process.communicate()[0]  is_git_repo = str(process_output.strip())  if is_git_repo == \"true\":     print(\"success! git repo found under {0}\".format(repo_dir)) else:     print(\"sorry. no git repo found under {0}\".format(repo_dir))      ","Language":"Python","Tags":["python","git"],"URL":"https://stackoverflow.com/questions/2044574/determine-if-directory-is-under-git-control","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How can I tell if a given directory is part of a git respository?  (The following is in python, but bash or something would be fine.)  os.path.isdir('.svn')   will tell you if the current directory is controlled by Subversion. Mercurial and Git just have a .hg/.git at the top of the repository, so for hg I can use  os.system('hg -q stat 2> /dev/null > /dev/null') == 0)   but git status returns a nonzero (error) exit status if nothing's changed.  Is iterating up the path looking for .git myself the best I can do?     ","Q_Votes":"61"},{"Q_Title":"How to reload modules in django shell?","A_Content":"  I recommend using the django-extensions project like stated above by dongweiming. But instead of just 'shell_plus' management command, use:  manage.py shell_plus --notebook   This will open a IPython notebook on your web browser. Write your code there in a cell, your imports etc. and run it.   When you change your modules, just click the notebook menu item 'Kernel->Restart'  There you go, your code is now using your modified modules.     ","Language":"Python","Tags":["python","django","ipython"],"URL":"https://stackoverflow.com/questions/3772260/how-to-reload-modules-in-django-shell","A_Votes":"22","_type":"dict","isAccepted":"Yes","Q_Content":"    I am working with Django and use Django shell all the time. The annoying part is that while the Django server reloads on code changes, the shell does not, so every time I make a change to a method I am testing, I need to quit the shell and restart it, re-import all the modules I need, reinitialize all the variables I need etc. While iPython history saves a lot of typing on this, this is still a pain. Is there a way to make django shell auto-reload, the same way django development server does?  I know about reload(), but I import a lot of models and generally use from app.models import * syntax, so reload() is not much help.     ","Q_Votes":"61"},{"Q_Title":"How to reload modules in django shell?","A_Content":"  look at the manage.py shell_plus command provided by the django-extensions project. It will load all your model files on shell startup. and autoreload your any modify but do not need exit, you can direct call there     ","Language":"Python","Tags":["python","django","ipython"],"URL":"https://stackoverflow.com/questions/3772260/how-to-reload-modules-in-django-shell","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    I am working with Django and use Django shell all the time. The annoying part is that while the Django server reloads on code changes, the shell does not, so every time I make a change to a method I am testing, I need to quit the shell and restart it, re-import all the modules I need, reinitialize all the variables I need etc. While iPython history saves a lot of typing on this, this is still a pain. Is there a way to make django shell auto-reload, the same way django development server does?  I know about reload(), but I import a lot of models and generally use from app.models import * syntax, so reload() is not much help.     ","Q_Votes":"61"},{"Q_Title":"How to reload modules in django shell?","A_Content":"  I'd suggest use IPython autoreload extension.  ./manage.py shell  In [1]: %load_ext autoreload In [2]: %autoreload 2   And from now all imported modules would be refreshed before evaluate.  In [3]: from x import print_something In [4]: print_something() Out[4]: 'Something'   # Do changes in print_something method in x.py file.  In [5]: print_something() Out[5]: 'Something else'   Works also if something was imported before %load_ext autoreload command.  ./manage.py shell In [1]: from x import print_something In [2]: print_something() Out[2]: 'Something'   # Do changes in print_something method in x.py file.  In [3]: %load_ext autoreload In [4]: %autoreload 2 In [5]: print_something() Out[5]: 'Something else'   There is possible also prevent some imports from refreshing with %aimport command and 3 autoreload strategies:     %autoreload         Reload all modules (except those excluded by %aimport) automatically   now.          %autoreload 0         Disable automatic reloading.          %autoreload 1         Reload all modules imported with %aimport every time before executing   the Python code typed.          %autoreload 2         Reload all modules (except those excluded by %aimport) every time   before executing the Python code typed.          %aimport         List modules which are to be automatically imported or not to be   imported.          %aimport foo         Import module ‘foo’ and mark it to be autoreloaded for %autoreload 1         %aimport -foo         Mark module ‘foo’ to not be autoreloaded.      This generally works good for my use, but there are some cavetas:        Replacing code objects does not always succeed: changing a @property in a class to an ordinary method or a method to a member variable can cause problems (but in old objects only).   Functions that are removed (eg. via monkey-patching) from a module before it is reloaded are not upgraded.   C extension modules cannot be reloaded, and so cannot be autoreloaded.         ","Language":"Python","Tags":["python","django","ipython"],"URL":"https://stackoverflow.com/questions/3772260/how-to-reload-modules-in-django-shell","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    I am working with Django and use Django shell all the time. The annoying part is that while the Django server reloads on code changes, the shell does not, so every time I make a change to a method I am testing, I need to quit the shell and restart it, re-import all the modules I need, reinitialize all the variables I need etc. While iPython history saves a lot of typing on this, this is still a pain. Is there a way to make django shell auto-reload, the same way django development server does?  I know about reload(), but I import a lot of models and generally use from app.models import * syntax, so reload() is not much help.     ","Q_Votes":"61"},{"Q_Title":"How to reload modules in django shell?","A_Content":"  It seems that the general consensus on this topic, is that python reload() sucks and there is no good way to do this.     ","Language":"Python","Tags":["python","django","ipython"],"URL":"https://stackoverflow.com/questions/3772260/how-to-reload-modules-in-django-shell","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    I am working with Django and use Django shell all the time. The annoying part is that while the Django server reloads on code changes, the shell does not, so every time I make a change to a method I am testing, I need to quit the shell and restart it, re-import all the modules I need, reinitialize all the variables I need etc. While iPython history saves a lot of typing on this, this is still a pain. Is there a way to make django shell auto-reload, the same way django development server does?  I know about reload(), but I import a lot of models and generally use from app.models import * syntax, so reload() is not much help.     ","Q_Votes":"61"},{"Q_Title":"How to reload modules in django shell?","A_Content":"  My solution to it is I write the code and save to a file and then use:     python manage.py shell < test.py   So I can make the change, save and run that command again till I fix whatever I'm trying to fix.     ","Language":"Python","Tags":["python","django","ipython"],"URL":"https://stackoverflow.com/questions/3772260/how-to-reload-modules-in-django-shell","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I am working with Django and use Django shell all the time. The annoying part is that while the Django server reloads on code changes, the shell does not, so every time I make a change to a method I am testing, I need to quit the shell and restart it, re-import all the modules I need, reinitialize all the variables I need etc. While iPython history saves a lot of typing on this, this is still a pain. Is there a way to make django shell auto-reload, the same way django development server does?  I know about reload(), but I import a lot of models and generally use from app.models import * syntax, so reload() is not much help.     ","Q_Votes":"61"},{"Q_Title":"How to reload modules in django shell?","A_Content":"  Reload() doesn't work in Django shell without some tricks. You can check this thread na and my answer specifically:  How do you reload a Django model module using the interactive interpreter via \"manage.py shell\"?     ","Language":"Python","Tags":["python","django","ipython"],"URL":"https://stackoverflow.com/questions/3772260/how-to-reload-modules-in-django-shell","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am working with Django and use Django shell all the time. The annoying part is that while the Django server reloads on code changes, the shell does not, so every time I make a change to a method I am testing, I need to quit the shell and restart it, re-import all the modules I need, reinitialize all the variables I need etc. While iPython history saves a lot of typing on this, this is still a pain. Is there a way to make django shell auto-reload, the same way django development server does?  I know about reload(), but I import a lot of models and generally use from app.models import * syntax, so reload() is not much help.     ","Q_Votes":"61"},{"Q_Title":"How to reload modules in django shell?","A_Content":"  My solution for this inconvenient follows. I am using IPython.  $ ./manage.py shell > import myapp.models as mdls   # 'mdls' or whatever you want, but short... > mdls.SomeModel.objects.get(pk=100) > # At this point save some changes in the model > reload(mdls) > mdls.SomeModel.objects.get(pk=100)   Hope it helps. Of course it is for debug purposes.  Cheers.     ","Language":"Python","Tags":["python","django","ipython"],"URL":"https://stackoverflow.com/questions/3772260/how-to-reload-modules-in-django-shell","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I am working with Django and use Django shell all the time. The annoying part is that while the Django server reloads on code changes, the shell does not, so every time I make a change to a method I am testing, I need to quit the shell and restart it, re-import all the modules I need, reinitialize all the variables I need etc. While iPython history saves a lot of typing on this, this is still a pain. Is there a way to make django shell auto-reload, the same way django development server does?  I know about reload(), but I import a lot of models and generally use from app.models import * syntax, so reload() is not much help.     ","Q_Votes":"61"},{"Q_Title":"How to reload modules in django shell?","A_Content":"  Instead of running commands from the Django shell, you can set up a management command like so and rerun that each time.     ","Language":"Python","Tags":["python","django","ipython"],"URL":"https://stackoverflow.com/questions/3772260/how-to-reload-modules-in-django-shell","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am working with Django and use Django shell all the time. The annoying part is that while the Django server reloads on code changes, the shell does not, so every time I make a change to a method I am testing, I need to quit the shell and restart it, re-import all the modules I need, reinitialize all the variables I need etc. While iPython history saves a lot of typing on this, this is still a pain. Is there a way to make django shell auto-reload, the same way django development server does?  I know about reload(), but I import a lot of models and generally use from app.models import * syntax, so reload() is not much help.     ","Q_Votes":"61"},{"Q_Title":"How to reload modules in django shell?","A_Content":"  Not exactly what you want, but I now tend to build myself management commands for testing and fiddling with things.  In the command you can set up a bunch of locals the way you want and afterwards drop into an interactive shell.  import code  class Command(BaseCommand):   def handle(self, *args, **kwargs):      foo = 'bar'      code.interact(local=locals())   No reload, but an easy and less annoying way to interactively test django functionality.     ","Language":"Python","Tags":["python","django","ipython"],"URL":"https://stackoverflow.com/questions/3772260/how-to-reload-modules-in-django-shell","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I am working with Django and use Django shell all the time. The annoying part is that while the Django server reloads on code changes, the shell does not, so every time I make a change to a method I am testing, I need to quit the shell and restart it, re-import all the modules I need, reinitialize all the variables I need etc. While iPython history saves a lot of typing on this, this is still a pain. Is there a way to make django shell auto-reload, the same way django development server does?  I know about reload(), but I import a lot of models and generally use from app.models import * syntax, so reload() is not much help.     ","Q_Votes":"61"},{"Q_Title":"how to remove an element in lxml","A_Content":"  Use the remove method of an xmlElement :   tree=et.fromstring(xml)  for bad in tree.xpath(\"//fruit[@state=\\'rotten\\']\"):   bad.getparent().remove(bad)     # here I grab the parent of the element to call the remove directly on it  print et.tostring(tree, pretty_print=True, xml_declaration=True)   If I had to compare with the @Acorn version, mine will work even if the elements to remove are not directly under the root node of your xml.     ","Language":"Python","Tags":["python","xml","lxml"],"URL":"https://stackoverflow.com/questions/7981840/how-to-remove-an-element-in-lxml","A_Votes":"113","_type":"dict","isAccepted":"Yes","Q_Content":"    I need to completely remove elements, based on the contents of an attribute, using python's lxml.  Example:  import lxml.etree as et  xml=\"\"\" <groceries>   <fruit state=\"rotten\">apple</fruit>   <fruit state=\"fresh\">pear</fruit>   <fruit state=\"fresh\">starfruit</fruit>   <fruit state=\"rotten\">mango</fruit>   <fruit state=\"fresh\">peach</fruit> </groceries> \"\"\"  tree=et.fromstring(xml)  for bad in tree.xpath(\"//fruit[@state=\\'rotten\\']\"):   #remove this element from the tree  print et.tostring(tree, pretty_print=True)   I would like this to print:  <groceries>   <fruit state=\"fresh\">pear</fruit>   <fruit state=\"fresh\">starfruit</fruit>   <fruit state=\"fresh\">peach</fruit> </groceries>   Is there a way to do this without storing a temporary variable and printing to it manually, as:  newxml=\"<groceries>\\n\" for elt in tree.xpath('//fruit[@state=\\'fresh\\']'):   newxml+=et.tostring(elt)  newxml+=\"</groceries>\"      ","Q_Votes":"61"},{"Q_Title":"how to remove an element in lxml","A_Content":"  You're looking for the remove function. Call the tree's remove method and pass it a subelement to remove.  import lxml.etree as et  xml=\"\"\" <groceries>   <fruit state=\"rotten\">apple</fruit>   <fruit state=\"fresh\">pear</fruit>   <punnet>     <fruit state=\"rotten\">strawberry</fruit>     <fruit state=\"fresh\">blueberry</fruit>   </punnet>   <fruit state=\"fresh\">starfruit</fruit>   <fruit state=\"rotten\">mango</fruit>   <fruit state=\"fresh\">peach</fruit> </groceries> \"\"\"  tree=et.fromstring(xml)  for bad in tree.xpath(\"//fruit[@state='rotten']\"):     bad.getparent().remove(bad)  print et.tostring(tree, pretty_print=True)   Result:  <groceries>   <fruit state=\"fresh\">pear</fruit>   <fruit state=\"fresh\">starfruit</fruit>   <fruit state=\"fresh\">peach</fruit> </groceries>      ","Language":"Python","Tags":["python","xml","lxml"],"URL":"https://stackoverflow.com/questions/7981840/how-to-remove-an-element-in-lxml","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I need to completely remove elements, based on the contents of an attribute, using python's lxml.  Example:  import lxml.etree as et  xml=\"\"\" <groceries>   <fruit state=\"rotten\">apple</fruit>   <fruit state=\"fresh\">pear</fruit>   <fruit state=\"fresh\">starfruit</fruit>   <fruit state=\"rotten\">mango</fruit>   <fruit state=\"fresh\">peach</fruit> </groceries> \"\"\"  tree=et.fromstring(xml)  for bad in tree.xpath(\"//fruit[@state=\\'rotten\\']\"):   #remove this element from the tree  print et.tostring(tree, pretty_print=True)   I would like this to print:  <groceries>   <fruit state=\"fresh\">pear</fruit>   <fruit state=\"fresh\">starfruit</fruit>   <fruit state=\"fresh\">peach</fruit> </groceries>   Is there a way to do this without storing a temporary variable and printing to it manually, as:  newxml=\"<groceries>\\n\" for elt in tree.xpath('//fruit[@state=\\'fresh\\']'):   newxml+=et.tostring(elt)  newxml+=\"</groceries>\"      ","Q_Votes":"61"},{"Q_Title":"how to remove an element in lxml","A_Content":"  I met one situation:  <div>     <script>         some code     </script>     text here </div>     div.remove(script) will remove the text here part which I didn't mean to.  following the answer here, I found that etree.strip_elements is a better solution for me, which you can control whether or not you will remove the text behind with with_tail=(bool) param.  But still I don't know if this can use xpath filter for tag. Just put this for informing.  Here is the doc:     strip_elements(tree_or_element, *tag_names, with_tail=True)      Delete all elements with the provided tag names from a tree or   subtree.  This will remove the elements and their entire subtree,   including all their attributes, text content and descendants.  It   will also remove the tail text of the element unless you   explicitly set the with_tail keyword argument option to False.      Tag names can contain wildcards as in _Element.iter.      Note that this will not delete the element (or ElementTree root   element) that you passed even if it matches.  It will only treat   its descendants.  If you want to include the root element, check   its tag name directly before even calling this function.      Example usage::     strip_elements(some_element,        'simpletagname',             # non-namespaced tag        '{http://some/ns}tagname',   # namespaced tag        '{http://some/other/ns}*'    # any tag from a namespace        lxml.etree.Comment           # comments        )       ","Language":"Python","Tags":["python","xml","lxml"],"URL":"https://stackoverflow.com/questions/7981840/how-to-remove-an-element-in-lxml","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I need to completely remove elements, based on the contents of an attribute, using python's lxml.  Example:  import lxml.etree as et  xml=\"\"\" <groceries>   <fruit state=\"rotten\">apple</fruit>   <fruit state=\"fresh\">pear</fruit>   <fruit state=\"fresh\">starfruit</fruit>   <fruit state=\"rotten\">mango</fruit>   <fruit state=\"fresh\">peach</fruit> </groceries> \"\"\"  tree=et.fromstring(xml)  for bad in tree.xpath(\"//fruit[@state=\\'rotten\\']\"):   #remove this element from the tree  print et.tostring(tree, pretty_print=True)   I would like this to print:  <groceries>   <fruit state=\"fresh\">pear</fruit>   <fruit state=\"fresh\">starfruit</fruit>   <fruit state=\"fresh\">peach</fruit> </groceries>   Is there a way to do this without storing a temporary variable and printing to it manually, as:  newxml=\"<groceries>\\n\" for elt in tree.xpath('//fruit[@state=\\'fresh\\']'):   newxml+=et.tostring(elt)  newxml+=\"</groceries>\"      ","Q_Votes":"61"},{"Q_Title":"Using the logging python class to write to a file?","A_Content":"  An example of using logging.basicConfig rather than logging.fileHandler()  logging.basicConfig(filename=logname,                             filemode='a',                             format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',                             datefmt='%H:%M:%S',                             level=logging.DEBUG)  logging.info(\"Running Urban Planning\")  self.logger = logging.getLogger('urbanGUI')   In order, the five parts do the following:    set the output file (filename=logname) set it to append rather than overwrite (filemode='a') determine the format of the output message (format=...) determine the format of the output time (datefmt='%H:%M:%S') and determine the minimum message level it will accept (level=logging.DEBUG).      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/6386698/using-the-logging-python-class-to-write-to-a-file","A_Votes":"85","_type":"dict","isAccepted":"Yes","Q_Content":"    How can I use the logging class in python to write to a file? Every time I try to use it, it just prints out the message.     ","Q_Votes":"61"},{"Q_Title":"Using the logging python class to write to a file?","A_Content":"  Taken from the \"logging cookbook\":  # create logger with 'spam_application' logger = logging.getLogger('spam_application') logger.setLevel(logging.DEBUG) # create file handler which logs even debug messages fh = logging.FileHandler('spam.log') fh.setLevel(logging.DEBUG) logger.addHandler(fh)   And you're good to go.  P.S. Make sure to read the logging HOWTO as well.     ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/6386698/using-the-logging-python-class-to-write-to-a-file","A_Votes":"40","_type":"dict","isAccepted":"No","Q_Content":"    How can I use the logging class in python to write to a file? Every time I try to use it, it just prints out the message.     ","Q_Votes":"61"},{"Q_Title":"Using the logging python class to write to a file?","A_Content":"  http://docs.python.org/library/logging.html#logging.basicConfig  logging.basicConfig(filename='/path/to/your/log', level=....)      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/6386698/using-the-logging-python-class-to-write-to-a-file","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    How can I use the logging class in python to write to a file? Every time I try to use it, it just prints out the message.     ","Q_Votes":"61"},{"Q_Title":"Using the logging python class to write to a file?","A_Content":"  I prefer to use a configuration file. It allows me to switch logging levels, locations, etc without changing code when I go from development to release. I simply package a different config file with the same name, and with the same defined loggers.  import logging.config if __name__ == '__main__':     # Configure the logger     # loggerConfigFileName: The name and path of your configuration file     logging.config.fileConfig(path.normpath(loggerConfigFileName))      # Create the logger     # Admin_Client: The name of a logger defined in the config file     mylogger = logging.getLogger('Admin_Client')      msg='Bite Me'     myLogger.debug(msg)     myLogger.info(msg)     myLogger.warn(msg)     myLogger.error(msg)     myLogger.critical(msg)      # Shut down the logger     logging.shutdown()   Here is my code for the log config file  #These are the loggers that are available from the code #Each logger requires a handler, but can have more than one [loggers] keys=root,Admin_Client   #Each handler requires a single formatter [handlers] keys=fileHandler, consoleHandler   [formatters] keys=logFormatter, consoleFormatter   [logger_root] level=DEBUG handlers=fileHandler   [logger_Admin_Client] level=DEBUG handlers=fileHandler, consoleHandler qualname=Admin_Client #propagate=0 Does not pass messages to ancestor loggers(root) propagate=0   # Do not use a console logger when running scripts from a bat file without a console # because it hangs! [handler_consoleHandler] class=StreamHandler level=DEBUG formatter=consoleFormatter args=(sys.stdout,)# The comma is correct, because the parser is looking for args   [handler_fileHandler] class=FileHandler level=DEBUG formatter=logFormatter # This causes a new file to be created for each script # Change time.strftime(\"%Y%m%d%H%M%S\") to time.strftime(\"%Y%m%d\") # And only one log per day will be created. All messages will be amended to it. args=(\"D:\\\\Logs\\\\PyLogs\\\\\" + time.strftime(\"%Y%m%d%H%M%S\")+'.log', 'a')   [formatter_logFormatter] #name is the name of the logger root or Admin_Client #levelname is the log message level debug, warn, ect  #lineno is the line number from where the call to log is made #04d is simple formatting to ensure there are four numeric places with leading zeros #4s would work as well, but would simply pad the string with leading spaces, right justify #-4s would work as well, but would simply pad the string with trailing spaces, left justify #filename is the file name from where the call to log is made #funcName is the method name from where the call to log is made #format=%(asctime)s | %(lineno)d | %(message)s #format=%(asctime)s | %(name)s | %(levelname)s | %(message)s #format=%(asctime)s | %(name)s | %(module)s-%(lineno) | %(levelname)s | %(message)s #format=%(asctime)s | %(name)s | %(module)s-%(lineno)04d | %(levelname)s | %(message)s #format=%(asctime)s | %(name)s | %(module)s-%(lineno)4s | %(levelname)-8s | %(message)s  format=%(asctime)s | %(levelname)-8s | %(lineno)04d | %(message)s   #Use a separate formatter for the console if you want [formatter_consoleFormatter] format=%(asctime)s | %(levelname)-8s | %(filename)s-%(funcName)s-%(lineno)04d | %(message)s      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/6386698/using-the-logging-python-class-to-write-to-a-file","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    How can I use the logging class in python to write to a file? Every time I try to use it, it just prints out the message.     ","Q_Votes":"61"},{"Q_Title":"Using the logging python class to write to a file?","A_Content":"  http://docs.python.org/library/logging.handlers.html#filehandler     The FileHandler class, located in the core logging package, sends logging output to a disk file.      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/6386698/using-the-logging-python-class-to-write-to-a-file","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    How can I use the logging class in python to write to a file? Every time I try to use it, it just prints out the message.     ","Q_Votes":"61"},{"Q_Title":"Using the logging python class to write to a file?","A_Content":"  import sys import logging  from util import reducer_logfile logging.basicConfig(filename=reducer_logfile, format='%(message)s',                     level=logging.INFO, filemode='w')      ","Language":"Python","Tags":["python","logging"],"URL":"https://stackoverflow.com/questions/6386698/using-the-logging-python-class-to-write-to-a-file","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How can I use the logging class in python to write to a file? Every time I try to use it, it just prints out the message.     ","Q_Votes":"61"},{"Q_Title":"Reading integers from binary file in Python","A_Content":"  The read method returns a sequence of bytes as a string. To convert from a string byte-sequence to binary data, use the built-in struct module: http://docs.python.org/library/struct.html.   import struct  print(struct.unpack('i', fin.read(4)))   Note that unpack always returns a tuple, so struct.unpack('i', fin.read(4))[0] gives the integer value that you are after.  You should probably use the format string '<i' (< is a modifier that indicates little-endian byte-order and standard size and alignment - the default is to use the platform's byte ordering, size and alignment). According to the BMP format spec, the bytes should be written in Intel/little-endian byte order.     ","Language":"Python","Tags":["python","file","binary","integer"],"URL":"https://stackoverflow.com/questions/1163459/reading-integers-from-binary-file-in-python","A_Votes":"98","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm trying to read a BMP file in Python. I know the first two bytes  indicate the BMP firm. The next 4 bytes are the file size. When I execute:  fin = open(\"hi.bmp\", \"rb\") firm = fin.read(2)   file_size = int(fin.read(4))     I get:     ValueError: invalid literal for int() with base 10: 'F#\\x13'   What I want to do is reading those four bytes as an integer, but it seems Python is reading them as characters and returning a string, which cannot be converted to an integer. How can I do this correctly?       ","Q_Votes":"61"},{"Q_Title":"Reading integers from binary file in Python","A_Content":"  An alternative method which does not make use of 'struct.unpack()' would be to use NumPy:  import numpy as np  f = open(\"file.bin\", \"r\") a = np.fromfile(f, dtype=np.uint32)   'dtype' represents the datatype and can be int#, uint#, float#, complex# or a user defined type. See numpy.fromfile.  Personally prefer using NumPy to work with array/matrix data as it is a lot faster than using Python lists.     ","Language":"Python","Tags":["python","file","binary","integer"],"URL":"https://stackoverflow.com/questions/1163459/reading-integers-from-binary-file-in-python","A_Votes":"34","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to read a BMP file in Python. I know the first two bytes  indicate the BMP firm. The next 4 bytes are the file size. When I execute:  fin = open(\"hi.bmp\", \"rb\") firm = fin.read(2)   file_size = int(fin.read(4))     I get:     ValueError: invalid literal for int() with base 10: 'F#\\x13'   What I want to do is reading those four bytes as an integer, but it seems Python is reading them as characters and returning a string, which cannot be converted to an integer. How can I do this correctly?       ","Q_Votes":"61"},{"Q_Title":"Reading integers from binary file in Python","A_Content":"  Except struct you can also use array module  import array values = array.array('l') # array of long integers values.read(fin, 1) # read 1 integer file_size  = values[0]      ","Language":"Python","Tags":["python","file","binary","integer"],"URL":"https://stackoverflow.com/questions/1163459/reading-integers-from-binary-file-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to read a BMP file in Python. I know the first two bytes  indicate the BMP firm. The next 4 bytes are the file size. When I execute:  fin = open(\"hi.bmp\", \"rb\") firm = fin.read(2)   file_size = int(fin.read(4))     I get:     ValueError: invalid literal for int() with base 10: 'F#\\x13'   What I want to do is reading those four bytes as an integer, but it seems Python is reading them as characters and returning a string, which cannot be converted to an integer. How can I do this correctly?       ","Q_Votes":"61"},{"Q_Title":"Reading integers from binary file in Python","A_Content":"  As of Python 3.2+, you can also accomplish this using the from_bytes native int method:  file_size = int.from_bytes(fin.read(2), byteorder='big')   Note that this function requires you to specify whether the number is encoded in big- or little-endian format, so you will have to determine the endian-ness to make sure it works correctly.     ","Language":"Python","Tags":["python","file","binary","integer"],"URL":"https://stackoverflow.com/questions/1163459/reading-integers-from-binary-file-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to read a BMP file in Python. I know the first two bytes  indicate the BMP firm. The next 4 bytes are the file size. When I execute:  fin = open(\"hi.bmp\", \"rb\") firm = fin.read(2)   file_size = int(fin.read(4))     I get:     ValueError: invalid literal for int() with base 10: 'F#\\x13'   What I want to do is reading those four bytes as an integer, but it seems Python is reading them as characters and returning a string, which cannot be converted to an integer. How can I do this correctly?       ","Q_Votes":"61"},{"Q_Title":"Reading integers from binary file in Python","A_Content":"  As you are reading  the binary file, you need to unpack it into a integer, so use struct module for that  import struct fin = open(\"hi.bmp\", \"rb\") firm = fin.read(2)   file_size, = struct.unpack(\"i\",fin.read(4))      ","Language":"Python","Tags":["python","file","binary","integer"],"URL":"https://stackoverflow.com/questions/1163459/reading-integers-from-binary-file-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to read a BMP file in Python. I know the first two bytes  indicate the BMP firm. The next 4 bytes are the file size. When I execute:  fin = open(\"hi.bmp\", \"rb\") firm = fin.read(2)   file_size = int(fin.read(4))     I get:     ValueError: invalid literal for int() with base 10: 'F#\\x13'   What I want to do is reading those four bytes as an integer, but it seems Python is reading them as characters and returning a string, which cannot be converted to an integer. How can I do this correctly?       ","Q_Votes":"61"},{"Q_Title":"Reading integers from binary file in Python","A_Content":"  When you read from a binary file, a data type called bytes is used. This is a bit like list or tuple, except it can only store integers from 0 to 255.  Try:  file_size = fin.read(4) file_size0 = file_size[0] file_size1 = file_size[1] file_size2 = file_size[2] file_size3 = file_size[3]   Or:  file_size = list(fin.read(4))   Instead of:  file_size = int(fin.read(4))      ","Language":"Python","Tags":["python","file","binary","integer"],"URL":"https://stackoverflow.com/questions/1163459/reading-integers-from-binary-file-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to read a BMP file in Python. I know the first two bytes  indicate the BMP firm. The next 4 bytes are the file size. When I execute:  fin = open(\"hi.bmp\", \"rb\") firm = fin.read(2)   file_size = int(fin.read(4))     I get:     ValueError: invalid literal for int() with base 10: 'F#\\x13'   What I want to do is reading those four bytes as an integer, but it seems Python is reading them as characters and returning a string, which cannot be converted to an integer. How can I do this correctly?       ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  As said by Niklas, you need recursion, i.e. you want to define a function to print your dict, and if the value is a dict, you want to call your print function using this new dict.  Something like :  def myprint(d):   for k, v in d.iteritems():     if isinstance(v, dict):       myprint(v)     else:       print \"{0} : {1}\".format(k, v)   Or for Python 3 onwards :  def myprint(d):   for k, v in d.items():     if isinstance(v, dict):       myprint(v)     else:       print(\"{0} : {1}\".format(k, v))      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"85","_type":"dict","isAccepted":"Yes","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  Since a dict is iterable, you can apply the classic nested container iterable formula to this problem with only a couple of minor changes. Here's a Python 2 version (see below for 3):  import collections def nested_dict_iter(nested):     for key, value in nested.iteritems():         if isinstance(value, collections.Mapping):             for inner_key, inner_value in nested_dict_iter(value):                 yield inner_key, inner_value         else:             yield key, value   Test:  list(nested_dict_iter({'a':{'b':{'c':1, 'd':2},                              'e':{'f':3, 'g':4}},                         'h':{'i':5, 'j':6}})) # output: [('g', 4), ('f', 3), ('c', 1), ('d', 2), ('i', 5), ('j', 6)]   In Python 2, It might be possible to create a custom Mapping that qualifies as a Mapping but doesn't contain iteritems, in which case this will fail. The docs don't indicate that iteritems is required for a Mapping; on the other hand, the source gives Mapping types an iteritems method. So for custom Mappings, inherit from collections.Mapping explicitly just in case.  In Python 3, there are a number of improvements to be made. As of Python 3.3, abstract base classes live in collections.abc. They remain in collections too for backwards compatibility, but it's nicer having our abstract base classes together in one namespace. So this imports abc from collections. Python 3.3 also adds yield from, which is designed for just these sorts of situations. This is not empty syntactic sugar; it may lead to faster code and more sensible interactions with coroutines.  from collections import abc def nested_dict_iter(nested):     for key, value in nested.items():         if isinstance(value, abc.Mapping):             yield from nested_dict_iter(value)         else:             yield key, value      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  Alternative iterative solution:  def myprint(d):     stack = d.items()     while stack:         k, v = stack.pop()         if isinstance(v, dict):             stack.extend(v.iteritems())         else:             print(\"%s: %s\" % (k, v))      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"18","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  There are potential problems if you write your own recursive implementation or the iterative equivalent with stack. See this example:      dic = {}     dic[\"key1\"] = {}     dic[\"key1\"][\"key1.1\"] = \"value1\"     dic[\"key2\"]  = {}     dic[\"key2\"][\"key2.1\"] = \"value2\"     dic[\"key2\"][\"key2.2\"] = dic[\"key1\"]     dic[\"key2\"][\"key2.3\"] = dic   In the normal sense, nested dictionary will be a n-nary tree like data structure. But the definition doesn't exclude the possibility of a cross edge or even a back edge (thus no longer a tree). For instance, here key2.2 holds to the dictionary from key1, key2.3 points to the entire dictionary(back edge/cycle). When there is a back edge(cycle), the stack/recursion will run infinitely.                            root<-------back edge                         /      \\           |                      _key1   __key2__      |                     /       /   \\    \\     |                |->key1.1 key2.1 key2.2 key2.3                |   /       |      |                | value1  value2   |                |                  |                cross edge----------|   If you print this dictionary with this implementation from Scharron      def myprint(d):       for k, v in d.iteritems():         if isinstance(v, dict):           myprint(v)         else:           print \"{0} : {1}\".format(k, v)   You would see this error:      RuntimeError: maximum recursion depth exceeded while calling a Python object   The same goes with the implementation from senderle.  Similarly, you get an infinite loop with this implementation from Fred Foo:      def myprint(d):         stack = d.items()         while stack:             k, v = stack.pop()             if isinstance(v, dict):                 stack.extend(v.iteritems())             else:                 print(\"%s: %s\" % (k, v))   However, Python actually detects cycles in nested dictionary:      print dic     {'key2': {'key2.1': 'value2', 'key2.3': {...},         'key2.2': {'key1.1': 'value1'}}, 'key1': {'key1.1': 'value1'}}   \"{...}\" is where a cycle is detected.  As requested by Moondra this is a way to avoid cycles (DFS):     def myprint(d):       stack = d.items()       visited = set()       while stack:         k, v = stack.pop()         if isinstance(v, dict):            if k not in visited:              stack.extend(v.iteritems())            else: print(\"%s: %s\" % (k, v))              visited.add(k)      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  Here is pythonic way to do it. This function will allow you to loop through key-value pair in all the levels. It does not save the whole thing to the memory but rather walks through the dict as you loop through it  def recursive_items(dictionary):     for key, value in dictionary.items():         if type(value) is dict:             yield (key, value)             yield from recursive_items(value)         else:             yield (key, value)  a = {'a': {1: {1: 2, 3: 4}, 2: {5: 6}}}  for key, value in recursive_items(a):     print(key, value)   Prints  a {1: {1: 2, 3: 4}, 2: {5: 6}} 1 {1: 2, 3: 4} 1 2 3 4 2 {5: 6} 5 6      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  Slightly different version I wrote that keeps track of the keys along the way to get there  def print_dict(v, prefix=''):     if isinstance(v, dict):         for k, v2 in v.items():             p2 = \"{}['{}']\".format(prefix, k)             print_dict(v2, p2)     elif isinstance(v, list):         for i, v2 in enumerate(v):             p2 = \"{}[{}]\".format(prefix, i)             print_dict(v2, p2)     else:         print('{} = {}'.format(prefix, repr(v)))   On your data, it'll print  data['xml']['config']['portstatus']['status'] = u'good' data['xml']['config']['target'] = u'1' data['xml']['port'] = u'11'   It's also easy to modify it to track the prefix as a tuple of keys rather than a string if you need it that way.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  Iterative solution as an alternative:  def traverse_nested_dict(d):     iters = [d.iteritems()]      while iters:         it = iters.pop()         try:             k, v = it.next()         except StopIteration:             continue          iters.append(it)          if isinstance(v, dict):             iters.append(v.iteritems())         else:             yield k, v   d = {\"a\": 1, \"b\": 2, \"c\": {\"d\": 3, \"e\": {\"f\": 4}}} for k, v in traverse_nested_dict(d):     print k, v      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  A alternative solution to work with lists based on Scharron's solution  def myprint(d):     my_list = d.iteritems() if isinstance(d, dict) else enumerate(d)      for k, v in my_list:         if isinstance(v, dict) or isinstance(v, list):             myprint(v)         else:             print u\"{0} : {1}\".format(k, v)      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  Here's a modified version of Fred Foo's answer for Python 2. In the original response, only the deepest level of nesting is output. If you output the keys as lists, you can keep the keys for all levels, although to reference them you need to reference a list of lists.   Here's the function:   def NestIter(nested):     for key, value in nested.iteritems():         if isinstance(value, collections.Mapping):             for inner_key, inner_value in NestIter(value):                 yield [key, inner_key], inner_value         else:             yield [key],value   To reference the keys:   for keys, vals in mynested:      print(mynested[keys[0]][keys[1][0]][keys[1][1][0]])   for a three-level dictionary.   You need to know the number of levels before to access multiple keys and the number of levels should be constant (it may be possible to add a small bit of script to check the number of nesting levels when iterating through values, but I haven't yet looked at this).      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  I find this approach a bit more flexible, here you just providing generator function that emits key, value pairs and can be easily extended to also iterate over lists.  def traverse(value, key=None):     if isinstance(value, dict):         for k, v in value.items():             yield from traverse(v, k)     else:         yield key, value   Then you can write your own myprint function, then would print those key value pairs.  def myprint(d):     for k, v in traverse(d):         print(f\"{k} : {v}\")   A test:  myprint({     'xml': {         'config': {             'portstatus': {                 'status': 'good',             },             'target': '1',         },         'port': '11',     }, })   Output:  status : good target : 1 port : 11   I tested this on Python 3.6.     ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Loop through all nested dictionary values?","A_Content":"  I am using the following code to print all the values of a nested dictionary, taking into account where the value could be a list containing dictionaries. This was useful to me when parsing a JSON file into a dictionary and needing to quickly check whether any of its values are None.      d = {             \"user\": 10,             \"time\": \"2017-03-15T14:02:49.301000\",             \"metadata\": [                 {\"foo\": \"bar\"},                 \"some_string\"             ]         }       def print_nested(d):         if isinstance(d, dict):             for k, v in d.items():                 print_nested(v)         elif hasattr(d, '__iter__') and not isinstance(d, str):             for item in d:                 print_nested(item)         elif isinstance(d, str):             print(d)          else:             print(d)      print_nested(d)   Output:      10     2017-03-15T14:02:49.301000     bar     some_string      ","Language":"Python","Tags":["python","dictionary"],"URL":"https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    for k, v in d.iteritems():     if type(v) is dict:         for t, c in v.iteritems():             print \"{0} : {1}\".format(t, c)   I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?  EDIT  How about this? It still only prints one thing.  def printDict(d):     for k, v in d.iteritems():         if type(v) is dict:             printDict(v)         else:             print \"{0} : {1}\".format(k, v)   Full Test Case  Dictionary:  {u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},       u'port': u'11'}}   Result:  xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}      ","Q_Votes":"61"},{"Q_Title":"Python - add PYTHONPATH during command line module run","A_Content":"  For Mac/Linux;  PYTHONPATH=/foo/bar/baz python somescript.py somecommand   For Windows, setup a wrapper pythonpath.bat;  @ECHO OFF setlocal set PYTHONPATH=%1 python %2 %3 endlocal   and call pythonpath.bat script file like;  pythonpath.bat /foo/bar/baz somescript.py somecommand      ","Language":"Python","Tags":["python","pythonpath"],"URL":"https://stackoverflow.com/questions/4580101/python-add-pythonpath-during-command-line-module-run","A_Votes":"105","_type":"dict","isAccepted":"Yes","Q_Content":"    I want to run:  python somescript.py somecommand   But, when I run this I need PYTHONPATH to include a certain directory. I can't just add it to my environment variables because the directory I want to add changes based on what project I'm running. Is there a way to alter PYTHONPATH while running a script? Note: I don't even have a PYTHONPATH variable, so I don't need to worry about appending to it vs overriding it during running of this script.     ","Q_Votes":"61"},{"Q_Title":"Python - add PYTHONPATH during command line module run","A_Content":"   import sys  sys.path.append('your certain directory')   Basically sys.path is a list with all the search paths for python modules. It is initialized by the interpreter. The content of PYTHONPATH is automatically added to the end of that list.     ","Language":"Python","Tags":["python","pythonpath"],"URL":"https://stackoverflow.com/questions/4580101/python-add-pythonpath-during-command-line-module-run","A_Votes":"41","_type":"dict","isAccepted":"No","Q_Content":"    I want to run:  python somescript.py somecommand   But, when I run this I need PYTHONPATH to include a certain directory. I can't just add it to my environment variables because the directory I want to add changes based on what project I'm running. Is there a way to alter PYTHONPATH while running a script? Note: I don't even have a PYTHONPATH variable, so I don't need to worry about appending to it vs overriding it during running of this script.     ","Q_Votes":"61"},{"Q_Title":"Python - add PYTHONPATH during command line module run","A_Content":"  If you are running the command from a POSIX-compliant shell, like bash, you can set the environment variable like this:  PYTHONPATH=\"/path/to\" python somescript.py somecommand   If it's all on one line, the PYTHONPATH environment value applies only to that one command.  $ echo $PYTHONPATH  $ python -c 'import sys;print(\"/tmp/pydir\" in sys.path)' False $ PYTHONPATH=/tmp/pydir python -c 'import sys;print(\"/tmp/pydir\" in sys.path)' True $ echo $PYTHONPATH      ","Language":"Python","Tags":["python","pythonpath"],"URL":"https://stackoverflow.com/questions/4580101/python-add-pythonpath-during-command-line-module-run","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    I want to run:  python somescript.py somecommand   But, when I run this I need PYTHONPATH to include a certain directory. I can't just add it to my environment variables because the directory I want to add changes based on what project I'm running. Is there a way to alter PYTHONPATH while running a script? Note: I don't even have a PYTHONPATH variable, so I don't need to worry about appending to it vs overriding it during running of this script.     ","Q_Votes":"61"},{"Q_Title":"Python - add PYTHONPATH during command line module run","A_Content":"  You may try this to execute a function inside your script  python -c \"import sys; sys.path.append('/your/script/path'); import yourscript; yourscript.yourfunction()\"      ","Language":"Python","Tags":["python","pythonpath"],"URL":"https://stackoverflow.com/questions/4580101/python-add-pythonpath-during-command-line-module-run","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I want to run:  python somescript.py somecommand   But, when I run this I need PYTHONPATH to include a certain directory. I can't just add it to my environment variables because the directory I want to add changes based on what project I'm running. Is there a way to alter PYTHONPATH while running a script? Note: I don't even have a PYTHONPATH variable, so I don't need to worry about appending to it vs overriding it during running of this script.     ","Q_Votes":"61"},{"Q_Title":"Python - add PYTHONPATH during command line module run","A_Content":"  This is for windows:  For example, I have a folder named \"mygrapher\" on my desktop. Inside, there's folders called \"calculation\" and \"graphing\" that contain Python files that my main file \"grapherMain.py\" needs. Also, \"grapherMain.py\" is stored in \"graphing\". To run everything without moving files, I can make a batch script. Let's call this batch file \"rungraph.bat\".  @ECHO OFF setlocal set PYTHONPATH=%cd%\\grapher;%cd%\\calculation python %cd%\\grapher\\grapherMain.py endlocal   This script is located in \"mygrapher\". To run things, I would get into my command prompt, then do:  >cd Desktop\\mygrapher (this navigates into the \"mygrapher\" folder) >rungraph.bat (this executes the batch file)      ","Language":"Python","Tags":["python","pythonpath"],"URL":"https://stackoverflow.com/questions/4580101/python-add-pythonpath-during-command-line-module-run","A_Votes":"-2","_type":"dict","isAccepted":"No","Q_Content":"    I want to run:  python somescript.py somecommand   But, when I run this I need PYTHONPATH to include a certain directory. I can't just add it to my environment variables because the directory I want to add changes based on what project I'm running. Is there a way to alter PYTHONPATH while running a script? Note: I don't even have a PYTHONPATH variable, so I don't need to worry about appending to it vs overriding it during running of this script.     ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  pymongo might give you a hand, followings are some codes I'm using:  import pandas as pd from pymongo import MongoClient   def _connect_mongo(host, port, username, password, db):     \"\"\" A util for making a connection to mongo \"\"\"      if username and password:         mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)         conn = MongoClient(mongo_uri)     else:         conn = MongoClient(host, port)       return conn[db]   def read_mongo(db, collection, query={}, host='localhost', port=27017, username=None, password=None, no_id=True):     \"\"\" Read from Mongo and Store into DataFrame \"\"\"      # Connect to MongoDB     db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)      # Make a query to the specific DB and Collection     cursor = db[collection].find(query)      # Expand the cursor and construct the DataFrame     df =  pd.DataFrame(list(cursor))      # Delete the _id     if no_id:         del df['_id']      return df      ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"87","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  You can load your mongodb data to pandas DataFrame using this code. It works for me. Hopefully for you too.  import pymongo import pandas as pd from pymongo import MongoClient client = MongoClient() db = client.database_name collection = db.collection_name data = pd.DataFrame(list(collection.find()))      ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"23","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  Monary does exactly that, and it's super fast. (another link)  See this cool post which includes a quick tutorial and some timings.     ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  import pandas as pd from odo import odo  data = odo('mongodb://localhost/db::collection', pd.DataFrame)      ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  As per PEP, simple is better than complicated:    import pandas as pd df = pd.DataFrame.from_records(db.<database_name>.<collection_name>.find())   You can include conditions as you would working with regular mongoDB database or even use find_one() to get only one element from the database, etc.   and voila!     ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  For dealing with out-of-core (not fitting into RAM) data efficiently (i.e. with parallel execution), you can try Python Blaze ecosystem: Blaze / Dask / Odo.  Blaze (and Odo) has out-of-the-box functions to deal with MongoDB.  A few useful articles to start off:   Introducing Blaze Expessions (with MongoDB query example) ReproduceIt: Reddit word count Difference between Dask Arrays and Blaze   And an article which shows what amazing things are possible with Blaze stack: Analyzing 1.7 Billion Reddit Comments with Blaze and Impala (essentially, querying 975 Gb of Reddit comments in seconds).  P.S. I'm not affiliated with any of these technologies.     ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  http://docs.mongodb.org/manual/reference/mongoexport  export to csv and use read_csv or JSON and use DataFrame.from_records     ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  Using   pandas.DataFrame(list(...))   will consume a lot of memory if the iterator/generator result is large  better to generate small chunks and concat at the end  def iterator2dataframes(iterator, chunk_size: int):   \"\"\"Turn an iterator into multiple small pandas.DataFrame    This is a balance between memory and efficiency   \"\"\"   records = []   frames = []   for i, record in enumerate(iterator):     records.append(record)     if i % chunk_size == chunk_size - 1:       frames.append(pd.DataFrame(records))       records = []   if records:     frames.append(pd.DataFrame(records))   return pd.concat(frames)      ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  A similar approach like Rafael Valero, waitingkuo and Deu Leung using pagination:  def read_mongo(        # db,         collection, query=None,         # host='localhost', port=27017, username=None, password=None,        chunksize = 100, page_num=1, no_id=True):      # Connect to MongoDB     db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)      # Calculate number of documents to skip     skips = chunksize * (page_num - 1)      # Sorry, this is in spanish     # https://www.toptal.com/python/c%C3%B3digo-buggy-python-los-10-errores-m%C3%A1s-comunes-que-cometen-los-desarrolladores-python/es     if not query:         query = {}      # Make a query to the specific DB and Collection     cursor = db[collection].find(query).skip(skips).limit(chunksize)      # Expand the cursor and construct the DataFrame     df =  pd.DataFrame(list(cursor))      # Delete the _id     if no_id:         del df['_id']      return df      ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  Another option I found very useful is:  from pandas.io.json import json_normalize  cursor = my_collection.find() df = json_normalize(cursor)   this way you get the unfolding of nested mongodb documents for free.     ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"How to import data from mongodb to pandas?","A_Content":"  Following this great answer by waitingkuo I would like to add the possibility of doing that using chunksize in line with .read_sql() and .read_csv(). I enlarge the answer from Deu Leung by avoiding go one by one each 'record' of the 'iterator' / 'cursor'. I will borrow previous read_mongo function.  def read_mongo(db,             collection, query={},             host='localhost', port=27017,             username=None, password=None,            chunksize = 100, no_id=True): \"\"\" Read from Mongo and Store into DataFrame \"\"\"   # Connect to MongoDB #db = _connect_mongo(host=host, port=port, username=username, password=password, db=db) client = MongoClient(host=host, port=port) # Make a query to the specific DB and Collection db_aux = client[db]   # Some variables to create the chunks skips_variable = range(0, db_aux[collection].find(query).count(), int(chunksize)) if len(skips_variable)<=1:     skips_variable = [0,len(skips_variable)]  # Iteration to create the dataframe in chunks. for i in range(1,len(skips_variable)):      # Expand the cursor and construct the DataFrame     #df_aux =pd.DataFrame(list(cursor_aux[skips_variable[i-1]:skips_variable[i]]))     df_aux =pd.DataFrame(list(db_aux[collection].find(query)[skips_variable[i-1]:skips_variable[i]]))      if no_id:         del df_aux['_id']      # Concatenate the chunks into a unique df     if 'df' not in locals():         df =  df_aux     else:         df = pd.concat([df, df_aux], ignore_index=True)  return df      ","Language":"Python","Tags":["python","mongodb","pandas","pymongo"],"URL":"https://stackoverflow.com/questions/16249736/how-to-import-data-from-mongodb-to-pandas","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a large amount of data in a collection in mongodb which I need to analyze. How do i import that data to pandas?  I am new to pandas and numpy.  EDIT: The mongodb collection contains sensor values tagged with date and time. The sensor values are of float datatype.   Sample Data:  { \"_cls\" : \"SensorReport\", \"_id\" : ObjectId(\"515a963b78f6a035d9fa531b\"), \"_types\" : [     \"SensorReport\" ], \"Readings\" : [     {         \"a\" : 0.958069536790466,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:26:35.297Z\"),         \"b\" : 6.296118156595,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95574014778624,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:09.963Z\"),         \"b\" : 6.29651468650064,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.953648289182713,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:27:37.545Z\"),         \"b\" : 7.29679823731148,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.955931884300997,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:28:21.369Z\"),         \"b\" : 6.29642922525632,         \"_cls\" : \"Reading\"     },     {         \"a\" : 0.95821381,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:20.801Z\"),         \"b\" : 7.28956613,         \"_cls\" : \"Reading\"     },     {         \"a\" : 4.95821335,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:41:36.931Z\"),         \"b\" : 6.28956574,         \"_cls\" : \"Reading\"     },     {         \"a\" : 9.95821341,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:42:09.971Z\"),         \"b\" : 0.28956488,         \"_cls\" : \"Reading\"     },     {         \"a\" : 1.95667927,         \"_types\" : [             \"Reading\"         ],         \"ReadingUpdatedDate\" : ISODate(\"2013-04-02T08:43:55.463Z\"),         \"b\" : 0.29115237,         \"_cls\" : \"Reading\"     } ], \"latestReportTime\" : ISODate(\"2013-04-02T08:43:55.463Z\"), \"sensorName\" : \"56847890-0\", \"reportCount\" : 8 }      ","Q_Votes":"61"},{"Q_Title":"UnicodeEncodeError: 'latin-1' codec can't encode character","A_Content":"  Character U+201C Left Double Quotation Mark is not present in the Latin-1 (ISO-8859-1) encoding.  It is present in code page 1252 (Western European). This is a Windows-specific encoding that is based on ISO-8859-1 but which puts extra characters into the range 0x80-0x9F. Code page 1252 is often confused with ISO-8859-1, and it's an annoying but now-standard web browser behaviour that if you serve your pages as ISO-8859-1, the browser will treat them as cp1252 instead. However, they really are two distinct encodings:  >>> u'He said \\u201CHello\\u201D'.encode('iso-8859-1') UnicodeEncodeError >>> u'He said \\u201CHello\\u201D'.encode('cp1252') 'He said \\x93Hello\\x94'   If you are using your database only as a byte store, you can use cp1252 to encode “ and other characters present in the Windows Western code page. But still other Unicode characters which are not present in cp1252 will cause errors.  You can use encode(..., 'ignore') to suppress the errors by getting rid of the characters, but really in this century you should be using UTF-8 in both your database and your pages. This encoding allows any character to be used. You should also ideally tell MySQL you are using UTF-8 strings (by setting the database connection and the collation on string columns), so it can get case-insensitive comparison and sorting right.     ","Language":"Python","Tags":["python","mysql","unicode","pylons"],"URL":"https://stackoverflow.com/questions/3942888/unicodeencodeerror-latin-1-codec-cant-encode-character","A_Votes":"48","_type":"dict","isAccepted":"Yes","Q_Content":"    What could be causing this error when I try to insert a foreign character into the database?  >>UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u201c' in position 0: ordinal not in range(256)   And how do I resolve it?  Thanks!     ","Q_Votes":"61"},{"Q_Title":"UnicodeEncodeError: 'latin-1' codec can't encode character","A_Content":"  I ran into this same issue when using the Python MySQLdb module.  Since MySQL will let you store just about any binary data you want in a text field regardless of character set, I found my solution here:  Using UTF8 with Python MySQLdb  Edit: Quote from the above URL to satisfy the request in the first comment...     \"UnicodeEncodeError:'latin-1' codec can't encode character ...\"      This is because MySQLdb normally tries to encode everythin to latin-1.   This can be fixed by executing the following commands right after   you've etablished the connection:   db.set_character_set('utf8') dbc.execute('SET NAMES utf8;') dbc.execute('SET CHARACTER SET utf8;') dbc.execute('SET character_set_connection=utf8;')      \"db\" is the result of MySQLdb.connect(), and \"dbc\" is the result of   db.cursor().      ","Language":"Python","Tags":["python","mysql","unicode","pylons"],"URL":"https://stackoverflow.com/questions/3942888/unicodeencodeerror-latin-1-codec-cant-encode-character","A_Votes":"78","_type":"dict","isAccepted":"No","Q_Content":"    What could be causing this error when I try to insert a foreign character into the database?  >>UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u201c' in position 0: ordinal not in range(256)   And how do I resolve it?  Thanks!     ","Q_Votes":"61"},{"Q_Title":"UnicodeEncodeError: 'latin-1' codec can't encode character","A_Content":"  I hope your database is at least UTF-8. Then you will need to run yourstring.encode('utf-8') before you try putting it into the database.     ","Language":"Python","Tags":["python","mysql","unicode","pylons"],"URL":"https://stackoverflow.com/questions/3942888/unicodeencodeerror-latin-1-codec-cant-encode-character","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    What could be causing this error when I try to insert a foreign character into the database?  >>UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u201c' in position 0: ordinal not in range(256)   And how do I resolve it?  Thanks!     ","Q_Votes":"61"},{"Q_Title":"UnicodeEncodeError: 'latin-1' codec can't encode character","A_Content":"  The best solution is    set mysql's charset to 'utf-8'  do like this comment(add use_unicode=True and charset=\"utf8\")     db = MySQLdb.connect(host=\"localhost\", user = \"root\", passwd = \"\", db = \"testdb\", use_unicode=True, charset=\"utf8\") – KyungHoon Kim Mar   13 '14 at 17:04    detail see :  class Connection(_mysql.connection):      \"\"\"MySQL Database Connection Object\"\"\"      default_cursor = cursors.Cursor      def __init__(self, *args, **kwargs):         \"\"\"          Create a connection to the database. It is strongly recommended         that you only use keyword parameters. Consult the MySQL C API         documentation for more information.          host           string, host to connect          user           string, user to connect as          passwd           string, password to use          db           string, database to use          port           integer, TCP/IP port to connect to          unix_socket           string, location of unix_socket to use          conv           conversion dictionary, see MySQLdb.converters          connect_timeout           number of seconds to wait before the connection attempt           fails.          compress           if set, compression is enabled          named_pipe           if set, a named pipe is used to connect (Windows only)          init_command           command which is run once the connection is created          read_default_file           file from which default client values are read          read_default_group           configuration group to use from the default file          cursorclass           class object, used to create cursors (keyword only)          use_unicode           If True, text-like columns are returned as unicode objects           using the connection's character set.  Otherwise, text-like           columns are returned as strings.  columns are returned as           normal strings. Unicode objects will always be encoded to           the connection's character set regardless of this setting.          charset           If supplied, the connection character set will be changed           to this character set (MySQL-4.1 and newer). This implies           use_unicode=True.          sql_mode           If supplied, the session SQL mode will be changed to this           setting (MySQL-4.1 and newer). For more details and legal           values, see the MySQL documentation.          client_flag           integer, flags to use or 0           (see MySQL docs or constants/CLIENTS.py)          ssl           dictionary or mapping, contains SSL connection parameters;           see the MySQL documentation for more details           (mysql_ssl_set()).  If this is set, and the client does not           support SSL, NotSupportedError will be raised.          local_infile           integer, non-zero enables LOAD LOCAL INFILE; zero disables          autocommit           If False (default), autocommit is disabled.           If True, autocommit is enabled.           If None, autocommit isn't set and server default is used.          There are a number of undocumented, non-standard methods. See the         documentation for the MySQL C API for some hints on what they do.          \"\"\"      ","Language":"Python","Tags":["python","mysql","unicode","pylons"],"URL":"https://stackoverflow.com/questions/3942888/unicodeencodeerror-latin-1-codec-cant-encode-character","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    What could be causing this error when I try to insert a foreign character into the database?  >>UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u201c' in position 0: ordinal not in range(256)   And how do I resolve it?  Thanks!     ","Q_Votes":"61"},{"Q_Title":"UnicodeEncodeError: 'latin-1' codec can't encode character","A_Content":"  You are trying to store a Unicode codepoint \\u201c using an encoding ISO-8859-1 / Latin-1 that can't describe that codepoint. Either you might need to alter the database to use utf-8, and store the string data using an appropriate encoding, or you might want to sanitise your inputs prior to storing the content; i.e. using something like Sam Ruby's excellent i18n guide. That talks about the issues that windows-1252 can cause, and suggests how to process it, plus links to sample code!     ","Language":"Python","Tags":["python","mysql","unicode","pylons"],"URL":"https://stackoverflow.com/questions/3942888/unicodeencodeerror-latin-1-codec-cant-encode-character","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    What could be causing this error when I try to insert a foreign character into the database?  >>UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u201c' in position 0: ordinal not in range(256)   And how do I resolve it?  Thanks!     ","Q_Votes":"61"},{"Q_Title":"UnicodeEncodeError: 'latin-1' codec can't encode character","A_Content":"  SQLAlchemy users can simply specify their field as convert_unicode=True.  Example: sqlalchemy.String(1000, convert_unicode=True)  SQLAlchemy will simply accept unicode objects and return them back, handling the encoding itself.  Docs     ","Language":"Python","Tags":["python","mysql","unicode","pylons"],"URL":"https://stackoverflow.com/questions/3942888/unicodeencodeerror-latin-1-codec-cant-encode-character","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    What could be causing this error when I try to insert a foreign character into the database?  >>UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u201c' in position 0: ordinal not in range(256)   And how do I resolve it?  Thanks!     ","Q_Votes":"61"},{"Q_Title":"UnicodeEncodeError: 'latin-1' codec can't encode character","A_Content":"  Latin-1 (aka ISO 8859-1) is a single octet character encoding scheme, and you can't fit \\u201c (“) into a byte.  Did you mean to use UTF-8 encoding?     ","Language":"Python","Tags":["python","mysql","unicode","pylons"],"URL":"https://stackoverflow.com/questions/3942888/unicodeencodeerror-latin-1-codec-cant-encode-character","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    What could be causing this error when I try to insert a foreign character into the database?  >>UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u201c' in position 0: ordinal not in range(256)   And how do I resolve it?  Thanks!     ","Q_Votes":"61"},{"Q_Title":"How do I get a empty array of any size I want in python?","A_Content":"  If by \"array\" you actually mean a Python list, you can use  a = [0] * 10   or  a = [None] * 10      ","Language":"Python","Tags":["python","arrays","dynamic-arrays"],"URL":"https://stackoverflow.com/questions/5205575/how-do-i-get-a-empty-array-of-any-size-i-want-in-python","A_Votes":"135","_type":"dict","isAccepted":"Yes","Q_Content":"    I basically want a python equivalent of this in C  int a[x];   but in python I declare an array like  a = []   but the problem is I want to assign random slots with values like  a[4] = 1   but I can't do that with python, since the array is empty     ","Q_Votes":"61"},{"Q_Title":"How do I get a empty array of any size I want in python?","A_Content":"  You can't do exactly what you want in Python (if I read you correctly).  You need to put values in for each element of the list (or as you called it, array).  But, try this:  a = [0 for x in range(N)]  # N = size of list you want a[i] = 5  # as long as i < N, you're okay   For lists of other types, use something besides 0.  None is often a good choice as well.     ","Language":"Python","Tags":["python","arrays","dynamic-arrays"],"URL":"https://stackoverflow.com/questions/5205575/how-do-i-get-a-empty-array-of-any-size-i-want-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    I basically want a python equivalent of this in C  int a[x];   but in python I declare an array like  a = []   but the problem is I want to assign random slots with values like  a[4] = 1   but I can't do that with python, since the array is empty     ","Q_Votes":"61"},{"Q_Title":"How do I get a empty array of any size I want in python?","A_Content":"  You can use numpy:  import numpy as np  Example from Empty Array:  np.empty([2, 2]) array([[ -9.74499359e+001,   6.69583040e-309],        [  2.13182611e-314,   3.06959433e-309]])        ","Language":"Python","Tags":["python","arrays","dynamic-arrays"],"URL":"https://stackoverflow.com/questions/5205575/how-do-i-get-a-empty-array-of-any-size-i-want-in-python","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I basically want a python equivalent of this in C  int a[x];   but in python I declare an array like  a = []   but the problem is I want to assign random slots with values like  a[4] = 1   but I can't do that with python, since the array is empty     ","Q_Votes":"61"},{"Q_Title":"How do I get a empty array of any size I want in python?","A_Content":"  also you can extend that with extend method of list.  a= [] a.extend([None]*10) a.extend([None]*20)      ","Language":"Python","Tags":["python","arrays","dynamic-arrays"],"URL":"https://stackoverflow.com/questions/5205575/how-do-i-get-a-empty-array-of-any-size-i-want-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I basically want a python equivalent of this in C  int a[x];   but in python I declare an array like  a = []   but the problem is I want to assign random slots with values like  a[4] = 1   but I can't do that with python, since the array is empty     ","Q_Votes":"61"},{"Q_Title":"How do I get a empty array of any size I want in python?","A_Content":"  Just declare the list and append each element. For ex:  a = [] a.append('first item') a.append('second item')      ","Language":"Python","Tags":["python","arrays","dynamic-arrays"],"URL":"https://stackoverflow.com/questions/5205575/how-do-i-get-a-empty-array-of-any-size-i-want-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I basically want a python equivalent of this in C  int a[x];   but in python I declare an array like  a = []   but the problem is I want to assign random slots with values like  a[4] = 1   but I can't do that with python, since the array is empty     ","Q_Votes":"61"},{"Q_Title":"How to construct a timedelta object from a simple string","A_Content":"  for the 4:13, and other standard formats(but if you don't know which one) use dateutil.parser.parse from python-dateutil  For the first format(5hr34m56s), you should parse using regular expressions  Here is re-based solution:  import re from datetime import timedelta   regex = re.compile(r'((?P<hours>\\d+?)hr)?((?P<minutes>\\d+?)m)?((?P<seconds>\\d+?)s)?')   def parse_time(time_str):     parts = regex.match(time_str)     if not parts:         return     parts = parts.groupdict()     time_params = {}     for (name, param) in parts.iteritems():         if param:             time_params[name] = int(param)     return timedelta(**time_params)   >>> from parse_time import parse_time >>> parse_time('12hr') datetime.timedelta(0, 43200) >>> parse_time('12hr5m10s') datetime.timedelta(0, 43510) >>> parse_time('12hr10s') datetime.timedelta(0, 43210) >>> parse_time('10s') datetime.timedelta(0, 10) >>>       ","Language":"Python","Tags":["python","timedelta"],"URL":"https://stackoverflow.com/questions/4628122/how-to-construct-a-timedelta-object-from-a-simple-string","A_Votes":"50","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm writing a function that needs a timedelta input to be passed in as a string. The user must enter something like \"32m\" or \"2h32m\", or even \"4:13\" or \"5hr34m56s\"... Is there a library or something that has this sort of thing already implemented?     ","Q_Votes":"61"},{"Q_Title":"How to construct a timedelta object from a simple string","A_Content":"  To me the most elegant solution, without having to resort to external libraries such as dateutil or manually parsing the input, is to use datetime's powerful strptime string parsing method.  from datetime import datetime, timedelta # we specify the input and the format... t = datetime.strptime(\"05:20:25\",\"%H:%M:%S\") # ...and use datetime's hour, min and sec properties to build a timedelta delta = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second)   After this you can use your timedelta object as normally, convert it to seconds to make sure we did the correct thing etc.  print(delta) assert(5*60*60+20*60+25 == delta.total_seconds())      ","Language":"Python","Tags":["python","timedelta"],"URL":"https://stackoverflow.com/questions/4628122/how-to-construct-a-timedelta-object-from-a-simple-string","A_Votes":"62","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a function that needs a timedelta input to be passed in as a string. The user must enter something like \"32m\" or \"2h32m\", or even \"4:13\" or \"5hr34m56s\"... Is there a library or something that has this sort of thing already implemented?     ","Q_Votes":"61"},{"Q_Title":"How to construct a timedelta object from a simple string","A_Content":"  I had a bit of time on my hands yesterday, so I developed @virhilo's answer into a Python module, adding a few more time expression formats, including all those requested by @priestc.  Source code is on github (MIT License) for anybody that wants it.  It's also on PyPI:  pip install pytimeparse   Returns the time as a number of seconds:  >>> from pytimeparse.timeparse import timeparse >>> timeparse('32m') 1920 >>> timeparse('2h32m') 9120 >>> timeparse('4:13') 253 >>> timeparse('5hr34m56s') 20096 >>> timeparse('1.2 minutes') 72      ","Language":"Python","Tags":["python","timedelta"],"URL":"https://stackoverflow.com/questions/4628122/how-to-construct-a-timedelta-object-from-a-simple-string","A_Votes":"47","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a function that needs a timedelta input to be passed in as a string. The user must enter something like \"32m\" or \"2h32m\", or even \"4:13\" or \"5hr34m56s\"... Is there a library or something that has this sort of thing already implemented?     ","Q_Votes":"61"},{"Q_Title":"How to construct a timedelta object from a simple string","A_Content":"  I wanted to input just a time and then add it to various dates so this worked for me:  from datetime import datetime as dtt  time_only = dtt.strptime('15:30', \"%H:%M\") - dtt.strptime(\"00:00\", \"%H:%M\")      ","Language":"Python","Tags":["python","timedelta"],"URL":"https://stackoverflow.com/questions/4628122/how-to-construct-a-timedelta-object-from-a-simple-string","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a function that needs a timedelta input to be passed in as a string. The user must enter something like \"32m\" or \"2h32m\", or even \"4:13\" or \"5hr34m56s\"... Is there a library or something that has this sort of thing already implemented?     ","Q_Votes":"61"},{"Q_Title":"How to construct a timedelta object from a simple string","A_Content":"  If you use Python 3 then here's updated version for Hari Shankar's solution, which I used:  from datetime import timedelta import re  regex = re.compile(r'(?P<hours>\\d+?)/'                    r'(?P<minutes>\\d+?)/'                    r'(?P<seconds>\\d+?)$')  def parse_time(time_str):     parts = regex.match(time_str)     if not parts:         return     parts = parts.groupdict()     print(parts)     time_params = {}     for name, param in parts.items():         if param:             time_params[name] = int(param)     return timedelta(**time_params)      ","Language":"Python","Tags":["python","timedelta"],"URL":"https://stackoverflow.com/questions/4628122/how-to-construct-a-timedelta-object-from-a-simple-string","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a function that needs a timedelta input to be passed in as a string. The user must enter something like \"32m\" or \"2h32m\", or even \"4:13\" or \"5hr34m56s\"... Is there a library or something that has this sort of thing already implemented?     ","Q_Votes":"61"},{"Q_Title":"How to construct a timedelta object from a simple string","A_Content":"  I've modified virhilo's nice answer with a few upgrades:    added a assertion that the string is a valid time string replace the \"hr\" hour-indicator with \"h\" allow for a \"d\" - days indicator allow non-integer times (e.g. 3m0.25s is 3 minutes, 0.25 seconds)   .  import re from datetime import timedelta   regex = re.compile(r'^((?P<days>[\\.\\d]+?)d)?((?P<hours>[\\.\\d]+?)h)?((?P<minutes>[\\.\\d]+?)m)?((?P<seconds>[\\.\\d]+?)s)?$')   def parse_time(time_str):     \"\"\"     Parse a time string e.g. (2h13m) into a timedelta object.      Modified from virhilo's answer at https://stackoverflow.com/a/4628148/851699      :param time_str: A string identifying a duration.  (eg. 2h13m)     :return datetime.timedelta: A datetime.timedelta object     \"\"\"     parts = regex.match(time_str)     assert parts is not None, \"Could not parse any time information from '{}'.  Examples of valid strings: '8h', '2d8h5m20s', '2m4s'\".format(time_str)     time_params = {name: float(param) for name, param in parts.groupdict().items() if param}     return timedelta(**time_params)      ","Language":"Python","Tags":["python","timedelta"],"URL":"https://stackoverflow.com/questions/4628122/how-to-construct-a-timedelta-object-from-a-simple-string","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I'm writing a function that needs a timedelta input to be passed in as a string. The user must enter something like \"32m\" or \"2h32m\", or even \"4:13\" or \"5hr34m56s\"... Is there a library or something that has this sort of thing already implemented?     ","Q_Votes":"61"},{"Q_Title":"How can I find the union of two Django querysets?","A_Content":"  This works and looks a bit cleaner:  records = query1 | query2   If you don't want duplicates, then you will need to append .distinct():  records = (query1 | query2).distinct()      ","Language":"Python","Tags":["python","django","django-models"],"URL":"https://stackoverflow.com/questions/4411049/how-can-i-find-the-union-of-two-django-querysets","A_Votes":"143","_type":"dict","isAccepted":"Yes","Q_Content":"    I’ve got a Django model with two custom manager methods. Each returns a different subset of the model’s objects, based on a different property of the object.  Is there any way to get a queryset, or just a list of objects, that’s the union of the querysets returned by each manager method?     ","Q_Votes":"61"},{"Q_Title":"How can I find the union of two Django querysets?","A_Content":"  Starting from version 1.11, django querysets have a builtin union method.  q = q1.union(q2) #q will contain all unique records of q1 + q2 q = q1.union(q2, all=True) #q will contain all records of q1 + q2 including duplicates q = q1.union(q2,q3) # more than 2 queryset union   See my blog post on this for more examples.     ","Language":"Python","Tags":["python","django","django-models"],"URL":"https://stackoverflow.com/questions/4411049/how-can-i-find-the-union-of-two-django-querysets","A_Votes":"27","_type":"dict","isAccepted":"No","Q_Content":"    I’ve got a Django model with two custom manager methods. Each returns a different subset of the model’s objects, based on a different property of the object.  Is there any way to get a queryset, or just a list of objects, that’s the union of the querysets returned by each manager method?     ","Q_Votes":"61"},{"Q_Title":"How to calculate moving average using NumPy?","A_Content":"  If you just want a straightforward non-weighted moving average, you can easily implement it with np.cumsum, which may be is faster than FFT based methods:  EDIT Corrected an off-by-one wrong indexing spotted by Bean in the code. EDIT  def moving_average(a, n=3) :     ret = np.cumsum(a, dtype=float)     ret[n:] = ret[n:] - ret[:-n]     return ret[n - 1:] / n  >>> a = np.arange(20) >>> moving_average(a) array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,         12.,  13.,  14.,  15.,  16.,  17.,  18.]) >>> moving_average(a, n=4) array([  1.5,   2.5,   3.5,   4.5,   5.5,   6.5,   7.5,   8.5,   9.5,         10.5,  11.5,  12.5,  13.5,  14.5,  15.5,  16.5,  17.5])   So I guess the answer is: it is really easy to implement, and maybe numpy is already a little bloated with specialized functionality.     ","Language":"Python","Tags":["python","numpy","scipy","time-series"],"URL":"https://stackoverflow.com/questions/14313510/how-to-calculate-moving-average-using-numpy","A_Votes":"110","_type":"dict","isAccepted":"No","Q_Content":"    There seems to be no function that simply calculates the moving average on numpy/scipy, leading to convoluted solutions.  My question is two-fold:   What's the easiest way to (correctly) implement a moving average with numpy? Since this seems non-trivial and error prone, is there a good reason not to have the batteries included in this case?      ","Q_Votes":"61"},{"Q_Title":"How to calculate moving average using NumPy?","A_Content":"  NumPy's lack of a particular domain-specific function is perhaps due to the Core Team's discipline and fidelity to NumPy's prime directive: provide an N-dimensional array type, as well as functions for creating, and indexing those arrays. Like many foundational objectives, this one is not small, and NumPy does it brilliantly.  The (much) larger SciPy contains a much larger collection of domain-specific libraries (called subpackages by SciPy devs)--for instance, numerical optimization (optimize), signal processsing (signal), and integral calculus (integrate).  My guess is that the function you are after is in at least one of the SciPy subpackages (scipy.signal perhaps); however, i would look first in the collection of SciPy scikits, identify the relevant scikit(s) and look for the function of interest there.  Scikits are independently developed packages based on NumPy/SciPy and directed to a particular technical discipline (e.g., scikits-image, scikits-learn, etc.) Several of these were (in particular, the awesome OpenOpt for numerical optimization) were highly regarded, mature projects long before choosing to reside under the relatively new scikits rubric. The Scikits homepage liked to above lists about 30 such scikits, though at least several of those are no longer under active development.   Following this advice would lead you to scikits-timeseries; however, that package is no longer under active development; In effect, Pandas has become, AFAIK, the de facto NumPy-based time series library.  Pandas has several functions that can be used to calculate a moving average; the simplest of these is probably rolling_mean, which you use like so:  >>> # the recommended syntax to import pandas >>> import pandas as PD >>> import numpy as NP  >>> # prepare some fake data: >>> # the date-time indices: >>> t = PD.date_range('1/1/2010', '12/31/2012', freq='D')  >>> # the data: >>> x = NP.arange(0, t.shape[0])  >>> # combine the data & index into a Pandas 'Series' object >>> D = PD.Series(x, t)   Now, just call the function rolling_mean passing in the Series object and a window size, which in my example below is 10 days.  >>> d_mva = PD.rolling_mean(D, 10)  >>> # d_mva is the same size as the original Series >>> d_mva.shape     (1096,)  >>> # though obviously the first w values are NaN where w is the window size >>> d_mva[:3]     2010-01-01         NaN     2010-01-02         NaN     2010-01-03         NaN   verify that it worked--e.g., compared values 10 - 15 in the original series versus the new Series smoothed with rolling mean  >>> D[10:15]      2010-01-11    2.041076      2010-01-12    2.041076      2010-01-13    2.720585      2010-01-14    2.720585      2010-01-15    3.656987      Freq: D  >>> d_mva[10:20]       2010-01-11    3.131125       2010-01-12    3.035232       2010-01-13    2.923144       2010-01-14    2.811055       2010-01-15    2.785824       Freq: D   The function rolling_mean, along with about a dozen or so other function are informally grouped in the Pandas documentation under the rubric moving window functions; a second, related group of functions in Pandas is referred to as exponentially-weighted functions (e.g., ewma, which calculates exponentially moving weighted average). The fact that this second group is not included in the first (moving window functions) is perhaps because the exponentially-weighted transforms don't rely on a fixed-length window     ","Language":"Python","Tags":["python","numpy","scipy","time-series"],"URL":"https://stackoverflow.com/questions/14313510/how-to-calculate-moving-average-using-numpy","A_Votes":"64","_type":"dict","isAccepted":"No","Q_Content":"    There seems to be no function that simply calculates the moving average on numpy/scipy, leading to convoluted solutions.  My question is two-fold:   What's the easiest way to (correctly) implement a moving average with numpy? Since this seems non-trivial and error prone, is there a good reason not to have the batteries included in this case?      ","Q_Votes":"61"},{"Q_Title":"Sorting related items in a Django template","A_Content":"  You need to specify the ordering in the attendee model, like this. For example (assuming your model class is named Attendee):  class Attendee(models.Model):     class Meta:         ordering = ['last_name']   See the manual for further reference.  EDIT. Another solution is to add a property to your Event model, that you can access from your template:  class Event(models.Model): # ... @property def sorted_attendee_set(self):     return self.attendee_set.order_by('last_name')   You could define more of these as you need them...     ","Language":"Python","Tags":["python","django","django-templates","sql-order-by"],"URL":"https://stackoverflow.com/questions/6540032/sorting-related-items-in-a-django-template","A_Votes":"100","_type":"dict","isAccepted":"Yes","Q_Content":"    Is it possible to sort a set of related items in a DJango template?  That is: this code (with HTML tags omitted for clarity):  {% for event in eventsCollection %}    {{ event.location }}    {% for attendee in event.attendee_set.all %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}   displays almost exactly want I want.  The only thing I want to change is I the list of attendees to be sorted by last name.  I've tried saying something like this:  {% for event in events %}    {{ event.location }}    {% for attendee in event.attendee_set.order_by__last_name %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}   Alas, the above syntax doesn't work (it produces an empty list) and neither does any other variation I have thought of (lot's of syntax errors reported, but no joy).     I could, of course, produce some kind of array of sorted attendee lists in my view, but that is an ugly and fragile (and did I mention ugly) solution.  Needless to say, but I'll say it anyway, I have perused the on-line docs and searched Stack Overflow and the archives of django-user without finding anything helpful (ah, if only a query set were a dictionary dictsort would do the job, but it's not and it doesn't)  ==============================================  Edited to add additional thoughts after accepting Tawmas's answer.    Tawmas addressed the issue exactly as I presented it -- although the solution was not what I expected.  As a result I learned a useful technique that can be used in other situations as well.   Tom's answer proposed an approach I had already mentioned in my OP and tentatively rejected as being \"ugly\".    The \"ugly\" was a gut reaction, and I wanted to clarify what was wrong with it.  In doing so I realized that the reason it was an ugly approach was because I was hung up on the idea of passing a query set to the template to be rendered.   If I relax that requirement, there is an un-ugly approach that should work.    I haven't tried this yet, but suppose that rather than passing the queryset, the view code iterated through the query set producing a list of Events, then decorated each Event with a query set for the corresponding attendees which WAS sorted (or filtered, or whatever) in the desired way.   Something like so:  eventCollection = []    events = Event.object.[filtered and sorted to taste] for event in events:    event.attendee_list = event.attendee_set.[filtered and sorted to taste]    eventCollection.append(event)   Now the template becomes:  {% for event in events %}    {{ event.location }}    {% for attendee in event.attendee_list %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}   The downside is the view has to \"actualize\" all of the events at once which could be a problem if there were large numbers of events.  Of course one could add pagination, but that complicates the view considerably.    The upside is the \"prepare the data to be displayed\" code is in the view where it belongs letting the template focus on formatting the data provided by the view for display. This is right and proper.  So my plan is to use Tawmas' technique for large tables and the above technique for small tables, with the definition of large and small left to the reader (grin.)     ","Q_Votes":"61"},{"Q_Title":"Sorting related items in a Django template","A_Content":"  You can use template filter dictsort https://docs.djangoproject.com/en/dev/ref/templates/builtins/#std:templatefilter-dictsort  This should work:  {% for event in eventsCollection %}    {{ event.location }}    {% for attendee in event.attendee_set.all|dictsort:\"last_name\" %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}      ","Language":"Python","Tags":["python","django","django-templates","sql-order-by"],"URL":"https://stackoverflow.com/questions/6540032/sorting-related-items-in-a-django-template","A_Votes":"79","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to sort a set of related items in a DJango template?  That is: this code (with HTML tags omitted for clarity):  {% for event in eventsCollection %}    {{ event.location }}    {% for attendee in event.attendee_set.all %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}   displays almost exactly want I want.  The only thing I want to change is I the list of attendees to be sorted by last name.  I've tried saying something like this:  {% for event in events %}    {{ event.location }}    {% for attendee in event.attendee_set.order_by__last_name %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}   Alas, the above syntax doesn't work (it produces an empty list) and neither does any other variation I have thought of (lot's of syntax errors reported, but no joy).     I could, of course, produce some kind of array of sorted attendee lists in my view, but that is an ugly and fragile (and did I mention ugly) solution.  Needless to say, but I'll say it anyway, I have perused the on-line docs and searched Stack Overflow and the archives of django-user without finding anything helpful (ah, if only a query set were a dictionary dictsort would do the job, but it's not and it doesn't)  ==============================================  Edited to add additional thoughts after accepting Tawmas's answer.    Tawmas addressed the issue exactly as I presented it -- although the solution was not what I expected.  As a result I learned a useful technique that can be used in other situations as well.   Tom's answer proposed an approach I had already mentioned in my OP and tentatively rejected as being \"ugly\".    The \"ugly\" was a gut reaction, and I wanted to clarify what was wrong with it.  In doing so I realized that the reason it was an ugly approach was because I was hung up on the idea of passing a query set to the template to be rendered.   If I relax that requirement, there is an un-ugly approach that should work.    I haven't tried this yet, but suppose that rather than passing the queryset, the view code iterated through the query set producing a list of Events, then decorated each Event with a query set for the corresponding attendees which WAS sorted (or filtered, or whatever) in the desired way.   Something like so:  eventCollection = []    events = Event.object.[filtered and sorted to taste] for event in events:    event.attendee_list = event.attendee_set.[filtered and sorted to taste]    eventCollection.append(event)   Now the template becomes:  {% for event in events %}    {{ event.location }}    {% for attendee in event.attendee_list %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}   The downside is the view has to \"actualize\" all of the events at once which could be a problem if there were large numbers of events.  Of course one could add pagination, but that complicates the view considerably.    The upside is the \"prepare the data to be displayed\" code is in the view where it belongs letting the template focus on formatting the data provided by the view for display. This is right and proper.  So my plan is to use Tawmas' technique for large tables and the above technique for small tables, with the definition of large and small left to the reader (grin.)     ","Q_Votes":"61"},{"Q_Title":"Sorting related items in a Django template","A_Content":"  regroup should be able to do what you want, but is there a reason you can't order them the way you want back in the view?     ","Language":"Python","Tags":["python","django","django-templates","sql-order-by"],"URL":"https://stackoverflow.com/questions/6540032/sorting-related-items-in-a-django-template","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Is it possible to sort a set of related items in a DJango template?  That is: this code (with HTML tags omitted for clarity):  {% for event in eventsCollection %}    {{ event.location }}    {% for attendee in event.attendee_set.all %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}   displays almost exactly want I want.  The only thing I want to change is I the list of attendees to be sorted by last name.  I've tried saying something like this:  {% for event in events %}    {{ event.location }}    {% for attendee in event.attendee_set.order_by__last_name %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}   Alas, the above syntax doesn't work (it produces an empty list) and neither does any other variation I have thought of (lot's of syntax errors reported, but no joy).     I could, of course, produce some kind of array of sorted attendee lists in my view, but that is an ugly and fragile (and did I mention ugly) solution.  Needless to say, but I'll say it anyway, I have perused the on-line docs and searched Stack Overflow and the archives of django-user without finding anything helpful (ah, if only a query set were a dictionary dictsort would do the job, but it's not and it doesn't)  ==============================================  Edited to add additional thoughts after accepting Tawmas's answer.    Tawmas addressed the issue exactly as I presented it -- although the solution was not what I expected.  As a result I learned a useful technique that can be used in other situations as well.   Tom's answer proposed an approach I had already mentioned in my OP and tentatively rejected as being \"ugly\".    The \"ugly\" was a gut reaction, and I wanted to clarify what was wrong with it.  In doing so I realized that the reason it was an ugly approach was because I was hung up on the idea of passing a query set to the template to be rendered.   If I relax that requirement, there is an un-ugly approach that should work.    I haven't tried this yet, but suppose that rather than passing the queryset, the view code iterated through the query set producing a list of Events, then decorated each Event with a query set for the corresponding attendees which WAS sorted (or filtered, or whatever) in the desired way.   Something like so:  eventCollection = []    events = Event.object.[filtered and sorted to taste] for event in events:    event.attendee_list = event.attendee_set.[filtered and sorted to taste]    eventCollection.append(event)   Now the template becomes:  {% for event in events %}    {{ event.location }}    {% for attendee in event.attendee_list %}      {{ attendee.first_name }} {{ attendee.last_name }}    {% endfor %}  {% endfor %}   The downside is the view has to \"actualize\" all of the events at once which could be a problem if there were large numbers of events.  Of course one could add pagination, but that complicates the view considerably.    The upside is the \"prepare the data to be displayed\" code is in the view where it belongs letting the template focus on formatting the data provided by the view for display. This is right and proper.  So my plan is to use Tawmas' technique for large tables and the above technique for small tables, with the definition of large and small left to the reader (grin.)     ","Q_Votes":"61"},{"Q_Title":"Django check for any exists for a query","A_Content":"  Use count():  sc=scorm.objects.filter(Header__id=qp.id)  if sc.count() > 0:    ...   The advantage over e.g. len() is, that the QuerySet is not yet evaluated:     count() performs a SELECT COUNT(*) behind the scenes, so you should always use count()  rather than loading all of the record into Python objects and calling len()  on the result.   Having this in mind, When QuerySets are evaluated can be worth reading.    If you use get(), e.g. scorm.objects.get(pk=someid), and the object does not exists, an ObjectDoesNotExist exception is raised:  from django.core.exceptions import ObjectDoesNotExist try:     sc = scorm.objects.get(pk=someid) except ObjectDoesNotExist:     print ...   Update: it's also possible to use exists():  if scorm.objects.filter(Header__id=qp.id).exists():     ....      Returns True if the QuerySet contains any results, and False if not. This tries to perform the query in the simplest and fastest way possible, but it does execute nearly the same query as a normal QuerySet query.      ","Language":"Python","Tags":["python","django","django-views"],"URL":"https://stackoverflow.com/questions/2690521/django-check-for-any-exists-for-a-query","A_Votes":"55","_type":"dict","isAccepted":"Yes","Q_Content":"    In django how to check whether any entry exists for a query   sc=scorm.objects.filter(Header__id=qp.id)   This was how it was done in php  if(mysql_num_rows($resultn)) {     // True condition     } else {     // False condition     }      ","Q_Votes":"61"},{"Q_Title":"Django check for any exists for a query","A_Content":"  As of Django 1.2, you can use exists():  https://docs.djangoproject.com/en/dev/ref/models/querysets/#exists  if some_queryset.filter(pk=entity_id).exists():     print(\"Entry contained in queryset\")      ","Language":"Python","Tags":["python","django","django-views"],"URL":"https://stackoverflow.com/questions/2690521/django-check-for-any-exists-for-a-query","A_Votes":"126","_type":"dict","isAccepted":"No","Q_Content":"    In django how to check whether any entry exists for a query   sc=scorm.objects.filter(Header__id=qp.id)   This was how it was done in php  if(mysql_num_rows($resultn)) {     // True condition     } else {     // False condition     }      ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  In the Python spirit of \"ask for forgiveness, not permission\", here's one way:  try:     b = a[4] except IndexError:     b = 'sss'      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"75","_type":"dict","isAccepted":"Yes","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  In the non-Python spirit of \"ask for permission, not forgiveness\", here's another way:  b = a[4] if len(a) > 4 else 'sss'      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"52","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  In the Python spirit of beautiful is better than ugly  Code golf method, using slice and unpacking   b=a[4:4+1] or 'sss'   Nicer than a wrapper function or try-catch IMHO, but intimidating for beginners. Personally I find tuple unpacking to be way sexier than list[#]  using slicing without unpacking:  b,=a[4:5] or ['sss']     or, if you have to do this often, and don't mind making a dictionary  d = dict(enumerate(a)) b=d.get(4,'sss')      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  another way:  b = (a[4:]+['sss'])[0]      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  You could create your own list-class:  class MyList(list):     def get(self, index, default=None):         return self[index] if len(self) > index else default   You can use it like this:  >>> l = MyList(['a', 'b', 'c']) >>> l.get(1) 'b' >>> l.get(9, 'no') 'no'      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  You could also define a little helper function for these cases:  def default(x, e, y):     try:         return x()     except e:         return y   It returns the return value of the function x, unless it raised an exception of type e; in that case, it returns the value y. Usage:  b = default(lambda: a[4], IndexError, 'sss')   Edit: Made it catch only one specified type of exception.  Suggestions for improvement are still welcome!     ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  For a common case where you want the first element, you can do  next(iter([1, 2, 3]), None)   I use this to \"unwrap\" a list, possibly after filtering it.  next((x for x in [1, 3, 5] if x % 2 == 0), None)   or   cur.execute(\"SELECT field FROM table\") next(cur.fetchone(), None)      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  try:     b = a[4] except IndexError:     b = 'sss'   A cleaner way (only works if you're using a dict):  b = a.get(4,\"sss\") # exact same thing as above   Here's another way you might like (again, only for dicts):  b = a.setdefault(4,\"sss\") # if a[4] exists, returns that, otherwise sets a[4] to \"sss\" and returns \"sss\"      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  I’m all for asking permission (i.e. I don’t like the try…except method). However, the code gets a lot cleaner when it’s encapsulated in a method:  def get_at(array, index, default):     if index < 0: index += len(array)     if index < 0: raise IndexError('list index out of range')     return array[index] if index < len(a) else default  b = get_at(a, 4, 'sss')      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  Using try/catch?  try:     b=a[4] except IndexError:     b='sss'      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  Since this is a top google hit, it's probably also worth mentioning that the standard \"collections\" package has a \"defaultdict\" which provides a more flexible solution to this problem.  You can do neat things, for example:  twodee = collections.defaultdict(dict) twodee[\"the horizontal\"][\"the vertical\"] = \"we control\"   Read more: http://docs.python.org/2/library/collections.html     ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  If you are looking for a maintainable way of getting default values on the index operator I found the following useful:  If you override operator.getitem  from the operator module to add an optional default parameter you get identical behaviour to the original while maintaining backwards compatibility.  def getitem(iterable, index, default=None):   import operator   try:     return operator.getitem(iterable, index)   except IndexError:     return default      ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"Getting a default value on index out of range in Python [duplicate]","A_Content":"  If you are looking for a quick hack for reducing the code length characterwise, you can try this.  a=['123','2',4] a.append('sss') #Default value n=5 #Index you want to access max_index=len(a)-1 b=a[min(max_index, n)] print(b)   But this trick is only useful when you no longer want further modification to the list     ","Language":"Python","Tags":["python","list","syntax","default-value"],"URL":"https://stackoverflow.com/questions/2574636/getting-a-default-value-on-index-out-of-range-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"          This question already has an answer here:                              How to get the nth element of a python list or a default if not available                                        8 answers                                          a=['123','2',4] b=a[4] or 'sss' print b   I want to get a default value when the list index is out of range (here: 'sss').  How can I do this?     ","Q_Votes":"61"},{"Q_Title":"looping over all member variables of a class in python","A_Content":"  dir(obj)   gives you all attributes of the object. You need to filter out the members from methods etc yourself:  class Example(object):     bool143 = True     bool2 = True     blah = False     foo = True     foobar2000 = False  example = Example() members = [attr for attr in dir(example) if not callable(getattr(example, attr)) and not attr.startswith(\"__\")] print members      Will give you:  ['blah', 'bool143', 'bool2', 'foo', 'foobar2000']      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1398022/looping-over-all-member-variables-of-a-class-in-python","A_Votes":"101","_type":"dict","isAccepted":"Yes","Q_Content":"    How do you get a list of all variables in a class thats iteratable? Kind of like locals(), but for a class  class Example(object):     bool143 = True     bool2 = True     blah = False     foo = True     foobar2000 = False      def as_list(self)        ret = []        for field in XXX:            if getattr(self, field):                ret.append(field)        return \",\".join(ret)   this should return  >>> e = Example() >>> e.as_list() bool143, bool2, foo      ","Q_Votes":"61"},{"Q_Title":"looping over all member variables of a class in python","A_Content":"  If you want only the variables (without functions) use:  vars(your_object)      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1398022/looping-over-all-member-variables-of-a-class-in-python","A_Votes":"80","_type":"dict","isAccepted":"No","Q_Content":"    How do you get a list of all variables in a class thats iteratable? Kind of like locals(), but for a class  class Example(object):     bool143 = True     bool2 = True     blah = False     foo = True     foobar2000 = False      def as_list(self)        ret = []        for field in XXX:            if getattr(self, field):                ret.append(field)        return \",\".join(ret)   this should return  >>> e = Example() >>> e.as_list() bool143, bool2, foo      ","Q_Votes":"61"},{"Q_Title":"looping over all member variables of a class in python","A_Content":"  @truppo: your answer is almost correct, but callable will always return false since you're just passing in a string. You need something like the following:  [attr for attr in dir(obj()) if not callable(getattr(obj(),attr)) and not attr.startswith(\"__\")]   which will filter out functions     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1398022/looping-over-all-member-variables-of-a-class-in-python","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    How do you get a list of all variables in a class thats iteratable? Kind of like locals(), but for a class  class Example(object):     bool143 = True     bool2 = True     blah = False     foo = True     foobar2000 = False      def as_list(self)        ret = []        for field in XXX:            if getattr(self, field):                ret.append(field)        return \",\".join(ret)   this should return  >>> e = Example() >>> e.as_list() bool143, bool2, foo      ","Q_Votes":"61"},{"Q_Title":"looping over all member variables of a class in python","A_Content":"  >>> a = Example() >>> dir(a) ['__class__', '__delattr__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'bool143', 'bool2', 'blah', 'foo', 'foobar2000', 'as_list']   —as you see, that gives you all attributes, so you'll have to filter out a little bit. But basically, dir() is what you're looking for.     ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1398022/looping-over-all-member-variables-of-a-class-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    How do you get a list of all variables in a class thats iteratable? Kind of like locals(), but for a class  class Example(object):     bool143 = True     bool2 = True     blah = False     foo = True     foobar2000 = False      def as_list(self)        ret = []        for field in XXX:            if getattr(self, field):                ret.append(field)        return \",\".join(ret)   this should return  >>> e = Example() >>> e.as_list() bool143, bool2, foo      ","Q_Votes":"61"},{"Q_Title":"looping over all member variables of a class in python","A_Content":"  The easy way to do this is to save all instances of the class in a list.  a = Example() b = Example() all_examples = [ a, b ]   Objects don't spring into existence spontaneously.  Some part of your program created them for a reason.  The creation is done for a reason.  Collecting them in a list can also be done for a reason.  If you use a factory, you can do this.  class ExampleFactory( object ):     def __init__( self ):         self.all_examples= []     def __call__( self, *args, **kw ):         e = Example( *args, **kw )         self.all_examples.append( e )         return e     def all( self ):         return all_examples  makeExample= ExampleFactory() a = makeExample() b = makeExample() for i in makeExample.all():     print i      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1398022/looping-over-all-member-variables-of-a-class-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How do you get a list of all variables in a class thats iteratable? Kind of like locals(), but for a class  class Example(object):     bool143 = True     bool2 = True     blah = False     foo = True     foobar2000 = False      def as_list(self)        ret = []        for field in XXX:            if getattr(self, field):                ret.append(field)        return \",\".join(ret)   this should return  >>> e = Example() >>> e.as_list() bool143, bool2, foo      ","Q_Votes":"61"},{"Q_Title":"looping over all member variables of a class in python","A_Content":"      class Employee:     '''     This class creates class employee with three attributes      and one function or method     '''      def __init__(self, first, last, salary):         self.first = first         self.last = last         self.salary = salary      def fullname(self):         fullname=self.first + ' ' + self.last         return fullname  emp1 = Employee('Abhijeet', 'Pandey', 20000) emp2 = Employee('John', 'Smith', 50000)  print('To get attributes of an instance', set(dir(emp1))-set(dir(Employee))) # you can now loop over      ","Language":"Python","Tags":["python"],"URL":"https://stackoverflow.com/questions/1398022/looping-over-all-member-variables-of-a-class-in-python","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    How do you get a list of all variables in a class thats iteratable? Kind of like locals(), but for a class  class Example(object):     bool143 = True     bool2 = True     blah = False     foo = True     foobar2000 = False      def as_list(self)        ret = []        for field in XXX:            if getattr(self, field):                ret.append(field)        return \",\".join(ret)   this should return  >>> e = Example() >>> e.as_list() bool143, bool2, foo      ","Q_Votes":"61"},{"Q_Title":"pytest: assert almost equal","A_Content":"  I noticed that this question specifically asked about py.test. py.test 3.0 includes an approx() function (well, really class) that is very useful for this purpose.  import pytest  assert 2.2 == pytest.approx(2.3) # fails, default is ± 2.3e-06 assert 2.2 == pytest.approx(2.3, 0.1) # passes  # also works the other way, in case you were worried: assert pytest.approx(2.3, 0.1) == 2.2 # passes   The documentation is here: https://docs.pytest.org/en/latest/reference.html#pytest-approx     ","Language":"Python","Tags":["python","unit-testing","py.test"],"URL":"https://stackoverflow.com/questions/8560131/pytest-assert-almost-equal","A_Votes":"106","_type":"dict","isAccepted":"Yes","Q_Content":"    How to do assert almost equal with py.test for floats without resorting to something like:  assert x - 0.00001 <= y <= x + 0.00001   More specifically it will be useful to know a neat solution for quickly compare pairs of float, without unpacking them:  assert (1.32, 2.4) == i_return_tuple_of_two_floats()      ","Q_Votes":"61"},{"Q_Title":"pytest: assert almost equal","A_Content":"  You will have to specify what is \"almost\" for you:  assert abs(x-y) < 0.0001   to apply to tuples (or any sequence):  def almost_equal(x,y,threshold=0.0001):   return abs(x-y) < threshold  assert all(map(almost_equal, zip((1.32, 2.4), i_return_tuple_of_two_floats())      ","Language":"Python","Tags":["python","unit-testing","py.test"],"URL":"https://stackoverflow.com/questions/8560131/pytest-assert-almost-equal","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    How to do assert almost equal with py.test for floats without resorting to something like:  assert x - 0.00001 <= y <= x + 0.00001   More specifically it will be useful to know a neat solution for quickly compare pairs of float, without unpacking them:  assert (1.32, 2.4) == i_return_tuple_of_two_floats()      ","Q_Votes":"61"},{"Q_Title":"pytest: assert almost equal","A_Content":"  If you have access to NumPy it has great functions for floating point comparison that already do pairwise comparison: http://docs.scipy.org/doc/numpy-dev/reference/routines.testing.html.  Then you can do something like:  numpy.testing.assert_allclose(i_return_tuple_of_two_floats(), (1.32, 2.4))      ","Language":"Python","Tags":["python","unit-testing","py.test"],"URL":"https://stackoverflow.com/questions/8560131/pytest-assert-almost-equal","A_Votes":"24","_type":"dict","isAccepted":"No","Q_Content":"    How to do assert almost equal with py.test for floats without resorting to something like:  assert x - 0.00001 <= y <= x + 0.00001   More specifically it will be useful to know a neat solution for quickly compare pairs of float, without unpacking them:  assert (1.32, 2.4) == i_return_tuple_of_two_floats()      ","Q_Votes":"61"},{"Q_Title":"pytest: assert almost equal","A_Content":"  Something like  assert round(x-y, 5) == 0   That is what unittest does  For the second part  assert all(round(x-y, 5) == 0 for x,y in zip((1.32, 2.4), i_return_tuple_of_two_floats()))   Probably better to wrap that in a function  def tuples_of_floats_are_almost_equal(X, Y):     return all(round(x-y, 5) == 0 for x,y in zip(X, Y))  assert tuples_of_floats_are_almost_equal((1.32, 2.4), i_return_tuple_of_two_floats())      ","Language":"Python","Tags":["python","unit-testing","py.test"],"URL":"https://stackoverflow.com/questions/8560131/pytest-assert-almost-equal","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    How to do assert almost equal with py.test for floats without resorting to something like:  assert x - 0.00001 <= y <= x + 0.00001   More specifically it will be useful to know a neat solution for quickly compare pairs of float, without unpacking them:  assert (1.32, 2.4) == i_return_tuple_of_two_floats()      ","Q_Votes":"61"},{"Q_Title":"Random hash in Python","A_Content":"  A md5-hash is just a 128-bit value, so if you want a random one:  import random  hash = random.getrandbits(128)  print \"hash value: %032x\" % hash   I don't really see the point, though. Maybe you should elaborate why you need this...     ","Language":"Python","Tags":["python","hash","md5"],"URL":"https://stackoverflow.com/questions/976577/random-hash-in-python","A_Votes":"95","_type":"dict","isAccepted":"Yes","Q_Content":"    What is the easiest way to generate a random hash (MD5) in Python?     ","Q_Votes":"61"},{"Q_Title":"pytest: assert almost equal","A_Content":"  These answers have been around for a long time, but I think the easiest and also most readable way is to use unittest for it's many nice assertions without using it for the testing structure.  Get assertions, ignore rest of unittest.TestCase  (based on this answer)  import unittest  assertions = unittest.TestCase('__init__')   Make some assertions  x = 0.00000001 assertions.assertAlmostEqual(x, 0)  # pass assertions.assertEqual(x, 0)  # fail # AssertionError: 1e-08 != 0   Implement original questions' auto-unpacking test  Just use * to unpack your return value without needing to introduce new names.  i_return_tuple_of_two_floats = lambda: (1.32, 2.4) assertions.assertAlmostEqual(*i_return_tuple_of_two_floats())  # fail # AssertionError: 1.32 != 2.4 within 7 places      ","Language":"Python","Tags":["python","unit-testing","py.test"],"URL":"https://stackoverflow.com/questions/8560131/pytest-assert-almost-equal","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    How to do assert almost equal with py.test for floats without resorting to something like:  assert x - 0.00001 <= y <= x + 0.00001   More specifically it will be useful to know a neat solution for quickly compare pairs of float, without unpacking them:  assert (1.32, 2.4) == i_return_tuple_of_two_floats()      ","Q_Votes":"61"},{"Q_Title":"pytest: assert almost equal","A_Content":"  I'd use nose.tools. It plays well with py.test runner and have other equally useful asserts - assert_dict_equal(), assert_list_equal(), etc.  from nose.tools import assert_almost_equals assert_almost_equals(x, y, places=7) #default is 7       ","Language":"Python","Tags":["python","unit-testing","py.test"],"URL":"https://stackoverflow.com/questions/8560131/pytest-assert-almost-equal","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    How to do assert almost equal with py.test for floats without resorting to something like:  assert x - 0.00001 <= y <= x + 0.00001   More specifically it will be useful to know a neat solution for quickly compare pairs of float, without unpacking them:  assert (1.32, 2.4) == i_return_tuple_of_two_floats()      ","Q_Votes":"61"},{"Q_Title":"Random hash in Python","A_Content":"  I think what you are looking for is a universal unique identifier.Then the module UUID in python is what you are looking for.  import uuid uuid.uuid4().hex   UUID4 gives you a random unique identifier that has the same length as a md5 sum. Hex will represent is as an hex string instead of returning a uuid object.   http://docs.python.org/2/library/uuid.html     ","Language":"Python","Tags":["python","hash","md5"],"URL":"https://stackoverflow.com/questions/976577/random-hash-in-python","A_Votes":"56","_type":"dict","isAccepted":"No","Q_Content":"    What is the easiest way to generate a random hash (MD5) in Python?     ","Q_Votes":"61"},{"Q_Title":"Random hash in Python","A_Content":"  This works for both python 2.x and 3.x  import os import binascii print(binascii.hexlify(os.urandom(16))) '4a4d443679ed46f7514ad6dbe3733c3d'      ","Language":"Python","Tags":["python","hash","md5"],"URL":"https://stackoverflow.com/questions/976577/random-hash-in-python","A_Votes":"38","_type":"dict","isAccepted":"No","Q_Content":"    What is the easiest way to generate a random hash (MD5) in Python?     ","Q_Votes":"61"},{"Q_Title":"Random hash in Python","A_Content":"  The secrets module was added in Python 3.6+. It provides cryptographically secure random values with a single call. The functions take an optional nbytes argument, default is 32 (bytes * 8 bits = 256-bit tokens). MD5 has 128-bit hashes, so provide 16 for \"MD5-like\" tokens.  >>> import secrets  >>> secrets.token_hex(nbytes=16) '17adbcf543e851aa9216acc9d7206b96'  >>> secrets.token_urlsafe(16) 'X7NYIolv893DXLunTzeTIQ'  >>> secrets.token_bytes(128 // 8) b'\\x0b\\xdcA\\xc0.\\x0e\\x87\\x9b`\\x93\\\\Ev\\x1a|u'      ","Language":"Python","Tags":["python","hash","md5"],"URL":"https://stackoverflow.com/questions/976577/random-hash-in-python","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    What is the easiest way to generate a random hash (MD5) in Python?     ","Q_Votes":"61"},{"Q_Title":"Random hash in Python","A_Content":"  Yet another approach. You won't have to format an int to get it.  import random import string  def random_string(length):     pool = string.letters + string.digits     return ''.join(random.choice(pool) for i in xrange(length))   Gives you flexibility on the length of the string.  >>> random_string(64) 'XTgDkdxHK7seEbNDDUim9gUBFiheRLRgg7HyP18j6BZU5Sa7AXiCHP1NEIxuL2s0'      ","Language":"Python","Tags":["python","hash","md5"],"URL":"https://stackoverflow.com/questions/976577/random-hash-in-python","A_Votes":"11","_type":"dict","isAccepted":"No","Q_Content":"    What is the easiest way to generate a random hash (MD5) in Python?     ","Q_Votes":"61"},{"Q_Title":"Random hash in Python","A_Content":"  Another approach to this specific question:  import random, string  def random_md5like_hash():     available_chars= string.hexdigits[:16]     return ''.join(         random.choice(available_chars)         for dummy in xrange(32))   I'm not saying it's faster or preferable to any other answer; just that it's another approach :)     ","Language":"Python","Tags":["python","hash","md5"],"URL":"https://stackoverflow.com/questions/976577/random-hash-in-python","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    What is the easiest way to generate a random hash (MD5) in Python?     ","Q_Votes":"61"},{"Q_Title":"Random hash in Python","A_Content":"  import uuid from md5 import md5  print md5(str(uuid.uuid4())).hexdigest()      ","Language":"Python","Tags":["python","hash","md5"],"URL":"https://stackoverflow.com/questions/976577/random-hash-in-python","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What is the easiest way to generate a random hash (MD5) in Python?     ","Q_Votes":"61"},{"Q_Title":"Random hash in Python","A_Content":"  import os, hashlib hashlib.md5(os.urandom(32)).hexdigest()      ","Language":"Python","Tags":["python","hash","md5"],"URL":"https://stackoverflow.com/questions/976577/random-hash-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    What is the easiest way to generate a random hash (MD5) in Python?     ","Q_Votes":"61"},{"Q_Title":"Regular expression to return text between parenthesis","A_Content":"  If your problem is really just this simple, you don't need regex:  s[s.find(\"(\")+1:s.find(\")\")]      ","Language":"Python","Tags":["python","regex","python-3.x"],"URL":"https://stackoverflow.com/questions/4894069/regular-expression-to-return-text-between-parenthesis","A_Votes":"153","_type":"dict","isAccepted":"Yes","Q_Content":"    u'abcde(date=\\'2/xc2/xb2\\',time=\\'/case/test.png\\')'   All I need is the contents inside the parenthesis.     ","Q_Votes":"61"},{"Q_Title":"Regular expression to return text between parenthesis","A_Content":"  Use re.search(r'\\((.*?)\\)',s).group(1):  >>> import re >>> s = u'abcde(date=\\'2/xc2/xb2\\',time=\\'/case/test.png\\')' >>> re.search(r'\\((.*?)\\)',s).group(1) u\"date='2/xc2/xb2',time='/case/test.png'\"      ","Language":"Python","Tags":["python","regex","python-3.x"],"URL":"https://stackoverflow.com/questions/4894069/regular-expression-to-return-text-between-parenthesis","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    u'abcde(date=\\'2/xc2/xb2\\',time=\\'/case/test.png\\')'   All I need is the contents inside the parenthesis.     ","Q_Votes":"61"},{"Q_Title":"Regular expression to return text between parenthesis","A_Content":"  If you want to find all occurences:   >>> re.findall('\\(.*?\\)',s) [u\"(date='2/xc2/xb2',time='/case/test.png')\", u'(eee)']  >>> re.findall('\\((.*?)\\)',s) [u\"date='2/xc2/xb2',time='/case/test.png'\", u'eee']      ","Language":"Python","Tags":["python","regex","python-3.x"],"URL":"https://stackoverflow.com/questions/4894069/regular-expression-to-return-text-between-parenthesis","A_Votes":"21","_type":"dict","isAccepted":"No","Q_Content":"    u'abcde(date=\\'2/xc2/xb2\\',time=\\'/case/test.png\\')'   All I need is the contents inside the parenthesis.     ","Q_Votes":"61"},{"Q_Title":"Regular expression to return text between parenthesis","A_Content":"  Building on tkerwin's answer, if you happen to have nested parentheses like in   st = \"sum((a+b)/(c+d))\"   his answer will not work if you need to take everything between the first opening parenthesis and the last closing parenthesis to get (a+b)/(c+d), because find searches from the left of the string, and would stop at the first closing parenthesis.  To fix that, you need to use rfind for the second part of the operation, so it would become   st[st.find(\"(\")+1:st.rfind(\")\")]      ","Language":"Python","Tags":["python","regex","python-3.x"],"URL":"https://stackoverflow.com/questions/4894069/regular-expression-to-return-text-between-parenthesis","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    u'abcde(date=\\'2/xc2/xb2\\',time=\\'/case/test.png\\')'   All I need is the contents inside the parenthesis.     ","Q_Votes":"61"},{"Q_Title":"Regular expression to return text between parenthesis","A_Content":"  import re  fancy = u'abcde(date=\\'2/xc2/xb2\\',time=\\'/case/test.png\\')'  print re.compile( \"\\((.*)\\)\" ).search( fancy ).group( 1 )      ","Language":"Python","Tags":["python","regex","python-3.x"],"URL":"https://stackoverflow.com/questions/4894069/regular-expression-to-return-text-between-parenthesis","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    u'abcde(date=\\'2/xc2/xb2\\',time=\\'/case/test.png\\')'   All I need is the contents inside the parenthesis.     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  Like this:  >>> text = 'a,b,c' >>> text = text.split(',') >>> text [ 'a', 'b', 'c' ]   Alternatively, you can use eval() if you trust the string to be safe:  >>> text = 'a,b,c' >>> text = eval('[' + text + ']')      ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"110","_type":"dict","isAccepted":"Yes","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  Just to add on to the existing answers: hopefully, you'll encounter something more like this in the future:  >>> word = 'abc' >>> L = list(word) >>> L ['a', 'b', 'c'] >>> ''.join(L) 'abc'   But what you're dealing with right now, go with @Cameron's answer.  >>> word = 'a,b,c' >>> L = word.split(',') >>> L ['a', 'b', 'c'] >>> ','.join(L) 'a,b,c'      ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"88","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  The following Python code will turn your string into a list of strings:  import ast teststr = \"['aaa','bbb','ccc']\" testarray = ast.literal_eval(teststr)      ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  I don't think you need to  In python you seldom need to convert a string to a list, because strings and lists are very similar  Changing the type  If you really have a string which should be a character array, do this:  In [1]: x = \"foobar\" In [2]: list(x) Out[2]: ['f', 'o', 'o', 'b', 'a', 'r']   Not changing the type  Note that Strings are very much like lists in python  Strings have accessors, like lists  In [3]: x[0] Out[3]: 'f'   Strings are iterable, like lists  In [4]: for i in range(len(x)): ...:     print x[i] ...:      f o o b a r   TLDR  Strings are lists. Almost.     ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"12","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  If you actually want arrays:  >>> from array import array >>> text = \"a,b,c\" >>> text = text.replace(',', '') >>> myarray = array('c', text) >>> myarray array('c', 'abc') >>> myarray[0] 'a' >>> myarray[1] 'b'   If you do not need arrays, and only want to look by index at your characters, remember a string is an iterable, just like a list except the fact that it is immutable:  >>> text = \"a,b,c\" >>> text = text.replace(',', '') >>> text[0] 'a'      ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  In case you want to split by spaces, you can just use .split():  a = 'mary had a little lamb' z = a.split() print z   Output:  ['mary', 'had', 'a', 'little', 'lamb']       ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  I usually use:  l = [ word.strip() for word in text.split(',') ]   the strip remove spaces around words.     ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  To convert a string having the form a=\"[[1, 3], [2, -6]]\" I wrote yet not optimized code:  matrixAr = [] mystring = \"[[1, 3], [2, -4], [19, -15]]\" b=mystring.replace(\"[[\",\"\").replace(\"]]\",\"\") # to remove head [[ and tail ]] for line in b.split('], ['):     row =list(map(int,line.split(','))) #map = to convert the number from string (some has also space ) to integer     matrixAr.append(row) print matrixAr      ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  m = '[[1,2,3],[4,5,6],[7,8,9]]'  m= eval(m.split()[0])  [[1, 2, 3], [4, 5, 6], [7, 8, 9]]      ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  # to strip `,` and `.` from a string ->  >>> 'a,b,c.'.translate(None, ',.') 'abc'   You should use the built-in translate method for strings.    Type help('abc'.translate) at Python shell for more info.     ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to convert a string to a list in Python?","A_Content":"  Using functional Python:  text=filter(lambda x:x!=',',map(str,text))      ","Language":"Python","Tags":["python","arrays","string"],"URL":"https://stackoverflow.com/questions/5387208/how-to-convert-a-string-to-a-list-in-python","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    How do you convert a string into a list?  Say the string is like text = \"a,b,c\". After the conversion, text == ['a', 'b', 'c'] and hopefully text[0] == 'a', text[1] == 'b'?     ","Q_Votes":"61"},{"Q_Title":"How to install pip3 on my Mac?","A_Content":"  UPDATED - Homebrew version after 1.5  According to the official Homebrew page:     On 1st March 2018 the python formula will be upgraded to Python 3.x and a python@2 formula will be added for installing Python 2.7 (although this will be keg-only so neither python nor python2 will be added to the PATH by default without a manual brew link --force). We will maintain python2, python3 and python@3 aliases.   So to install Python 3, run the following command:  brew install python3   Then, the pip or pip3 is installed automatically, and you can install any package by pip install <package>.    The older version of Homebrew  Not only brew install python3 but also brew postinstall python3  So you must run:  brew install python3 brew postinstall python3   Note that you should check the console, as it might get you errors and in that case, the pip3 is NOT installed.     ","Language":"Python","Tags":["python","python-3.x","pip"],"URL":"https://stackoverflow.com/questions/34573159/how-to-install-pip3-on-my-mac","A_Votes":"144","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install pip3, but I'm not having any luck. Also, I tried sudo install and it did not work. How could I install pip3 on my Mac?  sudo easy_install pip3 Password: Searching for pip3 Reading https://pypi.python.org/simple/pip3/ Couldn't find index page for 'pip3' (maybe misspelled?) Scanning index of all packages (this may take a while) Reading https://pypi.python.org/simple/  No local packages or download links found for pip3 error: Could not find suitable distribution for Requirement.parse('pip3')      ","Q_Votes":"61"},{"Q_Title":"How to install pip3 on my Mac?","A_Content":"  You could use home-brew  Then just run:  brew install python3      ","Language":"Python","Tags":["python","python-3.x","pip"],"URL":"https://stackoverflow.com/questions/34573159/how-to-install-pip3-on-my-mac","A_Votes":"59","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install pip3, but I'm not having any luck. Also, I tried sudo install and it did not work. How could I install pip3 on my Mac?  sudo easy_install pip3 Password: Searching for pip3 Reading https://pypi.python.org/simple/pip3/ Couldn't find index page for 'pip3' (maybe misspelled?) Scanning index of all packages (this may take a while) Reading https://pypi.python.org/simple/  No local packages or download links found for pip3 error: Could not find suitable distribution for Requirement.parse('pip3')      ","Q_Votes":"61"},{"Q_Title":"How to install pip3 on my Mac?","A_Content":"  I solved the same problem with these commands:  curl -O https://bootstrap.pypa.io/get-pip.py sudo python3 get-pip.py      ","Language":"Python","Tags":["python","python-3.x","pip"],"URL":"https://stackoverflow.com/questions/34573159/how-to-install-pip3-on-my-mac","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install pip3, but I'm not having any luck. Also, I tried sudo install and it did not work. How could I install pip3 on my Mac?  sudo easy_install pip3 Password: Searching for pip3 Reading https://pypi.python.org/simple/pip3/ Couldn't find index page for 'pip3' (maybe misspelled?) Scanning index of all packages (this may take a while) Reading https://pypi.python.org/simple/  No local packages or download links found for pip3 error: Could not find suitable distribution for Requirement.parse('pip3')      ","Q_Votes":"61"},{"Q_Title":"How to install pip3 on my Mac?","A_Content":"  Python3 was working successfully but without pip3. Tried many advises from stackoverflow, quora and others. (numerous installs and uninstalls)  Python3 was always fine but without pip3. Finally I downloaded Python3 from: https://www.python.org/downloads/  By simple mouse clicks and everything (Python3 + pip3) is working fine now.     ","Language":"Python","Tags":["python","python-3.x","pip"],"URL":"https://stackoverflow.com/questions/34573159/how-to-install-pip3-on-my-mac","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install pip3, but I'm not having any luck. Also, I tried sudo install and it did not work. How could I install pip3 on my Mac?  sudo easy_install pip3 Password: Searching for pip3 Reading https://pypi.python.org/simple/pip3/ Couldn't find index page for 'pip3' (maybe misspelled?) Scanning index of all packages (this may take a while) Reading https://pypi.python.org/simple/  No local packages or download links found for pip3 error: Could not find suitable distribution for Requirement.parse('pip3')      ","Q_Votes":"61"},{"Q_Title":"How to install pip3 on my Mac?","A_Content":"  For me brew postinstall python3 didn't work. Found this solution on GitHub homebrew issues page:  $ brew rm python  $ rm -rf /usr/local/opt/python $ brew prune  $ brew install python3      ","Language":"Python","Tags":["python","python-3.x","pip"],"URL":"https://stackoverflow.com/questions/34573159/how-to-install-pip3-on-my-mac","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install pip3, but I'm not having any luck. Also, I tried sudo install and it did not work. How could I install pip3 on my Mac?  sudo easy_install pip3 Password: Searching for pip3 Reading https://pypi.python.org/simple/pip3/ Couldn't find index page for 'pip3' (maybe misspelled?) Scanning index of all packages (this may take a while) Reading https://pypi.python.org/simple/  No local packages or download links found for pip3 error: Could not find suitable distribution for Requirement.parse('pip3')      ","Q_Votes":"61"},{"Q_Title":"How to install pip3 on my Mac?","A_Content":"  To install or upgrade pip, download get-pip.py from the official site. Then run the following command:   sudo python get-pip.py    and it will install pip for your python version which runs the script.      ","Language":"Python","Tags":["python","python-3.x","pip"],"URL":"https://stackoverflow.com/questions/34573159/how-to-install-pip3-on-my-mac","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install pip3, but I'm not having any luck. Also, I tried sudo install and it did not work. How could I install pip3 on my Mac?  sudo easy_install pip3 Password: Searching for pip3 Reading https://pypi.python.org/simple/pip3/ Couldn't find index page for 'pip3' (maybe misspelled?) Scanning index of all packages (this may take a while) Reading https://pypi.python.org/simple/  No local packages or download links found for pip3 error: Could not find suitable distribution for Requirement.parse('pip3')      ","Q_Votes":"61"},{"Q_Title":"How to install pip3 on my Mac?","A_Content":"  Similar to Oksana but add python3  $ brew rm python  $ brew rm python3  $ rm -rf /usr/local/opt/python $ rm -rf /usr/local/opt/python3 $ brew prune  $ brew install python3 $ brew postinstall python3   Seem now work for pip3 under mac os x 10.13.3 Xcode 9.2     ","Language":"Python","Tags":["python","python-3.x","pip"],"URL":"https://stackoverflow.com/questions/34573159/how-to-install-pip3-on-my-mac","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install pip3, but I'm not having any luck. Also, I tried sudo install and it did not work. How could I install pip3 on my Mac?  sudo easy_install pip3 Password: Searching for pip3 Reading https://pypi.python.org/simple/pip3/ Couldn't find index page for 'pip3' (maybe misspelled?) Scanning index of all packages (this may take a while) Reading https://pypi.python.org/simple/  No local packages or download links found for pip3 error: Could not find suitable distribution for Requirement.parse('pip3')      ","Q_Votes":"61"},{"Q_Title":"How to install pip3 on my Mac?","A_Content":"  I ran the below where <user>:<group> matched the other <user>:<group> for other files in the /usr/local/lib/python3.7/site-packages/ directory:  sudo chown -R <user>:<group> /usr/local/lib/python3.7/site-packages/pip* brew postinstall python3      ","Language":"Python","Tags":["python","python-3.x","pip"],"URL":"https://stackoverflow.com/questions/34573159/how-to-install-pip3-on-my-mac","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm trying to install pip3, but I'm not having any luck. Also, I tried sudo install and it did not work. How could I install pip3 on my Mac?  sudo easy_install pip3 Password: Searching for pip3 Reading https://pypi.python.org/simple/pip3/ Couldn't find index page for 'pip3' (maybe misspelled?) Scanning index of all packages (this may take a while) Reading https://pypi.python.org/simple/  No local packages or download links found for pip3 error: Could not find suitable distribution for Requirement.parse('pip3')      ","Q_Votes":"61"},{"Q_Title":"Is it Pythonic to use bools as ints?","A_Content":"  I'll be the odd voice out (since all answers are decrying the use of the fact that False == 0 and True == 1, as the language guarantees) as I claim that the use of this fact to simplify your code is perfectly fine.  Historically, logical true/false operations tended to simply use 0 for false and 1 for true; in the course of Python 2.2's life-cycle, Guido noticed that too many modules started with assignments such as false = 0; true = 1 and this produced boilerplate and useless variation (the latter because the capitalization of true and false was all over the place -- some used all-caps, some all-lowercase, some cap-initial) and so introduced the bool subclass of int and its True and False constants.  There was quite some pushback at the time since many of us feared that the new type and constants would be used by Python newbies to restrict the language's abilities, but Guido was adamant that we were just being pessimistic: nobody would ever understand Python so badly, for example, as to avoid the perfectly natural use of False and True as list indices, or in a summation, or other such perfectly clear and useful idioms.  The answers to this thread prove we were right: as we feared, a total misunderstanding of the roles of this type and constants has emerged, and people are avoiding, and, worse!, urging others to avoid, perfectly natural Python constructs in favor of useless gyrations.  Fighting against the tide of such misunderstanding, I urge everybody to use Python as Python, not trying to force it into the mold of other languages whose functionality and preferred style are quite different.  In Python, True and False are 99.9% like 1 and 0, differing exclusively in their str(...) (and thereby repr(...)) form -- for every other operation except stringification, just feel free to use them without contortions.  That goes for indexing, arithmetic, bit operations, etc, etc, etc.     ","Language":"Python","Tags":["boolean","python"],"URL":"https://stackoverflow.com/questions/3174392/is-it-pythonic-to-use-bools-as-ints","A_Votes":"156","_type":"dict","isAccepted":"Yes","Q_Content":"    False is equivalent to 0 and True is equivalent 1 so it's possible to do something like this:  def bool_to_str(value):     \"\"\"value should be a bool\"\"\"     return ['No', 'Yes'][value]  bool_to_str(True)   Notice how value is bool but is used as an int.  Is this this kind of use Pythonic or should it be avoided?     ","Q_Votes":"61"},{"Q_Title":"Is it Pythonic to use bools as ints?","A_Content":"  I'm with Alex. False==0 and True==1, and there's nothing wrong with that.  Still, in Python 2.5 and later I'd write the answer to this particular question using Python's conditional expression:  def bool_to_str(value):   return 'Yes' if value else 'No'   That way there's no requirement that the argument is actually a bool -- just as if x: ... accepts any type for x, the bool_to_str() function should do the right thing when it is passed None, a string, a list, or 3.14.     ","Language":"Python","Tags":["boolean","python"],"URL":"https://stackoverflow.com/questions/3174392/is-it-pythonic-to-use-bools-as-ints","A_Votes":"133","_type":"dict","isAccepted":"No","Q_Content":"    False is equivalent to 0 and True is equivalent 1 so it's possible to do something like this:  def bool_to_str(value):     \"\"\"value should be a bool\"\"\"     return ['No', 'Yes'][value]  bool_to_str(True)   Notice how value is bool but is used as an int.  Is this this kind of use Pythonic or should it be avoided?     ","Q_Votes":"61"},{"Q_Title":"Is it Pythonic to use bools as ints?","A_Content":"  surely:  def bool_to_str(value):     \"value should be a bool\"     return 'Yes' if value else 'No'   is more readable.     ","Language":"Python","Tags":["boolean","python"],"URL":"https://stackoverflow.com/questions/3174392/is-it-pythonic-to-use-bools-as-ints","A_Votes":"36","_type":"dict","isAccepted":"No","Q_Content":"    False is equivalent to 0 and True is equivalent 1 so it's possible to do something like this:  def bool_to_str(value):     \"\"\"value should be a bool\"\"\"     return ['No', 'Yes'][value]  bool_to_str(True)   Notice how value is bool but is used as an int.  Is this this kind of use Pythonic or should it be avoided?     ","Q_Votes":"61"},{"Q_Title":"Is it Pythonic to use bools as ints?","A_Content":"  Your code seems inaccurate in some cases:  >>> def bool_to_str(value): ...     \"\"\"value should be a bool\"\"\" ...     return ['No', 'Yes'][value] ... >>> bool_to_str(-2) 'No'   And I recommend you to use just the conditional operator for readability:  def bool_to_str(value):     \"\"\"value should be a bool\"\"\"     return \"Yes\" if value else \"No\"      ","Language":"Python","Tags":["boolean","python"],"URL":"https://stackoverflow.com/questions/3174392/is-it-pythonic-to-use-bools-as-ints","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    False is equivalent to 0 and True is equivalent 1 so it's possible to do something like this:  def bool_to_str(value):     \"\"\"value should be a bool\"\"\"     return ['No', 'Yes'][value]  bool_to_str(True)   Notice how value is bool but is used as an int.  Is this this kind of use Pythonic or should it be avoided?     ","Q_Votes":"61"},{"Q_Title":"Is it Pythonic to use bools as ints?","A_Content":"  It is actually a feature of the language that False == 0 and True == 1 (it does not depend on the implementation): Is False == 0 and True == 1 in Python an implementation detail or is it guaranteed by the language?  However, I do agree with most of the other answers: there are more readable ways of obtaining the same result as ['No', 'Yes'][value], through the use of the … if value else … or of a dictionary, which have the respective advantages of hinting and stating that value is a boolean.  Plus, the … if value else … follows the usual convention that non-0 is True: it also works even when value == -2 (value is True), as hinted by dahlia.  The list and dict approaches are not as robust, in this case, so I would not recommend them.     ","Language":"Python","Tags":["boolean","python"],"URL":"https://stackoverflow.com/questions/3174392/is-it-pythonic-to-use-bools-as-ints","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    False is equivalent to 0 and True is equivalent 1 so it's possible to do something like this:  def bool_to_str(value):     \"\"\"value should be a bool\"\"\"     return ['No', 'Yes'][value]  bool_to_str(True)   Notice how value is bool but is used as an int.  Is this this kind of use Pythonic or should it be avoided?     ","Q_Votes":"61"},{"Q_Title":"Is it Pythonic to use bools as ints?","A_Content":"  Using a bool as an int is quite OK because bool is s subclass of int.  >>> isinstance(True, int) True >>> isinstance(False, int) True   About your code: Putting it in a one-line function like that is over the top. Readers need to find your function source or docs and read it (the name of the function doesn't tell you much). This interrupts the flow. Just put it inline and don't use a list (built at run time), use a tuple (built at compile time if the values are constants). Example:  print foo, bar, num_things, (\"OK\", \"Too many!)[num_things > max_things]      ","Language":"Python","Tags":["boolean","python"],"URL":"https://stackoverflow.com/questions/3174392/is-it-pythonic-to-use-bools-as-ints","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    False is equivalent to 0 and True is equivalent 1 so it's possible to do something like this:  def bool_to_str(value):     \"\"\"value should be a bool\"\"\"     return ['No', 'Yes'][value]  bool_to_str(True)   Notice how value is bool but is used as an int.  Is this this kind of use Pythonic or should it be avoided?     ","Q_Votes":"61"},{"Q_Title":"Is it Pythonic to use bools as ints?","A_Content":"  Personally I think it depends on how do you want to use this fact, here are two examples   Just simply use boolean as conditional statement is fine. People do this all the time.  a = 0 if a:     do something  However say you want to count how many items has succeed, the code maybe not very friendly for other people to read.  def succeed(val):     if do_something(val):         return True     else:         return False  count = 0 values = [some values to process] for val in values:     count += succeed(val)    But I do see the production code look like this.  all_successful = all([succeed(val) for val in values]) at_least_one_successful = any([succeed(val) for val in values]) total_number_of_successful = sum([succeed(val) for val in values])      ","Language":"Python","Tags":["boolean","python"],"URL":"https://stackoverflow.com/questions/3174392/is-it-pythonic-to-use-bools-as-ints","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    False is equivalent to 0 and True is equivalent 1 so it's possible to do something like this:  def bool_to_str(value):     \"\"\"value should be a bool\"\"\"     return ['No', 'Yes'][value]  bool_to_str(True)   Notice how value is bool but is used as an int.  Is this this kind of use Pythonic or should it be avoided?     ","Q_Votes":"61"},{"Q_Title":"Why #egg=foo when pip-installing from git repo","A_Content":"  per pip install -h the \"egg\" string is the directory that gets checked out as part of the install     ","Language":"Python","Tags":["python","package","pip"],"URL":"https://stackoverflow.com/questions/11835396/why-egg-foo-when-pip-installing-from-git-repo","A_Votes":"21","_type":"dict","isAccepted":"Yes","Q_Content":"    When I do a \"pip install -e ...\" to install from a git repo, I have to specify #egg=somename or pip complains. For example:  pip install -e git://github.com/hiidef/oauth2app.git#egg=oauth2app   What's the significance of this \"egg\" string?     ","Q_Votes":"62"},{"Q_Title":"Why #egg=foo when pip-installing from git repo","A_Content":"  You have to include #egg=Package so pip knows what to expect at that URL. See https://pip.pypa.io/en/stable/reference/pip_install/#vcs-support  more on eggs     ","Language":"Python","Tags":["python","package","pip"],"URL":"https://stackoverflow.com/questions/11835396/why-egg-foo-when-pip-installing-from-git-repo","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    When I do a \"pip install -e ...\" to install from a git repo, I have to specify #egg=somename or pip complains. For example:  pip install -e git://github.com/hiidef/oauth2app.git#egg=oauth2app   What's the significance of this \"egg\" string?     ","Q_Votes":"62"},{"Q_Title":"Why #egg=foo when pip-installing from git repo","A_Content":"  https://pip.pypa.io/en/stable/reference/pip_install/#vcs-support says:     The \"project name\" component of the url suffix \"egg=-\" is used by pip in its dependency logic to identify   the project prior to pip downloading and analyzing the metadata. The   optional \"version\" component of the egg name is not functionally   important. It merely provides a human-readable clue as to what version   is in use. For projects where setup.py is not in the root of project,   \"subdirectory\" component is used. Value of \"subdirectory\" component   should be a path starting from root of the project to where setup.py   is located.   From this I deduce that the egg value is only used for dependency checks and therefore I think, by convention, the package name (i.e. some-pypi-package-name) should be used, not any contained folder (i.e. some_pypi_package_name)     ","Language":"Python","Tags":["python","package","pip"],"URL":"https://stackoverflow.com/questions/11835396/why-egg-foo-when-pip-installing-from-git-repo","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    When I do a \"pip install -e ...\" to install from a git repo, I have to specify #egg=somename or pip complains. For example:  pip install -e git://github.com/hiidef/oauth2app.git#egg=oauth2app   What's the significance of this \"egg\" string?     ","Q_Votes":"62"},{"Q_Title":"Text processing - Python vs Perl performance [closed]","A_Content":"  This is exactly the sort of stuff that Perl was designed to do, so it doesn't surprise me that it's faster.  One easy optimization in your Python code would be to precompile those regexes, so they aren't getting recompiled each time.  exists_re = re.compile(r'^(.*?) INFO.*Such a record already exists') location_re = re.compile(r'^AwbLocation (.*?) insert into')   And then in your loop:  mprev = exists_re.search(currline)   and  mcurr = location_re.search(currline)   That by itself won't magically bring your Python script in line with your Perl script, but repeatedly calling re in a loop without compiling first is bad practice in Python.     ","Language":"Python","Tags":["python","regex","performance","perl","text-processing"],"URL":"https://stackoverflow.com/questions/12793562/text-processing-python-vs-perl-performance","A_Votes":"17","_type":"dict","isAccepted":"No","Q_Content":"    Here is my Perl and Python script to do some simple text processing from about 21 log files, each about 300 KB to 1 MB (maximum) x 5 times repeated (total of 125 files, due to the log repeated 5 times).  Python Code (code modified to use compiled re and using re.I)  #!/usr/bin/python  import re import fileinput  exists_re = re.compile(r'^(.*?) INFO.*Such a record already exists', re.I) location_re = re.compile(r'^AwbLocation (.*?) insert into', re.I)  for line in fileinput.input():     fn = fileinput.filename()     currline = line.rstrip()      mprev = exists_re.search(currline)      if(mprev):         xlogtime = mprev.group(1)      mcurr = location_re.search(currline)      if(mcurr):         print fn, xlogtime, mcurr.group(1)   Perl Code  #!/usr/bin/perl  while (<>) {     chomp;      if (m/^(.*?) INFO.*Such a record already exists/i) {         $xlogtime = $1;     }      if (m/^AwbLocation (.*?) insert into/i) {         print \"$ARGV $xlogtime $1\\n\";     } }   And, on my PC both code generates exactly the same result file of 10,790 lines. And, here is the timing done on Cygwin's Perl and Python implementations.  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.py *log* *log* *log* *log* *log* > summarypy.log  real    0m8.185s user    0m8.018s sys     0m0.092s  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.pl *log* *log* *log* *log* *log* > summarypl.log  real    0m1.481s user    0m1.294s sys     0m0.124s   Originally, it took 10.2 seconds using Python and only 1.9 secs using Perl for this simple text processing.  (UPDATE) but, after the compiled re version of Python, it now takes 8.2 seconds in Python and 1.5 seconds in Perl. Still Perl is much faster.  Is there a way to improve the speed of Python at all OR it is obvious that Perl will be the speedy one for simple text processing.  By the way this was not the only test I did for simple text processing... And, each different way I make the source code, always always Perl wins by a large margin. And, not once did Python performed better for simple m/regex/ match and print stuff.     Please do not suggest to use C, C++, Assembly, other flavours of   Python, etc.      I am looking for a solution using Standard Python with its built-in   modules compared against Standard Perl (not even using the modules).   Boy, I wish to use Python for all my tasks due to its readability, but   to give up speed, I don't think so.      So, please suggest how can the code be improved to have comparable   results with Perl.   UPDATE: 2012-10-18  As other users suggested, Perl has its place and Python has its.  So, for this question, one can safely conclude that for simple regex match on each line for hundreds or thousands of text files and writing the results to a file (or printing to screen), Perl will always, always WIN in performance for this job. It as simple as that.  Please note that when I say Perl wins in performance... only standard Perl and Python is compared... not resorting to some obscure modules (obscure for a normal user like me) and also not calling C, C++, assembly libraries from Python or Perl. We don't have time to learn all these extra steps and installation for a simple text matching job.  So, Perl rocks for text processing and regex.  Python has its place to rock in other places.  Update 2013-05-29: An excellent article that does similar comparison is here. Perl again wins for simple text matching... And for more details, read the article.     ","Q_Votes":"62"},{"Q_Title":"Text processing - Python vs Perl performance [closed]","A_Content":"  Hypothesis: Perl spends less time backtracking in lines that don't match due to optimisations it has that Python doesn't.  What do you get by replacing  ^(.*?) INFO.*Such a record already exists   with  ^((?:(?! INFO).)*?) INFO.*Such a record already    or  ^(?>(.*?) INFO).*Such a record already exists      ","Language":"Python","Tags":["python","regex","performance","perl","text-processing"],"URL":"https://stackoverflow.com/questions/12793562/text-processing-python-vs-perl-performance","A_Votes":"14","_type":"dict","isAccepted":"No","Q_Content":"    Here is my Perl and Python script to do some simple text processing from about 21 log files, each about 300 KB to 1 MB (maximum) x 5 times repeated (total of 125 files, due to the log repeated 5 times).  Python Code (code modified to use compiled re and using re.I)  #!/usr/bin/python  import re import fileinput  exists_re = re.compile(r'^(.*?) INFO.*Such a record already exists', re.I) location_re = re.compile(r'^AwbLocation (.*?) insert into', re.I)  for line in fileinput.input():     fn = fileinput.filename()     currline = line.rstrip()      mprev = exists_re.search(currline)      if(mprev):         xlogtime = mprev.group(1)      mcurr = location_re.search(currline)      if(mcurr):         print fn, xlogtime, mcurr.group(1)   Perl Code  #!/usr/bin/perl  while (<>) {     chomp;      if (m/^(.*?) INFO.*Such a record already exists/i) {         $xlogtime = $1;     }      if (m/^AwbLocation (.*?) insert into/i) {         print \"$ARGV $xlogtime $1\\n\";     } }   And, on my PC both code generates exactly the same result file of 10,790 lines. And, here is the timing done on Cygwin's Perl and Python implementations.  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.py *log* *log* *log* *log* *log* > summarypy.log  real    0m8.185s user    0m8.018s sys     0m0.092s  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.pl *log* *log* *log* *log* *log* > summarypl.log  real    0m1.481s user    0m1.294s sys     0m0.124s   Originally, it took 10.2 seconds using Python and only 1.9 secs using Perl for this simple text processing.  (UPDATE) but, after the compiled re version of Python, it now takes 8.2 seconds in Python and 1.5 seconds in Perl. Still Perl is much faster.  Is there a way to improve the speed of Python at all OR it is obvious that Perl will be the speedy one for simple text processing.  By the way this was not the only test I did for simple text processing... And, each different way I make the source code, always always Perl wins by a large margin. And, not once did Python performed better for simple m/regex/ match and print stuff.     Please do not suggest to use C, C++, Assembly, other flavours of   Python, etc.      I am looking for a solution using Standard Python with its built-in   modules compared against Standard Perl (not even using the modules).   Boy, I wish to use Python for all my tasks due to its readability, but   to give up speed, I don't think so.      So, please suggest how can the code be improved to have comparable   results with Perl.   UPDATE: 2012-10-18  As other users suggested, Perl has its place and Python has its.  So, for this question, one can safely conclude that for simple regex match on each line for hundreds or thousands of text files and writing the results to a file (or printing to screen), Perl will always, always WIN in performance for this job. It as simple as that.  Please note that when I say Perl wins in performance... only standard Perl and Python is compared... not resorting to some obscure modules (obscure for a normal user like me) and also not calling C, C++, assembly libraries from Python or Perl. We don't have time to learn all these extra steps and installation for a simple text matching job.  So, Perl rocks for text processing and regex.  Python has its place to rock in other places.  Update 2013-05-29: An excellent article that does similar comparison is here. Perl again wins for simple text matching... And for more details, read the article.     ","Q_Votes":"62"},{"Q_Title":"Text processing - Python vs Perl performance [closed]","A_Content":"  Function calls are a bit expensive in terms of time in Python. And yet you have a loop invariant function call to get the file name inside the loop:  fn = fileinput.filename()   Move this line above the for loop and you should see some improvement to your Python timing. Probably not enough to beat out Perl though.     ","Language":"Python","Tags":["python","regex","performance","perl","text-processing"],"URL":"https://stackoverflow.com/questions/12793562/text-processing-python-vs-perl-performance","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Here is my Perl and Python script to do some simple text processing from about 21 log files, each about 300 KB to 1 MB (maximum) x 5 times repeated (total of 125 files, due to the log repeated 5 times).  Python Code (code modified to use compiled re and using re.I)  #!/usr/bin/python  import re import fileinput  exists_re = re.compile(r'^(.*?) INFO.*Such a record already exists', re.I) location_re = re.compile(r'^AwbLocation (.*?) insert into', re.I)  for line in fileinput.input():     fn = fileinput.filename()     currline = line.rstrip()      mprev = exists_re.search(currline)      if(mprev):         xlogtime = mprev.group(1)      mcurr = location_re.search(currline)      if(mcurr):         print fn, xlogtime, mcurr.group(1)   Perl Code  #!/usr/bin/perl  while (<>) {     chomp;      if (m/^(.*?) INFO.*Such a record already exists/i) {         $xlogtime = $1;     }      if (m/^AwbLocation (.*?) insert into/i) {         print \"$ARGV $xlogtime $1\\n\";     } }   And, on my PC both code generates exactly the same result file of 10,790 lines. And, here is the timing done on Cygwin's Perl and Python implementations.  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.py *log* *log* *log* *log* *log* > summarypy.log  real    0m8.185s user    0m8.018s sys     0m0.092s  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.pl *log* *log* *log* *log* *log* > summarypl.log  real    0m1.481s user    0m1.294s sys     0m0.124s   Originally, it took 10.2 seconds using Python and only 1.9 secs using Perl for this simple text processing.  (UPDATE) but, after the compiled re version of Python, it now takes 8.2 seconds in Python and 1.5 seconds in Perl. Still Perl is much faster.  Is there a way to improve the speed of Python at all OR it is obvious that Perl will be the speedy one for simple text processing.  By the way this was not the only test I did for simple text processing... And, each different way I make the source code, always always Perl wins by a large margin. And, not once did Python performed better for simple m/regex/ match and print stuff.     Please do not suggest to use C, C++, Assembly, other flavours of   Python, etc.      I am looking for a solution using Standard Python with its built-in   modules compared against Standard Perl (not even using the modules).   Boy, I wish to use Python for all my tasks due to its readability, but   to give up speed, I don't think so.      So, please suggest how can the code be improved to have comparable   results with Perl.   UPDATE: 2012-10-18  As other users suggested, Perl has its place and Python has its.  So, for this question, one can safely conclude that for simple regex match on each line for hundreds or thousands of text files and writing the results to a file (or printing to screen), Perl will always, always WIN in performance for this job. It as simple as that.  Please note that when I say Perl wins in performance... only standard Perl and Python is compared... not resorting to some obscure modules (obscure for a normal user like me) and also not calling C, C++, assembly libraries from Python or Perl. We don't have time to learn all these extra steps and installation for a simple text matching job.  So, Perl rocks for text processing and regex.  Python has its place to rock in other places.  Update 2013-05-29: An excellent article that does similar comparison is here. Perl again wins for simple text matching... And for more details, read the article.     ","Q_Votes":"62"},{"Q_Title":"Text processing - Python vs Perl performance [closed]","A_Content":"  In general, all artificial benchmarks are evil. However, everything else being equal (algorithmic approach), you can make improvements on a relative basis. However, it should be noted that I don't use Perl, so I can't argue in its favor. That being said, with Python you can try using Pyrex or Cython to improve performance. Or, if you are adventurous, you can try converting the Python code into C++ via ShedSkin (which works for most of the core language, and some - but not all, of the core modules).  Nevertheless, you can follow some of the tips posted here:  http://wiki.python.org/moin/PythonSpeed/PerformanceTips     ","Language":"Python","Tags":["python","regex","performance","perl","text-processing"],"URL":"https://stackoverflow.com/questions/12793562/text-processing-python-vs-perl-performance","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Here is my Perl and Python script to do some simple text processing from about 21 log files, each about 300 KB to 1 MB (maximum) x 5 times repeated (total of 125 files, due to the log repeated 5 times).  Python Code (code modified to use compiled re and using re.I)  #!/usr/bin/python  import re import fileinput  exists_re = re.compile(r'^(.*?) INFO.*Such a record already exists', re.I) location_re = re.compile(r'^AwbLocation (.*?) insert into', re.I)  for line in fileinput.input():     fn = fileinput.filename()     currline = line.rstrip()      mprev = exists_re.search(currline)      if(mprev):         xlogtime = mprev.group(1)      mcurr = location_re.search(currline)      if(mcurr):         print fn, xlogtime, mcurr.group(1)   Perl Code  #!/usr/bin/perl  while (<>) {     chomp;      if (m/^(.*?) INFO.*Such a record already exists/i) {         $xlogtime = $1;     }      if (m/^AwbLocation (.*?) insert into/i) {         print \"$ARGV $xlogtime $1\\n\";     } }   And, on my PC both code generates exactly the same result file of 10,790 lines. And, here is the timing done on Cygwin's Perl and Python implementations.  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.py *log* *log* *log* *log* *log* > summarypy.log  real    0m8.185s user    0m8.018s sys     0m0.092s  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.pl *log* *log* *log* *log* *log* > summarypl.log  real    0m1.481s user    0m1.294s sys     0m0.124s   Originally, it took 10.2 seconds using Python and only 1.9 secs using Perl for this simple text processing.  (UPDATE) but, after the compiled re version of Python, it now takes 8.2 seconds in Python and 1.5 seconds in Perl. Still Perl is much faster.  Is there a way to improve the speed of Python at all OR it is obvious that Perl will be the speedy one for simple text processing.  By the way this was not the only test I did for simple text processing... And, each different way I make the source code, always always Perl wins by a large margin. And, not once did Python performed better for simple m/regex/ match and print stuff.     Please do not suggest to use C, C++, Assembly, other flavours of   Python, etc.      I am looking for a solution using Standard Python with its built-in   modules compared against Standard Perl (not even using the modules).   Boy, I wish to use Python for all my tasks due to its readability, but   to give up speed, I don't think so.      So, please suggest how can the code be improved to have comparable   results with Perl.   UPDATE: 2012-10-18  As other users suggested, Perl has its place and Python has its.  So, for this question, one can safely conclude that for simple regex match on each line for hundreds or thousands of text files and writing the results to a file (or printing to screen), Perl will always, always WIN in performance for this job. It as simple as that.  Please note that when I say Perl wins in performance... only standard Perl and Python is compared... not resorting to some obscure modules (obscure for a normal user like me) and also not calling C, C++, assembly libraries from Python or Perl. We don't have time to learn all these extra steps and installation for a simple text matching job.  So, Perl rocks for text processing and regex.  Python has its place to rock in other places.  Update 2013-05-29: An excellent article that does similar comparison is here. Perl again wins for simple text matching... And for more details, read the article.     ","Q_Votes":"62"},{"Q_Title":"Text processing - Python vs Perl performance [closed]","A_Content":"  I expect Perl be faster. Just being curious, can you try the following?  #!/usr/bin/python  import re import glob import sys import os  exists_re = re.compile(r'^(.*?) INFO.*Such a record already exists', re.I) location_re = re.compile(r'^AwbLocation (.*?) insert into', re.I)  for mask in sys.argv[1:]:     for fname in glob.glob(mask):         if os.path.isfile(fname):             f = open(fname)             for line in f:                 mex = exists_re.search(line)                 if mex:                     xlogtime = mex.group(1)                  mloc = location_re.search(line)                 if mloc:                     print fname, xlogtime, mloc.group(1)             f.close()   Update as reaction to \"it is too complex\".  Of course it looks more complex than the Perl version. The Perl was built around the regular expressions. This way, you can hardly find interpreted language that is faster in regular expressions. The Perl syntax...  while (<>) {     ... }   ... also hides a lot of things that have to be done somehow in a more general language. On the other hand, it is quite easy to make the Python code more readable if you move the unreadable part out:  #!/usr/bin/python  import re import glob import sys import os  def input_files():     '''The generator loops through the files defined by masks from cmd.'''     for mask in sys.argv[1:]:         for fname in glob.glob(mask):             if os.path.isfile(fname):                 yield fname   exists_re = re.compile(r'^(.*?) INFO.*Such a record already exists', re.I) location_re = re.compile(r'^AwbLocation (.*?) insert into', re.I)  for fname in input_files():     with open(fname) as f:        # Now the f.close() is done automatically         for line in f:             mex = exists_re.search(line)             if mex:                 xlogtime = mex.group(1)              mloc = location_re.search(line)             if mloc:                 print fname, xlogtime, mloc.group(1)   Here the def input_files() could be placed elsewhere (say in another module), or it can be reused. It is possible to mimic even the Perl's while (<>) {...} easily, even though not the same way syntactically:  #!/usr/bin/python  import re import glob import sys import os  def input_lines():     '''The generator loops through the lines of the files defined by masks from cmd.'''     for mask in sys.argv[1:]:         for fname in glob.glob(mask):             if os.path.isfile(fname):                 with open(fname) as f: # now the f.close() is done automatically                     for line in f:                         yield fname, line  exists_re = re.compile(r'^(.*?) INFO.*Such a record already exists', re.I) location_re = re.compile(r'^AwbLocation (.*?) insert into', re.I)  for fname, line in input_lines():     mex = exists_re.search(line)     if mex:         xlogtime = mex.group(1)      mloc = location_re.search(line)     if mloc:         print fname, xlogtime, mloc.group(1)   Then the last for may look as easy (in principle) as the Perl's while (<>) {...}. Such readability enhancements are more difficult in Perl.  Anyway, it will not make the Python program faster. Perl will be faster again here. Perl is a file/text cruncher. But--in my opinion--Python is a better programming language for more general purposes.     ","Language":"Python","Tags":["python","regex","performance","perl","text-processing"],"URL":"https://stackoverflow.com/questions/12793562/text-processing-python-vs-perl-performance","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Here is my Perl and Python script to do some simple text processing from about 21 log files, each about 300 KB to 1 MB (maximum) x 5 times repeated (total of 125 files, due to the log repeated 5 times).  Python Code (code modified to use compiled re and using re.I)  #!/usr/bin/python  import re import fileinput  exists_re = re.compile(r'^(.*?) INFO.*Such a record already exists', re.I) location_re = re.compile(r'^AwbLocation (.*?) insert into', re.I)  for line in fileinput.input():     fn = fileinput.filename()     currline = line.rstrip()      mprev = exists_re.search(currline)      if(mprev):         xlogtime = mprev.group(1)      mcurr = location_re.search(currline)      if(mcurr):         print fn, xlogtime, mcurr.group(1)   Perl Code  #!/usr/bin/perl  while (<>) {     chomp;      if (m/^(.*?) INFO.*Such a record already exists/i) {         $xlogtime = $1;     }      if (m/^AwbLocation (.*?) insert into/i) {         print \"$ARGV $xlogtime $1\\n\";     } }   And, on my PC both code generates exactly the same result file of 10,790 lines. And, here is the timing done on Cygwin's Perl and Python implementations.  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.py *log* *log* *log* *log* *log* > summarypy.log  real    0m8.185s user    0m8.018s sys     0m0.092s  User@UserHP /cygdrive/d/tmp/Clipboard # time /tmp/scripts/python/afs/process_file.pl *log* *log* *log* *log* *log* > summarypl.log  real    0m1.481s user    0m1.294s sys     0m0.124s   Originally, it took 10.2 seconds using Python and only 1.9 secs using Perl for this simple text processing.  (UPDATE) but, after the compiled re version of Python, it now takes 8.2 seconds in Python and 1.5 seconds in Perl. Still Perl is much faster.  Is there a way to improve the speed of Python at all OR it is obvious that Perl will be the speedy one for simple text processing.  By the way this was not the only test I did for simple text processing... And, each different way I make the source code, always always Perl wins by a large margin. And, not once did Python performed better for simple m/regex/ match and print stuff.     Please do not suggest to use C, C++, Assembly, other flavours of   Python, etc.      I am looking for a solution using Standard Python with its built-in   modules compared against Standard Perl (not even using the modules).   Boy, I wish to use Python for all my tasks due to its readability, but   to give up speed, I don't think so.      So, please suggest how can the code be improved to have comparable   results with Perl.   UPDATE: 2012-10-18  As other users suggested, Perl has its place and Python has its.  So, for this question, one can safely conclude that for simple regex match on each line for hundreds or thousands of text files and writing the results to a file (or printing to screen), Perl will always, always WIN in performance for this job. It as simple as that.  Please note that when I say Perl wins in performance... only standard Perl and Python is compared... not resorting to some obscure modules (obscure for a normal user like me) and also not calling C, C++, assembly libraries from Python or Perl. We don't have time to learn all these extra steps and installation for a simple text matching job.  So, Perl rocks for text processing and regex.  Python has its place to rock in other places.  Update 2013-05-29: An excellent article that does similar comparison is here. Perl again wins for simple text matching... And for more details, read the article.     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  If you just plan on doing Python dev, I'd just go with Platform Runtime Binary.  After that, I'd follow the instructions http://pydev.org/download.html and http://pydev.org/manual_101_root.html to install PyDev.  I use the same setup for Python development.  I also have the RadRails plugin for Ruby on Rails development.     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"29","_type":"dict","isAccepted":"Yes","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  PyDev was acquired by Aptana, so you might want to check that one out as well.     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  Assuming Python, and nothing else - I would just get the \"Runtime Binary\" edition of Eclipse, and add the PyDev extension. That way Eclipse starts up lightning fast, consumes less memory and generally gets in your way less. On top of that, you can always add in whatever extensions/plugins you find you need. The runtime is generally around 50MB, instead of the usual 100+ for the SDK or other versions.  You can always find the latest version here:  http://download.eclipse.org/eclipse/downloads/  At the time of this posting, that would be 3.6.1:  http://download.eclipse.org/eclipse/downloads/drops/R-3.6.1-201009090800/index.php#PlatformRuntime     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  If you are getting started, I would recommend you python easyeclipse.  Pydev can give some incompatibilities when using it together with other extensions.     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  A useful shortcut is to download EasyEclipse for PyDev.  This is a version of Eclipse already pre-configured for pydev, and seems to be easier to install than gathering all of the Eclipse pieces yourself.  Unfortunately it uses a rather old version of PyDev, but this is easily remedied by going to Help > Software Updates > and letting Eclipse grab the latest version (you'll need to change the PyDev location to SourceForge before doing this).     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  I prefer that you should use Luna which is a tool for Java developers creating Java EE and Web applications, surely you can add PyDev to it.  As you are getting started with python, eclipse and pydev, you probably need step-by-step process.  Either follow these simple steps or Watch this video.  Step 1: Download and install Eclipse(Luna)  Step 2: Open Eclipse >> Help >> Install New Software...  Step 3: In the 'Work with' textfield type : http://pydev.org/updates  Step 4: select checkbox PyDev >> next >> next >> finish  Step 5: It Will install but later a new frame will open,make sure to check on \"Brainwy Software,PyDev,Brainwy >> OK  Eclipse will restart after you click ok.   Step 6: Click on File >> New >> Project >> PyDev Project >>  Now you have to add Interpreter.  Step 7: Click on \"Please configure an interpreter before proceeding\"  Step 8: Click on \"Manual Config\"  Step 9: Click on \"New\" then give interpreter Name(python 2.x.x or python 3.x.x the version you are using) or any other name as you like.  Step 10: Click on \"Browse\" to give path.  If you are using Windows it probably would be in C: drive,  If you are using Ubuntu it would be in \"/usr/bin/python2.x\" or use command \"whereis python\" in terminal.  Step 11: After this Select the interpreter >> Finish.   And you are good to go.     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  I'd recommend http://www.liclipse.com/ if you want a simple and straightforward setup (especially for web development, as it also has editors for web-related contents, such as html, css, javascript) or getting only the Platform Runtime Binary (which is the lightest released Eclipse with things needed for Pydev, around 47 MB -- it can be gotten at: http://download.eclipse.org/eclipse/downloads/, selecting the version you want and then looking for the Platform Runtime Binary).  The install instructions are at: http://pydev.org/manual_101_install.html (and from there a getting started manual follows).     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  pydev and Python2.6 doesnt work with eclipse for C++. Download the classic version and you should be good.      ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  I think that the Aptana distribution of Eclipse the the easiest way to get PyDev these days...especially since it's now free for the full version.  If you download the Studio from here:  http://www.aptana.org/  You can easily install PyDev from their plugin manager once it's up and running.     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  Usually no-one mention but Eclipse do have Python support in its DLTK (dynamic languages toolkit) plugin set. You certainly may want to try it.  Anyway it is not as much functional as PyDev plugin thus you can have it securely. PyDev asks to accept its certificate that is vulnerability to MIM attacks.  You may want to consider PyCharm IDE as it has also PyDev work included. PyCharm team has own PyDev branch and had some work on its debugger. Some details on this collaboration.     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  I use J2EE Eclipse for Python and Java development. It works well. But Classic Eclipse should be enought.     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  I would just get [ JetBrains PyCharm Community Edition 4.5.3 ]. its FREE, fully featured and most of all, its dedicated for Python development.  there are 3 other IDE's that are great too, and they do over 30 languages each, without needing plugins and additional 18 more by adding plugins. check out --> Brackets, Atom and Visual Studio Code. they are all free. I suggest checking out PyCharm first.     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"Which Eclipse package should I download for PyDev?","A_Content":"  Easy Eclipse for python is good and  light weight tool. But, then you dont get any of the extra features from it.  I tried to start with Django learning, but thn this version wasn't enough for it. If you only opt fr simple python codes, its a very good tool.     ","Language":"Python","Tags":["python","eclipse","package","pydev"],"URL":"https://stackoverflow.com/questions/243962/which-eclipse-package-should-i-download-for-pydev","A_Votes":"-1","_type":"dict","isAccepted":"No","Q_Content":"    Which Eclipse package should I choose for Python development with PyDev?  Nothing on the Eclipse homepage tells me what to choose, and the PyDev documentation assumes I already have Eclipse installed. Does it matter which Eclipse package I choose?     ","Q_Votes":"62"},{"Q_Title":"For what purpose Django is used for? [closed]","A_Content":"  No. It's not for making websites. Your sample just sounds like you want plain old HTML.  Django is for creating web applications. That is, software, normally backed by a database, that includes some kind of interactivity, that operates through a browser.  A Framework provides a structure and common methods for making this kind of software.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/12797999/for-what-purpose-django-is-used-for","A_Votes":"45","_type":"dict","isAccepted":"Yes","Q_Content":"    I heard a lot of people talking about Django on various forums. But I am having a very basic question : What is meant by Framework and why Django is used.  After listening a lot about Django, I ran few chapters for Django (from Djangobook.com). After running these chapters,  I am wondering how Django can be used to create a very simple website. (Website should have few pages like Home, Favorites, About, Contact linked to each other and will be providing static content).   Can Django be used for creation of such website? I searched a lot on internet but couldn't find any relevant examples, I only encountered with the examples for creation of blog, forum sites etc. If Django can be used for creation of this website, what should be the approach.  Can someone please explain this basic term \"Framework\" and its significance?      ","Q_Votes":"62"},{"Q_Title":"For what purpose Django is used for? [closed]","A_Content":"  I think what you're looking for is a very simple CMS (Content Management System), there are many of those available in all kinds of languages/frameworks. Django has django-cms and mezzanine (among others).  What django is really awesome at is building dynamic websites really fast, you don't need to worry about most things, you just define your data model and off you go (almost). If you want to have a better insight into what's possible, have a look at the django tutorial (under \"First Steps\"), it gives you a good introduction to django and how to build websites using it.      ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/12797999/for-what-purpose-django-is-used-for","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I heard a lot of people talking about Django on various forums. But I am having a very basic question : What is meant by Framework and why Django is used.  After listening a lot about Django, I ran few chapters for Django (from Djangobook.com). After running these chapters,  I am wondering how Django can be used to create a very simple website. (Website should have few pages like Home, Favorites, About, Contact linked to each other and will be providing static content).   Can Django be used for creation of such website? I searched a lot on internet but couldn't find any relevant examples, I only encountered with the examples for creation of blog, forum sites etc. If Django can be used for creation of this website, what should be the approach.  Can someone please explain this basic term \"Framework\" and its significance?      ","Q_Votes":"62"},{"Q_Title":"For what purpose Django is used for? [closed]","A_Content":"  Django can be used to create dynamic high-security web applications. For creating a static website like the one you asked, HTML is enough.  Tutorial for creating a django application can be found here.     ","Language":"Python","Tags":["python","django"],"URL":"https://stackoverflow.com/questions/12797999/for-what-purpose-django-is-used-for","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I heard a lot of people talking about Django on various forums. But I am having a very basic question : What is meant by Framework and why Django is used.  After listening a lot about Django, I ran few chapters for Django (from Djangobook.com). After running these chapters,  I am wondering how Django can be used to create a very simple website. (Website should have few pages like Home, Favorites, About, Contact linked to each other and will be providing static content).   Can Django be used for creation of such website? I searched a lot on internet but couldn't find any relevant examples, I only encountered with the examples for creation of blog, forum sites etc. If Django can be used for creation of this website, what should be the approach.  Can someone please explain this basic term \"Framework\" and its significance?      ","Q_Votes":"62"},{"Q_Title":"Is .ix() always better than .loc() and .iloc() since it is faster and supports integer and label access?","A_Content":"  Please refer to the doc Different Choices for Indexing, it states clearly when and why you should use .loc, .iloc over .ix, it's about explicit use case:     .ix supports mixed integer and label based access. It is primarily   label based, but will fall back to integer positional access unless   the corresponding axis is of integer type. .ix is the most general and   will support any of the inputs in .loc and .iloc. .ix also supports   floating point label schemes. .ix is exceptionally useful when dealing   with mixed positional and label based hierachical indexes.      However, when an axis is integer based, ONLY label based access and   not positional access is supported. Thus, in such cases, it’s usually   better to be explicit and use .iloc or .loc.   Hope this helps.  Update 22 Mar 2017  Thanks to comment from @Alexander, Pandas is going to deprecate ix in 0.20, details in here.  One of the strong reason behind is because mixing indexes -- positional and label (effectively using ix) has been a significant source of problems for users.  It is expected to migrate to use iloc and loc instead, here is a link on how to convert code.     ","Language":"Python","Tags":["python","pandas"],"URL":"https://stackoverflow.com/questions/27667759/is-ix-always-better-than-loc-and-iloc-since-it-is-faster-and-supports-i","A_Votes":"64","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm learning the Python pandas library. Coming from an R background, the indexing and selecting functions seem more complicated than they need to be. My understanding it that .loc() is only label based and .iloc() is only integer based.   Why should I ever use .loc() and .iloc() if .ix() is faster and supports integer and label access?      ","Q_Votes":"62"},{"Q_Title":"Is `import module` better coding style than `from module import function`?","A_Content":"  The negatives you list for IM/FPIM can often be ameliorated by appropriate use of an as clause.  from some.package import mymodulewithalongname as mymod can usefully shorten your code and enhance its readability, and if you rename mymodulewithalongname to somethingcompletelydifferent tomorrow, the as clause can be used as a single statement to edit.  Consider your pro-FMIF point 3 (call it R for redirection) vs your pro-FPIM point 2 (call it F for flexibility): R amounts to facilitating the loss of integrity of module boundaries, while F strenghtens it.  Multiple functions, classes and variables in a module are often intended to work together: they should not be independently switched to different meanings.  For example, consider module random and its functions seed and uniform: if you were to switch the import of just one of them to a different module, then you'd break the normal connection between calls to seed and results of calls to uniform.  When a module is well designed, with cohesion and integrity, R's facilitation of breaking down the module's boundaries is actually a negative -- it makes it easier to do something you're better off not doing.  Vice versa, F is what enables coordinated switching of coupled functions, classes, and variables (so, generally, of entities that belong together, by modularity). For example, to make testing repeatable (FPIM pro-point 1), you mock both seed and random in the random module, and if your code follows FPIM, you're all set, coordination guaranteed; but if you have code that has imported the functions directly, you have to hunt down each such module and repeat the mocking over and over and over again.  Making tests perfectly repeatable typically also requires \"coordinated mocking\" of date and time functions -- if you use from datetime import datetime in some modules, you need to find and mock them all (as well as all those doing from time import time, and so forth) to ensure that all the times received when the various parts of the system ask \"so what time is it now?\" are perfectly consistent (if you use FPIM, you just mock the two relevant modules).  I like FPIM, because there's really not much added value by using a multiply qualified name rather than a singly qualified one (while the difference between barenames and qualified names is huge -- you get so much more control with a qualified name, be it singly or multiply, than you possibly ever can with a barename!).  Ah well, can't devote all of the working day to responding to each and every one of your points -- your question should probably be half a dozen questions;-).  I hope this at least addresses \"why is F better than R\" and some of the mocking/testing issues -- it boils down to preserving and enhancing well-designed modularity (via F) rather than undermining it (via R).     ","Language":"Python","Tags":["python","python-import"],"URL":"https://stackoverflow.com/questions/1744258/is-import-module-better-coding-style-than-from-module-import-function","A_Votes":"40","_type":"dict","isAccepted":"Yes","Q_Content":"    Let from module import function be called the FMIF coding style.  Let import module be called the IM coding style.  Let from package import module be called the FPIM coding style.  Why is IM+FPIM considered a better coding style than FMIF? (See this post for the inspiration for this question.)  Here are some criteria which lead me to prefer FMIF over IM:  Shortness of code: It allows me to use shorter function names and thus help stick to the 80 columns-per-line convention.   Readability: chisquare(...) appears more readable than   scipy.stats.stats.chisquare(...). Although this is a subjective criterion, I think most people would agree.  Ease of redirection: If I use FMIF and for some reason at some later time want to redirect python to define function from alt_module instead of module I need to change just one line: from alt_module import function. If I were to use IM, I'd need to change many lines of code.   I realize FPIM goes some way to nullifying the first two issues, but what about the third?  I am interested in all reasons why IM+FPIM may be better than FMIF,  but in particular, I'd be interested in elaboration on the following points mentioned here:  Pros for IM:  ease of mocking/injecting in tests. (I am not very familiar with mocking, though I recently learned what the term means. Can you show code which demonstrates how IM is better than FMIF here?)  ability for a module to change flexibly by redefining some entries. (I must be misunderstanding something, because this seems to be an advantage of FMIF over IM. See my third reason in favor of FMIF above.)  predictable and controllable behavior on serialization and recovery of your data. (I really don't understand how the choice of IM or FMIF affects this issue. Please elaborate.)   I understand that FMIF \"pollutes my namespace\", but beyond being a negative-sounding phrase, I don't appreciate how this hurts the code in any concrete way.   PS. While writing this question I received a warning that the question appears subjective and is likely to be closed. Please don't close it. I'm not looking for subjective opinion, but rather concrete coding situations where IM+FPIM is demonstrably better than FMIF.  Many thanks.     ","Q_Votes":"62"},{"Q_Title":"Is `import module` better coding style than `from module import function`?","A_Content":"  The classic text on this, as so often, is from Fredrik Lundh, the effbot. His advice: always use import - except when you shouldn't.  In other words, be sensible. Personally I find that anything that's several modules deep tends to get imported via from x.y.z import a - the main example being Django models. But as much as anything else it's a matter of style, and you should have a consistent one - especially with modules like datetime, where both the module and the class it contains are called the same thing. Do you need to write datetime.datetime.now() or just datetime.now()? (In my code, always the former.)  Items 1 and 2 in your list of questions seem to be the same issue. Python's dynamic nature means it is fairly simple to replace an item in a module's namespace no matter which of the methods you use. The difficulty comes if one function in a module refers to another, which is the one you want to mock. In this case, importing the module rather than the functions means you can do module.function_to_replace = myreplacementfunc and everything works transparently - but that is as easy to do via FPIM as it is via IM.  I also don't understand how item 3 has anything to do with anything. I think your item 4, however, is based on a bit of a misunderstanding. None of the methods you give will 'pollute your namespace'. What does do that is from module import *, where you have no idea at all what you're importing and so functions can appear in your code with no clue given to the reader where they came from. That's horrible, and should be avoided at all costs.     ","Language":"Python","Tags":["python","python-import"],"URL":"https://stackoverflow.com/questions/1744258/is-import-module-better-coding-style-than-from-module-import-function","A_Votes":"16","_type":"dict","isAccepted":"No","Q_Content":"    Let from module import function be called the FMIF coding style.  Let import module be called the IM coding style.  Let from package import module be called the FPIM coding style.  Why is IM+FPIM considered a better coding style than FMIF? (See this post for the inspiration for this question.)  Here are some criteria which lead me to prefer FMIF over IM:  Shortness of code: It allows me to use shorter function names and thus help stick to the 80 columns-per-line convention.   Readability: chisquare(...) appears more readable than   scipy.stats.stats.chisquare(...). Although this is a subjective criterion, I think most people would agree.  Ease of redirection: If I use FMIF and for some reason at some later time want to redirect python to define function from alt_module instead of module I need to change just one line: from alt_module import function. If I were to use IM, I'd need to change many lines of code.   I realize FPIM goes some way to nullifying the first two issues, but what about the third?  I am interested in all reasons why IM+FPIM may be better than FMIF,  but in particular, I'd be interested in elaboration on the following points mentioned here:  Pros for IM:  ease of mocking/injecting in tests. (I am not very familiar with mocking, though I recently learned what the term means. Can you show code which demonstrates how IM is better than FMIF here?)  ability for a module to change flexibly by redefining some entries. (I must be misunderstanding something, because this seems to be an advantage of FMIF over IM. See my third reason in favor of FMIF above.)  predictable and controllable behavior on serialization and recovery of your data. (I really don't understand how the choice of IM or FMIF affects this issue. Please elaborate.)   I understand that FMIF \"pollutes my namespace\", but beyond being a negative-sounding phrase, I don't appreciate how this hurts the code in any concrete way.   PS. While writing this question I received a warning that the question appears subjective and is likely to be closed. Please don't close it. I'm not looking for subjective opinion, but rather concrete coding situations where IM+FPIM is demonstrably better than FMIF.  Many thanks.     ","Q_Votes":"62"},{"Q_Title":"Is `import module` better coding style than `from module import function`?","A_Content":"  Like Alex Martelli, I am fond of using as when importing a function.  One thing I have done is to use some prefix on all the functions that were imported from the same module:  from random import seed as r_seed from random import random as r_random   r_seed is shorter to type than random.seed but somewhat preserves the module boundaries.  Someone casually looking at your code can see r_seed() and r_random() and have a chance to grok that they are related.  Of course, you can always simply do:  import random as r   and then use r.random() and r.seed(), which may be the ideal compromise for this case.  I only use the prefix trick when I'm importing one or two functions from a module.  When I want to use many functions from the same module, I'll import the module, perhaps with an as to shorten the name.     ","Language":"Python","Tags":["python","python-import"],"URL":"https://stackoverflow.com/questions/1744258/is-import-module-better-coding-style-than-from-module-import-function","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Let from module import function be called the FMIF coding style.  Let import module be called the IM coding style.  Let from package import module be called the FPIM coding style.  Why is IM+FPIM considered a better coding style than FMIF? (See this post for the inspiration for this question.)  Here are some criteria which lead me to prefer FMIF over IM:  Shortness of code: It allows me to use shorter function names and thus help stick to the 80 columns-per-line convention.   Readability: chisquare(...) appears more readable than   scipy.stats.stats.chisquare(...). Although this is a subjective criterion, I think most people would agree.  Ease of redirection: If I use FMIF and for some reason at some later time want to redirect python to define function from alt_module instead of module I need to change just one line: from alt_module import function. If I were to use IM, I'd need to change many lines of code.   I realize FPIM goes some way to nullifying the first two issues, but what about the third?  I am interested in all reasons why IM+FPIM may be better than FMIF,  but in particular, I'd be interested in elaboration on the following points mentioned here:  Pros for IM:  ease of mocking/injecting in tests. (I am not very familiar with mocking, though I recently learned what the term means. Can you show code which demonstrates how IM is better than FMIF here?)  ability for a module to change flexibly by redefining some entries. (I must be misunderstanding something, because this seems to be an advantage of FMIF over IM. See my third reason in favor of FMIF above.)  predictable and controllable behavior on serialization and recovery of your data. (I really don't understand how the choice of IM or FMIF affects this issue. Please elaborate.)   I understand that FMIF \"pollutes my namespace\", but beyond being a negative-sounding phrase, I don't appreciate how this hurts the code in any concrete way.   PS. While writing this question I received a warning that the question appears subjective and is likely to be closed. Please don't close it. I'm not looking for subjective opinion, but rather concrete coding situations where IM+FPIM is demonstrably better than FMIF.  Many thanks.     ","Q_Votes":"62"},{"Q_Title":"Is `import module` better coding style than `from module import function`?","A_Content":"  Great answers here (I upvoted them all), and here are my thoughts on this matter:  First, addressing each of your bullets:  (Allegedly) Pros of FMIF:   Shortness of code: shorter function names help stick to the 80 columns-per-line.   Perhaps, but module names are usually short enough so this is not relevant. Sure, there's datetime, but also os, re, sys, etc. And Python has free line breaks inside { [ (. And for nested modules there's always as in both IM and FPIM   Readability: chisquare(...) appears more readable than scipy.stats.stats.chisquare(...).    Strongly disagree. When reading foreign code (or my own code after a few months) it's hard to know where each function comes from. Qualified names saves me from going back and forth from line 2345 to module declarations header. And it also gives you context: \"chisquare? What's that? Oh, it's from scypy? Ok, some math-related stuff then\". And, once again, you can always abbreviate scipy.stats.stats as scypyst. scypyst.chisquare(...) is short enough with all benefits of a qualified name.  import os.path as osp is another good example, considering it's very common to chain 3 or more of its functions together in a single call: join(expanduser(),basename(splitext())) etc.   Ease of redirection: one-line redefinition of a function from altmodule instead of module.   How often you want to redefine a single function but not whole module? Module boundaries and function coordination should be preserved, and Alex already explained this in great depth. For most (all?) real-world scenarios, if alt_module.x is a viable replacement for module.x, then probably alt_module itself is a drop in alternative for module, so both IM and FPIM are one-liners just like FMIF, provided you use as.   I realize FPIM goes some way to nullifying the first two issues...    Actually, as is the one that mitigates the first 2 issues (and the 3rd), not FPIM. You can use IM for that too:  import some.long.package.path.x as x for the same result as FPIM.    So none of the above are really pros of FMIF. And the reasons I prefer IM/FPIM are:  For the sake of simplicity and consistency, when I import something, either IM or FPIM, I'm always importing a module, not an object from a module. Remember FMIF can be (ab-)used to import functions, classes, variables, or even other modules! Think about the mess of from somemodule import sys, somevar, os, SomeClass, datetime, someFunc.  Also, if you want more than a single object from a module, FMIF will pollute your namespace more than IM or FPIM, which will use a single name no matter how many objects you want to use. And such objects will have a qualified  name, which is a pro, not a con: as I've said in issue 2, IMHO a it improves readability.  it all comes down to consistency, simplicity, organization. \"Import modules, not objects\" is a good, easy mind model to stick with.     ","Language":"Python","Tags":["python","python-import"],"URL":"https://stackoverflow.com/questions/1744258/is-import-module-better-coding-style-than-from-module-import-function","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Let from module import function be called the FMIF coding style.  Let import module be called the IM coding style.  Let from package import module be called the FPIM coding style.  Why is IM+FPIM considered a better coding style than FMIF? (See this post for the inspiration for this question.)  Here are some criteria which lead me to prefer FMIF over IM:  Shortness of code: It allows me to use shorter function names and thus help stick to the 80 columns-per-line convention.   Readability: chisquare(...) appears more readable than   scipy.stats.stats.chisquare(...). Although this is a subjective criterion, I think most people would agree.  Ease of redirection: If I use FMIF and for some reason at some later time want to redirect python to define function from alt_module instead of module I need to change just one line: from alt_module import function. If I were to use IM, I'd need to change many lines of code.   I realize FPIM goes some way to nullifying the first two issues, but what about the third?  I am interested in all reasons why IM+FPIM may be better than FMIF,  but in particular, I'd be interested in elaboration on the following points mentioned here:  Pros for IM:  ease of mocking/injecting in tests. (I am not very familiar with mocking, though I recently learned what the term means. Can you show code which demonstrates how IM is better than FMIF here?)  ability for a module to change flexibly by redefining some entries. (I must be misunderstanding something, because this seems to be an advantage of FMIF over IM. See my third reason in favor of FMIF above.)  predictable and controllable behavior on serialization and recovery of your data. (I really don't understand how the choice of IM or FMIF affects this issue. Please elaborate.)   I understand that FMIF \"pollutes my namespace\", but beyond being a negative-sounding phrase, I don't appreciate how this hurts the code in any concrete way.   PS. While writing this question I received a warning that the question appears subjective and is likely to be closed. Please don't close it. I'm not looking for subjective opinion, but rather concrete coding situations where IM+FPIM is demonstrably better than FMIF.  Many thanks.     ","Q_Votes":"62"},{"Q_Title":"Is `import module` better coding style than `from module import function`?","A_Content":"  I agree with MestreLion the most here (and so an upvote).   My perspective: I review code frequently that I am unfamiliar with, and not knowing what module a function is coming from just looking at the function is quite frustrating.   Code is written once and read many times, and so readability and maintainability trumps ease of typing.   In a similar vein, typically code is not being written for the benefit of the coder, but for the benefit of another entity.   Your code should be readable to someone who knows python better than you, but is unfamiliar with the code.   Full path imports can also better help IDE's point you at the correct source of the function or object you're looking at.  For all of these reasons and the reasons MestreLion noted, I conclude that it is best practice to import and use the full path.     ","Language":"Python","Tags":["python","python-import"],"URL":"https://stackoverflow.com/questions/1744258/is-import-module-better-coding-style-than-from-module-import-function","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Let from module import function be called the FMIF coding style.  Let import module be called the IM coding style.  Let from package import module be called the FPIM coding style.  Why is IM+FPIM considered a better coding style than FMIF? (See this post for the inspiration for this question.)  Here are some criteria which lead me to prefer FMIF over IM:  Shortness of code: It allows me to use shorter function names and thus help stick to the 80 columns-per-line convention.   Readability: chisquare(...) appears more readable than   scipy.stats.stats.chisquare(...). Although this is a subjective criterion, I think most people would agree.  Ease of redirection: If I use FMIF and for some reason at some later time want to redirect python to define function from alt_module instead of module I need to change just one line: from alt_module import function. If I were to use IM, I'd need to change many lines of code.   I realize FPIM goes some way to nullifying the first two issues, but what about the third?  I am interested in all reasons why IM+FPIM may be better than FMIF,  but in particular, I'd be interested in elaboration on the following points mentioned here:  Pros for IM:  ease of mocking/injecting in tests. (I am not very familiar with mocking, though I recently learned what the term means. Can you show code which demonstrates how IM is better than FMIF here?)  ability for a module to change flexibly by redefining some entries. (I must be misunderstanding something, because this seems to be an advantage of FMIF over IM. See my third reason in favor of FMIF above.)  predictable and controllable behavior on serialization and recovery of your data. (I really don't understand how the choice of IM or FMIF affects this issue. Please elaborate.)   I understand that FMIF \"pollutes my namespace\", but beyond being a negative-sounding phrase, I don't appreciate how this hurts the code in any concrete way.   PS. While writing this question I received a warning that the question appears subjective and is likely to be closed. Please don't close it. I'm not looking for subjective opinion, but rather concrete coding situations where IM+FPIM is demonstrably better than FMIF.  Many thanks.     ","Q_Votes":"62"},{"Q_Title":"Which PEP's are must reads?","A_Content":"  Definitely PEP 8, a Style Guide for Python.     ","Language":"Python","Tags":["python","pep"],"URL":"https://stackoverflow.com/questions/1382648/which-peps-are-must-reads","A_Votes":"30","_type":"dict","isAccepted":"Yes","Q_Content":"    I'm a fairly strong Python coder, but too much of my style is a little haphazard, and I'm sure there are more Pythonic solutions to many problems than the ones I come up with. Which PEPs are essential for any well versed Pythonista to read?     ","Q_Votes":"62"},{"Q_Title":"Which PEP's are must reads?","A_Content":"  Although Python is incredibly intuitive, a lot of people do not comprehend his philosophy.     Pep 20: The Zen of Python         Beautiful is better than ugly.   Explicit is better than implicit.   Simple is better than complex.   Complex is better than complicated.   Flat is better than nested.   Sparse is better than dense.   Readability counts.   Special cases aren't special enough to break the rules.   Although practicality beats purity.   Errors should never pass silently.   Unless explicitly silenced.   In the face of ambiguity, refuse the temptation to guess.   There should be one-- and preferably only one --obvious way to do   it.   Although that way may not be obvious at first unless you're Dutch.   Now is better than never.   Although never is often better than right now.   If the implementation is hard to explain, it's a bad idea.   If the implementation is easy to explain, it may be a good idea.   Namespaces are one honking great idea -- let's do more of those!         ","Language":"Python","Tags":["python","pep"],"URL":"https://stackoverflow.com/questions/1382648/which-peps-are-must-reads","A_Votes":"19","_type":"dict","isAccepted":"No","Q_Content":"    I'm a fairly strong Python coder, but too much of my style is a little haphazard, and I'm sure there are more Pythonic solutions to many problems than the ones I come up with. Which PEPs are essential for any well versed Pythonista to read?     ","Q_Votes":"62"},{"Q_Title":"Which PEP's are must reads?","A_Content":"  It is now retrospective, but still interesting: I think Things that will Not Change in Python 3000 is a good read, with lots of links to the discussions that preceded the decisions.     ","Language":"Python","Tags":["python","pep"],"URL":"https://stackoverflow.com/questions/1382648/which-peps-are-must-reads","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm a fairly strong Python coder, but too much of my style is a little haphazard, and I'm sure there are more Pythonic solutions to many problems than the ones I come up with. Which PEPs are essential for any well versed Pythonista to read?     ","Q_Votes":"62"},{"Q_Title":"Which PEP's are must reads?","A_Content":"  Also pep 0257 docstring convention     ","Language":"Python","Tags":["python","pep"],"URL":"https://stackoverflow.com/questions/1382648/which-peps-are-must-reads","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    I'm a fairly strong Python coder, but too much of my style is a little haphazard, and I'm sure there are more Pythonic solutions to many problems than the ones I come up with. Which PEPs are essential for any well versed Pythonista to read?     ","Q_Votes":"62"},{"Q_Title":"Which PEP's are must reads?","A_Content":"  I found that reading the declined ones can give some good insights into what's Pythonic and what isn't. This was a while ago so I don't have any specific examples.     ","Language":"Python","Tags":["python","pep"],"URL":"https://stackoverflow.com/questions/1382648/which-peps-are-must-reads","A_Votes":"8","_type":"dict","isAccepted":"No","Q_Content":"    I'm a fairly strong Python coder, but too much of my style is a little haphazard, and I'm sure there are more Pythonic solutions to many problems than the ones I come up with. Which PEPs are essential for any well versed Pythonista to read?     ","Q_Votes":"62"},{"Q_Title":"Which PEP's are must reads?","A_Content":"  Here is a index of PEP - http://www.python.org/dev/peps/   when ever one has doubt about a topic, they can search in that     ","Language":"Python","Tags":["python","pep"],"URL":"https://stackoverflow.com/questions/1382648/which-peps-are-must-reads","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I'm a fairly strong Python coder, but too much of my style is a little haphazard, and I'm sure there are more Pythonic solutions to many problems than the ones I come up with. Which PEPs are essential for any well versed Pythonista to read?     ","Q_Votes":"62"},{"Q_Title":"Which PEP's are must reads?","A_Content":"  I'd also recommend PEPs 8 and 257. I know this deviates slightly from the original question, but I'd like to point out that PyCharm (probably the best Python IDE around in my opinion) automatically checks if you're following some of the most important PEP 8 guidelines, just in case anyone's interested...     ","Language":"Python","Tags":["python","pep"],"URL":"https://stackoverflow.com/questions/1382648/which-peps-are-must-reads","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I'm a fairly strong Python coder, but too much of my style is a little haphazard, and I'm sure there are more Pythonic solutions to many problems than the ones I come up with. Which PEPs are essential for any well versed Pythonista to read?     ","Q_Votes":"62"},{"Q_Title":"As a Java programmer learning Python, what should I look out for? [closed]","A_Content":"   Don't put everything into classes. Python's built-in list and dictionaries will take you far. Don't worry about keeping one class per module. Divide modules by purpose, not by class. Use inheritance for behavior, not interfaces. Don't create an \"Animal\" class for \"Dog\" and \"Cat\" to inherit from, just so you can have a generic \"make_sound\" method.    Just do this:  class Dog(object):     def make_sound(self):         return \"woof!\"  class Cat(object):     def make_sound(self):         return \"meow!\"  class LolCat(object):     def make_sound(self):         return \"i can has cheezburger?\"      ","Language":"Python","Tags":["java","python"],"URL":"https://stackoverflow.com/questions/2339371/as-a-java-programmer-learning-python-what-should-i-look-out-for","A_Votes":"24","_type":"dict","isAccepted":"Yes","Q_Content":"    Much of my programming background is in Java, and I'm still doing most of my programming in Java. However, I'm starting to learn Python for some side projects at work, and I'd like to learn it as independent of my Java background as possible - i.e. I don't want to just program Java in Python. What are some things I should look out for?  A quick example - when looking through the Python tutorial, I came across the fact that defaulted mutable parameters of a function (such as a list) are persisted (remembered from call to call). This was counter-intuitive to me as a Java programmer and hard to get my head around. (See here and here if you don't understand the example.)  Someone also provided me with this list, which I found helpful, but short. Anyone have any other examples of how a Java programmer might tend to misuse Python...? Or things a Java programmer would falsely assume or have trouble understanding?  Edit: Ok, a brief overview of the reasons addressed by the article I linked to to prevent duplicates in the answers (as suggested by Bill the Lizard). (Please let me know if I make a mistake in phrasing, I've only just started with Python so I may not understand all the concepts fully. And a disclaimer - these are going to be very brief, so if you don't understand what it's getting at check out the link.)   A static method in Java does not translate to a Python classmethod A switch statement in Java translates to a hash table in Python Don't use XML Getters and setters are evil (hey, I'm just quoting :) ) Code duplication is often a necessary evil in Java (e.g. method overloading), but not in Python   (And if you find this question at all interesting, check out the link anyway. :) It's quite good.)     ","Q_Votes":"62"},{"Q_Title":"As a Java programmer learning Python, what should I look out for? [closed]","A_Content":"  The referenced article has some good advice that can easily be misquoted and misunderstood.  And some bad advice.  Leave Java behind.   Start fresh.  \"do not trust your [Java-based] instincts\".  Saying things are \"counter-intuitive\" is a bad habit in any programming discipline.  When learning a new language, start fresh, and drop your habits.  Your intuition must be wrong.    Languages are different.  Otherwise, they'd be the same language with different syntax, and there'd be simple translators.  Because there are not simple translators, there's no simple mapping.  That means that intuition is unhelpful and dangerous.   \"A static method in Java does not translate to a Python classmethod.\"  This kind of thing is really limited and unhelpful.  Python has a staticmethod decorator. It also has a classmethod decorator, for which Java has no equivalent.    This point, BTW, also included the much more helpful advice on not needlessly wrapping everything in a class.  \"The idiomatic translation of a Java static method is usually a module-level function\". The Java switch statement in Java can be implemented several ways.  First, and foremost, it's usually an if elif elif elif construct.  The article is unhelpful in this respect. If you're absolutely sure this is too slow (and can prove it) you can use a Python dictionary as a slightly faster mapping from value to block of code.  Blindly translating switch to dictionary (without thinking) is really bad advice. Don't use XML.  Doesn't make sense when taken out of context.  In context it means don't rely on XML to add flexibility.  Java relies on describing stuff in XML; WSDL files, for example, repeat information that's obvious from inspecting the code.  Python relies on introspection instead of restating everything in XML.  But Python has excellent XML processing libraries.  Several. Getters and setters are not required in Python they way they're required in Java.  First, you have better introspection in Python, so you don't need getters and setters to help make dynamic bean objects.  (For that, you use collections.namedtuple).    However, you have the property decorator which will bundle getters (and setters) into an attribute-like construct.  The point is that Python prefers naked attributes; when necessary, we can bundle getters and setters to appear as if there's a simple attribute.  Also, Python has descriptor classes if properties aren't sophisticated enough. Code duplication is often a necessary evil in Java (e.g. method overloading), but not in Python.  Correct.  Python uses optional arguments instead of method overloading.    The bullet point went on to talk about closure; that isn't as helpful as the simple advice to use default argument values wisely.      ","Language":"Python","Tags":["java","python"],"URL":"https://stackoverflow.com/questions/2339371/as-a-java-programmer-learning-python-what-should-i-look-out-for","A_Votes":"22","_type":"dict","isAccepted":"No","Q_Content":"    Much of my programming background is in Java, and I'm still doing most of my programming in Java. However, I'm starting to learn Python for some side projects at work, and I'd like to learn it as independent of my Java background as possible - i.e. I don't want to just program Java in Python. What are some things I should look out for?  A quick example - when looking through the Python tutorial, I came across the fact that defaulted mutable parameters of a function (such as a list) are persisted (remembered from call to call). This was counter-intuitive to me as a Java programmer and hard to get my head around. (See here and here if you don't understand the example.)  Someone also provided me with this list, which I found helpful, but short. Anyone have any other examples of how a Java programmer might tend to misuse Python...? Or things a Java programmer would falsely assume or have trouble understanding?  Edit: Ok, a brief overview of the reasons addressed by the article I linked to to prevent duplicates in the answers (as suggested by Bill the Lizard). (Please let me know if I make a mistake in phrasing, I've only just started with Python so I may not understand all the concepts fully. And a disclaimer - these are going to be very brief, so if you don't understand what it's getting at check out the link.)   A static method in Java does not translate to a Python classmethod A switch statement in Java translates to a hash table in Python Don't use XML Getters and setters are evil (hey, I'm just quoting :) ) Code duplication is often a necessary evil in Java (e.g. method overloading), but not in Python   (And if you find this question at all interesting, check out the link anyway. :) It's quite good.)     ","Q_Votes":"62"},{"Q_Title":"As a Java programmer learning Python, what should I look out for? [closed]","A_Content":"  One thing you might be used to in Java that you won't find in Python is strict privacy.  This is not so much something to look out for as it is something not to look for (I am embarrassed by how long I searched for a Python equivalent to 'private' when I started out!).  Instead, Python has much more transparency and easier introspection than Java.  This falls under what is sometimes described as the \"we're all consenting adults here\" philosophy.  There are a few conventions and language mechanisms to help prevent accidental use of \"unpublic\" methods and so forth, but the whole mindset of information hiding is virtually absent in Python.     ","Language":"Python","Tags":["java","python"],"URL":"https://stackoverflow.com/questions/2339371/as-a-java-programmer-learning-python-what-should-i-look-out-for","A_Votes":"13","_type":"dict","isAccepted":"No","Q_Content":"    Much of my programming background is in Java, and I'm still doing most of my programming in Java. However, I'm starting to learn Python for some side projects at work, and I'd like to learn it as independent of my Java background as possible - i.e. I don't want to just program Java in Python. What are some things I should look out for?  A quick example - when looking through the Python tutorial, I came across the fact that defaulted mutable parameters of a function (such as a list) are persisted (remembered from call to call). This was counter-intuitive to me as a Java programmer and hard to get my head around. (See here and here if you don't understand the example.)  Someone also provided me with this list, which I found helpful, but short. Anyone have any other examples of how a Java programmer might tend to misuse Python...? Or things a Java programmer would falsely assume or have trouble understanding?  Edit: Ok, a brief overview of the reasons addressed by the article I linked to to prevent duplicates in the answers (as suggested by Bill the Lizard). (Please let me know if I make a mistake in phrasing, I've only just started with Python so I may not understand all the concepts fully. And a disclaimer - these are going to be very brief, so if you don't understand what it's getting at check out the link.)   A static method in Java does not translate to a Python classmethod A switch statement in Java translates to a hash table in Python Don't use XML Getters and setters are evil (hey, I'm just quoting :) ) Code duplication is often a necessary evil in Java (e.g. method overloading), but not in Python   (And if you find this question at all interesting, check out the link anyway. :) It's quite good.)     ","Q_Votes":"62"},{"Q_Title":"As a Java programmer learning Python, what should I look out for? [closed]","A_Content":"  The biggest one I can think of is not understanding or not fully utilizing duck typing.  In Java you're required to specify very explicit and detailed type information upfront.  In Python typing is both dynamic and largely implicit.  The philosophy is that you should be thinking about your program at a higher level than nominal types.  For example, in Python, you don't use inheritance to model substitutability.  Substitutability comes by default as a result of duck typing.  Inheritance is only a programmer convenience for reusing implementation.  Similarly, the Pythonic idiom is \"beg forgiveness, don't ask permission\".  Explicit typing is considered evil.  Don't check whether a parameter is a certain type upfront.  Just try to do whatever you need to do with the parameter.  If it doesn't conform to the proper interface, it will throw a very clear exception and you will be able to find the problem very quickly.  If someone passes a parameter of a type that was nominally unexpected but has the same interface as what you expected, then you've gained flexibility for free.     ","Language":"Python","Tags":["java","python"],"URL":"https://stackoverflow.com/questions/2339371/as-a-java-programmer-learning-python-what-should-i-look-out-for","A_Votes":"9","_type":"dict","isAccepted":"No","Q_Content":"    Much of my programming background is in Java, and I'm still doing most of my programming in Java. However, I'm starting to learn Python for some side projects at work, and I'd like to learn it as independent of my Java background as possible - i.e. I don't want to just program Java in Python. What are some things I should look out for?  A quick example - when looking through the Python tutorial, I came across the fact that defaulted mutable parameters of a function (such as a list) are persisted (remembered from call to call). This was counter-intuitive to me as a Java programmer and hard to get my head around. (See here and here if you don't understand the example.)  Someone also provided me with this list, which I found helpful, but short. Anyone have any other examples of how a Java programmer might tend to misuse Python...? Or things a Java programmer would falsely assume or have trouble understanding?  Edit: Ok, a brief overview of the reasons addressed by the article I linked to to prevent duplicates in the answers (as suggested by Bill the Lizard). (Please let me know if I make a mistake in phrasing, I've only just started with Python so I may not understand all the concepts fully. And a disclaimer - these are going to be very brief, so if you don't understand what it's getting at check out the link.)   A static method in Java does not translate to a Python classmethod A switch statement in Java translates to a hash table in Python Don't use XML Getters and setters are evil (hey, I'm just quoting :) ) Code duplication is often a necessary evil in Java (e.g. method overloading), but not in Python   (And if you find this question at all interesting, check out the link anyway. :) It's quite good.)     ","Q_Votes":"62"},{"Q_Title":"As a Java programmer learning Python, what should I look out for? [closed]","A_Content":"  The most important thing, from a Java POV, is that it's perfectly ok to not make classes for everything.  There are many situations where a procedural approach is simpler and shorter.  The next most important thing is that you will have to get over the notion that the type of an object controls what it may do; rather, the code controls what objects must be able to support at runtime (this is by virtue of duck-typing).    Oh, and use native lists and dicts (not customized descendants) as far as possible.     ","Language":"Python","Tags":["java","python"],"URL":"https://stackoverflow.com/questions/2339371/as-a-java-programmer-learning-python-what-should-i-look-out-for","A_Votes":"6","_type":"dict","isAccepted":"No","Q_Content":"    Much of my programming background is in Java, and I'm still doing most of my programming in Java. However, I'm starting to learn Python for some side projects at work, and I'd like to learn it as independent of my Java background as possible - i.e. I don't want to just program Java in Python. What are some things I should look out for?  A quick example - when looking through the Python tutorial, I came across the fact that defaulted mutable parameters of a function (such as a list) are persisted (remembered from call to call). This was counter-intuitive to me as a Java programmer and hard to get my head around. (See here and here if you don't understand the example.)  Someone also provided me with this list, which I found helpful, but short. Anyone have any other examples of how a Java programmer might tend to misuse Python...? Or things a Java programmer would falsely assume or have trouble understanding?  Edit: Ok, a brief overview of the reasons addressed by the article I linked to to prevent duplicates in the answers (as suggested by Bill the Lizard). (Please let me know if I make a mistake in phrasing, I've only just started with Python so I may not understand all the concepts fully. And a disclaimer - these are going to be very brief, so if you don't understand what it's getting at check out the link.)   A static method in Java does not translate to a Python classmethod A switch statement in Java translates to a hash table in Python Don't use XML Getters and setters are evil (hey, I'm just quoting :) ) Code duplication is often a necessary evil in Java (e.g. method overloading), but not in Python   (And if you find this question at all interesting, check out the link anyway. :) It's quite good.)     ","Q_Votes":"62"},{"Q_Title":"As a Java programmer learning Python, what should I look out for? [closed]","A_Content":"  The way exceptions are treated in Python is different from  how they are treated in Java. While in Java the advice is to use exceptions only for exceptional conditions this is not so with Python.   In Python things like Iterator makes use of exception mechanism to signal that there are no more items.But such a design is not considered as good practice in Java.  As Alex Martelli puts in his book Python in a Nutshell the exception mechanism with other languages (and applicable to Java)  is LBYL (Look Before You Leap) :  is to check in advance, before attempting an operation, for all circumstances that might make the operation invalid.   Where as with Python the approach is EAFP (it's easier to Ask for forgiveness than permission)     ","Language":"Python","Tags":["java","python"],"URL":"https://stackoverflow.com/questions/2339371/as-a-java-programmer-learning-python-what-should-i-look-out-for","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    Much of my programming background is in Java, and I'm still doing most of my programming in Java. However, I'm starting to learn Python for some side projects at work, and I'd like to learn it as independent of my Java background as possible - i.e. I don't want to just program Java in Python. What are some things I should look out for?  A quick example - when looking through the Python tutorial, I came across the fact that defaulted mutable parameters of a function (such as a list) are persisted (remembered from call to call). This was counter-intuitive to me as a Java programmer and hard to get my head around. (See here and here if you don't understand the example.)  Someone also provided me with this list, which I found helpful, but short. Anyone have any other examples of how a Java programmer might tend to misuse Python...? Or things a Java programmer would falsely assume or have trouble understanding?  Edit: Ok, a brief overview of the reasons addressed by the article I linked to to prevent duplicates in the answers (as suggested by Bill the Lizard). (Please let me know if I make a mistake in phrasing, I've only just started with Python so I may not understand all the concepts fully. And a disclaimer - these are going to be very brief, so if you don't understand what it's getting at check out the link.)   A static method in Java does not translate to a Python classmethod A switch statement in Java translates to a hash table in Python Don't use XML Getters and setters are evil (hey, I'm just quoting :) ) Code duplication is often a necessary evil in Java (e.g. method overloading), but not in Python   (And if you find this question at all interesting, check out the link anyway. :) It's quite good.)     ","Q_Votes":"62"},{"Q_Title":"As a Java programmer learning Python, what should I look out for? [closed]","A_Content":"  A corrollary to \"Don't use classes for everything\": callbacks.   The Java way for doing callbacks relies on passing objects that implement the callback interface (for example ActionListener with its actionPerformed() method). Nothing of this sort is necessary in Python, you can directly pass methods or even locally defined functions:  def handler():    print(\"click!\") button.onclick(handler)   Or even lambdas:  button.onclick(lambda: print(\"click!\\n\"))       ","Language":"Python","Tags":["java","python"],"URL":"https://stackoverflow.com/questions/2339371/as-a-java-programmer-learning-python-what-should-i-look-out-for","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Much of my programming background is in Java, and I'm still doing most of my programming in Java. However, I'm starting to learn Python for some side projects at work, and I'd like to learn it as independent of my Java background as possible - i.e. I don't want to just program Java in Python. What are some things I should look out for?  A quick example - when looking through the Python tutorial, I came across the fact that defaulted mutable parameters of a function (such as a list) are persisted (remembered from call to call). This was counter-intuitive to me as a Java programmer and hard to get my head around. (See here and here if you don't understand the example.)  Someone also provided me with this list, which I found helpful, but short. Anyone have any other examples of how a Java programmer might tend to misuse Python...? Or things a Java programmer would falsely assume or have trouble understanding?  Edit: Ok, a brief overview of the reasons addressed by the article I linked to to prevent duplicates in the answers (as suggested by Bill the Lizard). (Please let me know if I make a mistake in phrasing, I've only just started with Python so I may not understand all the concepts fully. And a disclaimer - these are going to be very brief, so if you don't understand what it's getting at check out the link.)   A static method in Java does not translate to a Python classmethod A switch statement in Java translates to a hash table in Python Don't use XML Getters and setters are evil (hey, I'm just quoting :) ) Code duplication is often a necessary evil in Java (e.g. method overloading), but not in Python   (And if you find this question at all interesting, check out the link anyway. :) It's quite good.)     ","Q_Votes":"62"},{"Q_Title":"Raise exception vs. return None in functions?","A_Content":"  It's really a matter of semantics.  What does foo = latestpdf(d) mean?  Is it perfectly reasonable that there's no latest file?  Then sure, just return None.  Are you expecting to always find a latest file?  Raise an exception.  And yes, re-raising a more appropriate exception is fine.  If this is just a general function that's supposed to apply to any directory, I'd do the former and return None.  If the directory is, e.g., meant to be a specific data directory that contains an application's known set of files, I'd raise an exception.     ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/1313812/raise-exception-vs-return-none-in-functions","A_Votes":"72","_type":"dict","isAccepted":"Yes","Q_Content":"    What's better practice in a user-defined function in Python: raise an exception or return None?  For example, I have a function that finds the most recent file in a folder.  def latestpdf(folder):     # list the files and sort them     try:         latest = files[-1]     except IndexError:         # Folder is empty.         return None  # One possibility         raise FileNotFoundError()  # Alternative     else:         return somefunc(latest)  # In my case, somefunc parses the filename   Another option is leave the exception and handle it in the caller code, but I figure it's more clear to deal with a FileNotFoundError than an IndexError. Or is it bad form to re-raise an exception with a different name?     ","Q_Votes":"62"},{"Q_Title":"Raise exception vs. return None in functions?","A_Content":"  I would make a couple suggestions before answering your question as it may answer the question for you.   Always name your functions descriptive.  latestpdf means very little to anyone but looking over your function latestpdf() gets the latest pdf.  I would suggest that you name it getLatestPdfFromFolder(folder).   As soon as I did this it became clear what it should return..  If there isn't a pdf raise an exception. But wait there more..   Keep the functions clearly defined.  Since it's not apparent what somefuc is supposed to do and it's not (apparently) obvious how it relates to getting the latest pdf I would suggest you move it out.  This makes the code much more readable.     for folder in folders:    try:        latest = getLatestPdfFromFolder(folder)        results = somefuc(latest)    except IOError: pass   Hope this helps!     ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/1313812/raise-exception-vs-return-none-in-functions","A_Votes":"5","_type":"dict","isAccepted":"No","Q_Content":"    What's better practice in a user-defined function in Python: raise an exception or return None?  For example, I have a function that finds the most recent file in a folder.  def latestpdf(folder):     # list the files and sort them     try:         latest = files[-1]     except IndexError:         # Folder is empty.         return None  # One possibility         raise FileNotFoundError()  # Alternative     else:         return somefunc(latest)  # In my case, somefunc parses the filename   Another option is leave the exception and handle it in the caller code, but I figure it's more clear to deal with a FileNotFoundError than an IndexError. Or is it bad form to re-raise an exception with a different name?     ","Q_Votes":"62"},{"Q_Title":"Raise exception vs. return None in functions?","A_Content":"  I usually prefer to handle exceptions internally (i.e. try/except inside the called function, possibly returning a None) because python is dynamically typed.  In general, I consider it a judgment call one way or the other, but in a dynamically typed language, there are small factors that tip the scales in favor of not passing the exception to the caller:   Anyone calling your function is not notified of the exceptions that can be thrown.  It becomes a bit of an art form to know what kind of exception you are hunting for (and generic except blocks ought to be avoided). if val is None is a little easier than except ComplicatedCustomExceptionThatHadToBeImportedFromSomeNameSpace.  Seriously, I hate having to remember to type from django.core.exceptions import ObjectDoesNotExist at the top of all my django files just to handle a really common use case.  In a statically typed world, let the editor do it for you.   Honestly, though, it's always a judgment call, and the situation you're describing, where the called function receives an error it can't help, is an excellent reason to re-raise an exception that is meaningful.  You have the exact right idea, but unless you're exception is going to provide more meaningful information in a stack trace than  AttributeError: 'NoneType' object has no attribute 'foo'   which, nine times out of ten, is what the caller will see if you return an unhandled None, don't bother.  (All this kind of makes me wish that python exceptions had the cause attributes by default, as in java, which lets you pass exceptions into new exceptions so that you can rethrow all you want and never lose the original source of the problem.)     ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/1313812/raise-exception-vs-return-none-in-functions","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    What's better practice in a user-defined function in Python: raise an exception or return None?  For example, I have a function that finds the most recent file in a folder.  def latestpdf(folder):     # list the files and sort them     try:         latest = files[-1]     except IndexError:         # Folder is empty.         return None  # One possibility         raise FileNotFoundError()  # Alternative     else:         return somefunc(latest)  # In my case, somefunc parses the filename   Another option is leave the exception and handle it in the caller code, but I figure it's more clear to deal with a FileNotFoundError than an IndexError. Or is it bad form to re-raise an exception with a different name?     ","Q_Votes":"62"},{"Q_Title":"Raise exception vs. return None in functions?","A_Content":"  In general, I'd say an exception should be thrown if something catastrophic has occured that cannot be recovered from (i.e. your function deals with some internet resource that cannot be connected to), and you should return None if your function should really return something but nothing would be appropriate to return (i.e. \"None\" if your function tries to match a substring in a string for example).     ","Language":"Python","Tags":["python","exception-handling"],"URL":"https://stackoverflow.com/questions/1313812/raise-exception-vs-return-none-in-functions","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    What's better practice in a user-defined function in Python: raise an exception or return None?  For example, I have a function that finds the most recent file in a folder.  def latestpdf(folder):     # list the files and sort them     try:         latest = files[-1]     except IndexError:         # Folder is empty.         return None  # One possibility         raise FileNotFoundError()  # Alternative     else:         return somefunc(latest)  # In my case, somefunc parses the filename   Another option is leave the exception and handle it in the caller code, but I figure it's more clear to deal with a FileNotFoundError than an IndexError. Or is it bad form to re-raise an exception with a different name?     ","Q_Votes":"62"},{"Q_Title":"What is the difference between 'content' and 'text'","A_Content":"  The developer interface has more details:  r.text is the content of the response in unicode, and r.content is the content of the response in bytes.     ","Language":"Python","Tags":["python","python-requests"],"URL":"https://stackoverflow.com/questions/17011357/what-is-the-difference-between-content-and-text","A_Votes":"78","_type":"dict","isAccepted":"Yes","Q_Content":"    I am using the terrific Python Requests library. I notice that the fine documentation has many examples of how to do something without explaining the why. For instance, both r.text and r.content are shown as examples of how to get the server response. But where is it explained what these properties do? For instance, when would I choose one over the other? I see thar r.text returns a unicode object sometimes, and I suppose that there would be a difference for a non-text response. But where is all this documented? Note that the linked document does state:     You can also access the response body as bytes, for non-text requests:   But then it goes on to show an example of a text response! I can only suppose that the quote above means to say non-text responses instead of non-text requests, as a non-text request does not make sense in HTTP.  In short, where is the proper documentation of the library, as opposed to the (excellent) tutorial on the Python Requests site?     ","Q_Votes":"62"},{"Q_Title":"What is the difference between 'content' and 'text'","A_Content":"  It seems clear from the documentation is that r.content  You can also access the response body as bytes, for non-text requests:   >>> r.content   If you read further down the page it addresses for example an image file     ","Language":"Python","Tags":["python","python-requests"],"URL":"https://stackoverflow.com/questions/17011357/what-is-the-difference-between-content-and-text","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    I am using the terrific Python Requests library. I notice that the fine documentation has many examples of how to do something without explaining the why. For instance, both r.text and r.content are shown as examples of how to get the server response. But where is it explained what these properties do? For instance, when would I choose one over the other? I see thar r.text returns a unicode object sometimes, and I suppose that there would be a difference for a non-text response. But where is all this documented? Note that the linked document does state:     You can also access the response body as bytes, for non-text requests:   But then it goes on to show an example of a text response! I can only suppose that the quote above means to say non-text responses instead of non-text requests, as a non-text request does not make sense in HTTP.  In short, where is the proper documentation of the library, as opposed to the (excellent) tutorial on the Python Requests site?     ","Q_Votes":"62"},{"Q_Title":"how to convert 2d list to 2d numpy array?","A_Content":"  Just pass the list to np.array:  a = np.array(a)   You can also take this opportunity to set the dtype if the default is not what you desire.  a = np.array(a, dtype=...)      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/7717380/how-to-convert-2d-list-to-2d-numpy-array","A_Votes":"68","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a 2D list something like   a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]    and I want to convert it to a 2d numpy array. Can we do it without allocating memory like   numpy.zeros((3,3))   and then storing values to it?     ","Q_Votes":"61"},{"Q_Title":"how to convert 2d list to 2d numpy array?","A_Content":"  I am using large data sets exported to a python file in the form  XVals1 = [.........]  XVals2 = [.........]    Each list is of identical length.  I use  >>> a1 = np.array(SV.XVals1)  >>> a2 = np.array(SV.XVals2)   Then  >>> A = np.matrix([a1,a2])      ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/7717380/how-to-convert-2d-list-to-2d-numpy-array","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I have a 2D list something like   a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]    and I want to convert it to a 2d numpy array. Can we do it without allocating memory like   numpy.zeros((3,3))   and then storing values to it?     ","Q_Votes":"61"},{"Q_Title":"how to convert 2d list to 2d numpy array?","A_Content":"  just use following code  c = np.matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) matrix([[1, 2, 3],     [4, 5, 6],     [7, 8, 9]])   Then it will give you  you can check shape and dimension of matrix by using following code  c.shape  c.ndim     ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/7717380/how-to-convert-2d-list-to-2d-numpy-array","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I have a 2D list something like   a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]    and I want to convert it to a 2d numpy array. Can we do it without allocating memory like   numpy.zeros((3,3))   and then storing values to it?     ","Q_Votes":"61"},{"Q_Title":"how to convert 2d list to 2d numpy array?","A_Content":"  np.array() is even more powerful than what unutbu said above. You also could use it to convert a list of np arrays to a higher dimention array, the following is a simple example:  aArray=np.array([1,1,1])  bArray=np.array([2,2,2])  aList=[aArray, bArray]  xArray=np.array(aList)   xArray's shape is (2,3), it's a standard np array. This operation avoids a loop programming.     ","Language":"Python","Tags":["python","numpy"],"URL":"https://stackoverflow.com/questions/7717380/how-to-convert-2d-list-to-2d-numpy-array","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have a 2D list something like   a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]    and I want to convert it to a 2d numpy array. Can we do it without allocating memory like   numpy.zeros((3,3))   and then storing values to it?     ","Q_Votes":"61"},{"Q_Title":"Mocking a function to raise an Exception to test an except block","A_Content":"  Your mock is raising the exception just fine, but the error.resp.status value is missing. Rather than use return_value, just tell Mock that status is an attribute:  barMock.side_effect = HttpError(mock.Mock(status=404), 'not found')   Additional keyword arguments to Mock() are set as attributes on the resulting object.  I put your foo and bar definitions in a my_tests module, added in the HttpError class so I could use it too, and your test then can be ran to success:  >>> from my_tests import foo, HttpError >>> import mock >>> with mock.patch('my_tests.bar') as barMock: ...     barMock.side_effect = HttpError(mock.Mock(status=404), 'not found') ...     result = my_test.foo() ...  404 -  >>> result is None True   You can even see the print '404 - %s' % error.message line run, but I think you wanted to use error.content there instead; that's the attribute HttpError() sets from the second argument, at any rate.     ","Language":"Python","Tags":["python","unit-testing","python-2.7","mocking","python-mock"],"URL":"https://stackoverflow.com/questions/28305406/mocking-a-function-to-raise-an-exception-to-test-an-except-block","A_Votes":"71","_type":"dict","isAccepted":"Yes","Q_Content":"    I have a function (foo) which calls another function (bar). If invoking bar() raises an HttpError, I want to handle it specially if the status code is 404, otherwise re-raise.  I am trying to write some unit tests around this foo function, mocking out the call to bar(). Unfortunately, I am unable to get the mocked call to bar() to raise an Exception which is caught by my except block.  Here is my code which illustrates my problem:  import unittest import mock from apiclient.errors import HttpError   class FooTests(unittest.TestCase):     @mock.patch('my_tests.bar')     def test_foo_shouldReturnResultOfBar_whenBarSucceeds(self, barMock):         barMock.return_value = True         result = foo()         self.assertTrue(result)  # passes      @mock.patch('my_tests.bar')     def test_foo_shouldReturnNone_whenBarRaiseHttpError404(self, barMock):         barMock.side_effect = HttpError(mock.Mock(return_value={'status': 404}), 'not found')         result = foo()         self.assertIsNone(result)  # fails, test raises HttpError      @mock.patch('my_tests.bar')     def test_foo_shouldRaiseHttpError_whenBarRaiseHttpErrorNot404(self, barMock):         barMock.side_effect = HttpError(mock.Mock(return_value={'status': 500}), 'error')         with self.assertRaises(HttpError):  # passes             foo()  def foo():     try:         result = bar()         return result     except HttpError as error:         if error.resp.status == 404:             print '404 - %s' % error.message             return None         raise  def bar():     raise NotImplementedError()   I followed the Mock docs which say that you should set the side_effect of a Mock instance to an Exception class to have the mocked function raise the error.  I also looked at some other related StackOverflow Q&As, and it looks like I am doing the same thing they are doing to cause and Exception to be raised by their mock.   https://stackoverflow.com/a/10310532/346561 How to use Python Mock to raise an exception - but with Errno set to a given value   Why is setting the side_effect of barMock not causing the expected Exception to be raised? If I am doing something weird, how should I go about testing logic in my except block?     ","Q_Votes":"61"},{"Q_Title":"What is “pkg-resources==0.0.0” in output of pip freeze command","A_Content":"  According to https://github.com/pypa/pip/issues/4022, this is a bug resulting from Ubuntu providing incorrect metadata to pip. So, no there does not seem to be a good reason for this behaviour. I filed a follow-up bug with Ubuntu. https://bugs.launchpad.net/ubuntu/+source/python-pip/+bug/1635463  To backup the previous answer, it should be safe to remove that line from your requirements.txt. Here is an example Make file stanza that safely freezes your package list (drop in your Makefile and run with make freeze):  freeze:     pip freeze | grep -v \"pkg-resources\" > requirements.txt      ","Language":"Python","Tags":["python","python-3.x","pip","ubuntu-16.04"],"URL":"https://stackoverflow.com/questions/39577984/what-is-pkg-resources-0-0-0-in-output-of-pip-freeze-command","A_Votes":"68","_type":"dict","isAccepted":"Yes","Q_Content":"    When I run pip freeze I see (among other expected packages) pkg-resources==0.0.0. I have seen a few posts mentioning this package (including this one), but none explaining what it is, or why it is included in the output of pip freeze. The main reason I am wondering is out of curiosity, but also, it seems to break things in some cases when trying to install packages with a requirements.txt file generated with pip freeze that includes the pkg-resources==0.0.0 line (for example when Travis CI tries to install dependencies through pip and finds this line).  What is pkg-resources, and is it OK to remove this line from requirements.txt?  Update:  I have found that this line only seems to exist in the output of pip freeze when I am in a virtualenv. I am still not sure what it is or what it does, but I will investigate further knowing that it is likely related to virtualenv.     ","Q_Votes":"61"},{"Q_Title":"What is “pkg-resources==0.0.0” in output of pip freeze command","A_Content":"  As for the part of your question \"is it OK to remove this line\":  I have the same issue here developing on an ubuntu 16.04 with that very line in the requirements. When deploying on a debian 8.5 running \"pip install -r requirements.txt\" pip complains that pkg-resources  is \"not found\" but there is a global package installed \"python-pkg-resources\" so the dependency should be satisfied. Same on ubuntu: The package exists there as well.  As stated here it seems to be some \"implicitly installed package\".   So: If you are on a Debian/Ubuntu having python-pkg-resources installed it should be safe to remove that line. I did so and everything is running fine. However since I am no expert on this you should keep in mind that this might lead to complications when deploying on another machine.     ","Language":"Python","Tags":["python","python-3.x","pip","ubuntu-16.04"],"URL":"https://stackoverflow.com/questions/39577984/what-is-pkg-resources-0-0-0-in-output-of-pip-freeze-command","A_Votes":"7","_type":"dict","isAccepted":"No","Q_Content":"    When I run pip freeze I see (among other expected packages) pkg-resources==0.0.0. I have seen a few posts mentioning this package (including this one), but none explaining what it is, or why it is included in the output of pip freeze. The main reason I am wondering is out of curiosity, but also, it seems to break things in some cases when trying to install packages with a requirements.txt file generated with pip freeze that includes the pkg-resources==0.0.0 line (for example when Travis CI tries to install dependencies through pip and finds this line).  What is pkg-resources, and is it OK to remove this line from requirements.txt?  Update:  I have found that this line only seems to exist in the output of pip freeze when I am in a virtualenv. I am still not sure what it is or what it does, but I will investigate further knowing that it is likely related to virtualenv.     ","Q_Votes":"61"},{"Q_Title":"Multiple assignment semantics","A_Content":"  One case when you need to include more structure on the left hand side of the assignment is when you're asking Python unpack a slightly more complicated sequence.  E.g.:  # Works >>> a, (b, c) = [1, [2, 3]]  # Does not work >>> a, b, c = [1, [2, 3]] Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: need more than 2 values to unpack   This has proved useful for me in the past, for example, when using enumerate to iterate over a sequence of 2-tuples.  Something like:  >>> d = { 'a': 'x', 'b': 'y', 'c': 'z' } >>> for i, (key, value) in enumerate(d.iteritems()): ...     print (i, key, value) (0, 'a', 'x') (1, 'c', 'z') (2, 'b', 'y')      ","Language":"Python","Tags":["python","variable-assignment"],"URL":"https://stackoverflow.com/questions/5182573/multiple-assignment-semantics","A_Votes":"66","_type":"dict","isAccepted":"Yes","Q_Content":"    In Python one can do:  a, b   = 1, 2 (a, b) = 1, 2 [a, b] = 1, 2   I checked the generated bytecode using dis and they are identical. So why allow this at all? Would I ever need one of these instead of the others?     ","Q_Votes":"61"},{"Q_Title":"Multiple assignment semantics","A_Content":"  Python tuples can often be written with or without the parentheses:  a = 1, 2, 3   is equivalent to   a = (1, 2, 3)   In some cases, you need parentheses to resolve ambiguities, for examples if you want to pass the tuple (1, 2) to the function f, you will have to write f((1, 2)).  Because the parentheses are sometimes needed, they are always allowed for consistency, just like you can always write (a + b) instead of a + b.  If you want to unpack a nested sequence, you also need parentheses:  a, (b, c) = 1, (2, 3)   There does not seem to be a reason to also allow square brackets, and people rarely do.     ","Language":"Python","Tags":["python","variable-assignment"],"URL":"https://stackoverflow.com/questions/5182573/multiple-assignment-semantics","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    In Python one can do:  a, b   = 1, 2 (a, b) = 1, 2 [a, b] = 1, 2   I checked the generated bytecode using dis and they are identical. So why allow this at all? Would I ever need one of these instead of the others?     ","Q_Votes":"61"},{"Q_Title":"Multiple assignment semantics","A_Content":"  They are also same because the assignment happens from Right to left and on the right, you have one type, which is a sequence of two elements. When the asignment call is made, the sequence is unpacked and looked for corresponding elements to match and given to those values. Yes, any one way should be fine in this case where the sequence is unpacked to respective elements.      ","Language":"Python","Tags":["python","variable-assignment"],"URL":"https://stackoverflow.com/questions/5182573/multiple-assignment-semantics","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    In Python one can do:  a, b   = 1, 2 (a, b) = 1, 2 [a, b] = 1, 2   I checked the generated bytecode using dis and they are identical. So why allow this at all? Would I ever need one of these instead of the others?     ","Q_Votes":"61"},{"Q_Title":"Multiple assignment semantics","A_Content":"  An open parenthesis allows for a multi-line assignment. For example, when reading a row from csv.reader(), it makes code more readable (if less efficient) to load the list into named variables with a single assignment.  Starting with a parenthesis avoids long or \\ escaped lines.  (a, b, c) = [1, 2, 3]  (Imagine more and longer variable names)     ","Language":"Python","Tags":["python","variable-assignment"],"URL":"https://stackoverflow.com/questions/5182573/multiple-assignment-semantics","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    In Python one can do:  a, b   = 1, 2 (a, b) = 1, 2 [a, b] = 1, 2   I checked the generated bytecode using dis and they are identical. So why allow this at all? Would I ever need one of these instead of the others?     ","Q_Votes":"61"},{"Q_Title":"Multiple assignment semantics","A_Content":"  When unpacking a single-element iterable, the list syntax is prettier:  a,=f()    # comma looks out of place (a,)=f()  # still odd [a]=f()   # looks like every other list      ","Language":"Python","Tags":["python","variable-assignment"],"URL":"https://stackoverflow.com/questions/5182573/multiple-assignment-semantics","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    In Python one can do:  a, b   = 1, 2 (a, b) = 1, 2 [a, b] = 1, 2   I checked the generated bytecode using dis and they are identical. So why allow this at all? Would I ever need one of these instead of the others?     ","Q_Votes":"61"},{"Q_Title":"How to setup VIM autoindentation properly for editing Python files - *.py","A_Content":"  I use this on my macbook:  \" configure expanding of tabs for various file types au BufRead,BufNewFile *.py set expandtab au BufRead,BufNewFile *.c set noexpandtab au BufRead,BufNewFile *.h set noexpandtab au BufRead,BufNewFile Makefile* set noexpandtab  \" -------------------------------------------------------------------------------- \" configure editor with tabs and nice stuff... \" -------------------------------------------------------------------------------- set expandtab           \" enter spaces when tab is pressed set textwidth=120       \" break lines when line length increases set tabstop=4           \" use 4 spaces to represent tab set softtabstop=4 set shiftwidth=4        \" number of spaces to use for auto indent set autoindent          \" copy indent from current line when starting a new line  \" make backspaces more powerfull set backspace=indent,eol,start  set ruler                           \" show line and column number syntax on               \" syntax highlighting set showcmd             \" show (partial) command in status line   (edited to only show stuff related to indent / tabs)     ","Language":"Python","Tags":["python","vim","configuration","spaces"],"URL":"https://stackoverflow.com/questions/65076/how-to-setup-vim-autoindentation-properly-for-editing-python-files-py","A_Votes":"56","_type":"dict","isAccepted":"No","Q_Content":"    I've troubles setting VIM (7.1.xxx) for editing python files.  Indenting seems to be broken (optimal 4 spaces). I've followed some tutorials I found via Google. Still no effect :/  Please help.     ","Q_Votes":"61"},{"Q_Title":"How to setup VIM autoindentation properly for editing Python files - *.py","A_Content":"  I use:  $ cat ~/.vimrc syntax on set showmatch set ts=4 set sts=4 set sw=4 set autoindent set smartindent set smarttab set expandtab set number   But but I'm going to try Daren's entries     ","Language":"Python","Tags":["python","vim","configuration","spaces"],"URL":"https://stackoverflow.com/questions/65076/how-to-setup-vim-autoindentation-properly-for-editing-python-files-py","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I've troubles setting VIM (7.1.xxx) for editing python files.  Indenting seems to be broken (optimal 4 spaces). I've followed some tutorials I found via Google. Still no effect :/  Please help.     ","Q_Votes":"61"},{"Q_Title":"How to setup VIM autoindentation properly for editing Python files - *.py","A_Content":"  I use the vimrc in the python repo among other things:  http://svn.python.org/projects/python/trunk/Misc/Vim/vimrc  I also add  set softtabstop=4   I have my old config here that I'm updating     ","Language":"Python","Tags":["python","vim","configuration","spaces"],"URL":"https://stackoverflow.com/questions/65076/how-to-setup-vim-autoindentation-properly-for-editing-python-files-py","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I've troubles setting VIM (7.1.xxx) for editing python files.  Indenting seems to be broken (optimal 4 spaces). I've followed some tutorials I found via Google. Still no effect :/  Please help.     ","Q_Votes":"61"},{"Q_Title":"How to setup VIM autoindentation properly for editing Python files - *.py","A_Content":"  A simpler option: just uncomment the following part of the configuration (which is originally commented out) in the /etc/vim/vimrc file:      if has(\"autocmd\")       filetype plugin indent on     endif      ","Language":"Python","Tags":["python","vim","configuration","spaces"],"URL":"https://stackoverflow.com/questions/65076/how-to-setup-vim-autoindentation-properly-for-editing-python-files-py","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    I've troubles setting VIM (7.1.xxx) for editing python files.  Indenting seems to be broken (optimal 4 spaces). I've followed some tutorials I found via Google. Still no effect :/  Please help.     ","Q_Votes":"61"},{"Q_Title":"How to setup VIM autoindentation properly for editing Python files - *.py","A_Content":"  Ensure you are editing the correct configuration file for VIM. Especially if you are using windows, where the file could be named _vimrc instead of .vimrc as on other platforms.  In vim type  :help vimrc  and check your path to the _vimrc/.vimrc file with  :echo $HOME  :echo $VIM  Make sure you are only using one file. If you want to split your configuration into smaller chunks you can source other files from inside your _vimrc file.  :help source     ","Language":"Python","Tags":["python","vim","configuration","spaces"],"URL":"https://stackoverflow.com/questions/65076/how-to-setup-vim-autoindentation-properly-for-editing-python-files-py","A_Votes":"3","_type":"dict","isAccepted":"No","Q_Content":"    I've troubles setting VIM (7.1.xxx) for editing python files.  Indenting seems to be broken (optimal 4 spaces). I've followed some tutorials I found via Google. Still no effect :/  Please help.     ","Q_Votes":"61"},{"Q_Title":"How to setup VIM autoindentation properly for editing Python files - *.py","A_Content":"  for more advanced python editing consider installing the simplefold vim plugin. it allows you do advanced code folding using regular expressions. i use it to fold my class and method definitions for faster editing.     ","Language":"Python","Tags":["python","vim","configuration","spaces"],"URL":"https://stackoverflow.com/questions/65076/how-to-setup-vim-autoindentation-properly-for-editing-python-files-py","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I've troubles setting VIM (7.1.xxx) for editing python files.  Indenting seems to be broken (optimal 4 spaces). I've followed some tutorials I found via Google. Still no effect :/  Please help.     ","Q_Votes":"61"},{"Q_Title":"How does a Python set([]) check if two objects are equal? What methods does an object need to define to customise this?","A_Content":"  I am afraid you will have to provide a __hash__() method. But you can code it the way, that it does not depend on the mutable attributes of your Item.     ","Language":"Python","Tags":["python","methods","comparison","set"],"URL":"https://stackoverflow.com/questions/3942303/how-does-a-python-set-check-if-two-objects-are-equal-what-methods-does-an-o","A_Votes":"22","_type":"dict","isAccepted":"Yes","Q_Content":"    I need to create a 'container' object or class in Python, which keeps a record of other objects which I also define. One requirement of this container is that if two objects are deemed to be identical, one (either one) is removed. My first thought was to use a set([]) as the containing object, to complete this requirement.   However, the set does not remove one of the two identical object instances. What must I define to create one?   Here is the Python code.  class Item(object):   def __init__(self, foo, bar):     self.foo = foo     self.bar = bar   def __repr__(self):     return \"Item(%s, %s)\" % (self.foo, self.bar)   def __eq__(self, other):     if isinstance(other, Item):       return ((self.foo == other.foo) and (self.bar == other.bar))     else:       return False   def __ne__(self, other):     return (not self.__eq__(other))   Interpreter  >>> set([Item(1,2), Item(1,2)]) set([Item(1, 2), Item(1, 2)])   It is clear that __eq__(), which is called by x == y, is not the method called by the set. What is called? What other method must I define?  Note: The Items must remain mutable, and can change, so I cannot provide a __hash__() method. If this is the only way of doing it, then I will rewrite for use of immutable Items.     ","Q_Votes":"61"},{"Q_Title":"How does a Python set([]) check if two objects are equal? What methods does an object need to define to customise this?","A_Content":"  Yes, you need a __hash__()-method AND the comparing-operator which you already provided.  class Item(object):     def __init__(self, foo, bar):         self.foo = foo         self.bar = bar     def __repr__(self):         return \"Item(%s, %s)\" % (self.foo, self.bar)     def __eq__(self, other):         if isinstance(other, Item):             return ((self.foo == other.foo) and (self.bar == other.bar))         else:             return False     def __ne__(self, other):         return (not self.__eq__(other))     def __hash__(self):         return hash(self.__repr__())      ","Language":"Python","Tags":["python","methods","comparison","set"],"URL":"https://stackoverflow.com/questions/3942303/how-does-a-python-set-check-if-two-objects-are-equal-what-methods-does-an-o","A_Votes":"56","_type":"dict","isAccepted":"No","Q_Content":"    I need to create a 'container' object or class in Python, which keeps a record of other objects which I also define. One requirement of this container is that if two objects are deemed to be identical, one (either one) is removed. My first thought was to use a set([]) as the containing object, to complete this requirement.   However, the set does not remove one of the two identical object instances. What must I define to create one?   Here is the Python code.  class Item(object):   def __init__(self, foo, bar):     self.foo = foo     self.bar = bar   def __repr__(self):     return \"Item(%s, %s)\" % (self.foo, self.bar)   def __eq__(self, other):     if isinstance(other, Item):       return ((self.foo == other.foo) and (self.bar == other.bar))     else:       return False   def __ne__(self, other):     return (not self.__eq__(other))   Interpreter  >>> set([Item(1,2), Item(1,2)]) set([Item(1, 2), Item(1, 2)])   It is clear that __eq__(), which is called by x == y, is not the method called by the set. What is called? What other method must I define?  Note: The Items must remain mutable, and can change, so I cannot provide a __hash__() method. If this is the only way of doing it, then I will rewrite for use of immutable Items.     ","Q_Votes":"61"},{"Q_Title":"Python inheritance: TypeError: object.__init__() takes no parameters","A_Content":"  You are calling the wrong class name in your super() call:  class SimpleHelloWorld(IRCReplyModule):       def __init__(self):             #super(IRCReplyModule,self).__init__('hello world')             super(SimpleHelloWorld,self).__init__('hello world')   Essentially what you are resolving to is the __init__ of the object base class which takes no params.  Its a bit redundant, I know, to have to specify the class that you are already inside of, which is why in python3 you can just do:  super().__init__()     ","Language":"Python","Tags":["python","inheritance"],"URL":"https://stackoverflow.com/questions/11179008/python-inheritance-typeerror-object-init-takes-no-parameters","A_Votes":"80","_type":"dict","isAccepted":"Yes","Q_Content":"    I get this error:  TypeError: object.__init__() takes no parameters    when running my code, I don't really see what I'm doing wrong here though:  class IRCReplyModule(object):      activated=True     moduleHandlerResultList=None     moduleHandlerCommandlist=None     modulename=\"\"      def __init__(self,modulename):         self.modulename = modulename   class SimpleHelloWorld(IRCReplyModule):       def __init__(self):             super(IRCReplyModule,self).__init__('hello world')      ","Q_Votes":"61"},{"Q_Title":"Django, query filtering from model method","A_Content":"  You cannot query against model methods or properties. Either use the criteria within it in the query, or filter in Python using a list comprehension or genex.     ","Language":"Python","Tags":["python","django","django-models","django-queryset","django-orm"],"URL":"https://stackoverflow.com/questions/2276768/django-query-filtering-from-model-method","A_Votes":"31","_type":"dict","isAccepted":"Yes","Q_Content":"    I have these models:  def Foo(Models.model):     size = models.IntegerField()     # other fields      def is_active(self):          if check_condition:               return True          else:               return False  def Bar(Models.model):      foo = models.ForeignKey(\"Foo\")      # other fields   Now I want to query Bars that are having active Foo's as such:  Bar.objects.filter(foo.is_active())   I am getting error such as  SyntaxError at / ('non-keyword arg after keyword arg'   How can I achieve this?     ","Q_Votes":"61"},{"Q_Title":"Django, query filtering from model method","A_Content":"  You could also use a custom manager. Then you could run something like this:  Bar.objects.foo_active()   And all you have to do is:  class BarManager(models.Manager):     def foo_active(self):        # use your method to filter results        return you_custom_queryset   Check out the docs.     ","Language":"Python","Tags":["python","django","django-models","django-queryset","django-orm"],"URL":"https://stackoverflow.com/questions/2276768/django-query-filtering-from-model-method","A_Votes":"26","_type":"dict","isAccepted":"No","Q_Content":"    I have these models:  def Foo(Models.model):     size = models.IntegerField()     # other fields      def is_active(self):          if check_condition:               return True          else:               return False  def Bar(Models.model):      foo = models.ForeignKey(\"Foo\")      # other fields   Now I want to query Bars that are having active Foo's as such:  Bar.objects.filter(foo.is_active())   I am getting error such as  SyntaxError at / ('non-keyword arg after keyword arg'   How can I achieve this?     ","Q_Votes":"61"},{"Q_Title":"Django, query filtering from model method","A_Content":"  I had similar problem: I am using class-based view object_list and I had to filter by model's method. (storing the information in database wasn't an option because the property was based on time and I would have to create a cronjob and/or... no way)  My answer is ineffective and I don't know how it's gonna scale on larger data; but, it works:  q = Model.objects.filter(...)... # here is the trick q_ids = [o.id for o in q if o.method()] q = q.filter(id__in=q_ids)      ","Language":"Python","Tags":["python","django","django-models","django-queryset","django-orm"],"URL":"https://stackoverflow.com/questions/2276768/django-query-filtering-from-model-method","A_Votes":"15","_type":"dict","isAccepted":"No","Q_Content":"    I have these models:  def Foo(Models.model):     size = models.IntegerField()     # other fields      def is_active(self):          if check_condition:               return True          else:               return False  def Bar(Models.model):      foo = models.ForeignKey(\"Foo\")      # other fields   Now I want to query Bars that are having active Foo's as such:  Bar.objects.filter(foo.is_active())   I am getting error such as  SyntaxError at / ('non-keyword arg after keyword arg'   How can I achieve this?     ","Q_Votes":"61"},{"Q_Title":"Django, query filtering from model method","A_Content":"  You can't filter on methods, however if the is_active method on Foo checks an attribute on Foo, you can use the double-underscore syntax like Bar.objects.filter(foo__is_active_attribute=True)     ","Language":"Python","Tags":["python","django","django-models","django-queryset","django-orm"],"URL":"https://stackoverflow.com/questions/2276768/django-query-filtering-from-model-method","A_Votes":"10","_type":"dict","isAccepted":"No","Q_Content":"    I have these models:  def Foo(Models.model):     size = models.IntegerField()     # other fields      def is_active(self):          if check_condition:               return True          else:               return False  def Bar(Models.model):      foo = models.ForeignKey(\"Foo\")      # other fields   Now I want to query Bars that are having active Foo's as such:  Bar.objects.filter(foo.is_active())   I am getting error such as  SyntaxError at / ('non-keyword arg after keyword arg'   How can I achieve this?     ","Q_Votes":"61"},{"Q_Title":"Django, query filtering from model method","A_Content":"  class Page(models.Model):     category = models.ForeignKey(Category)     title = models.CharField(max_length=128)     url = models.URLField() ...  class Category(models.Model):     ...     open = models.BooleanField(default=True)   May be you can use simple filter, for this type of conditions.  Page.objects.filter(category__open=True)      ","Language":"Python","Tags":["python","django","django-models","django-queryset","django-orm"],"URL":"https://stackoverflow.com/questions/2276768/django-query-filtering-from-model-method","A_Votes":"0","_type":"dict","isAccepted":"No","Q_Content":"    I have these models:  def Foo(Models.model):     size = models.IntegerField()     # other fields      def is_active(self):          if check_condition:               return True          else:               return False  def Bar(Models.model):      foo = models.ForeignKey(\"Foo\")      # other fields   Now I want to query Bars that are having active Foo's as such:  Bar.objects.filter(foo.is_active())   I am getting error such as  SyntaxError at / ('non-keyword arg after keyword arg'   How can I achieve this?     ","Q_Votes":"61"},{"Q_Title":"Custom PyCharm docstring stubs (i.e. for google docstring or numpydoc formats)","A_Content":"  With PyCharm 5.0 we finally got to select Google and NumPy Style Python Docstrings templates.   It is also mentioned in the whatsnew section for PyCharm 5.0.  How to change the Docstring Format:     File --> Settings --> Tools --> Python Integrated Tools   There you can choose from the available Docstrings formats:      Plain, Epytext, reStructuredText, NumPy, Google   As pointed out by jstol: for Mac users, this is under      PyCharm -> Preferences -> Tools -> Python Integrated Tools.      ","Language":"Python","Tags":["python","pycharm","docstring","doctest"],"URL":"https://stackoverflow.com/questions/18666885/custom-pycharm-docstring-stubs-i-e-for-google-docstring-or-numpydoc-formats","A_Votes":"78","_type":"dict","isAccepted":"Yes","Q_Content":"    Does PyCharm 2.7 (or will PyCharm 3) have support for custom docstring and doctest stubs?  If so, how does one go about writing this specific type of custom extension?  My current project has standardized on using the Google Python Style Guide (http://google-styleguide.googlecode.com/svn/trunk/pyguide.html).  I love PyCharm's docstring support, but it's only two supported formats right now are epytext and reStructureText.  I want, and am willing to write myself, a PyCharm plugin that creates a documentation comment stub formatted in either Google or Numpydoc style (https://pypi.python.org/pypi/sphinxcontrib-napoleon/). Of special importance here is incorporating the type inference abilities that PyCharm has with the other two documentation types.     ","Q_Votes":"61"},{"Q_Title":"Custom PyCharm docstring stubs (i.e. for google docstring or numpydoc formats)","A_Content":"  As CrazyCoder mentions, its a ticket. Right now, you can only use EpyType and reStructuredText.     ","Language":"Python","Tags":["python","pycharm","docstring","doctest"],"URL":"https://stackoverflow.com/questions/18666885/custom-pycharm-docstring-stubs-i-e-for-google-docstring-or-numpydoc-formats","A_Votes":"4","_type":"dict","isAccepted":"No","Q_Content":"    Does PyCharm 2.7 (or will PyCharm 3) have support for custom docstring and doctest stubs?  If so, how does one go about writing this specific type of custom extension?  My current project has standardized on using the Google Python Style Guide (http://google-styleguide.googlecode.com/svn/trunk/pyguide.html).  I love PyCharm's docstring support, but it's only two supported formats right now are epytext and reStructureText.  I want, and am willing to write myself, a PyCharm plugin that creates a documentation comment stub formatted in either Google or Numpydoc style (https://pypi.python.org/pypi/sphinxcontrib-napoleon/). Of special importance here is incorporating the type inference abilities that PyCharm has with the other two documentation types.     ","Q_Votes":"61"},{"Q_Title":"Custom PyCharm docstring stubs (i.e. for google docstring or numpydoc formats)","A_Content":"  Just to be make @Nras answer explicit, as of PyCharm 5.0:     File > Settings > Tools > Python Integrated Tools > Docstrings  >   Google      ","Language":"Python","Tags":["python","pycharm","docstring","doctest"],"URL":"https://stackoverflow.com/questions/18666885/custom-pycharm-docstring-stubs-i-e-for-google-docstring-or-numpydoc-formats","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    Does PyCharm 2.7 (or will PyCharm 3) have support for custom docstring and doctest stubs?  If so, how does one go about writing this specific type of custom extension?  My current project has standardized on using the Google Python Style Guide (http://google-styleguide.googlecode.com/svn/trunk/pyguide.html).  I love PyCharm's docstring support, but it's only two supported formats right now are epytext and reStructureText.  I want, and am willing to write myself, a PyCharm plugin that creates a documentation comment stub formatted in either Google or Numpydoc style (https://pypi.python.org/pypi/sphinxcontrib-napoleon/). Of special importance here is incorporating the type inference abilities that PyCharm has with the other two documentation types.     ","Q_Votes":"61"},{"Q_Title":"Segmentation fault: 11 in OS X","A_Content":"  This is a bug in the readline compatibility in python, related to changes introduced in OSX10.9. This weekend, release candidates for Python2.7.6 and Python3.3.3 were released which fix this bug. The download links are below.  http://python.org/download/releases/2.7.6/  http://python.org/download/releases/3.3.3/  Here's the issue, quoting from Ned Deily, writing on the python-dev email list.     On Tuesday, Apple released OS X 10.9 (a.k.a. Mavericks).   There has already    been a lot of interest in it, in part because Apple has made it available for    free and has made it easy for users with 10.8, 10.7, and (most) 10.6 systems    to upgrade directly to 10.9.  Unfortunately, there are issues with our current    maintenance releases (3.3.2 and 2.7.5) on OS X 10.9 that call for new    maintenance releases as soon as possible.      One is critical in that it causes the interpreter to crash when running in    interactive mode (http://bugs.python.org/issue18458).  The problem was due to    a long-standing compatibility issue in libedit's readline compatibility layer    that upstream has finally fixed and Apple has now shipped in 10.9.  Because    the python.org installers dynamically link to libedit, the original workaround    in readline.c for the original design flaw in history indexing now causes a    segfault on 10.9 when the user types in the second command interactively.  Not    good.  Ronald devised a fix that allows readline.so at runtime to detect and    work with either version of libedit so that we continue to have binary    compatibility across multiple OS X releases.  That fix is already out in the    3.4.0 alphas and backported to the 3.3 and 2.7 branches, awaiting release    there.  Just in the last 12 hours, there have been at least four duplicates of    the issue reported by users.  I've updated the original issue to explicitly    mention 10.9, now that it is no longer under NDA, and to provide a    downloadable script for inexperienced users to workaround the problem by    \"removing\" readline.so.  Presumably, as word gets out, there will be fewer    duplicate issues opened but the impact will remain.      ","Language":"Python","Tags":["python","macos"],"URL":"https://stackoverflow.com/questions/19531969/segmentation-fault-11-in-os-x","A_Votes":"47","_type":"dict","isAccepted":"Yes","Q_Content":"    I am getting an issue in Python 3.3.2 on OSX 10.9 where if I open Python in a terminal window, it exits with \"Segmentation error: 11\" after the second line I enter, regardless of what the two commands are. For example, if I enter:  >>> for x in range(1000): print(x)   that works fine, but if I enter:  >>> for x in range(1000): ...     print(x)   then I get the error when I press enter on the second line. I can also run a script with more than 2 lines without any problems.  I updated to OSX 10.9 this afternoon, so I suspect that may be it.   However, I just recently installed IPython (along with several other packages) and have been using that the past couple of days, so it could be something else I installed recently. I had a couple unsuccessful attempts at installing PyQt where I ran configure.py but then the \"make\" command failed, which I was also suspicious of.  I tried reinstalling Python, but it didn't resolve the issue. Both IPython and IDLE work with no problems. I'm just concerned about what could be the underlying issue.     ","Q_Votes":"61"},{"Q_Title":"Segmentation fault: 11 in OS X","A_Content":"  I had this problem after upgrading to OS X 10.9 and used the patch provided on the Python website: http://bugs.python.org/issue18458#msg201087  To use it, open a terminal session in Terminal.app (or other shell), then enter:  curl -O http://bugs.python.org/file32324/patch_readline_issue_18458.sh openssl sha1 patch_readline_issue_18458.sh # the digest should be 7cb0ff57820a027dd4ca242eb2418930f8f46b4c   then     sh ./patch_readline_issue_18458.sh  Enter your password, if prompted     ","Language":"Python","Tags":["python","macos"],"URL":"https://stackoverflow.com/questions/19531969/segmentation-fault-11-in-os-x","A_Votes":"34","_type":"dict","isAccepted":"No","Q_Content":"    I am getting an issue in Python 3.3.2 on OSX 10.9 where if I open Python in a terminal window, it exits with \"Segmentation error: 11\" after the second line I enter, regardless of what the two commands are. For example, if I enter:  >>> for x in range(1000): print(x)   that works fine, but if I enter:  >>> for x in range(1000): ...     print(x)   then I get the error when I press enter on the second line. I can also run a script with more than 2 lines without any problems.  I updated to OSX 10.9 this afternoon, so I suspect that may be it.   However, I just recently installed IPython (along with several other packages) and have been using that the past couple of days, so it could be something else I installed recently. I had a couple unsuccessful attempts at installing PyQt where I ran configure.py but then the \"make\" command failed, which I was also suspicious of.  I tried reinstalling Python, but it didn't resolve the issue. Both IPython and IDLE work with no problems. I'm just concerned about what could be the underlying issue.     ","Q_Votes":"61"},{"Q_Title":"Segmentation fault: 11 in OS X","A_Content":"  I had this problem. Changing the chunksize in my csv parser to 100 eliminated the error.     ","Language":"Python","Tags":["python","macos"],"URL":"https://stackoverflow.com/questions/19531969/segmentation-fault-11-in-os-x","A_Votes":"2","_type":"dict","isAccepted":"No","Q_Content":"    I am getting an issue in Python 3.3.2 on OSX 10.9 where if I open Python in a terminal window, it exits with \"Segmentation error: 11\" after the second line I enter, regardless of what the two commands are. For example, if I enter:  >>> for x in range(1000): print(x)   that works fine, but if I enter:  >>> for x in range(1000): ...     print(x)   then I get the error when I press enter on the second line. I can also run a script with more than 2 lines without any problems.  I updated to OSX 10.9 this afternoon, so I suspect that may be it.   However, I just recently installed IPython (along with several other packages) and have been using that the past couple of days, so it could be something else I installed recently. I had a couple unsuccessful attempts at installing PyQt where I ran configure.py but then the \"make\" command failed, which I was also suspicious of.  I tried reinstalling Python, but it didn't resolve the issue. Both IPython and IDLE work with no problems. I'm just concerned about what could be the underlying issue.     ","Q_Votes":"61"},{"Q_Title":"Segmentation fault: 11 in OS X","A_Content":"  I was encountering similar 'segmentation fault 11' errors but for me it was using mercurial(hg)   This was trying to use Python 2.7.8 installed via the .mpkg installer and pip install mercurial On OS X 10.9.5  I thought updating to 2.7.8 would have resolved this but it seemed that mercurial was still looking for the System/Library/Frameworks/Python.framework/Versions/2.7  Even after trying to follow this slightly unwise advice Things still weren't working.  I would run   hg init hg add * hg commit -m ... hg status   would get 'segmentation fault 11'  The first couple of lines of the stack trace point to this:  Thread 0 Crashed:: Dispatch queue: com.apple.main-thread 0   ???                             000000000000000000 0 + 0 1   osutil.so                       0x00000001095ef768 listdir + 313 2   org.python.python               0x0000000109261b35 PyEval_EvalFrameEx + 14712 3   org.python.python               0x000000010925e093 PyEval_EvalCodeEx + 1641   In the end my solution seems to have come from (re)installing python with homebrew using that to get the 2.7.8 release (as of Dec 2014)  I then reinstalled mercurial with brew install mercurial which seems to have resolved whatever dependencies where causing this.  I wish I understood better what was happening with the Seg fault but couldn't get to the bottom of it.  The best guess I still have is that mercurial was still referencing the system python despite 2.7.8 being installed properly and usr/local/bin being first in the path  /usr/local/bin:usr/local/git/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/Library/Frameworks/Python.framework/Versions/3.4/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:~/Develop:/usr/local/git/bin: No such file or directory  So, what I'm suggesting is updating the python install with brew and then reinstalling whatever other packages you depend on.     ","Language":"Python","Tags":["python","macos"],"URL":"https://stackoverflow.com/questions/19531969/segmentation-fault-11-in-os-x","A_Votes":"1","_type":"dict","isAccepted":"No","Q_Content":"    I am getting an issue in Python 3.3.2 on OSX 10.9 where if I open Python in a terminal window, it exits with \"Segmentation error: 11\" after the second line I enter, regardless of what the two commands are. For example, if I enter:  >>> for x in range(1000): print(x)   that works fine, but if I enter:  >>> for x in range(1000): ...     print(x)   then I get the error when I press enter on the second line. I can also run a script with more than 2 lines without any problems.  I updated to OSX 10.9 this afternoon, so I suspect that may be it.   However, I just recently installed IPython (along with several other packages) and have been using that the past couple of days, so it could be something else I installed recently. I had a couple unsuccessful attempts at installing PyQt where I ran configure.py but then the \"make\" command failed, which I was also suspicious of.  I tried reinstalling Python, but it didn't resolve the issue. Both IPython and IDLE work with no problems. I'm just concerned about what could be the underlying issue.     ","Q_Votes":"61"}]