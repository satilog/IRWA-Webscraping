[
{"URL": "https://stackoverflow.com/questions/761804/how-do-i-trim-whitespace-from-a-python-string", "Language": "Python", "Q_Title": "How do I trim whitespace from a Python string?", "Q_Votes": "941", "Q_Content": "    How do I remove leading and trailing whitespace from a string in Python?  For example:  \" Hello \" --> \"Hello\" \" Hello\"  --> \"Hello\" \"Hello \"  --> \"Hello\" \"Bob has a cat\" --> \"Bob has a cat\"      ", "Tags": ["python", "string", "trim"], "A_Votes": "1443", "A_Content": "  Just one space, or all such spaces?  If the second, then strings already have a .strip() method:  >>> ' Hello '.strip() 'Hello' >>> ' Hello'.strip() 'Hello' >>> 'Bob has a cat'.strip() 'Bob has a cat' >>> '          Hello        '.strip()  # ALL spaces at ends removed 'Hello'   If you need only to remove one space however, you could do it with:  def strip_one_space(s):     if s.endswith(\" \"): s = s[:-1]     if s.startswith(\" \"): s = s[1:]     return s  >>> strip_one_space(\"   Hello \") '  Hello'   Also, note that str.strip() removes other whitespace characters as well (e.g. tabs and newlines).  To remove only spaces, you can specify the character to remove as an argument to strip, i.e.:  >>> \"  Hello\\n\".strip(\" \") 'Hello\\n'      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/761804/how-do-i-trim-whitespace-from-a-python-string", "Language": "Python", "Q_Title": "How do I trim whitespace from a Python string?", "Q_Votes": "941", "Q_Content": "    How do I remove leading and trailing whitespace from a string in Python?  For example:  \" Hello \" --> \"Hello\" \" Hello\"  --> \"Hello\" \"Hello \"  --> \"Hello\" \"Bob has a cat\" --> \"Bob has a cat\"      ", "Tags": ["python", "string", "trim"], "A_Votes": "227", "A_Content": "  As pointed out in answers above   myString.strip()   will remove all the leading and trailing whitespace characters such as \\n, \\r, \\t, \\f, space.  For more flexibility use the following   Removes only leading whitespace chars: myString.lstrip() Removes only trailing whitespace chars: myString.rstrip() Removes specific whitespace chars: myString.strip('\\n') or myString.lstrip('\\n\\r') or myString.rstrip('\\n\\t') and so on.   More details are available in the docs     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/761804/how-do-i-trim-whitespace-from-a-python-string", "Language": "Python", "Q_Title": "How do I trim whitespace from a Python string?", "Q_Votes": "941", "Q_Content": "    How do I remove leading and trailing whitespace from a string in Python?  For example:  \" Hello \" --> \"Hello\" \" Hello\"  --> \"Hello\" \"Hello \"  --> \"Hello\" \"Bob has a cat\" --> \"Bob has a cat\"      ", "Tags": ["python", "string", "trim"], "A_Votes": "102", "A_Content": "  strip is not limited to whitespace characters either:  # remove all leading/trailing commas, periods and hyphens title = title.strip(',.-')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/761804/how-do-i-trim-whitespace-from-a-python-string", "Language": "Python", "Q_Title": "How do I trim whitespace from a Python string?", "Q_Votes": "941", "Q_Content": "    How do I remove leading and trailing whitespace from a string in Python?  For example:  \" Hello \" --> \"Hello\" \" Hello\"  --> \"Hello\" \"Hello \"  --> \"Hello\" \"Bob has a cat\" --> \"Bob has a cat\"      ", "Tags": ["python", "string", "trim"], "A_Votes": "44", "A_Content": "  This will remove all leading and trailing whitespace in myString:  myString.strip()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/761804/how-do-i-trim-whitespace-from-a-python-string", "Language": "Python", "Q_Title": "How do I trim whitespace from a Python string?", "Q_Votes": "941", "Q_Content": "    How do I remove leading and trailing whitespace from a string in Python?  For example:  \" Hello \" --> \"Hello\" \" Hello\"  --> \"Hello\" \"Hello \"  --> \"Hello\" \"Bob has a cat\" --> \"Bob has a cat\"      ", "Tags": ["python", "string", "trim"], "A_Votes": "19", "A_Content": "  You want strip():  myphrases = [ \" Hello \", \" Hello\", \"Hello \", \"Bob has a cat\" ]  for phrase in myphrases:     print phrase.strip()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/761804/how-do-i-trim-whitespace-from-a-python-string", "Language": "Python", "Q_Title": "How do I trim whitespace from a Python string?", "Q_Votes": "941", "Q_Content": "    How do I remove leading and trailing whitespace from a string in Python?  For example:  \" Hello \" --> \"Hello\" \" Hello\"  --> \"Hello\" \"Hello \"  --> \"Hello\" \"Bob has a cat\" --> \"Bob has a cat\"      ", "Tags": ["python", "string", "trim"], "A_Votes": "-1", "A_Content": "  There is also a way to do it without that function  string = \"Hello Wor l d \" tmp_list = [] for char in string:     if char != \" \":     tmp_list +=char final_string = \"\".join(tmp_list) print final_string   But is just for fun :)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7943751/what-is-the-python-3-equivalent-of-python-m-simplehttpserver", "Language": "Python", "Q_Title": "What is the Python 3 equivalent of \u201cpython -m SimpleHTTPServer\u201d", "Q_Votes": "786", "Q_Content": "    What is the Python 3 equivalent of python -m SimpleHTTPServer?     ", "Tags": ["python", "python-3.x", "httpserver", "simplehttpserver"], "A_Votes": "1123", "A_Content": "  From the docs:     The SimpleHTTPServer module has been merged into http.server in Python 3.0. The 2to3 tool will automatically adapt imports when converting your sources to 3.0.   So, your command is python3 -m http.server.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/7943751/what-is-the-python-3-equivalent-of-python-m-simplehttpserver", "Language": "Python", "Q_Title": "What is the Python 3 equivalent of \u201cpython -m SimpleHTTPServer\u201d", "Q_Votes": "786", "Q_Content": "    What is the Python 3 equivalent of python -m SimpleHTTPServer?     ", "Tags": ["python", "python-3.x", "httpserver", "simplehttpserver"], "A_Votes": "170", "A_Content": "  The equivalent is:  python3 -m http.server      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7943751/what-is-the-python-3-equivalent-of-python-m-simplehttpserver", "Language": "Python", "Q_Title": "What is the Python 3 equivalent of \u201cpython -m SimpleHTTPServer\u201d", "Q_Votes": "786", "Q_Content": "    What is the Python 3 equivalent of python -m SimpleHTTPServer?     ", "Tags": ["python", "python-3.x", "httpserver", "simplehttpserver"], "A_Votes": "110", "A_Content": "  Using 2to3 utility.  $ cat try.py import SimpleHTTPServer  $ 2to3 try.py RefactoringTool: Skipping implicit fixer: buffer RefactoringTool: Skipping implicit fixer: idioms RefactoringTool: Skipping implicit fixer: set_literal RefactoringTool: Skipping implicit fixer: ws_comma RefactoringTool: Refactored try.py --- try.py  (original) +++ try.py  (refactored) @@ -1 +1 @@ -import SimpleHTTPServer +import http.server RefactoringTool: Files that need to be modified: RefactoringTool: try.py      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7943751/what-is-the-python-3-equivalent-of-python-m-simplehttpserver", "Language": "Python", "Q_Title": "What is the Python 3 equivalent of \u201cpython -m SimpleHTTPServer\u201d", "Q_Votes": "786", "Q_Content": "    What is the Python 3 equivalent of python -m SimpleHTTPServer?     ", "Tags": ["python", "python-3.x", "httpserver", "simplehttpserver"], "A_Votes": "44", "A_Content": "  If you must use a different port use:  python -m http.server 8080      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7943751/what-is-the-python-3-equivalent-of-python-m-simplehttpserver", "Language": "Python", "Q_Title": "What is the Python 3 equivalent of \u201cpython -m SimpleHTTPServer\u201d", "Q_Votes": "786", "Q_Content": "    What is the Python 3 equivalent of python -m SimpleHTTPServer?     ", "Tags": ["python", "python-3.x", "httpserver", "simplehttpserver"], "A_Votes": "29", "A_Content": "  In addition to Petr's answer, if you want to bind to a specific interface instead of all the interfaces you can use -b/--bind flag.  python -m http.server 8000 --bind 127.0.0.1   The above snippet should do the trick. 8000 is the port number. 80 is used as the standard port for HTTP communications.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7943751/what-is-the-python-3-equivalent-of-python-m-simplehttpserver", "Language": "Python", "Q_Title": "What is the Python 3 equivalent of \u201cpython -m SimpleHTTPServer\u201d", "Q_Votes": "786", "Q_Content": "    What is the Python 3 equivalent of python -m SimpleHTTPServer?     ", "Tags": ["python", "python-3.x", "httpserver", "simplehttpserver"], "A_Votes": "4", "A_Content": "  In one of my projects I run tests against Python 2 and 3. For that I wrote a small script which starts a local server independently:  $ python -m $(python -c 'import sys; print(\"http.server\" if sys.version_info[:2] > (2,7) else \"SimpleHTTPServer\")') Serving HTTP on 0.0.0.0 port 8000 ...   As an alias:  $ alias serve=\"python -m $(python -c 'import sys; print(\"http.server\" if sys.version_info[:2] > (2,7) else \"SimpleHTTPServer\")')\" $ serve Serving HTTP on 0.0.0.0 port 8000 ...   Please note that I control my Python version via conda environments, because of that I can use python instead of python3 for using Python 3.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7943751/what-is-the-python-3-equivalent-of-python-m-simplehttpserver", "Language": "Python", "Q_Title": "What is the Python 3 equivalent of \u201cpython -m SimpleHTTPServer\u201d", "Q_Votes": "786", "Q_Content": "    What is the Python 3 equivalent of python -m SimpleHTTPServer?     ", "Tags": ["python", "python-3.x", "httpserver", "simplehttpserver"], "A_Votes": "-1", "A_Content": "  if you have to choose which dir is root for website, forexample ./dist and port 9000: then use:   for v3  pushd ./dist; python -m http.server 9000; popd   for 2.*  pushd ./dist; python -m SimpleHTTPServer 9000; popd      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4015417/python-class-inherits-object", "Language": "Python", "Q_Title": "Python class inherits object", "Q_Votes": "787", "Q_Content": "    Is there any reason for a class declaration to inherit from object?  I just found some code that does this and I can't find a good reason why.  class MyClass(object):     # class code follows...      ", "Tags": ["python", "class", "object", "inheritance"], "A_Votes": "280", "A_Content": "     Is there any reason for a class declaration to inherit from object?   tl;dr: In Python 3, apart from compatibility between Python 2 and 3, no reason. In Python 2, many reasons.     Python 2.x story:  In Python 2.x (from 2.2 onwards) there's two styles of classes depending on the presence or absence of object as a base-class:   \"classic\" style classes: they don't have object as a base class:  >>> class ClassicSpam:      # no base class ...     pass >>> ClassicSpam.__bases__ ()  \"new\" style classes: they have, directly or indirectly (e.g inherit from a built-in type), object as a base class:  >>> class NewSpam(object):           # directly inherit from object ...    pass >>> NewSpam.__bases__ (<type 'object'>,) >>> class IntSpam(int):              # indirectly inherit from object... ...    pass >>> IntSpam.__bases__ (<type 'int'>,)  >>> IntSpam.__bases__[0].__bases__   # ... because int inherits from object   (<type 'object'>,)    Without a doubt, when writing a class you'll always want to go for new-style classes. The perks of doing so are numerous, to list some of them:   Support for descriptors. Specifically, the following constructs are made possible with descriptors:    classmethod: A method that receives the class as an implicit argument instead of the instance. staticmethod: A method that does not receive the implicit argument self as a first argument. properties with property: Create functions for managing the getting, setting and deleting of an attribute.  __slots__: Saves memory consumptions of a class and also results in faster attribute access. Of course, it does impose limitations.  The __new__ static method: lets you customize how new class instances are created.  Method resolution order (MRO): in what order the base classes of a class will be searched when trying to resolve which method to call.  Related to MRO, super calls. Also see, super() considered super.   If you don't inherit from object, forget these. A more exhaustive description of the previous bullet points along with other perks of \"new\" style classes can be found here.  One of the downsides of new-style classes is that the class itself is more memory demanding. Unless you're creating many class objects, though, I doubt this would be an issue and it's a negative sinking in a sea of positives.    Python 3.x story:  In Python 3, things are simplified. Only new-style classes exist (referred to plainly as classes) so, the only difference in adding object is requiring you to type in 8 more characters. This:  class ClassicSpam:     pass   is completely equivalent (apart from their name :-) to this:  class NewSpam(object):      pass   and to this:  class Spam():     pass   all have object in their __bases__.  >>> [object in cls.__bases__ for cls in {Spam, NewSpam, ClassicSpam}] [True, True, True]     So, what should you do?  In Python 2: always inherit from object explicitly. Get the perks.  In Python 3: inherit from object if you are writing code that tries to be Python agnostic, that is, it needs to work both in Python 2 and in Python 3. Otherwise don't, it really makes no difference since Python inserts it for you behind the scenes.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/4015417/python-class-inherits-object", "Language": "Python", "Q_Title": "Python class inherits object", "Q_Votes": "787", "Q_Content": "    Is there any reason for a class declaration to inherit from object?  I just found some code that does this and I can't find a good reason why.  class MyClass(object):     # class code follows...      ", "Tags": ["python", "class", "object", "inheritance"], "A_Votes": "497", "A_Content": "  Python 3.x: class MyClass(object): = new-style class class MyClass: = new-style class (implicitly inherits from object)  Python 2.x: class MyClass(object): = new-style class class MyClass: = OLD-STYLE CLASS  Explanation:  When defining base classes in Python 3.x, you\u2019re allowed to drop the object from the definition. However, this can open the door for a seriously hard to track problem\u2026  Python introduced new-style classes back in Python 2.2, and by now old-style classes are really quite old. Discussion of old-style classes is buried in the 2.x docs, and non-existent in the 3.x docs.  The problem is, the syntax for old-style classes in Python 2.x is the same as the alternative syntax for new-style classes in Python 3.x. Python 2.x is still very widely used (e.g. GAE, Web2Py), and any code (or coder) unwittingly bringing 3.x-style class definitions into 2.x code is going to end up with some seriously outdated base objects. And because old-style classes aren\u2019t on anyone\u2019s radar, they likely won\u2019t know what hit them.  So just spell it out the long way and save some 2.x developer the tears.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4015417/python-class-inherits-object", "Language": "Python", "Q_Title": "Python class inherits object", "Q_Votes": "787", "Q_Content": "    Is there any reason for a class declaration to inherit from object?  I just found some code that does this and I can't find a good reason why.  class MyClass(object):     # class code follows...      ", "Tags": ["python", "class", "object", "inheritance"], "A_Votes": "389", "A_Content": "  Yes, this is a 'new style' object. It was a feature introduced in python2.2.  New style objects have a different object model to classic objects, and some things won't work properly with old style objects, for instance, super(), @property and descriptors. See this article for a good description of what a new style class is.  SO link for a description of the differences: What is the difference between old style and new style classes in Python?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4015417/python-class-inherits-object", "Language": "Python", "Q_Title": "Python class inherits object", "Q_Votes": "787", "Q_Content": "    Is there any reason for a class declaration to inherit from object?  I just found some code that does this and I can't find a good reason why.  class MyClass(object):     # class code follows...      ", "Tags": ["python", "class", "object", "inheritance"], "A_Votes": "30", "A_Content": "  History from Learn Python the Hard Way:     Python's original rendition of a class was broken in many serious   ways. By the time this fault was recognized it was already too late,   and they had to support it. In order to fix the problem, they needed   some \"new class\" style so that the \"old classes\" would keep working   but you can use the new more correct version.      They decided that they would use a word \"object\", lowercased, to be   the \"class\" that you inherit from to make a class. It is confusing,   but a class inherits from the class named \"object\" to make a class but   it's not an object really its a class, but don't forget to inherit   from object.   Also just to let you know what the difference between new-style classes and old-style classes is, it's that new-style classes always inherit from  object class or from another class that inherited from object:  class NewStyle(object):     pass   Another example is:  class AnotherExampleOfNewStyle(NewStyle):     pass   While an old-style base class looks like this:  class OldStyle():     pass   And an old-style child class looks like this:  class OldStyleSubclass(OldStyle):     pass   You can see that an Old Style base class doesn't inherit from any other class, however, Old Style classes can, of course, inherit from one another. Inheriting from object guarantees that certain functionality is available in every Python class. New style classes were introduced in Python 2.2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4015417/python-class-inherits-object", "Language": "Python", "Q_Title": "Python class inherits object", "Q_Votes": "787", "Q_Content": "    Is there any reason for a class declaration to inherit from object?  I just found some code that does this and I can't find a good reason why.  class MyClass(object):     # class code follows...      ", "Tags": ["python", "class", "object", "inheritance"], "A_Votes": "23", "A_Content": "  Yes, it's historical. Without it, it creates an old-style class.  If you use type() on an old-style object, you just get \"instance\". On a new-style object you get its class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4015417/python-class-inherits-object", "Language": "Python", "Q_Title": "Python class inherits object", "Q_Votes": "787", "Q_Content": "    Is there any reason for a class declaration to inherit from object?  I just found some code that does this and I can't find a good reason why.  class MyClass(object):     # class code follows...      ", "Tags": ["python", "class", "object", "inheritance"], "A_Votes": "6", "A_Content": "  The syntax of the class creation statement:  class <ClassName>(superclass):     #code follows   In the absence of any other superclasses that you specifically want to inherit from, the superclass should always be object, which is the root of all classes in Python.  object is technically the root of \"new-style\" classes in Python. But the new-style classes today are as good as being the only style of classes.  But, if you don't explicitly use the word object when creating classes, then as others mentioned, Python 3.x implicitly inherits from the object superclass. But I guess explicit is always better than implicit (hell)  Reference     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4015417/python-class-inherits-object", "Language": "Python", "Q_Title": "Python class inherits object", "Q_Votes": "787", "Q_Content": "    Is there any reason for a class declaration to inherit from object?  I just found some code that does this and I can't find a good reason why.  class MyClass(object):     # class code follows...      ", "Tags": ["python", "class", "object", "inheritance"], "A_Votes": "1", "A_Content": "  This creates a new-style class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "723", "A_Content": "  This should be as simple as:  with open('somefile.txt', 'a') as the_file:     the_file.write('Hello\\n')   From The Documentation:     Do not use os.linesep as a line terminator when writing files opened in text mode (the default); use a single '\\n' instead, on all platforms.   Some useful reading:   The with statement open()   'a' is for append, or use 'w' to write with truncation  os (particularly os.linesep)      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "905", "A_Content": "  You should use the print() function which is available since Python 2.6+  from __future__ import print_function  # Only needed for Python 2 print(\"hi there\", file=f)   For Python 3 you don't need the import, since the  print() function is the default.  The alternative would be to use:  f = open('myfile', 'w') f.write('hi there\\n')  # python will convert \\n to os.linesep f.close()  # you can omit in most cases as the destructor will call it   Quoting from Python documentation regarding newlines:     On output, if newline is None, any '\\n' characters written are translated to the system default line separator, os.linesep. If newline is '', no translation takes place. If newline is any of the other legal values, any '\\n' characters written are translated to the given string.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "93", "A_Content": "  The python docs recommend this way:  with open('file_to_write', 'w') as f:     f.write('file contents')   So this is the way I usually do it :)  Statement from docs.python.org:     It is good practice to use the 'with' keyword when dealing with file   objects. This has the advantage that the file is properly closed after   its suite finishes, even if an exception is raised on the way. It is   also much shorter than writing equivalent try-finally blocks.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "80", "A_Content": "  Regarding os.linesep:  Here is an exact unedited Python 2.7.1 interpreter session on Windows:  Python 2.7.1 (r271:86832, Nov 27 2010, 18:30:46) [MSC v.1500 32 bit (Intel)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import os >>> os.linesep '\\r\\n' >>> f = open('myfile','w') >>> f.write('hi there\\n') >>> f.write('hi there' + os.linesep) # same result as previous line ????????? >>> f.close() >>> open('myfile', 'rb').read() 'hi there\\r\\nhi there\\r\\r\\n' >>>   On Windows:  As expected, os.linesep does NOT produce the same outcome as '\\n'. There is no way that it could produce the same outcome. 'hi there' + os.linesep is equivalent to 'hi there\\r\\n', which is NOT equivalent to 'hi there\\n'.  It's this simple: use \\n which will be translated automatically to os.linesep. And it's been that simple ever since the first port of Python to Windows.  There is no point in using os.linesep on non-Windows systems, and it produces wrong results on Windows.  DO NOT USE os.linesep!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "46", "A_Content": "  I do not think there is a \"correct\" way.  I would use:  with open ('myfile', 'a') as f: f.write ('hi there\\n')   In memoriam Tim Toady.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "17", "A_Content": "  In Python 3 it is a function, but in Python 2 you can add this to the top of the source file:  from __future__ import print_function   Then you do   print(\"hi there\", file=f)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "14", "A_Content": "  If you are writing a lot of data and speed is a concern you should probably go with f.write(...). I did a quick speed comparison and it was considerably faster than print(..., file=f) when performing a large number of writes.  import time      start = start = time.time() with open(\"test.txt\", 'w') as f:     for i in range(10000000):         # print('This is a speed test', file=f)         # f.write('This is a speed test\\n') end = time.time() print(end - start)   On average write finished in 2.45s on my machine, whereas print took about 4 times as long (9.76s). That being said, in most real-world scenarios this will not be an issue.  If you choose to go with print(..., file=f) you will probably find that you'll want to suppress the newline from time to time, or replace it with something else. This can be done by setting the optional end parameter, e.g.;  with open(\"test\", 'w') as f:     print('Foo1,', file=f, end='')     print('Foo2,', file=f, end='')     print('Foo3', file=f)   Whichever way you choose I'd suggest using with since it makes the code much easier to read.  Update: This difference in performance is explained by the fact that write is highly buffered and returns before any writes to disk actually take place (see this answer), whereas print (probably) uses line buffering. A simple test for this would be to check performance for long writes as well, where the disadvantages (in terms of speed) for line buffering would be less pronounced.  start = start = time.time() long_line = 'This is a speed test' * 100 with open(\"test.txt\", 'w') as f:     for i in range(1000000):         # print(long_line, file=f)         # f.write(long_line + '\\n') end = time.time()  print(end - start, \"s\")   The performance difference now becomes much less pronounced, with an average time of 2.20s for write and 3.10s for print. If you need to concatenate a bunch of strings to get this loooong line performance will suffer, so use-cases where print would be more efficient are a bit rare.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "5", "A_Content": "  When you said Line it means some serialized characters which are ended to '\\n' characters. Line should be last at some point so we should consider '\\n' at the end of each line. Here is solution:  with open('YOURFILE.txt', 'a') as the_file:     the_file.write('Hello')   in append mode after each write the cursor move to new line, if you want to use 'w' mode you should add '\\n' characters at the end of write() function:  the_file.write('Hello'+'\\n')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "0", "A_Content": "  One can also use the io module as in:  import io my_string = \"hi there\"  with io.open(\"output_file.txt\", mode='w', encoding='utf-8') as f:     f.write(my_string)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file", "Language": "Python", "Q_Title": "Correct way to write line to file?", "Q_Votes": "789", "Q_Content": "    I'm used to doing print >>f, \"hi there\"  However, it seems that print >> is getting deprecated. What is the recommended way to do the line above?  Update: Regarding all those answers with \"\\n\"...is this universal or Unix-specific? IE, should I be doing \"\\r\\n\" on Windows?     ", "Tags": ["python", "file-io"], "A_Votes": "0", "A_Content": "  Since 3.5 you can also use the pathlib for that purpose:     Path.write_text(data, encoding=None, errors=None)      Open the file pointed to in text mode, write data to it, and close the file:   import pathlib  pathlib.Path('textfile.txt').write_text('content')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "1211", "A_Content": "  You're looking for os.path.isdir, or os.path.exists if you don't care whether it's a file or a directory.  Example:  import os print(os.path.isdir(\"/home/el\")) print(os.path.exists(\"/home/el/myfile.txt\"))      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "52", "A_Content": "  So close! os.path.isdir returns True if you pass in the name of a directory that currently exists. If it doesn't exist or it's not a directory, then it returns False.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "29", "A_Content": "  Yes, use os.path.exists().     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "20", "A_Content": "  Python 3.4 introduced the pathlib module into the standard library, which provides an object oriented approach to handle filesystem paths:  In [1]: from pathlib import Path  In [2]: p = Path('/usr')  In [3]: p.exists() Out[3]: True  In [4]: p.is_dir() Out[4]: True  In [5]: q = p / 'bin' / 'vim'  In [6]: q.exists() Out[6]: True  In [7]: q.is_dir() Out[7]: False   Pathlib is also available on Python 2.7 via the pathlib2 module on PyPi.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "12", "A_Content": "  Yes use os.path.isdir(path)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "7", "A_Content": "  As in:  In [3]: os.path.exists('/d/temp') Out[3]: True   Probably toss in a os.path.isdir(...) to be sure.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "6", "A_Content": "  We can check with 2 built in functions   os.path.isdir(\"directory\")   It will give boolean true the specified directory is available.   os.path.exists(\"directoryorfile\")   It will give boolead true if specified directory or file is available.   To check whether the path is directory;   os.path.isdir(\"directorypath\")  will give boolean true if the path is directory     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "3", "A_Content": "  os provides you with a lot of these capabilities:  import os os.path.isdir(dir_in) #True/False: check if this is a directory os.listdir(dir_in)    #gets you a list of all files and directories under dir_in   the listdir will throw an exception if the input path is invalid.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "3", "A_Content": "  Just to provide the os.stat version (python 2):  import os, stat, errno def CheckIsDir(directory):   try:     return stat.S_ISDIR(os.stat(directory).st_mode)   except OSError, e:     if e.errno == errno.ENOENT:       return False     raise      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/8933237/how-to-find-if-directory-exists-in-python", "Language": "Python", "Q_Title": "How to find if directory exists in Python", "Q_Votes": "773", "Q_Content": "    In the os module in Python, is there a way to find if a directory exists, something like:  >>> os.direxists(os.path.join(os.getcwd()), 'new_folder')) # in pseudocode True/False      ", "Tags": ["python", "directory"], "A_Votes": "2", "A_Content": "  #You can also check it get help for you  if not os.path.isdir('mydir'):     print('new directry has been created')     os.system('mkdir mydir')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "589", "A_Content": "  I suggest ElementTree.  There are other compatible implementations of the same API, such as lxml, and cElementTree in the Python standard library itself; but, in this context, what they chiefly add is even more speed -- the ease of programming part depends on the API, which ElementTree defines.  After building an Element instance e from the XML, e.g. with the XML function, or by parsing a file with something like  import xml.etree.ElementTree e = xml.etree.ElementTree.parse('thefile.xml').getroot()   or any of the many other ways shown at ElementTree, you just do something like:  for atype in e.findall('type'):     print(atype.get('foobar'))   and similar, usually pretty simple, code patterns.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "380", "A_Content": "  minidom is the quickest and pretty straight forward:  XML:  <data>     <items>         <item name=\"item1\"></item>         <item name=\"item2\"></item>         <item name=\"item3\"></item>         <item name=\"item4\"></item>     </items> </data>   PYTHON:  from xml.dom import minidom xmldoc = minidom.parse('items.xml') itemlist = xmldoc.getElementsByTagName('item') print(len(itemlist)) print(itemlist[0].attributes['name'].value) for s in itemlist:     print(s.attributes['name'].value)   OUTPUT  4 item1 item1 item2 item3 item4      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "205", "A_Content": "  You can use BeautifulSoup  from bs4 import BeautifulSoup  x=\"\"\"<foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>\"\"\"  y=BeautifulSoup(x) >>> y.foo.bar.type[\"foobar\"] u'1'  >>> y.foo.bar.findAll(\"type\") [<type foobar=\"1\"></type>, <type foobar=\"2\"></type>]  >>> y.foo.bar.findAll(\"type\")[0][\"foobar\"] u'1' >>> y.foo.bar.findAll(\"type\")[1][\"foobar\"] u'2'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "77", "A_Content": "  There are many options out there. cElementTree looks excellent if speed and memory usage are an issue. It has very little overhead compared to simply reading in the file using readlines.  The relevant metrics can be found in the table below, copied from the cElementTree website:  library                         time    space xml.dom.minidom (Python 2.1)    6.3 s   80000K gnosis.objectify                2.0 s   22000k xml.dom.minidom (Python 2.4)    1.4 s   53000k ElementTree 1.2                 1.6 s   14500k   ElementTree 1.2.4/1.3           1.1 s   14500k   cDomlette (C extension)         0.540 s 20500k PyRXPU (C extension)            0.175 s 10850k libxml2 (C extension)           0.098 s 16000k readlines (read as utf-8)       0.093 s 8850k cElementTree (C extension)  --> 0.047 s 4900K <-- readlines (read as ascii)       0.032 s 5050k      As pointed out by @jfs, cElementTree comes bundled with Python:   Python 2: from xml.etree import cElementTree as ElementTree. Python 3: from xml.etree import ElementTree (the accelerated C version is used automatically).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "36", "A_Content": "  lxml.objectify is really simple.  Taking your sample text:  from lxml import objectify from collections import defaultdict  count = defaultdict(int)  root = objectify.fromstring(text)  for item in root.bar.type:     count[item.attrib.get(\"foobar\")] += 1  print dict(count)   Output:  {'1': 1, '2': 1}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "31", "A_Content": "  I suggest xmltodict for simplicity.  It parses your xml to an OrderedDict;  >>> e = '<foo>              <bar>                  <type foobar=\"1\"/>                  <type foobar=\"2\"/>              </bar>         </foo> '  >>> import xmltodict >>> result = xmltodict.parse(e) >>> result  OrderedDict([(u'foo', OrderedDict([(u'bar', OrderedDict([(u'type', [OrderedDict([(u'@foobar', u'1')]), OrderedDict([(u'@foobar', u'2')])])]))]))])  >>> result['foo']  OrderedDict([(u'bar', OrderedDict([(u'type', [OrderedDict([(u'@foobar', u'1')]), OrderedDict([(u'@foobar', u'2')])])]))])  >>> result['foo']['bar']  OrderedDict([(u'type', [OrderedDict([(u'@foobar', u'1')]), OrderedDict([(u'@foobar', u'2')])])])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "17", "A_Content": "  Python has an interface to the expat xml parser.  xml.parsers.expat   It's a non-validating parser, so bad xml will not be caught. But if you know your file is correct, then this is pretty good, and you'll probably get the exact info you want and you can discard the rest on the fly.  stringofxml = \"\"\"<foo>     <bar>         <type arg=\"value\" />         <type arg=\"value\" />         <type arg=\"value\" />     </bar>     <bar>         <type arg=\"value\" />     </bar> </foo>\"\"\" count = 0 def start(name, attr):     global count     if name == 'type':         count += 1  p = expat.ParserCreate() p.StartElementHandler = start p.Parse(stringofxml)  print count # prints 4      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "8", "A_Content": "  Here a very simple but effective code using cElementTree.   try:     import cElementTree as ET except ImportError:   try:     # Python 2.5 need to import a different module     import xml.etree.cElementTree as ET   except ImportError:     exit_err(\"Failed to import cElementTree from any known place\")        def find_in_tree(tree, node):     found = tree.find(node)     if found == None:         print \"No %s in file\" % node         found = []     return found    # Parse a xml file (specify the path) def_file = \"xml_file_name.xml\" try:     dom = ET.parse(open(def_file, \"r\"))     root = dom.getroot() except:     exit_err(\"Unable to open and parse input definition file: \" + def_file)  # Parse to find the child nodes list of node 'myNode' fwdefs = find_in_tree(root,\"myNode\")   Source:  http://www.snip2code.com/Snippet/991/python-xml-parse?fromPage=1     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "8", "A_Content": "  Just to add another possibility, you can use untangle, as it is a simple xml-to-python-object library. Here you have an example:  Installation  pip install untangle   Usage  Your xml file (a little bit changed):  <foo>    <bar name=\"bar_name\">       <type foobar=\"1\"/>    </bar> </foo>   accessing the attributes with untangle:  import untangle  obj = untangle.parse('/path_to_xml_file/file.xml')  print obj.foo.bar['name'] print obj.foo.bar.type['foobar']   the output will be:  bar_name 1   More information about untangle can be found here.Also (if you are curious), you can find a list of tools for working with XML and Python here (you will also see that the most common ones were mentioned by previous answers).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "8", "A_Content": "  I might suggest declxml.  Full disclosure: I wrote this library because I was looking for a way to convert between XML and Python data structures without needing to write dozens of lines of imperative parsing/serialization code with ElementTree.  With declxml, you use processors to declaratively define the structure of your XML document and how to map between XML and Python data structures. Processors are used to for both serialization and parsing as well as for a basic level of validation.  Parsing into Python data structures is straightforward:  import declxml as xml  xml_string = \"\"\" <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo> \"\"\"  processor = xml.dictionary('foo', [     xml.dictionary('bar', [         xml.array(xml.integer('type', attribute='foobar'))     ]) ])  xml.parse_from_string(processor, xml_string)   Which produces the output:  {'bar': {'foobar': [1, 2]}}   You can also use the same processor to serialize data to XML  data = {'bar': {     'foobar': [7, 3, 21, 16, 11] }}  xml.serialize_to_string(processor, data, indent='    ')   Which produces the following output  <?xml version=\"1.0\" ?> <foo>     <bar>         <type foobar=\"7\"/>         <type foobar=\"3\"/>         <type foobar=\"21\"/>         <type foobar=\"16\"/>         <type foobar=\"11\"/>     </bar> </foo>   If you want to work with objects instead of dictionaries, you can define processors to transform data to and from objects as well.  import declxml as xml  class Bar:      def __init__(self):         self.foobars = []      def __repr__(self):         return 'Bar(foobars={})'.format(self.foobars)   xml_string = \"\"\" <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo> \"\"\"  processor = xml.dictionary('foo', [     xml.user_object('bar', Bar, [         xml.array(xml.integer('type', attribute='foobar'), alias='foobars')     ]) ])  xml.parse_from_string(processor, xml_string)   Which produces the following output  {'bar': Bar(foobars=[1, 2])}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "6", "A_Content": "  I find the Python xml.dom and xml.dom.minidom quite easy. Keep in mind that DOM isn't good for large amounts of XML, but if your input is fairly small then this will work fine.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "4", "A_Content": "  import xml.etree.ElementTree as ET data = '''<foo>            <bar>                <type foobar=\"1\"/>                <type foobar=\"2\"/>           </bar>        </foo>''' tree = ET.fromstring(data) lst = tree.findall('bar/type') for item in lst:     print item.get('foobar')   This will print the value of foobar attribute.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python", "Language": "Python", "Q_Title": "How do I parse XML in Python?", "Q_Votes": "769", "Q_Content": "    I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   How can I access the attributes 1 and 2 in the XML using Python?     ", "Tags": ["python", "xml"], "A_Votes": "1", "A_Content": "  XML  <foo>    <bar>       <type foobar=\"1\"/>       <type foobar=\"2\"/>    </bar> </foo>   PYTHON_CODE  import xml.etree.cElementTree as ET  tree = ET.parse(\"foo.xml\") root = tree.getroot()  root_tag = root.tag print(root_tag)   for form in root.findall(\"./bar/type\"):     x=(form.attrib)     z=list(x)     for i in z:         print(x[i])   OUTPUT:  foo 1 2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "1038", "A_Content": "  import sys sys.exit()   details from the sys module documentation:     sys.exit([arg])           Exit from Python. This is implemented by raising the     SystemExit exception, so cleanup actions specified by finally clauses     of try statements are honored, and it is possible to intercept the     exit attempt at an outer level.          The optional argument arg can be an integer giving the exit status     (defaulting to zero), or another type of object. If it is an integer,     zero is considered \u201csuccessful termination\u201d and any nonzero value is     considered \u201cabnormal termination\u201d by shells and the like. Most systems     require it to be in the range 0-127, and produce undefined results     otherwise. Some systems have a convention for assigning specific     meanings to specific exit codes, but these are generally     underdeveloped; Unix programs generally use 2 for command line syntax     errors and 1 for all other kind of errors. If another type of object     is passed, None is equivalent to passing zero, and any other object is     printed to stderr and results in an exit code of 1. In particular,     sys.exit(\"some error message\") is a quick way to exit a program when     an error occurs.          Since exit() ultimately \u201conly\u201d raises an exception, it will only exit     the process when called from the main thread, and the exception is not     intercepted.      Note that this is the 'nice' way to exit.  @glyphtwistedmatrix below points out that if you want a 'hard exit', you can use os._exit(errorcode), though it's likely os-specific to some extent (it might not take an errorcode under windows, for example), and it definitely is less friendly since it doesn't let the interpreter do any cleanup before the process dies.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "931", "A_Content": "  While the question has been answered, I'd like to add some useful tips when using savefig. The file format can be specified by the extension:  savefig('foo.png') savefig('foo.pdf')   Will give a rasterized or vectorized output respectively, both which could be useful. In addition, you'll find that pylab leaves a generous, often undesirable, whitespace around the image. Remove it with:  savefig('foo.png', bbox_inches='tight')      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "221", "A_Content": "  A simple way to terminate a Python script early is to use the built-in function quit(). There is no need to import any library, and it is efficient and simple.  Example:  #do stuff if this == that:   quit()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "102", "A_Content": "  Another way is:  raise SystemExit      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "59", "A_Content": "  While you should generally prefer sys.exit because it is more \"friendly\" to other code, all it actually does is raise an exception.  If you are sure that you need to exit a process immediately, and you might be inside of some exception handler which would catch SystemExit, there is another function - os._exit - which terminates immediately at the C level and does not perform any of the normal tear-down of the interpreter; for example, hooks registered with the \"atexit\" module are not executed.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "47", "A_Content": "  You can also use simply exit().  Keep in mind that sys.exit(), exit(), quit(), and os._exit(0) kill the Python interpreter. Therefore, if it appears in a script called from another script by execfile(), it stops execution of both scripts.   See \"Stop execution of a script called with execfile\" to avoid this.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "25", "A_Content": "  from sys import exit exit()   As a parameter you can pass an exit code, which will be returned to OS. Default is 0.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "16", "A_Content": "  I'm a total novice but surely this is cleaner and more controlled  def main():     try:         Answer = 1/0         print  Answer     except:         print 'Program terminated'         return     print 'You wont see this'  if __name__ == '__main__':      main()   ...     Program terminated   than  import sys def main():     try:         Answer = 1/0         print  Answer     except:         print 'Program terminated'         sys.exit()     print 'You wont see this'  if __name__ == '__main__':      main()   ...          Program terminated Traceback (most recent call last):   File \"Z:\\Directory\\testdieprogram.py\", line 12, in          main()   File \"Z:\\Directory\\testdieprogram.py\", line 8, in main         sys.exit() SystemExit      Edit  The point being that the program ends smoothly and peacefully, rather than \"I'VE STOPPED !!!!\"     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "13", "A_Content": "  I've just found out that when writing a multithreadded app, raise SystemExit and sys.exit() both kills only the running thread. On the other hand, os._exit() exits the whole process. This was discussed here.  The example below has 2 threads. Kenny and Cartman. Cartman is supposed to live forever, but Kenny is called recursively and should die after 3 seconds. (recursive calling is not the best way, but I had other reasons)  If we also want Cartman to die when Kenny dies, Kenny should go away with os._exit, otherwise, only Kenny will die and Cartman will live forever.  import threading import time import sys import os  def kenny(num=0):     if num > 3:         # print(\"Kenny dies now...\")         # raise SystemExit #Kenny will die, but Cartman will live forever         # sys.exit(1) #Same as above          print(\"Kenny dies and also kills Cartman!\")         os._exit(1)     while True:         print(\"Kenny lives: {0}\".format(num))         time.sleep(1)         num += 1         kenny(num)  def cartman():     i = 0     while True:         print(\"Cartman lives: {0}\".format(i))         i += 1         time.sleep(1)  if __name__ == '__main__':     daemon_kenny = threading.Thread(name='kenny', target=kenny)     daemon_cartman = threading.Thread(name='cartman', target=cartman)     daemon_kenny.setDaemon(True)     daemon_cartman.setDaemon(True)      daemon_kenny.start()     daemon_cartman.start()     daemon_kenny.join()     daemon_cartman.join()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "5", "A_Content": "  In Python 3.5, I tried to incorporate similar code without use of modules (e.g. sys, Biopy) other than what's built-in to stop the script and print an error message to my users. Here's my example:  ## My example: if \"ATG\" in my_DNA:      ## <Do something & proceed...> else:      print(\"Start codon is missing! Check your DNA sequence!\");     exit(); ## as most folks said above   Later on, I found it is more succinct to just throw an error:  ## My example revised: if \"ATG\" in my_DNA:      ## <Do something & proceed...> else:      raise ValueError(\"Start codon is missing! Check your DNA sequence!\");      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/73663/terminating-a-python-script", "Language": "Python", "Q_Title": "Terminating a Python script", "Q_Votes": "760", "Q_Content": "    I am aware of the die() command in PHP which stops a script early.  How can I do this in Python?     ", "Tags": ["python", "termination"], "A_Votes": "0", "A_Content": "  try using break after a loop then use quit() or exit().     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "132", "A_Content": "  The solution is:   pylab.savefig('foo.png')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "119", "A_Content": "  As others have said, plt.savefig() or fig1.savefig() is indeed the way to save an image.  However I've found that in certain cases (eg. with Spyder having plt.ion(): interactive mode = On) the figure is always shown.  I work around this by forcing the closing of the figure window in my giant loop, so I don't have a million open figures during the loop:  import matplotlib.pyplot as plt fig, ax = plt.subplots( nrows=1, ncols=1 )  # create figure & 1 axis ax.plot([0,1,2], [10,20,3]) fig.savefig('path/to/save/image/to.png')   # save the figure to file plt.close(fig)    # close the figure      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "61", "A_Content": "  Just found this link on the MatPlotLib documentation addressing exactly this issue: http://matplotlib.org/faq/howto_faq.html#generate-images-without-having-a-window-appear  They say that the easiest way to prevent the figure from popping up is to use a non-interactive backend (eg. Agg), via matplotib.use(<backend>), eg:  import matplotlib matplotlib.use('Agg') import matplotlib.pyplot as plt plt.plot([1,2,3]) plt.savefig('myfig')   I still personally prefer using plt.close( fig ), since then you have the option to hide certain figures (during a loop), but still display figures for post-loop data processing. It is probably slower than choosing a non-interactive backend though - would be interesting if someone tested that.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "34", "A_Content": "  If you don't like the concept of the \"current\" figure, do:  import matplotlib.image as mpimg  img = mpimg.imread(\"src.png\") mpimg.imsave(\"out.png\", img)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "25", "A_Content": "  The other answers are correct.  However, I sometimes find that I want to open the figure object later.  For example, I might want to change the label sizes, add a grid, or do other processing.  In a perfect world, I would simply rerun the code generating the plot, and adapt the settings.  Alas, the world is not perfect.  Therefore, in addition to saving to PDF or PNG, I add:  with open('some_file.pkl', \"wb\") as fp:     pickle.dump(fig, fp, protocol=4)   Like this, I can later load the figure object and manipulate the settings as I please.  I also write out the stack with the source-code and locals() dictionary for each function/method in the stack, so that I can later tell exactly what generated the figure.  NB: Be careful, as sometimes this method generates huge files.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "22", "A_Content": "  import datetime import numpy as np from matplotlib.backends.backend_pdf import PdfPages import matplotlib.pyplot as plt  # Create the PdfPages object to which we will save the pages: # The with statement makes sure that the PdfPages object is closed properly at # the end of the block, even if an Exception occurs. with PdfPages('multipage_pdf.pdf') as pdf:     plt.figure(figsize=(3, 3))     plt.plot(range(7), [3, 1, 4, 1, 5, 9, 2], 'r-o')     plt.title('Page One')     pdf.savefig()  # saves the current figure into a pdf page     plt.close()      plt.rc('text', usetex=True)     plt.figure(figsize=(8, 6))     x = np.arange(0, 5, 0.1)     plt.plot(x, np.sin(x), 'b-')     plt.title('Page Two')     pdf.savefig()     plt.close()      plt.rc('text', usetex=False)     fig = plt.figure(figsize=(4, 5))     plt.plot(x, x*x, 'ko')     plt.title('Page Three')     pdf.savefig(fig)  # or you can pass a Figure object to pdf.savefig     plt.close()      # We can also set the file's metadata via the PdfPages object:     d = pdf.infodict()     d['Title'] = 'Multipage PDF Example'     d['Author'] = u'Jouni K. Sepp\\xe4nen'     d['Subject'] = 'How to create a multipage pdf file and set its metadata'     d['Keywords'] = 'PdfPages multipage keywords author title subject'     d['CreationDate'] = datetime.datetime(2009, 11, 13)     d['ModDate'] = datetime.datetime.today()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "18", "A_Content": "  After using the plot() and other functions to create the content you want, you could use a clause like this to select between plotting to the screen or to file:  import matplotlib.pyplot as plt  fig = plt.figure(figuresize=4, 5) # use plot(), etc. to create your plot.  # Pick one of the following lines to uncomment # save_file = None # save_file = os.path.join(your_directory, your_file_name)    if save_file:     plt.savefig(save_file)     plt.close(fig) else:     plt.show()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "16", "A_Content": "  I used the following:  import matplotlib.pyplot as plt  p1 = plt.plot(dates, temp, 'r-', label=\"Temperature (celsius)\")   p2 = plt.plot(dates, psal, 'b-', label=\"Salinity (psu)\")   plt.legend(loc='upper center', numpoints=1, bbox_to_anchor=(0.5, -0.05),        ncol=2, fancybox=True, shadow=True)  plt.savefig('data.png')   plt.show()   f.close() plt.close()   I found very important to use plt.show after saving the figure, otherwise it won't work.figure exported in png     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "11", "A_Content": "  If, like me, you use Spyder IDE, you have to disable the interactive mode with :  plt.ioff()  (this command is automatically launched with the scientific startup)  If you want to enable it again, use :  plt.ion()     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "10", "A_Content": "  The Solution :   import pandas as pd import numpy as np import matplotlib.pyplot as plt import matplotlib matplotlib.style.use('ggplot') ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000)) ts = ts.cumsum() plt.figure() ts.plot() plt.savefig(\"foo.png\", bbox_inches='tight')   If you do want to display the image as well as saving the image use:  %matplotlib inline   after  import matplotlib     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "10", "A_Content": "  You can either do:   plt.show(hold=False) plt.savefig('name.pdf')   and remember to let savefig finish before closing the GUI plot. This way you can see the image beforehand.   Alternatively, you can look at it with plt.show() Then close the GUI and run the script again, but this time replace plt.show() with plt.savefig().   Alternatively, you can use   fig, ax = plt.figure(nrows=1, ncols=1) plt.plot(...) plt.show() fig.savefig('out.pdf')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "3", "A_Content": "  #write the code for the plot      plt.savefig(\"filename.png\")   The file will be saved in the same directory as the python/Jupyter file running     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib", "Language": "Python", "Q_Title": "Save plot to image file instead of displaying it using Matplotlib", "Q_Votes": "767", "Q_Content": "    I am writing a quick-and-dirty script to generate plots on the fly. I am using the code below (from Matplotlib documentation) as a starting point:  from pylab import figure, axes, pie, title, show  # Make a square figure and axes figure(1, figsize=(6, 6)) ax = axes([0.1, 0.1, 0.8, 0.8])  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' fracs = [15, 30, 45, 10]  explode = (0, 0.05, 0, 0) pie(fracs, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True) title('Raining Hogs and Dogs', bbox={'facecolor': '0.8', 'pad': 5})  show()  # Actually, don't show, just save to foo.png   I don't want to display the plot on a GUI, instead, I want to save the plot to a file (say foo.png), so that, for example, it can be used in batch scripts. How do I do that?     ", "Tags": ["python", "matplotlib", "plot"], "A_Votes": "2", "A_Content": "  According to question Matplotlib (pyplot) savefig outputs blank image.  One thing should note: if you use plt.show and it should after plt.savefig, or you will give a blank image.  A detailed example:  import numpy as np import matplotlib.pyplot as plt   def draw_result(lst_iter, lst_loss, lst_acc, title):     plt.plot(lst_iter, lst_loss, '-b', label='loss')     plt.plot(lst_iter, lst_acc, '-r', label='accuracy')      plt.xlabel(\"n iteration\")     plt.legend(loc='upper left')     plt.title(title)     plt.savefig(title+\".png\")  # should before plt.show method      plt.show()   def test_draw():     lst_iter = range(100)     lst_loss = [0.01 * i + 0.01 * i ** 2 for i in xrange(100)]     # lst_loss = np.random.randn(1, 100).reshape((100, ))     lst_acc = [0.01 * i - 0.01 * i ** 2 for i in xrange(100)]     # lst_acc = np.random.randn(1, 100).reshape((100, ))     draw_result(lst_iter, lst_loss, lst_acc, \"sgd_method\")   if __name__ == '__main__':     test_draw()        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "1196", "A_Content": "  Just use the --python (or short -p) option when creating your virtualenv instance to specify the Python executable you want to use, e.g.:  virtualenv --python=/usr/bin/python2.6 <path/to/new/virtualenv/>   N.B. For Python 3.3 or later, refer to The Aelfinn's answer below. [Editor's note: I know this should normally be a comment, not an edit, but a new comment would be hidden, and I just spent 45 minutes untangling errors because this important answer was buried under three or four parrot answers. I'm just trying to save everyone time here.]     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "167", "A_Content": "  These are steps when you are on shared hosting environment and need to install & complie Python from source and then create venv from your Python version. For Python 2.7.9 you would do something along these lines:  mkdir ~/src wget http://www.python.org/ftp/python/2.7.9/Python-2.7.9.tgz tar -zxvf Python-2.7.9.tgz cd Python-2.7.9 mkdir ~/.localpython ./configure --prefix=$HOME/.localpython make make install   virtual env  cd ~/src wget https://pypi.python.org/packages/5c/79/5dae7494b9f5ed061cff9a8ab8d6e1f02db352f3facf907d9eb614fb80e9/virtualenv-15.0.2.tar.gz#md5=0ed59863994daf1292827ffdbba80a63 tar -zxvf virtualenv-15.0.2.tar.gz cd virtualenv-15.0.2/ ~/.localpython/bin/python setup.py install virtualenv ve -p $HOME/.localpython/bin/python2.7 source ve/bin/activate      Naturally this can be applicable to any situation where you want to replicate the exact environment you work and deploy on.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "143", "A_Content": "  UPDATE:  For Python3.6, the below pyvenv script is deprecated. Instead,  the Python Docs suggest creating the virtual environment with the following command:  python3 -m venv <myenvname>   For python3 (3.3+), use either the above method or the script pyvenv command.  pyvenv /path/to/new/virtual/environment   Please note that venv does not permit creating virtualenv with other versions of Python. For that, install and use the virtualenv package.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "90", "A_Content": "  virtualenv --python=/usr/bin/python2.6 <path/to/myvirtualenv>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "63", "A_Content": "  Under Windows for me this works:  virtualenv --python=c:\\Python25\\python.exe envname   without the python.exe I got WindowsError: [Error 5] Access is denied  I have Python2.7.1 installed with virtualenv 1.6.1, and I wanted python 2.5.2.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "59", "A_Content": "  There is an easier way,   virtualenv venv --python=python2.7   Thanks to  a comment, this only works if you have python2.7 installed at the system level (e.g. /usr/bin/python2.7).  Otherwise, if you are using homebrew you can use the path to give you what you want.  virtualenv venv --python=/usr/local/bin/python   You can find the path to your python installation with   which python   This will also work with python 3.   which python3 >> /usr/local/bin/python3 virtualenv venv --python=/usr/local/bin/python3   Ultimately condensing to:  virtualenv venv -p `which python` virtualenv venv -p `which python3`      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "27", "A_Content": "  Mac OSX 10.6.8 (Snow Leopard):  1) When you do pip install virtualenv, the pip command is associated with one of your python versions, and virtualenv gets installed into that version of python.  You can do   $ which pip      to see what version of python that is.  If you see something like:   $ which pip  /usr/local/bin/pip   then do:  $ ls -al /usr/local/bin/pip lrwxrwxr-x  1 root  admin  65 Apr 10  2015 /usr/local/bin/pip -> ../../../Library/Frameworks/Python.framework/Versions/2.7/bin/pip   You can see the python version in the output.  By default, that will be the version of python that is used for any new environment you create. However, you can specify any version of python installed on your computer to use inside a new environment with the -p flag:    $ virtualenv -p python3.2 my_env   Running virtualenv with interpreter /usr/local/bin/python3.2   New python executable in my_env/bin/python   Installing setuptools, pip...done.        virtualenv my_env will create a folder in the current directory which   will contain the Python executable files, and a copy of the pip   [command] which you can use to install other packages.   http://docs.python-guide.org/en/latest/dev/virtualenvs/  virtualenv just copies python from a location on your computer into the newly created my_env/bin/ directory.   2) The system python is in /usr/bin, while the various python versions I installed were, by default, installed into:   /usr/local/bin   3) The various pythons I installed have names like python2.7 or python3.2, and I can use those names rather than full paths.   ========VIRTUALENVWRAPPER=========  1) I had some problems getting virtualenvwrapper to work.  This is what I ended up putting in ~/.bash_profile:    export WORKON_HOME=$HOME/.virtualenvs export PROJECT_HOME=$HOME/django_projects  #Not very important -- mkproject command uses this #Added the following based on:  #http://stackoverflow.com/questions/19665327/virtualenvwrapper-installation-snow-leopard-python export VIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python2.7  #source /usr/local/bin/virtualenvwrapper.sh source /Library/Frameworks/Python.framework/Versions/2.7/bin/virtualenvwrapper.sh   2) The -p option works differently with virtualenvwrapper: I have to specify the full path to the python interpreter to be used in the new environment(when I do not want to use the default python version):    $ mkvirtualenv -p /usr/local/bin/python3.2 my_env Running virtualenv with interpreter /usr/local/bin/python3 New python executable in my_env/bin/python Installing setuptools, pip...done. Usage: source deactivate  removes the 'bin' directory of the environment activated with 'source activate' from PATH.    Unlike virtualenv, virtualenvwrapper will create the environment at the location specified by the $WORKON_HOME environment variable.  That keeps all your environments in one place.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "16", "A_Content": "  Suppose you currently have python 2.7 installed in your virtualenv. But want to make use of python3.2, You would have to update this with:  $ virtualenv --python=/usr/bin/python3.2 name_of_your_virtualenv   Then activate your virtualenv by:  $ source activate name_of_your_virtualenv   and then do: python --version in shell to check whether your version is now updated.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "10", "A_Content": "  You can call virtualenv with python version you want. For example:  python3 -m virtualenv venv   Or alternatively directly point to your virtualenv path. e.g. for windows:  c:\\Python34\\Scripts\\virtualenv.exe venv   And by running:  venv/bin/python  Python 3.5.1 (v3.5.1:37a07cee5969, Dec  5 2015, 21:12:44)  [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>>   you can see the python version installed in virtual environment     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "7", "A_Content": "  The -p approach works well, but you do have to remember to use it every time.  If your goal is to switch to a newer version of Python generally, that's a pain and can also lead to mistakes.  Your other option is to set an environment variable that does the same thing as -p. Set this via your ~/.bashrc file or wherever you manage environment variables for your login sessions:  export VIRTUALENV_PYTHON=/path/to/desired/version   Then virtualenv will use that any time you don't specify -p on the command line.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "6", "A_Content": "  On the mac I use pyenv and virtualenvwrapper. I had to create a new virtualenv. You need homebrew which I'll assume you've installed if you're on a mac, but just for fun:  ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"   brew install pyenv pyenv install 2.7.10 pyenv global 2.7.10 export PATH=/Users/{USERNAME}/.pyenv/versions/2.7.10/bin:$PATH mkvirtualenv -p ~/.pyenv/versions/2.7.10/bin/python  {virtual_env_name}   I also froze my requirements first so i could simply reinstall in the new virtualenv with:  pip install -r requirements.txt      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "1417", "A_Content": "  Like this:  >>> keys = ['a', 'b', 'c'] >>> values = [1, 2, 3] >>> dictionary = dict(zip(keys, values)) >>> print(dictionary) {'a': 1, 'b': 2, 'c': 3}   Voila :-)  The pairwise dict constructor and zip function are awesomely useful: https://docs.python.org/3/library/functions.html#func-dict     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "6", "A_Content": "  Even easier, by using command substitution to find python2 for you:  virtualenv -p $(which python2) <path/to/new/virtualenv/>  Or when using virtualenvwrapper :   mkvirtualenv -p $(which python2) <env_name>     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "4", "A_Content": "  In windows subsystem for linux:   Create environment for python3:  virtualenv --python=/usr/bin/python3 env  Activate it:  source env/bin/activate       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "3", "A_Content": "  For Mac(High Sierra), install the virtualenv in python3 and create a virtualenv for python2:  $ python3 -m virtualenv --python=python2 vp27 $ source vp27/bin/activate (vp27)$ python --version Python 2.7.14      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "3", "A_Content": "  These two commands should work fine for a newbie  virtualenv -p python2 myenv  (For python2)  virtualenv -p python3 myenv  (For python3)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "2", "A_Content": "  It worked for me  sudo apt-get install python3-minimal  virtualenv --no-site-packages --distribute -p /usr/bin/python3 ~/.virtualenvs/py3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "2", "A_Content": "  Yes, the above answers are correct and works fine on Unix based systems like Linux & MAC OS X.  I tried to create virtualenv for Python2 & Python3 with the following commands.  Here I have used venv2 & venv3 as their names for Python2 & Python3 respectively.     Python2 \u00bb   MacBook-Pro-2:~ admin$ virtualenv venv2 --python=`which python2` Running virtualenv with interpreter /usr/local/bin/python2 New python executable in /Users/admin/venv2/bin/python Installing setuptools, pip, wheel...done. MacBook-Pro-2:~ admin$  MacBook-Pro-2:~ admin$ ls venv2/bin/ activate        easy_install        pip2.7          python2.7 activate.csh        easy_install-2.7    python          wheel activate.fish       pip         python-config activate_this.py    pip2            python2 MacBook-Pro-2:~ admin$       Python3 \u00bb   MacBook-Pro-2:~ admin$ virtualenv venv3 --python=`which python3` Running virtualenv with interpreter /usr/local/bin/python3 Using base prefix '/Library/Frameworks/Python.framework/Versions/3.6' New python executable in /Users/admin/venv3/bin/python3 Also creating executable in /Users/admin/venv3/bin/python Installing setuptools, pip, wheel...done. MacBook-Pro-2:~ admin$  MacBook-Pro-2:~ admin$ ls venv3/bin/ activate        easy_install        pip3.6          python3.6 activate.csh        easy_install-3.6    python          wheel activate.fish       pip         python-config activate_this.py    pip3            python3 MacBook-Pro-2:~ admin$       Checking Python installation locations   MacBook-Pro-2:~ admin$ which python2 /usr/local/bin/python2 MacBook-Pro-2:~ admin$  MacBook-Pro-2:~ admin$ which python3 /usr/local/bin/python3 MacBook-Pro-2:~ admin$       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "1", "A_Content": "  On windows:  py -3.4x32 -m venv venv34   or   py -2.6.2 -m venv venv26   This uses the py launcher which will find the right python executable for you (assuming you have it installed).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv", "Language": "Python", "Q_Title": "Use different Python version with virtualenv", "Q_Votes": "793", "Q_Content": "    I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?  I compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "1", "A_Content": "  virtualenv -p python3 myenv   Link to Creating virtualenv     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "110", "A_Content": "  Try this:  >>> import itertools >>> keys = ('name', 'age', 'food') >>> values = ('Monty', 42, 'spam') >>> adict = dict(itertools.izip(keys,values)) >>> adict {'food': 'spam', 'age': 42, 'name': 'Monty'}   In Python 2, it's also more economical in memory consumption compared to zip.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "88", "A_Content": "     Imagine that you have:  keys = ('name', 'age', 'food') values = ('Monty', 42, 'spam')       What is the simplest way to produce the following dictionary ?  dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}    Most performant - Python 2.7 and 3, dict comprehension:  A possible improvement on using the dict constructor is to use the native syntax of a dict comprehension (not a list comprehension, as others have mistakenly put it):  new_dict = {k: v for k, v in zip(keys, values)}   In Python 2, zip returns a list, to avoid creating an unnecessary list, use izip instead (aliased to zip can reduce code changes when you move to Python 3).  from itertools import izip as zip   So that is still:  new_dict = {k: v for k, v in zip(keys, values)}   Python 2, ideal for <= 2.6  izip from itertools becomes zip in Python 3. izip is better than zip for Python 2 (because it avoids the unnecessary list creation), and ideal for 2.6 or below:  from itertools import izip new_dict = dict(izip(keys, values))   Python 3  In Python 3, zip becomes the same function that was in the itertools module, so that is simply:  new_dict = dict(zip(keys, values))   A dict comprehension would be more performant though (see performance review at the end of this answer).  Result for all cases:  In all cases:  >>> new_dict {'age': 42, 'name': 'Monty', 'food': 'spam'}   Explanation:  If we look at the help on dict we see that it takes a variety of forms of arguments:  >>> help(dict)  class dict(object)  |  dict() -> new empty dictionary  |  dict(mapping) -> new dictionary initialized from a mapping object's  |      (key, value) pairs  |  dict(iterable) -> new dictionary initialized as if via:  |      d = {}  |      for k, v in iterable:  |          d[k] = v  |  dict(**kwargs) -> new dictionary initialized with the name=value pairs  |      in the keyword argument list.  For example:  dict(one=1, two=2)   The optimal approach is to use an iterable while avoiding creating unnecessary data structures. In Python 2, zip creates an unnecessary list:  >>> zip(keys, values) [('name', 'Monty'), ('age', 42), ('food', 'spam')]   In Python 3, the equivalent would be:  >>> list(zip(keys, values)) [('name', 'Monty'), ('age', 42), ('food', 'spam')]   and Python 3's zip merely creates an iterable object:  >>> zip(keys, values) <zip object at 0x7f0e2ad029c8>   Since we want to avoid creating unnecessary data structures, we usually want to avoid Python 2's zip (since it creates an unnecessary list).  Less performant alternatives:  This is a generator expression being passed to the dict constructor:  generator_expression = ((k, v) for k, v in zip(keys, values)) dict(generator_expression)   or equivalently:  dict((k, v) for k, v in zip(keys, values))   And this is a list comprehension being passed to the dict constructor:  dict([(k, v) for k, v in zip(keys, values)])   In the first two cases, an extra layer of non-operative (thus unnecessary) computation is placed over the zip iterable, and in the case of the list comprehension, an extra list is unnecessarily created. I would expect all of them to be less performant, and certainly not more-so.  Performance review:  In 64 bit Python 3.4.3, on Ubuntu 14.04, ordered from fastest to slowest:  >>> min(timeit.repeat(lambda: {k: v for k, v in zip(keys, values)})) 0.7836067057214677 >>> min(timeit.repeat(lambda: dict(zip(keys, values)))) 1.0321204089559615 >>> min(timeit.repeat(lambda: {keys[i]: values[i] for i in range(len(keys))})) 1.0714934510178864 >>> min(timeit.repeat(lambda: dict([(k, v) for k, v in zip(keys, values)]))) 1.6110592018812895 >>> min(timeit.repeat(lambda: dict((k, v) for k, v in zip(keys, values)))) 1.7361853648908436      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "29", "A_Content": "  >>> keys = ('name', 'age', 'food') >>> values = ('Monty', 42, 'spam') >>> dict(zip(keys, values)) {'food': 'spam', 'age': 42, 'name': 'Monty'}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "26", "A_Content": "  You can also use dictionary comprehensions in Python \u2265 2.7:  >>> keys = ('name', 'age', 'food') >>> values = ('Monty', 42, 'spam') >>> {k: v for k, v in zip(keys, values)} {'food': 'spam', 'age': 42, 'name': 'Monty'}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "13", "A_Content": "  If you need to transform keys or values before creating a dictionary then a generator expression could be used. Example:  >>> adict = dict((str(k), v) for k, v in zip(['a', 1, 'b'], [2, 'c', 3]))    Take a look Code Like a Pythonista: Idiomatic Python.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "9", "A_Content": "  with Python 3.x, goes for dict comprehensions  keys = ('name', 'age', 'food') values = ('Monty', 42, 'spam')  dic = {k:v for k,v in zip(keys, values)}  print(dic)   More on dict comprehensions here, an example is there:  >>> print {i : chr(65+i) for i in range(4)}     {0 : 'A', 1 : 'B', 2 : 'C', 3 : 'D'}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "9", "A_Content": "  A more natural way is to use dictionary comprehension   keys = ('name', 'age', 'food') values = ('Monty', 42, 'spam')     dict = {keys[i]: values[i] for i in range(len(keys))}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "5", "A_Content": "  For those who need simple code and aren\u2019t familiar with zip:  List1 = ['This', 'is', 'a', 'list'] List2 = ['Put', 'this', 'into', 'dictionary']   This can be done by one line of code:  d = {List1[n]: List2[n] for n in range(len(List1))}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "2", "A_Content": "   2018-04-18   The best solution is still:  In [92]: keys = ('name', 'age', 'food') ...: values = ('Monty', 42, 'spam') ...:   In [93]: dt = dict(zip(keys, values)) In [94]: dt Out[94]: {'age': 42, 'food': 'spam', 'name': 'Monty'}   Tranpose it:      lst = [('name', 'Monty'), ('age', 42), ('food', 'spam')]     keys, values = zip(*lst)     In [101]: keys     Out[101]: ('name', 'age', 'food')     In [102]: values     Out[102]: ('Monty', 42, 'spam')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "1", "A_Content": "  you can use this below code:  dict(zip(['name', 'age', 'food'], ['Monty', 42, 'spam']))   But make sure that length of the lists will be same.if length is not same.then zip function turncate the longer one.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/209840/convert-two-lists-into-a-dictionary-in-python", "Language": "Python", "Q_Title": "Convert two lists into a dictionary in Python", "Q_Votes": "771", "Q_Content": "    Imagine that you have:  keys = ['name', 'age', 'food'] values = ['Monty', 42, 'spam']   What is the simplest way to produce the following dictionary?  a_dict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}      ", "Tags": ["python", "dictionary"], "A_Votes": "0", "A_Content": "  method without zip function  l1 = {1,2,3,4,5} l2 = {'a','b','c','d','e'} d1 = {} for l1_ in l1:     for l2_ in l2:         d1[l1_] = l2_         l2.remove(l2_)         break    print (d1)   {1: 'd', 2: 'b', 3: 'e', 4: 'a', 5: 'c'}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "910", "A_Content": "  For Python 3.5+ use:  import importlib.util spec = importlib.util.spec_from_file_location(\"module.name\", \"/path/to/file.py\") foo = importlib.util.module_from_spec(spec) spec.loader.exec_module(foo) foo.MyClass()   For Python 3.3 and 3.4 use:  from importlib.machinery import SourceFileLoader  foo = SourceFileLoader(\"module.name\", \"/path/to/file.py\").load_module() foo.MyClass()   (Although this has been deprecated in Python 3.4.)  Python 2 use:  import imp  foo = imp.load_source('module.name', '/path/to/file.py') foo.MyClass()   There are equivalent convenience functions for compiled Python files and DLLs.  See also. http://bugs.python.org/issue21436.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "317", "A_Content": "  The advantage of adding a path to sys.path (over using imp) is that it simplifies things when importing more than one module from a single package.  For example:  import sys # the mock-0.3.1 dir contains testcase.py, testutils.py & mock.py sys.path.append('/foo/bar/mock-0.3.1')  from testcase import TestCase from testutils import RunTests from mock import Mock, sentinel, patch      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "19", "A_Content": "  You can also do something like this and add the directory that the configuration file is sitting in to the Python load path, and then just do a normal import, assuming you know the name of the file in advance, in this case \"config\".  Messy, but it works.  configfile = '~/config.py'  import os import sys  sys.path.append(os.path.dirname(os.path.expanduser(configfile)))  import config      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "16", "A_Content": "  You can use the   load_source(module_name, path_to_file)    method from imp module.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "14", "A_Content": "  It sounds like you don't want to specifically import the configuration file (which has a whole lot of side effects and additional complications involved), you just want to run it, and be able to access the resulting namespace. The standard library provides an API specifically for that in the form of runpy.run_path:  from runpy import run_path settings = run_path(\"/path/to/file.py\")   That interface is available in Python 2.7 and Python 3.2+     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "10", "A_Content": "  def import_file(full_path_to_module):     try:         import os         module_dir, module_file = os.path.split(full_path_to_module)         module_name, module_ext = os.path.splitext(module_file)         save_cwd = os.getcwd()         os.chdir(module_dir)         module_obj = __import__(module_name)         module_obj.__file__ = full_path_to_module         globals()[module_name] = module_obj         os.chdir(save_cwd)     except:         raise ImportError  import_file('/home/somebody/somemodule.py')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "9", "A_Content": "  Do you mean load or import?  You can manipulate the sys.path list specify the path to your module, then import your module. For example, given a module at:  /foo/bar.py   You could do:  import sys sys.path[0:0] = '/foo' # puts the /foo directory at the start of your path import bar      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "8", "A_Content": "  I believe you can use imp.find_module() and imp.load_module() to load the specified module.  You'll need to split the module name off of the path, i.e. if you wanted to load /home/mypath/mymodule.py you'd need to do:  imp.find_module('mymodule', '/home/mypath/')   ...but that should get the job done.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "7", "A_Content": "  Here is some code that works in all Python versions, from 2.7-3.5 and probably even others.  config_file = \"/tmp/config.py\" with open(config_file) as f:     code = compile(f.read(), config_file, 'exec')     exec(code, globals(), locals())   I tested it. It may be ugly but so far is the only one that works in all versions.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "5", "A_Content": "  I have come up with a slightly modified version of @SebastianRittau's wonderful answer (for Python > 3.4 I think), which will allow you to load a file with any extension as a module using spec_from_loader instead of spec_from_file_location:  from importlib.util import spec_from_loader, module_from_spec from importlib.machinery import SourceFileLoader   spec = spec_from_loader(\"module.name\", SourceFileLoader(\"module.name\", \"/path/to/file.py\")) mod = module_from_spec(spec) spec.loader.exec_module(mod)   The advantage of encoding the path in an explicit SourceFileLoader is that the machinery will not try to figure out the type of the file from the extension. This means that you can load something like a .txt file using this method, but you could not do it with spec_from_file_location without specifying the loader because .txt is not in importlib.machinery.SOURCE_SUFFIXES.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "5", "A_Content": "  If your top-level module is not a file but is packaged as a directory with __init__.py, then the accepted solution almost works, but not quite. In Python 3.5+ the following code is needed (note the added line that begins with 'sys.modules'):  MODULE_PATH = \"/path/to/your/module/__init__.py\" MODULE_NAME = \"mymodule\" spec = importlib.util.spec_from_file_location(\"mymodule\", MODULE_PATH) module = importlib.util.module_from_spec(spec) sys.modules[spec.name] = module  spec.loader.exec_module(module)   Without this line, when exec_module is executed, it tries to bind relative imports in your top level __init__.py to the top level module name -- in this case \"mymodule\". But \"mymodule\" isn't loaded yet so you'll get the error \"SystemError: Parent module 'mymodule' not loaded, cannot perform relative import\". So you need to bind the name before you load it. The reason for this is the fundamental invariant of the relative import system: \"The invariant holding is that if you have sys.modules['spam'] and sys.modules['spam.foo'] (as you would after the above import), the latter must appear as the foo attribute of the former\" as discussed here.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "3", "A_Content": "  This should work  path = os.path.join('./path/to/folder/with/py/files', '*.py') for infile in glob.glob(path):     basename = os.path.basename(infile)     basename_without_extension = basename[:-3]      # http://docs.python.org/library/imp.html?highlight=imp#module-imp     imp.load_source(basename_without_extension, infile)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "3", "A_Content": "  This area of Python 3.4 seems to be extremely tortuous to understand! However with a bit of hacking using the code from Chris Calloway as a start I managed to get something working. Here's the basic function.  def import_module_from_file(full_path_to_module):     \"\"\"     Import a module given the full path/filename of the .py file      Python 3.4      \"\"\"      module = None      try:          # Get module name and path from full path         module_dir, module_file = os.path.split(full_path_to_module)         module_name, module_ext = os.path.splitext(module_file)          # Get module \"spec\" from filename         spec = importlib.util.spec_from_file_location(module_name,full_path_to_module)          module = spec.loader.load_module()      except Exception as ec:         # Simple error printing         # Insert \"sophisticated\" stuff here         print(ec)      finally:         return module   This appears to use non-deprecated modules from Python 3.4. I don't pretend to understand why, but it seems to work from within a program. I found Chris' solution worked on the command line but not from inside a program.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "3", "A_Content": "  I'm not saying that it is better, but for the sake of completeness, I wanted to suggest the exec function, available in both python 2 and 3. exec allows you to execute arbitrary code in either the global scope, or in an internal scope, provided as a dictionary.  For example, if you have a module stored in \"/path/to/module\" with the function foo(), you could run it by doing the following:  module = dict() with open(\"/path/to/module\") as f:     exec(f.read(), module) module['foo']()   This makes it a bit more explicit that you're loading code dynamically, and grants you some additional power, such as the ability to provide custom builtins.   And if having access through attributes, instead of keys is important to you, you can design a custom dict class for the globals, that provides such access, e.g.:  class MyModuleClass(dict):     def __getattr__(self, name):         return self.__getitem__(name)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "3", "A_Content": "  To import a module from a given filename, you can temporarily extend the path, and restore the system path in the finally block reference:  filename = \"directory/module.py\"  directory, module_name = os.path.split(filename) module_name = os.path.splitext(module_name)[0]  path = list(sys.path) sys.path.insert(0, directory) try:     module = __import__(module_name) finally:     sys.path[:] = path # restore      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "2", "A_Content": "  Import package modules at runtime (Python recipe)   http://code.activestate.com/recipes/223972/  ################### ##                # ## classloader.py # ##                # ###################  import sys, types  def _get_mod(modulePath):     try:         aMod = sys.modules[modulePath]         if not isinstance(aMod, types.ModuleType):             raise KeyError     except KeyError:         # The last [''] is very important!         aMod = __import__(modulePath, globals(), locals(), [''])         sys.modules[modulePath] = aMod     return aMod  def _get_func(fullFuncName):     \"\"\"Retrieve a function object from a full dotted-package name.\"\"\"      # Parse out the path, module, and function     lastDot = fullFuncName.rfind(u\".\")     funcName = fullFuncName[lastDot + 1:]     modPath = fullFuncName[:lastDot]      aMod = _get_mod(modPath)     aFunc = getattr(aMod, funcName)      # Assert that the function is a *callable* attribute.     assert callable(aFunc), u\"%s is not callable.\" % fullFuncName      # Return a reference to the function itself,     # not the results of the function.     return aFunc  def _get_class(fullClassName, parentClass=None):     \"\"\"Load a module and retrieve a class (NOT an instance).      If the parentClass is supplied, className must be of parentClass     or a subclass of parentClass (or None is returned).     \"\"\"     aClass = _get_func(fullClassName)      # Assert that the class is a subclass of parentClass.     if parentClass is not None:         if not issubclass(aClass, parentClass):             raise TypeError(u\"%s is not a subclass of %s\" %                             (fullClassName, parentClass))      # Return a reference to the class itself, not an instantiated object.     return aClass   ###################### ##       Usage      ## ######################  class StorageManager: pass class StorageManagerMySQL(StorageManager): pass  def storage_object(aFullClassName, allOptions={}):     aStoreClass = _get_class(aFullClassName, StorageManager)     return aStoreClass(allOptions)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "2", "A_Content": "  You can use the pkgutil module (specifically the walk_packages method) to get a list of the packages in the current directory. From there it's trivial to use the importlib machinery to import the modules you want:  import pkgutil import importlib  packages = pkgutil.walk_packages(path='.') for importer, name, is_package in packages:     mod = importlib.import_module(name)     # do whatever you want with module now, it's been imported!      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "2", "A_Content": "  In Linux, adding a symbolic link in the directory your python script is located works.  ie:   ln -s /absolute/path/to/module/module.py /absolute/path/to/script/module.py   python will create /absolute/path/to/script/module.pyc and will update it if you change the contents of /absolute/path/to/module/module.py  then include the following in mypythonscript.py  from module import *      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "1", "A_Content": "  I made a package that uses imp for you. I call it import_file and this is how it's used:  >>>from import_file import import_file >>>mylib = import_file('c:\\\\mylib.py') >>>another = import_file('relative_subdir/another.py')   You can get it at:  http://pypi.python.org/pypi/import_file  or at  http://code.google.com/p/import-file/     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "1", "A_Content": "  quite simple way: suppose you want import file with relative path ../../MyLibs/pyfunc.py   libPath = '../../MyLibs' import sys if not libPath in sys.path: sys.path.append(libPath) import pyfunc as pf   But if you make it without a guard you can finally get a very long path     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "1", "A_Content": "  A simple solution using importlib instead of the imp package (tested for Python 2.7, although it should work for Python 3 too):  import importlib  dirname, basename = os.path.split(pyfilepath) # pyfilepath: '/my/path/mymodule.py' sys.path.append(dirname) # only directories should be added to PYTHONPATH module_name = os.path.splitext(basename)[0] # '/my/path/mymodule.py' --> 'mymodule' module = importlib.import_module(module_name) # name space of defined module (otherwise we would literally look for \"module_name\")   Now you can directly use the namespace of the imported module, like this:  a = module.myvar b = module.myfunc(a)   The advantage of this solution is that we don't even need to know the actual name of the module we would like to import, in order to use it in our code. This is useful, e.g. in case the path of the module is a configurable argument.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "0", "A_Content": "  Adding this to the list of answers as I couldn't find anything that worked. This will allow imports of compiled (pyd) python modules in 3.4:  import sys import importlib.machinery  def load_module(name, filename):     # If the Loader finds the module name in this list it will use     # module_name.__file__ instead so we need to delete it here     if name in sys.modules:         del sys.modules[name]     loader = importlib.machinery.ExtensionFileLoader(name, filename)     module = loader.load_module()     locals()[name] = module     globals()[name] = module  load_module('something', r'C:\\Path\\To\\something.pyd') something.do_something()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "0", "A_Content": "  This answer is a supplement to Sebastian Rittau's answer responding to the comment: \"but what if you don't have the module name?\"  This is a quick and dirty way of getting the likely python module name given a filename -- it just goes up the tree until it finds a directory without an __init__.py file and then turns it back into a filename.  For Python 3.4+ (uses pathlib), which makes sense since Py2 people can use \"imp\" or other ways of doing relative imports:  import pathlib  def likely_python_module(filename):     '''     Given a filename or Path, return the \"likely\" python module name.  That is, iterate     the parent directories until it doesn't contain an __init__.py file.      :rtype: str     '''     p = pathlib.Path(filename).resolve()     paths = []     if p.name != '__init__.py':         paths.append(p.stem)     while True:         p = p.parent         if not p:             break         if not p.is_dir():             break          inits = [f for f in p.iterdir() if f.name == '__init__.py']         if not inits:             break          paths.append(p.stem)      return '.'.join(reversed(paths))   There are certainly possibilities for improvement, and the optional __init__.py files might necessitate other changes, but if you have __init__.py in general, this does the trick.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path", "Language": "Python", "Q_Title": "How to import a module given the full path?", "Q_Votes": "792", "Q_Content": "    How can I load a Python module given its full path? Note that the file can be anywhere in the filesystem, as it is a configuration option.     ", "Tags": ["python", "configuration", "python-import", "python-module"], "A_Votes": "-1", "A_Content": "  The best way, I think, is from the official documentation (29.1. imp \u2014 Access the import internals):  import imp import sys  def __import__(name, globals=None, locals=None, fromlist=None):     # Fast path: see if the module has already been imported.     try:         return sys.modules[name]     except KeyError:         pass      # If any of the following calls raises an exception,     # there's a problem we can't handle -- let the caller handle it.      fp, pathname, description = imp.find_module(name)      try:         return imp.load_module(name, fp, pathname, description)     finally:         # Since we may exit via an exception, close fp explicitly.         if fp:             fp.close()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/227459/ascii-value-of-a-character-in-python", "Language": "Python", "Q_Title": "ASCII value of a character in Python", "Q_Votes": "805", "Q_Content": "    How do I get the ASCII value of a character as an int in Python?     ", "Tags": ["python", "ascii"], "A_Votes": "1046", "A_Content": "  From here:     function ord() would get the int value   of the char. And in case you want to   convert back after playing with the   number, function chr() does the trick.   >>> ord('a') 97 >>> chr(97) 'a' >>> chr(ord('a') + 3) 'd' >>>   In Python 2, there is also the unichr function, returning the Unicode character whose ordinal is the unichr argument:  >>> unichr(97) u'a' >>> unichr(1234) u'\\u04d2'   In Python 3 you can use chr instead of unichr.    ord() - Python 3.6.5rc1 documentation  ord() - Python 2.7.14 documentation     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/227459/ascii-value-of-a-character-in-python", "Language": "Python", "Q_Title": "ASCII value of a character in Python", "Q_Votes": "805", "Q_Content": "    How do I get the ASCII value of a character as an int in Python?     ", "Tags": ["python", "ascii"], "A_Votes": "141", "A_Content": "  Note that ord() doesn't give you the ASCII value per se; it gives you the numeric value of the character in whatever encoding it's in. Therefore the result of ord('\u00e4') can be 228 if you're using Latin-1, or it can raise a TypeError if you're using UTF-8. It can even return the Unicode codepoint instead if you pass it a unicode:  >>> ord(u'\u3042') 12354      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/227459/ascii-value-of-a-character-in-python", "Language": "Python", "Q_Title": "ASCII value of a character in Python", "Q_Votes": "805", "Q_Content": "    How do I get the ASCII value of a character as an int in Python?     ", "Tags": ["python", "ascii"], "A_Votes": "41", "A_Content": "  You are looking for:  ord()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/227459/ascii-value-of-a-character-in-python", "Language": "Python", "Q_Title": "ASCII value of a character in Python", "Q_Votes": "805", "Q_Content": "    How do I get the ASCII value of a character as an int in Python?     ", "Tags": ["python", "ascii"], "A_Votes": "16", "A_Content": "  The accepted answer is correct, but there is a more clever/efficient way to do this if you need to convert a whole bunch of ASCII characters to their ASCII codes at once. Instead of doing:        for ch in mystr:     code = ord(ch)   or the slightly faster:  for code in map(ord, mystr):   you convert to Python native types that iterate the codes directly. On Python 3, it's trivial:  for code in mystr.encode('ascii'):   and on Python 2.6/2.7, it's only slightly more involved because it doesn't have a Py3 style bytes object (bytes is an alias for str, which iterates by character), but they do have bytearray:  # If mystr is definitely str, not unicode for code in bytearray(mystr):  # If mystr could be either str or unicode for code in bytearray(mystr, 'ascii'):   Encoding as a type that natively iterates by ordinal means the conversion goes much faster; in local tests on both Py2.7 and Py3.5, iterating a str to get its ASCII codes using map(ord, mystr) starts off taking about twice as long for a len 10 str than using bytearray(mystr) on Py2 or mystr.encode('ascii') on Py3, and as the str gets longer, the multiplier paid for map(ord, mystr) rises to ~6.5x-7x.  The only downside is that the conversion is all at once, so your first result might take a little longer, and a truly enormous str would have a proportionately large temporary bytes/bytearray, but unless this forces you into page thrashing, this isn't likely to matter.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "11", "A_Content": "  I managed to solve this issue and generate the .so file in one command   gcc -shared -o UtilcS.so -fPIC -I/usr/include/python2.7 -lpython2.7  utilsmodule.c      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "1430", "A_Content": "  Looks like you haven't properly installed the header files and static libraries for python dev.  Use your package manager to install them system-wide.    For apt (Ubuntu, Debian...):  sudo apt-get install python-dev   # for python2.x installs sudo apt-get install python3-dev  # for python3.x installs   For yum (CentOS, RHEL...):  sudo yum install python-devel   # for python2.x installs sudo yum install python34-devel   # for python3.4 installs   For dnf (Fedora...):  sudo dnf install python2-devel  # for python2.x installs sudo dnf install python3-devel  # for python3.x installs   For zypper (openSUSE...):  sudo zypper in python-devel   # for python2.x installs sudo zypper in python3-devel  # for python3.x installs   For apk (Alpine...):  # This is a departure from the normal Alpine naming # scheme, which uses py2- and py3- prefixes sudo apk add python2-dev  # for python2.x installs sudo apk add python3-dev  # for python3.x installs      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "232", "A_Content": "  On Ubuntu, I was running Python 3 and I had to install   sudo apt-get install python3-dev   If you want to use a version of Python that is not linked to python3, install the associated python3.x-dev package.  For example:  sudo apt-get install python3.5-dev      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "55", "A_Content": "  Two things you have to do.  Install development package for Python, in case of Debian/Ubuntu/Mint it's done with command:  sudo apt-get install python-dev   Second thing is that include files are not by default in the include path, nor is Python library linked with executable by default. You need to add these flags (replace Python's version accordingly):  -I/usr/include/python2.7 -lpython2.7    In other words your compile command ought to be:  gcc -Wall -I/usr/include/python2.7 -lpython2.7  utilsmodule.c -o Utilc       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "44", "A_Content": "  If you are using a Raspberry Pi:  sudo apt-get install python-dev      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "31", "A_Content": "  on Fedora run this for Python 2:  sudo dnf install python2-devel   and for Python 3:  sudo dnf install python3-devel      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "26", "A_Content": "  If you are using tox to run tests on multiple versions of Python, you may need to install the Python dev libraries for each version of Python you are testing on.  sudo apt-get install python2.6-dev  sudo apt-get install python2.7-dev  etc.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "21", "A_Content": "  I would like to add also the solution for Cygwin:  You need to install the package python2-devel or python3-devel, depending on the Python version you're using.   You can quickly install it using the 32-bit or 64-bit setup.exe (depending on your installation) from Cygwin.com.  Example (modify setup.exe's filename and Python's major version if you need):  $ setup.exe -q --packages=python3-devel   You can also check my other answer for a few more options to install Cygwin's packages from the command-line.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "18", "A_Content": "  In AWS API (centOS) its   yum install python27-devel      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "18", "A_Content": "  For me, changing it to this worked:  #include <python2.7/Python.h>   I found the file /usr/include/python2.7/Python.h, and since /usr/include is already in the include path, then python2.7/Python.h should be sufficient.  You could also add the include path from command line instead - gcc -I/usr/lib/python2.7 (thanks @erm3nda).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "14", "A_Content": "  Make sure that the Python dev files come with your OS.  You should not hard code the library and include paths. Instead, use pkg-config, which will output the correct options for your specific system:  $ pkg-config --cflags --libs python2 -I/usr/include/python2.7 -lpython2.7   You may add it to your gcc line:  gcc $(pkg-config --cflags --libs python2) -Wall utilsmodule.c -o Utilc      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "14", "A_Content": "  AWS EC2 install running python34:  sudo yum install python34-devel     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "13", "A_Content": "  It's not the same situation, but it also works for me and now I can use SWIG with Python3.5:  I was trying to compile:  gcc -fPIC -c existe.c existe_wrap.c -I /usr/include/python3.5m/   With Python 2.7 works fine, not with my version 3.5:     existe_wrap.c:147:21: fatal error: Python.h: No existe el archivo o el   directorio compilation terminated.   After run in my Ubuntu 16.04 installation:  sudo apt-get install python3-dev  # for python3.x installs   Now I can compile without problems Python3.5:  gcc -fPIC -c existe.c existe_wrap.c -I /usr/include/python3.5m/      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "12", "A_Content": "  In my case, what fixed it in Ubuntu was to install the packages libpython-all-dev (or libpython3-all-dev if you use Python 3).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "12", "A_Content": "  If you use a virtualenv with a 3.6 python (edge right now), be sure to install the matching python 3.6 dev sudo apt-get install python3.6-dev, otherwise executing sudo python3-dev will install the python dev 3.3.3-1, which won't solve the issue.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "9", "A_Content": "  try apt-file. It is difficult to remember the package name where the missing file resides. It is generic and useful for any package files.  For example:  root@ubuntu234:~/auto# apt-file search --regexp '/Python.h$' pypy-dev: /usr/lib/pypy/include/Python.h python2.7-dbg: /usr/include/python2.7_d/Python.h python2.7-dev: /usr/include/python2.7/Python.h python3.2-dbg: /usr/include/python3.2dmu/Python.h python3.2-dev: /usr/include/python3.2mu/Python.h root@ubuntu234:~/auto#    Now you can make an expert guess as to which one to choose from.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "8", "A_Content": "  For the OpenSuse comrades out there:  sudo zypper install python3-devel      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "8", "A_Content": "  For CentOS 7:     sudo yum install python36u-devel   I followed the instructions here for installing python3.6 on several VMs: https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-centos-7 and was then able to build mod_wsgi and get it working with a python3.6 virtualenv     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "6", "A_Content": "  I also encountered this error when I was installing coolprop in ubuntu.   For ubuntu 16.04 with python 3.6   sudo apt-get install python3.6-dev   If ever this doesn't work try installing/updating gcc lib.  sudo apt-get install gcc      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "4", "A_Content": "  This error occurred when I attempted to install ctds on CentOS 7 with Python3.6. I did all the tricks mentioned here including yum install python34-devel.  The problem was Python.h was found in /usr/include/python3.4m but not in /usr/include/python3.6m.  I tried to use --global-option to point to include dir (pip3.6 install --global-option=build_ext --global-option=\"--include-dirs=/usr/include/python3.4m\" ctds).  This resulted in a lpython3.6m not found when linking ctds.  Finally what worked was fixing the development environment for Python3.6 needs to correct with the include and libs.  yum -y install https://dl.iuscommunity.org/pub/ius/stable/CentOS/7/x86_64/python36u-libs-3.6.3-1.ius.centos7.x86_64.rpm   Python.h needs to be in your include path for gcc.  Whichever version of python is used, for example if it's 3.6, then it should be in /usr/include/python3.6m/Python.h typically.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "3", "A_Content": "  Sure python-dev or libpython-all-dev are the first thing to (apt )install, but if that doesn't help as was my case, I advice you to install the foreign Function Interface packages by sudo apt-get install libffi-dev and sudo pip install cffi.  This should help out especially if you see the error as/from c/_cffi_backend.c:2:20: fatal error: Python.h: No such file or directory.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "2", "A_Content": "  It often appear when you trying to remove python3.5 and install python3.6.  So when using python3 (which python3 -V => python3.6) to install some packages required python3.5 header will appear this error.  Resolve by install python3.6-dev module.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "1", "A_Content": "  This means that Python.h isn't in your compiler's default include paths. Have you installed it system-wide or locally? What's your OS?  You could use the -I<path> flag to specify an additional directory where your compiler should look for headers. You will probably have to follow up with -L<path> so that gcc can find the library you'll be linking with using -l<name>.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "1", "A_Content": "  If you're using Python 3.6 on Amazon Linux (based on RHEL, but the RHEL answers given here didn't work):  sudo yum install python36-devel      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory", "Language": "Python", "Q_Title": "fatal error: Python.h: No such file or directory", "Q_Votes": "740", "Q_Content": "    I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:  gcc -Wall utilsmodule.c -o Utilc   After executing the command, I get this error message:     utilsmodule.c:1:20: fatal error: Python.h: No such file or directory   compilation terminated.   in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??     ", "Tags": ["python", "gcc", "python-c-api", "python-c-extension"], "A_Votes": "1", "A_Content": "  Sometimes even after installing python-dev the error persists, Check for the error if it is 'gcc' missing.  First download as stated in https://stackoverflow.com/a/21530768/8687063, then install gcc  For apt (Ubuntu, Debian...):  sudo apt-get install gcc   For yum (CentOS, RHEL...):  sudo yum install gcc   For dnf (Fedora...):  sudo dnf install gcc   For zypper (openSUSE...):  sudo zypper in gcc   For apk (Alpine...):  sudo apk gcc      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "1164", "A_Content": "  iterrows is a generator which yield both index and row  for index, row in df.iterrows():    print row['c1'], row['c2']  Output:     10 100    11 110    12 120      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "161", "A_Content": "  To iterate through DataFrame's row in pandas one can use:   DataFrame.iterrows()  for index, row in df.iterrows():     print row[\"c1\"], row[\"c2\"]  DataFrame.itertuples()  for row in df.itertuples(index=True, name='Pandas'):     print getattr(row, \"c1\"), getattr(row, \"c2\")    itertuples() is supposed to be faster than iterrows()  But be aware, according to the docs (pandas 0.21.1 at the moment):   iterrows: dtype might not match from row to row     Because iterrows returns a Series for each row, it does not preserve dtypes across the rows (dtypes are preserved across columns for DataFrames).  iterrows: Do not modify rows     You should never modify something you are iterating over. This is not guaranteed to work in all cases. Depending on the data types, the iterator returns a copy and not a view, and writing to it will have no effect.   Use DataFrame.apply() instead:  new_df = df.apply(lambda x: x * 2)  itertuples:      The column names will be renamed to positional names if they are invalid Python identifiers, repeated, or start with an underscore. With a large number of columns (>255), regular tuples are returned.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "120", "A_Content": "  While iterrows() is a good option, sometimes itertuples() can be much faster:  df = pd.DataFrame({'a': randn(1000), 'b': randn(1000),'N': randint(100, 1000, (1000)), 'x': 'x'})  %timeit [row.a * 2 for idx, row in df.iterrows()] # => 10 loops, best of 3: 50.3 ms per loop  %timeit [row[1] * 2 for row in df.itertuples()] # => 1000 loops, best of 3: 541 \u00b5s per loop      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "64", "A_Content": "  You can also use df.apply() to iterate over rows and access multiple columns for a function.  docs: DataFrame.apply()  def valuation_formula(x, y):     return x * y * 0.5  df['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "49", "A_Content": "  You can use the df.iloc function as follows:  for i in range(0, len(df)):     print df.iloc[i]['c1'], df.iloc[i]['c2']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "15", "A_Content": "  Use itertuples(). It is faster than iterrows():  for row in df.itertuples():     print \"c1 :\",row.c1,\"c2 :\",row.c2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "13", "A_Content": "  I was looking for How to iterate on rows AND columns and ended here so :  for i, row in df.iterrows():     for j, column in row.iteritems():         print(column)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "12", "A_Content": "  To loop all rows in a dataframe you can use:  for x in range(len(date_example.index)):     print date_example['Date'].iloc[x]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "11", "A_Content": "  You can write your own iterator that implements namedtuple  from collections import namedtuple  def myiter(d, cols=None):     if cols is None:         v = d.values.tolist()         cols = d.columns.values.tolist()     else:         j = [d.columns.get_loc(c) for c in cols]         v = d.values[:, j].tolist()      n = namedtuple('MyTuple', cols)      for line in iter(v):         yield n(*line)   This is directly comparable to pd.DataFrame.itertuples.  I'm aiming at performing the same task with more efficiency.    For the given dataframe with my function:  list(myiter(df))  [MyTuple(c1=10, c2=100), MyTuple(c1=11, c2=110), MyTuple(c1=12, c2=120)]   Or with pd.DataFrame.itertuples:  list(df.itertuples(index=False))  [Pandas(c1=10, c2=100), Pandas(c1=11, c2=110), Pandas(c1=12, c2=120)]     A comprehensive test We test making all columns available and subsetting the columns.    def iterfullA(d):     return list(myiter(d))  def iterfullB(d):     return list(d.itertuples(index=False))  def itersubA(d):     return list(myiter(d, ['col3', 'col4', 'col5', 'col6', 'col7']))  def itersubB(d):     return list(d[['col3', 'col4', 'col5', 'col6', 'col7']].itertuples(index=False))  res = pd.DataFrame(     index=[10, 30, 100, 300, 1000, 3000, 10000, 30000],     columns='iterfullA iterfullB itersubA itersubB'.split(),     dtype=float )  for i in res.index:     d = pd.DataFrame(np.random.randint(10, size=(i, 10))).add_prefix('col')     for j in res.columns:         stmt = '{}(d)'.format(j)         setp = 'from __main__ import d, {}'.format(j)         res.at[i, j] = timeit(stmt, setp, number=100)  res.groupby(res.columns.str[4:-1], axis=1).plot(loglog=True);          ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "7", "A_Content": "  IMHO, the simplest decision   for ind in df.index:      print df['c1'][ind], df['c2'][ind]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "3", "A_Content": "  To loop all rows in a dataframe and use values of each row conveniently, namedtuples can be converted to ndarrays. For example:  df = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]}, index=['a', 'b'])   Iterating over the rows:  for row in df.itertuples(index=False, name='Pandas'):     print np.asarray(row)   results in:  [ 1.   0.1] [ 2.   0.2]   Please note that if index=True, the index is added as the first element of the tuple, which may be undesirable for some applications.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "3", "A_Content": "  Adding to the answers above, sometimes a useful pattern is:  # Borrowing @KutalmisB df example df = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]}, index=['a', 'b']) # The to_dict call results in a list of dicts # where each row_dict is a dictionary with k:v pairs of columns:value for that row for row_dict in df.to_dict(orient='records'):     print(row_dict)   Which results in:  {'col1':1.0, 'col2':0.1} {'col1':2.0, 'col2':0.2}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "2", "A_Content": "  Why complicate things?    Simple.  import pandas as pd import numpy as np  # Here is an example dataframe df_existing = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))  for idx,row in df_existing.iterrows():     print row['A'],row['B'],row['C'],row['D']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "Language": "Python", "Q_Title": "How to iterate over rows in a DataFrame in Pandas?", "Q_Votes": "811", "Q_Content": "    I have a DataFrame from pandas:  import pandas as pd inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}] df = pd.DataFrame(inp) print df   Output:     c1   c2 0  10  100 1  11  110 2  12  120   Now I want to iterate over the rows of this frame. For every row I want to be able to access its elements (values in cells) by the name of the columns. For example:  for row in df.rows:    print row['c1'], row['c2']   Is it possible to do that in pandas?  I found this similar question. But it does not give me the answer I need. For example, it is suggested there to use:  for date, row in df.T.iteritems():   or  for row in df.iterrows():   But I do not understand what the row object is and how I can work with it.     ", "Tags": ["python", "pandas", "rows", "dataframe"], "A_Votes": "1", "A_Content": "  You can also do numpy indexing for even greater speed ups. It's not really iterating but works much better than iteration for certain applications.  subset = row['c1'][0:5] all = row['c1'][:]   You may also want to cast it to an array. These indexes/selections are supposed to act like Numpy arrays already but I ran into issues and needed to cast  np.asarray(all) imgs[:] = cv2.resize(imgs[:], (224,224) ) #resize every image in an hdf5 file      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11241523/why-does-python-code-run-faster-in-a-function", "Language": "Python", "Q_Title": "Why does Python code run faster in a function?", "Q_Votes": "737", "Q_Content": "    def main():     for i in xrange(10**8):         pass main()   This piece of code in Python runs in  (Note: The timing is done with the time function in BASH in Linux.)  real    0m1.841s user    0m1.828s sys     0m0.012s   However, if the for loop isn't placed within a function,   for i in xrange(10**8):     pass   then it runs for a much longer time:  real    0m4.543s user    0m4.524s sys     0m0.012s   Why is this?     ", "Tags": ["python", "performance", "profiling", "benchmarking", "cpython"], "A_Votes": "446", "A_Content": "  You might ask why it is faster to store local variables than globals. This is a CPython implementation detail.  Remember that CPython is compiled to bytecode, which the interpreter runs. When a function is compiled, the local variables are stored in a fixed-size array (not a dict) and variable names are assigned to indexes. This is possible because you can't dynamically add local variables to a function. Then retrieving a local variable is literally a pointer lookup into the list and a refcount increase on the PyObject which is trivial.  Contrast this to a global lookup (LOAD_GLOBAL), which is a true dict search involving a hash and so on. Incidentally, this is why you need to specify global i if you want it to be global: if you ever assign to a variable inside a scope, the compiler will issue STORE_FASTs for its access unless you tell it not to.  By the way, global lookups are still pretty optimised. Attribute lookups foo.bar are the really slow ones!  Here is small illustration on local variable efficiency.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/11241523/why-does-python-code-run-faster-in-a-function", "Language": "Python", "Q_Title": "Why does Python code run faster in a function?", "Q_Votes": "737", "Q_Content": "    def main():     for i in xrange(10**8):         pass main()   This piece of code in Python runs in  (Note: The timing is done with the time function in BASH in Linux.)  real    0m1.841s user    0m1.828s sys     0m0.012s   However, if the for loop isn't placed within a function,   for i in xrange(10**8):     pass   then it runs for a much longer time:  real    0m4.543s user    0m4.524s sys     0m0.012s   Why is this?     ", "Tags": ["python", "performance", "profiling", "benchmarking", "cpython"], "A_Votes": "633", "A_Content": "  Inside a function, the bytecode is    2           0 SETUP_LOOP              20 (to 23)               3 LOAD_GLOBAL              0 (xrange)               6 LOAD_CONST               3 (100000000)               9 CALL_FUNCTION            1              12 GET_ITER                     >>   13 FOR_ITER                 6 (to 22)              16 STORE_FAST               0 (i)    3          19 JUMP_ABSOLUTE           13         >>   22 POP_BLOCK                    >>   23 LOAD_CONST               0 (None)              26 RETURN_VALUE           At top level, the bytecode is    1           0 SETUP_LOOP              20 (to 23)               3 LOAD_NAME                0 (xrange)               6 LOAD_CONST               3 (100000000)               9 CALL_FUNCTION            1              12 GET_ITER                     >>   13 FOR_ITER                 6 (to 22)              16 STORE_NAME               1 (i)    2          19 JUMP_ABSOLUTE           13         >>   22 POP_BLOCK                    >>   23 LOAD_CONST               2 (None)              26 RETURN_VALUE           The difference is that STORE_FAST is faster (!) than STORE_NAME.  This is because in a function, i is a local but at toplevel it is a global.  To examine bytecode, use the dis module.  I was able to disassemble the function directly, but to disassemble the toplevel code I had to use the compile builtin.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11241523/why-does-python-code-run-faster-in-a-function", "Language": "Python", "Q_Title": "Why does Python code run faster in a function?", "Q_Votes": "737", "Q_Content": "    def main():     for i in xrange(10**8):         pass main()   This piece of code in Python runs in  (Note: The timing is done with the time function in BASH in Linux.)  real    0m1.841s user    0m1.828s sys     0m0.012s   However, if the for loop isn't placed within a function,   for i in xrange(10**8):     pass   then it runs for a much longer time:  real    0m4.543s user    0m4.524s sys     0m0.012s   Why is this?     ", "Tags": ["python", "performance", "profiling", "benchmarking", "cpython"], "A_Votes": "29", "A_Content": "  Aside from local/global variable store times, opcode prediction makes the function faster.  As the other answers explain, the function uses the STORE_FAST opcode in the loop. Here's the bytecode for the function's loop:      >>   13 FOR_ITER                 6 (to 22)   # get next value from iterator          16 STORE_FAST               0 (x)       # set local variable          19 JUMP_ABSOLUTE           13           # back to FOR_ITER   Normally when a program is run, Python executes each opcode one after the other, keeping track of the a stack and preforming other checks on the stack frame after each opcode is executed. Opcode prediction means that in certain cases Python is able to jump directly to the next opcode, thus avoiding some of this overhead.  In this case, every time Python sees FOR_ITER (the top of the loop), it will \"predict\" that STORE_FAST is the next opcode it has to execute. Python then peeks at the next opcode and, if the prediction was correct, it jumps straight to STORE_FAST. This has the effect of squeezing the two opcodes into a single opcode.  On the other hand, the STORE_NAME opcode is used in the loop at the global level. Python does *not* make similar predictions when it sees this opcode. Instead, it must go back to the top of the evaluation-loop which has obvious implications for the speed at which the loop is executed.  To give some more technical detail about this optimization, here's a quote from the ceval.c file (the \"engine\" of Python's virtual machine):     Some opcodes tend to come in pairs thus making it possible to    predict the second code when the first is run.  For example,    GET_ITER is often followed by FOR_ITER. And FOR_ITER is often    followed by STORE_FAST or UNPACK_SEQUENCE.      Verifying the prediction costs a single high-speed test of a register       variable against a constant.  If the pairing was good, then the       processor's own internal branch predication has a high likelihood of       success, resulting in a nearly zero-overhead transition to the       next opcode.  A successful prediction saves a trip through the eval-loop       including its two unpredictable branches, the HAS_ARG test and the       switch-case.  Combined with the processor's internal branch prediction,       a successful PREDICT has the effect of making the two opcodes run as if       they were a single new opcode with the bodies combined.   We can see in the source code for the FOR_ITER opcode exactly where the prediction for STORE_FAST is made:  case FOR_ITER:                         // the FOR_ITER opcode case     v = TOP();     x = (*v->ob_type->tp_iternext)(v); // x is the next value from iterator     if (x != NULL) {                              PUSH(x);                       // put x on top of the stack         PREDICT(STORE_FAST);           // predict STORE_FAST will follow - success!         PREDICT(UNPACK_SEQUENCE);      // this and everything below is skipped         continue;     }     // error-checking and more code for when the iterator ends normally                                        The PREDICT function expands to if (*next_instr == op) goto PRED_##op i.e. we just jump to the start of the predicted opcode. In this case, we jump here:  PREDICTED_WITH_ARG(STORE_FAST); case STORE_FAST:     v = POP();                     // pop x back off the stack     SETLOCAL(oparg, v);            // set it as the new local variable     goto fast_next_opcode;   The local variable is now set and the next opcode is up for execution. Python continues through the iterable until it reaches the end, making the successful prediction each time.  The Python wiki page has more information about how CPython's virtual machine works.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "847", "A_Content": "  By default, you can't. When importing a file, Python only searches the current directory, the directory that the entry-point script is running from, and sys.path which includes locations such as the package installation directory (it's actually a little more complex than this, but this covers most cases).  However, you can add to the Python path at runtime:  # some_file.py import sys sys.path.insert(0, '/path/to/application/app/folder')  import file      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "426", "A_Content": "  Nothing wrong with:  from application.app.folder.file import func_name   Just make sure folder also contains an __init__.py, this allows it to be included as a package. Not sure why the other answers talk about PYTHONPATH.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "47", "A_Content": "  When modules are in parallel locations, as in the question:  application/app2/some_folder/some_file.py application/app2/another_folder/another_file.py   This shorthand makes one module visible to the other:  import sys sys.path.append('../')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "32", "A_Content": "  I think a clean way would be to use the environment variable PYTHONPATH as described in the documentation: Python2, Python3  export PYTHONPATH=$HOME/dirWithScripts/:$PYTHONPATH # Windows users: use \"set\" instead of \"export\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "22", "A_Content": "  From what I know,  add an __init__.py file directly in the folder of the functions you want  to  import  will do  the job.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "16", "A_Content": "  Considering application as the root directory for your python project, create an empty __init__.py file in application, app and folder folders. Then in your some_file.py make changes as follows to get the definition of func_name:  import sys sys.path.insert(0, r'/from/root/directory/application')  from application.app.folder.file import func_name ## You can also use '*' wildcard to import all the functions in file.py file. func_name()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "16", "A_Content": "  The answers here are lacking in clarity, this is tested on Python 3.6  With this folder structure:  main.py | ---- myfolder/myfile.py   Where myfile.py has the content:  def myfunc():     print('hello')   The import statement in main.py is:  from myfolder.myfile import myfunc myfunc()   and this will print hello.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "13", "A_Content": "  Worked for me in python3 on linux  import sys   sys.path.append(pathToFolderContainingScripts)   from scriptName import functionName #scriptName without .py extension        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "12", "A_Content": "  Your problem is that Python is looking in the Python directory for this file and not finding it. You must specify that you are talking about the directory that you are in and not the Python one.  To do this you change this:  from application.app.folder.file import func_name  to this:  from .application.app.folder.file import func_name   By adding the dot you are saying look in this folder for the application folder instead of looking in the Python directory.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "11", "A_Content": "  This works for me on windows   # some_file.py on mainApp/app2  import sys sys.path.insert(0, sys.path[0]+'\\\\app2')  import some_file      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "9", "A_Content": "  First import sys   import sys   Second append the folder path   sys.path.insert(0, '/the/folder/path/name-folder/')   Third Make a blank file called __ init __.py in your subdirectory (this tells Python it is a module)   name-file.py   name-folder   __ init __.py name-module.py     Fourth import the module inside the folder  from name-folder import name-module      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "7", "A_Content": "  Try Python's relative imports:  from ...app.folder.file import func_name   Every leading dot is another higher level in the hierarchy beginning with the current directory.    Problems? If this isn't working for you then you probably are getting bit by the many gotcha's relative imports has. Read answers and comments for more details:  How to fix \"Attempted relative import in non-package\" even with __init__.py  Hint: have __init__.py at every directory level. You might need python -m application.app2.some_folder.some_file (leaving off .py) which you run from the top level directory or have that top level directory in your PYTHONPATH. Phew!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "678", "A_Content": "  Update: Comments point out that the instructions here may be dangerous. Consider using the Visual C++ 2008 Express edition or the purpose-built Microsoft Visual C++ Compiler for Python (details) and NOT using the original answer below. Original error message means the required version of Visual C++ is not installed.    For Windows installations:  While running setup.py for package installations, Python 2.7 searches for an installed Visual Studio 2008. You can trick Python to use a newer Visual Studio by setting the correct path in VS90COMNTOOLS environment variable before calling setup.py.  Execute the following command based on the version of Visual Studio installed:   Visual Studio 2010 (VS10): SET VS90COMNTOOLS=%VS100COMNTOOLS% Visual Studio 2012 (VS11): SET VS90COMNTOOLS=%VS110COMNTOOLS% Visual Studio 2013 (VS12): SET VS90COMNTOOLS=%VS120COMNTOOLS% Visual Studio 2015 (VS14): SET VS90COMNTOOLS=%VS140COMNTOOLS%     WARNING: As noted below, this answer is unlikely to work if you are trying to compile python modules.  See Building lxml for Python 2.7 on Windows for details.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "6", "A_Content": "  Using sys.path.append with an absolute path is not ideal when moving the application to other environments. Using a relative path won't always work because the current working directory depends on how the script was invoked.  Since the application folder structure is fixed, we can use os.path to get the full path of the module we wish to import. For example, if this is the structure:  /home/me/application/app2/some_folder/vanilla.py /home/me/application/app2/another_folder/mango.py   And let's say that you want to import the \"mango\" module. You could do the following in vanilla.py:  import sys, os.path mango_dir = (os.path.abspath(os.path.join(os.path.dirname(__file__), '..')) + '/another_folder/') sys.path.append(mango_dir) import mango   Of course, you don't need the mango_dir variable.  To understand how this works look at this interactive session example:  >>> import os >>> mydir = '/home/me/application/app2/some_folder' >>> newdir = os.path.abspath(os.path.join(mydir, '..')) >>> newdir     '/home/me/application/app2' >>> newdir = os.path.abspath(os.path.join(mydir, '..')) + '/another_folder' >>>  >>> newdir '/home/me/application/app2/another_folder' >>>    And check the os.path documentation.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "5", "A_Content": "  If the purpose of loading a module from a specific path is to assist you during the development of a custom module, you can create a symbolic link in the same folder of the test script that points to the root of the custom module. This module reference will take precedence over any other modules installed of the same name for any script run in that folder.  I tested this on Linux but it should work in any modern OS that supports symbolic links.  One advantage to this approach is that you can you can point to a module that's sitting in your own local SVC branch working copy which can greatly simplify the development cycle time and reduce failure modes of managing different versions of the module.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "5", "A_Content": "  I'm quite special : I use Python with Windows !  I just complete information : for both Windows and Linux, both relative and absolute path work into sys.path (I need relative paths because I use my scripts on the several PCs and under different main directories).    And when using Windows both \\ and / can be used as separator for file names and of course you must double \\ into Python strings, some valid examples :  sys.path.append('c:\\\\tools\\\\mydir') sys.path.append('..\\\\mytools') sys.path.append('c:/tools/mydir') sys.path.append('../mytools')   (note : I think that / is more convenient than \\, event if it is less 'Windows-native' because it is Linux-compatible and simpler to write and copy to Windows explorer)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "1", "A_Content": "  So I had just right clicked on my IDE, and added a new folder and was wondering why I wasn't able to import from it. Later I realized I have to right click and create a Python Package, and not a classic file system folder. Or a post-mortem method being adding an __init__.py (which makes python treat the file system folder as a package) as mentioned in other answers. Adding this answer here just in case someone went this route.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "0", "A_Content": "  You can refresh the Python shell by pressing f5, or go to Run-> Run Module. This way you don't have to change the directory to read something from the file. Python will automatically change the directory. But if you want to work with different files from different directory in the Python Shell, then you can change the directory in sys, as Cameron said earlier.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "0", "A_Content": "  In my case I had a class to import.  My file looked like this:  # /opt/path/to/code/log_helper.py class LogHelper:     # stuff here   In my main file I included the code via:  path.append(\"/opt/path/to/code/\") from log_helper import LogHelper      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "0", "A_Content": "  In Python 3.4 and later, you can import from a source file directly (link to documentation).  Here is an example. First, the file to be imported, named foo.py:  def announce():     print(\"Imported!\")   The code that imports the file above, inspired heavily by the example in the documentation:  import importlib, importlib.util, os.path  def module_from_file(module_name, file_path):     spec = importlib.util.spec_from_file_location(module_name, file_path)     module = importlib.util.module_from_spec(spec)     spec.loader.exec_module(module)     return module  foo = module_from_file(\"foo\", \"/path/to/foo.py\")  if __name__ == \"__main__\":     print(foo)     print(dir(foo))     foo.announce()   The output:  <module 'foo' from '/path/to/foo.py'> ['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'announce'] Imported!   Note that the variable name, the module name, and the filename need not match. This code still works:  import importlib, importlib.util, os.path  def module_from_file(module_name, file_path):     spec = importlib.util.spec_from_file_location(module_name, file_path)     module = importlib.util.module_from_spec(spec)     spec.loader.exec_module(module)     return module  baz = module_from_file(\"bar\", \"/path/to/foo.py\")  if __name__ == \"__main__\":     print(baz)     print(dir(baz))     baz.announce()   The output:  <module 'bar' from '/path/to/foo.py'> ['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'announce'] Imported!   Programmatically importing modules was introduced in Python 3.1 and gives you more control over how modules are imported. Refer to the documentation for more information.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4383571/importing-files-from-different-folder", "Language": "Python", "Q_Title": "Importing files from different folder", "Q_Votes": "737", "Q_Content": "    I have the following folder structure.  application/app/folder/file.py  and I want to import some functions from file.py in another Python file which resides in  application/app2/some_folder/some_file.py  I've tried  from application.app.folder.file import func_name  and some other various attempts but so far I couldn't manage to import properly. How can I do this?     ", "Tags": ["python", "importerror", "python-import"], "A_Votes": "-2", "A_Content": "  sys.path.insert(0, '/path/to/application/app/folder')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "224", "A_Content": "  I found the solution.  I had the exact same problem, and error, installing 'amara'. I had mingw32 installed, but distutils needed to be configured.   I have Python 2.6 that was already installed. I installed mingw32 to C:\\programs\\mingw\\ Add mingw32's bin directory to your environment variable: append c:\\programs\\MinGW\\bin; to the PATH Edit (create if not existing) distutils.cfg file located at C:\\Python26\\Lib\\distutils\\distutils.cfg to be:    [build] compiler=mingw32  Now run easy_install.exe amara.   Make sure environment is set by opening a new cmd.exe.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "222", "A_Content": "  You can install compiled version from http://www.lfd.uci.edu/~gohlke/pythonlibs/     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "146", "A_Content": "  If you want to compile with Visual Studio C++ instead of mingw...   Run python.exe to display which version of VC++ it was compiled with (example shown below).     It is important to use the corresponding version of the Visual C++ compiler that Python was compiled with since distilutils's get_build_version prevents mixing versions (per Piotr's warning).    Yellow (top) is Python 2.7, compiled with MSC v.1500 (Visual Studio C++ 2008) Red (bottom) is Python 3.4.1, compiled with MSC v.1600 (Visual Studio C++ 2010)    Use the table below[1] to match the internal VC++ version with the corresponding Visual Studio release:  MSC v.1000 -> Visual C++ 4.x         MSC v.1100 -> Visual C++ 5           MSC v.1200 -> Visual C++ 6           MSC v.1300 -> Visual C++ .NET        MSC v.1310 -> Visual C++ .NET 2003   MSC v.1400 -> Visual C++ 2005  (8.0) MSC v.1500 -> Visual C++ 2008  (9.0) MSC v.1600 -> Visual C++ 2010 (10.0) MSC v.1700 -> Visual C++ 2012 (11.0) MSC v.1800 -> Visual C++ 2013 (12.0) MSC v.1900 -> Visual C++ 2015 (14.0) MSC v.1910 -> Visual C++ 2017 (15.0)        Download and install the corresponding version of Visual Studio C++ from the previous step. Additional notes for specific versions of VC++ are listed below.    Notes for Visual Studio C++ 2008  For only the 32-bit compilers, download Visual Studio C++ 2008 Express Edition.  For the 64-bit compilers[2][3], download Windows SDK for Windows 7 and .NET Framework 3.5 SP1.            Uncheck everything except Developer Tools >> Visual C++ Compilers to save time and disk space from installing SDK tools you otherwise don't need.        Notes for Visual Studio C++ 2010  According to Microsoft, if you installed Visual Studio 2010 SP1, it may have removed the compilers and libraries for VC++. If that is the case, download Visual C++ 2010 SP1 Compiler Update.  Notes for Visual Studio C++ 2015  If you don't need the Visual Studio IDE, download Visual Studio C++ 2015 Build Tools.  Notes for Visual Studio C++ 2017  If you don't need the Visual Studio IDE, download Build Tools for Visual Studio 2017.  Suggestion: If you have both a 32- and 64-bit Python installation, you may also want to use virtualenv to create separate Python environments so you can use one or the other at a time without messing with your path to choose which Python version to use.      According to @srodriguex, you may be able to skip manually loading the   batch file (Steps 4-6) by instead copying a few batch files to where Python is searching by following this answer. If that doesn't work, here are the following steps that originally worked for me.    Open up a cmd.exe Before you try installing something which requires C extensions, run the following batch file to load the VC++ compiler's environment into the session (i.e. environment variables, the path to the compiler, etc).    Execute:       32-bit Compilers:  Note: 32-bit Windows installs will only have C:\\Program Files\\ as expected     \"C:\\Program Files (x86)\\Microsoft Visual Studio 9.0\\Common7\\Tools\\vsvars32.bat\"  64-bit Compilers:     \"C:\\Program Files (x86)\\Microsoft Visual Studio 9.0\\Common7\\Tools\\vsvars64.bat\"   Note: Yes, the native 64-bit compilers are in Program Files (x86). Don't ask me why.   Additionally, if you are wondering what the difference between vcvars64.bat and vcvarsx86_amd64.bat or more importantly the difference between amd64 and x86_amd64, the former are for the native 64-bit compiler tools and the latter are the 64-bit cross compilers that can run on a 32-bit Windows installation.   Update: If for some reason you are getting error: ... was unexpected at this time. where the ... is some series of characters, then you need to check that you path variable does not have any extraneous characters like extra quotations or stray characters. The batch file is not going to be able to update your session path if it can't make sense of it in the first place. If that went well, you should get one of the following messages depending on which version of VC++ and which command you ran:    For the 32-bit compiler tools: Setting environment for using Microsoft Visual Studio 20xx x86 tools.    For the 64-bit compiler tools: Setting environment for using Microsoft Visual Studio 20xx x64 tools. Now, run the setup via python setup.py install or pip install pkg-name Hope and cross your fingers that the planets are aligned correctly for VC++ to cooperate.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "70", "A_Content": "  What's going on? Python modules can be part written in C or C++ (typically for speed). If you try to install such a package with Pip (or setup.py), it has to compile that C/C++ from source. Out the box, Pip will brazenly assume you the compiler Microsoft Visual C++ installed. If you don't have it, you'll see this cryptic error message \"Error: Unable to find vcvarsall.bat\".  The prescribed solution is to install a C/C++ compiler, either Microsoft Visual C++, or MinGW (an open-source project). However, installing and configuring either is prohibitively difficult. (Edit 2014: Microsoft have published a special C++ compiler for Python 2.7)  The easiest solution is to use Christoph Gohlke's Windows installers (.msi) for popular Python packages. He builds installers for Python 2.x and 3.x, 32 bit and 64 bit. You can download them from http://www.lfd.uci.edu/~gohlke/pythonlibs/    If you too think \"Error: Unable to find vcvarsall.bat\" is a ludicrously cryptic and unhelpful message, then please comment on the bug at http://bugs.python.org/issue2943 to replace it with a more helpful and user-friendly message.   For comparison, Ruby ships with a package manager Gem and offers a quasi-official C/C++ compiler, DevKit. If you try to install a package without it, you see this helpful friendly useful message:     Please update your PATH to include build tools or download the DevKit from http://rubyinstaller.org/downloads and follow the instructions at http://github.com/oneclick/rubyinstaller/wiki/Development-Kit   You can read a longer rant about Python packaging at https://stackoverflow.com/a/13445719/284795     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "63", "A_Content": "  You'll need to install a Microsoft compiler, compatible with the compiler used to build Python. This means you need Visual C++ 2008 (or newer, with some tweaking).  Microsoft now supplies a bundled compiler and headers just to be able to compile Python extensions, at the memorable URL:      Microsoft Visual C++ Compiler for Python 2.7      http://aka.ms/vcpython27   This is a relatively small package; 85MB to download, installable without admin privileges, no reboot required. The name is a little misleading, the compiler will work for any Python version originally compiled with Visual C++ 2008, not just Python 2.7.  If you start a Python interactive prompt or print sys.version, look for the MSC version string; if it is MSC v.1500 you can use this tool.  From the original announcement to the distutils list:     Microsoft has released a compiler package for Python 2.7 to make it easier for people to build and distribute their C extension modules on Windows. The Microsoft Visual C++ Compiler for Python 2.7 (a.k.a. VC9) is available from: http://aka.ms/vcpython27       This package contains all the tools and headers required to build C extension modules for Python 2.7 32-bit and 64-bit (note that some extension modules require 3rd party dependencies such as OpenSSL or libxml2 that are not included). Other versions of Python built with Visual C++ 2008 are also supported, so \"Python 2.7\" is just advertising - it'll work fine with 2.6 and 3.2.   Note that you need to have setuptools 6.0 or newer installed (listed in the system requirements on the download page). The project you are installing must use setuptools.setup(), not distutils or the auto-detection won't work.  Microsoft has stated that they want to keep the URL stable, so that automated scripts can reference it easily.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "55", "A_Content": "  I just had this same problem, so I'll tell my story here hoping it helps someone else with the same issues and save them the couple of hours I just spent:  I have mingw (g++ (GCC) 4.6.1) and python 2.7.3 in a windows 7 box and I'm trying to install PyCrypto.  It all started with this error when running setup.py install:   error: Unable to find vcvarsall.bat   Easily solved after googling the error by specifying mingw as the compiler of choice:   setup.py install build --compiler=mingw32   The problem is that then I got a different error:   configure: error: cannot run C compiled programs.   It turns out that my anti-virus was blocking the execution of a freshly compiled .exe. I just disabled the anti-virus \"resident shield\" and went to the next error:  cc1.exe: error: unrecognized command line option '-mno-cygwin'  error: command 'gcc' failed with exit status 1   This solved it: \"Either install a slightly older version of MinGW, or edit distutils\\cygwinccompiler.py in your Python directory to remove all instances of -mno-cygwin.\" (from here)  Now, I can finally start working.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "23", "A_Content": "  Looks like its looking for VC compilers, so you could try to mention compiler type with -c mingw32, since you have msys  python setup.py install -c mingw32      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "20", "A_Content": "  I have python 2.73 and windows 7 .The solution that worked for me was:   Added mingw32's bin directory to environment variable: append PATH with C:\\programs\\mingw\\bin; Created distutils.cfg located at C:\\Python27\\Lib\\distutils\\distutils.cfg containing:    [build] compiler=mingw32    To deal with MinGW not recognizing the -mno-cygwin flag anymore, remove the flag in C:\\Python27\\Lib\\distutils\\cygwincompiler.py line 322 to 326, so it looks like this:    self.set_executables(compiler='gcc -O -Wall',                          compiler_so='gcc -mdll -O -Wall',                          compiler_cxx='g++ -O -Wall',                          linker_exe='gcc',                          linker_so='%s %s %s'                                     % (self.linker_dll, shared_option,                                        entry_point))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "16", "A_Content": "  Look in the setup.py file of the package you are trying to install. If it is an older package it may be importing distutils.core.setup() rather than setuptools.setup().  I ran in to this (in 2015) with a combination of these factors:   The Microsoft Visual C++ Compiler for Python 2.7 from http://aka.ms/vcpython27 An older package that uses distutils.core.setup() Trying to do python setup.py build rather than using pip.   If you use a recent version of pip, it will force (monkeypatch) the package to use setuptools, even if its setup.py calls for distutils. However, if you are not using pip, and instead are just doing python setup.py build, the build process will use distutils.core.setup(), which does not know about the compiler install location.    Solution  Step 1: Open the appropriate Visual C++ 2008 Command Prompt  Open the Start menu or Start screen, and search for \"Visual C++ 2008 32-bit Command Prompt\" (if your python is 32-bit) or \"Visual C++ 2008 64-bit Command Prompt\" (if your python is 64-bit). Run it. The command prompt should say Visual C++ 2008 ... in the title bar.  Step 2: Set environment variables  Set these environment variables in the command prompt you just opened.  SET DISTUTILS_USE_SDK=1 SET MSSdk=1   Reference http://bugs.python.org/issue23246  Step 3: Build and install  cd to the package you want to build, and run python setup.py build, then python setup.py install. If you want to install in to a virtualenv, activate it before you build.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "2402", "A_Content": "  os.remove() will remove a file.  os.rmdir() will remove an empty directory.  shutil.rmtree() will delete a directory and all its contents.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "9", "A_Content": "  Maybe somebody can be interested, the following worked for me for the py2exe package. (I have windows 7 64 bit and portable python 2.7, Visual Studio 2005 Express with Windows SDK for Windows 7 and .NET Framework 4)  set VS90COMNTOOLS=%VS80COMNTOOLS%   then:  python.exe setup.py install      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "8", "A_Content": "  I spent almost 2 days figuring out how to fix this problem in my python 3.4 64 bit version: Python 3.4.3 (v3.4.3:9b73f1c3e601, Feb 24 2015, 22:44:40) [MSC v.1600 64 bit (AMD64)] on win32  Solution 1, hard: (before reading this, read first Solution 2 below) Finally, this is what helped me:   install Visual C++ 2010 Express install Microsoft Windows SDK v7.1 for Windows 7 create manually file vcvars64.bat in C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\VC\\bin\\amd64 which contains CALL \"C:\\Program Files\\Microsoft SDKs\\Windows\\v7.1\\Bin\\SetEnv.cmd\" /x64 or other path depending on where you have yours installed (this seems to be optional) install Microsoft Visual Studio 2010 Service Pack 1 together with Microsoft Visual C++ 2010 Service Pack 1 Compiler Update for the Windows SDK 7.1 after that I tried to pip install numpy but received the following error:  File \"numpy\\core\\setup.py\", line 686, in get_mathlib_info raise RuntimeError(\"Broken toolchain: cannot link a simple C program\") RuntimeError: Broken toolchain: cannot link a simple C program   I changed mfinfo to None in C:\\Python34\\Lib\\distutils\\msvc9compiler.py per this https://stackoverflow.com/a/23099820/4383472 finally after pip install numpy command my avast antivirus tried to interfere into the installation process, but i quickly disabled it   It took very long - several minutes for numpy to compile, I even thought that there was an error, but finally everything was ok.  Solution 2, easy: (I know this approach has already been mentioned in a highly voted answer, but let me repeat since it really is easier) After going through all of this work I understood that the best way for me is just to use already precompiled binaries from http://www.lfd.uci.edu/~gohlke/pythonlibs/ in future. There is very small chance that I will ever need some package (or a version of a package) which this site doesn't contain. The installation process is also much quicker this way. For example, to install numpy:   donwload numpy\u20111.9.2+mkl\u2011cp34\u2011none\u2011win_amd64.whl (if you have Python 3.4 64-bit) from that site in command prompt or powershell install it with pip pip install numpy\u20111.9.2+mkl\u2011cp34\u2011none\u2011win_amd64.whl (or full path to the file depending how command prompt is opened)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "7", "A_Content": "  I tried all the above answers, and found all of them not to work, this was perhaps I was using Windows 8 and had installed Visual Studio 2012. In this case, this is what you do.  The vcvarsall.bat file is located here: C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC  Simply select the file, and copy it.  Then go to this directory: C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\Common7\\Tools  and paste the file. And then, all should be well.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "7", "A_Content": "  I encountered this issue when I tried to install numpy library on my python 3.5. The solution is to install VS2015. I had VS2008, 2012, 2013, none of which is compatible with python 3.5. Apparently newer version of python has dependency on newer versions of VS.  Also make sure C++ Common Tools are installed with Visual Studio.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "6", "A_Content": "  You can download the free Visual C++ 2008 Express Edition from http://go.microsoft.com/?linkid=7729279, which will set the VS90COMNTOOLS environment variable during installation and therefore build with a compatible compiler.  As @PiotrDobrogost mentioned in a comment, his answer to this other question goes into details about why Visual C++ 2008 is the right thing to build with, but this can change as the Windows build of Python moves to newer versions of Visual Studio: Building lxml for Python 2.7 on Windows     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "6", "A_Content": "  I had this problem using Python 3.4.1 on Windows 7 x64, and unfortunately the packages I needed didn't have suitable exe or wheels that I could use. This system requires a few 'workarounds', which are detailed below (and TLDR at bottom).  Using the info in Jaxrtech's answer above, I determined I needed Visual Studio C++ 2010 (sys.version return MSC v.1600), so I installed Visual C++ 2010 Express from the link in his answer, which is http://go.microsoft.com/?linkid=9709949. I installed everything with updates, but as you can read below, this was a mistake. Only the original version of Express should be installed at this time (no updated anything).  vcvarsall.bat was now present, but there was a new error when installing the package, query_vcvarsall    raise ValueError(str(list(result.keys())))ValueError: [u'path']. There are other stackoverflow questions with this error, such as Errors while building/installing C module for Python 2.7  I determined from that answer that 2010 Express only installs 32-bit compilers. To get 64-bit (and other) compilers, you need to install Windows 7.1 SDK. See http://msdn.microsoft.com/en-us/windowsserver/bb980924.aspx  This would not install for me though, and the installer returned the error installation failed with return code 5100. I found the solution at the following link: http://support.microsoft.com/kb/2717426. In short, if newer versions of x86 and x64 Microsoft Visual C++ 2010 Redistributable's are installed, they conflict with the ones in SDK installer, and need uninstalling first.  The SDK then installed, but I noticed vcvars64.bat still did not exist in C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\VC\\bin, nor its subfolders. vcvarsall.bat runs the vcvars64 batch file, so without it, the python package still wouldn't install (I forgot the error that was shown at this time).  I then found some instructions here: http://www.cryptohaze.com/wiki/index.php/Windows_7_Build_Setup#Download_VS_2010_and_Windows_SDK_7.1 Following the instructions, I had already installed Express and 7.1 SDK, so installed SDK 7.1 SP1, and did the missing header file fix. I then manually created vcvars64.bat with the content CALL setenv /x64. I will paste all those instructions here, so they don't get lost.     Step 1 is to download Visual Studio Express 2010.      http://www.microsoft.com/visualstudio/en-us/products/2010-editions/express   is a good place to start. Download the installer, and run it   (vc_web.exe). You don't need the SQL 2008 additional download.      You'll also need the Windows SDK (currently 7.1) for the 64-bit   compilers - unless you want to do 32-bit only builds, which are not   fully supported...      http://www.microsoft.com/en-us/download/details.aspx?id=8279 is a good   starting point to download this - you'll want to run winsdk_web.exe   when downloaded!      The default install here is just fine.      Finally, download and install the Windows SDK 7.1 SP1 update:   http://www.microsoft.com/en-us/download/details.aspx?id=4422      And, to fix missing header file, VS2010 SP1.   http://www.microsoft.com/downloads/en/confirmation.aspx?FamilyID=75568aa6-8107-475d-948a-ef22627e57a5      And, bloody hell, fix the missing batch file for VS2010 Express. This   is getting downright absurd.      In C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\VC\\bin\\amd64,   create \"vcvars64.bat\" with the following (you will need to be running   as administrator):      CALL setenv /x64   My python package still did not install (can't recall error). I then found some instructions (copied below) to use the special SDK 7.1 Command Prompt, see: https://mail.python.org/pipermail/distutils-sig/2012-February/018300.html     Never mind this question.  Somebody here noticed this item on the menu:  Start->All Programs->Microsoft Windows SDK v7.1 ->Windows SDK 7.1 Command Prompt      This runs a batch job that appears to set up a working environment for the compiler.  From that prompt, you can type \"setup.py build\" or \"setup.py install\".   I opened the Windows SDK 7.1 Command Prompt as instructed, and used it to run easy_install on the python package. And at last, success!    TLDR;   Install Visual Studio Express 2010 (preferably without updated redistributables or SQL server). Install Windows 7.1 SDK Instal SDK 7.1 SP1 update, and VS2010 SP1 header file fix (this step may not be required). Manually create C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\VC\\bin\\amd64\\vcvars64.bat with content CALL setenv /x64 Start->All Programs->Microsoft Windows SDK v7.1 ->Windows SDK 7.1 Command Prompt to open special x64 command prompt, which can then be used with python/easy_install/pip/etc (including those in virtual_envs).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "6", "A_Content": "  I wanted to run pysph on Windows 10 under Python 2.7 and got vcvarsall.bat was not found (from distutils)  My solution was the following:  Install Microsoft Visual C++ for Python 2.7 (like @Michael suggested)  On Windows 10 it was installed into (my username is Andreas):  C:\\Users\\Andreas\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0   Set environment variable VS90COMNTOOLS to the installation path of Visual C++ for Python 2.7 (see above path).  If it still doesn't work, then modifiy in the module  C:/Python27/lib/distutils   the file msvc9compiler.py. Find in it the function find_vcvarsall and do following modification.  Replace the line:  productdir = os.path.join(toolsdir, os.pardir, os.pardir, \"VC\")   with  productdir = os.path.join(toolsdir)   This is where vcvarsall.bat resides in my case (check, where vcvarsall.bat is in your installation).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "3", "A_Content": "  I tried many solutions but only one worked for me, the install of Microsoft Visual Studio 2008 Express C++.  I got this issue with a Python 2.7 module written in C (yEnc, which has other issues with MS VS). Note that Python 2.7 is built with MS VS 2008 version, not 2010!  Despite the fact it's free, it is quite hard to find since MS is promoting VS 2010. Still, the MSDN official very direct links are still working: check https://stackoverflow.com/a/15319069/2227298 for download links.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "3", "A_Content": "  If you have mingw installed  pip install --global-option build_ext --global-option --compiler=mingw32 packagename   works, forcing pip to build using the mingw compiler instead of Microsoft's. See here https://github.com/pypa/pip/issues/18 for details (last post).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "3", "A_Content": "  Is Microsoft Visual C++ Compiler for Python 2.7 at http://www.microsoft.com/en-us/download/details.aspx?id=44266 not a solution?      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "3", "A_Content": "  The easiest way to solve this in 2016 is to install Chocolatey and then the  vcpython27 package. Open Powershell:  > iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1')) > choco install python2 -y > choco install vcpython27 -y      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "114", "A_Content": "  Python syntax to delete a file  import os os.remove(\"/tmp/<file_name>.txt\")   Or  import os os.unlink(\"/tmp/<file_name>.txt\")   Best practice   First, check whether the file or folder exists or not then only delete that file. This can be achieved in two ways : a. os.path.isfile(\"/path/to/file\") b. Use exception handling.   EXAMPLE for os.path.isfile  #!/usr/bin/python import os myfile=\"/tmp/foo.txt\"  ## If file exists, delete it ## if os.path.isfile(myfile):     os.remove(myfile) else:    ## Show an error ##     print(\"Error: %s file not found\" % myfile)   Exception Handling  #!/usr/bin/python import os  ## Get input ## myfile= raw_input(\"Enter file name to delete: \")  ## Try to delete the file ## try:     os.remove(myfile) except OSError as e:  ## if failed, report it back to the user ##     print (\"Error: %s - %s.\" % (e.filename, e.strerror))   RESPECTIVE OUTPUT   Enter file name to delete : demo.txt Error: demo.txt - No such file or directory.  Enter file name to delete : rrr.txt Error: rrr.txt - Operation not permitted.  Enter file name to delete : foo.txt   Python syntax to delete a folder  shutil.rmtree()   Example for shutil.rmtree()  #!/usr/bin/python import os import sys import shutil  # Get directory name mydir= raw_input(\"Enter directory name: \")  ## Try to remove tree; if failed show an error using try...except on screen try:     shutil.rmtree(mydir) except OSError as e:     print (\"Error: %s - %s.\" % (e.filename, e.strerror))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "62", "A_Content": "  Use   shutil.rmtree(path[, ignore_errors[, onerror]])   (See complete documentation on shutil) and/or  os.remove   and  os.rmdir   (Complete documentation on os.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "51", "A_Content": "  For deleting files:  You can use unlink or remove.   os.unlink(path, *, dir_fd=None)   Or  os.remove(path, *, dir_fd=None)   This functions removes (deletes) the file path. If path is a directory, OSError is raised.  In Python 2, if the path does not exist, OSError with [Errno 2] (ENOENT) is raised. In Python 3, FileNotFoundError with [Errno 2] (ENOENT) is raised. In Python 3, because FileNotFoundError is a subclass of OSError, catching the latter will catch the former.  For deleting folders:  os.rmdir(path, *, dir_fd=None)   rmdir Remove (delete) the directory path. Only works when the directory is empty, otherwise, OSError is raised.  In order to remove whole directory trees, shutil.rmtree() can be used.  shutil.rmtree(path, ignore_errors=False, onerror=None)   shutil.rmtree Delete an entire directory tree. Path must point to a directory (but not a symbolic link to a directory).   If ignore_errors is true, errors resulting from failed removals will be ignored and if false or omitted, such errors are handled by calling a handler specified by onerror or, if that is omitted, they raise an exception.  See also:  os.removedirs(name)   os.removedirs(name) Remove directories recursively. Works like rmdir() except that, if the leaf directory is successfully removed, removedirs() tries to successively remove every parent directory mentioned in path until an error is raised (which is ignored, because it generally means that a parent directory is not empty).   For example, os.removedirs('foo/bar/baz') will first remove the directory 'foo/bar/baz', and then remove 'foo/bar' and 'foo' if they are empty.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "24", "A_Content": "  Create a function for you guys.  def remove(path):     \"\"\" param <path> could either be relative or absolute. \"\"\"     if os.path.isfile(path):         os.remove(path)  # remove the file     elif os.path.isdir(path):         shutil.rmtree(path)  # remove dir and all contains     else:         raise ValueError(\"file {} is not a file or dir.\".format(path))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "22", "A_Content": "  You can use the built-in pathlib module (requires Python 3.4+, but there are backports for older versions on PyPI: pathlib, pathlib2).   To remove a file there is the unlink method:  import pathlib path = pathlib.Path(name_of_file) path.unlink()   Or the rmdir method to remove an empty folder:  import pathlib path = pathlib.Path(name_of_folder) path.rmdir()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "8", "A_Content": "     How do I delete a file or folder in Python?   For Python 3, to remove the file and directory individually, use the unlink and rmdir Path object methods respectively:  from pathlib import Path dir_path = Path.home() / 'directory'  file_path = dir_path / 'file'  file_path.unlink() # remove file  dir_path.rmdir()   # remove directory   Note that you can also use relative paths with Path objects, and you can check your current working directory with Path.cwd.  For removing individual files and directories in Python 2, see the section so labeled below.  To remove a directory with contents, use shutil.rmtree, and note that this is available in Python 2 and 3:  from shutil import rmtree  rmtree(dir_path)   Demonstration  New in Python 3.4 is the Path object.   Let's use one to create a directory and file to demonstrate usage. Note that we use the / to join the parts of the path, this works around issues between operating systems and issues from using backslashes on Windows (where you'd need to either double up your backslashes like \\\\ or use raw strings, like r\"foo\\bar\"):  from pathlib import Path  # .home() is new in 3.5, otherwise use os.path.expanduser('~') directory_path = Path.home() / 'directory' directory_path.mkdir()  file_path = directory_path / 'file' file_path.touch()   and now:  >>> file_path.is_file() True   Now let's delete them. First the file:  >>> file_path.unlink()     # remove file >>> file_path.is_file() False >>> file_path.exists() False   We can use globbing to remove multiple files - first let's create a few files for this:  >>> (directory_path / 'foo.my').touch() >>> (directory_path / 'bar.my').touch()   Then just iterate over the glob pattern:  >>> for each_file_path in directory_path.glob('*.my'): ...     print(f'removing {each_file_path}') ...     each_file_path.unlink() ...  removing ~/directory/foo.my removing ~/directory/bar.my   Now, demonstrating removing the directory:  >>> directory_path.rmdir() # remove directory >>> directory_path.is_dir() False >>> directory_path.exists() False   What if we want to remove a directory  and everything in it?  For this use-case, use shutil.rmtree  Let's recreate our directory and file:  file_path.parent.mkdir() file_path.touch()   and note that rmdir fails unless it's empty, which is why rmtree is so convenient:  >>> directory_path.rmdir() Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"~/anaconda3/lib/python3.6/pathlib.py\", line 1270, in rmdir     self._accessor.rmdir(self)   File \"~/anaconda3/lib/python3.6/pathlib.py\", line 387, in wrapped     return strfunc(str(pathobj), *args) OSError: [Errno 39] Directory not empty: '/home/excelsiora/directory'   Now, import rmtree and pass the directory to the funtion:  from shutil import rmtree rmtree(directory_path)      # remove everything    and we can see the whole thing has been removed:  >>> directory_path.exists() False   Python 2  If you're on Python 2, there's a backport of the pathlib module called pathlib2, which can be installed with pip:  $ pip install pathlib2   And then you can alias the library to pathlib  import pathlib2 as pathlib   Or just directly import the Path object (as demonstrated here):  from pathlib2 import Path   If that's too much, you can remove files with os.remove or os.unlink  from os import unlink, remove from os.path import join, expanduser  remove(join(expanduser('~'), 'directory/file'))   or  unlink(join(expanduser('~'), 'directory/file'))   and you can remove directories with os.rmdir:  from os import rmdir  rmdir(join(expanduser('~'), 'directory'))   Note that there is also a os.removedirs - it only removes empty directories recursively, but it may suit your use-case.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "3", "A_Content": "  shutil.rmtree is the asynchronous function,  so if you want to check when it complete, you can use while...loop  import os import shutil  shutil.rmtree(path)  while os.path.exists(path):   pass  print('done')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "2", "A_Content": "  import os  folder = '/Path/to/yourDir/' fileList = os.listdir(folder)  for f in fileList:     filePath = folder + '/'+f      if os.path.isfile(filePath):         os.remove(filePath)      elif os.path.isdir(filePath):         newFileList = os.listdir(filePath)         for f1 in newFileList:             insideFilePath = filePath + '/' + f1              if os.path.isfile(insideFilePath):                 os.remove(insideFilePath)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder", "Language": "Python", "Q_Title": "Delete a file or folder", "Q_Votes": "1495", "Q_Content": "    How to delete a file or folder in Python?     ", "Tags": ["python", "file-io", "folder", "delete-file"], "A_Votes": "1", "A_Content": "  I recommend using subprocess if writing a beautiful and readable code is your cup of tea:  import subprocess subprocess.Popen(\"rm -r my_dir\", shell=True)   And if you are not a software engineer, then maybe consider using Jupyter; you can simply type bash commands:  !rm -r my_dir   Traditionally, you use shutil:  import shutil shutil.rmtree(my_dir)       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "2", "A_Content": "  You can use easy_install instead of pip it works for me.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "2", "A_Content": "  I don't know if it is too late, but I found Microsoft Visual C++ Compiler for Python 2.7 which reads     The typical error message you will receive if you need this compiler package is Unable to find vcvarsall.bat   Hope this helps!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "2", "A_Content": "  I got the same problem and have solved it at the moment.  \"Google\" told me that I need to install \"Microsoft Visual C++ Compiler for Python 2.7\". I install not only the tool, but also Visual C++ 2008 Reditributable, but it didn't help. I then tried to install Visual C++ 2008 Express Edition. And the problem has gone!  Just try to install Visual C++ 2008 Express Edition!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "2", "A_Content": "  Below steps fixed this issue for me, I was trying to create setup with cython extension.   Install Microsoft Visual C++ Compiler for Python 2.7  The default install location would be @ C:\\Users\\PC-user\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python This might actually fix the issue, test once before proceeding.  If it fails, Check where in VC++ for python vcvarsall.bat file is located Open the msvc9compiler.py file of distutils package in notepad.  In my box this was @ C:\\Anaconda2\\Lib\\distutils\\msvc9compiler.py find_vcvarsall function in this file, determine the version of VC by printing out version argument. For Python 2.7 it's likely to be 9.0 Now create an environment variable VS90COMNTOOLS, Pointing to C:\\Users\\PC-user\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0\\VC\\bin For some reason distutils expects the vcvarsall.bat file to be within VC dir, but VC++ for python tools has it in the root of 9.0 To fix this, remove \"VC\" from the path.join (roughly around line 247)       #productdir = os.path.join(toolsdir, os.pardir, os.pardir, \"VC\")     productdir = os.path.join(toolsdir, os.pardir, os.pardir)    The above steps fixed the issue for me.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "1", "A_Content": "  If you're looking to install pyodbc on a Windows box that doesn't have Visual Studio installed another option is to manually install pyodbc using the binary distribution.  This is particularly useful if you do not have administrator privileges on the machine you're working with and are trying to set up a virtualenv.  Steps:   Download the latest Windows installer from here (pyodbc-X.X.X.win-Y-py2.7.exe) Open the installer executable using 7-Zip (or WinRAR or whatever) Extract pyodbc.pyd and pyodbc-X.X.X-py2.7.egg-info and place them in [python installation directory or virtualenv]\\Lib\\site-packages There is no step 4 :)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "1", "A_Content": "  With Python 3.4, the dependency is on Visual Studio 2010. Installing Visual C++ 2010 Express fixed the problem for me.   Tricking it into using the VS 2008 or 2013 installs that I happened to have didn't work.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "1", "A_Content": "  The answer given by @monkey is one of the correct ones, but it is incomplete.  In case you'd like to use MinGW, you should select the C, C++ and also other development tools suggested during the MinGW installation process to also get \"make.exe.\"  You must also have the path set to make.exe in the env.  To complete his answer, here are the steps:   Add mingw32's bin directory to your environment variables Append C:\\Programs\\MinGW\\bin;C:\\Programs\\MinGW\\msys\\1.0\\bin; to the PATH  Edit (create if it doesn't exist) the distutils.cfg file located at C:\\Python26\\Lib\\distutils\\distutils.cfg to be:  [build] compiler=mingw32    Make sure the environment variables is set by opening a new cmd.exe.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "1", "A_Content": "  I had the same error (which I find silly and not really helpful whatsoever as error messages go) and continued having problems, despite having a C compiler available.   Surprising, what ended up working for me was simply upgrading pip and setuptools to the most recent version. Hope this helps someone else out there.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2817869/error-unable-to-find-vcvarsall-bat", "Language": "Python", "Q_Title": "error: Unable to find vcvarsall.bat", "Q_Votes": "812", "Q_Content": "    I tried to install the Python package dulwich:    pip install dulwich   But I get a cryptic error message:  error: Unable to find vcvarsall.bat   The same happens if I try installing the package manually:  > python setup.py install running build_ext building 'dulwich._objects' extension error: Unable to find vcvarsall.bat      ", "Tags": ["python", "windows", "pip", "setup.py", "failed-installation"], "A_Votes": "1", "A_Content": "  fastest solution:  If you have python 3.4.x, the solution is simply to install  VC++ 2010 since it is used to compile itself into.  https://www.visualstudio.com/en-us/downloads#d-2010-express  my python version is MSC v.1600 32 bit (intel)] on win32  worked fine on Windows8     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "1320", "A_Content": "  By default, cin is synchronized with stdio, which causes it to avoid any input buffering.  If you add this to the top of your main, you should see much better performance:  std::ios_base::sync_with_stdio(false);   Normally, when an input stream is buffered, instead of reading one character at a time, the stream will be read in larger chunks.  This reduces the number of system calls, which are typically relatively expensive.  However, since the FILE* based stdio and iostreams often have separate implementations and therefore separate buffers, this could lead to a problem if both were used together.  For example:  int myvalue1; cin >> myvalue1; int myvalue2; scanf(\"%d\",&myvalue2);   If more input was read by cin than it actually needed, then the second integer value wouldn't be available for the scanf function, which has its own independent buffer.  This would lead to unexpected results.  To avoid this, by default, streams are synchronized with stdio.  One common way to achieve this is to have cin read each character one at a time as needed using stdio functions.  Unfortunately, this introduces a lot of overhead.  For small amounts of input, this isn't a big problem, but when you are reading millions of lines, the performance penalty is significant.  Fortunately, the library designers decided that you should also be able to disable this feature to get improved performance if you knew what you were doing, so they provided the sync_with_stdio method.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "121", "A_Content": "  Just out of curiosity I've taken a look at what happens under the hood, and I've used dtruss/strace on each test.  C++  ./a.out < in Saw 6512403 lines in 8 seconds.  Crunch speed: 814050   syscalls sudo dtruss -c ./a.out < in  CALL                                        COUNT __mac_syscall                                   1 <snip> open                                            6 pread                                           8 mprotect                                       17 mmap                                           22 stat64                                         30 read_nocancel                               25958   Python  ./a.py < in Read 6512402 lines in 1 seconds. LPS: 6512402   syscalls sudo dtruss -c ./a.py < in  CALL                                        COUNT __mac_syscall                                   1 <snip> open                                            5 pread                                           8 mprotect                                       17 mmap                                           21 stat64                                         29      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "91", "A_Content": "  I'm a few years behind here, but:  In 'Edit 4/5/6' of the original post, you are using the construction:  $ /usr/bin/time cat big_file | program_to_benchmark   This is wrong in a couple of different ways:   You're actually timing the execution of `cat`, not your benchmark.  The 'user' and 'sys' CPU usage displayed by `time` are those of `cat`, not your benchmarked program.  Even worse, the 'real' time is also not necessarily accurate.  Depending on the implementation of `cat` and of pipelines in your local OS, it is possible that `cat` writes a final giant buffer and exits long before the reader process finishes its work. Use of `cat` is unnecessary and in fact counterproductive; you're adding moving parts.  If you were on a sufficiently old system (i.e.  with a single CPU and -- in certain generations of computers -- I/O faster than CPU) -- the mere fact that `cat` was running could substantially color the results.  You are also subject to whatever input and output buffering and other processing `cat` may do.  (This would likely earn you a 'Useless Use Of Cat' award if I were Randal Schwartz.   A better construction would be:  $ /usr/bin/time program_to_benchmark < big_file   In this statement it is the shell which opens big_file, passing it to your program (well, actually to `time` which then executes your program as a subprocess) as an already-open file descriptor.  100% of the file reading is strictly the responsibility of the program you're trying to benchmark.  This gets you a real reading of its performance without spurious complications.  I will mention two possible, but actually wrong, 'fixes' which could also be considered (but I 'number' them differently as these are not things which were wrong in the original post):  A. You could 'fix' this by timing only your program:  $ cat big_file | /usr/bin/time program_to_benchmark   B. or by timing the entire pipeline:  $ /usr/bin/time sh -c 'cat big_file | program_to_benchmark'   These are wrong for the same reasons as #2: they're still using `cat` unnecessarily.  I mention them for a few reasons:   they're more 'natural' for people who aren't entirely comfortable with the I/O redirection facilities of the POSIX shell there may be cases where `cat` is needed (e.g.: the file to be read requires some sort of privilege to access, and you do not want to grant that privilege to the program to be benchmarked: `sudo cat /dev/sda | /usr/bin/time my_compression_test --no-output`) in practice, on modern machines, the added `cat` in the pipeline is probably of no real consequence   But I say that last thing with some hesitation.  If we examine the last result in 'Edit 5' --  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU ...   -- this claims that `cat` consumed 74% of the CPU during the test; and indeed 1.34/1.83 is approximately 74%.  Perhaps a run of:  $ /usr/bin/time wc -l < temp_big_file   would have taken only the remaining .49 seconds!  Probably not: `cat` here had to pay for the read() system calls (or equivalent) which transferred the file from 'disk' (actually buffer cache), as well as the pipe writes to deliver them to `wc`.  The correct test would still have had to do those read() calls; only the write-to-pipe and read-from-pipe calls would have been saved, and those should be pretty cheap.  Still, I predict you would be able to measure the difference between `cat file | wc -l` and `wc -l < file` and find a noticeable (2-digit percentage) difference.  Each of the slower tests will have paid a similar penalty in absolute time; which would however amount to a smaller fraction of its larger total time.  In fact I did some quick tests with a 1.5 gigabyte file of garbage, on a Linux 3.13 (Ubuntu 14.04) system, obtaining these results (these are actually 'best of 3' results; after priming the cache, of course):   $ time wc -l < /tmp/junk real 0.280s user 0.156s sys 0.124s (total cpu 0.280s) $ time cat /tmp/junk | wc -l real 0.407s user 0.157s sys 0.618s (total cpu 0.775s) $ time sh -c 'cat /tmp/junk | wc -l' real 0.411s user 0.118s sys 0.660s (total cpu 0.778s)   Notice that the two pipeline results claim to have taken more CPU time (user+sys) than realtime.  This is because I'm using the shell (Bash)'s built-in 'time' command, which is cognizant of the pipeline; and I'm on a multi-core machine where separate processes in a pipeline can use separate cores, accumulating CPU time faster than realtime.  Using /usr/bin/time I see smaller CPU time than realtime -- showing that it can only time the single pipeline element passed to it on its command line.  Also, the shell's output gives milliseconds while /usr/bin/time only gives hundreths of a second.  So at the efficiency level of `wc -l`, the `cat` makes a huge difference: 409 / 283 = 1.453 or 45.3% more realtime, and 775 / 280 = 2.768, or a whopping 177% more CPU used!  On my random it-was-there-at-the-time test box.  I should add that there is at least one other significant difference between these styles of testing, and I can't say whether it is a benefit or fault; you have to decide this yourself:  When you run `cat big_file | /usr/bin/time my_program`, your program is receiving input from a pipe, at precisely the pace sent by `cat`, and in chunks no larger than written by `cat`.  When you run `/usr/bin/time my_program < big_file`, your program receives an open file descriptor to the actual file.  Your program -- or in many cases the I/O libraries of the language in which it was written -- may take different actions when presented with a file descriptor referencing a regular file.  It may use mmap(2) to map the input file into its address space, instead of using explicit read(2) system calls.  These differences could have a far larger effect on your benchmark results than the small cost of running the `cat` binary.  Of course it is an interesting benchmark result if the same program performs significantly differently between the two cases.  It shows that, indeed, the program or its I/O libraries are doing something interesting, like using mmap().  So in practice it might be good to run the benchmarks both ways; perhaps discounting the `cat` result by some small factor to \"forgive\" the cost of running `cat` itself.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "77", "A_Content": "  I reproduced the original result on my computer using g++ on a Mac.  Adding the following statements to the C++ version just before the while loop brings it inline with the Python version:  std::ios_base::sync_with_stdio(false); char buffer[1048576]; std::cin.rdbuf()->pubsetbuf(buffer, sizeof(buffer));   sync_with_stdio improved speed to 2 seconds, and setting a larger buffer brought it down to 1 second.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "25", "A_Content": "  getline, stream operators, scanf, can be convenient if you don't care about file loading time or if you are loading small text files. But, if the performance is something you care about, you should really just buffer the entire file into memory (assuming it will fit).  Here's an example:  //open file in binary mode std::fstream file( filename, std::ios::in|::std::ios::binary ); if( !file ) return NULL;  //read the size... file.seekg(0, std::ios::end); size_t length = (size_t)file.tellg(); file.seekg(0, std::ios::beg);  //read into memory buffer, then close it. char *filebuf = new char[length+1]; file.read(filebuf, length); filebuf[length] = '\\0'; //make it null-terminated file.close();   If you want, you can wrap a stream around that buffer for more convenient access like this:  std::istrstream header(&filebuf[0], length);   Also, if you are in control of the file, consider using a flat binary data format instead of text. It's more reliable to read and write because you don't have to deal with all the ambiguities of whitespace. It's also smaller and much faster to parse.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "13", "A_Content": "  By the way, the reason the line count for the C++ version is one greater than the count for the Python version is that the eof flag only gets set when an attempt is made to read beyond eof. So the correct loop would be:  while (cin) {     getline(cin, input_line);      if (!cin.eof())         line_count++; };      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "10", "A_Content": "  The following code was faster for me than the other code posted here so far: (Visual Studio 2013, 64-bit, 500 MB file with line length uniformly in [0, 1000)).  const int buffer_size = 500 * 1024;  // Too large/small buffer is not good. std::vector<char> buffer(buffer_size); int size; while ((size = fread(buffer.data(), sizeof(char), buffer_size, stdin)) > 0) {     line_count += count_if(buffer.begin(), buffer.begin() + size, [](char ch) { return ch == '\\n'; }); }   It beats all my Python attempts by more than a factor 2.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "9", "A_Content": "  In your second example (with scanf()) reason why this is still slower might be because scanf(\"%s\") parses string and looks for any space char (space, tab, newline).  Also, yes, CPython does some caching to avoid harddisk reads.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "8", "A_Content": "  A first element of an answer: <iostream> is slow. Damn slow. I get a huge performance boost with scanf as in the below, but it is still two times slower than Python.  #include <iostream> #include <time.h> #include <cstdio>  using namespace std;  int main() {     char buffer[10000];     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      int read = 1;     while(read > 0) {         read = scanf(\"%s\", buffer);         line_count++;     };     sec = (int) time(NULL) - start;     line_count--;     cerr << \"Saw \" << line_count << \" lines in \" << sec << \" seconds.\" ;     if (sec > 0) {         lps = line_count / sec;         cerr << \"  Crunch speed: \" << lps << endl;     }      else         cerr << endl;     return 0; }      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python", "Language": "Python", "Q_Title": "Why is reading lines from stdin much slower in C++ than Python?", "Q_Votes": "1496", "Q_Content": "    I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.    (TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.  TLDR results: scroll all the way down to the bottom of my question and look at the table.)    C++ code:  #include <iostream> #include <time.h>  using namespace std;  int main() {     string input_line;     long line_count = 0;     time_t start = time(NULL);     int sec;     int lps;      while (cin) {         getline(cin, input_line);         if (!cin.eof())             line_count++;     };      sec = (int) time(NULL) - start;     cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";     if (sec > 0) {         lps = line_count / sec;         cerr << \" LPS: \" << lps << endl;     } else         cerr << endl;     return 0; }  // Compiled with: // g++ -O3 -o readline_test_cpp foo.cpp   Python Equivalent:  #!/usr/bin/env python import time import sys  count = 0 start = time.time()  for line in  sys.stdin:     count += 1  delta_sec = int(time.time() - start_time) if delta_sec >= 0:     lines_per_sec = int(round(count/delta_sec))     print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,        lines_per_sec))   Here are my results:  $ cat test_lines | ./readline_test_cpp Read 5570000 lines in 9 seconds. LPS: 618889  $cat test_lines | ./readline_test.py Read 5570000 lines in 1 seconds. LPS: 5570000   Edit: I should note that I tried this both under Mac\u00a0OS\u00a0X\u00a0v10.6.8 (Snow\u00a0Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.  Edit 2: (Removed this edit, as no longer applicable)  $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done Test run 1 at Mon Feb 20 21:29:28 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 2 at Mon Feb 20 21:29:39 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 3 at Mon Feb 20 21:29:50 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 4 at Mon Feb 20 21:30:01 EST 2012 CPP:   Read 5570001 lines in 9 seconds. LPS: 618889 Python:Read 5570000 lines in 1 seconds. LPS: 5570000 Test run 5 at Mon Feb 20 21:30:11 EST 2012 CPP:   Read 5570001 lines in 10 seconds. LPS: 557000 Python:Read 5570000 lines in  1 seconds. LPS: 5570000   Edit 3:  Okay, I tried J.N.'s suggestion of trying having Python store the line read: but it made no difference to python's speed.  I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string. Bingo! This resulted in equivalent performance for both Python and C++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 characters wide, though sometimes more).  Code:  char input_a[512]; char input_b[32]; char input_c[512]; while(scanf(\"%s %s %s\\n\", input_a, input_b, input_c) != EOF) {     line_count++; };   Speed:  $ cat test_lines | ./readline_test_cpp2 Read 10000000 lines in 3 seconds. LPS: 3333333 $ cat test_lines | ./readline_test2.py Read 10000000 lines in 3 seconds. LPS: 3333333   (Yes, I ran it several times.) So, I guess I will now use scanf instead of getline. But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable.  Edit 4 (was: Final Edit / Solution):  Adding:  cin.sync_with_stdio(false);   Immediately above my original while loop above results in code that runs faster than Python.  New performance comparison (this is on my 2011 MacBook Pro), using the original code, the original with the sync disabled, and the original Python code, respectively, on a file with 20M lines of text. Yes, I ran it several times to eliminate disk caching confound.  $ /usr/bin/time cat test_lines_double | ./readline_test_cpp        33.30 real         0.04 user         0.74 sys Read 20000001 lines in 33 seconds. LPS: 606060 $ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b         3.79 real         0.01 user         0.50 sys Read 20000000 lines in 4 seconds. LPS: 5000000 $ /usr/bin/time cat test_lines_double | ./readline_test.py         6.88 real         0.01 user         0.38 sys Read 20000000 lines in 6 seconds. LPS: 3333333   Thanks to @Vaughn Cato for his answer! Any elaboration people can make or good references people can point to as to why this synchronisation happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)  Edit 5 / Better Solution:  As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach. I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow. So, I wrote this iteration using fgets, the safer alternative to gets. Here are the pertinent lines for my fellow noobs:  char input_line[MAX_LINE]; char *result;  //<snip>  while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)     line_count++; if (ferror(stdin))     perror(\"Error reading stdin.\");   Now, here are the results using an even larger file (100M lines; ~3.4\u00a0GB) on a fast server with very fast disk, comparing the Python code, the unsynchronised cin, and the fgets approaches, as well as comparing with the wc utility. [The scanf version segmentation faulted and I don't feel like troubleshooting it.]:  $ /usr/bin/time cat temp_big_file | readline_test.py 0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 28 seconds. LPS: 3571428  $ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps Read 100000000 lines in 8 seconds. LPS: 12500000  $ /usr/bin/time cat temp_big_file | readline_test_fgets 0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 7 seconds. LPS: 14285714  $ /usr/bin/time cat temp_big_file | wc -l 0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k 0inputs+0outputs (0major+182minor)pagefaults 0swaps 100000000   Recap (lines per second): python:         3,571,428 cin (no sync): 12,500,000 fgets:         14,285,714 wc:            54,644,808   As you can see, fgets is better, but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying. I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  Also note that a small tradeoff with using a char * buffer and fgets vs. unsynchronised cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input.  This has been educational. Thanks to all for your comments and suggestions.  Edit 6:  As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines. Here's a Python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the Python for loop:  BUFFER_SIZE = 16384 count = sum(chunk.count('\\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))   The performance of this version is quite fast (though still a bit slower than the raw C wc utility, of course):  $ /usr/bin/time cat temp_big_file | readline_test3.py 0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k 0inputs+0outputs (0major+181minor)pagefaults 0swaps Read 100000000 lines in 4.7275 seconds. LPS: 21152829   Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last Python snippet on the other, as the latter two don't actually store the read lines, but merely count newlines. Still, it's interesting to explore all the different implementations and think about the performance implications. Thanks again!  Edit 7: Tiny benchmark addendum and recap  For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the complete table now:  Implementation      Lines per second python (default)           3,571,428 cin (default/naive)          819,672 cin (no sync)             12,500,000 fgets                     14,285,714 wc (not fair comparison)  54,644,808      ", "Tags": ["c++", "python", "benchmarking", "readline", "getline"], "A_Votes": "7", "A_Content": "  Well, I see that in your second solution you switched from cin to scanf, which was the first suggestion I was going to make you (cin is sloooooooooooow). Now, if you switch from scanf to fgets, you would see another boost in performance: fgets is the fastest C++ function for string input.  BTW, didn't know about that sync thing, nice. But you should still try fgets.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "1842", "A_Content": "  shutil has many methods you can use. One of which is:  from shutil import copyfile  copyfile(src, dst)   Copy the contents of the file named src to a file named dst. The destination location must be writable; otherwise, an IOError exception will be raised. If dst already exists, it will be replaced. Special files such as character or block devices and pipes cannot be copied with this function. src and dst are path names given as strings.      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "578", "A_Content": "  ----------------------------------------------------------------------------------- | Function          |Copies Metadata|Copies Permissions|Can Use Buffer|Dest Dir OK ----------------------------------------------------------------------------------- | shutil.copy       |      No       |        Yes       |      No      |    Yes ----------------------------------------------------------------------------------- | shutil.copyfile   |      No       |        No        |      No      |    No ----------------------------------------------------------------------------------- | shutil.copy2      |      Yes      |        Yes       |      No      |    Yes ----------------------------------------------------------------------------------- | shutil.copyfileobj|      No       |        No        |      Yes     |    No -----------------------------------------------------------------------------------      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "560", "A_Content": "  copy2(src,dst) is often more useful than copyfile(src,dst) because:   it allows dst to be a directory (instead of the complete target filename), in which case the basename of src is used for creating the new file; it preserves the original modification and access info (mtime and atime) in the file metadata (however, this comes with a slight overhead).   Here is a short example:  import shutil shutil.copy2('/src/dir/file.ext', '/dst/dir/newname.ext') # complete target filename given shutil.copy2('/src/file.ext', '/dst/dir') # target filename is /dst/dir/file.ext      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "74", "A_Content": "  Copying a file is a relatively straightforward operation as shown by the examples below, but you should instead use the shutil stdlib module for that.  def copyfileobj_example(source, dest, buffer_size=1024*1024):     \"\"\"           Copy a file from source to dest. source and dest     must be file-like objects, i.e. any object with a read or     write method, like for example StringIO.     \"\"\"     while True:         copy_buffer = source.read(buffer_size)         if not copy_buffer:             break         dest.write(copy_buffer)   If you want to copy by filename you could do something like this:  def copyfile_example(source, dest):     # Beware, this example does not handle any edge cases!     with open(source, 'rb') as src, open(dest, 'wb') as dst:         copyfileobj_example(src, dst)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "47", "A_Content": "  Use the shutil module.  copyfile(src, dst)   Copy the contents of the file named src to a file named dst. The destination location must be writable; otherwise, an IOError exception will be raised. If dst already exists, it will be replaced. Special files such as character or block devices and pipes cannot be copied with this function. src and dst are path names given as strings.  Take a look at filesys for all the file and directory handling functions available in standard Python modules.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "45", "A_Content": "  You can use one of the copy functions from the shutil package:   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 Function              preserves     supports          accepts     copies other                       permissions   directory dest.   file obj    metadata   \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 shutil.copy              \u2714             \u2714                 \u2610           \u2610 shutil.copy2             \u2714             \u2714                 \u2610           \u2714 shutil.copyfile          \u2610             \u2610                 \u2610           \u2610 shutil.copyfileobj       \u2610             \u2610                 \u2714           \u2610 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501   Example:  import shutil shutil.copy('/etc/hostname', '/var/tmp/testhostname')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "36", "A_Content": "  Directory and File copy example - From Tim Golden's Python Stuff:  http://timgolden.me.uk/python/win32_how_do_i/copy-a-file.html  import os import shutil import tempfile  filename1 = tempfile.mktemp (\".txt\") open (filename1, \"w\").close () filename2 = filename1 + \".copy\" print filename1, \"=>\", filename2  shutil.copy (filename1, filename2)  if os.path.isfile (filename2): print \"Success\"  dirname1 = tempfile.mktemp (\".dir\") os.mkdir (dirname1) dirname2 = dirname1 + \".copy\" print dirname1, \"=>\", dirname2  shutil.copytree (dirname1, dirname2)  if os.path.isdir (dirname2): print \"Success\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "25", "A_Content": "  In Python, you can copy the files using   shutil module os module subprocess module     import os import shutil import subprocess     1) Copying files using shutil module  shutil.copyfile  signature  shutil.copyfile(src_file, dest_file, *, follow_symlinks=True)  # example     shutil.copyfile('source.txt', 'destination.txt')     shutil.copy  signature  shutil.copy(src_file, dest_file, *, follow_symlinks=True)  # example shutil.copy('source.txt', 'destination.txt')     shutil.copy2  signature  shutil.copy2(src_file, dest_file, *, follow_symlinks=True)  # example shutil.copy2('source.txt', 'destination.txt')       shutil.copyfileobj  signature  shutil.copyfileobj(src_file_object, dest_file_object[, length])  # example file_src = 'source.txt'   f_src = open(file_src, 'rb')  file_dest = 'destination.txt'   f_dest = open(file_dest, 'wb')  shutil.copyfileobj(f_src, f_dest)       2) Copying files using os module  os.popen  signature  os.popen(cmd[, mode[, bufsize]])  # example # In Unix/Linux os.popen('cp source.txt destination.txt')   # In Windows os.popen('copy source.txt destination.txt')     os.system  signature  os.system(command)   # In Linux/Unix os.system('cp source.txt destination.txt')    # In Windows os.system('copy source.txt destination.txt')     3) Copying files using subprocess module  subprocess.call  signature  subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False)  # example (WARNING: setting `shell=True` might be a security-risk) # In Linux/Unix status = subprocess.call('cp source.txt destination.txt', shell=True)   # In Windows status = subprocess.call('copy source.txt destination.txt', shell=True)     subprocess.check_output  signature  subprocess.check_output(args, *, stdin=None, stderr=None, shell=False, universal_newlines=False)  # example (WARNING: setting `shell=True` might be a security-risk) # In Linux/Unix status = subprocess.check_output('cp source.txt destination.txt', shell=True)  # In Windows status = subprocess.check_output('copy source.txt destination.txt', shell=True)        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "21", "A_Content": "  Look at module shutil.  It contains function copyfile(src, dst)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "13", "A_Content": "  You could use os.system('cp nameoffilegeneratedbyprogram /otherdirectory/')  or as I did it,    os.system('cp '+ rawfile + ' rawdata.dat')   where rawfile is the name that I had generated inside the program.  This is a Linux only solution      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "8", "A_Content": "  For large files, what I did was read the file line by line and read each line into an array. Then, once the array reached a certain size, append it to a new file.   for line in open(\"file.txt\", \"r\"):     list.append(line)     if len(list) == 1000000:          output.writelines(list)         del list[:]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "7", "A_Content": "  from subprocess import call call(\"cp -p <file> <file>\", shell=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "7", "A_Content": "  I suggest using Swati's answer, but supposing you have a text file and don't want to use additional libraries in your code just to copy it, you can use the following one-liner:  with open(source, 'r') as src, open(dest, 'w') as dst: dst.write(src.read())      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python", "Language": "Python", "Q_Title": "How do I copy a file in Python?", "Q_Votes": "1518", "Q_Content": "    How do I copy a file in Python?  I couldn't find anything under os.     ", "Tags": ["python", "file", "copy", "filesystems", "copyfile"], "A_Votes": "3", "A_Content": "  Firstly, I made an exhaustive cheatsheet of shutil methods for your reference.  shutil_methods = {'copy':['shutil.copyfileobj',           'shutil.copyfile',           'shutil.copymode',           'shutil.copystat',           'shutil.copy',           'shutil.copy2',           'shutil.copytree',],  'move':['shutil.rmtree',          'shutil.move',],  'exception': ['exception shutil.SameFileError',                  'exception shutil.Error'],  'others':['shutil.disk_usage',              'shutil.chown',              'shutil.which',              'shutil.ignore_patterns',] }   Secondly, explain methods of copy in exmaples:        shutil.copyfileobj(fsrc, fdst[, length]) manipulate opened objects      In [3]: src = '~/Documents/Head+First+SQL.pdf' In [4]: dst = '~/desktop' In [5]: shutil.copyfileobj(src, dst) AttributeError: 'str' object has no attribute 'read' #copy the file object In [7]: with open(src, 'rb') as f1,open(os.path.join(dst,'test.pdf'), 'wb') as f2:     ...:      shutil.copyfileobj(f1, f2) In [8]: os.stat(os.path.join(dst,'test.pdf')) Out[8]: os.stat_result(st_mode=33188, st_ino=8598319475, st_dev=16777220, st_nlink=1, st_uid=501, st_gid=20, st_size=13507926, st_atime=1516067347, st_mtime=1516067335, st_ctime=1516067345)         shutil.copyfile(src, dst, *, follow_symlinks=True)  Copy and rename      In [9]: shutil.copyfile(src, dst) IsADirectoryError: [Errno 21] Is a directory: ~/desktop' #so dst should be a filename instead of a directory name         shutil.copy()  Copy without preseving the metadata      In [10]: shutil.copy(src, dst) Out[10]: ~/desktop/Head+First+SQL.pdf' #check their metadata In [25]: os.stat(src) Out[25]: os.stat_result(st_mode=33188, st_ino=597749, st_dev=16777220, st_nlink=1, st_uid=501, st_gid=20, st_size=13507926, st_atime=1516066425, st_mtime=1493698739, st_ctime=1514871215) In [26]: os.stat(os.path.join(dst, 'Head+First+SQL.pdf')) Out[26]: os.stat_result(st_mode=33188, st_ino=8598313736, st_dev=16777220, st_nlink=1, st_uid=501, st_gid=20, st_size=13507926, st_atime=1516066427, st_mtime=1516066425, st_ctime=1516066425) # st_atime,st_mtime,st_ctime changed         shutil.copy2()  Copy with preseving the metadata      In [30]: shutil.copy2(src, dst) Out[30]: ~/desktop/Head+First+SQL.pdf' In [31]: os.stat(src) Out[31]: os.stat_result(st_mode=33188, st_ino=597749, st_dev=16777220, st_nlink=1, st_uid=501, st_gid=20, st_size=13507926, st_atime=1516067055, st_mtime=1493698739, st_ctime=1514871215) In [32]: os.stat(os.path.join(dst, 'Head+First+SQL.pdf')) Out[32]: os.stat_result(st_mode=33188, st_ino=8598313736, st_dev=16777220, st_nlink=1, st_uid=501, st_gid=20, st_size=13507926, st_atime=1516067063, st_mtime=1493698739, st_ctime=1516067055) # Preseved st_mtime         `shutil.copytree()``      Recursively copy an entire directory tree rooted at src, returning the destination directory     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "2475", "A_Content": "  datetime.strptime is the main routine for parsing strings into datetimes. It can handle all sorts of formats, with the format determined by a format string you give it:  from datetime import datetime  datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')   The resulting datetime object is timezone-naive.  Links:   Python documentation for strptime: Python 2, Python 3 Python documentation for strptime/strftime format strings: Python 2, Python 3 strftime.org is also a really nice reference for strftime   Notes:   strptime = \"string parse time\" strftime = \"string format time\" Pronounce it out loud today & you won't have to search for it again in 6 months.      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "640", "A_Content": "  Use the third party dateutil library:  from dateutil import parser dt = parser.parse(\"Aug 28 1999 12:00AM\")   It can handle most date formats, including the one you need to parse. It's more convenient than strptime as it can guess the correct format most of the time.  It very useful for writing tests, where readability is more important than performance.  You can install it with:  pip install python-dateutil      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "462", "A_Content": "  Check out strptime in the time module.  It is the inverse of strftime.  $ python >>> import time >>> time.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p') time.struct_time(tm_year=2005, tm_mon=6, tm_mday=1,                  tm_hour=13, tm_min=33, tm_sec=0,                  tm_wday=2, tm_yday=152, tm_isdst=-1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "88", "A_Content": "  I have put together a project that can convert some really neat expressions. Check out timestring.   Here are some examples below:  pip install timestring  >>> import timestring >>> timestring.Date('monday, aug 15th 2015 at 8:40 pm') <timestring.Date 2015-08-15 20:40:00 4491909392> >>> timestring.Date('monday, aug 15th 2015 at 8:40 pm').date datetime.datetime(2015, 8, 15, 20, 40) >>> timestring.Range('next week') <timestring.Range From 03/10/14 00:00:00 to 03/03/14 00:00:00 4496004880> >>> (timestring.Range('next week').start.date, timestring.Range('next week').end.date) (datetime.datetime(2014, 3, 10, 0, 0), datetime.datetime(2014, 3, 14, 0, 0))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "35", "A_Content": "  Remember this and you didn't need to get confused in datetime conversion again.  String to datetime object = strptime  datetime object to other formats = strftime  Jun 1 2005  1:33PM  is equals to  %b %d %Y %I:%M%p     %b    Month as locale\u2019s abbreviated name(Jun)      %d    Day of the month as a zero-padded decimal number(1)      %Y    Year with century as a decimal number(2015)      %I    Hour (12-hour clock) as a zero-padded decimal number(01)      %M    Minute as a zero-padded decimal number(33)      %p    Locale\u2019s equivalent of either AM or PM(PM)   so you need strptime i-e converting string to   >>> dates = [] >>> dates.append('Jun 1 2005  1:33PM') >>> dates.append('Aug 28 1999 12:00AM') >>> from datetime import datetime >>> for d in dates: ...     date = datetime.strptime(d, '%b %d %Y %I:%M%p') ...     print type(date) ...     print date ...    Output  <type 'datetime.datetime'> 2005-06-01 13:33:00 <type 'datetime.datetime'> 1999-08-28 00:00:00   What if you have different format of dates you can use panda or dateutil.parse  >>> import dateutil >>> dates = [] >>> dates.append('12 1 2017') >>> dates.append('1 1 2017') >>> dates.append('1 12 2017') >>> dates.append('June 1 2017 1:30:00AM') >>> [parser.parse(x) for x in dates]   OutPut  [datetime.datetime(2017, 12, 1, 0, 0), datetime.datetime(2017, 1, 1, 0, 0), datetime.datetime(2017, 1, 12, 0, 0), datetime.datetime(2017, 6, 1, 1, 30)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "30", "A_Content": "  Many timestamps have an implied timezone. To ensure that your code will work in every timezone, you should use UTC internally and attach a timezone each time a foreign object enters the system.  Python 3.2+:  >>> datetime.datetime.strptime( ...     \"March 5, 2014, 20:13:50\", \"%B %d, %Y, %H:%M:%S\" ... ).replace(tzinfo=datetime.timezone(datetime.timedelta(hours=-3)))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "21", "A_Content": "  Something that isn't mentioned here and is useful: adding a suffix to the day. I decoupled the suffix logic so you can use it for any number you like, not just dates.  import time  def num_suffix(n):     '''     Returns the suffix for any given int     '''     suf = ('th','st', 'nd', 'rd')     n = abs(n) # wise guy     tens = int(str(n)[-2:])     units = n % 10     if tens > 10 and tens < 20:         return suf[0] # teens with 'th'     elif units <= 3:         return suf[units]     else:         return suf[0] # 'th'  def day_suffix(t):     '''     Returns the suffix of the given struct_time day     '''     return num_suffix(t.tm_mday)  # Examples print num_suffix(123) print num_suffix(3431) print num_suffix(1234) print '' print day_suffix(time.strptime(\"1 Dec 00\", \"%d %b %y\")) print day_suffix(time.strptime(\"2 Nov 01\", \"%d %b %y\")) print day_suffix(time.strptime(\"3 Oct 02\", \"%d %b %y\")) print day_suffix(time.strptime(\"4 Sep 03\", \"%d %b %y\")) print day_suffix(time.strptime(\"13 Nov 90\", \"%d %b %y\")) print day_suffix(time.strptime(\"14 Oct 10\", \"%d %b %y\"))\u200b\u200b\u200b\u200b\u200b\u200b\u200b      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "20", "A_Content": "  Here are two solutions using Pandas to convert dates formatted as strings into datetime.date objects.  import pandas as pd  dates = ['2015-12-25', '2015-12-26']  # 1) Use a list comprehension. >>> [d.date() for d in pd.to_datetime(dates)] [datetime.date(2015, 12, 25), datetime.date(2015, 12, 26)]  # 2) Convert the dates to a DatetimeIndex and extract the python dates. >>> pd.DatetimeIndex(dates).date.tolist() [datetime.date(2015, 12, 25), datetime.date(2015, 12, 26)]   Timings  dates = pd.DatetimeIndex(start='2000-1-1', end='2010-1-1', freq='d').date.tolist()  >>> %timeit [d.date() for d in pd.to_datetime(dates)] # 100 loops, best of 3: 3.11 ms per loop  >>> %timeit pd.DatetimeIndex(dates).date.tolist() # 100 loops, best of 3: 6.85 ms per loop   And here is how to convert the OP's original date-time examples:  datetimes = ['Jun 1 2005  1:33PM', 'Aug 28 1999 12:00AM']  >>> pd.to_datetime(datetimes).to_pydatetime().tolist() [datetime.datetime(2005, 6, 1, 13, 33),   datetime.datetime(1999, 8, 28, 0, 0)]   There are many options for converting from the strings to Pandas Timestamps using to_datetime, so check the docs if you need anything special.  Likewise, Timestamps have many properties and methods that can be accessed in addition to .date     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "12", "A_Content": "  Django Timezone aware datetime object example.  import datetime from django.utils.timezone import get_current_timezone tz = get_current_timezone()  format = '%b %d %Y %I:%M%p' date_object = datetime.datetime.strptime('Jun 1 2005  1:33PM', format) date_obj = tz.localize(date_object)   This conversion is very important for Django and Python when you have USE_TZ = True:  RuntimeWarning: DateTimeField MyModel.created received a naive datetime (2016-03-04 00:00:00) while time zone support is active.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "11", "A_Content": "  In [34]: import datetime  In [35]: _now = datetime.datetime.now()  In [36]: _now Out[36]: datetime.datetime(2016, 1, 19, 9, 47, 0, 432000)  In [37]: print _now 2016-01-19 09:47:00.432000  In [38]: _parsed = datetime.datetime.strptime(str(_now),\"%Y-%m-%d %H:%M:%S.%f\")  In [39]: _parsed Out[39]: datetime.datetime(2016, 1, 19, 9, 47, 0, 432000)  In [40]: assert _now == _parsed      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "8", "A_Content": "  Create a small utility function like:  def date(datestr=\"\", format=\"%Y-%m-%d\"):     from datetime import datetime     if not datestr:         return datetime.today().date()     return datetime.strptime(datestr, format).date()   This is versatile enough:   If you don't pass any arguments it will return today's date. There's a date format as default that you can override. You can easily modify it to return a datetime.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "8", "A_Content": "  The datetime Python module is good for getting date time and converting date time formats.  import datetime  new_date_format1 = datetime.datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p') new_date_format2 = datetime.datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p').strftime('%Y/%m/%d %I:%M%p') print new_date_format1 print new_date_format2   Output:  2005-06-01 13:33:00 2005/06/01 01:33PM      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "8", "A_Content": "  I personally like the solution using the parser module, which is the second Answer to this question and is beautiful, as you don't have to construct any string literals to get it working. However, one downside is that it is 90% slower than the accepted answer with strptime.  from dateutil import parser from datetime import datetime import timeit  def dt():     dt = parser.parse(\"Jun 1 2005  1:33PM\") def strptime():     datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')  print(timeit.timeit(stmt=dt, number=10**5)) print(timeit.timeit(stmt=strptime, number=10**5)) >10.70296801342902 >1.3627995655316933   As long as you are not doing this a million times over and over again, I still  think the parser method is more convenient and will handle most of the time formats automatically.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "7", "A_Content": "  arrow offers many useful functions for dates and times. This bit of code provides an answer to the question and shows that arrow is also capable of formatting dates easily and displaying information for other locales.  >>> import arrow >>> dateStrings = [ 'Jun 1  2005 1:33PM', 'Aug 28 1999 12:00AM' ] >>> for dateString in dateStrings: ...     dateString ...     arrow.get(dateString.replace('  ',' '), 'MMM D YYYY H:mmA').datetime ...     arrow.get(dateString.replace('  ',' '), 'MMM D YYYY H:mmA').format('ddd, Do MMM YYYY HH:mm') ...     arrow.get(dateString.replace('  ',' '), 'MMM D YYYY H:mmA').humanize(locale='de') ... 'Jun 1  2005 1:33PM' datetime.datetime(2005, 6, 1, 13, 33, tzinfo=tzutc()) 'Wed, 1st Jun 2005 13:33' 'vor 11 Jahren' 'Aug 28 1999 12:00AM' datetime.datetime(1999, 8, 28, 0, 0, tzinfo=tzutc()) 'Sat, 28th Aug 1999 00:00' 'vor 17 Jahren'   See http://arrow.readthedocs.io/en/latest/ for more.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "5", "A_Content": "  You can use easy_date to make it easy:  import date_converter converted_date = date_converter.string_to_datetime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "3", "A_Content": "  If you want only date format then you can manually convert it by passing your individual fields like:  >>> import datetime >>> date = datetime.date(int('2017'),int('12'),int('21')) >>> date datetime.date(2017, 12, 21) >>> type(date) <type 'datetime.date'>   You can pass your split string values to convert it into date type like:  selected_month_rec = '2017-09-01' date_formate = datetime.date(int(selected_month_rec.split('-')[0]),int(selected_month_rec.split('-')[1]),int(selected_month_rec.split('-')[2]))   You will get the resulting value in date format.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "1", "A_Content": "  It would do the helpful for converting string to datetime and also with time zone  def convert_string_to_time(date_string, timezone):     from datetime import datetime     import pytz     date_time_obj = datetime.strptime(date_string[:26], '%Y-%m-%d %H:%M:%S.%f')     date_time_obj_timezone = pytz.timezone(timezone).localize(date_time_obj)      return date_time_obj_timezone  date = '2018-08-14 13:09:24.543953+00:00' TIME_ZONE = 'UTC' date_time_obj_timezone = convert_string_to_time(date, TIME_ZONE)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/466345/converting-string-into-datetime", "Language": "Python", "Q_Title": "Converting string into datetime", "Q_Votes": "1513", "Q_Content": "    Short and simple. I've got a huge list of date-times like this as strings:  Jun 1 2005  1:33PM Aug 28 1999 12:00AM   I'm going to be shoving these back into proper datetime fields in a database so I need to magic them into real datetime objects.   Any help (even if it's just a kick in the right direction) would be appreciated.  Edit: This is going through Django's ORM so I can't use SQL to do the conversion on insert.     ", "Tags": ["python", "datetime"], "A_Votes": "-1", "A_Content": "  See my answer.  In real-world data this is a real problem: multiple, mismatched, incomplete, inconsistent and multilanguage/region date formats, often mixed freely in one dataset. It's not ok for production code to fail, let alone go exception-happy like a fox.  We need to try...catch multiple datetime formats fmt1,fmt2,...,fmtn and suppress/handle the exceptions (from strptime()) for all those that mismatch (and in particular, avoid needing a yukky n-deep indented ladder of try..catch clauses). From my solution  def try_strptime(s, fmts=['%d-%b-%y','%m/%d/%Y']):     for fmt in fmts:         try:             return datetime.strptime(s, fmt)         except:             continue      return None # or reraise the ValueError if no format matched, if you prefer      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "1504", "A_Content": "  Variables declared inside the class definition, but not inside a method are class or static variables:  >>> class MyClass: ...     i = 3 ... >>> MyClass.i 3    As @millerdev points out, this creates a class-level i variable, but this is distinct from any instance-level i variable, so you could have  >>> m = MyClass() >>> m.i = 4 >>> MyClass.i, m.i >>> (3, 4)   This is different from C++ and Java, but not so different from C#, where a static member can't be accessed using a reference to an instance.  See what the Python tutorial has to say on the subject of classes and class objects.  @Steve Johnson has already answered regarding static methods, also documented under \"Built-in Functions\" in the Python Library Reference.  class C:     @staticmethod     def f(arg1, arg2, ...): ...   @beidy recommends classmethods over staticmethod, as the method then receives the class type as the first argument, but I'm still a little fuzzy on the advantages of this approach over staticmethod. If you are too, then it probably doesn't matter.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "528", "A_Content": "  @Blair Conrad said static variables declared inside the class definition, but not inside a method are class or \"static\" variables:  >>> class Test(object): ...     i = 3 ... >>> Test.i 3   There are a few gotcha's here. Carrying on from the example above:  >>> t = Test() >>> t.i     # static variable accessed via instance 3 >>> t.i = 5 # but if we assign to the instance ... >>> Test.i  # we have not changed the static variable 3 >>> t.i     # we have overwritten Test.i on t by creating a new attribute t.i 5 >>> Test.i = 6 # to change the static variable we do it by assigning to the class >>> t.i 5 >>> Test.i 6 >>> u = Test() >>> u.i 6           # changes to t do not affect new instances of Test  # Namespaces are one honking great idea -- let's do more of those! >>> Test.__dict__ {'i': 6, ...} >>> t.__dict__ {'i': 5} >>> u.__dict__ {}   Notice how the instance variable t.i got out of sync with the \"static\" class variable when the attribute i was set directly on t. This is because i was re-bound within the t namespace, which is distinct from the Test namespace. If you want to change the value of a \"static\" variable, you must change it within the scope (or object) where it was originally defined. I put \"static\" in quotes because Python does not really have static variables in the sense that C++ and Java do.  Although it doesn't say anything specific about static variables or methods, the Python tutorial has some relevant information on classes and class objects.   @Steve Johnson also answered regarding static methods, also documented under \"Built-in Functions\" in the Python Library Reference.  class Test(object):     @staticmethod     def f(arg1, arg2, ...):         ...   @beid also mentioned classmethod, which is similar to staticmethod. A classmethod's first argument is the class object. Example:  class Test(object):     i = 3 # class (or static) variable     @classmethod     def g(cls, arg):         # here we can use 'cls' instead of the class name (Test)         if arg > cls.i:             cls.i = arg # would the the same as  Test.i = arg1        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "144", "A_Content": "  Static and Class Methods  As the other answers have noted, static and class methods are easily accomplished using the built-in decorators:  class Test(object):      # regular instance method:     def MyMethod(self):         pass      # class method:     @classmethod     def MyClassMethod(klass):         pass      # static method:     @staticmethod     def MyStaticMethod():         pass   As usual, the first argument to MyMethod() is bound to the class instance object. In contrast, the first argument to MyClassMethod() is bound to the class object itself (e.g., in this case, Test). For MyStaticMethod(), none of the arguments are bound, and having arguments at all is optional.   \"Static Variables\"  However, implementing \"static variables\" (well, mutable static variables, anyway, if that's not a contradiction in terms...) is not as straight forward. As millerdev pointed out in his answer, the problem is that Python's class attributes are not truly \"static variables\". Consider:   class Test(object):     i = 3  # This is a class attribute  x = Test() x.i = 12   # Attempt to change the value of the class attribute using x instance assert x.i == Test.i  # ERROR assert Test.i == 3    # Test.i was not affected assert x.i == 12      # x.i is a different object than Test.i   This is because the line x.i = 12 has added a new instance attribute i to x instead of changing the value of the Test class i attribute.   Partial expected static variable behavior, i.e., syncing of the attribute between multiple instances (but not with the class itself; see \"gotcha\" below), can be achieved by turning the class attribute into a property:  class Test(object):      _i = 3      @property     def i(self):         return type(self)._i      @i.setter     def i(self,val):         type(self)._i = val  ## ALTERNATIVE IMPLEMENTATION - FUNCTIONALLY EQUIVALENT TO ABOVE ## ## (except with separate methods for getting and setting i) ##  class Test(object):      _i = 3      def get_i(self):         return type(self)._i      def set_i(self,val):         type(self)._i = val      i = property(get_i, set_i)   Now you can do:  x1 = Test() x2 = Test() x1.i = 50 assert x2.i == x1.i  # no error assert x2.i == 50    # the property is synced   The static variable will now remain in sync between all class instances.   (NOTE: That is, unless a class instance decides to define its own version of _i! But if someone decides to do THAT, they deserve what they get, don't they???)  Note that technically speaking, i is still not a 'static variable' at all; it is a property, which is a special type of descriptor. However, the property behavior is now equivalent to a (mutable) static variable synced across all class instances.   Immutable \"Static Variables\"  For immutable static variable behavior, simply omit the property setter:  class Test(object):      _i = 3      @property     def i(self):         return type(self)._i  ## ALTERNATIVE IMPLEMENTATION - FUNCTIONALLY EQUIVALENT TO ABOVE ## ## (except with separate methods for getting i) ##  class Test(object):      _i = 3      def get_i(self):         return type(self)._i      i = property(get_i)   Now attempting to set the instance i attribute will return an AttributeError:   x = Test() assert x.i == 3  # success x.i = 12         # ERROR   One Gotcha to be Aware of  Note that the above methods only work with instances of your class - they will not work when using the class itself. So for example:   x = Test() assert x.i == Test.i  # ERROR  # x.i and Test.i are two different objects: type(Test.i)  # class 'property' type(x.i)     # class 'int'   The line assert Test.i == x.i produces an error, because the i attribute of Test and x are two different objects.   Many people will find this surprising. However, it should not be. If we go back and inspect our Test class definition (the second version), we take note of this line:       i = property(get_i)    Clearly, the member i of Test must be a property object, which is the type of object returned from the property function.   If you find the above confusing, you are most likely still thinking about it from the perspective of other languages (e.g. Java or c++). You should go study the property object, about the order in which Python attributes are returned, the descriptor protocol, and the method resolution order (MRO).   I present a solution to the above 'gotcha' below; however I would suggest - strenuously - that you do not try to do something like the following until - at minimum - you thoroughly understand why assert Test.i = x.i causes an error.   REAL, ACTUAL Static Variables - Test.i == x.i  I present the (Python 3) solution below for informational purposes only. I am not endorsing it as a \"good solution\". I have my doubts as to whether emulating the static variable behavior of other languages in Python is ever actually necessary. However, regardless as to whether it is actually useful, the below should help further understanding of how Python works.   UPDATE: this attempt is really pretty awful; if you insist on doing something like this (hint: please don't; Python is a very elegant language and shoe-horning it into behaving like another language is just not necessary), use the code in Ethan Furman's answer instead.  Emulating static variable behavior of other languages using a metaclass  A metaclass is the class of a class. The default metaclass for all classes in Python (i.e., the \"new style\" classes post Python 2.3 I believe) is type. For example:   type(int)  # class 'type' type(str)  # class 'type' class Test(): pass type(Test) # class 'type'   However, you can define your own metaclass like this:   class MyMeta(type): pass   And apply it to your own class like this (Python 3 only):  class MyClass(metaclass = MyMeta):     pass  type(MyClass)  # class MyMeta   Below is a metaclass I have created which attempts to emulate \"static variable\" behavior of other languages. It basically works by replacing the default getter, setter, and deleter with versions which check to see if the attribute being requested is a \"static variable\".   A catalog of the \"static variables\" is stored in the StaticVarMeta.statics attribute. All attribute requests are initially attempted to be resolved using a substitute resolution order. I have dubbed this the \"static resolution order\", or \"SRO\". This is done by looking for the requested attribute in the set of \"static variables\" for a given class (or its parent classes). If the attribute does not appear in the \"SRO\", the class will fall back on the default attribute get/set/delete behavior (i.e., \"MRO\").   from functools import wraps  class StaticVarsMeta(type):     '''A metaclass for creating classes that emulate the \"static variable\" behavior     of other languages. I do not advise actually using this for anything!!!      Behavior is intended to be similar to classes that use __slots__. However, \"normal\"     attributes and __statics___ can coexist (unlike with __slots__).       Example usage:           class MyBaseClass(metaclass = StaticVarsMeta):             __statics__ = {'a','b','c'}             i = 0  # regular attribute             a = 1  # static var defined (optional)          class MyParentClass(MyBaseClass):             __statics__ = {'d','e','f'}             j = 2              # regular attribute             d, e, f = 3, 4, 5  # Static vars             a, b, c = 6, 7, 8  # Static vars (inherited from MyBaseClass, defined/re-defined here)          class MyChildClass(MyParentClass):             __statics__ = {'a','b','c'}             j = 2  # regular attribute (redefines j from MyParentClass)             d, e, f = 9, 10, 11   # Static vars (inherited from MyParentClass, redefined here)             a, b, c = 12, 13, 14  # Static vars (overriding previous definition in MyParentClass here)'''     statics = {}     def __new__(mcls, name, bases, namespace):         # Get the class object         cls = super().__new__(mcls, name, bases, namespace)         # Establish the \"statics resolution order\"         cls.__sro__ = tuple(c for c in cls.__mro__ if isinstance(c,mcls))          # Replace class getter, setter, and deleter for instance attributes         cls.__getattribute__ = StaticVarsMeta.__inst_getattribute__(cls, cls.__getattribute__)         cls.__setattr__ = StaticVarsMeta.__inst_setattr__(cls, cls.__setattr__)         cls.__delattr__ = StaticVarsMeta.__inst_delattr__(cls, cls.__delattr__)         # Store the list of static variables for the class object         # This list is permanent and cannot be changed, similar to __slots__         try:             mcls.statics[cls] = getattr(cls,'__statics__')         except AttributeError:             mcls.statics[cls] = namespace['__statics__'] = set() # No static vars provided         # Check and make sure the statics var names are strings         if any(not isinstance(static,str) for static in mcls.statics[cls]):             typ = dict(zip((not isinstance(static,str) for static in mcls.statics[cls]), map(type,mcls.statics[cls])))[True].__name__             raise TypeError('__statics__ items must be strings, not {0}'.format(typ))         # Move any previously existing, not overridden statics to the static var parent class(es)         if len(cls.__sro__) > 1:             for attr,value in namespace.items():                 if attr not in StaticVarsMeta.statics[cls] and attr != ['__statics__']:                     for c in cls.__sro__[1:]:                         if attr in StaticVarsMeta.statics[c]:                             setattr(c,attr,value)                             delattr(cls,attr)         return cls     def __inst_getattribute__(self, orig_getattribute):         '''Replaces the class __getattribute__'''         @wraps(orig_getattribute)         def wrapper(self, attr):             if StaticVarsMeta.is_static(type(self),attr):                 return StaticVarsMeta.__getstatic__(type(self),attr)             else:                 return orig_getattribute(self, attr)         return wrapper     def __inst_setattr__(self, orig_setattribute):         '''Replaces the class __setattr__'''         @wraps(orig_setattribute)         def wrapper(self, attr, value):             if StaticVarsMeta.is_static(type(self),attr):                 StaticVarsMeta.__setstatic__(type(self),attr, value)             else:                 orig_setattribute(self, attr, value)         return wrapper     def __inst_delattr__(self, orig_delattribute):         '''Replaces the class __delattr__'''         @wraps(orig_delattribute)         def wrapper(self, attr):             if StaticVarsMeta.is_static(type(self),attr):                 StaticVarsMeta.__delstatic__(type(self),attr)             else:                 orig_delattribute(self, attr)         return wrapper     def __getstatic__(cls,attr):         '''Static variable getter'''         for c in cls.__sro__:             if attr in StaticVarsMeta.statics[c]:                 try:                     return getattr(c,attr)                 except AttributeError:                     pass         raise AttributeError(cls.__name__ + \" object has no attribute '{0}'\".format(attr))     def __setstatic__(cls,attr,value):         '''Static variable setter'''         for c in cls.__sro__:             if attr in StaticVarsMeta.statics[c]:                 setattr(c,attr,value)                 break     def __delstatic__(cls,attr):         '''Static variable deleter'''         for c in cls.__sro__:             if attr in StaticVarsMeta.statics[c]:                 try:                     delattr(c,attr)                     break                 except AttributeError:                     pass         raise AttributeError(cls.__name__ + \" object has no attribute '{0}'\".format(attr))     def __delattr__(cls,attr):         '''Prevent __sro__ attribute from deletion'''         if attr == '__sro__':             raise AttributeError('readonly attribute')         super().__delattr__(attr)     def is_static(cls,attr):         '''Returns True if an attribute is a static variable of any class in the __sro__'''         if any(attr in StaticVarsMeta.statics[c] for c in cls.__sro__):             return True         return False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "23", "A_Content": "  You can also add class variables to classes on the fly  >>> class X: ...     pass ...  >>> X.bar = 0 >>> x = X() >>> x.bar 0 >>> x.foo Traceback (most recent call last):   File \"<interactive input>\", line 1, in <module> AttributeError: X instance has no attribute 'foo' >>> X.foo = 1 >>> x.foo 1   And class instances can change class variables  class X:   l = []   def __init__(self):     self.l.append(1)  print X().l print X().l  >python test.py [1] [1, 1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "13", "A_Content": "  Personally I would use a classmethod whenever I needed a static method. Mainly because I get the class as an argument.  class myObj(object):    def myMethod(cls)      ...    myMethod = classmethod(myMethod)    or use a decorator  class myObj(object):    @classmethod    def myMethod(cls)   For static properties.. Its time you look up some python definition.. variable can always change. There are two types of them mutable and immutable.. Also, there are class attributes and instance attributes.. Nothing really like static attributes in the sense of java & c++  Why use static method in pythonic sense, if it has no relation whatever to the class! If I were you, I'd either use classmethod or define the method independent from the class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "12", "A_Content": "  Static methods in python are called classmethods. Take a look at the following code  class MyClass:      def myInstanceMethod(self):         print 'output from an instance method'      @classmethod     def myStaticMethod(cls):         print 'output from a static method'  >>> MyClass.myInstanceMethod() Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: unbound method myInstanceMethod() must be called [...]  >>> MyClass.myStaticMethod() output from a static method   Notice that when we call the method myInstanceMethod, we get an error. This is because it requires that method be called on an instance of this class. The method myStaticMethod is set as a classmethod using the decorator @classmethod.  Just for kicks and giggles, we could call myInstanceMethod on the class by passing in an instance of the class, like so:  >>> MyClass.myInstanceMethod(MyClass()) output from an instance method      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "10", "A_Content": "  One special thing to note about static properties & instance properties, shown in the example below:  class my_cls:   my_prop = 0  #static property print my_cls.my_prop  #--> 0  #assign value to static property my_cls.my_prop = 1  print my_cls.my_prop  #--> 1  #access static property thru' instance my_inst = my_cls() print my_inst.my_prop #--> 1  #instance property is different from static property  #after being assigned a value my_inst.my_prop = 2 print my_cls.my_prop  #--> 1 print my_inst.my_prop #--> 2   This means before assigning the value to instance property, if we try to access the property thru' instance, the static value is used. Each property declared in python class always has a static slot in memory.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "8", "A_Content": "  When define some member variable outside any member method, the variable can be either static or non-static depending on how the variable is expressed.    CLASSNAME.var is static variable INSTANCENAME.var is not static variable.  self.var inside class is not static variable.  var inside the class member function is not defined.   For example:  #!/usr/bin/python  class A:     var=1      def printvar(self):         print \"self.var is %d\" % self.var         print \"A.var is %d\" % A.var       a = A()     a.var = 2     a.printvar()      A.var = 3     a.printvar()   The results are  self.var is 2 A.var is 1 self.var is 2 A.var is 3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "6", "A_Content": "  You could also enforce a class to be static using metaclass.  class StaticClassError(Exception):     pass   class StaticClass:     __metaclass__ = abc.ABCMeta      def __new__(cls, *args, **kw):         raise StaticClassError(\"%s is a static class and cannot be initiated.\"                                 % cls)  class MyClass(StaticClass):     a = 1     b = 3      @staticmethod     def add(x, y):         return x+y   Then whenever by accident you try to initialize MyClass you'll get an StaticClassError.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "4", "A_Content": "  It is possible to have static class variables, but probably not worth the effort.  Here's a proof-of-concept written in Python 3 -- if any of the exact details are wrong the code can be tweaked to match just about whatever you mean by a static variable:    class Static:     def __init__(self, value, doc=None):         self.deleted = False         self.value = value         self.__doc__ = doc     def __get__(self, inst, cls=None):         if self.deleted:             raise AttributeError('Attribute not set')         return self.value     def __set__(self, inst, value):         self.deleted = False         self.value = value     def __delete__(self, inst):         self.deleted = True  class StaticType(type):     def __delattr__(cls, name):         obj = cls.__dict__.get(name)         if isinstance(obj, Static):             obj.__delete__(name)         else:             super(StaticType, cls).__delattr__(name)     def __getattribute__(cls, *args):         obj = super(StaticType, cls).__getattribute__(*args)         if isinstance(obj, Static):             obj = obj.__get__(cls, cls.__class__)         return obj     def __setattr__(cls, name, val):         # check if object already exists         obj = cls.__dict__.get(name)         if isinstance(obj, Static):             obj.__set__(name, val)         else:             super(StaticType, cls).__setattr__(name, val)   and in use:  class MyStatic(metaclass=StaticType):     \"\"\"     Testing static vars     \"\"\"     a = Static(9)     b = Static(12)     c = 3  class YourStatic(MyStatic):     d = Static('woo hoo')     e = Static('doo wop')   and some tests:  ms1 = MyStatic() ms2 = MyStatic() ms3 = MyStatic() assert ms1.a == ms2.a == ms3.a == MyStatic.a assert ms1.b == ms2.b == ms3.b == MyStatic.b assert ms1.c == ms2.c == ms3.c == MyStatic.c ms1.a = 77 assert ms1.a == ms2.a == ms3.a == MyStatic.a ms2.b = 99 assert ms1.b == ms2.b == ms3.b == MyStatic.b MyStatic.a = 101 assert ms1.a == ms2.a == ms3.a == MyStatic.a MyStatic.b = 139 assert ms1.b == ms2.b == ms3.b == MyStatic.b del MyStatic.b for inst in (ms1, ms2, ms3):     try:         getattr(inst, 'b')     except AttributeError:         pass     else:         print('AttributeError not raised on %r' % attr) ms1.c = 13 ms2.c = 17 ms3.c = 19 assert ms1.c == 13 assert ms2.c == 17 assert ms3.c == 19 MyStatic.c = 43 assert ms1.c == 13 assert ms2.c == 17 assert ms3.c == 19  ys1 = YourStatic() ys2 = YourStatic() ys3 = YourStatic() MyStatic.b = 'burgler' assert ys1.a == ys2.a == ys3.a == YourStatic.a == MyStatic.a assert ys1.b == ys2.b == ys3.b == YourStatic.b == MyStatic.b assert ys1.d == ys2.d == ys3.d == YourStatic.d assert ys1.e == ys2.e == ys3.e == YourStatic.e ys1.a = 'blah' assert ys1.a == ys2.a == ys3.a == YourStatic.a == MyStatic.a ys2.b = 'kelp' assert ys1.b == ys2.b == ys3.b == YourStatic.b == MyStatic.b ys1.d = 'fee' assert ys1.d == ys2.d == ys3.d == YourStatic.d ys2.e = 'fie' assert ys1.e == ys2.e == ys3.e == YourStatic.e MyStatic.a = 'aargh' assert ys1.a == ys2.a == ys3.a == YourStatic.a == MyStatic.a      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "4", "A_Content": "  One very interesting point about Python's attribute lookup is that it can be used to create \"virtual variables\":  class A(object):    label=\"Amazing\"    def __init__(self,d):        self.data=d    def say(self):        print(\"%s %s!\"%(self.label,self.data))  class B(A):   label=\"Bold\"  # overrides A.label  A(5).say()      # Amazing 5! B(3).say()      # Bold 3!   Normally there aren't any assignments to these after they are created.  Note that the lookup uses self because, although label is static in the sense of not being associated with a particular instance, the value still depends on the (class of the) instance.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "3", "A_Content": "  To avoid any potential confusion, I would like to contrast static variables and immutable objects.  Some primitive object types like integers, floats, strings, and touples are immutable in Python. This means that the object that is referred to by a given name cannot change if it is of one of the aforementioned object types. The name can be reassigned to a different object, but the object itself may not be changed.  Making a variable static takes this a step further by disallowing the variable name to point to any object but that to which it currently points. (Note: this is a general software concept and not specific to Python; please see others' posts for information about implementing statics in Python).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "3", "A_Content": "  The best way I found is to use another class. You can create an object and then use it on other objects.  class staticFlag:     def __init__(self):         self.__success = False     def isSuccess(self):         return self.__success     def succeed(self):         self.__success = True  class tryIt:     def __init__(self, staticFlag):         self.isSuccess = staticFlag.isSuccess         self.succeed = staticFlag.succeed  tryArr = [] flag = staticFlag() for i in range(10):     tryArr.append(tryIt(flag))     if i == 5:         tryArr[i].succeed()     print tryArr[i].isSuccess()   With the example above, I made a class named staticFlag.  This class should present the static var __success (Private Static Var).  tryIt class represented the regular class we need to use.  Now I made an object for one flag (staticFlag). This flag will be sent as reference to all the regular objects.  All these objects are being added to the list tryArr.    This Script Results:  False False False False False True True True True True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "3", "A_Content": "  Absolutely Yes,   Python by itself don't have any static data member explicitly, but We can have by doing so   class A:     counter =0     def callme (self):         A.counter +=1     def getcount (self):         return self.counter   >>> x=A() >>> y=A() >>> print(x.getcount()) >>> print(y.getcount()) >>> x.callme()  >>> print(x.getcount()) >>> print(y.getcount())   output  0 0 1 1   explanation  here object (x) alone increment the counter variable from 0 to 1 by not object y. But result it as \"static counter\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "2", "A_Content": "  In regards to this answer, for a constant static variable, you can use a descriptor. Here's an example:  class ConstantAttribute(object):     '''You can initialize my value but not change it.'''     def __init__(self, value):         self.value = value      def __get__(self, obj, type=None):         return self.value      def __set__(self, obj, val):         pass   class Demo(object):     x = ConstantAttribute(10)   class SubDemo(Demo):     x = 10   demo = Demo() subdemo = SubDemo() # should not change demo.x = 100 # should change subdemo.x = 100 print \"small demo\", demo.x print \"small subdemo\", subdemo.x print \"big demo\", Demo.x print \"big subdemo\", SubDemo.x   resulting in ...  small demo 10 small subdemo 100 big demo 10 big subdemo 10   You can always raise an exception if quietly ignoring setting value (pass above) is not your thing. If you're looking for a C++, Java style static class variable:  class StaticAttribute(object):     def __init__(self, value):         self.value = value      def __get__(self, obj, type=None):         return self.value      def __set__(self, obj, val):         self.value = val   Have a look at this answer and the official docs HOWTO for more information about descriptors.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/68645/are-static-class-variables-possible", "Language": "Python", "Q_Title": "Are static class variables possible?", "Q_Votes": "1531", "Q_Content": "    Is it possible to have static class variables or methods in python? What syntax is required to do this?     ", "Tags": ["python", "class", "methods", "static", "class-variables"], "A_Votes": "1", "A_Content": "  Static Variables in Class factory python3.6  For anyone using a class factory with python3.6 and up use the nonlocal keyword to add it to the scope / context of the class being created like so:  >>> def SomeFactory(some_var=None): ...     class SomeClass(object): ...         nonlocal some_var ...         def print(): ...             print(some_var) ...     return SomeClass ...  >>> SomeFactory(some_var=\"hello world\").print() hello world      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6797984/how-to-convert-string-to-lowercase-in-python", "Language": "Python", "Q_Title": "How to convert string to lowercase in Python", "Q_Votes": "1534", "Q_Content": "    Is there a way to convert a string from uppercase, or even part uppercase to lowercase?   E.g. Kilometers --> kilometers.     ", "Tags": ["python", "string", "unicode", "uppercase", "lowercase"], "A_Votes": "2396", "A_Content": "  s = \"Kilometer\" print(s.lower())   The official documentation is str.lower().     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/6797984/how-to-convert-string-to-lowercase-in-python", "Language": "Python", "Q_Title": "How to convert string to lowercase in Python", "Q_Votes": "1534", "Q_Content": "    Is there a way to convert a string from uppercase, or even part uppercase to lowercase?   E.g. Kilometers --> kilometers.     ", "Tags": ["python", "string", "unicode", "uppercase", "lowercase"], "A_Votes": "161", "A_Content": "  With Python 2, this doesn't work for non-English words in UTF-8. In this case decode('utf-8') can help:  >>> s='\u041a\u0438\u043b\u043e\u043c\u0435\u0442\u0440' >>> print s.lower() \u041a\u0438\u043b\u043e\u043c\u0435\u0442\u0440 >>> print s.decode('utf-8').lower() \u043a\u0438\u043b\u043e\u043c\u0435\u0442\u0440      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6797984/how-to-convert-string-to-lowercase-in-python", "Language": "Python", "Q_Title": "How to convert string to lowercase in Python", "Q_Votes": "1534", "Q_Content": "    Is there a way to convert a string from uppercase, or even part uppercase to lowercase?   E.g. Kilometers --> kilometers.     ", "Tags": ["python", "string", "unicode", "uppercase", "lowercase"], "A_Votes": "109", "A_Content": "     How to convert string to lowercase in Python?      Is there any way to convert an entire user inputted string from uppercase, or even part uppercase to lowercase?       E.g. Kilometers --> kilometers   The canonical Pythonic way of doing this is   >>> 'Kilometers'.lower() 'kilometers'   However, if the purpose is to do case insensitive matching, you should use case-folding:  >>> 'Kilometers'.casefold() 'kilometers'   Here's why:  >>> \"Ma\u00dfe\".casefold() 'masse' >>> \"Ma\u00dfe\".lower() 'ma\u00dfe' >>> \"MASSE\" == \"Ma\u00dfe\" False >>> \"MASSE\".lower() == \"Ma\u00dfe\".lower() False >>> \"MASSE\".casefold() == \"Ma\u00dfe\".casefold() True   This is a str method in Python 3, but in Python 2, you'll want to look at the PyICU or py2casefold - several answers address this here.  Unicode Python 3  Python 3 handles unicode as regular strings:  >>> string = '\u041a\u0438\u043b\u043e\u043c\u0435\u0442\u0440' >>> string '\u041a\u0438\u043b\u043e\u043c\u0435\u0442\u0440' >>> string.lower() '\u043a\u0438\u043b\u043e\u043c\u0435\u0442\u0440'   Unicode Python 2  But Python 2 does not, the below, pasted into a shell, encodes the literal as a string of bytes, using utf-8.  And lower doesn't map any changes that native Unicode objects would be aware of, so we get the same string.   >>> string = '\u041a\u0438\u043b\u043e\u043c\u0435\u0442\u0440' >>> string '\\xd0\\x9a\\xd0\\xb8\\xd0\\xbb\\xd0\\xbe\\xd0\\xbc\\xd0\\xb5\\xd1\\x82\\xd1\\x80' >>> string.lower() '\\xd0\\x9a\\xd0\\xb8\\xd0\\xbb\\xd0\\xbe\\xd0\\xbc\\xd0\\xb5\\xd1\\x82\\xd1\\x80' >>> print string.lower() \u041a\u0438\u043b\u043e\u043c\u0435\u0442\u0440   In scripts, Python will object to non-ascii (as of Python 2.5, and warning in Python 2.4) bytes being in a string with no encoding given, since the intended coding would be ambiguous. For more on that, see the Unicode how-to in the docs and PEP 263  Use Unicode literals, not str literals  So we need a unicode string to handle this conversion, accomplished easily with a unicode literal:  >>> unicode_literal = u'\u041a\u0438\u043b\u043e\u043c\u0435\u0442\u0440' >>> print unicode_literal.lower() \u043a\u0438\u043b\u043e\u043c\u0435\u0442\u0440   Note that the bytes are completely different from the str bytes - the escape character is '\\u' followed by the 2-byte width, or 16 bit representation of these unicode letters:  >>> unicode_literal u'\\u041a\\u0438\\u043b\\u043e\\u043c\\u0435\\u0442\\u0440' >>> unicode_literal.lower() u'\\u043a\\u0438\\u043b\\u043e\\u043c\\u0435\\u0442\\u0440'   Now if we only have it in the form of a str, we need to convert it to unicode. Python's Unicode type is a universal encoding format that has many advantages relative to most other encodings. We can either use the unicode constructor or str.decode method with the codec to convert the str to unicode:  >>> unicode_from_string = unicode(string, 'utf-8') # \"encoding\" unicode from string >>> print unicode_from_string.lower() \u043a\u0438\u043b\u043e\u043c\u0435\u0442\u0440 >>> string_to_unicode = string.decode('utf-8')  >>> print string_to_unicode.lower() \u043a\u0438\u043b\u043e\u043c\u0435\u0442\u0440 >>> unicode_from_string == string_to_unicode == unicode_literal True   Both methods convert to the unicode type - and same as the unicode_literal.  Best Practice, use Unicode  It is recommended that you always work with text in Unicode.     Software should only work with Unicode strings internally, converting to a particular encoding on output.   Can encode back when necessary  However, to get the lowercase back in type str, encode the python string to utf-8 again:  >>> print string \u041a\u0438\u043b\u043e\u043c\u0435\u0442\u0440 >>> string '\\xd0\\x9a\\xd0\\xb8\\xd0\\xbb\\xd0\\xbe\\xd0\\xbc\\xd0\\xb5\\xd1\\x82\\xd1\\x80' >>> string.decode('utf-8') u'\\u041a\\u0438\\u043b\\u043e\\u043c\\u0435\\u0442\\u0440' >>> string.decode('utf-8').lower() u'\\u043a\\u0438\\u043b\\u043e\\u043c\\u0435\\u0442\\u0440' >>> string.decode('utf-8').lower().encode('utf-8') '\\xd0\\xba\\xd0\\xb8\\xd0\\xbb\\xd0\\xbe\\xd0\\xbc\\xd0\\xb5\\xd1\\x82\\xd1\\x80' >>> print string.decode('utf-8').lower().encode('utf-8') \u043a\u0438\u043b\u043e\u043c\u0435\u0442\u0440   So in Python 2, Unicode can encode into Python strings, and Python strings can decode into the Unicode type.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6797984/how-to-convert-string-to-lowercase-in-python", "Language": "Python", "Q_Title": "How to convert string to lowercase in Python", "Q_Votes": "1534", "Q_Content": "    Is there a way to convert a string from uppercase, or even part uppercase to lowercase?   E.g. Kilometers --> kilometers.     ", "Tags": ["python", "string", "unicode", "uppercase", "lowercase"], "A_Votes": "71", "A_Content": "  You can do what Peter said, or if you want the user to input something you could do the below code:  raw_input('Type Something').lower()   It will then automatically convert the string they typed into lowercase.  Note: raw_input was renamed to input in Python 3.x and above.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6797984/how-to-convert-string-to-lowercase-in-python", "Language": "Python", "Q_Title": "How to convert string to lowercase in Python", "Q_Votes": "1534", "Q_Content": "    Is there a way to convert a string from uppercase, or even part uppercase to lowercase?   E.g. Kilometers --> kilometers.     ", "Tags": ["python", "string", "unicode", "uppercase", "lowercase"], "A_Votes": "18", "A_Content": "  Also, you can overwrite some variables:  s = input('UPPER CASE') lower = s.lower()   If you use like this:  s = \"Kilometer\" print(s.lower())     - kilometer print(s)             - Kilometer   It will work just when called.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6797984/how-to-convert-string-to-lowercase-in-python", "Language": "Python", "Q_Title": "How to convert string to lowercase in Python", "Q_Votes": "1534", "Q_Content": "    Is there a way to convert a string from uppercase, or even part uppercase to lowercase?   E.g. Kilometers --> kilometers.     ", "Tags": ["python", "string", "unicode", "uppercase", "lowercase"], "A_Votes": "0", "A_Content": "  string.lower() is used to turn a string into a lower case string.  for example:  word = \"Turn Th!S !nt0 a L0w3rCas3! $string\" print(word.lower())   In this case, all the alphabets will be converted to lower case alphabets.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6797984/how-to-convert-string-to-lowercase-in-python", "Language": "Python", "Q_Title": "How to convert string to lowercase in Python", "Q_Votes": "1534", "Q_Content": "    Is there a way to convert a string from uppercase, or even part uppercase to lowercase?   E.g. Kilometers --> kilometers.     ", "Tags": ["python", "string", "unicode", "uppercase", "lowercase"], "A_Votes": "-2", "A_Content": "  If the whole text is uppercase like \"KILOMETER\", and you only want the first character to be lowercased, then do  text = \"KILOMETER\" result = text[:1] + text[1:].lower()  print(result)   But to lowercase the whole string, do      text = \"KILOMETER\" text = text.lower() print(text)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "2357", "A_Content": "  To get the full path to the directory a Python file is contained in, write this in that file:  import os  dir_path = os.path.dirname(os.path.realpath(__file__))   (Note that the incantation above won't work if you've already used os.chdir() to change your current working directory, since the value of the __file__ constant is relative to the current working directory and is not changed by an os.chdir() call.)    To get the current working directory use   import os cwd = os.getcwd()     Documentation references for the modules, constants and functions used above:   The os and os.path modules. The __file__ constant os.path.realpath(path) (returns \"the canonical path of the specified filename, eliminating any symbolic links encountered in the path\") os.path.dirname(path) (returns \"the directory name of pathname path\") os.getcwd() (returns \"a string representing the current working directory\") os.chdir(path) (\"change the current working directory to path\")      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "272", "A_Content": "  Current Working Directory:  os.getcwd()  And the __file__ attribute  can help you find out where the file you are executing is located.  This SO post explains everything:  How do I get the path of the current executed file in Python?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "229", "A_Content": "  You may find this useful as a reference:  import os  print(\"Path at terminal when executing this file\") print(os.getcwd() + \"\\n\")  print(\"This file path, relative to os.getcwd()\") print(__file__ + \"\\n\")  print(\"This file full path (following symlinks)\") full_path = os.path.realpath(__file__) print(full_path + \"\\n\")  print(\"This file directory and name\") path, filename = os.path.split(full_path) print(path + ' --> ' + filename + \"\\n\")  print(\"This file directory only\") print(os.path.dirname(full_path))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "47", "A_Content": "  1.To get the current directory full path      >>import os     >>print os.getcwd()   o/p:\"C :\\Users\\admin\\myfolder\"  1.To get the current directory folder name alone      >>import os     >>str1=os.getcwd()     >>str2=str1.split('\\\\')     >>n=len(str2)     >>print str2[n-1]   o/p:\"myfolder\"     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "33", "A_Content": "  If you are trying to find the current directory of the file you are currently in:  OS agnostic way:  dirname, filename = os.path.split(os.path.abspath(__file__))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "26", "A_Content": "  Answer to #1:  If you want the current directory, do this:  import os os.getcwd()   If you want just any folder name and you have the path to that folder, do this:  def get_folder_name(folder):     '''     Returns the folder name, given a full folder path     '''     return folder.split(os.sep)[-1]   Answer to #2:  import os print os.path.abspath(__file__)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "25", "A_Content": "  A bit late to the party, but I think the most succinct way to find just the name of your current execution context would be   current_folder_path, current_folder_name = os.path.split(os.getcwd())      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "24", "A_Content": "  If you're using Python 3.4, there is the brand new higher-level pathlib module which allows you to conveniently call pathlib.Path.cwd() to get a Path object representing your current working directory, along with many other new features.  More info on this new API can be found here.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "23", "A_Content": "  pathlib module, introduced in Python 3.4 (PEP 428 \u2014 The pathlib module \u2014 object-oriented filesystem paths), makes path-related experience much much better.  $ pwd /home/skovorodkin/stack $ tree . \u2514\u2500\u2500 scripts     \u251c\u2500\u2500 1.py     \u2514\u2500\u2500 2.py   In order to get current working directory use Path.cwd():  from pathlib import Path  print(Path.cwd())  # /home/skovorodkin/stack   To get an absolute path to your script file, use Path.resolve() method:  print(Path(__file__).resolve())  # /home/skovorodkin/stack/scripts/1.py   And to get path of a directory where your script is located, access .parent (it is recommended to call .resolve() before .parent):  print(Path(__file__).resolve().parent)  # /home/skovorodkin/stack/scripts   Remember that __file__ is not reliable in some situations: How do I get the path of the current executed file in Python?.    Please note, that Path.cwd(), Path.resolve() and other Path methods return path objects (PosixPath in my case), not strings. In Python 3.4 and 3.5 that caused some pain, because open built-in function could only work with string or bytes objects, and did not support Path objects, so you had to convert Path objects to strings or use Path.open() method, but the latter option required you to change old code:  $ cat scripts/2.py from pathlib import Path  p = Path(__file__).resolve()  with p.open() as f: pass with open(str(p)) as f: pass with open(p) as f: pass  print('OK')  $ python3.5 scripts/2.py Traceback (most recent call last):   File \"scripts/2.py\", line 11, in <module>     with open(p) as f: TypeError: invalid file: PosixPath('/home/skovorodkin/stack/scripts/2.py')   As you can see open(p) does not work with Python 3.5.  PEP 519 \u2014 Adding a file system path protocol, implemented in Python 3.6, adds support of PathLike objects to open function, so now you can pass Path objects to open function directly:  $ python3.6 scripts/2.py OK      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "17", "A_Content": "  If you're searching for the location of the currently executed script, you can use sys.argv[0] to get the full path.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "16", "A_Content": "  To get the current directory full path:     os.path.realpath('.')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "14", "A_Content": "  Pathlib can be used this way to get the directory containing current script :  import pathlib filepath = pathlib.Path(__file__).resolve().parent      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "5", "A_Content": "  For question 1 use os.getcwd() # get working dir and os.chdir(r'D:\\Steam\\steamapps\\common') # set working dir    I recommend using sys.argv[0] for question 2 because sys.argv is immutable and therefore always returns the current file (module object path) and not affected by os.chdir(). Also you can do like this:  import os this_py_file = os.path.realpath(__file__)  # vvv Below comes your code vvv #   but that snippet and sys.argv[0] will not work or will work wierd when compiled by PyInstaller because magic properties are not set in __main__ level and sys.argv[0] is the way your exe was called (means that it becomes affected by the working dir).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "4", "A_Content": "  In order to see current working directory type following script:  import os current_working_directory = os.getcwd()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5137497/find-current-directory-and-files-directory", "Language": "Python", "Q_Title": "Find current directory and file's directory [duplicate]", "Q_Votes": "1541", "Q_Content": "          This question already has an answer here:                              How to properly determine current script directory?                                        13 answers                                                    How to know/change current directory in Python shell?                                        6 answers                                          In Python, what commands can I use to find:   the current directory (where I was in the terminal when I ran the Python script), and where the file I am executing is?      ", "Tags": ["python", "directory"], "A_Votes": "3", "A_Content": "  For Get and set working directory in python. You can Use following code:  import os cwd = os.getcwd() #for Get the working directory     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "1370", "A_Content": "  This somewhat depends on what platform you are on. The most common way to do this is by printing ANSI escape sequences. For a simple example, here's some python code from the blender build scripts:  class bcolors:     HEADER = '\\033[95m'     OKBLUE = '\\033[94m'     OKGREEN = '\\033[92m'     WARNING = '\\033[93m'     FAIL = '\\033[91m'     ENDC = '\\033[0m'     BOLD = '\\033[1m'     UNDERLINE = '\\033[4m'   To use code like this, you can do something like   print bcolors.WARNING + \"Warning: No active frommets remain. Continue?\"        + bcolors.ENDC   This will work on unixes including OS X, linux and windows (provided you use ANSICON, or in Windows 10 provided you enable VT100 emulation). There are ansi codes for setting the color, moving the cursor, and more.  If you are going to get complicated with this (and it sounds like you are if you are writing a game), you should look into the \"curses\" module, which handles a lot of the complicated parts of this for you. The Python Curses HowTO is a good introduction.  If you are not using extended ASCII (i.e. not on a PC), you are stuck with the ascii characters below 127, and '#' or '@' is probably your best bet for a block. If you can ensure your terminal is using a IBM extended ascii character set, you have many more options. Characters 176, 177, 178 and 219 are the \"block characters\".  Some modern text-based programs, such as \"Dwarf Fortress\", emulate text mode in a graphical mode, and use images of the classic PC font. You can find some of these bitmaps that you can use on the Dwarf Fortress Wiki see (user-made tilesets).  The Text Mode Demo Contest has more resources for doing graphics in text mode.  Hmm.. I think got a little carried away on this answer. I am in the midst of planning an epic text-based adventure game, though. Good luck with your colored text!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "570", "A_Content": "  I'm surprised no one has mentioned the Python termcolor module. Usage is pretty simple:  from termcolor import colored  print colored('hello', 'red'), colored('world', 'green')   Or in Python 3:  print(colored('hello', 'red'), colored('world', 'green'))   It may not be sophisticated enough, however, for game programming and the \"colored blocks\" that you want to do...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "497", "A_Content": "  The answer is Colorama for all cross-platform coloring in Python.  A Python 3.6 example screenshot:      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "292", "A_Content": "  Print a string that starts a color/style, then the string, then end the color/style change with '\\x1b[0m':  print('\\x1b[6;30;42m' + 'Success!' + '\\x1b[0m')     Get a table of format options for shell text with following code:  def print_format_table():     \"\"\"     prints table of formatted text format options     \"\"\"     for style in range(8):         for fg in range(30,38):             s1 = ''             for bg in range(40,48):                 format = ';'.join([str(style), str(fg), str(bg)])                 s1 += '\\x1b[%sm %s \\x1b[0m' % (format, format)             print(s1)         print('\\n')  print_format_table()   Light-on-dark example (complete)    Dark-on-light example (partial)       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "79", "A_Content": "  Define a string that starts a color and a string that ends the color, then print your text with the start string at the front and the end string at the end.  CRED = '\\033[91m' CEND = '\\033[0m' print(CRED + \"Error, does not compute!\" + CEND)   This produces the following in bash, in urxvt with a Zenburn-style color scheme:    Through experemintation, we can get more colors:    Note: \\33[5m and \\33[6m are blinking.  This way we can create a full color collection:  CEND      = '\\33[0m' CBOLD     = '\\33[1m' CITALIC   = '\\33[3m' CURL      = '\\33[4m' CBLINK    = '\\33[5m' CBLINK2   = '\\33[6m' CSELECTED = '\\33[7m'  CBLACK  = '\\33[30m' CRED    = '\\33[31m' CGREEN  = '\\33[32m' CYELLOW = '\\33[33m' CBLUE   = '\\33[34m' CVIOLET = '\\33[35m' CBEIGE  = '\\33[36m' CWHITE  = '\\33[37m'  CBLACKBG  = '\\33[40m' CREDBG    = '\\33[41m' CGREENBG  = '\\33[42m' CYELLOWBG = '\\33[43m' CBLUEBG   = '\\33[44m' CVIOLETBG = '\\33[45m' CBEIGEBG  = '\\33[46m' CWHITEBG  = '\\33[47m'  CGREY    = '\\33[90m' CRED2    = '\\33[91m' CGREEN2  = '\\33[92m' CYELLOW2 = '\\33[93m' CBLUE2   = '\\33[94m' CVIOLET2 = '\\33[95m' CBEIGE2  = '\\33[96m' CWHITE2  = '\\33[97m'  CGREYBG    = '\\33[100m' CREDBG2    = '\\33[101m' CGREENBG2  = '\\33[102m' CYELLOWBG2 = '\\33[103m' CBLUEBG2   = '\\33[104m' CVIOLETBG2 = '\\33[105m' CBEIGEBG2  = '\\33[106m' CWHITEBG2  = '\\33[107m'   Here is the code to generate the test:  x = 0 for i in range(24):   colors = \"\"   for j in range(5):     code = str(x+j)     colors = colors + \"\\33[\" + code + \"m\\\\33[\" + code + \"m\\033[0m \"   print(colors)   x=x+5      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "71", "A_Content": "  You want to learn about ANSI escape sequences. Here's a brief example:  CSI=\"\\x1B[\" print CSI+\"31;40m\" + \"Colored Text\" + CSI + \"0m\"   For more info see http://en.wikipedia.org/wiki/ANSI_escape_code  For a block character, try a unicode character like \\u2588:  print u\"\\u2588\"   Putting it all together:  print CSI+\"31;40m\" + u\"\\u2588\" + CSI + \"0m\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "59", "A_Content": "  My favorite way is with the Blessings library (full disclosure: I wrote it). For example:  from blessings import Terminal  t = Terminal() print t.red('This is red.') print t.bold_bright_red_on_black('Bright red on black')   To print colored bricks, the most reliable way is to print spaces with background colors. I use this technique to draw the progress bar in nose-progressive:  print t.on_green(' ')   You can print in specific locations as well:  with t.location(0, 5):     print t.on_yellow(' ')   If you have to muck with other terminal capabilities in the course of your game, you can do that as well. You can use Python's standard string formatting to keep it readable:  print '{t.clear_eol}You just cleared a {t.bold}whole{t.normal} line!'.format(t=t)   The nice thing about Blessings is that it does its best to work on all sorts of terminals, not just the (overwhelmingly common) ANSI-color ones. It also keeps unreadable escape sequences out of your code while remaining concise to use. Have fun!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "42", "A_Content": "  generated a class with all the colors using a for loop to iterate every combination of color up to 100, then wrote a class with python colors. Copy and paste as you will, GPLv2 by me:  class colors:     '''Colors class:     reset all colors with colors.reset     two subclasses fg for foreground and bg for background.     use as colors.subclass.colorname.     i.e. colors.fg.red or colors.bg.green     also, the generic bold, disable, underline, reverse, strikethrough,     and invisible work with the main class     i.e. colors.bold     '''     reset='\\033[0m'     bold='\\033[01m'     disable='\\033[02m'     underline='\\033[04m'     reverse='\\033[07m'     strikethrough='\\033[09m'     invisible='\\033[08m'     class fg:         black='\\033[30m'         red='\\033[31m'         green='\\033[32m'         orange='\\033[33m'         blue='\\033[34m'         purple='\\033[35m'         cyan='\\033[36m'         lightgrey='\\033[37m'         darkgrey='\\033[90m'         lightred='\\033[91m'         lightgreen='\\033[92m'         yellow='\\033[93m'         lightblue='\\033[94m'         pink='\\033[95m'         lightcyan='\\033[96m'     class bg:         black='\\033[40m'         red='\\033[41m'         green='\\033[42m'         orange='\\033[43m'         blue='\\033[44m'         purple='\\033[45m'         cyan='\\033[46m'         lightgrey='\\033[47m'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "36", "A_Content": "  Try this simple code   def prRed(prt): print(\"\\033[91m {}\\033[00m\" .format(prt)) def prGreen(prt): print(\"\\033[92m {}\\033[00m\" .format(prt)) def prYellow(prt): print(\"\\033[93m {}\\033[00m\" .format(prt)) def prLightPurple(prt): print(\"\\033[94m {}\\033[00m\" .format(prt)) def prPurple(prt): print(\"\\033[95m {}\\033[00m\" .format(prt)) def prCyan(prt): print(\"\\033[96m {}\\033[00m\" .format(prt)) def prLightGray(prt): print(\"\\033[97m {}\\033[00m\" .format(prt)) def prBlack(prt): print(\"\\033[98m {}\\033[00m\" .format(prt))  prGreen(\"Hello world\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "24", "A_Content": "  On Windows you can use module 'win32console' (available in some Python distributions) or module 'ctypes' (Python 2.5 and up) to access the Win32 API.  To see complete code that supports both ways, see the color console reporting code from Testoob.  ctypes example:  import ctypes  # Constants from the Windows API STD_OUTPUT_HANDLE = -11 FOREGROUND_RED    = 0x0004 # text color contains red.  def get_csbi_attributes(handle):     # Based on IPython's winconsole.py, written by Alexander Belchenko     import struct     csbi = ctypes.create_string_buffer(22)     res = ctypes.windll.kernel32.GetConsoleScreenBufferInfo(handle, csbi)     assert res      (bufx, bufy, curx, cury, wattr,     left, top, right, bottom, maxx, maxy) = struct.unpack(\"hhhhHhhhhhh\", csbi.raw)     return wattr   handle = ctypes.windll.kernel32.GetStdHandle(STD_OUTPUT_HANDLE) reset = get_csbi_attributes(handle)  ctypes.windll.kernel32.SetConsoleTextAttribute(handle, FOREGROUND_RED) print \"Cherry on top\" ctypes.windll.kernel32.SetConsoleTextAttribute(handle, reset)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "20", "A_Content": "  Stupidly simple based on @joeld's answer  class PrintInColor:     RED = '\\033[91m'     GREEN = '\\033[92m'     YELLOW = '\\033[93m'     LIGHT_PURPLE = '\\033[94m'     PURPLE = '\\033[95m'     END = '\\033[0m'      @classmethod     def red(cls, s, **kwargs):         print(cls.RED + s + cls.END, **kwargs)      @classmethod     def green(cls, s, **kwargs):         print(cls.GREEN + s + cls.END, **kwargs)      @classmethod     def yellow(cls, s, **kwargs):         print(cls.YELLOW + s + cls.END, **kwargs)      @classmethod     def lightPurple(cls, s, **kwargs):         print(cls.LIGHT_PURPLE + s + cls.END, **kwargs)      @classmethod     def purple(cls, s, **kwargs):         print(cls.PURPLE + s + cls.END, **kwargs)   Then just  PrintInColor.red('hello', end=' ') PrintInColor.green('world')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "18", "A_Content": "  I have wrapped @joeld answer into a module with global functions that I can use anywhere in my code.  file: log.py       HEADER = '\\033[95m' OKBLUE = '\\033[94m' OKGREEN = '\\033[92m' WARNING = '\\033[93m' FAIL = '\\033[91m' ENDC = '\\033[0m' BOLD = \"\\033[1m\"  def disable():     HEADER = ''     OKBLUE = ''     OKGREEN = ''     WARNING = ''     FAIL = ''     ENDC = ''  def infog( msg):     print OKGREEN + msg + ENDC  def info( msg):     print OKBLUE + msg + ENDC  def warn( msg):     print WARNING + msg + ENDC  def err( msg):     print FAIL + msg + ENDC   use as follows:   import log     log.info(\"Hello World\")     log.err(\"System Error\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "18", "A_Content": "  Building on @joeld answer, using https://pypi.python.org/pypi/lazyme  pip install -U lazyme :  from lazyme.string import color_print >>> color_print('abc') abc >>> color_print('abc', color='pink') abc >>> color_print('abc', color='red') abc >>> color_print('abc', color='yellow') abc >>> color_print('abc', color='green') abc >>> color_print('abc', color='blue', underline=True) abc >>> color_print('abc', color='blue', underline=True, bold=True) abc >>> color_print('abc', color='pink', underline=True, bold=True) abc   Screenshot:      Some updates to the color_print with new formatters, e.g.:  >>> from lazyme.string import palette, highlighter, formatter >>> from lazyme.string import color_print >>> palette.keys() # Available colors. ['pink', 'yellow', 'cyan', 'magenta', 'blue', 'gray', 'default', 'black', 'green', 'white', 'red'] >>> highlighter.keys() # Available highlights. ['blue', 'pink', 'gray', 'black', 'yellow', 'cyan', 'green', 'magenta', 'white', 'red'] >>> formatter.keys() # Available formatter,  ['hide', 'bold', 'italic', 'default', 'fast_blinking', 'faint', 'strikethrough', 'underline', 'blinking', 'reverse']   Note: italic, fast blinking and strikethrough may not work on all terminals, doesn't work on Mac / Ubuntu.   E.g.   >>> color_print('foo bar', color='pink', highlight='white') foo bar >>> color_print('foo bar', color='pink', highlight='white', reverse=True) foo bar >>> color_print('foo bar', color='pink', highlight='white', bold=True) foo bar >>> color_print('foo bar', color='pink', highlight='white', faint=True) foo bar >>> color_print('foo bar', color='pink', highlight='white', faint=True, reverse=True) foo bar >>> color_print('foo bar', color='pink', highlight='white', underline=True, reverse=True) foo bar   Screenshot:       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "17", "A_Content": "  For Windows you cannot print to console with colors unless you're using the win32api.  For Linux it's as simple as using print, with the escape sequences outlined here:  Colors  For the character to print like a box, it really depends on what font you are using for the console window. The pound symbol works well, but it depends on the font:  #      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "15", "A_Content": "  note how well the with keyword mixes with modifiers like these that need to be reset (using Python 3 and Colorama):  from colorama import Fore, Style import sys  class Highlight:   def __init__(self, clazz, color):     self.color = color     self.clazz = clazz   def __enter__(self):     print(self.color, end=\"\")   def __exit__(self, type, value, traceback):     if self.clazz == Fore:       print(Fore.RESET, end=\"\")     else:       assert self.clazz == Style       print(Style.RESET_ALL, end=\"\")     sys.stdout.flush()  with Highlight(Fore, Fore.GREEN):   print(\"this is highlighted\") print(\"this is not\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "15", "A_Content": "  I ended up doing this, I felt it was cleanest:   formatters = {                  'RED': '\\033[91m',          'GREEN': '\\033[92m',        'END': '\\033[0m',       }  print 'Master is currently {RED}red{END}!'.format(**formatters) print 'Help make master {GREEN}green{END} again!'.format(**formatters)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "15", "A_Content": "  You could use CLINT:  from clint.textui import colored print colored.red('some warning message') print colored.green('nicely done!')   Get it from GitHub.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "14", "A_Content": "  You can use the Python implementation of the curses library: http://docs.python.org/library/curses.html  Also, run this and you'll find your box:  for i in range(255):     print i, chr(i)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "12", "A_Content": "  sty is similar to colorama, but it's less verbose, supports 8bit and 24bit (rgb) colors, allows you to register your own colors, is really flexible and well documented. If you don't care about compatibility with terminal emulators that are stuck in the 90th and like to use new features, you might want to give it a try.  from sty import fg, bg, ef, rs, Rule  foo = fg.red + 'This is red text!' + fg.rs bar = bg.blue + 'This has a blue background!' + bg.rs baz = ef.italic + 'This is italic text' + rs.italic qux = fg(201) + 'This is pink text using 8bit colors' + fg.rs qui = fg(255, 10, 10) + 'This is red text using 24bit colors.' + fg.rs  # Add new colors:  fg.orange = Rule('rgb_fg', 255, 150, 50)  buf = fg.orange + 'Yay, Im orange.' + fg.rs   print(foo, bar, baz, qux, qui, buf, sep='\\n')   prints:    Demo:      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "10", "A_Content": "  If you are programming a game perhaps you would like to change the background color and use only spaces? For example:  print \" \"+ \"\\033[01;41m\" + \" \" +\"\\033[01;46m\"  + \"  \" + \"\\033[01;42m\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "10", "A_Content": "  asciimatics provides a portable support for building text UI and animations:  #!/usr/bin/env python from asciimatics.effects import RandomNoise  # $ pip install asciimatics from asciimatics.renderers import SpeechBubble, Rainbow from asciimatics.scene import Scene from asciimatics.screen import Screen from asciimatics.exceptions import ResizeScreenError   def demo(screen):     render = Rainbow(screen, SpeechBubble('Rainbow'))     effects = [RandomNoise(screen, signal=render)]     screen.play([Scene(effects, -1)], stop_on_resize=True)  while True:     try:         Screen.wrapper(demo)         break     except ResizeScreenError:         pass   Asciicast:       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "10", "A_Content": "  Yet another pypi module that wraps the python 3 print function:  https://pypi.python.org/pypi/colorprint  It's usable in python 2.x if you also from __future__ import print. Here is a python 2 example from the modules pypi page:  from __future__ import print_function from colorprint import *  print('Hello', 'world', color='blue', end='', sep=', ') print('!', color='red', format=['bold', 'blink'])   Outputs \"Hello, world!\" with the words in blue and the exclamation mark bold red and blinking.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "9", "A_Content": "  Here's a curses example:  import curses  def main(stdscr):     stdscr.clear()     if curses.has_colors():         for i in xrange(1, curses.COLORS):             curses.init_pair(i, i, curses.COLOR_BLACK)             stdscr.addstr(\"COLOR %d! \" % i, curses.color_pair(i))             stdscr.addstr(\"BOLD! \", curses.color_pair(i) | curses.A_BOLD)             stdscr.addstr(\"STANDOUT! \", curses.color_pair(i) | curses.A_STANDOUT)             stdscr.addstr(\"UNDERLINE! \", curses.color_pair(i) | curses.A_UNDERLINE)             stdscr.addstr(\"BLINK! \", curses.color_pair(i) | curses.A_BLINK)             stdscr.addstr(\"DIM! \", curses.color_pair(i) | curses.A_DIM)             stdscr.addstr(\"REVERSE! \", curses.color_pair(i) | curses.A_REVERSE)     stdscr.refresh()     stdscr.getch()  if __name__ == '__main__':     print \"init...\"     curses.wrapper(main)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "9", "A_Content": "  YAY! another version  while i find this answer useful, i modified it a bit. this Github Gist is the result  usage  print colors.draw(\"i'm yellow\", bold=True, fg_yellow=True)     in addition you can wrap common usages:  print colors.error('sorry, ')     https://gist.github.com/Jossef/0ee20314577925b4027f     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "8", "A_Content": "  https://raw.github.com/fabric/fabric/master/fabric/colors.py  \"\"\" .. versionadded:: 0.9.2  Functions for wrapping strings in ANSI color codes.  Each function within this module returns the input string ``text``, wrapped with ANSI color codes for the appropriate color.  For example, to print some text as green on supporting terminals::      from fabric.colors import green      print(green(\"This text is green!\"))  Because these functions simply return modified strings, you can nest them::      from fabric.colors import red, green      print(red(\"This sentence is red, except for \" + \\           green(\"these words, which are green\") + \".\"))  If ``bold`` is set to ``True``, the ANSI flag for bolding will be flipped on for that particular invocation, which usually shows up as a bold or brighter version of the original color on most terminals. \"\"\"   def _wrap_with(code):      def inner(text, bold=False):         c = code         if bold:             c = \"1;%s\" % c         return \"\\033[%sm%s\\033[0m\" % (c, text)     return inner  red = _wrap_with('31') green = _wrap_with('32') yellow = _wrap_with('33') blue = _wrap_with('34') magenta = _wrap_with('35') cyan = _wrap_with('36') white = _wrap_with('37')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "7", "A_Content": "  If you are using Windows, then here you go!  # display text on a Windows console # Windows XP with Python27 or Python32 from ctypes import windll # needed for Python2/Python3 diff try:     input = raw_input except:     pass STD_OUTPUT_HANDLE = -11 stdout_handle = windll.kernel32.GetStdHandle(STD_OUTPUT_HANDLE) # look at the output and select the color you want # for instance hex E is yellow on black # hex 1E is yellow on blue # hex 2E is yellow on green and so on for color in range(0, 75):      windll.kernel32.SetConsoleTextAttribute(stdout_handle, color)      print(\"%X --> %s\" % (color, \"Have a fine day!\"))      input(\"Press Enter to go on ... \")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "7", "A_Content": "  If you are using Django   >>> from django.utils.termcolors import colorize >>> print colorize(\"Hello World!\", fg=\"blue\", bg='red', ...                 opts=('bold', 'blink', 'underscore',)) Hello World! >>> help(colorize)   snapshot:    (I generally use colored output for debugging on runserver terminal so I added it.)   You can test if it is installed in your machine:  $ python -c \"import django; print django.VERSION\" To install it check: How to install Django   Give it a Try!!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "5", "A_Content": "  # Pure Python 3.x demo, 256 colors # Works with bash under Linux  fg = lambda text, color: \"\\33[38;5;\" + str(color) + \"m\" + text + \"\\33[0m\" bg = lambda text, color: \"\\33[48;5;\" + str(color) + \"m\" + text + \"\\33[0m\"  def print_six(row, format):     for col in range(6):         color = row*6 + col + 4         if color>=0:             text = \"{:3d}\".format(color)             print (format(text,color), end=\" \")         else:             print(\"   \", end=\" \")  for row in range(-1,42):     print_six(row, fg)     print(\"\",end=\" \")     print_six(row, bg)     print()         ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "5", "A_Content": "  One easier option would be to use the cprint function from termcolor package.    It also supports %s, %d format of printing       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", "Language": "Python", "Q_Title": "Print in terminal with colors?", "Q_Votes": "1549", "Q_Content": "    How can I output colored text to the terminal, in Python? What is the best Unicode symbol to represent a solid block?     ", "Tags": ["python", "unicode", "terminal", "ansi-colors"], "A_Votes": "3", "A_Content": "  For the characters  Your terminal most probably uses Unicode (typically UTF-8 encoded) characters, so it's only a matter of the appropriate font selection to see your favorite character. Unicode char U+2588, \"Full block\" is the one I would suggest you use.  Try the following:  import unicodedata fp= open(\"character_list\", \"w\") for index in xrange(65536):     char= unichr(index)     try: its_name= unicodedata.name(char)     except ValueError: its_name= \"N/A\"     fp.write(\"%05d %04x %s %s\\n\" % (index, index, char.encode(\"UTF-8\"), its_name) fp.close()   Examine the file later with your favourite viewer.  For the colors  curses is the module you want to use. Check this tutorial.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1712227/how-to-get-the-number-of-elements-in-a-list-in-python", "Language": "Python", "Q_Title": "How to get the number of elements in a list in Python?", "Q_Votes": "1575", "Q_Content": "    items = [] items.append(\"apple\") items.append(\"orange\") items.append(\"banana\")  # FAKE METHOD:: items.amount()  # Should return 3   How do I get the number of elements in the list?     ", "Tags": ["python", "list"], "A_Votes": "2178", "A_Content": "  The len() function can be used with a lot of types in Python - both built-in types and library types.  >>> len([1,2,3]) 3      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1712227/how-to-get-the-number-of-elements-in-a-list-in-python", "Language": "Python", "Q_Title": "How to get the number of elements in a list in Python?", "Q_Votes": "1575", "Q_Content": "    items = [] items.append(\"apple\") items.append(\"orange\") items.append(\"banana\")  # FAKE METHOD:: items.amount()  # Should return 3   How do I get the number of elements in the list?     ", "Tags": ["python", "list"], "A_Votes": "145", "A_Content": "     How to get the size of a list?   To find the size of a list, use the builtin function, len:  items = [] items.append(\"apple\") items.append(\"orange\") items.append(\"banana\")   And now:  len(items)   returns 3.  Explanation  Everything in Python is an object, including lists. All objects have a header of some sort in the C implementation.   Lists and other similar builtin objects with a \"size\" in Python, in particular, have an attribute called ob_size, where the number of elements in the object is cached. So checking the number of objects in a list is very fast.  But if you're checking if list size is zero or not, don't use len - instead, put the list in a boolean context - it treated as False if empty, True otherwise.  From the docs  len(s)     Return the length (the number of items) of an object. The argument may be a sequence (such as a string, bytes, tuple, list, or range) or   a collection (such as a dictionary, set, or frozen set).   len is implemented with __len__, from the data model docs:  object.__len__(self)     Called to implement the built-in function len(). Should return the length of the object, an integer >= 0. Also, an object that doesn\u2019t   define a __nonzero__() [in Python 2 or __bool__() in Python 3] method and whose __len__() method returns zero   is considered to be false in a Boolean context.   And we can also see that __len__ is a method of lists:  items.__len__()   returns 3.  Builtin types you can get the len (length) of  And in fact we see we can get this information for all of the described types:  >>> all(hasattr(cls, '__len__') for cls in (str, bytes, tuple, list,                                              xrange, dict, set, frozenset)) True   Do not use len to test for an empty or nonempty list  To test for a specific length, of course, simply test for equality:  if len(items) == required_length:     ...   But there's a special case for testing for a zero length list or the inverse. In that case, do not test for equality.  Also, do not do:  if len(items):      ...   Instead, simply do:  if items:     # Then we have some items, not empty!     ...   or  if not items: # Then we have an empty list!     ...   I explain why here but in short, if items or if not items is both more readable and more performant.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1712227/how-to-get-the-number-of-elements-in-a-list-in-python", "Language": "Python", "Q_Title": "How to get the number of elements in a list in Python?", "Q_Votes": "1575", "Q_Content": "    items = [] items.append(\"apple\") items.append(\"orange\") items.append(\"banana\")  # FAKE METHOD:: items.amount()  # Should return 3   How do I get the number of elements in the list?     ", "Tags": ["python", "list"], "A_Votes": "64", "A_Content": "  While this may not be useful due to the fact that it'd make a lot more sense as being \"out of the box\" functionality, a fairly simple hack would be to build a class with a length property:  class slist(list):     @property     def length(self):         return len(self)   You can use it like so:  >>> l = slist(range(10)) >>> l.length 10 >>> print l [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]   Essentially, it's exactly identical to a list object, with the added benefit of having an OOP-friendly length property.  As always, your mileage may vary.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1712227/how-to-get-the-number-of-elements-in-a-list-in-python", "Language": "Python", "Q_Title": "How to get the number of elements in a list in Python?", "Q_Votes": "1575", "Q_Content": "    items = [] items.append(\"apple\") items.append(\"orange\") items.append(\"banana\")  # FAKE METHOD:: items.amount()  # Should return 3   How do I get the number of elements in the list?     ", "Tags": ["python", "list"], "A_Votes": "9", "A_Content": "  Besides len you can also use operator.length_hint (requires python 3.4+). For normal list both are equivalent but length_hint makes it possible to get the length of a list-iterator, which could be useful in certain circumstances:  >>> from operator import length_hint >>> l = [\"apple\", \"orange\", \"banana\"] >>> len(l) 3 >>> length_hint(l) 3  >>> list_iterator = iter(l) >>> len(list_iterator) TypeError: object of type 'list_iterator' has no len() >>> length_hint(list_iterator) 3   But length_hint is by definition only a \"hint\", so most of the time len is better.  I've seen several answers suggesting accessing __len__. This is alright when dealing with built-in classes like list but it could lead to problems with custom classes because len (and length_hint) implement some safety checks. For example both do not allow negative lengths or lengths that exceed a certain value (the sys.maxsize value). So it's always safer to use the len function instead of the __len__ method!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1712227/how-to-get-the-number-of-elements-in-a-list-in-python", "Language": "Python", "Q_Title": "How to get the number of elements in a list in Python?", "Q_Votes": "1575", "Q_Content": "    items = [] items.append(\"apple\") items.append(\"orange\") items.append(\"banana\")  # FAKE METHOD:: items.amount()  # Should return 3   How do I get the number of elements in the list?     ", "Tags": ["python", "list"], "A_Votes": "6", "A_Content": "  Answering your question as the examples also given previously:  items = [] items.append(\"apple\") items.append(\"orange\") items.append(\"banana\")  print items.__len__()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1712227/how-to-get-the-number-of-elements-in-a-list-in-python", "Language": "Python", "Q_Title": "How to get the number of elements in a list in Python?", "Q_Votes": "1575", "Q_Content": "    items = [] items.append(\"apple\") items.append(\"orange\") items.append(\"banana\")  # FAKE METHOD:: items.amount()  # Should return 3   How do I get the number of elements in the list?     ", "Tags": ["python", "list"], "A_Votes": "3", "A_Content": "  And for completeness (taking one for the team with the downvotes), it is possible without using the len() function (I would not condone this as a good option):  def count(list):   item_count = 0   for item in list[:]:     item_count = item_count + 1   return item_count  count([1,2,3,4,5])   (the colon in list[:] is implicit, therefore also optional)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python", "Language": "Python", "Q_Title": "Manually raising (throwing) an exception in Python", "Q_Votes": "1580", "Q_Content": "    How can I raise an exception in Python so that it can later be caught via an except block?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "1968", "A_Content": "     How do I manually throw/raise an exception in Python?   Use the most specific Exception constructor that semantically fits your issue.    Be specific in your message, e.g.:  raise ValueError('A very specific bad thing happened.')   Don't raise generic exceptions  Avoid raising a generic Exception. To catch it, you'll have to catch all other more specific exceptions that subclass it.  Problem 1: Hiding bugs  raise Exception('I know Python!') # Don't! If you catch, likely to hide bugs.   For example:  def demo_bad_catch():     try:         raise ValueError('Represents a hidden bug, do not catch this')         raise Exception('This is the exception you expect to handle')     except Exception as error:         print('Caught this error: ' + repr(error))  >>> demo_bad_catch() Caught this error: ValueError('Represents a hidden bug, do not catch this',)   Problem 2: Won't catch  and more specific catches won't catch the general exception:  def demo_no_catch():     try:         raise Exception('general exceptions not caught by specific handling')     except ValueError as e:         print('we will not catch exception: Exception')   >>> demo_no_catch() Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 3, in demo_no_catch Exception: general exceptions not caught by specific handling   Best Practices: raise statement  Instead, use the most specific Exception constructor that semantically fits your issue.  raise ValueError('A very specific bad thing happened')   which also handily allows an arbitrary number of arguments to be passed to the constructor:  raise ValueError('A very specific bad thing happened', 'foo', 'bar', 'baz')    These arguments are accessed by the args attribute on the Exception object. For example:  try:     some_code_that_may_raise_our_value_error() except ValueError as err:     print(err.args)   prints   ('message', 'foo', 'bar', 'baz')       In Python 2.5, an actual message attribute was added to BaseException in favor of encouraging users to subclass Exceptions and stop using args, but the introduction of message and the original deprecation of args has been retracted.  Best Practices: except clause  When inside an except clause, you might want to, for example, log that a specific type of error happened, and then re-raise. The best way to do this while preserving the stack trace is to use a bare raise statement. For example:  logger = logging.getLogger(__name__)  try:     do_something_in_app_that_breaks_easily() except AppError as error:     logger.error(error)     raise                 # just this!     # raise AppError      # Don't do this, you'll lose the stack trace!   Don't modify your errors... but if you insist.  You can preserve the stacktrace (and error value) with sys.exc_info(), but this is way more error prone and has compatibility problems between Python 2 and 3, prefer to use a bare raise to re-raise.   To explain - the sys.exc_info() returns the type, value, and traceback.   type, value, traceback = sys.exc_info()   This is the syntax in Python 2 - note this is not compatible with Python 3:      raise AppError, error, sys.exc_info()[2] # avoid this.     # Equivalently, as error *is* the second object:     raise sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]   If you want to, you can modify what happens with your new raise - e.g. setting new args for the instance:  def error():     raise ValueError('oops!')  def catch_error_modify_message():     try:         error()     except ValueError:         error_type, error_instance, traceback = sys.exc_info()         error_instance.args = (error_instance.args[0] + ' <modification>',)         raise error_type, error_instance, traceback   And we have preserved the whole traceback while modifying the args. Note that this is not a best practice and it is invalid syntax in Python 3 (making keeping compatibility much harder to work around).  >>> catch_error_modify_message() Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 3, in catch_error_modify_message   File \"<stdin>\", line 2, in error ValueError: oops! <modification>   In Python 3:      raise error.with_traceback(sys.exc_info()[2])   Again: avoid manually manipulating tracebacks. It's less efficient and more error prone. And if you're using threading and sys.exc_info you may even get the wrong traceback (especially if you're using exception handling for control flow - which I'd personally tend to avoid.)  Python 3, Exception chaining  In Python 3, you can chain Exceptions, which preserve tracebacks:      raise RuntimeError('specific message') from error   Be aware:   this does allow changing the error type raised, and this is not compatible with Python 2.   Deprecated Methods:  These can easily hide and even get into production code. You want to raise an exception, and doing them will raise an exception, but not the one intended!  Valid in Python 2, but not in Python 3 is the following:  raise ValueError, 'message' # Don't do this, it's deprecated!   Only valid in much older versions of Python (2.4 and lower), you may still see people raising strings:  raise 'message' # really really wrong. don't do this.   In all modern versions, this will actually raise a TypeError, because you're not raising a BaseException type. If you're not checking for the right exception and don't have a reviewer that's aware of the issue, it could get into production.  Example Usage  I raise Exceptions to warn consumers of my API if they're using it incorrectly:  def api_func(foo):     '''foo should be either 'baz' or 'bar'. returns something very useful.'''     if foo not in _ALLOWED_ARGS:         raise ValueError('{foo} wrong, use \"baz\" or \"bar\"'.format(foo=repr(foo)))   Create your own error types when apropos     \"I want to make an error on purpose, so that it would go into the except\"   You can create your own error types, if you want to indicate something specific is wrong with your application, just subclass the appropriate point in the exception hierarchy:  class MyAppLookupError(LookupError):     '''raise this when there's a lookup error for my app'''   and usage:  if important_key not in resource_dict and not ok_to_be_missing:     raise MyAppLookupError('resource is missing, and that is not ok.')      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python", "Language": "Python", "Q_Title": "Manually raising (throwing) an exception in Python", "Q_Votes": "1580", "Q_Content": "    How can I raise an exception in Python so that it can later be caught via an except block?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "537", "A_Content": "     DON'T DO THIS. Raising a bare Exception is absolutely not the right thing to do; see Aaron Hall's excellent answer instead.   Can't get much more pythonic than this:  raise Exception(\"I know python!\")   See the raise statement docs for python if you'd like more info.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python", "Language": "Python", "Q_Title": "Manually raising (throwing) an exception in Python", "Q_Votes": "1580", "Q_Content": "    How can I raise an exception in Python so that it can later be caught via an except block?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "30", "A_Content": "  For the common case where you need to throw an exception in response to some unexpected conditions, and that you never intend to catch, but simply to fail fast to enable you to debug from there if it ever happens \u2014 the most logical one seems to be AssertionError:  if 0 < distance <= RADIUS:     #Do something. elif RADIUS < distance:     #Do something. else:     raise AssertionError(\"Unexpected value of 'distance'!\", distance)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python", "Language": "Python", "Q_Title": "Manually raising (throwing) an exception in Python", "Q_Votes": "1580", "Q_Content": "    How can I raise an exception in Python so that it can later be caught via an except block?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "26", "A_Content": "  In Python3 there are 4 different syntaxes for rasing exceptions:   1. raise exception  2. raise exception (args)  3. raise 4. raise exception (args) from original_exception      1. raise exception vs. 2. raise exception (args)   If you use raise exception (args)  to raise an exception then the   args will be printed when you print the exception object - as shown in the example below.     #raise exception (args)     try:         raise ValueError(\"I have raised an Exception\")     except ValueError as exp:         print (\"Error\", exp)     # Output -> Error I have raised an Exception       #raise execption      try:         raise ValueError     except ValueError as exp:         print (\"Error\", exp)     # Output -> Error       3.raise   raise statement without any arguments re-raises the last exception.  This is useful if you need to perform some actions after catching the exception and  then want to re-raise it. But if there was no exception before, raise statement raises  TypeError Exception.   def somefunction():     print(\"some cleaning\")  a=10 b=0  result=None  try:     result=a/b     print(result)  except Exception:            #Output ->     somefunction()           #some cleaning     raise                    #Traceback (most recent call last):                              #File \"python\", line 8, in <module>                              #ZeroDivisionError: division by zero      4. raise exception (args) from original_exception   This statement is used to create exception chaining in which an exception that is raised in response to another exception can contain the details of the original exception - as shown in the example below.  class MyCustomException(Exception): pass  a=10 b=0  reuslt=None try:     try:         result=a/b      except ZeroDivisionError as exp:         print(\"ZeroDivisionError -- \",exp)         raise MyCustomException(\"Zero Division \") from exp  except MyCustomException as exp:         print(\"MyException\",exp)         print(exp.__cause__)   Output:  ZeroDivisionError --  division by zero MyException Zero Division  division by zero      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python", "Language": "Python", "Q_Title": "Manually raising (throwing) an exception in Python", "Q_Votes": "1580", "Q_Content": "    How can I raise an exception in Python so that it can later be caught via an except block?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "5", "A_Content": "  Read the existing answers first, this is just an addendum.  Notice that you can raise exceptions with or without arguments.  Example:  raise SystemExit   exits the program but you might want to know what happened.So you can use this.  raise SystemExit(\"program exited\")   this will print \"program exited\" to stderr before closing the program.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "2474", "A_Content": "  >>> x = \"Hello World!\" >>> x[2:] 'llo World!' >>> x[:2] 'He' >>> x[:-2] 'Hello Worl' >>> x[-2:] 'd!' >>> x[2:-2] 'llo Worl'   Python calls this concept \"slicing\" and it works on more than just strings. Take a look here for a comprehensive introduction.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "311", "A_Content": "  Just for completeness as nobody else has mentioned it.  The third parameter to an array slice is a step.  So reversing a string is as simple as:  some_string[::-1]   Or selecting alternate characters would be:  \"H-e-l-l-o- -W-o-r-l-d\"[::2] # outputs \"Hello World\"   The ability to step forwards and backwards through the string maintains consistency with being able to array slice from the start or end.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "94", "A_Content": "  Substr() normally (i.e. PHP and Perl) works this way:   s = Substr(s, beginning, LENGTH)   So the parameters are beginning and LENGTH.  But Python's behaviour is different; it expects beginning and one after END (!). This is difficult to spot by beginners. So the correct replacement for Substr(s, beginning, LENGTH) is  s = s[ beginning : beginning + LENGTH]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "45", "A_Content": "  A common way to achieve this is by String slicing. MyString[a:b] gives you a substring from index a to (b - 1)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "17", "A_Content": "  One example seems to be missing here: full (shallow) copy.  >>> x = \"Hello World!\" >>> x 'Hello World!' >>> x[:] 'Hello World!' >>> x==x[:] True >>>    This is a common idiom for creating a copy of sequence types (not of interned strings). [:] Shallow copies a list, See python-list-slice-used-for-no-obvious-reason.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "14", "A_Content": "     Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?      Maybe like myString[2:end]?   Yes, this actually works if you assign, or bind, the name,end, to constant singleton, None:  >>> end = None >>> myString = '1234567890' >>> myString[2:end] '34567890'   Slice notation has 3 important arguments:   start stop step   Their defaults when not given are None - but we can pass them explicitly:  >>> stop = step = None >>> start = 2 >>> myString[start:stop:step] '34567890'      If leaving the second part means 'till the end', if you leave the first part, does it start from the start?   Yes, for example:  >>> start = None >>> stop = 2 >>> myString[start:stop:step] '12'   Note that we include start in the slice, but we only go up to, and not including, stop.  When step is None, by default the slice uses 1 for the step. If you step with a negative integer, Python is smart enough to go from the end to the beginning.  >>> myString[::-1] '0987654321'   I explain slice notation in great detail in my answer to Explain slice notation Question.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "7", "A_Content": "  You've got it right there except for \"end\". It's called slice notation. Your example should read:  new_sub_string = myString[2:]   If you leave out the second parameter it is implicitly the end of the string.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "6", "A_Content": "  I would like to add two points to the discussion:   You can use None instead on an empty space to specify \"from the start\" or \"to the end\":  'abcde'[2:None] == 'abcde'[2:] == 'cde'   This is particularly helpful in functions, where you can't provide an empty space as an argument:  def substring(s, start, end):     \"\"\"Remove `start` characters from the beginning and `end`      characters from the end of string `s`.      Examples     --------     >>> substring('abcde', 0, 3)     'abc'     >>> substring('abcde', 1, None)     'bcde'     \"\"\"     return s[start:end]  Python has slice objects:  idx = slice(2, None) 'abcde'[idx] == 'abcde'[2:] == 'cde'       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "2", "A_Content": "  Maybe I missed it, but I couldn't find a complete answer on this page to the original question(s) because variables are not further discussed here. So I had to go on searching.  Since I'm not yet allowed to comment, let me add my conclusion here. I'm sure I was not the only one interested in it when accessing this page:     >>>myString = 'Hello World'  >>>end = 5   >>>myString[2:end]  'llo'   If you leave the first part, you get      >>>myString[:end]  'Hello'    And if you left the : in the middle as well you got the simplest substring, which would be the 5th character (count starting with 0, so it's the blank in this case):   >>>myString[end]  ' '      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/663171/is-there-a-way-to-substring-a-string-in-python", "Language": "Python", "Q_Title": "Is there a way to substring a string in Python?", "Q_Votes": "1634", "Q_Content": "    Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?  Maybe like myString[2:end]?  If leaving the second part means 'till the end', if you leave the first part, does it start from the start?     ", "Tags": ["python", "string"], "A_Votes": "0", "A_Content": "  Using hardcoded indexes itself can be a mess.  In order to avoid that, Python offers a built-in object slice().  string = \"my company has 1000$ on profit, but I lost 500$ gambling.\"   If we want to know how many money I got left.  Normal solution:  final = int(string[15:19]) - int(string[43:46]) print(final) >>>500   Using slices:  EARNINGS = slice(15, 19) LOSSES = slice(43, 46) final = int(string[EARNINGS]) - int(string[LOSSES]) print(final) >>>500   Using slice you gain readability.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "2925", "A_Content": "  easy_install pip     If you need admin privileges to run this, try:  sudo easy_install pip      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "418", "A_Content": "  You can install it through Homebrew on OS X.  Why would you install Python with Homebrew?     The version of Python that ships with OS X is great for learning but   it\u2019s not good for development. The version shipped with OS X may be   out of date from the official current Python release, which is   considered the stable production version. (source)   Homebrew is something of a package manager for OS X.  Find more details on the Homebrew page.  Once Homebrew is installed, run the following to install the latest Python, Pip & Setuptools:  brew install python      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "411", "A_Content": "     \u26a1\ufe0f TL;DR \u2014 One line solution.   All you have to do is:  sudo easy_install pip   I made a gif, coz. why not?    Details:     \u26a1\ufe0f OK, I read the solutions given above, but here's an EASY solution to install pip.    MacOS comes with Python installed. But to make sure that you have Python installed open the terminal and run the following command.  python --version   If this command returns a version number that means Python exists. Which also means that you already have access to easy_install considering you are using macOS/OSX.  \u2139\ufe0f Now, all you have to do is run the following command.  sudo easy_install pip   After that, pip will be installed and you'll be able to use it for installing other packages.  Let me know if you have any problems installing pip this way.  Cheers!   P.S. I ended up blogging a post about it. QuickTip: How Do I Install pip on macOS or OS X?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "277", "A_Content": "  I'm surprised no-one has mentioned this - since 2013, python itself is capable of installing pip, no external commands (and no internet connection) required.  sudo python -m ensurepip   This will create a similar install to what easy_install would.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "130", "A_Content": "  On Mac:   Install easy_install  curl https://bootstrap.pypa.io/ez_setup.py -o - | sudo python  Install pip  sudo easy_install pip  Now, you could install external modules. For example  pip install regex   # This is only an example for installing other modules       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "88", "A_Content": "  pip is available on OS X via easy_install. Open a terminal and type:  sudo easy_install pip   When prompted for a password enter your normal login password. After the installation has completed you should be able to use pip as expected.     note: this works for other python packages too     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "74", "A_Content": "  The simplest solution is to follow the installation instruction from pip's home site.  Basically, this consists in:   downloading get-pip.py. Be sure to do this by following a trusted link since you will have to run the script as root. call sudo python get-pip.py   The main advantage of that solution is that it install pip for the python version that has been used to run get-pip.py, which means that if you use the default OS X installation of python to run get-pip.py you will install pip for the python install from the system.  Most solutions that use a package manager (homebrew or macport) on OS X create a redundant installation of python in the environment of the package manager which can create inconsistencies in your system since, depending on what you are doing, you may call one installation of python instead of another.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "45", "A_Content": "  NEW 2016 December: This worked for me on OS\u00a0X v10.11 (El Capitan):  Mac comes with python 2, but not with pip.  Requirements  homebrew   Steps:   curl -O https://bootstrap.pypa.io/get-pip.py sudo python get-pip.py   With this I got these errors (but I've solved them in step 3):  The directory '/Users/myuser/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.  The directory '/Users/myuser/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.   pip install --upgrade pip   Finally you can install an app like:   pip install couchapp   UPDATE: Python 3  If you install python 3, pip will be installed automatically.  brew install python3   You need only to upgrade pip, but before that you need create a virtual environment to work with Python 3. You can use a project folder or any folder:  python3 -m venv venv source venv/bin/activate pip install --upgrade pip   Check the versions:  pip -V python --version   To deactivate the environment:  $ deactivate      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "41", "A_Content": "  Installing a separate copy of Python is a popular option, even though Python already comes with MacOS. You take on the responsibility to make sure you're using the copy of Python you intend. But, the benefits are having the latest Python release and some protection from hosing your system if things go badly wrong.  To install Python using HomeBrew:  brew update brew install python # or brew install python3   Now confirm that we're working with our newly installed Python:  ls -lh `which python`   ...should show a symbolic link to a path with \"Cellar\" in it like:  lrwxr-xr-x  1 chris  admin    35B Dec  2 13:40 /usr/local/bin/python -> ../Cellar/python/2.7.8_2/bin/python   Pip should be installed along with Python. You might want to upgrade it by typing:  pip install --upgrade pip   Now you're ready to install any of the 50,000+ packages on PyPI.  Other Notes  Formerly, I've used get-pip.py to install pip. But, the docs warn that get-pip.py does not coordinate with package managers and may leave your system in an inconsistent state. Anyway, there's no need, given that pip is now included with Python as of 2.7.9.  Note that pip isn't the only package manager for Python. There's also easy_install. It's no good to mix the two, so don't do it.  Finally, if you have both Python 2 and 3 installed, pip will point to whichever Python you installed last. Get in the habit of explicitly using either pip2 or pip3, so you're sure which Python is getting the new library.  Happy hacking!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "26", "A_Content": "  For those who have both python2 & python3 installed, here's the solution:  python2.7 -m ensurepip --default-pip   Additionally, if you wanna install pip for python3.6:  wget https://bootstrap.pypa.io/get-pip.py sudo python3.6 get-pip.py      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "23", "A_Content": "  You should install Brew first:  ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"   Then brew install Python  brew install python   Then pip will work     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "15", "A_Content": "  Download this file: get-pip.py  Then simply type  sudo python get-pip.py   Make sure you are on the same directory as get-pip.py or you supply the correct path for that file.  For details, you can visit: http://pip.readthedocs.org/en/latest/installing.html  or, http://thegauraw.tumblr.com/post/47601704154/how-to-install-pip-in-both-windows-ubuntu-easiest-way      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "13", "A_Content": "  $ sudo port install py27-pip   Then update your PATH to include py27-pip bin directory (you can add this in ~/.bash_profile PATH=/opt/local/Library/Frameworks/Python.framework/Versions/2.7/bin:$PATH  pip will be available in new terminal window.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "13", "A_Content": "  On the recent version (from Yosemite or El Capitan I believe... at least from Sierra onward), you need to run brew postinstall python3 after brew install python3 if you use homebrew.   So,  brew install python3 # this only installs python brew postinstall python3 # this installs pip     UPDATED - Homebrew version after 1.5  According to the official Homebrew page:     On 1st March 2018 the python formula will be upgraded to Python 3.x and a python@2 formula will be added for installing Python 2.7 (although this will be keg-only so neither python nor python2 will be added to the PATH by default without a manual brew link --force). We will maintain python2, python3 and python@3 aliases.   So to install Python 3, run the following command:  brew install python3   Then, the pip is installed automatically, and you can install any package by pip install <package>.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "12", "A_Content": "  If you want \"pip3\" you can do the ff:     via brew:   brew install python3     then you can execute  pip3 <command> [options]     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "10", "A_Content": "  To install or upgrade pip, download get-pip.py from http://www.pip-installer.org/en/latest/installing.html  Then run the following: sudo python get-pip.py  For example:  sudo python Desktop/get-pip.py  Password:   Downloading/unpacking pip   Downloading pip-1.5.2-py2.py3-none-any.whl (1.2MB): 1.2MB downloaded Installing collected packages: pip Successfully installed pip Cleaning up...  sudo pip install pymongo Password: Downloading/unpacking pymongo   Downloading pymongo-2.6.3.tar.gz (324kB): 324kB downloaded   Running setup.py (path:/private/var/folders/0c/jb79t3bx7cz6h7p71ydhwb_m0000gn/T/pip_build_goker/pymongo/setup.py) egg_info for package pymongo  Installing collected packages: pymongo ...      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "8", "A_Content": "  Download python setup tools from the below website:  https://pypi.python.org/pypi/setuptools  Use the tar file.  Once you download, go to the downloaded folder and run   python setup.py install   Once you do that,you will have easy_install.  Use the below then to install pip:  sudo easy_install pip      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "6", "A_Content": "  Install python3 first, then use pip3 to install packages.  brew install python   python3 will be installed, and pip is shipped with it. To use pip to install some package, run the following  pip3 install package   Notice it's pip3 because you want to use python3.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "5", "A_Content": "  Somehow easy install doesn't work on my old mac (10.8). This solve my problem.  wget https://bootstrap.pypa.io/get-pip.py sudo python get-pip.py   If you do not have wget, just open in browser https://bootstrap.pypa.io/get-pip.py then save as get-pip.py     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "5", "A_Content": "  Install without the need for sudo  If you want to install pip without the need for sudo, which is always frustrating when trying to install packages globally, install pip in your local folder /usr/local like this:  curl https://bootstrap.pypa.io/get-pip.py > get-pip.py python get-pip.py --prefix=/usr/local/   and then:  pip install <package-of-choice> without sudo     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "Language": "Python", "Q_Title": "How do I install pip on macOS or OS X?", "Q_Votes": "1676", "Q_Content": "    I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.  How do I install it?     ", "Tags": ["python", "macos", "pip", "install"], "A_Votes": "-1", "A_Content": "  I recommend Anaconda to you. It`s the leading open data science platform powered by Python. There are many basic packages installed.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "1593", "A_Content": "  The *args and **kwargs is a common idiom to allow arbitrary number of arguments to functions as described in the section more on defining functions in the Python documentation.  The *args will give you all function parameters as a tuple:  In [1]: def foo(*args):    ...:     for a in args:    ...:         print a    ...:             ...:           In [2]: foo(1) 1   In [4]: foo(1,2,3) 1 2 3   The **kwargs will give you all  keyword arguments except for those corresponding to a formal parameter as a dictionary.  In [5]: def bar(**kwargs):    ...:     for a in kwargs:    ...:         print a, kwargs[a]    ...:             ...:           In [6]: bar(name='one', age=27) age 27 name one   Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:  def foo(kind, *args, **kwargs):    pass   Another usage of the *l idiom is to unpack argument lists when calling a function.  In [9]: def foo(bar, lee):    ...:     print bar, lee    ...:         ...:       In [10]: l = [1,2]  In [11]: foo(*l) 1 2   In Python 3 it is possible to use *l on the left side of an assignment (Extended Iterable Unpacking), though it gives a list instead of a tuple in this context:  first, *rest = [1,2,3,4] first, *l, last = [1,2,3,4]   Also Python 3 adds new semantic (refer PEP 3102):  def func(arg1, arg2, arg3, *, kwarg1, kwarg2):     pass   Such function accepts only 3 positional arguments, and everything after * can only be passed as keyword arguments.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "462", "A_Content": "  It's also worth noting that you can use * and ** when calling functions as well. This is a shortcut that allows you to pass multiple arguments to a function directly using either a list/tuple or a dictionary. For example, if you have the following function:  def foo(x,y,z):     print(\"x=\" + str(x))     print(\"y=\" + str(y))     print(\"z=\" + str(z))   You can do things like:  >>> mylist = [1,2,3] >>> foo(*mylist) x=1 y=2 z=3  >>> mydict = {'x':1,'y':2,'z':3} >>> foo(**mydict) x=1 y=2 z=3  >>> mytuple = (1, 2, 3) >>> foo(*mytuple) x=1 y=2 z=3   Note: The keys in mydict have to be named exactly like the parameters of function foo. Otherwise it will throw a TypeError:  >>> mydict = {'x':1,'y':2,'z':3,'badnews':9} >>> foo(**mydict) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: foo() got an unexpected keyword argument 'badnews'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "132", "A_Content": "  The single * means that there can be any number of extra positional arguments. foo() can be invoked like foo(1,2,3,4,5). In the body of foo() param2 is a sequence containing 2-5.  The double ** means there can be any number of extra named parameters. bar() can be invoked like bar(1, a=2, b=3). In the body of bar() param2 is a dictionary containing {'a':2, 'b':3 }  With the following code:  def foo(param1, *param2):     print param1     print param2  def bar(param1, **param2):     print param1     print param2  foo(1,2,3,4,5) bar(1,a=2,b=3)   the output is  1 (2, 3, 4, 5) 1 {'a': 2, 'b': 3}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "109", "A_Content": "     What does ** (double star) and * (star) do for parameters   They allow for functions to be defined to accept and for users to pass any number of arguments, positional (*) and keyword (**).  Defining Functions  *args allows for any number of optional positional arguments (parameters), which will be assigned to a tuple named args.   **kwargs allows for any number of optional keyword arguments (parameters), which will be in a dict named kwargs.  You can (and should) choose any appropriate name, but if the intention is for the arguments to be of non-specific semantics, args and kwargs are standard names.  Expansion, Passing any number of arguments  You can also use *args and **kwargs to pass in parameters from lists (or any iterable) and dicts (or any mapping), respectively.  The function recieving the parameters does not have to know that they are being expanded.   For example, Python 2's xrange does not explicitly expect *args, but since it takes 3 integers as arguments:  >>> x = xrange(3) # create our *args - an iterable of 3 integers >>> xrange(*x)    # expand here xrange(0, 2, 2)   As another example, we can use dict expansion in str.format:  >>> foo = 'FOO' >>> bar = 'BAR' >>> 'this is foo, {foo} and bar, {bar}'.format(**locals()) 'this is foo, FOO and bar, BAR'   New in Python 3: Defining functions with keyword only arguments  You can have keyword only arguments after the *args - for example, here, kwarg2 must be given as a keyword argument - not positionally:  def foo(arg, kwarg=None, *args, kwarg2=None, **kwargs):      return arg, kwarg, args, kwarg2, kwargs   Usage:  >>> foo(1,2,3,4,5,kwarg2='kwarg2', bar='bar', baz='baz') (1, 2, (3, 4, 5), 'kwarg2', {'bar': 'bar', 'baz': 'baz'})   Also, * can be used by itself  to indicate that keyword only arguments follow, without allowing for unlimited positional arguments.  def foo(arg, kwarg=None, *, kwarg2=None, **kwargs):      return arg, kwarg, kwarg2, kwargs   Here, kwarg2 again must be an explicitly named, keyword argument:  >>> foo(1,2,kwarg2='kwarg2', foo='foo', bar='bar') (1, 2, 'kwarg2', {'foo': 'foo', 'bar': 'bar'})   And we can no longer accept unlimited positional arguments because we don't have *args*:  >>> foo(1,2,3,4,5, kwarg2='kwarg2', foo='foo', bar='bar') Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: foo() takes from 1 to 2 positional arguments      but 5 positional arguments (and 1 keyword-only argument) were given   Again, more simply, here we require kwarg to be given by name, not positionally:  def bar(*, kwarg=None):      return kwarg   In this example, we see that if we try to pass kwarg positionally, we get an error:  >>> bar('kwarg') Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: bar() takes 0 positional arguments but 1 was given   We must explicitly pass the kwarg parameter as a keyword argument.  >>> bar(kwarg='kwarg') 'kwarg'   Python 2 compatible demos  *args (typically said \"star-args\") and **kwargs (stars can be implied by saying \"kwargs\", but be explicit with \"double-star kwargs\") are common idioms of Python for using the * and ** notation. These specific variable names aren't required (e.g. you could use *foos and **bars), but a departure from convention is likely to enrage your fellow Python coders.   We typically use these when we don't know what our function is going to receive or how many arguments we may be passing, and sometimes even when naming every variable separately would get very messy and redundant (but this is a case where usually explicit is better than implicit).  Example 1  The following function describes how they can be used, and demonstrates behavior. Note the named b argument will be consumed by the second positional argument before :  def foo(a, b=10, *args, **kwargs):     '''     this function takes required argument a, not required keyword argument b     and any number of unknown positional arguments and keyword arguments after     '''     print('a is a required argument, and its value is {0}'.format(a))     print('b not required, its default value is 10, actual value: {0}'.format(b))     # we can inspect the unknown arguments we were passed:     #  - args:     print('args is of type {0} and length {1}'.format(type(args), len(args)))     for arg in args:         print('unknown arg: {0}'.format(arg))     #  - kwargs:     print('kwargs is of type {0} and length {1}'.format(type(kwargs),                                                         len(kwargs)))     for kw, arg in kwargs.items():         print('unknown kwarg - kw: {0}, arg: {1}'.format(kw, arg))     # But we don't have to know anything about them      # to pass them to other functions.     print('Args or kwargs can be passed without knowing what they are.')     # max can take two or more positional args: max(a, b, c...)     print('e.g. max(a, b, *args) \\n{0}'.format(       max(a, b, *args)))      kweg = 'dict({0})'.format( # named args same as unknown kwargs       ', '.join('{k}={v}'.format(k=k, v=v)                               for k, v in sorted(kwargs.items())))     print('e.g. dict(**kwargs) (same as {kweg}) returns: \\n{0}'.format(       dict(**kwargs), kweg=kweg))   We can check the online help for the function's signature, with help(foo), which tells us   foo(a, b=10, *args, **kwargs)   Let's call this function with foo(1, 2, 3, 4, e=5, f=6, g=7)   which prints:  a is a required argument, and its value is 1 b not required, its default value is 10, actual value: 2 args is of type <type 'tuple'> and length 2 unknown arg: 3 unknown arg: 4 kwargs is of type <type 'dict'> and length 3 unknown kwarg - kw: e, arg: 5 unknown kwarg - kw: g, arg: 7 unknown kwarg - kw: f, arg: 6 Args or kwargs can be passed without knowing what they are. e.g. max(a, b, *args)  4 e.g. dict(**kwargs) (same as dict(e=5, f=6, g=7)) returns:  {'e': 5, 'g': 7, 'f': 6}   Example 2  We can also call it using another function, into which we just provide a:  def bar(a):     b, c, d, e, f = 2, 3, 4, 5, 6     # dumping every local variable into foo as a keyword argument      # by expanding the locals dict:     foo(**locals())    bar(100) prints:  a is a required argument, and its value is 100 b not required, its default value is 10, actual value: 2 args is of type <type 'tuple'> and length 0 kwargs is of type <type 'dict'> and length 4 unknown kwarg - kw: c, arg: 3 unknown kwarg - kw: e, arg: 5 unknown kwarg - kw: d, arg: 4 unknown kwarg - kw: f, arg: 6 Args or kwargs can be passed without knowing what they are. e.g. max(a, b, *args)  100 e.g. dict(**kwargs) (same as dict(c=3, d=4, e=5, f=6)) returns:  {'c': 3, 'e': 5, 'd': 4, 'f': 6}   Example 3: practical usage in decorators  OK, so maybe we're not seeing the utility yet. So imagine you have several functions with redundant code before and/or after the differentiating code. The following named functions are just pseudo-code for illustrative purposes.  def foo(a, b, c, d=0, e=100):     # imagine this is much more code than a simple function call     preprocess()      differentiating_process_foo(a,b,c,d,e)     # imagine this is much more code than a simple function call     postprocess()  def bar(a, b, c=None, d=0, e=100, f=None):     preprocess()     differentiating_process_bar(a,b,c,d,e,f)     postprocess()  def baz(a, b, c, d, e, f):     ... and so on   We might be able to handle this differently, but we can certainly extract the redundancy with a decorator, and so our below example demonstrates how *args and **kwargs can be very useful:  def decorator(function):     '''function to wrap other functions with a pre- and postprocess'''     @functools.wraps(function) # applies module, name, and docstring to wrapper     def wrapper(*args, **kwargs):         # again, imagine this is complicated, but we only write it once!         preprocess()         function(*args, **kwargs)         postprocess()     return wrapper   And now every wrapped function can be written much more succinctly, as we've factored out the redundancy:  @decorator def foo(a, b, c, d=0, e=100):     differentiating_process_foo(a,b,c,d,e)  @decorator def bar(a, b, c=None, d=0, e=100, f=None):     differentiating_process_bar(a,b,c,d,e,f)  @decorator def baz(a, b, c=None, d=0, e=100, f=None, g=None):     differentiating_process_baz(a,b,c,d,e,f, g)  @decorator def quux(a, b, c=None, d=0, e=100, f=None, g=None, h=None):     differentiating_process_quux(a,b,c,d,e,f,g,h)   And by factoring out our code, which *args and **kwargs allows us to do, we reduce lines of code, improve readability and maintainability, and have sole canonical locations for the logic in our program. If we need to change any part of this structure, we have one place in which to make each change.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "38", "A_Content": "  Let us first understand what are positional arguments and keyword arguments. Below is an example of function definition with Positional arguments.  def test(a,b,c):      print(a)      print(b)      print(c)  test(1,2,3) #output: 1 2 3   So this is a function definition with positional arguments. You can call it with keyword/named arguments as well:  def test(a,b,c):      print(a)      print(b)      print(c)  test(a=1,b=2,c=3) #output: 1 2 3   Now let us study an example of function definition with keyword arguments:  def test(a=0,b=0,c=0):      print(a)      print(b)      print(c)      print('-------------------------')  test(a=1,b=2,c=3) #output : 1 2 3 -------------------------   You can call this function with positional arguments as well:  def test(a=0,b=0,c=0):     print(a)     print(b)     print(c)     print('-------------------------')  test(1,2,3) # output : 1 2 3 ---------------------------------   So we now know function definitions with positional as well as keyword arguments.  Now let us study the '*' operator and '**' operator.  Please note these operators can be used in 2 areas:  a) function call  b) function definition  The use of '*' operator and '**' operator in function call.   Let us get straight to an example and then discuss it.  def sum(a,b):  #receive args from function calls as sum(1,2) or sum(a=1,b=2)     print(a+b)  my_tuple = (1,2) my_list = [1,2] my_dict = {'a':1,'b':2}  # Let us unpack data structure of list or tuple or dict into arguments with help of '*' operator sum(*my_tuple)   # becomes same as sum(1,2) after unpacking my_tuple with '*' sum(*my_list)    # becomes same as sum(1,2) after unpacking my_list with  '*' sum(**my_dict)   # becomes same as sum(a=1,b=2) after unpacking by '**'   # output is 3 in all three calls to sum function.   So remember   when the '*' or '**' operator is used in a function call -  '*' operator unpacks data structure such as a list or tuple  into arguments needed by function definition.  '**' operator unpacks a dictionary into arguments needed by function definition.  Now let us study the '*' operator use in function definition. Example:  def sum(*args): #pack the received positional args into data structure of tuple. after applying '*' - def sum((1,2,3,4))     sum = 0     for a in args:         sum+=a     print(sum)  sum(1,2,3,4)  #positional args sent to function sum #output: 10   In function definition the '*' operator packs the received arguments into a tuple.  Now let us see an example of '**' used in function definition:  def sum(**args): #pack keyword args into datastructure of dict after applying '**' - def sum({a:1,b:2,c:3,d:4})     sum=0     for k,v in args.items():         sum+=v     print(sum)  sum(a=1,b=2,c=3,d=4) #positional args sent to function sum   In function definition The '**' operator packs the received arguments into a dictionary.  So remember:  In a function call the '*' unpacks data structure of tuple or list into positional or keyword arguments to be received by function definition.  In a function call the '**' unpacks data structure of dictionary into positional or keyword arguments to be received by function definition.  In a function definition the '*' packs positional arguments into a tuple.  In a function definition the '**' packs keyword arguments into a dictionary.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "20", "A_Content": "  * and ** have special usage in the function argument list. * implies that the argument is a list and ** implies that the argument is a dictionary. This allows functions to take arbitrary number of arguments     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "11", "A_Content": "  From the Python documentation:     If there are more positional arguments than there are formal parameter slots, a TypeError exception is raised, unless a formal parameter using the syntax \"*identifier\" is present; in this case, that formal parameter receives a tuple containing the excess positional arguments (or an empty tuple if there were no excess positional arguments).       If any keyword argument does not correspond to a formal parameter name, a TypeError exception is raised, unless a formal parameter using the syntax \"**identifier\" is present; in this case, that formal parameter receives a dictionary containing the excess keyword arguments (using the keywords as keys and the argument values as corresponding values), or a (new) empty dictionary if there were no excess keyword arguments.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "7", "A_Content": "  I want to give an example which others haven't  mentioned  * can also unpack a generator  An example from Python3 Document  x = [1, 2, 3] y = [4, 5, 6]  unzip_x, unzip_y = zip(*zip(x, y))   unzip_x will be [1, 2, 3], unzip_y will be [4, 5, 6]  The zip() receives multiple iretable args, and return a generator.   zip(*zip(x,y)) -> zip((1, 4), (2, 5), (3, 6))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "7", "A_Content": "  While uses for the star/splat operators have been expanded in Python 3, I like the following table as it relates to use of these operators with functions.  The splat operator(s) can be used both within function construction and in the function call:              In function *construction*      In function *call* =======================================================================           |  def f(*args):                 |  def f(a, b): *args     |      for arg in args:          |      return a + b           |          print(arg)            |  args = (1, 2)           |  f(1, 2)                       |  f(*args) ----------|--------------------------------|---------------------------           |  def f(a, b):                  |  def f(a, b): **kwargs  |      return a + b              |      return a + b           |  def g(**kwargs):              |  kwargs = dict(a=1, b=2)           |      return f(**kwargs)        |  f(**kwargs)           |  g(a=1, b=2)                   | -----------------------------------------------------------------------   This really just serves to summarize Lorin Hochstein's answer but I find it helpful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "6", "A_Content": "  In Python 3.5, you can also use this syntax in list, dict, tuple, and set displays (also sometimes called literals). See PEP 488: Additional Unpacking Generalizations.  >>> (0, *range(1, 4), 5, *range(6, 8)) (0, 1, 2, 3, 5, 6, 7) >>> [0, *range(1, 4), 5, *range(6, 8)] [0, 1, 2, 3, 5, 6, 7] >>> {0, *range(1, 4), 5, *range(6, 8)} {0, 1, 2, 3, 5, 6, 7} >>> d = {'one': 1, 'two': 2, 'three': 3} >>> e = {'six': 6, 'seven': 7} >>> {'zero': 0, **d, 'five': 5, **e} {'five': 5, 'seven': 7, 'two': 2, 'one': 1, 'three': 3, 'six': 6, 'zero': 0}   It also allows multiple iterables to be unpacked in a single function call.  >>> range(*[1, 10], *[2]) range(1, 10, 2)   (Thanks to mgilson for the PEP link.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "5", "A_Content": "  For those of you who learn by examples!   The purpose of *  is to give you the ability to define a function that can take an arbitrary number of arguments provided as a list (e.g. f(*myList) ). The purpose of ** is to give you the ability to feed a function's arguments by providing a dictionary (e.g. f(**{'x' : 1, 'y' : 2}) ).   Let us show this by defining a function that takes two normal variables x, y, and can accept more arguments as myArgs, and can accept even more arguments as myKW. Later, we will show how to feed y using myArgDict.  def f(x, y, *myArgs, **myKW):     print(\"# x      = {}\".format(x))     print(\"# y      = {}\".format(y))     print(\"# myArgs = {}\".format(myArgs))     print(\"# myKW   = {}\".format(myKW))     print(\"# ----------------------------------------------------------------------\")  # Define a list for demonstration purposes myList    = [\"Left\", \"Right\", \"Up\", \"Down\"] # Define a dictionary for demonstration purposes myDict    = {\"Wubba\": \"lubba\", \"Dub\": \"dub\"} # Define a dictionary to feed y myArgDict = {'y': \"Why?\", 'y0': \"Why not?\", \"q\": \"Here is a cue!\"}  # The 1st elem of myList feeds y f(\"myEx\", *myList, **myDict) # x      = myEx # y      = Left # myArgs = ('Right', 'Up', 'Down') # myKW   = {'Wubba': 'lubba', 'Dub': 'dub'} # ----------------------------------------------------------------------  # y is matched and fed first # The rest of myArgDict becomes additional arguments feeding myKW f(\"myEx\", **myArgDict) # x      = myEx # y      = Why? # myArgs = () # myKW   = {'y0': 'Why not?', 'q': 'Here is a cue!'} # ----------------------------------------------------------------------  # The rest of myArgDict becomes additional arguments feeding myArgs f(\"myEx\", *myArgDict) # x      = myEx # y      = y # myArgs = ('y0', 'q') # myKW   = {} # ----------------------------------------------------------------------  # Feed extra arguments manually and append even more from my list f(\"myEx\", 4, 42, 420, *myList, *myDict, **myDict) # x      = myEx # y      = 4 # myArgs = (42, 420, 'Left', 'Right', 'Up', 'Down', 'Wubba', 'Dub') # myKW   = {'Wubba': 'lubba', 'Dub': 'dub'} # ----------------------------------------------------------------------  # Without the stars, the entire provided list and dict become x, and y: f(myList, myDict) # x      = ['Left', 'Right', 'Up', 'Down'] # y      = {'Wubba': 'lubba', 'Dub': 'dub'} # myArgs = () # myKW   = {} # ----------------------------------------------------------------------   Caveats   ** is exclusively reserved for dictionaries. Non-optional argument assignment happens first. You cannot use a non-optional argument twice. If applicable, ** must come after *, always.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "4", "A_Content": "  In addition to function calls, *args and **kwargs are useful in class hierarchies and also avoid having to write __init__ method in Python. Similar usage can seen in frameworks like Django code.  For example,  def __init__(self, *args, **kwargs):     for attribute_name, value in zip(self._expected_attributes, args):         setattr(self, attribute_name, value)         if kwargs.has_key(attribute_name):             kwargs.pop(attribute_name)      for attribute_name in kwargs.viewkeys():         setattr(self, attribute_name, kwargs[attribute_name])   A subclass can then be  class RetailItem(Item):     _expected_attributes = Item._expected_attributes + ['name', 'price', 'category', 'country_of_origin']  class FoodItem(RetailItem):     _expected_attributes = RetailItem._expected_attributes +  ['expiry_date']   The subclass then be instantiated as   food_item = FoodItem(name = 'Jam',                       price = 12.0,                       category = 'Foods',                       country_of_origin = 'US',                       expiry_date = datetime.datetime.now())   Also, a subclass with a new attribute which makes sense only to that subclass instance can call the Base class __init__ to offload the attributes setting. This is done through *args and **kwargs. kwargs mainly used so that code is readable using named arguments. For example,  class ElectronicAccessories(RetailItem):     _expected_attributes = RetailItem._expected_attributes +  ['specifications']     # Depend on args and kwargs to populate the data as needed.     def __init__(self, specifications = None, *args, **kwargs):         self.specifications = specifications  # Rest of attributes will make sense to parent class.         super(ElectronicAccessories, self).__init__(*args, **kwargs)   which can be instatiated as  usb_key = ElectronicAccessories(name = 'Sandisk',                                  price = '$6.00',                                  category = 'Electronics',                                 country_of_origin = 'CN',                                 specifications = '4GB USB 2.0/USB 3.0')   The complete code is here     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "1", "A_Content": "  A good example of using both in a function is:  >>> def foo(*arg,**kwargs): ...     print arg ...     print kwargs >>> >>> a = (1, 2, 3) >>> b = {'aa': 11, 'bb': 22} >>> >>> >>> foo(*a,**b) (1, 2, 3) {'aa': 11, 'bb': 22} >>> >>> >>> foo(a,**b)  ((1, 2, 3),) {'aa': 11, 'bb': 22} >>> >>> >>> foo(a,b)  ((1, 2, 3), {'aa': 11, 'bb': 22}) {} >>> >>> >>> foo(a,*b) ((1, 2, 3), 'aa', 'bb') {}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "2763", "A_Content": "  You can use the + operator to combine them:  listone = [1,2,3] listtwo = [4,5,6]  mergedlist = listone + listtwo   Output:  >>> mergedlist [1,2,3,4,5,6]      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "1", "A_Content": "  This example would help you remember *args, **kwargs and even super and inheritance in Python at once.  class base(object):     def __init__(self, base_param):         self.base_param = base_param   class child1(base): # inherited from base class     def __init__(self, child_param, *args) # *args for non-keyword args         self.child_param = child_param         super(child1, self).__init__(*args) # call __init__ of the base class and initialize it with a NON-KEYWORD arg  class child2(base):     def __init__(self, child_param, **kwargs):         self.child_param = child_param         super(child2, self).__init__(**kwargs) # call __init__ of the base class and initialize it with a KEYWORD arg  c1 = child1(1,0) c2 = child2(1,base_param=0) print c1.base_param # 0 print c1.child_param # 1 print c2.base_param # 0 print c2.child_param # 1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "0", "A_Content": "  *args and **kwargs: allow you to pass a variable number of arguments to a function.   *args: is used to send a non-keyworded variable length argument list to the function:  def args(normal_arg, *argv):     print (\"normal argument:\",normal_arg)      for arg in argv:         print(\"Argument in list of arguments from *argv:\", arg)  args('animals','fish','duck','bird')   Will produce:  normal argument: animals Argument in list of arguments from *argv: fish Argument in list of arguments from *argv: duck Argument in list of arguments from *argv: bird   **kwargs*  **kwargs allows you to pass keyworded variable length of arguments to a function. You should use **kwargs if you want to handle named arguments in a function.   def who(**kwargs):     if kwargs is not None:         for key, value in kwargs.items():             print (\"Your %s is %s.\" %(key,value))  who (name=\"Nikola\", last_name=\"Tesla\", birthday = \"7.10.1856\", birthplace = \"Croatia\")     Will produce:  Your name is Nikola. Your last_name is Tesla. Your birthday is 7.10.1856. Your birthplace is Croatia.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "0", "A_Content": "  * means receive variable arguments as list  ** means receive variable arguments as dictionary  Used like the following:  1) single *  def foo(*args):     for arg in args:         print(arg)  foo(\"two\", 3)   Output:  two 3   2) Now **  def bar(**kwargs):     for key in kwargs:         print(key, kwargs[key])  bar(dic1=\"two\", dic2=3)   Output:  dic1 two dic2 3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "0", "A_Content": "   def foo(param1, *param2): is a method can accept arbitrary number of values for *param2, def bar(param1, **param2): is a method can accept arbitrary number of values with keys for *param2 param1 is a simple parameter.   For example, the syntax for implementing varargs in Java as follows:  accessModifier methodName(datatype\u2026 arg) {     // method body }      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "Language": "Python", "Q_Title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "Q_Votes": "1620", "Q_Content": "    In the following method definitions, what does the * and ** do for param2?  def foo(param1, *param2): def bar(param1, **param2):      ", "Tags": ["python", "syntax", "parameter-passing", "identifier", "kwargs"], "A_Votes": "-1", "A_Content": "  *args = *aList = all elements in a List  **args= ** aDict =all items in a dict     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "218", "A_Content": "  It's also possible to create a generator that simply iterates over the items in both lists.  This allows you to chain lists (or any iterable) together for processing without copying the items to a new list:  import itertools for item in itertools.chain(listone, listtwo):    # do something with each list item      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "151", "A_Content": "  You can use sets to obtain merged list of unique values  mergedlist = list(set(listone + listtwo))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "107", "A_Content": "  You could also use extend in order to add a list add the end of another one:  listone = [1,2,3] listtwo = [4,5,6] mergedlist = [] mergedlist.extend(listone) mergedlist.extend(listtwo)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "103", "A_Content": "  Python >= 3.5 alternative: [*l1, *l2]  Even though this is an old answer, another alternative has been introduced via the acceptance of PEP 448 which deserves mentioning.   The PEP, titled Additional Unpacking Generalizations, generally reduced some syntactic restrictions when using the starred * expression in Python; with it, joining two lists (applies to any iterable) can now also be done with:  >>> l1 = [1, 2, 3] >>> l2 = [4, 5, 6]  #unpack both iterables in a list literal >>> joinedList = [*l1, *l2] >>> print(joinedList) [1, 2, 3, 4, 5, 6]   This functionality was defined for Python 3.5 it hasn't been backported to previous versions in the 3.x family. In unsupported versions a SyntaxError is going to be raised.  As with the other approaches, this too creates as shallow copy of the elements in the corresponding lists.    The upside to this approach is that you really don't need lists in order to perform it, anything that is iterable will do. As stated in the PEP:     This is also useful as a more readable way of summing iterables into a   list, such as my_list + list(my_tuple) + list(my_range) which is now   equivalent to just [*my_list, *my_tuple, *my_range].   So while addition with + would raise a TypeError due to type mismatch:  l = [1, 2, 3] r = range(4, 7) res = l + r   The following won't:  res = [*l, *r]   because it will first unpack the contents of the iterables and then simply create a list from the contents.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "58", "A_Content": "  This is quite simple, I think it was even shown in the tutorial:  >>> listone = [1,2,3] >>> listtwo = [4,5,6] >>> >>> listone + listtwo [1, 2, 3, 4, 5, 6]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "33", "A_Content": "  You could simply use the + or += operator as follows:  a = [1, 2, 3] b = [4, 5, 6]  c = a + b   Or:  c = [] a = [1, 2, 3] b = [4, 5, 6]  c += (a + b)   Also, if you want the values in the merged list to be unique you can do:  c = list(set(a + b))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "29", "A_Content": "  This question directly asks about joining two lists. However it's pretty high in search even when you are looking for a way of joining many lists (including the case when you joining zero lists).  I think the best option is to use list comprehensions:  >>> a = [[1,2,3], [4,5,6], [7,8,9]] >>> [x for xs in a for x in xs] [1, 2, 3, 4, 5, 6, 7, 8, 9]   You can create generators as well:  >>> map(str, (x for xs in a for x in xs)) ['1', '2', '3', '4', '5', '6', '7', '8', '9']   Old Answer  Consider this more generic approach:  a = [[1,2,3], [4,5,6], [7,8,9]] reduce(lambda c, x: c + x, a, [])   Will output:  [1, 2, 3, 4, 5, 6, 7, 8, 9]   Note, this also works correctly when a is [] or [[1,2,3]].  However, this can be done more efficiently with itertools:  a = [[1,2,3], [4,5,6], [7,8,9]] list(itertools.chain(*a))   If you don't need a list, but just an iterable, omit list().  Update  Alternative suggested by Patrick Collins in the comments could also work for you:  sum(a, [])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "20", "A_Content": "  It's worth noting that the itertools.chain function accepts variable number of arguments:  >>> l1 = ['a']; l2 = ['b', 'c']; l3 = ['d', 'e', 'f'] >>> [i for i in itertools.chain(l1, l2)] ['a', 'b', 'c'] >>> [i for i in itertools.chain(l1, l2, l3)] ['a', 'b', 'c', 'd', 'e', 'f']   If an iterable (tuple, list, generator, etc.) is the input, the from_iterable class method may be used:  >>> il = [['a'], ['b', 'c'], ['d', 'e', 'f']] >>> [i for i in itertools.chain.from_iterable(il)] ['a', 'b', 'c', 'd', 'e', 'f']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "19", "A_Content": "  With Python 3.3+ you can use yield from:  listone = [1,2,3] listtwo = [4,5,6]  def merge(l1, l2):     yield from l1     yield from l2  >>> list(merge(listone, listtwo)) [1, 2, 3, 4, 5, 6]   Or, if you want to support an arbitrary number of iterators:  def merge(*iters):     for it in iters:         yield from it  >>> list(merge(listone, listtwo, 'abcd', [20, 21, 22])) [1, 2, 3, 4, 5, 6, 'a', 'b', 'c', 'd', 20, 21, 22]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "15", "A_Content": "  You can go for list.extend function.  l1 = [1,2,3] l2 = [4,5,6] l1.extend(l2) print l1   Output:   [1,2,3,4,5,6]     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "14", "A_Content": "  If you want to merge the two lists in sorted form, you can use merge function from the heapq library.  from heapq import merge  a = [1,2,4] b = [2,4,6,7]  print list(merge(a,b))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "11", "A_Content": "  If you can't use the plus operator (+), you can uses the  __add__ function:  listone = [1,2,3] listtwo = [4,5,6]  result = list.__add__(listone, listtwo) print(result)  >>> [1, 2, 3, 4, 5, 6]   Alternatively, if you don't like the use of dunders you can use the operator import:  import operator  listone = [1,2,3] listtwo = [4,5,6]  result = operator.add(listone, listtwo) print(result)  >>> [1, 2, 3, 4, 5, 6]   One could argue this is a bit more readable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "8", "A_Content": "  As a more general way for more lists you can put them within a list and use itertools.chain.from_iterable()1 function which based on THIS answer is the best way for flatting a nested list :  >>> l=[[1, 2, 3], [4, 5, 6], [7, 8, 9]] >>> import itertools >>> list(itertools.chain.from_iterable(l)) [1, 2, 3, 4, 5, 6, 7, 8, 9]       1. Note that chain.from_iterable() is available in python =>2.6.In other versions use chain(*l)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "2176", "A_Content": "  Here's a generator that yields the chunks you want:  def chunks(l, n):     \"\"\"Yield successive n-sized chunks from l.\"\"\"     for i in range(0, len(l), n):         yield l[i:i + n]     import pprint pprint.pprint(list(chunks(range(10, 75), 10))) [[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],  [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],  [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],  [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],  [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],  [70, 71, 72, 73, 74]]     If you're using Python 2, you should use xrange() instead of range():  def chunks(l, n):     \"\"\"Yield successive n-sized chunks from l.\"\"\"     for i in xrange(0, len(l), n):         yield l[i:i + n]     Also you can simply use list comprehension instead of writing a function. Python 3:  [l[i:i + n] for i in range(0, len(l), n)]   Python 2 version:  [l[i:i + n] for i in xrange(0, len(l), n)]      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "2391", "A_Content": "  With new_list = my_list, you don't actually have two lists. The assignment just copies the reference to the list, not the actual list, so both new_list and my_list refer to the same list after the assignment.  To actually copy the list, you have various possibilities:   You can use the builtin list.copy() method (available since python 3.3):  new_list = old_list.copy()  You can slice it:   new_list = old_list[:]   Alex Martelli's opinion (at least back in 2007) about this is, that it is a weird syntax and it does not make sense to use it ever. ;) (In his opinion, the next one is more readable). You can use the built in list() function:  new_list = list(old_list)  You can use generic copy.copy():  import copy new_list = copy.copy(old_list)   This is a little slower than list() because it has to find out the datatype of old_list first. If the list contains objects and you want to copy them as well, use generic copy.deepcopy():  import copy new_list = copy.deepcopy(old_list)   Obviously the slowest and most memory-needing method, but sometimes unavoidable.   Example:  import copy  class Foo(object):     def __init__(self, val):          self.val = val      def __repr__(self):         return str(self.val)  foo = Foo(1)  a = ['foo', foo] b = a.copy() c = a[:] d = list(a) e = copy.copy(a) f = copy.deepcopy(a)  # edit orignal list and instance  a.append('baz') foo.val = 5  print('original: %r\\n list.copy(): %r\\n slice: %r\\n list(): %r\\n copy: %r\\n deepcopy: %r'       % (a, b, c, d, e, f))   Result:  original: ['foo', 5, 'baz'] list.copy(): ['foo', 5] slice: ['foo', 5] list(): ['foo', 5] copy: ['foo', 5] deepcopy: ['foo', 1]      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "8", "A_Content": "  Joining two lists in Python:  >>> a = [1, 2, 3, 4] >>> b = [1, 4, 6, 7] >>> c = a + b >>> c [1, 2, 3, 4, 1, 4, 6, 7]   If you don't want any duplication:  >>> a = [1, 2, 3, 4, 5, 6] >>> b = [5, 6, 7, 8] >>> c = list(set(a + b)) >>> c [1, 2, 3, 4, 5, 6, 7, 8]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "6", "A_Content": "  If you need to merge two ordered lists with complicated sorting rules, you might have to roll it yourself like in the following code (using a simple sorting rule for readability :-) ).  list1 = [1,2,5] list2 = [2,3,4] newlist = []  while list1 and list2:     if list1[0] == list2[0]:         newlist.append(list1.pop(0))         list2.pop(0)     elif list1[0] < list2[0]:         newlist.append(list1.pop(0))     else:         newlist.append(list2.pop(0))  if list1:     newlist.extend(list1) if list2:     newlist.extend(list2)  assert(newlist == [1, 2, 3, 4, 5])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "6", "A_Content": "  As already pointed out by many, itertools.chain() is the way to go if one needs to apply exactly the same treatment to both lists. In my case, I had a label and a flag which were different from one list to the other, so I needed something slightly more complex. As it turns out, behind the scenes itertools.chain() simply does the following:  for it in iterables:     for element in it:         yield element   (see https://docs.python.org/2/library/itertools.html), so I took inspiration from here and wrote something along these lines:  for iterable, header, flag in ( (newList, 'New', ''), (modList, 'Modified', '-f')):     print header + ':'     for path in iterable:         [...]         command = 'cp -r' if os.path.isdir(srcPath) else 'cp'         print >> SCRIPT , command, flag, srcPath, mergedDirPath         [...]   The main points to understand here are that lists are just a special case of iterable, which are objects like any other; and that for ... in loops in python can work with tuple variables, so it is simple to loop on multiple variables at the same time.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "6", "A_Content": "  list(set(listone) | set(listtwo))   The above code, does not preserve order, removes duplicate from each list (but not from the concatenated list)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "5", "A_Content": "  You could use the append() method defined on list objects:   mergedlist =[] for elem in listone:     mergedlist.append(elem) for elem in listtwo:     mergedlist.append(elem)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "4", "A_Content": "  A really concise way to combine a list of lists is  list_of_lists = [[1,2,3], [4,5,6], [7,8,9]] reduce(list.__add__, list_of_lists)   which gives us  [1, 2, 3, 4, 5, 6, 7, 8, 9]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "2", "A_Content": "  lst1 = [1,2]  lst2 = [3,4]  def list_combinationer(Bushisms, are_funny):      for item in lst1:         lst2.append(item)         lst1n2 = sorted(lst2)         print lst1n2  list_combinationer(lst1, lst2)  [1,2,3,4]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "2", "A_Content": "  You can use extends function   listone.extends(listtwo)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  import itertools  A = list(zip([1,3,5,7,9],[2,4,6,8,10])) B = [1,3,5,7,9]+[2,4,6,8,10] C = list(set([1,3,5,7,9] + [2,4,6,8,10]))  D = [1,3,5,7,9] D.append([2,4,6,8,10])  E = [1,3,5,7,9] E.extend([2,4,6,8,10])  F = [] for a in itertools.chain([1,3,5,7,9], [2,4,6,8,10]):     F.append(a)   print (\"A: \" + str(A)) print (\"B: \" + str(B)) print (\"C: \" + str(C)) print (\"D: \" + str(D)) print (\"E: \" + str(E)) print (\"F: \" + str(F))   Output:  A: [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)] B: [1, 3, 5, 7, 9, 2, 4, 6, 8, 10] C: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] D: [1, 3, 5, 7, 9, [2, 4, 6, 8, 10]] E: [1, 3, 5, 7, 9, 2, 4, 6, 8, 10] F: [1, 3, 5, 7, 9, 2, 4, 6, 8, 10]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  I'm surprised it seems nobody proposed using a simple list comprehension:  joined_list = [y for x in [list_one, list_two] for y in x]   It has all the advantages of the newest approach of using Additional Unpacking Generalizations - i.e. you can concatenate an arbitrary number of different iterables (e.g. lists, tuples, ranges, generators) that way - and it's not limited to Python >= 3.5.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  a = [1,2,3,4,5,6] b = [7,8,9,10] c = a.extend(b)   print(c) gives  [1,2,3,4,5,6,7,8,9,10]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "0", "A_Content": "  If you wanted a new list whilst keeping the two old lists:  def concatenate_list(listOne, listTwo):     joinedList = []     for i in listOne:         joinedList.append(i)     for j in listTwo:         joinedList.append(j)      sorted(joinedList)      return joinedList      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "0", "A_Content": "  In Python you can concatenate two arrays of compatible dimensions with this command numpy.concatenate([a,b])     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1720421/how-to-concatenate-two-lists-in-python", "Language": "Python", "Q_Title": "How to concatenate two lists in Python?", "Q_Votes": "1690", "Q_Content": "    How do I concatenate two lists in Python?  Example:  listone = [1, 2, 3] listtwo = [4, 5, 6]   Expected outcome:  >>> joinedlist [1, 2, 3, 4, 5, 6]      ", "Tags": ["python", "list"], "A_Votes": "0", "A_Content": "  So there are two easy ways.    Using + : It creates a new list from provided lists    Example :   In [1]: a = [1, 2, 3]  In [2]: b = [4, 5, 6]  In [3]: a + b Out[3]: [1, 2, 3, 4, 5, 6]  In [4]: %timeit a + b 10000000 loops, best of 3: 126 ns per loop    Using extend : It appends new list to existing list. That means it does not create a separate list.    Example :   In [1]: a = [1, 2, 3]  In [2]: b = [4, 5, 6]  In [3]: %timeit a.extend(b) 10000000 loops, best of 3: 91.1 ns per loop   Thus we see that out of two of most popular methods, extend is efficient.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "484", "A_Content": "  If you want something super simple:  def chunks(l, n):     n = max(1, n)     return (l[i:i+n] for i in xrange(0, len(l), n))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "253", "A_Content": "  Directly from the (old) Python documentation (recipes for itertools):  from itertools import izip, chain, repeat  def grouper(n, iterable, padvalue=None):     \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"     return izip(*[chain(iterable, repeat(padvalue, n-1))]*n)   The current version, as suggested by J.F.Sebastian:  #from itertools import izip_longest as zip_longest # for Python 2.x from itertools import zip_longest # for Python 3.x #from six.moves import zip_longest # for both (uses the six compat library)  def grouper(n, iterable, padvalue=None):     \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"     return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)   I guess Guido's time machine works\u2014worked\u2014will work\u2014will have worked\u2014was working again.  These solutions work because [iter(iterable)]*n (or the equivalent in the earlier version) creates one iterator, repeated n times in the list. izip_longest then effectively performs a round-robin of \"each\" iterator; because this is the same iterator, it is advanced by each such call, resulting in each such zip-roundrobin generating one tuple of n items.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "104", "A_Content": "  I know this is kind of old but I don't why nobody mentioned numpy.array_split:  lst = range(50) In [26]: np.array_split(lst,5) Out[26]:  [array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),  array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),  array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),  array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]),  array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "80", "A_Content": "  Here is a generator that work on arbitrary iterables:  def split_seq(iterable, size):     it = iter(iterable)     item = list(itertools.islice(it, size))     while item:         yield item         item = list(itertools.islice(it, size))   Example:  >>> import pprint >>> pprint.pprint(list(split_seq(xrange(75), 10))) [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],  [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],  [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],  [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],  [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],  [70, 71, 72, 73, 74]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "67", "A_Content": "  I'm surprised nobody has thought of using iter's two-argument form:  from itertools import islice  def chunk(it, size):     it = iter(it)     return iter(lambda: tuple(islice(it, size)), ())   Demo:  >>> list(chunk(range(14), 3)) [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13)]   This works with any iterable and produces output lazily. It returns tuples rather than iterators, but I think it has a certain elegance nonetheless. It also doesn't pad; if you want padding, a simple variation on the above will suffice:  from itertools import islice, chain, repeat  def chunk_pad(it, size, padval=None):     it = chain(iter(it), repeat(padval))     return iter(lambda: tuple(islice(it, size)), (padval,) * size)   Demo:  >>> list(chunk_pad(range(14), 3)) [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, None)] >>> list(chunk_pad(range(14), 3, 'a')) [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, 'a')]   Like the izip_longest-based solutions, the above always pads. As far as I know, there's no one- or two-line itertools recipe for a function that optionally pads. By combining the above two approaches, this one comes pretty close:  _no_padding = object()  def chunk(it, size, padval=_no_padding):     if padval == _no_padding:         it = iter(it)         sentinel = ()     else:         it = chain(iter(it), repeat(padval))         sentinel = (padval,) * size     return iter(lambda: tuple(islice(it, size)), sentinel)   Demo:  >>> list(chunk(range(14), 3)) [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13)] >>> list(chunk(range(14), 3, None)) [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, None)] >>> list(chunk(range(14), 3, 'a')) [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, 'a')]   I believe this is the shortest chunker proposed that offers optional padding.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "47", "A_Content": "  def chunk(input, size):     return map(None, *([iter(input)] * size))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "39", "A_Content": "  Simple yet elegant  l = range(1, 1000) print [l[x:x+10] for x in xrange(0, len(l), 10)]   or if you prefer:  chunks = lambda l, n: [l[x: x+n] for x in xrange(0, len(l), n)] chunks(l, 10)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "28", "A_Content": "  Critique of other answers here:  None of these answers are evenly sized chunks, they all leave a runt chunk at the end, so they're not completely balanced. If you were using these functions to distribute work, you've built-in the prospect of one likely finishing well before the others, so it would sit around doing nothing while the others continued working hard.  For example, the current top answer ends with:  [60, 61, 62, 63, 64, 65, 66, 67, 68, 69], [70, 71, 72, 73, 74]]   I just hate that runt at the end!  Others, like list(grouper(3, xrange(7))), and chunk(xrange(7), 3) both return: [(0, 1, 2), (3, 4, 5), (6, None, None)]. The None's are just padding, and rather inelegant in my opinion. They are NOT evenly chunking the iterables.  Why can't we divide these better?  My Solution(s)  Here's a balanced solution, adapted from a function I've used in production (Note in Python 3 to replace xrange with range):  def baskets_from(items, maxbaskets=25):     baskets = [[] for _ in xrange(maxbaskets)] # in Python 3 use range     for i, item in enumerate(items):         baskets[i % maxbaskets].append(item)     return filter(None, baskets)    And I created a generator that does the same if you put it into a list:  def iter_baskets_from(items, maxbaskets=3):     '''generates evenly balanced baskets from indexable iterable'''     item_count = len(items)     baskets = min(item_count, maxbaskets)     for x_i in xrange(baskets):         yield [items[y_i] for y_i in xrange(x_i, item_count, baskets)]   And finally, since I see that all of the above functions return elements in a contiguous order (as they were given):  def iter_baskets_contiguous(items, maxbaskets=3, item_count=None):     '''     generates balanced baskets from iterable, contiguous contents     provide item_count if providing a iterator that doesn't support len()     '''     item_count = item_count or len(items)     baskets = min(item_count, maxbaskets)     items = iter(items)     floor = item_count // baskets      ceiling = floor + 1     stepdown = item_count % baskets     for x_i in xrange(baskets):         length = ceiling if x_i < stepdown else floor         yield [items.next() for _ in xrange(length)]   Output  To test them out:  print(baskets_from(xrange(6), 8)) print(list(iter_baskets_from(xrange(6), 8))) print(list(iter_baskets_contiguous(xrange(6), 8))) print(baskets_from(xrange(22), 8)) print(list(iter_baskets_from(xrange(22), 8))) print(list(iter_baskets_contiguous(xrange(22), 8))) print(baskets_from('ABCDEFG', 3)) print(list(iter_baskets_from('ABCDEFG', 3))) print(list(iter_baskets_contiguous('ABCDEFG', 3))) print(baskets_from(xrange(26), 5)) print(list(iter_baskets_from(xrange(26), 5))) print(list(iter_baskets_contiguous(xrange(26), 5)))   Which prints out:  [[0], [1], [2], [3], [4], [5]] [[0], [1], [2], [3], [4], [5]] [[0], [1], [2], [3], [4], [5]] [[0, 8, 16], [1, 9, 17], [2, 10, 18], [3, 11, 19], [4, 12, 20], [5, 13, 21], [6, 14], [7, 15]] [[0, 8, 16], [1, 9, 17], [2, 10, 18], [3, 11, 19], [4, 12, 20], [5, 13, 21], [6, 14], [7, 15]] [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14], [15, 16, 17], [18, 19], [20, 21]] [['A', 'D', 'G'], ['B', 'E'], ['C', 'F']] [['A', 'D', 'G'], ['B', 'E'], ['C', 'F']] [['A', 'B', 'C'], ['D', 'E'], ['F', 'G']] [[0, 5, 10, 15, 20, 25], [1, 6, 11, 16, 21], [2, 7, 12, 17, 22], [3, 8, 13, 18, 23], [4, 9, 14, 19, 24]] [[0, 5, 10, 15, 20, 25], [1, 6, 11, 16, 21], [2, 7, 12, 17, 22], [3, 8, 13, 18, 23], [4, 9, 14, 19, 24]] [[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]]   Notice that the contiguous generator provide chunks in the same length patterns as the other two, but the items are all in order, and they are as evenly divided as one may divide a list of discrete elements.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "28", "A_Content": "  I saw the most awesome Python-ish answer in a duplicate of this question:  from itertools import zip_longest  a = range(1, 16) i = iter(a) r = list(zip_longest(i, i, i)) >>> print(r) [(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12), (13, 14, 15)]   You can create n-tuple for any n. If a = range(1, 15), then the result will be:  [(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12), (13, 14, None)]   If the list is divided evenly, then you can replace zip_longest with zip, otherwise the triplet (13, 14, None) would be lost. Python 3 is used above. For Python 2, use izip_longest.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "17", "A_Content": "  If you had a chunk size of 3 for example, you could do:  zip(*[iterable[i::3] for i in range(3)])    source: http://code.activestate.com/recipes/303060-group-a-list-into-sequential-n-tuples/  I would use this when my chunk size is fixed number I can type, e.g. '3', and would never change.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "16", "A_Content": "  If you know list size:  def SplitList(list, chunk_size):     return [list[offs:offs+chunk_size] for offs in range(0, len(list), chunk_size)]   If you don't (an iterator):  def IterChunks(sequence, chunk_size):     res = []     for item in sequence:         res.append(item)         if len(res) >= chunk_size:             yield res             res = []     if res:         yield res  # yield the last, incomplete, portion   In the latter case, it can be rephrased in a more beautiful way if you can be sure that the sequence always contains a whole number of chunks of given size (i.e. there is no incomplete last chunk).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "15", "A_Content": "  A generator expression:  def chunks(seq, n):     return (seq[i:i+n] for i in xrange(0, len(seq), n))   eg.  print list(chunks(range(1, 1000), 10))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "14", "A_Content": "  I like the Python doc's version proposed by tzot and J.F.Sebastian a lot,  but it has two shortcomings:   it is not very explicit I usually don't want a fill value in the last chunk   I'm using this one a lot in my code:  from itertools import islice  def chunks(n, iterable):     iterable = iter(iterable)     while True:         yield tuple(islice(iterable, n)) or iterable.next()   UPDATE: A lazy chunks version:  from itertools import chain, islice  def chunks(n, iterable):    iterable = iter(iterable)    while True:        yield chain([next(iterable)], islice(iterable, n-1))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "13", "A_Content": "  The toolz library has the partition function for this:  from toolz.itertoolz.core import partition  list(partition(2, [1, 2, 3, 4])) [(1, 2), (3, 4)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "456", "A_Content": "  Felix already provided an excellent answer, but I thought I'd do a speed comparison of the various methods:   10.59 sec (105.9us/itn) -  copy.deepcopy(old_list) 10.16 sec (101.6us/itn) - pure python Copy() method copying classes with deepcopy 1.488 sec (14.88us/itn) - pure python Copy() method not copying classes (only dicts/lists/tuples) 0.325 sec (3.25us/itn) - for item in old_list: new_list.append(item) 0.217 sec (2.17us/itn) - [i for i in old_list] (a list comprehension) 0.186 sec (1.86us/itn) - copy.copy(old_list) 0.075 sec (0.75us/itn) - list(old_list) 0.053 sec (0.53us/itn) - new_list = []; new_list.extend(old_list) 0.039 sec (0.39us/itn) - old_list[:] (list slicing)   So the fastest is list slicing. But be aware that copy.copy(), list[:] and list(list), unlike copy.deepcopy() and the python version don't copy any lists, dictionaries and class instances in the list, so if the originals change, they will change in the copied list too and vice versa.  (Here's the script if anyone's interested or wants to raise any issues:)  from copy import deepcopy  class old_class:     def __init__(self):         self.blah = 'blah'  class new_class(object):     def __init__(self):         self.blah = 'blah'  dignore = {str: None, unicode: None, int: None, type(None): None}  def Copy(obj, use_deepcopy=True):     t = type(obj)      if t in (list, tuple):         if t == tuple:             # Convert to a list if a tuple to              # allow assigning to when copying             is_tuple = True             obj = list(obj)         else:              # Otherwise just do a quick slice copy             obj = obj[:]             is_tuple = False          # Copy each item recursively         for x in xrange(len(obj)):             if type(obj[x]) in dignore:                 continue             obj[x] = Copy(obj[x], use_deepcopy)          if is_tuple:              # Convert back into a tuple again             obj = tuple(obj)      elif t == dict:          # Use the fast shallow dict copy() method and copy any          # values which aren't immutable (like lists, dicts etc)         obj = obj.copy()         for k in obj:             if type(obj[k]) in dignore:                 continue             obj[k] = Copy(obj[k], use_deepcopy)      elif t in dignore:          # Numeric or string/unicode?          # It's immutable, so ignore it!         pass       elif use_deepcopy:          obj = deepcopy(obj)     return obj  if __name__ == '__main__':     import copy     from time import time      num_times = 100000     L = [None, 'blah', 1, 543.4532,           ['foo'], ('bar',), {'blah': 'blah'},          old_class(), new_class()]      t = time()     for i in xrange(num_times):         Copy(L)     print 'Custom Copy:', time()-t      t = time()     for i in xrange(num_times):         Copy(L, use_deepcopy=False)     print 'Custom Copy Only Copying Lists/Tuples/Dicts (no classes):', time()-t      t = time()     for i in xrange(num_times):         copy.copy(L)     print 'copy.copy:', time()-t      t = time()     for i in xrange(num_times):         copy.deepcopy(L)     print 'copy.deepcopy:', time()-t      t = time()     for i in xrange(num_times):         L[:]     print 'list slicing [:]:', time()-t      t = time()     for i in xrange(num_times):         list(L)     print 'list(L):', time()-t      t = time()     for i in xrange(num_times):         [i for i in L]     print 'list expression(L):', time()-t      t = time()     for i in xrange(num_times):         a = []         a.extend(L)     print 'list extend:', time()-t      t = time()     for i in xrange(num_times):         a = []         for y in L:             a.append(y)     print 'list append:', time()-t      t = time()     for i in xrange(num_times):         a = []         a.extend(i for i in L)     print 'generator expression extend:', time()-t   EDIT: Added new-style, old-style classes and dicts to the benchmarks, and made the python version much faster and added some more methods including list expressions and extend().     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "116", "A_Content": "  I've been told that Python 3.3+ adds list.copy() method, which should be as fast as slicing:  newlist = old_list.copy()     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "90", "A_Content": "     What are the options to clone or copy a list in Python?   In Python 3, a shallow copy can be made with:  a_copy = a_list.copy()   In Python 2 and 3, you can get a shallow copy with a full slice of the original:  a_copy = a_list[:]   Explanation  There are two semantic ways to copy a list. A shallow copy creates a new list of the same objects, a deep copy creates a new list containing new equivalent objects.  Shallow list copy  A shallow copy only copies the list itself, which is a container of references to the objects in the list. If the objects contained themselves are mutable and one is changed, the change will be reflected in both lists.   There are different ways to do this in Python 2 and 3. The Python 2 ways will also work in Python 3.  Python 2  In Python 2, the idiomatic way of making a shallow copy of a list is with a complete slice of the original:  a_copy = a_list[:]   You can also accomplish the same thing by passing the list through the list constructor,   a_copy = list(a_list)   but using the constructor is less efficient:  >>> timeit >>> l = range(20) >>> min(timeit.repeat(lambda: l[:])) 0.30504298210144043 >>> min(timeit.repeat(lambda: list(l))) 0.40698814392089844   Python 3  In Python 3, lists get the list.copy method:  a_copy = a_list.copy()   In Python 3.5:  >>> import timeit >>> l = list(range(20)) >>> min(timeit.repeat(lambda: l[:])) 0.38448613602668047 >>> min(timeit.repeat(lambda: list(l))) 0.6309100328944623 >>> min(timeit.repeat(lambda: l.copy())) 0.38122922903858125   Making another pointer does not make a copy     Using new_list = my_list then modifies new_list every time my_list changes. Why is this?   my_list is just a name that points to the actual list in memory. When you say new_list = my_list you're not making a copy, you're just adding another name that points at that original list in memory. We can have similar issues when we make copies of lists.   >>> l = [[], [], []] >>> l_copy = l[:] >>> l_copy [[], [], []] >>> l_copy[0].append('foo') >>> l_copy [['foo'], [], []] >>> l [['foo'], [], []]   The list is just an array of pointers to the contents, so a shallow copy just copies the pointers, and so you have two different lists, but they have the same contents. To make copies of the contents, you need a deep copy.  Deep copies  To make a deep copy of a list, in Python 2 or 3, use deepcopy in the copy module:  import copy a_deep_copy = copy.deepcopy(a_list)   To demonstrate how this allows us to make new sub-lists:  >>> import copy >>> l [['foo'], [], []] >>> l_deep_copy = copy.deepcopy(l) >>> l_deep_copy[0].pop() 'foo' >>> l_deep_copy [[], [], []] >>> l [['foo'], [], []]   And so we see that the deep copied list is an entirely different list from the original. You could roll your own function - but don't. You're likely to create bugs you otherwise wouldn't have by using the standard library's deepcopy function.  Don't use eval  You may see this used as a way to deepcopy, but don't do it:  problematic_deep_copy = eval(repr(a_list))    It's dangerous, particularly if you're evaluating something from a source you don't trust. It's not reliable, if a subelement you're copying doesn't have a representation that can be eval'd to reproduce an equivalent element. It's also less performant.    In 64 bit Python 2.7:  >>> import timeit >>> import copy >>> l = range(10) >>> min(timeit.repeat(lambda: copy.deepcopy(l))) 27.55826997756958 >>> min(timeit.repeat(lambda: eval(repr(l)))) 29.04534101486206   on 64 bit Python 3.5:  >>> import timeit >>> import copy >>> l = list(range(10)) >>> min(timeit.repeat(lambda: copy.deepcopy(l))) 16.84255409205798 >>> min(timeit.repeat(lambda: eval(repr(l)))) 34.813894678023644      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "42", "A_Content": "  There are many answers already that tell you how to make a proper copy, but none of them say why your original 'copy' failed.   Python doesn't store values in variables; it binds names to objects. Your original assignment took the object referred to by my_list and bound it to new_list as well. No matter which name you use there is still only one list, so changes made when referring to it as my_list will persist when referring to it as new_list. Each of the other answers to this question give you different ways of creating a new object to bind to new_list.   Each element of a list acts like a name, in that each element binds non-exclusively to an object. A shallow copy creates a new list whose elements bind to the same objects as before.  new_list = list(my_list)  # or my_list[:], but I prefer this syntax # is simply a shorter way of: new_list = [element for element in my_list]   To take your list copy one step further, copy each object that your list refers to, and bind those element copies to a new list.   import copy   # each element must have __copy__ defined for this... new_list = [copy.copy(element) for element in my_list]   This is not yet a deep copy, because each element of a list may refer to other objects, just like the list is bound to its elements. To recursively copy every element in the list, and then each other object referred to by each element, and so on: perform a deep copy.   import copy # each element must have __deepcopy__ defined for this... new_list = copy.deepcopy(my_list)   See the documentation for more information about corner cases in copying.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "31", "A_Content": "  new_list = list(old_list)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "27", "A_Content": "  Use thing[:]  >>> a = [1,2] >>> b = a[:] >>> a += [3] >>> a [1, 2, 3] >>> b [1, 2] >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "26", "A_Content": "  Python's idiom for doing this is newList = oldList[:]     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "18", "A_Content": "  All of the other contributors gave great answers, which work when you have a single dimension (leveled) list, however of the methods mentioned so far, only copy.deepcopy() works to clone/copy a list and not have it point to the nested list objects when you are working with multidimensional, nested lists (list of lists). While Felix Kling refers to it in his answer, there is a little bit more to the issue and possibly a workaround using built-ins that might prove a faster alternative to deepcopy.  While new_list = old_list[:], copy.copy(old_list)' and for Py3k old_list.copy() work for single-leveled lists, they revert to pointing at the list objects nested within the old_list and the new_list, and changes to one of the list objects are perpetuated in the other.   Edit: New information brought to light     As was pointed out by both Aaron Hall and PM 2Ring using eval() is not only a bad idea, it is also much slower than copy.deepcopy().       This means that for multidimensional lists, the only option is copy.deepcopy(). With that being said, it really isn't an option as the performance goes way south when you try to use it on a moderately sized multidimensional array.  I tried to timeit using a 42x42 array, not unheard of or even that large for bioinformatics applications, and I gave up on waiting for a response and just started typing my edit to this post.      It would seem that the only real option then is to initialize multiple lists and work on them independently. If anyone has any other suggestions, for how to handle multidimensional list copying, it would be appreciated.   As others have stated, there can be are significant performance issues using the copy module and copy.deepcopy for multidimensional lists.  Trying to work out a different way of copying the multidimensional list without using deepcopy, (I was working on a problem for a course that only allows 5 seconds for the entire algorithm to run in order to receive credit), I came up with a way of using built-in functions to make a copy of the nested list without having them point at one another or at the list objects nested within them. I used eval() and repr() in the assignment to make the copy of the old list into the new list without creating a link to the old list. It takes the form of:  new_list = eval(repr(old_list))   Basically what this does is make a representation of old_list as a string and then evaluates the string as if it were the object that the string represents. By doing this, no link to the original list object is made. A new list object is created and each variable points to its own independent object. Here is an example using a 2 dimensional nested list.  old_list = [[0 for j in range(y)] for i in range(x)] # initialize (x,y) nested list  # assign a copy of old_list to new list without them pointing to the same list object new_list = eval(repr(old_list))   # make a change to new_list  for j in range(y):     for i in range(x):     new_list[i][j] += 1   If you then check the contents of each list, for example a 4 by 3 list, Python will return   >>> new_list  [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]  >>> old_list  [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]   While this probably isn't the canonical or syntactically correct way to do it, it seems to work well. I haven't tested performance, but I am going to guess that eval() and rep() will have less overhead to run than deepcopy will.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "13", "A_Content": "  Unlike other languages that have variable and value, Python has name and object.  This statement:  a = [1,2,3]   means to give the list (object) a name a, and, this:  b = a   just gives the same object a a new name b, so whenever you do something with a, the object changes and therefore b changes.  The only way to make a really copy of a is to create a new object like other answers already have said.  You can see more about this here.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "12", "A_Content": "  Python 3.6.0 Timings  Here are the timing results using Python 3.6.0. Keep in mind these times are relative to one another, not absolute.  I stuck to only doing shallow copies, and also added some new methods that weren't possible in Python2, such as list.copy() (the Python3 slice equivalent) and list unpacking (*new_list, = list):  METHOD                  TIME TAKEN b = a[:]                6.468942025996512   #Python2 winner b = a.copy()            6.986593422974693   #Python3 \"slice equivalent\" b = []; b.extend(a)     7.309216841997113 b = a[0:len(a)]         10.916740721993847 *b, = a                 11.046738261007704 b = list(a)             11.761539687984623 b = [i for i in a]      24.66165203397395 b = copy.copy(a)        30.853400873980718 b = [] for item in a:   b.append(item)        48.19176080400939   We can see the old winner still comes out on top, but not really by a huge amount, considering the increased readability of the Python3 list.copy() approach.  Note that these methods do not output equivalent results for any input other than lists. They all work for sliceable objects, a few work for any iterable, but only copy.copy() works for any Python object.    Here is the testing code for interested parties (Template from here):  import timeit  COUNT = 50000000 print(\"Array duplicating. Tests run\", COUNT, \"times\") setup = 'a = [0,1,2,3,4,5,6,7,8,9]; import copy'  print(\"b = list(a)\\t\\t\", timeit.timeit(stmt='b = list(a)', setup=setup, number=COUNT)) print(\"b = copy.copy(a)\\t\\t\", timeit.timeit(stmt='b = copy.copy(a)', setup=setup, number=COUNT)) print(\"b = a.copy()\\t\\t\", timeit.timeit(stmt='b = a.copy()', setup=setup, number=COUNT)) print(\"b = a[:]\\t\\t\", timeit.timeit(stmt='b = a[:]', setup=setup, number=COUNT)) print(\"b = a[0:len(a)]\\t\", timeit.timeit(stmt='b = a[0:len(a)]', setup=setup, number=COUNT)) print(\"*b, = a\\t\", timeit.timeit(stmt='*b, = a', setup=setup, number=COUNT)) print(\"b = []; b.extend(a)\\t\", timeit.timeit(stmt='b = []; b.extend(a)', setup=setup, number=COUNT)) print(\"b = []\\nfor item in a: b.append(item)\\t\", timeit.timeit(stmt='b = []\\nfor item in a:  b.append(item)', setup=setup, number=COUNT)) print(\"b = [i for i in a]\\t\", timeit.timeit(stmt='b = [i for i in a]', setup=setup, number=COUNT))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "11", "A_Content": "     Let's start from the beginning and explorer it a little deep :   So Suppose you have two list :  list_1=['01','98'] list_2=[['01','98']]   And we have to copy both list , now starting from the first list:  So first let's try by general method of copy:  copy=list_1   Now if you are thinking copy copied the list_1 then you can be wrong, let's check it:   The id() function shows us that both variables point to the same list object, i.e. they share this object.    print(id(copy)) print(id(list_1))   output:  4329485320 4329485320   Surprised ? Ok let's explore it:  So as we know python doesn't store anything in a variable, Variables are just referencing to the object and object store the value. Here object is list but we created two references to that same object by two different variable names. So both variables are pointing to the same object :  so when you do copy=list_1 what actually its doing :    Here in the image list_1 and copy are two variable names but the object is same for both variable which is list  So if you try to modify copied list then it will modify the original list too because the list is only one there, you will modify that list no matter you do from the copied list or from the original list:  copy[0]=\"modify\"  print(copy) print(list_1)   output:  ['modify', '98'] ['modify', '98']   So it modified the original list :     What is the solution then?      Solution :   Now let's move to a second pythonic method of copying list:  copy_1=list_1[:]   Now this method fix the thing what we were facing in first issue let's check it :  print(id(copy_1)) print(id(list_1))  4338792136 4338791432   So as we can see our both list having different id and it means both variables are pointing to different objects so what actually going on here is :    Now let's try to modify the list and let's see if we still face the previous problem :  copy_1[0]=\"modify\"  print(list_1) print(copy_1)   Output:  ['01', '98'] ['modify', '98']   So as you can see it is not modifying the original list, it only modified the copied list, So we are ok with it.   So now i think we are done? wait we have to copy the second nested list too so let's try pythonic way :  copy_2=list_2[:]   So list_2 should reference to another object which is copy of list_2 let's check:  print(id((list_2)),id(copy_2))   we get the output:  4330403592 4330403528   Now we can assume both lists are pointing different object so now let's try to modify it and let's see it is giving what we want :  So when we try:  copy_2[0][1]=\"modify\"  print(list_2,copy_2)   it gives us output:  [['01', 'modify']] [['01', 'modify']]   Now, this is little confusing we used the pythonic way and still, we are facing the same issue.  let's understand it:  So when we do :  copy_2=list_2[:]   we are actually copying the outer list only, not the nested list, so nested list is same object for both list, let's check:  print(id(copy_2[0])) print(id(list_2[0]))   output:  4329485832 4329485832   So actually when we do copy_2=list_2[:]  this is what happens:    It creates the copy of list but only outer list copy, not the nested list copy, nested list is same for both variable so if you try to modify the nested list then it will modify the original list too because nested list object is same for both nested list.  So what is the solution?  Solution is deep copy  from copy import deepcopy deep=deepcopy(list_2)   So now let's check it :  print(id((list_2)),id(deep))   output:  4322146056 4322148040   both id are different  , now let's check nested list id:  print(id(deep[0])) print(id(list_2[0]))   output:  4322145992 4322145800   As you can see both id are different so we can assume that both nested list are pointing different object now.  So when you do deep=deepcopy(list_2) what actually happens :    So both nested list are pointing different object and they have seprate copy of nested list now.  Now let's try to modify the nested list and let's see if it solved the previous issue or not:  so if we do :  deep[0][1]=\"modify\" print(list_2,deep)   output:  [['01', '98']] [['01', 'modify']]   So as you can see it didn't modify the original nested list , it only modified the copied list.   If you like my detailed answer , let me know by upvoting it ,   if you have any doubt realted this answer , comment down :)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "11", "A_Content": "  At this point, I think we need a recursive generator, just in case...  In python 2:  def chunks(li, n):     if li == []:         return     yield li[:n]     for e in chunks(li[n:], n):         yield e   In python 3:  def chunks(li, n):     if li == []:         return     yield li[:n]     yield from chunks(li[n:], n)   Also, in case of massive Alien invasion, a decorated recursive generator might become handy:  def dec(gen):     def new_gen(li, n):         for e in gen(li, n):             if e == []:                 return             yield e     return new_gen  @dec def chunks(li, n):     yield li[:n]     for e in chunks(li[n:], n):         yield e      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "10", "A_Content": "  You may also use get_chunks function of utilspie library as:  >>> from utilspie import iterutils >>> a = [1, 2, 3, 4, 5, 6, 7, 8, 9]  >>> list(iterutils.get_chunks(a, 5)) [[1, 2, 3, 4, 5], [6, 7, 8, 9]]   You can install utilspie via pip:  sudo pip install utilspie   Disclaimer: I am the creator of utilspie library.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "10", "A_Content": "  I was curious about the performance of different approaches and here it is:  Tested on Python 3.5.1  import time batch_size = 7 arr_len = 298937  #---------slice-------------  print(\"\\r\\nslice\") start = time.time() arr = [i for i in range(0, arr_len)] while True:     if not arr:         break      tmp = arr[0:batch_size]     arr = arr[batch_size:-1] print(time.time() - start)  #-----------index-----------  print(\"\\r\\nindex\") arr = [i for i in range(0, arr_len)] start = time.time() for i in range(0, round(len(arr) / batch_size + 1)):     tmp = arr[batch_size * i : batch_size * (i + 1)] print(time.time() - start)  #----------batches 1------------  def batch(iterable, n=1):     l = len(iterable)     for ndx in range(0, l, n):         yield iterable[ndx:min(ndx + n, l)]  print(\"\\r\\nbatches 1\") arr = [i for i in range(0, arr_len)] start = time.time() for x in batch(arr, batch_size):     tmp = x print(time.time() - start)  #----------batches 2------------  from itertools import islice, chain  def batch(iterable, size):     sourceiter = iter(iterable)     while True:         batchiter = islice(sourceiter, size)         yield chain([next(batchiter)], batchiter)   print(\"\\r\\nbatches 2\") arr = [i for i in range(0, arr_len)] start = time.time() for x in batch(arr, batch_size):     tmp = x print(time.time() - start)  #---------chunks------------- def chunks(l, n):     \"\"\"Yield successive n-sized chunks from l.\"\"\"     for i in range(0, len(l), n):         yield l[i:i + n] print(\"\\r\\nchunks\") arr = [i for i in range(0, arr_len)] start = time.time() for x in chunks(arr, batch_size):     tmp = x print(time.time() - start)  #-----------grouper-----------  from itertools import zip_longest # for Python 3.x #from six.moves import zip_longest # for both (uses the six compat library)  def grouper(iterable, n, padvalue=None):     \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"     return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)  arr = [i for i in range(0, arr_len)] print(\"\\r\\ngrouper\") start = time.time() for x in grouper(arr, batch_size):     tmp = x print(time.time() - start)   Results:  slice 31.18285083770752  index 0.02184295654296875  batches 1 0.03503894805908203  batches 2 0.22681021690368652  chunks 0.019841909408569336  grouper 0.006506919860839844      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "9", "A_Content": "  [AA[i:i+SS] for i in range(len(AA))[::SS]]   Where AA is array, SS is chunk size. For example:  >>> AA=range(10,21);SS=3 >>> [AA[i:i+SS] for i in range(len(AA))[::SS]] [[10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20]] # or [range(10, 13), range(13, 16), range(16, 19), range(19, 21)] in py3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "8", "A_Content": "  code:  def split_list(the_list, chunk_size):     result_list = []     while the_list:         result_list.append(the_list[:chunk_size])         the_list = the_list[chunk_size:]     return result_list  a_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  print split_list(a_list, 3)   result:  [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "7", "A_Content": "  def split_seq(seq, num_pieces):     start = 0     for i in xrange(num_pieces):         stop = start + len(seq[i::num_pieces])         yield seq[start:stop]         start = stop   usage:  seq = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  for seq in split_seq(seq, 3):     print seq      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "7", "A_Content": "  Another more explicit version.  def chunkList(initialList, chunkSize):     \"\"\"     This function chunks a list into sub lists      that have a length equals to chunkSize.      Example:     lst = [3, 4, 9, 7, 1, 1, 2, 3]     print(chunkList(lst, 3))      returns     [[3, 4, 9], [7, 1, 1], [2, 3]]     \"\"\"     finalList = []     for i in range(0, len(initialList), chunkSize):         finalList.append(initialList[i:i+chunkSize])     return finalList      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "6", "A_Content": "  heh, one line version  In [48]: chunk = lambda ulist, step:  map(lambda i: ulist[i:i+step],  xrange(0, len(ulist), step))  In [49]: chunk(range(1,100), 10) Out[49]:  [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],  [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],  [21, 22, 23, 24, 25, 26, 27, 28, 29, 30],  [31, 32, 33, 34, 35, 36, 37, 38, 39, 40],  [41, 42, 43, 44, 45, 46, 47, 48, 49, 50],  [51, 52, 53, 54, 55, 56, 57, 58, 59, 60],  [61, 62, 63, 64, 65, 66, 67, 68, 69, 70],  [71, 72, 73, 74, 75, 76, 77, 78, 79, 80],  [81, 82, 83, 84, 85, 86, 87, 88, 89, 90],  [91, 92, 93, 94, 95, 96, 97, 98, 99]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "5", "A_Content": "  Consider using matplotlib.cbook pieces  for example:  import matplotlib.cbook as cbook segments = cbook.pieces(np.arange(20), 3) for s in segments:      print s      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "5", "A_Content": "  a = [1, 2, 3, 4, 5, 6, 7, 8, 9] CHUNK = 4 [a[i*CHUNK:(i+1)*CHUNK] for i in xrange((len(a) + CHUNK - 1) / CHUNK )]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "5", "A_Content": "  At this point, I think we need the obligatory anonymous-recursive function.  Y = lambda f: (lambda x: x(x))(lambda y: f(lambda *args: y(y)(*args))) chunks = Y(lambda f: lambda n: [n[0][:n[1]]] + f((n[0][n[1]:], n[1])) if len(n[0]) > 0 else [])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "5", "A_Content": "  Without calling len() which is good for large lists:  def splitter(l, n):     i = 0     chunk = l[:n]     while chunk:         yield chunk         i += n         chunk = l[i:i+n]   And this is for iterables:  def isplitter(l, n):     l = iter(l)     chunk = list(islice(l, n))     while chunk:         yield chunk         chunk = list(islice(l, n))   The functional flavour of the above:  def isplitter2(l, n):     return takewhile(bool,                      (tuple(islice(start, n))                             for start in repeat(iter(l))))   OR:  def chunks_gen_sentinel(n, seq):     continuous_slices = imap(islice, repeat(iter(seq)), repeat(0), repeat(n))     return iter(imap(tuple, continuous_slices).next,())   OR:  def chunks_gen_filter(n, seq):     continuous_slices = imap(islice, repeat(iter(seq)), repeat(0), repeat(n))     return takewhile(bool,imap(tuple, continuous_slices))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "5", "A_Content": "  One more solution  def make_chunks(data, chunk_size):      while data:         chunk, data = data[:chunk_size], data[chunk_size:]         yield chunk  >>> for chunk in make_chunks([1, 2, 3, 4, 5, 6, 7], 2): ...     print chunk ...  [1, 2] [3, 4] [5, 6] [7] >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "4", "A_Content": "  def chunks(iterable,n):     \"\"\"assumes n is an integer>0     \"\"\"     iterable=iter(iterable)     while True:         result=[]         for i in range(n):             try:                 a=next(iterable)             except StopIteration:                 break             else:                 result.append(a)         if result:             yield result         else:             break  g1=(i*i for i in range(10)) g2=chunks(g1,3) print g2 '<generator object chunks at 0x0337B9B8>' print list(g2) '[[0, 1, 4], [9, 16, 25], [36, 49, 64], [81]]'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "Language": "Python", "Q_Title": "How do you split a list into evenly sized chunks?", "Q_Votes": "1625", "Q_Content": "    I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.  I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.  I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.  Related question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?     ", "Tags": ["python", "list", "split", "chunks"], "A_Votes": "4", "A_Content": "  I realise this question is old (stumbled over it on Google), but surely something like the following is far simpler and clearer than any of the huge complex suggestions and only uses slicing:  def chunker(iterable, chunksize):     for i,c in enumerate(iterable[::chunksize]):         yield iterable[i*chunksize:(i+1)*chunksize]  >>> for chunk in chunker(range(0,100), 10): ...     print list(chunk) ...  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [10, 11, 12, 13, 14, 15, 16, 17, 18, 19] [20, 21, 22, 23, 24, 25, 26, 27, 28, 29] ... etc ...      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "7", "A_Content": "  It surprises me that this hasn't been mentioned yet, so for the sake of completeness...  You can perform list unpacking with the \"splat operator\": *, which will also copy elements of your list.  old_list = [1, 2, 3]  new_list = [*old_list]  new_list.append(4) old_list == [1, 2, 3] new_list == [1, 2, 3, 4]   The obvious downside to this method is that it is only available in Python 3.5+.  Timing wise though, this appears to perform better than other common methods.  x = [random.random() for _ in range(1000)]  %timeit a = list(x) %timeit a = x.copy() %timeit a = x[:]  %timeit a = [*x]  #: 2.47 \u00b5s \u00b1 38.1 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) #: 2.47 \u00b5s \u00b1 54.6 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) #: 2.39 \u00b5s \u00b1 58.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)  #: 2.22 \u00b5s \u00b1 43.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "4", "A_Content": "  Not sure if this is still actual, but the same behavior holds for dictionaries as well. Look at this example.  a = {'par' : [1,21,3], 'sar' : [5,6,8]} b = a c = a.copy() a['har'] = [1,2,3]  a Out[14]: {'har': [1, 2, 3], 'par': [1, 21, 3], 'sar': [5, 6, 8]}  b Out[15]: {'har': [1, 2, 3], 'par': [1, 21, 3], 'sar': [5, 6, 8]}  c Out[16]: {'par': [1, 21, 3], 'sar': [5, 6, 8]}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "3", "A_Content": "  Note that there are some cases where if you have defined your own custom class and you want to keep the attributes then you should use copy.copy() or copy.deepcopy() rather than the alternatives, for example in Python 3:  import copy  class MyList(list):     pass  lst = MyList([1,2,3])  lst.name = 'custom list'  d = { 'original': lst, 'slicecopy' : lst[:], 'lstcopy' : lst.copy(), 'copycopy': copy.copy(lst), 'deepcopy': copy.deepcopy(lst) }   for k,v in d.items():     print('lst: {}'.format(k), end=', ')     try:         name = v.name     except AttributeError:         name = 'NA'     print('name: {}'.format(name))   Outputs:  lst: original, name: custom list lst: slicecopy, name: NA lst: lstcopy, name: NA lst: copycopy, name: custom list lst: deepcopy, name: custom list      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "2", "A_Content": "  new_list = my_list[:]   new_list = my_list Try to understand this. Let's say that my_list is in the heap memory at location X i.e. my_list is pointing to the X. Now by assigning new_list = my_list you're Letting new_list pointing to the X. This is known as shallow Copy.                                                                Now if you assign new_list = my_list[:] You're simply copying each object of my_list to new_list. This is known as Deep copy.  The Other way you can do this are :   new_list = list(old_list) import copy new_list = copy.deepcopy(old_list)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "2", "A_Content": "  A very simple approach independent of python version was missing in already given answers which you can use most of the time (at least I do):  new_list = my_list * 1       #Solution 1 when you are not using nested lists   However, If my_list contains other containers (for eg. nested lists) you must use deepcopy as others suggested in the answers above from the copy library. For example:  import copy new_list = copy.deepcopy(my_list)   #Solution 2 when you are using nested lists   .Bonus: If you don't want to copy elements use (aka shallow copy):  new_list = my_list[:]     Let's understand difference between Solution#1 and Solution #2  >>> a = range(5) >>> b = a*1 >>> a,b ([0, 1, 2, 3, 4], [0, 1, 2, 3, 4]) >>> a[2] = 55  >>> a,b ([0, 1, 55, 3, 4], [0, 1, 2, 3, 4])   As you can see Solution #1 worked perfectly when we were not using the nested lists. Let's check what will happen when we apply solution #1 to nested lists.  >>> from copy import deepcopy >>> a = [range(i,i+4) for i in range(3)] >>> a [[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]] >>> b = a*1 >>> c = deepcopy(a) >>> for i in (a, b, c): print i    [[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]] [[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]] [[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]] >>> a[2].append('99') >>> for i in (a, b, c): print i    [[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5, 99]] [[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5, 99]]   #Solution#1 didn't work in nested list [[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]       #Solution #2 - DeepCopy worked in nested list      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list", "Language": "Python", "Q_Title": "How to clone or copy a list?", "Q_Votes": "1747", "Q_Content": "    What are the options to clone or copy a list in Python?  Using new_list = my_list then modifies new_list every time my_list changes. Why is this?     ", "Tags": ["python", "list", "copy", "clone"], "A_Votes": "2", "A_Content": "  you can use bulit in list() function:  newlist=list(oldlist)   i think this code will help you.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "838", "A_Content": "  One way is to use Kivy:     Open source Python library for rapid development of applications   that make use of innovative user interfaces, such as multi-touch apps.        Kivy runs on Linux, Windows, OS X, Android and iOS. You can run the same [python] code on all supported platforms.   Kivy Showcase app       ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "311", "A_Content": "  There is also the new Android Scripting Environment (ASE/SL4A) project. It looks awesome, and it has some integration with native Android components.   Note: no longer under \"active development\", but some forks may be.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "187", "A_Content": "  YES!  An example via Matt Cutts via SL4A -- \"here\u2019s a barcode scanner written in six lines of Python code:  import android droid = android.Android() code = droid.scanBarcode() isbn = int(code['result']['SCAN_RESULT']) url = \"http://books.google.com?q=%d\" % isbn droid.startActivity('android.intent.action.VIEW', url)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "78", "A_Content": "  There's also SL4A written in large by Google employees.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "76", "A_Content": "  \"The Pygame Subset for Android is a port of a subset of Pygame functionality to the Android platform. The goal of the project is to allow the creation of Android-specific games, and to ease the porting of games from PC-like platforms to Android.\"  The examples include a complete game packaged in an APK, which is pretty interesting.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "67", "A_Content": "  I've posted instructions and a patch for cross compiling Python 2.7.2 for Android, you can get it at my blog here: http://mdqinc.com/blog/2011/09/cross-compiling-python-for-android/  EDIT: I've open sourced Ignifuga, my 2D Game Engine, it's Python/SDL based and it cross compiles for Android. Even if you don't use it for games, you might get useful ideas from the code and the builder utility (named Schafer, after Tim...you know who).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "64", "A_Content": "  Scripting Layer for Android  SL4A does what you want. You can easily install it directly onto your device from their site, and do not need root.  It supports a range of languages. Python is the most mature. By default, it uses Python 2.6, but there is a 3.2 port you can use instead. I have used that port for all kinds of things on a Galaxy S2 and it worked fine.  API  SL4A provides a port of their android library for each supported language. The library provides an interface to the underlying Android API through a single Android object.  from android import Android  droid = Android() droid.ttsSpeak('hello world') # example using the text to speech facade   Each language has pretty much the same API. You can even use the JavaScript API inside webviews.  let droid = new Android(); droid.ttsSpeak(\"hello from js\");   User Interfaces  For user interfaces, you have three options:   You can easily use the generic, native dialogues and menus through the API. This is good for confirmation dialogues and other basic user inputs. You can also open a webview from inside a Python script, then use HTML5 for the user interface. When you use webviews from Python, you can pass messages back and forth, between the webview and the Python process that spawned it. The UI will not be native, but it is still a good option to have. There is some support for native Android user interfaces, but I am not sure how well it works; I just haven't ever used it.   You can mix options, so you can have a webview for the main interface, and still use native dialogues.  QPython  There is a third party project named QPython. It builds on SL4A, and throws in some other useful stuff.  QPython gives you a nicer UI to manage your installation, and includes a little, touchscreen code editor, a Python shell, and a PIP shell for package management. They also have a Python 3 port. Both versions are available from the Play Store, free of charge. QPython also bundles libraries from a bunch of Python on Android projects, including Kivy, so it is not just SL4A.  Note that QPython still develop their fork of SL4A (though, not much to be honest). The main SL4A project itself is pretty much dead.  Useful Links   SL4A Project (now on GitHub): https://github.com/damonkohler/sl4a SL4A Python 3 Port: https://code.google.com/p/python-for-android/wiki/Python3 QPython Project: http://qpython.com      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "58", "A_Content": "  As a Python lover and Android programmer, I am sad to say this is not really a good way to go. There are two problems.  One problem is that there is a lot more than just a programming language to the Android development tools. A lot of the Android graphics involve XML files to configure the display, similar to HTML. The built-in java objects are really integrated with this XML layout, and it's a lot easier than writing your own code to go from logic to bitmap.  The other problem is that the G1 (and probably other Android devices for the near future) are really not that fast. 200 MHz processors, and RAM is very limited. Even in Java you have to do a decent amount of rewriting-to-avoid-more-object-creation if you want to make your app perfectly smooth. Python is going to be too slow for a while still on mobile devices.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "34", "A_Content": "  Not at the moment and you would be lucky to get Jython to work soon. If you're planning to start your development now you would be better off with just sticking to Java for now on.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "32", "A_Content": "  Using SL4A (which has already been mentioned by itself in other answers) you can run a full-blown web2py instance (other python web frameworks are likely candidates as well).  SL4A doesn't allow you to do native UI components (buttons, scroll bars, and the like), but it does support WebViews.  A WebView is basically nothing more than a striped down web browser pointed at a fixed address. I believe the native Gmail app uses a WebView instead of going the regular widget route.    This route would have some interesting features:   In the case of most python web frameworks, you could actually develop and test without using an android device or android emulator. Whatever Python code you end up writing for the phone could also be put on a public webserver with very little (if any)  modification. You could take advantage of all of the crazy web stuff out there: query, HTML5, CSS3, etc.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "32", "A_Content": "  Kivy    I want to post this as an extension of what @JohnMudd has already answered (but please bear with me as English isn't my first language)  It has been years since then, and Kivy has evolved to v1.9-dev. The biggest selling point of Kivy, in my opinion, is its cross-platform compatibility. You can code and test under your local environment (Windows/*nix etc.), you can also build, debug and package your app to run on your Android/iOS/Mac/Windows devices.  With Kivy's own KV language, you can code and build the GUI interface easily (it's just like Java XML, but rather than TextView etc., KV has its own ui.widgets for the similar translation), which is in my opinion quite easy to adopt.  Currently Buildozer and python-for-android are the most recommended tools to build/package your apps. I have tried them both and can firmly say that they make building Android apps with Python a breeze. Users who feel comfortable in their console/terminal/command prompt should have no problems using them, and their guides are well documented, too.  Furthermore, iOS is another big selling point of Kivy, provided that you can use the same code base with little changes required to test-run on your iOS device, via kivy-ios Homebrew tools, although Xcode is required for the build before running on their devices (AFAIK the iOS Simulator in Xcode currently doesn't work for the x86-architecture build). There are also some dependency issues which must be manually compiled and fiddled around with in Xcode to have a successful build, but they wouldn't be too difficult to resolve and people in Kivy Google Group are really helpful too.  With all being said, users with good Python knowledge should have no problem picking up the basics in weeks (if not days) to build some simple apps.  Also worth mentioning is that you can bundle (build recipes) your Python modules with the build so users can really make use of many existing libraries Python bring us, like Requests & PIL etc. through Kivy's extension support.     Sometimes your application requires functionality that is beyond the   scope of what Kivy can deliver. In those cases, it is necessary to   resort to external software libraries. Given the richness of the   Python ecosystem, there is already a lot of software   libraries that you can simply import and use right away.   The last but not the least, if you are going to use Kivy for more serious/commercial projects, you may find existing modules not satisfactory. There are some workable solutions though, with the \"work in progress\" of pyjnius for Android, and pyobjus. Users can now access Java/Objective-C classes through those modules to control some of the native APIs.  My experience in Kivy is that it will find its best fit with seasoned Python programmers and some serious programmers who want rapid development or simple code base maintenance. It runs well on multiple platforms, albeit not really with the native feeling.   I do hope some Python app programmers find this information useful and start taking a look at Kivy. It can only get better (with more support and as libraries/modules get ported) if there is great interest from the community.  P.S. I have no relationship with Kivy whatsoever, I'm merely a programmer who really likes the idea of bringing Python coding fun to mobile/cross-platform development.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "22", "A_Content": "  I use the QPython application. It has an editor, a console, and you can run your Python programs with it. The application is free, and the link is http://qpython.com/.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "19", "A_Content": "  From the Python for android site:     Python for android is a project to create your own Python distribution including the modules you want, and create an apk including python, libs, and your application.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "16", "A_Content": "  Yet another attempt: https://code.google.com/p/android-python27/  This one embed directly the Python interpretter in your app apk.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "15", "A_Content": "  You can use Termux application:  Note that apt install python install python 3. for python 2 you shoud call apt install python2.  Some demos here: https://www.youtube.com/watch?v=fqqsl72mASE  And also the github page: https://github.com/termux     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "11", "A_Content": "  You can run your Python code using sl4a. sl4a supports Python, Perl, JRuby, Lua, BeanShell, JavaScript, Tcl, and shell script.  You can learn sl4a Python Examples.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "11", "A_Content": "  There's also python-on-a-chip possibly running mosync: google group     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "10", "A_Content": "  You can use QPython:  It has a Python Console, Editor, as well as Package Management / Installers  http://qpython.com/  It's an open source project with both Python 2 and Python 3 implementations. You can download the source and the Android .apk files directly from github.  QPython 2: https://github.com/qpython-android/qpython/releases  QPython 3: https://github.com/qpython-android/qpython3/releases     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "10", "A_Content": "  There is an app called QPython3 in playstore which can be used for both editing and running python script.  Playstore link  Another app called Termux in which you can install python using command  pkg install python   Playstore Link     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "8", "A_Content": "  Didn't see this posted here, but you can do it with Pyside and Qt now that Qt works on Android thanks to Necessitas.  It seems like quite a kludge at the moment but could be a viable route eventually...  http://qt-project.org/wiki/PySide_for_Android_guide     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "8", "A_Content": "  Another option if you are looking for 3.4.2 or 3.5.1 is this archive on GitHub.    Python3-Android 3.4.2 or Python3-Android 3.5.1  It currently supports Python 3.4.2 or 3.5.1 and the 10d version of the NDK.  It can also support 3.3 and 9c, 11c and 12  It's nice in that you simply download it, run make and you get the .so or the .a  I currently use this to run raw Python on android devices. With a couple modifications to the build files you can also make x86 and armeabi 64 bit     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "8", "A_Content": "  Chaquopy  Chaquopy is a plugin for Android Studio's Gradle-based build system. It focuses on close integration with the standard Android development tools.   It provides complete APIs to call Java from Python or Python from Java, allowing the developer to use whichever language is best for each component of their app. It can automatically download PyPI packages and build them into an app, including selected native packages such as NumPy. It enables full access to all Android APIs from Python, including the native user interface toolkit (example pure-Python activity).   This is a commercial product, but it's free for open-source use and will always remain that way.  (I am the creator of this product.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "6", "A_Content": "  One more option seems to be pyqtdeploy which citing the docs is:     a tool that, in conjunction with other tools provided with Qt, enables   the deployment of PyQt4 and PyQt5 applications written with Python   v2.7 or Python v3.3 or later. It supports deployment to desktop   platforms (Linux, Windows and OS X) and to mobile platforms (iOS and   Android).   According to Deploying PyQt5 application to Android via pyqtdeploy and Qt5 it is actively developed, although it is difficult to find examples of working Android apps or tutorial on how to cross-compile all the required libraries to Android. It is an interesting project to keep in mind though!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "3", "A_Content": "  Take a look at BeeWare. At the moment of answering this question it is still in early development. It's aim is to be able to create native apps with Python for all supported operating systems, including Android.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/101754/is-there-a-way-to-run-python-on-android", "Language": "Python", "Q_Title": "Is there a way to run Python on Android? [closed]", "Q_Votes": "1938", "Q_Content": "    We are working on an S60 version and this platform has a nice Python API.   However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together?     ", "Tags": ["android", "python", "jython", "ase", "android-scripting"], "A_Votes": "3", "A_Content": "  Check out enaml-native which takes the react-native concept and applies it to python.   It lets users build apps with native Android widgets and provides APIs to use android and java libraries from python.   It also integrates with android-studio and shares a few of react's nice dev features like code reloading and remote debugging.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "1700", "A_Content": "  with open(fname) as f:     content = f.readlines() # you may also want to remove whitespace characters like `\\n` at the end of each line content = [x.strip() for x in content]       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "795", "A_Content": "  See Input and Ouput:  with open('filename') as f:     lines = f.readlines()   or with stripping the newline character:  lines = [line.rstrip('\\n') for line in open('filename')]   Editor's note: This answer's original whitespace-stripping command, line.strip(), as implied by Janus Troelsen's comment, would remove all leading and trailing whitespace, not just the trailing \\n.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "380", "A_Content": "  This is more explicit than necessary, but does what you want.  with open(\"file.txt\", \"r\") as ins:     array = []     for line in ins:         array.append(line)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "211", "A_Content": "  This will yield an \"array\" of lines from the file.  lines = tuple(open(filename, 'r'))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "153", "A_Content": "  If you want the \\n included:  with open(fname) as f:     content = f.readlines()   If you do not want \\n included:  with open(fname) as f:     content = f.read().splitlines()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "101", "A_Content": "  You could simply do the following, as has been suggested:  with open('/your/path/file') as f:     my_lines = f.readlines()   Note that this approach has 2 downsides:  1) You store all the lines in memory. In the general case, this is a very bad idea. The file could be very large, and you could run out of memory. Even if it's not large, it is simply a waste of memory.  2) This does not allow processing of each line as you read them. So if you process your lines after this, it is not efficient (requires two passes rather than one).  A better approach for the general case would be the following:  with open('/your/path/file') as f:     for line in f:         process(line)   Where you define your process function any way you want. For example:  def process(line):     if 'save the world' in line.lower():          superman.save_the_world()   (The implementation of the Superman class is left as an exercise for you).  This will work nicely for any file size and you go through your file in just 1 pass. This is typically how generic parsers will work.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "62", "A_Content": "  If you don't care about closing the file, this one-liner works:  lines = open('file.txt').read().split(\"\\n\")   The traditional way:  fp = open('file.txt') # Open file on read mode lines = fp.read().split(\"\\n\") # Create a list containing all lines fp.close() # Close file   Using with (recommended):  with open('file.txt') as fp:     lines = fp.read().split(\"\\n\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "39", "A_Content": "  This should encapsulate the open command.   array = [] with open(\"file.txt\", \"r\") as f:   for line in f:     array.append(line)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "38", "A_Content": "  Data into list  Assume that we have a text file with our data like in the following lines:  Text file content:     line 1    line 2    line 3    Open the cmd in the same directory (right click the mouse and choose cmd or PowerShell) Run python and in the interpreter write:   The Python script  >>> with open(\"myfile.txt\", encoding=\"utf-8\") as file: ...     x = [l.strip() for l in file] >>> x ['line 1','line 2','line 3']   Using append  x = [] with open(\"myfile.txt\") as file:     for l in file:         x.append(l.strip())   Or...  >>> x = open(\"myfile.txt\").read().splitlines() >>> x ['line 1', 'line 2', 'line 3']   Or...  >>> y = [x.rstrip() for x in open(\"my_file.txt\")] >>> y ['line 1','line 2','line 3']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "32", "A_Content": "  Clean and Pythonic Way of Reading the Lines of a File Into a List    First and foremost, you should focus on opening your file and reading its contents in an efficient and pythonic way. Here is an example of the way I personally DO NOT prefer:  infile = open('my_file.txt', 'r')  # Open the file for reading.  data = infile.read()  # Read the contents of the file.  infile.close()  # Close the file since we're done using it.   Instead, I prefer the below method of opening files for both reading and writing as it is very clean, and does not require an extra step of closing the file once you are done using it. In the statement below, we're opening the file for reading, and assigning it to the variable 'infile.'  Once the code within this statement has finished running, the file will be automatically closed.  # Open the file for reading. with open('my_file.txt', 'r') as infile:      data = infile.read()  # Read the contents of the file into memory.   Now we need to focus on bringing this data into a Python List because they are iterable, efficient, and flexible.  In your case, the desired goal is to bring each line of the text file into a separate element. To accomplish this, we will use the splitlines() method as follows:  # Return a list of the lines, breaking at line boundaries. my_list = data.splitlines()     The Final Product:  # Open the file for reading. with open('my_file.txt', 'r') as infile:      data = infile.read()  # Read the contents of the file into memory.  # Return a list of the lines, breaking at line boundaries. my_list = data.splitlines()   Testing Our Code:   Contents of the text file:        A fost odat\u00e3 ca-n povesti,      A fost ca niciodat\u00e3,      Din rude m\u00e3ri \u00eemp\u00e3r\u00e3testi,      O prea frumoas\u00e3 fat\u00e3.    Print statements for testing purposes:       print my_list  # Print the list.      # Print each line in the list.     for line in my_list:         print line      # Print the fourth element in this list.     print my_list[3]    Output (different-looking because of unicode characters):        ['A fost odat\\xc3\\xa3 ca-n povesti,', 'A fost ca niciodat\\xc3\\xa3,',      'Din rude m\\xc3\\xa3ri \\xc3\\xaemp\\xc3\\xa3r\\xc3\\xa3testi,', 'O prea      frumoas\\xc3\\xa3 fat\\xc3\\xa3.']       A fost odat\u00e3 ca-n povesti, A fost ca niciodat\u00e3, Din rude m\u00e3ri      \u00eemp\u00e3r\u00e3testi, O prea frumoas\u00e3 fat\u00e3.       O prea frumoas\u00e3 fat\u00e3.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "27", "A_Content": "  I'd do it like this.  lines = [] with open(\"myfile.txt\") as f:     for line in f:         lines.append(line)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "27", "A_Content": "  To read a file into a list you need to do three things:   Open the file Read the file Store the contents as list   Fortunately Python makes it very easy to do these things so the shortest way to read a file into a list is:  lst = list(open(filename))   However I'll add some more explanation.  Opening the file  I assume that you want to open a specific file and you don't deal directly with a file-handle (or a file-like-handle). The most commonly used function to open a file in Python is open, it takes one mandatory argument and two optional ones in Python 2.7:   Filename Mode Buffering (I'll ignore this argument in this answer)   The filename should be a string that represents the path to the file. For example:  open('afile')   # opens the file named afile in the current working directory open('adir/afile')            # relative path (relative to the current working directory) open('C:/users/aname/afile')  # absolute path (windows) open('/usr/local/afile')      # absolute path (linux)   Note that the file extension needs to be specified. This is especially important for Windows users because file extensions like .txt or .doc, etc. are hidden by default when viewed in the explorer.  The second argument is the mode, it's r by default which means \"read-only\". That's exactly what you need in your case.   But in case you actually want to create a file and/or write to a file you'll need a different argument here. There is an excellent answer if you want an overview.  For reading a file you can omit the mode or pass it in explicitly:  open(filename) open(filename, 'r')   Both will open the file in read-only mode. In case you want to read in a binary file on Windows you need to use the mode rb:  open(filename, 'rb')   On other platforms the 'b' (binary mode) is simply ignored.    Now that I've shown how to open the file, let's talk about the fact that you always need to close it again. Otherwise it will keep an open file-handle to the file until the process exits (or Python garbages the file-handle).   While you could use:  f = open(filename) # ... do stuff with f f.close()   That will fail to close the file when something between open and close throws an exception. You could avoid that by using a try and finally:  f = open(filename) # nothing in between! try:     # do stuff with f finally:     f.close()   However Python provides context managers that have a prettier syntax (but for open it's almost identical to the try and finally above):  with open(filename) as f:     # do stuff with f # The file is always closed after the with-scope ends.   The last approach is the recommended approach to open a file in Python!  Reading the file  Okay, you've opened the file, now how to read it?   The open function returns a file object and it supports Pythons iteration protocol. Each iteration will give you a line:  with open(filename) as f:     for line in f:         print(line)   This will print each line of the file. Note however that each line will contain a newline character \\n at the end (you might want to check if your Python is built with universal newlines support - otherwise you could also have \\r\\n on Windows or \\r on Mac as newlines). If you don't want that you can could simply remove the last character (or the last two characters on Windows):  with open(filename) as f:     for line in f:         print(line[:-1])   But the last line doesn't necessarily has a trailing newline, so one shouldn't use that. One could check if it ends with a trailing newline and if so remove it:  with open(filename) as f:     for line in f:         if line.endswith('\\n'):             line = line[:-1]         print(line)   But you could simply remove all whitespaces (including the \\n character) from the end of the string, this will also remove all other trailing whitespaces so you have to be careful if these are important:  with open(filename) as f:     for line in f:         print(f.rstrip())   However if the lines end with \\r\\n (Windows \"newlines\") that .rstrip() will also take care of the \\r!  Store the contents as list  Now that you know how to open the file and read it, it's time to store the contents in a list. The simplest option would be to use the list function:  with open(filename) as f:     lst = list(f)   In case you want to strip the trailing newlines you could use a list comprehension instead:  with open(filename) as f:     lst = [line.rstrip() for line in f]   Or even simpler: The .readlines() method of the file object by default returns a list of the lines:  with open(filename) as f:     lst = f.readlines()   This will also include the trailing newline characters, if you don't want them I would recommend the [line.rstrip() for line in f] approach because it avoids keeping two lists containing all the lines in memory.  There's an additional option to get the desired output, however it's rather \"suboptimal\": read the complete file in a string and then split on newlines:  with open(filename) as f:     lst = f.read().split('\\n')   or:  with open(filename) as f:     lst = f.read().splitlines()   These take care of the trailing newlines automatically because the split character isn't included. However they are not ideal because you keep the file as string and as a list of lines in memory!  Summary   Use with open(...) as f when opening files because you don't need to take care of closing the file yourself and it closes the file even if some exception happens. file objects support the iteration protocol so reading a file line-by-line is as simple as for line in the_file_object:. Always browse the documentation for the available functions/classes. Most of the time there's a perfect match for the task or at least one or two good ones. The obvious choice in this case would be readlines() but if you want to process the lines before storing them in the list I would recommend a simple list-comprehension.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "20", "A_Content": "  Here's one more option by using list comprehensions on files;  lines = [line.rstrip() for line in open('file.txt')]   This should be more efficient way as the most of the work is done inside the Python interpreter.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "20", "A_Content": "  Another option is numpy.genfromtxt, for example:  import numpy as np data = np.genfromtxt(\"yourfile.dat\",delimiter=\"\\n\")   This will make data a NumPy array with as many rows as are in your file.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "18", "A_Content": "  If you'd like to read a file from the command line or from stdin, you can also use the fileinput module:  # reader.py import fileinput  content = [] for line in fileinput.input():     content.append(line.strip())  fileinput.close()   Pass files to it like so:  $ python reader.py textfile.txt    Read more here: http://docs.python.org/2/library/fileinput.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "2581", "A_Content": "  >>> d = {'key':'value'} >>> print(d) {'key': 'value'} >>> d['mynewkey'] = 'mynewvalue' >>> print(d) {'mynewkey': 'mynewvalue', 'key': 'value'}      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "2121", "A_Content": "  >>> a = \"545.2222\" >>> float(a) 545.22220000000004 >>> int(float(a)) 545      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "15", "A_Content": "  The simplest way to do it  A simple way is to:   Read the whole file as a string Split the string line by line   In one line, that would give:  lines = open('C:/path/file.txt').read().splitlines()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "14", "A_Content": "  f = open(\"your_file.txt\",'r') out = f.readlines() # will append in the list out   Now variable out is a list (array) of what you want. You could either do:  for line in out:     print line   or  for line in f:     print line   you'll get the same results.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "13", "A_Content": "  Just use the splitlines() functions. Here is an example.  inp = \"file.txt\" data = open(inp) dat = data.read() lst = dat.splitlines() print lst # print(lst) # for python 3   In the output you will have the list of lines.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "13", "A_Content": "  A real easy way:  with open(file) as g:     stuff = g.readlines()   If you want to make it a fully-fledged program, type this in:  file = raw_input (\"Enter EXACT file name: \") with open(file) as g:     stuff = g.readlines() print (stuff) exit = raw_input(\"Press enter when you are done.\")   For some reason, it doesn't read .py files properly.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "13", "A_Content": "  Read and write text files with Python 2 and Python 3; it works with Unicode  #!/usr/bin/env python3 # -*- coding: utf-8 -*-  # Define data lines = ['     A first string  ',          'A Unicode sample: \u20ac',          'German: \u00e4\u00f6\u00fc\u00df']  # Write text file with open('file.txt', 'w') as fp:     fp.write('\\n'.join(lines))  # Read text file with open('file.txt', 'r') as fp:     read_lines = fp.readlines()     read_lines = [line.rstrip('\\n') for line in read_lines]  print(lines == read_lines)   Things to notice:   with is a so-called context manager. It makes sure that the opened file is closed again. All solutions here which simply make .strip() or .rstrip() will fail to reproduce the lines as they also strip the white space.   Common file endings  .txt  More advanced file writing / reading   CSV: Super simple format (read & write) JSON: Nice for writing human-readable data; VERY commonly used (read & write) YAML: YAML is a superset of JSON, but easier to read (read & write, comparison of JSON and YAML) pickle: A Python serialization format (read & write) MessagePack (Python package): More compact representation (read & write) HDF5 (Python package): Nice for matrices (read & write) XML: exists too *sigh* (read & write)   For your application, the following might be important:   Support by other programming languages Reading / writing performance Compactness (file size)   See also: Comparison of data serialization formats  In case you are rather looking for a way to make configuration files, you might want to read my short article Configuration files in Python.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "12", "A_Content": "  You can just open your file for reading using:  file1 = open(\"filename\",\"r\") # And for reading use lines = file1.readlines() file1.close()   The list lines will contain all your lines as individual elements, and you can call a specific element using lines[\"linenumber-1\"] as Python starts its counting from 0.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "9", "A_Content": "  If you want to are faced with a very large / huge file and want to read faster (imagine you are in a Topcoder/Hackerrank coding competition), you might read a considerably bigger chunk of lines into a memory buffer at one time, rather than just iterate line by line at file level.  buffersize = 2**16 with open(path) as f:      while True:         lines_buffer = f.readlines(buffersize)         if not lines_buffer:             break         for line in lines_buffer:             process(line)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "7", "A_Content": "  To my knowledge Python doesn't have a native array data structure. But it does support the list data structure which is much simpler to use than an array.  array = [] #declaring a list with name '**array**' with open(PATH,'r') as reader :     for line in reader :         array.append(line)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "5", "A_Content": "  Use this:  import pandas as pd data = pd.read_csv(filename) # You can also add parameters such as header, sep, etc. array = data.values   data is a dataframe type, and uses values to get ndarray. You can also get a list by using array.tolist().     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "4", "A_Content": "  You can easily do it by the following piece of code:  lines = open(filePath).readlines()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "4", "A_Content": "  Introduced in Python 3.4, pathlib has a really convenient method for reading in text from files, as follows:  from pathlib import Path p = Path('my_text_file') lines = p.read_text().splitlines()   (The splitlines call is what turns it from a string containing the whole contents of the file to a list of lines in the file).  pathlib has a lot of handy conveniences in it. read_text is nice and concise, and you don't have to worry about opening and closing the file. If all you need to do with the file is read it all in in one go, it's a good choice.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "4", "A_Content": "  You could also use the loadtxt command in NumPy. This checks for fewer conditions than genfromtxt, so it may be faster.  import numpy data = numpy.loadtxt(filename, delimiter=\"\\n\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "2", "A_Content": "  Command line version  #!/bin/python3 import os import sys abspath = os.path.abspath(__file__) dname = os.path.dirname(abspath) filename = dname + sys.argv[1] arr = open(filename).read().split(\"\\n\")  print(arr)   Run with:  python3 somefile.py input_file_name.txt      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "2", "A_Content": "  I like to use the following. Reading the lines immediately.  contents = [] for line in open(filepath, 'r').readlines():     contents.append(line.strip())   Or using list comprehension:  contents = [line.strip() for line in open(filepath, 'r').readlines()]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3277503/in-python-how-do-i-read-a-file-line-by-line-into-a-list", "Language": "Python", "Q_Title": "In Python, how do I read a file line-by-line into a list?", "Q_Votes": "1753", "Q_Content": "    How do I read every line of a file in Python and store each line as an element in a list?   I want to read the file line by line and append each line to the end of the list.     ", "Tags": ["python", "string", "file", "readlines"], "A_Votes": "1", "A_Content": "  Outline and Summary  With a filename, handling the file from a Path(filename) object, or directly with open(filename) as f, do one of the following:   list(fileinput.input(filename)) using with path.open() as f, call f.readlines()  list(f) path.read_text().splitlines() path.read_text().splitlines(keepends=True) iterate over fileinput.input or f and list.append each line one at a time pass f to a bound list.extend method use f in a list comprehension   I explain the use-case for each below.     In Python, how do I read a file line-by-line?   This is an excellent question. First, let's create some sample data:  from pathlib import Path Path('filename').write_text('foo\\nbar\\nbaz')   File objects are lazy iterators, so just iterate over it.  filename = 'filename' with open(filename) as f:     for line in f:         line # do something with the line   Alternatively, if you have multiple files, use fileinput.input, another lazy iterator. With just one file:  import fileinput  for line in fileinput.input(filename):      line # process the line   or for multiple files, pass it a list of filenames:  for line in fileinput.input([filename]*2):      line # process the line   Again, f and fileinput.input above both are/return lazy iterators. You can only use an iterator one time, so to provide functional code while avoiding verbosity I'll use the slightly more terse fileinput.input(filename) where apropos from here.     In Python, how do I read a file line-by-line into a list?   Ah but you want it in a list for some reason? I'd avoid that if possible. But if you insist... just pass the result of fileinput.input(filename) to list:  list(fileinput.input(filename))   Another direct answer is to call f.readlines, which returns the contents of the file (up to an optional hint number of characters, so you could break this up into multiple lists that way).   You can get to this file object two ways. One way is to pass the filename to the open builtin:  filename = 'filename'  with open(filename) as f:     f.readlines()   or using the new Path object from the pathlib module (which I have become quite fond of, and will use from here on):  from pathlib import Path  path = Path(filename)  with path.open() as f:     f.readlines()   list will also consume the file iterator and return a list - a quite direct method as well:  with path.open() as f:     list(f)   If you don't mind reading the entire text into memory as a single string before splitting it, you can do this as a one-liner with the Path object and the splitlines() string method. By default, splitlines removes the newlines:  path.read_text().splitlines()   If you want to keep the newlines, pass keepends=True:  path.read_text().splitlines(keepends=True)      I want to read the file line by line and append each line to the end of the list.   Now this is a bit silly to ask for, given that we've demonstrated the end result easily with several methods. But you might need to filter or operate on the lines as you make your list, so let's humor this request.  Using list.append would allow you to filter or operate on each line before you append it:  line_list = [] for line in fileinput.input(filename):     line_list.append(line)  line_list   Using list.extend would be a bit more direct, and perhaps useful if you have a preexisting list:  line_list = [] line_list.extend(fileinput.input(filename)) line_list   Or more idiomatically, we could instead use a list comprehension, and map and filter inside it if desirable:  [line for line in fileinput.input(filename)]   Or even more directly, to close the circle, just pass it to list to create a new list directly without operating on the lines:  list(fileinput.input(filename))   Conclusion  You've seen many ways to get lines from a file into a list, but I'd recommend you avoid materializing large quantities of data into a list and instead use Python's lazy iteration to process the data if possible.  That is, prefer fileinput.input or with path.open() as f.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "857", "A_Content": "  >>> x = {1:2} >>> print x {1: 2}  >>> x.update({3:4}) >>> print x {1: 2, 3: 4}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "617", "A_Content": "  I feel like consolidating info about Python dictionaries:  Creating an empty dictionary  data = {} # OR data = dict()   Creating a dictionary with initial values  data = {'a':1,'b':2,'c':3} # OR data = dict(a=1, b=2, c=3) # OR data = {k: v for k, v in (('a', 1),('b',2),('c',3))}   Inserting/Updating a single value  data['a']=1  # Updates if 'a' exists, else adds 'a' # OR data.update({'a':1}) # OR data.update(dict(a=1)) # OR data.update(a=1)   Inserting/Updating multiple values  data.update({'c':3,'d':4})  # Updates 'c' and adds 'd'   Creating a merged dictionary without modifying originals  data3 = {} data3.update(data)  # Modifies data3, not data data3.update(data2)  # Modifies data3, not data2   Deleting items in dictionary  del data[key]  # Removes specific element in a dictionary data.pop(key)  # Removes the key & returns the value data.clear()  # Clears entire dictionary   Check if a key is already in dictionary  key in data   Iterate through pairs in a dictionary  for key in data: # Iterates just through the keys, ignoring the values for key, value in d.items(): # Iterates through the pairs for key in d.keys(): # Iterates just through key, ignoring the values for value in d.values(): # Iterates just through value, ignoring the keys   Create a dictionary from 2 lists  data = dict(zip(list_with_keys, list_with_values))   Feel free to add more!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "134", "A_Content": "  Yeah, it's pretty easy. Just do the following:  dict[\"key\"] = \"value\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "105", "A_Content": "     \"Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.\"   Yes it is possible, and it does have a method that implements this, but you don't want to use it directly.  To demonstrate how and how not to use it, let's create an empty dict with the dict literal, {}:  my_dict = {}   Best Practice 1: Subscript notation  To update this dict with a single new key and value, you can use the subscript notation (see Mappings here) that provides for item assignment:   my_dict['new key'] = 'new value'   my_dict is now:  {'new key': 'new value'}   Best Practice 2: The update method - 2 ways  We can also update the dict with multiple values efficiently as well using the update method.  We may be unnecessarily creating an extra dict here, so we hope our dict has already been created and came from or was used for another purpose:  my_dict.update({'key 2': 'value 2', 'key 3': 'value 3'})   my_dict is now:  {'key 2': 'value 2', 'key 3': 'value 3', 'new key': 'new value'}   Another efficient way of doing this with the update method is with keyword arguments, but since they have to be legitimate python words, you can't have spaces or special symbols or start the name with a number, but many consider this a more readable way to create keys for a dict, and here we certainly avoid creating an extra unnecessary dict:  my_dict.update(foo='bar', foo2='baz')   and my_dict is now:  {'key 2': 'value 2', 'key 3': 'value 3', 'new key': 'new value',   'foo': 'bar', 'foo2': 'baz'}   So now we have covered three Pythonic ways of updating a dict.     Magic method, __setitem__, and why it should be avoided  There's another way of updating a dict that you shouldn't use, which uses the __setitem__ method. Here's an example of how one might use the __setitem__ method to add a key-value pair to a dict, and a demonstration of the poor performance of using it:  >>> d = {} >>> d.__setitem__('foo', 'bar') >>> d {'foo': 'bar'}   >>> def f(): ...     d = {} ...     for i in xrange(100): ...         d['foo'] = i ...  >>> def g(): ...     d = {} ...     for i in xrange(100): ...         d.__setitem__('foo', i) ...  >>> import timeit >>> number = 100 >>> min(timeit.repeat(f, number=number)) 0.0020880699157714844 >>> min(timeit.repeat(g, number=number)) 0.005071878433227539   So we see that using the subscript notation is actually much faster than using __setitem__. Doing the Pythonic thing, that is, using the language in the way it was intended to be used, usually is both more readable and computationally efficient.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "73", "A_Content": "  dictionary[key] = value      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "44", "A_Content": "  If you want to add a dictionary within a dictionary you can do it this way.   Example: Add a new entry to your dictionary & sub dictionary  dictionary = {} dictionary[\"new key\"] = \"some new entry\" # add new dictionary entry dictionary[\"dictionary_within_a_dictionary\"] = {} # this is required by python dictionary[\"dictionary_within_a_dictionary\"][\"sub_dict\"] = {\"other\" : \"dictionary\"} print (dictionary)   Output:  {'new key': 'some new entry', 'dictionary_within_a_dictionary': {'sub_dict': {'other': 'dictionarly'}}}   NOTE: Python requires that you first add a sub    dictionary[\"dictionary_within_a_dictionary\"] = {}   before adding entries.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "31", "A_Content": "  The orthodox syntax is d[key] = value, but if your keyboard is missing the square bracket keys you could do:  d.__setitem__(key, value)   In fact, defining __getitem__ and __setitem__ methods is how you can make your own class support the  square bracket syntax. See http://www.diveintopython.net/object_oriented_framework/special_class_methods.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "25", "A_Content": "  you can create one  class myDict(dict):      def __init__(self):         self = dict()      def add(self, key, value):         self[key] = value  ## example  myd = myDict() myd.add('apples',6) myd.add('bananas',3) print(myd)   gives  >>>  {'apples': 6, 'bananas': 3}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "25", "A_Content": "  This popular question addresses functional methods of merging dictionaries a and b.  Here are some of the more straightforward methods (tested in Python 3)...  c = dict( a, **b ) ## see also https://stackoverflow.com/q/2255878 c = dict( list(a.items()) + list(b.items()) ) c = dict( i for d in [a,b] for i in d.items() )   Note: The first method above only works if the keys in b are strings.  To add or modify a single element, the b dictionary would contain only that one element...  c = dict( a, **{'d':'dog'} ) ## returns a dictionary based on 'a'   This is equivalent to...  def functional_dict_add( dictionary, key, value ):    temp = dictionary.copy()    temp[key] = value    return temp  c = functional_dict_add( a, 'd', 'dog' )      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "15", "A_Content": "  data = {} data['a'] = 'A' data['b'] = 'B'  for key, value in data.iteritems():     print \"%s-%s\" % (key, value)   results in   a-A b-B      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "9", "A_Content": "  This is exactly how I would do it:     # fixed data with sapce  data = {} data['f'] = 'F' data['c'] = 'C'  for key, value in data.iteritems():     print \"%s-%s\" % (key, value)   This works for me. Enjoy!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "9", "A_Content": "  Let's pretend you want to live in the immutable world and do NOT want to modify the original but want to create a new dict that is the result of adding a new key to the original.  In Python 3.5+ you can do:  params = {'a': 1, 'b': 2} new_params = {**params, **{'c': 3}}   The Python 2 equivalent is:  params = {'a': 1, 'b': 2} new_params = dict(params, **{'c': 3})   After either of these:  params is still equal to {'a': 1, 'b': 2}  and  new_params is equal to {'a': 1, 'b': 2, 'c': 3}  There will be times when you don't want to modify the original (you only want the result of adding to the original). I find this a refreshing alternative to the following:  params = {'a': 1, 'b': 2} new_params = params.copy() new_params['c'] = 3   or  params = {'a': 1, 'b': 2} new_params = params.copy() new_params.update({'c': 3})   Reference: https://stackoverflow.com/a/2255892/514866     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "8", "A_Content": "  we can add new keys to dictionary by this way:     Dictionary_Name[New_Key_Name] = New_Key_Value   Here is the Example:  # This is my dictionary my_dict = {'Key1': 'Value1', 'Key2': 'Value2'} # Now add new key in my dictionary my_dict['key3'] = 'Value3' # Print updated dictionary print my_dict   Output:  {'key3': 'Value3', 'Key2': 'Value2', 'Key1': 'Value1'}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "6", "A_Content": "  So many answers and still everybody forgot about the strangely named, oddly behaved, and yet still handy dict.setdefault()  This  value = my_dict.setdefault(key, default)   basically just does this:  try:     value = my_dict[key] except KeyError: # key not found     value = my_dict[key] = default   e.g.  >>> mydict = {'a':1, 'b':2, 'c':3} >>> mydict.setdefault('d', 4) 4 # returns new value at mydict['d'] >>> print(mydict) {'a':1, 'b':2, 'c':3, 'd':4} # a new key/value pair was indeed added # but see what happens when trying it on an existing key... >>> mydict.setdefault('a', 111) 1 # old value was returned >>> print(mydict) {'a':1, 'b':2, 'c':3, 'd':4} # existing key was ignored      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "4", "A_Content": "  It has a update method which you can use like this:  dict.update({\"key\" : \"value\"})     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "4", "A_Content": "  Basically two simple ways with which you can add new key in the dict  dict_input = {'one': 1, 'two': 2, 'three': 3}  #1. Set a new value dict_input['four'] = 4  #2. or use the update() function dict_input.update({'five': 5})      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "0", "A_Content": "  I would do it like this. Watch out for the directory[name]=number part.  n = int(raw_input()) directory={} entry={} # store the values as if they appear in the stdin for i in xrange(n):     name, number = raw_input().split()     directory[name]=number  #  query the values     while (True):     queryname = (str) (raw_input())     try:         strdisp = queryname + \"=\" + directory[queryname]         print strdisp     except:       print 'Not found'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "448", "A_Content": "  def num(s):     try:         return int(s)     except ValueError:         return float(s)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "424", "A_Content": "  Python method to check if a string is a float:  def is_float(value):   try:     float(value)     return True   except:     return False   A longer and more accurate name for this function could be: is_convertible_to_float(value)  What is, and is not a float in Python may surprise you:  val                   is_float(val) Note --------------------  ----------   -------------------------------- \"\"                    False        Blank string \"127\"                 True         Passed string True                  True         Pure sweet Truth \"True\"                False        Vile contemptible lie False                 True         So false it becomes true \"123.456\"             True         Decimal \"      -127    \"      True         Spaces trimmed \"\\t\\n12\\r\\n\"          True         whitespace ignored \"NaN\"                 True         Not a number \"NaNanananaBATMAN\"    False        I am Batman \"-iNF\"                True         Negative infinity \"123.E4\"              True         Exponential notation \".1\"                  True         mantissa only \"1,234\"               False        Commas gtfo u'\\x30'               True         Unicode is fine. \"NULL\"                False        Null is not special 0x3fade               True         Hexadecimal \"6e7777777777777\"     True         Shrunk to infinity \"1.797693e+308\"       True         This is max value \"infinity\"            True         Same as inf \"infinityandBEYOND\"   False        Extra characters wreck it \"12.34.56\"            False        Only one dot allowed u'\u56db'                 False        Japanese '4' is not a float. \"#56\"                 False        Pound sign \"56%\"                 False        Percent of what? \"0E0\"                 True         Exponential, move dot 0 places 0**0                  True         0___0  Exponentiation \"-5e-5\"               True         Raise to a negative number \"+1e1\"                True         Plus is OK with exponent \"+1e1^5\"              False        Fancy exponent not interpreted \"+1e1.3\"              False        No decimals in exponent \"-+1\"                 False        Make up your mind \"(1)\"                 False        Parenthesis is bad   You think you know what numbers are? You are not so good as you think! Not big surprise.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "105", "A_Content": "  This is another method which deserves to be mentioned here, ast.literal_eval:     This can be used for safely evaluating strings containing Python expressions from untrusted sources without the need to parse the values oneself.   That is, a safe 'eval'  >>> import ast >>> ast.literal_eval(\"545.2222\") 545.2222 >>> ast.literal_eval(\"31\") 31      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "74", "A_Content": "  float(x) if '.' in x else int(x)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "46", "A_Content": "  Localization and commas  You should consider the possibility of commas in the string representation of a number, for cases like  float(\"545,545.2222\") which throws an exception. Instead, use methods in locale to convert the strings to numbers and interpret commas correctly. The locale.atof method converts to a float in one step once the locale has been set for the desired number convention.  Example 1 -- United States number conventions   In the United States and the UK, commas can be used as a thousands separator.  In this example with American locale, the comma is handled properly as a separator:  >>> import locale >>> a = u'545,545.2222' >>> locale.setlocale(locale.LC_ALL, 'en_US.UTF-8') 'en_US.UTF-8' >>> locale.atof(a) 545545.2222 >>> int(locale.atof(a)) 545545 >>>   Example 2 -- European number conventions  In the majority of countries of the world,  commas are used for decimal marks instead of periods.  In this example with French locale, the comma is correctly handled as a decimal mark:  >>> import locale >>> b = u'545,2222' >>> locale.setlocale(locale.LC_ALL, 'fr_FR') 'fr_FR' >>> locale.atof(b) 545.2222   The method locale.atoi is also available, but the argument should be an integer.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "22", "A_Content": "  Users codelogic and harley are correct, but keep in mind if you know the string is an integer (for example, 545) you can call int(\"545\") without first casting to float.  If your strings are in a list, you could use the map function as well.   >>> x = [\"545.0\", \"545.6\", \"999.2\"] >>> map(float, x) [545.0, 545.60000000000002, 999.20000000000005] >>>   It is only good if they're all the same type.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "21", "A_Content": "  If you aren't averse to third-party modules, you could check out the fastnumbers module. It provides a function called fast_real that does exactly what this question is asking for and does it faster than a pure-Python implementation:  >>> from fastnumbers import fast_real >>> fast_real(\"545.2222\") 545.2222 >>> type(fast_real(\"545.2222\")) float >>> fast_real(\"31\") 31 >>> type(fast_real(\"31\")) int      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "17", "A_Content": "     In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?   I just want to know how to parse a float string to a float, and (separately) an int string to an int.   It's good that you ask to do these separately. If you're mixing them, you may be setting yourself up for problems later. The simple answer is:  \"545.2222\" to float:  >>> float(\"545.2222\") 545.2222   \"31\" to an integer:  >>> int(\"31\") 31   Other conversions, ints to and from strings and literals:  Conversions from various bases, and you should know the base in advance (10 is the default). Note you can prefix them with what Python expects for its literals (see below) or remove the prefix:  >>> int(\"0b11111\", 2) 31 >>> int(\"11111\", 2) 31 >>> int('0o37', 8) 31 >>> int('37', 8) 31 >>> int('0x1f', 16) 31 >>> int('1f', 16) 31   If you don't know the base in advance, but you do know they will have the correct prefix, Python can infer this for you if you pass 0 as the base:  >>> int(\"0b11111\", 0) 31 >>> int('0o37', 0) 31 >>> int('0x1f', 0) 31   Non-Decimal (i.e. Integer) Literals from other Bases  If your motivation is to have your own code clearly represent hard-coded specific values, however, you may not need to convert from the bases - you can let Python do it for you automatically with the correct syntax.  You can use the apropos prefixes to get automatic conversion to integers with the following literals. These are valid for Python 2 and 3:  Binary, prefix 0b  >>> 0b11111 31   Octal, prefix 0o  >>> 0o37 31   Hexadecimal, prefix 0x  >>> 0x1f 31   This can be useful when describing binary flags, file permissions in code, or hex values for colors - for example, note no quotes:  >>> 0b10101 # binary flags 21 >>> 0o755 # read, write, execute perms for owner, read & ex for group & others 493 >>> 0xffffff # the color, white, max values for red, green, and blue 16777215   Making ambiguous Python 2 octals compatible with Python 3  If you see an integer that starts with a 0, in Python 2, this is (deprecated) octal syntax.  >>> 037 31   It is bad because it looks like the value should be 37. So in Python 3, it now raises a SyntaxError:  >>> 037   File \"<stdin>\", line 1     037       ^ SyntaxError: invalid token   Convert your Python 2 octals to octals that work in both 2 and 3 with the 0o prefix:  >>> 0o37 31      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "16", "A_Content": "  The question seems a little bit old. But let me suggest a function, parseStr, which makes something similar, that is, returns integer or float and if a given ASCII string cannot be converted to none of them it returns it untouched. The code of course might be adjusted to do only what you want:     >>> import string    >>> parseStr = lambda x: x.isalpha() and x or x.isdigit() and \\    ...                      int(x) or x.isalnum() and x or \\    ...                      len(set(string.punctuation).intersection(x)) == 1 and \\    ...                      x.count('.') == 1 and float(x) or x    >>> parseStr('123')    123    >>> parseStr('123.3')    123.3    >>> parseStr('3HC1')    '3HC1'    >>> parseStr('12.e5')    1200000.0    >>> parseStr('12$5')    '12$5'    >>> parseStr('12.2.2')    '12.2.2'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "14", "A_Content": "  float(\"545.2222\") and int(float(\"545.2222\"))     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "12", "A_Content": "  The YAML parser can help you figure out what datatype your string is. Use yaml.load(), and then you can use type(result) to test for type:  >>> import yaml  >>> a = \"545.2222\" >>> result = yaml.load(a) >>> result 545.22220000000004 >>> type(result) <type 'float'>  >>> b = \"31\" >>> result = yaml.load(b) >>> result 31 >>> type(result) <type 'int'>  >>> c = \"HI\" >>> result = yaml.load(c) >>> result 'HI' >>> type(result) <type 'str'>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "11", "A_Content": "  def get_int_or_float(v):     number_as_float = float(v)     number_as_int = int(number_as_float)     return number_as_int if number_as_float == number_as_int else number_as_float      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "8", "A_Content": "  I use this function for that  import ast  def parse_str(s):    try:       return ast.literal_eval(str(s))    except:       return   It will convert the string to its type  value = parse_str('1')  # Returns Integer value = parse_str('1.5')  # Returns Float      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "7", "A_Content": "  You need to take into account rounding to do this properly.  I.e. int(5.1) => 5      int(5.6) => 5  -- wrong, should be 6 so we do int(5.6 + 0.5) => 6  def convert(n):     try:         return int(n)     except ValueError:         return float(n + 0.5)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "7", "A_Content": "  def num(s): \"\"\"num(s) num(3),num(3.7)-->3 num('3')-->3, num('3.7')-->3.7 num('3,700')-->ValueError num('3a'),num('a3'),-->ValueError num('3e4') --> 30000.0 \"\"\" try:     return int(s) except ValueError:     try:         return float(s)     except ValueError:         raise ValueError('argument is not a string of number')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "3", "A_Content": "  This is a corrected version of  https://stackoverflow.com/a/33017514/5973334  This will try to parse a string and return either int or float depending on what the string represents. It might rise parsing exceptions or have some unexpected behaviour.    def get_int_or_float(v):         number_as_float = float(v)         number_as_int = int(number_as_float)         return number_as_int if number_as_float == number_as_int else          number_as_float      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "2084", "A_Content": "  Use:  >>> import datetime >>> datetime.datetime.now() datetime(2009, 1, 6, 15, 8, 24, 78915)  >>> print(datetime.datetime.now()) 2018-07-29 09:17:13.812189   And just the time:  >>> datetime.datetime.time(datetime.datetime.now()) datetime.time(15, 8, 24, 78915)  >>> print(datetime.datetime.time(datetime.datetime.now())) 09:17:51.914526   The same, but slightly more compact:  >>> datetime.datetime.now().time()   See the documentation for more information.  To save typing, you can import the datetime object from the datetime module:  >>> from datetime import datetime   Then remove the leading datetime. from all of the above.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "2308", "A_Content": "  import time time.sleep(5)   # Delays for 5 seconds. You can also use a float value.   Here is another example where something is run approximately once a minute:  import time while True:     print(\"This prints once a minute.\")     time.sleep(60) # Delay for 1 minute (60 seconds).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1024847/add-new-keys-to-a-dictionary", "Language": "Python", "Q_Title": "Add new keys to a dictionary?", "Q_Votes": "1965", "Q_Content": "    Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.     ", "Tags": ["python", "dictionary"], "A_Votes": "-1", "A_Content": "  Use the subscript assignment operator:   d['x'] = \"value\"   Don't forget that Python's key can by anything hashable which means bool, int, string even a tuple or any objects hashable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "3", "A_Content": "  I am surprised nobody mentioned regex because sometimes string must be prepared and normalized before casting to number  import re def parseNumber(value, as_int=False):     try:         number = float(re.sub('[^.\\-\\d]', '', value))         if as_int:             return int(number + 0.5)         else:             return number     except ValueError:         return float('nan')  # or None if you wish   usage:  parseNumber('13,345') > 13345.0  parseNumber('- 123 000') > -123000.0  parseNumber('99999\\n') > 99999.0   and by the way, something to verify you have a number:  import numbers def is_number(value):     return isinstance(value, numbers.Number)     # will work with int, float, long, Decimal      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "3", "A_Content": "  Python have this great flexibility of parsing in one liners.   str = \"545.2222\" print (\"int: \", + int(float(a))) print (\"float: \", +(float(a)))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "2", "A_Content": "  To typecast in python use the constructor funtions of the type, passing the string (or whatever value you are trying to cast) as a parameter.  For example:  >>>float(\"23.333\")    23.333   Behind the scenes, python is calling the objects __float__ method, which should return a float representation of the parameter. This is especially powerful, as you can define your own types (using classes) with a __float__ method so that it can be casted into a float using float(myobject).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "1", "A_Content": "  Use:  def num(s):     try:         for each in s:             yield int(each)     except ValueError:         yield float(each) a = num([\"123.55\",\"345\",\"44\"]) print a.next() print a.next()   This is the most Pythonic way I could come up with.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/379906/how-do-i-parse-a-string-to-a-float-or-int-in-python", "Language": "Python", "Q_Title": "How do I parse a string to a float or int in Python?", "Q_Votes": "1792", "Q_Content": "    In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?  I just want to know how to parse a float string to a float, and (separately) an int string to an int.     ", "Tags": ["python", "parsing", "floating-point", "type-conversion", "integer"], "A_Votes": "0", "A_Content": "  Use:  >>> str_float = \"545.2222\" >>> float(str_float) 545.2222 >>> type(_) # Check its type <type 'float'>  >>> str_int = \"31\" >>> int(str_int) 31 >>> type(_) # Check its type <type 'int'>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "795", "A_Content": "  You can use time.strftime():      >>> from time import gmtime, strftime >>> strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) '2009-01-05 22:14:39'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "411", "A_Content": "  Similar to Harley's answer, but use the str() function for a quick-n-dirty, slightly more human readable format:  >>> from datetime import datetime >>> str(datetime.now()) '2011-05-03 17:45:35.177000'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "376", "A_Content": "  >>> from datetime import datetime >>> datetime.now().strftime('%Y-%m-%d %H:%M:%S')   For this example, the output will be like this: '2013-09-18 11:16:32'  Here is the list of strftime.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "217", "A_Content": "     How do I get the current time in Python?   The time module  The time module provides functions that tells us the time in \"seconds since the epoch\" as well as other utilities.  import time   Unix Epoch Time  This is the format you should get timestamps in for saving in databases. It is a simple floating point number that can be converted to an integer. It is also good for arithmetic in seconds, as it represents the number of seconds since Jan 1, 1970 00:00:00, and it is memory light relative to the other representations of time we'll be looking at next:  >>> time.time() 1424233311.771502   This timestamp does not account for leap-seconds, so it's not linear - leap seconds are ignored. So while it is not equivalent to the international UTC standard, it is close, and therefore quite good for most cases of record-keeping.   This is not ideal for human scheduling, however. If you have a future event you wish to take place at a certain point in time, you'll want to store that time with a string that can be parsed into a datetime object or a serialized datetime object (these will be described later).  time.ctime  You can also represent the current time in the way preferred by your operating system (which means it can change when you change your system preferences, so don't rely on this to be standard across all systems, as I've seen others expect). This is typically user friendly, but doesn't typically result in strings one can sort chronologically:  >>> time.ctime() 'Tue Feb 17 23:21:56 2015'   You can hydrate timestamps into human readable form with ctime as well:  >>> time.ctime(1424233311.771502) 'Tue Feb 17 23:21:51 2015'   This conversion is also not good for record-keeping (except in text that will only be parsed by humans - and with improved Optical Character Recognition and Artificial Intelligence, I think the number of these cases will diminish).  datetime module  The datetime module is also quite useful here:  >>> import datetime   datetime.datetime.now  The datetime.now is a class method that returns the current time. It uses the time.localtime without the timezone info (if not given, otherwise see timezone aware below). It has a representation (which would allow you to recreate an equivalent object) echoed on the shell, but when printed (or coerced to a str), it is in human readable (and nearly ISO) format, and the lexicographic sort is equivalent to the chronological sort:  >>> datetime.datetime.now() datetime.datetime(2015, 2, 17, 23, 43, 49, 94252) >>> print(datetime.datetime.now()) 2015-02-17 23:43:51.782461   datetime's utcnow  You can get a datetime object in UTC time, a global standard, by doing this:  >>> datetime.datetime.utcnow() datetime.datetime(2015, 2, 18, 4, 53, 28, 394163) >>> print(datetime.datetime.utcnow()) 2015-02-18 04:53:31.783988   UTC is a time standard that is nearly equivalent to the GMT timezone. (While GMT and UTC do not change for Daylight Savings Time, their users may switch to other timezones, like British Summer Time, during the Summer.)   datetime timezone aware  However, none of the datetime objects we've created so far can be easily converted to various timezones. We can solve that problem with the pytz module:  >>> import pytz >>> then = datetime.datetime.now(pytz.utc) >>> then datetime.datetime(2015, 2, 18, 4, 55, 58, 753949, tzinfo=<UTC>)   Equivalently, in Python 3 we have the timezone class with a utc timezone instance attached, which also makes the object timezone aware (but to convert to another timezone without the handy pytz module is left as an exercise to the reader):  >>> datetime.datetime.now(datetime.timezone.utc) datetime.datetime(2015, 2, 18, 22, 31, 56, 564191, tzinfo=datetime.timezone.utc)   And we see we can easily convert to timezones from the original utc object.  >>> print(then) 2015-02-18 04:55:58.753949+00:00 >>> print(then.astimezone(pytz.timezone('US/Eastern'))) 2015-02-17 23:55:58.753949-05:00   You can also make a naive datetime object aware with the pytz timezone localize method, or by replacing the tzinfo attribute (with replace, this is done blindly), but these are more last resorts than best practices:  >>> pytz.utc.localize(datetime.datetime.utcnow()) datetime.datetime(2015, 2, 18, 6, 6, 29, 32285, tzinfo=<UTC>) >>> datetime.datetime.utcnow().replace(tzinfo=pytz.utc) datetime.datetime(2015, 2, 18, 6, 9, 30, 728550, tzinfo=<UTC>)   The pytz module allows us to make our datetime objects timezone aware and convert the times to the hundreds of timezones available in the pytz module.  One could ostensibly serialize this object for UTC time and store that in a database, but it would require far more memory and be more prone to error than simply storing the Unix Epoch time, which I demonstrated first.   The other ways of viewing times are much more error prone, especially when dealing with data that may come from different time zones. You want there to be no confusion as to which timezone a string or serialized datetime object was intended for.  If you're displaying the time with Python for the user, ctime works nicely, not in a table (it doesn't typically sort well), but perhaps in a clock. However, I personally recommend, when dealing with time in Python, either using Unix time, or a timezone aware UTC datetime object.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "114", "A_Content": "  Do  from time import time  t = time()    t - float number, good for time interval measurement.   There is some difference for Unix and Windows platforms.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "83", "A_Content": "  >>> from time import gmtime, strftime >>> strftime(\"%a, %d %b %Y %X +0000\", gmtime()) 'Tue, 06 Jan 2009 04:54:56 +0000'   That outputs the current GMT in the specified format. There is also a localtime() method.   This page has more details.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "44", "A_Content": "  All good suggestions, but I find it easiest to use ctime() myself:  In [2]: from time import ctime In [3]: ctime() Out[3]: 'Thu Oct 31 11:40:53 2013'   This gives a nicely formatted string representation of current local time.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "35", "A_Content": "  If you need current time as a time object:  >>> import datetime >>> now = datetime.datetime.now() >>> datetime.time(now.hour, now.minute, now.second) datetime.time(11, 23, 44)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "34", "A_Content": "  Quickest way is  >>> import time >>> time.strftime(\"%Y%m%d\") '20130924'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "31", "A_Content": "  Simple and easy:  Using the datetime module,  import datetime print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))   Output:  2017-10-17 23:48:55   OR  Using time,  import time print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))   Output:  2017-10-17 18:22:26      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "26", "A_Content": "  Why not ask the U.S. Naval Observatory, the official timekeeper of the United States Navy?  import requests from lxml import html  page = requests.get('http://tycho.usno.navy.mil/cgi-bin/timer.pl') tree = html.fromstring(page.content) print(tree.xpath('//html//body//h3//pre/text()')[1])   If you live in the D.C. area (like me) the latency might not be too bad...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "26", "A_Content": "  .isoformat() is in the documentation, but not yet here (this is mighty similar to @Ray Vega's answer):  >>> import datetime >>> datetime.datetime.now().isoformat() '2013-06-24T20:35:55.982000'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "16", "A_Content": "  This is what I ended up going with:   >>>from time import strftime >>>strftime(\"%m/%d/%Y %H:%M\") 01/09/2015 13:11   Also, this table is a necessary reference for choosing the appropriate format codes to get the date formatted just the way you want it (from Python \"datetime\" documentation here).       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "11", "A_Content": "  You can use the time module.  import time print time.strftime(\"%d/%m/%Y\")  >>> 06/02/2015   The use of the capital Y gives the full year, and using y would give 06/02/15.  You could also use to give a more lengthy time.  time.strftime(\"%a, %d %b %Y %H:%M:%S\") >>> 'Fri, 06 Feb 2015 17:45:09'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "11", "A_Content": "  import datetime date_time = datetime.datetime.now()  date = date_time.date()  # Gives the date time = date_time.time()  # Gives the time  print date.year, date.month, date.day print time.hour, time.minute, time.second, time.microsecond   Do dir(date) or any variables including the package. You can get all the attributes and methods associated with the variable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "11", "A_Content": "  Using Pandas to get the current time, kind of over killing the problem at hand:  import pandas as pd print (pd.datetime.now()) print (pd.datetime.now().date()) print (pd.datetime.now().year) print (pd.datetime.now().month) print (pd.datetime.now().day) print (pd.datetime.now().hour) print (pd.datetime.now().minute) print (pd.datetime.now().second) print (pd.datetime.now().microsecond)   Output:  2017-09-22 12:44:56.092642 2017-09-22 2017 9 22 12 44 56 92693      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "10", "A_Content": "  datetime.now() returns the current time as a naive datetime object that represents time in the local timezone. That value may be ambiguous e.g., during DST transitions (\"fall back\"). To avoid ambiguity either UTC timezone should be used:  from datetime import datetime  utc_time = datetime.utcnow() print(utc_time) # -> 2014-12-22 22:48:59.916417   Or a timezone-aware object that has the corresponding timezone info attached (Python 3.2+):  from datetime import datetime, timezone  now = datetime.now(timezone.utc).astimezone() print(now) # -> 2014-12-23 01:49:25.837541+03:00      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block", "Language": "Python", "Q_Title": "Catch multiple exceptions in one line (except block)", "Q_Votes": "2003", "Q_Content": "    I know that I can do:  try:     # do something that may fail except:     # do this if ANYTHING goes wrong   I can also do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreTooShortException:     # stand on a ladder   But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreBeingMeanException:     # say please   Is there any way that I can do something like this (since the action to take in both exceptions is to say please):  try:     # do something that may fail except IDontLikeYouException, YouAreBeingMeanException:     # say please   Now this really won't work, as it matches the syntax for:  try:     # do something that may fail except Exception, e:     # say please   So, my effort to catch the two distinct exceptions doesn't exactly come through.  Is there a way to do this?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "2759", "A_Content": "  From Python Documentation:     An except clause may name multiple exceptions as a parenthesized tuple, for example   except (IDontLikeYouException, YouAreBeingMeanException) as e:     pass   Or, for Python 2 only:  except (IDontLikeYouException, YouAreBeingMeanException), e:     pass   Separating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using as.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "584", "A_Content": "  You can use the sleep() function in the time module. It can take a float argument for sub second resolution.  from time import sleep sleep(0.1) # Time in seconds.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "117", "A_Content": "  Please read https://web.archive.org/web/20090207081238/http://faqts.com/knowledge_base/view.phtml/aid/2609/fid/378, which can help you further:     Try the sleep function in the time module.  import time time.sleep(60)       And put this in a while loop and a statement will only execute on the   minute...  That allows you to run a statement at predefined intervals   regardless of how long the command takes (as long as it takes less than    a minute or 5 or 60 or whatever you set it to)  For example, I wanted to    run a ping once a minute.  If I just time.sleep(60) or time.sleep(45)    even, the ping will not always take the same amount of time.  Here's the    code :)  time.sleep(time.localtime(time.time())[5])       The [5] just pulls the seconds out of the time.localtime()'s return    value.      The great thing about time.sleep is that it supports floating point    numbers!  import time time.sleep(0.1)        http://python.org/doc/current/lib/module-time.html      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "34", "A_Content": "  A bit of fun with a sleepy generator.  The question is about time delay. It can be fixed time, but in some cases we might need a delay measured since last time. Here is one possible solution:  Delay measured since last time (waking up regularly)  The situation can be, we want to do something as regularly as possible and we do not want to bother with all the last_time, next_time stuff all around our code.  Buzzer generator  The following code (sleepy.py) defines a buzzergen generator:  import time from itertools import count  def buzzergen(period):     nexttime = time.time() + period     for i in count():         now = time.time()         tosleep = nexttime - now         if tosleep > 0:             time.sleep(tosleep)             nexttime += period         else:             nexttime = now + period         yield i, nexttime   Invoking regular buzzergen  from sleepy import buzzergen import time buzzer = buzzergen(3) # Planning to wake up each 3 seconds print time.time() buzzer.next() print time.time() time.sleep(2) buzzer.next() print time.time() time.sleep(5) # Sleeping a bit longer than usually buzzer.next() print time.time() buzzer.next() print time.time()   And running it we see:  1400102636.46 1400102639.46 1400102642.46 1400102647.47 1400102650.47   We can also use it directly in a loop:  import random for ring in buzzergen(3):     print \"now\", time.time()     print \"ring\", ring     time.sleep(random.choice([0, 2, 4, 6]))   And running it we might see:  now 1400102751.46 ring (0, 1400102754.461676) now 1400102754.46 ring (1, 1400102757.461676) now 1400102757.46 ring (2, 1400102760.461676) now 1400102760.46 ring (3, 1400102763.461676) now 1400102766.47 ring (4, 1400102769.47115) now 1400102769.47 ring (5, 1400102772.47115) now 1400102772.47 ring (6, 1400102775.47115) now 1400102775.47 ring (7, 1400102778.47115)   As we see, this buzzer is not too rigid and allow us to catch up with regular sleepy intervals even if we oversleep and get out of regular schedule.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "23", "A_Content": "     How can I make a time delay in Python?   In a single thread I suggest the sleep function:  >>> from time import sleep  >>> sleep(4)   This actually suspends the processing of the thread in which it is called by the operating system, allowing other threads and processes to execute while it sleeps.  Use it for that purpose, or simply to delay a function from executing. For example:  >>> def party_time(): ...     print('hooray!') ...  >>> sleep(3); party_time() hooray!   \"hooray!\" printed 3 seconds after I hit Enter.  Example using sleep with multiple threads and processes  Again, sleep suspends your thread - it uses next to zero processing power.  To demonstrate, create a script like this (I first attempted this in an interactive Python 3.5 shell, but sub-processes can't find the party_later function for some reason):  from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed from time import sleep, time  def party_later(kind='', n=''):     sleep(3)     return kind + n + ' party time!: ' + __name__  def main():     with ProcessPoolExecutor() as proc_executor:         with ThreadPoolExecutor() as thread_executor:             start_time = time()             proc_future1 = proc_executor.submit(party_later, kind='proc', n='1')             proc_future2 = proc_executor.submit(party_later, kind='proc', n='2')             thread_future1 = thread_executor.submit(party_later, kind='thread', n='1')             thread_future2 = thread_executor.submit(party_later, kind='thread', n='2')             for f in as_completed([               proc_future1, proc_future2, thread_future1, thread_future2,]):                 print(f.result())             end_time = time()     print('total time to execute four 3-sec functions:', end_time - start_time)  if __name__ == '__main__':     main()   Example output from this script:  thread1 party time!: __main__ thread2 party time!: __main__ proc1 party time!: __mp_main__ proc2 party time!: __mp_main__ total time to execute four 3-sec functions: 3.4519670009613037   Multithreading  You can trigger a function to be called at a later time in a separate thread with the Timer threading object:  >>> from threading import Timer >>> t = Timer(3, party_time, args=None, kwargs=None) >>> t.start() >>> >>> hooray!  >>>    The blank line illustrates that the function printed to my standard out and I had to hit Enter to ensure I was on a prompt.  The upside of this method is that while the Timer thread was waiting, I was able to do other things, in this case, hitting Enter one time - before the function executed (see the first empty prompt).  There isn't a respective object in the multiprocessing library. You can create one, but it probably doesn't exist for a reason. A sub-thread makes a lot more sense for a simple timer than a whole new sub-process.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "20", "A_Content": "  The tkinter library in the Python standard library is an interactive tool which you can import. Basically, you can create buttons and boxes and popups and stuff that appear as windows which you manipulate with code.  If you use tkinter, DO NOT USE TIME.SLEEP() because it will muck up your program. This happened to me. Instead, use root.after() and replace the values for however many seconds, with a milliseconds. E.g, time.sleep(1) is equivalent to root.after(1000) in tkinter.  Otherwise, time.sleep(), which many answers have pointed out, which is the way to go.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "13", "A_Content": "  Delays are done with the time library, specifically the time.sleep() function...  To just make it wait for a second:  from time import sleep sleep(1)   This works because by doing:  from time import sleep   you extract the sleep function only from the time library which means you can just call it with:  sleep(seconds)   rather than having to type out  time.sleep()   which is awkwardly long to type.  With this method, you wouldn't get access to the other features of the time library and you can't have a variable called sleep. But you could create a variable called time.  Doing from [library] import [function] (, [function2]) is great if you just want certain parts of a module.  You could equally do it as  import time time.sleep(1)   and you would have access to the other features of the time library like time.clock() as long as you type time.[function](), but you couldn't create the variable time.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "11", "A_Content": "  Delays can be implemented by using three methods.  Let's start with the easiest one:  import time time.sleep(5) # Delay for 5 seconds.   The second method to delay would be using the implicit wait method:   driver.implicitly_wait(5)   The third method is more useful when you have to wait until a particular action is completed or until an element is found:  self.wait.until(EC.presence_of_element_located((By.ID, 'UserName'))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "11", "A_Content": "  There are 4 methods which I know: time.sleep(), pygame.time.wait(), matplotlib's pyplot.pause(), and .after().    time.sleep() example (do not use if using Tkinter):  import time print('Hello') time.sleep(5) #number of seconds print('Bye')     pygame.time.wait() example (not recommended if you are not using the pygame window, but you could exit the window instantly):  import pygame #If you are going to use the time module #don't do \"from pygame import *\" pygame.init() print('Hello') pygame.time.wait(5000)#milliseconds print('Bye')     matplotlib's function pyplot.pause() example (not recommended if you are not using the graph, but you could exit the graph instantly):  import matplotlib print('Hello') matplotlib.pyplot.pause(5)#seconds  print('Bye')     Finally, the .after() method (best with Tkinter):  import tkinter as tk #Tkinter for python 2 root = tk.Tk() print('Hello') def ohhi():  print('Oh, hi!') root.after(5000, ohhi)#milliseconds and then a function print('Bye')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510348/how-can-i-make-a-time-delay-in-python", "Language": "Python", "Q_Title": "How can I make a time delay in Python?", "Q_Votes": "2076", "Q_Content": "    I would like to know how to put a time delay in a Python script.     ", "Tags": ["python", "delay", "sleep", "timedelay"], "A_Votes": "0", "A_Content": "  While everyone else has suggested the de facto time module, I thought I'd share a different method using matplotlib's pyplot function, pause.  An example  from matplotlib import pyplot as plt plt.pause(5)    # Pauses the program for 5 seconds   Typically this is used to prevent the plot from disappearing as soon as it is plotted or to make crude animations.  This would save you an import if you already have matplotlib imported.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "9", "A_Content": "  >>> import datetime, time >>> time = strftime(\"%H:%M:%S:%MS\", time.localtime()) >>> print time '00:20:58:20S'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "9", "A_Content": "  Try the arrow module from http://crsmithdev.com/arrow/:  import arrow arrow.now()   Or the UTC version:  arrow.utcnow()   To change its output, add .format():  arrow.utcnow().format('YYYY-MM-DD HH:mm:ss ZZ')   For a specific timezone:  arrow.now('US/Pacific')   An hour ago:  arrow.utcnow().replace(hours=-1)   Or if you want the gist.  arrow.get('2013-05-11T21:23:58.970460+00:00').humanize() >>> '2 years ago'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "9", "A_Content": "  I want to get the time with milliseconds. A simple way to get them:  import time, datetime  print(datetime.datetime.now().time())                         # 11:20:08.272239  # Or in a more complicated way print(datetime.datetime.now().time().isoformat())             # 11:20:08.272239 print(datetime.datetime.now().time().strftime('%H:%M:%S.%f')) # 11:20:08.272239  # But do not use this: print(time.strftime(\"%H:%M:%S.%f\", time.localtime()), str)    # 11:20:08.%f   But I want only milliseconds, right? The shortest way to get them:  import time  time.strftime(\"%H:%M:%S\", time.localtime()) + '.%d' % (time.time() % 1 * 1000) # 11:34:23.751   Add or remove zeroes from the last multiplication to adjust number of decimal points, or just:  def get_time_str(decimal_points=3):     return time.strftime(\"%H:%M:%S\", time.localtime()) + '.%d' % (time.time() % 1 * 10**decimal_points)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "6", "A_Content": "  By default, now() function returns output in the YYYY-MM-DD HH:MM:SS:MS format. Use the below sample script to get the current date and time in a Python script and print results on the screen. Create file getDateTime1.py with the below content.  import datetime  currentDT = datetime.datetime.now() print (str(currentDT))   The output looks like below:  2018-03-01 17:03:46.759624      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "4", "A_Content": "  The following is what I use to get the time without having to format. Some people don't like the split method, but it is useful here:  from time import ctime print ctime().split()[3]   It will print in HH:MM:SS format.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "3", "A_Content": "  from time import ctime  // Day {Mon,Tue,..} print ctime().split()[0] // Month {Jan, Feb,..} print ctime().split()[1] // Date {1,2,..} print ctime().split()[2] // HH:MM:SS print ctime().split()[3] // Year {2018,..} print ctime().split()[4]   When you call ctime() it will convert seconds to string in format 'Day Month Date HH:MM:SS Year' (for example: 'Wed January 17 16:53:22 2018'), then you call split() method that will make a list from your string['Wed','Jan','17','16:56:45','2018'] (default delimeter is space).  Brackets are used to 'select' wanted argument in list.  One should call just one code line. One should not call them like I did, that was just an example, because in some cases you will get different values, rare but not impossible cases.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "3", "A_Content": "  If you are using NumPy already then directly you can use the numpy.datetime64() function.  import numpy as np str(np.datetime64('now'))   For only the date:  str(np.datetime64('today'))   Or, if you are using Pandas already then you can use the pandas.to_datetime() function:  import pandas as pd str(pd.to_datetime('now'))   Or:  str(pd.to_datetime('today'))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "1", "A_Content": "  import datetime date_time = str(datetime.datetime.now()) date = date_time.split()[0] time = date_time.split()[1]   date will print date and time will print time.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "1", "A_Content": "  First import the datetime module from datetime  from datetime import datetime   Then print the current time as 'yyyy-mm-dd hh:mm:ss'  print(str(datetime.now())   To get only the time in the form 'hh:mm:ss' where ss stands for the full number of seconds plus the fraction of seconds elapsed, just do;  print(str(datetime.now()[11:])   Converting the datetime.now() to a string yields an answer that is in the format that feels like the regular DATES AND TIMES we are used to.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "1", "A_Content": "  Because no one has mentioned it yet, and this is something I ran into recently... a pytz timezone's fromutc() method combined with datetime's utcnow() is the best way I've found to get a useful current time (and date) in any timezone.  from datetime import datetime  import pytz   JST = pytz.timezone(\"Asia/Tokyo\")   local_time = JST.fromutc(datetime.utcnow())   If all you want is the time, you can then get that with local_time.time().     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "1", "A_Content": "  If you just want the current timestamp in ms (for example, to measure execution time), you can also use the \"timeit\" module:  import timeit start_time = timeit.default_timer() do_stuff_you_want_to_measure() end_time = timeit.default_timer() print(\"Elapsed time: {}\".format(end_time - start_time))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python", "Language": "Python", "Q_Title": "How to get the current time in Python", "Q_Votes": "2010", "Q_Content": "    What is the module/method used to get the current time?     ", "Tags": ["python", "datetime", "time"], "A_Votes": "0", "A_Content": "  You can use this function to get the time (unfortunately it doesn't say AM or PM):  def gettime():         from datetime import datetime         return ((str(datetime.now())).split(' ')[1]).split('.')[0]   To get the hours, minutes, seconds and milliseconds to merge later, you can use these functions:  Hour:  def gethour():         from datetime import datetime         return return (((str(datetime.now())).split(' ')[1]).split('.')[0]).split(':')[0]   Minute:  def getminute():         from datetime import datetime         return (((str(datetime.now())).split(' ')[1]).split('.')[0]).split(':')[1]   Second:  def getsecond():         from datetime import datetime         return (((str(datetime.now())).split(' ')[1]).split('.')[0]).split(':')[2]   Millisecond:  def getmillisecond():         from datetime import datetime         return return (str(datetime.now())).split('.')[1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block", "Language": "Python", "Q_Title": "Catch multiple exceptions in one line (except block)", "Q_Votes": "2003", "Q_Content": "    I know that I can do:  try:     # do something that may fail except:     # do this if ANYTHING goes wrong   I can also do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreTooShortException:     # stand on a ladder   But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreBeingMeanException:     # say please   Is there any way that I can do something like this (since the action to take in both exceptions is to say please):  try:     # do something that may fail except IDontLikeYouException, YouAreBeingMeanException:     # say please   Now this really won't work, as it matches the syntax for:  try:     # do something that may fail except Exception, e:     # say please   So, my effort to catch the two distinct exceptions doesn't exactly come through.  Is there a way to do this?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "194", "A_Content": "     How do I catch multiple exceptions in one line (except block)   Do this:  try:     may_raise_specific_errors(): except (SpecificErrorOne, SpecificErrorTwo) as error:     handle(error) # might log or have some other default behavior...   The parentheses are required due to older syntax that used the commas to assign the error object to a name. The as keyword is used for the assignment. You can use any name for the error object, I prefer error personally.  Best Practice  To do this in a manner currently and forward compatible with Python, you need to separate the Exceptions with commas and wrap them with parentheses to differentiate from earlier syntax that assigned the exception instance to a variable name by following the Exception type to be caught with a comma.   Here's an example of simple usage:  try:     mainstuff() except (KeyboardInterrupt, EOFError): # the parens are necessary     quit(0)   I'm specifying only these exceptions to avoid hiding bugs, which if I encounter I expect the full stack trace from.  This is documented here: https://docs.python.org/tutorial/errors.html  You can assign the exception to a variable, (e is common, but you might prefer a more verbose variable if you have long exception handling or your IDE only highlights selections larger than that, as mine does.) The instance has an args attribute. Here is an example:  try:     mainstuff() except (KeyboardInterrupt, EOFError) as err:      print(err)     print(err.args)     quit(0)   Note that in Python 3, the err object falls out of scope when the except block is concluded.  Deprecated  You may see code that assigns the error with a comma. This usage, the only form available in Python 2.5 and earlier, is deprecated, and if you wish your code to be forward compatible in Python 3, you should update the syntax to use the new form:  try:     mainstuff() except (KeyboardInterrupt, EOFError), err: # don't do this in Python 2.6+     print err     print err.args     quit(0)   If you see the comma name assignment in your codebase, and you're using Python 2.5 or higher, switch to the new way of doing it so your code remains compatible when you upgrade.  The suppress context manager  The accepted answer is really 4 lines of code, minimum:  try:     do_something() except (IDontLikeYouException, YouAreBeingMeanException) as e:     pass   The try, except, pass lines can be handled in a single line with the suppress context manager, available in Python 3.4:  from contextlib import suppress  with suppress(IDontLikeYouException, YouAreBeingMeanException):      do_something()   So when you want to pass on certain exceptions, use suppress.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block", "Language": "Python", "Q_Title": "Catch multiple exceptions in one line (except block)", "Q_Votes": "2003", "Q_Content": "    I know that I can do:  try:     # do something that may fail except:     # do this if ANYTHING goes wrong   I can also do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreTooShortException:     # stand on a ladder   But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreBeingMeanException:     # say please   Is there any way that I can do something like this (since the action to take in both exceptions is to say please):  try:     # do something that may fail except IDontLikeYouException, YouAreBeingMeanException:     # say please   Now this really won't work, as it matches the syntax for:  try:     # do something that may fail except Exception, e:     # say please   So, my effort to catch the two distinct exceptions doesn't exactly come through.  Is there a way to do this?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "49", "A_Content": "  For python 2.5 and earlier versions, the correct syntax is:  except (IDontLikeYouException, YouAreBeingMeanException), e:     print e   Where e is the Exception instance.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block", "Language": "Python", "Q_Title": "Catch multiple exceptions in one line (except block)", "Q_Votes": "2003", "Q_Content": "    I know that I can do:  try:     # do something that may fail except:     # do this if ANYTHING goes wrong   I can also do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreTooShortException:     # stand on a ladder   But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreBeingMeanException:     # say please   Is there any way that I can do something like this (since the action to take in both exceptions is to say please):  try:     # do something that may fail except IDontLikeYouException, YouAreBeingMeanException:     # say please   Now this really won't work, as it matches the syntax for:  try:     # do something that may fail except Exception, e:     # say please   So, my effort to catch the two distinct exceptions doesn't exactly come through.  Is there a way to do this?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "37", "A_Content": "  From Python documentation -> 8.3 Handling Exceptions:     A try statement may have more than one except clause, to specify   handlers for different exceptions. At most one handler will be   executed. Handlers only handle exceptions that occur in the   corresponding try clause, not in other handlers of the same try   statement. An except clause may name multiple exceptions as a   parenthesized tuple, for example:  except (RuntimeError, TypeError, NameError):     pass       Note that the parentheses around this tuple are required, because   except ValueError, e: was the syntax used for what is normally   written as except ValueError as e: in modern Python (described   below). The old syntax is still supported for backwards compatibility.   This means except RuntimeError, TypeError is not equivalent to   except (RuntimeError, TypeError): but to except RuntimeError as   TypeError: which is not what you want.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block", "Language": "Python", "Q_Title": "Catch multiple exceptions in one line (except block)", "Q_Votes": "2003", "Q_Content": "    I know that I can do:  try:     # do something that may fail except:     # do this if ANYTHING goes wrong   I can also do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreTooShortException:     # stand on a ladder   But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreBeingMeanException:     # say please   Is there any way that I can do something like this (since the action to take in both exceptions is to say please):  try:     # do something that may fail except IDontLikeYouException, YouAreBeingMeanException:     # say please   Now this really won't work, as it matches the syntax for:  try:     # do something that may fail except Exception, e:     # say please   So, my effort to catch the two distinct exceptions doesn't exactly come through.  Is there a way to do this?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "16", "A_Content": "  If you frequently use a large number of exceptions, you can pre-define a tuple, so you don't have to re-type them many times.   #This example code is a technique I use in a library that connects with websites to gather data  ConnectErrs  = (URLError, SSLError, SocketTimeoutError, BadStatusLine, ConnectionResetError)  def connect(url, data):     #do connection and return some data     return(received_data)  def some_function(var_a, var_b, ...):     try: o = connect(url, data)     except ConnectErrs as e:         #do the recovery stuff     blah #do normal stuff you would do if no exception occurred   NOTES:    If you, also, need to catch other exceptions than those in the pre-defined tuple, you will need to define another except block.   If you just cannot tolerate a global variable, define it in main() and pass it around where needed...      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block", "Language": "Python", "Q_Title": "Catch multiple exceptions in one line (except block)", "Q_Votes": "2003", "Q_Content": "    I know that I can do:  try:     # do something that may fail except:     # do this if ANYTHING goes wrong   I can also do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreTooShortException:     # stand on a ladder   But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreBeingMeanException:     # say please   Is there any way that I can do something like this (since the action to take in both exceptions is to say please):  try:     # do something that may fail except IDontLikeYouException, YouAreBeingMeanException:     # say please   Now this really won't work, as it matches the syntax for:  try:     # do something that may fail except Exception, e:     # say please   So, my effort to catch the two distinct exceptions doesn't exactly come through.  Is there a way to do this?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "5", "A_Content": "  One of the way to do this is..  try:    You do your operations here;    ...................... except(Exception1[, Exception2[,...ExceptionN]]]):    If there is any exception from the given exception list,     then execute this block.    ...................... else:    If there is no exception then execute this block.    and another way is to create method which performs task executed by except block and call it through all of the except block that you write..  try:    You do your operations here;    ...................... except Exception1:     functionname(parameterList) except Exception2:     functionname(parameterList) except Exception3:     functionname(parameterList) else:    If there is no exception then execute this block.   def functionname( parameters ):    //your task..    return [expression]   I know that second one is not the best way to do this, but i'm just showing number of ways to do this thing.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block", "Language": "Python", "Q_Title": "Catch multiple exceptions in one line (except block)", "Q_Votes": "2003", "Q_Content": "    I know that I can do:  try:     # do something that may fail except:     # do this if ANYTHING goes wrong   I can also do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreTooShortException:     # stand on a ladder   But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:  try:     # do something that may fail except IDontLikeYouException:     # say please except YouAreBeingMeanException:     # say please   Is there any way that I can do something like this (since the action to take in both exceptions is to say please):  try:     # do something that may fail except IDontLikeYouException, YouAreBeingMeanException:     # say please   Now this really won't work, as it matches the syntax for:  try:     # do something that may fail except Exception, e:     # say please   So, my effort to catch the two distinct exceptions doesn't exactly come through.  Is there a way to do this?     ", "Tags": ["python", "exception", "exception-handling"], "A_Votes": "3", "A_Content": "  Python 2.7 Documentation states that:     A try statement may have more than one except clause, to specify   handlers for different exceptions. At most one handler will be   executed. Handlers only handle exceptions that occur in the   corresponding try clause, not in other handlers of the same try   statement. An except clause may name multiple exceptions as a   parenthesized tuple, for example:   try:     raise ValueError(\"hello\") except (RuntimeError, ValueError, KeyError) as a:     print a      Note   that the parentheses around this tuple are required, because except   ValueError, e: was the syntax used for what is normally written as   except ValueError as e: in modern Python (described below). The old   syntax is still supported for backwards compatibility. This means   except RuntimeError, TypeError is not equivalent to except   (RuntimeError, TypeError): but to except RuntimeError as TypeError:   which is not what you want.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods", "Language": "Python", "Q_Title": "Understanding Python super() with __init__() methods [duplicate]", "Q_Votes": "2017", "Q_Content": "          This question already has an answer here:                              What does 'super' do in Python?                                        6 answers                                          I'm trying to understand the use of super(). From the looks of it, both child classes can be created, just fine.   I'm curious to know about the actual difference between the following 2 child classes.  class Base(object):     def __init__(self):         print \"Base created\"  class ChildA(Base):     def __init__(self):         Base.__init__(self)  class ChildB(Base):     def __init__(self):         super(ChildB, self).__init__()  ChildA()  ChildB()      ", "Tags": ["python", "class", "oop", "inheritance", "super"], "A_Votes": "1446", "A_Content": "  super() lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of fun stuff can happen. See the standard docs on super if you haven't already.  Note that the syntax changed in Python 3.0: you can just say super().__init__() instead of super(ChildB, self).__init__() which IMO is quite a bit nicer.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods", "Language": "Python", "Q_Title": "Understanding Python super() with __init__() methods [duplicate]", "Q_Votes": "2017", "Q_Content": "          This question already has an answer here:                              What does 'super' do in Python?                                        6 answers                                          I'm trying to understand the use of super(). From the looks of it, both child classes can be created, just fine.   I'm curious to know about the actual difference between the following 2 child classes.  class Base(object):     def __init__(self):         print \"Base created\"  class ChildA(Base):     def __init__(self):         Base.__init__(self)  class ChildB(Base):     def __init__(self):         super(ChildB, self).__init__()  ChildA()  ChildB()      ", "Tags": ["python", "class", "oop", "inheritance", "super"], "A_Votes": "438", "A_Content": "     I'm trying to understand super()   The reason we use super is so that child classes that may be using cooperative multiple inheritance will call the correct next parent class function in the Method Resolution Order (MRO).  In Python 3, we can call it like this:  class ChildB(Base):     def __init__(self):         super().__init__()    In Python 2, we are required to use it like this:          super(ChildB, self).__init__()   Without super, you are limited in your ability to use multiple inheritance:          Base.__init__(self) # Avoid this.   I further explain below.     \"What difference is there actually in this code?:\"   class ChildA(Base):     def __init__(self):         Base.__init__(self)  class ChildB(Base):     def __init__(self):         super(ChildB, self).__init__()         # super().__init__() # you can call super like this in Python 3!   The primary difference in this code is that you get a layer of indirection in the __init__ with super, which uses the current class to determine the next class's __init__ to look up in the MRO.  I illustrate this difference in an answer at the canonical question, How to use 'super' in Python?, which demonstrates dependency injection and cooperative multiple inheritance.  If Python didn't have super  Here's code that's actually closely equivalent to super (how it's implemented in C, minus some checking and fallback behavior, and translated to Python):  class ChildB(Base):     def __init__(self):         mro = type(self).mro()             # Get the Method Resolution Order.         check_next = mro.index(ChildB) + 1 # Start looking after *this* class.         while check_next < len(mro):             next_class = mro[check_next]             if '__init__' in next_class.__dict__:                 next_class.__init__(self)                 break             check_next += 1   Written a little more like native Python:  class ChildB(Base):     def __init__(self):         mro = type(self).mro()         for next_class in mro[mro.index(ChildB) + 1:]: # slice to end             if hasattr(next_class, '__init__'):                 next_class.__init__(self)                 break   If we didn't have the super object, we'd have to write this manual code everywhere (or recreate it!) to ensure that we call the proper next method in the Method Resolution Order!  How does super do this in Python 3 without being told explicitly which class and instance from the method it was called from?   It gets the calling stack frame, and finds the class (implicitly stored as a local free variable, __class__, making the calling function a closure over the class) and the first argument to that function, which should be the instance or class that informs it which Method Resolution Order (MRO) to use.   Since it requires that first argument for the MRO, using super with static methods is impossible.  Criticisms of other answers:     super() lets you avoid referring to the base class explicitly, which can be nice. . But the main advantage comes with multiple inheritance, where all sorts of fun stuff can happen. See the standard docs on super if you haven't already.   It's rather hand-wavey and doesn't tell us much, but the point of super is not to avoid writing the parent class. The point is to ensure that the next method in line in the method resolution order (MRO) is called. This becomes important in multiple inheritance.  I'll explain here.  class Base(object):     def __init__(self):         print(\"Base init'ed\")  class ChildA(Base):     def __init__(self):         print(\"ChildA init'ed\")         Base.__init__(self)  class ChildB(Base):     def __init__(self):         print(\"ChildB init'ed\")         super(ChildB, self).__init__()   And let's create a dependency that we want to be called after the Child:  class UserDependency(Base):     def __init__(self):         print(\"UserDependency init'ed\")         super(UserDependency, self).__init__()   Now remember, ChildB uses super, ChildA does not:  class UserA(ChildA, UserDependency):     def __init__(self):         print(\"UserA init'ed\")         super(UserA, self).__init__()  class UserB(ChildB, UserDependency):     def __init__(self):         print(\"UserB init'ed\")         super(UserB, self).__init__()   And UserA does not call the UserDependency method:  >>> UserA() UserA init'ed ChildA init'ed Base init'ed <__main__.UserA object at 0x0000000003403BA8>   But UserB, because ChildB uses super, does!:  >>> UserB() UserB init'ed ChildB init'ed UserDependency init'ed Base init'ed <__main__.UserB object at 0x0000000003403438>   Criticism for another answer  In no circumstance should you do the following, which another answer suggests, as you'll definitely get errors when you subclass ChildB:          super(self.__class__, self).__init__() # Don't do this. Ever.   (That answer is not clever or particularly interesting, but in spite of direct criticism in the comments and over 17 downvotes, the answerer persisted in suggesting it until a kind editor fixed his problem.)  Explanation: That answer suggested calling super like this:  super(self.__class__, self).__init__()   This is completely wrong. super lets us look up the next parent in the MRO (see the first section of this answer) for child classes. If you tell super we're in the child instance's method, it will then lookup the next method in line (probably this one) resulting in recursion, probably causing a logical failure (in the answerer's example, it does) or a RuntimeError when the recursion depth is exceeded.  >>> class Polygon(object): ...     def __init__(self, id): ...         self.id = id ... >>> class Rectangle(Polygon): ...     def __init__(self, id, width, height): ...         super(self.__class__, self).__init__(id) ...         self.shape = (width, height) ... >>> class Square(Rectangle): ...     pass ... >>> Square('a', 10, 10) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 3, in __init__ TypeError: __init__() missing 2 required positional arguments: 'width' and 'height'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods", "Language": "Python", "Q_Title": "Understanding Python super() with __init__() methods [duplicate]", "Q_Votes": "2017", "Q_Content": "          This question already has an answer here:                              What does 'super' do in Python?                                        6 answers                                          I'm trying to understand the use of super(). From the looks of it, both child classes can be created, just fine.   I'm curious to know about the actual difference between the following 2 child classes.  class Base(object):     def __init__(self):         print \"Base created\"  class ChildA(Base):     def __init__(self):         Base.__init__(self)  class ChildB(Base):     def __init__(self):         super(ChildB, self).__init__()  ChildA()  ChildB()      ", "Tags": ["python", "class", "oop", "inheritance", "super"], "A_Votes": "224", "A_Content": "  It's been noted that in Python 3.0+ you can use  super().__init__()   to make your call, which is concise and does not require you to reference the parent OR class names explicitly, which can be handy. I just want to add that for Python 2.7 or under, it is possible to get this name-insensitive behaviour by writing self.__class__ instead of the class name, i.e.  super(self.__class__, self).__init__()   HOWEVER, this breaks calls to super for any classes that inherit from your class, where self.__class__ could return a child class. For example:  class Polygon(object):     def __init__(self, id):         self.id = id  class Rectangle(Polygon):     def __init__(self, id, width, height):         super(self.__class__, self).__init__(id)         self.shape = (width, height)  class Square(Rectangle):     pass   Here I have a class Square, which is a sub-class of Rectangle. Say I don't want to write a separate constructor for Square because the constructor for Rectangle is good enough, but for whatever reason I want to implement a Square so I can reimplement some other method.  When I create a Square using mSquare = Square('a', 10,10), Python calls the constructor for Rectangle because I haven't given Square its own constructor. However, in the constructor for Rectangle, the call super(self.__class__,self) is going to return the superclass of mSquare, so it calls the constructor for Rectangle again. This is how the infinite loop happens, as was mentioned by @S_C. In this case, when I run super(...).__init__() I am calling the constructor for Rectangle but since I give it no arguments, I will get an error.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods", "Language": "Python", "Q_Title": "Understanding Python super() with __init__() methods [duplicate]", "Q_Votes": "2017", "Q_Content": "          This question already has an answer here:                              What does 'super' do in Python?                                        6 answers                                          I'm trying to understand the use of super(). From the looks of it, both child classes can be created, just fine.   I'm curious to know about the actual difference between the following 2 child classes.  class Base(object):     def __init__(self):         print \"Base created\"  class ChildA(Base):     def __init__(self):         Base.__init__(self)  class ChildB(Base):     def __init__(self):         super(ChildB, self).__init__()  ChildA()  ChildB()      ", "Tags": ["python", "class", "oop", "inheritance", "super"], "A_Votes": "75", "A_Content": "  Super has no side effects  Base = ChildB  Base()   works as expected  Base = ChildA  Base()   gets into infinite recursion.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods", "Language": "Python", "Q_Title": "Understanding Python super() with __init__() methods [duplicate]", "Q_Votes": "2017", "Q_Content": "          This question already has an answer here:                              What does 'super' do in Python?                                        6 answers                                          I'm trying to understand the use of super(). From the looks of it, both child classes can be created, just fine.   I'm curious to know about the actual difference between the following 2 child classes.  class Base(object):     def __init__(self):         print \"Base created\"  class ChildA(Base):     def __init__(self):         Base.__init__(self)  class ChildB(Base):     def __init__(self):         super(ChildB, self).__init__()  ChildA()  ChildB()      ", "Tags": ["python", "class", "oop", "inheritance", "super"], "A_Votes": "68", "A_Content": "  Just a heads up... with Python 2.7, and I believe ever since super() was introduced in version 2.2, you can only call super() if one of the parents inherit from a class that eventually inherits object (new-style classes).  Personally, as for python 2.7 code, I'm going to continue using BaseClassName.__init__(self, args) until I actually get the advantage of using super().     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods", "Language": "Python", "Q_Title": "Understanding Python super() with __init__() methods [duplicate]", "Q_Votes": "2017", "Q_Content": "          This question already has an answer here:                              What does 'super' do in Python?                                        6 answers                                          I'm trying to understand the use of super(). From the looks of it, both child classes can be created, just fine.   I'm curious to know about the actual difference between the following 2 child classes.  class Base(object):     def __init__(self):         print \"Base created\"  class ChildA(Base):     def __init__(self):         Base.__init__(self)  class ChildB(Base):     def __init__(self):         super(ChildB, self).__init__()  ChildA()  ChildB()      ", "Tags": ["python", "class", "oop", "inheritance", "super"], "A_Votes": "46", "A_Content": "  There isn't, really. super() looks at the next class in the MRO (method resolution order, accessed with cls.__mro__) to call the methods. Just calling the base __init__ calls the base __init__. As it happens, the MRO has exactly one item-- the base. So you're really doing the exact same thing, but in a nicer way with super() (particularly if you get into multiple inheritance later).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods", "Language": "Python", "Q_Title": "Understanding Python super() with __init__() methods [duplicate]", "Q_Votes": "2017", "Q_Content": "          This question already has an answer here:                              What does 'super' do in Python?                                        6 answers                                          I'm trying to understand the use of super(). From the looks of it, both child classes can be created, just fine.   I'm curious to know about the actual difference between the following 2 child classes.  class Base(object):     def __init__(self):         print \"Base created\"  class ChildA(Base):     def __init__(self):         Base.__init__(self)  class ChildB(Base):     def __init__(self):         super(ChildB, self).__init__()  ChildA()  ChildB()      ", "Tags": ["python", "class", "oop", "inheritance", "super"], "A_Votes": "22", "A_Content": "  The main difference is that ChildA.__init__ will unconditionally call Base.__init__ whereas ChildB.__init__ will call __init__ in whatever class happens to be ChildB ancestor in self's line of ancestors (which may differ from what you expect).   If you add a ClassC that uses multiple inheritance:   class Mixin(Base):   def __init__(self):     print \"Mixin stuff\"     super(Mixin, self).__init__()  class ChildC(ChildB, Mixin):  # Mixin is now between ChildB and Base   pass  ChildC() help(ChildC) # shows that the the Method Resolution Order is ChildC->ChildB->Mixin->Base   then Base is no longer the parent of ChildB for ChildC instances. Now super(ChildB, self) will point to Mixin if self is a ChildC instance.  You have inserted Mixin in between ChildB and Base. And you can take advantage of it with super()  So if you are designed your classes so that they can be used in a Cooperative Multiple Inheritance scenario, you use super because you don't really know who is going to be the ancestor at runtime.   The super considered super post and pycon 2015 accompanying video explain this pretty well.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "2253", "A_Content": "  Arguments are passed by assignment. The rationale behind this is twofold:   the parameter passed in is actually a reference to an object (but the reference is passed by value) some data types are mutable, but others aren't   So:   If you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object.  If you pass an immutable object to a method, you still can't rebind the outer reference, and you can't even mutate the object.   To make it even more clear, let's have some examples.   List - a mutable type  Let's try to modify the list that was passed to a method:  def try_to_change_list_contents(the_list):     print('got', the_list)     the_list.append('four')     print('changed to', the_list)  outer_list = ['one', 'two', 'three']  print('before, outer_list =', outer_list) try_to_change_list_contents(outer_list) print('after, outer_list =', outer_list)   Output:  before, outer_list = ['one', 'two', 'three'] got ['one', 'two', 'three'] changed to ['one', 'two', 'three', 'four'] after, outer_list = ['one', 'two', 'three', 'four']   Since the parameter passed in is a reference to outer_list, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.  Now let's see what happens when we try to change the reference that was passed in as a parameter:  def try_to_change_list_reference(the_list):     print('got', the_list)     the_list = ['and', 'we', 'can', 'not', 'lie']     print('set to', the_list)  outer_list = ['we', 'like', 'proper', 'English']  print('before, outer_list =', outer_list) try_to_change_list_reference(outer_list) print('after, outer_list =', outer_list)   Output:  before, outer_list = ['we', 'like', 'proper', 'English'] got ['we', 'like', 'proper', 'English'] set to ['and', 'we', 'can', 'not', 'lie'] after, outer_list = ['we', 'like', 'proper', 'English']   Since the the_list parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The the_list was a copy of the outer_list reference, and we had the_list point to a new list, but there was no way to change where outer_list pointed.  String - an immutable type  It's immutable, so there's nothing we can do to change the contents of the string  Now, let's try to change the reference  def try_to_change_string_reference(the_string):     print('got', the_string)     the_string = 'In a kingdom by the sea'     print('set to', the_string)  outer_string = 'It was many and many a year ago'  print('before, outer_string =', outer_string) try_to_change_string_reference(outer_string) print('after, outer_string =', outer_string)   Output:  before, outer_string = It was many and many a year ago got It was many and many a year ago set to In a kingdom by the sea after, outer_string = It was many and many a year ago   Again, since the the_string parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The the_string was a copy of the outer_string reference, and we had the_string point to a new string, but there was no way to change where outer_string pointed.  I hope this clears things up a little.  EDIT: It's been noted that this doesn't answer the question that @David originally asked, \"Is there something I can do to pass the variable by actual reference?\". Let's work on that.  How do we get around this?  As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:  def return_a_whole_new_string(the_string):     new_string = something_to_do_with_the_old_string(the_string)     return new_string  # then you could call it like my_string = return_a_whole_new_string(my_string)   If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:  def use_a_wrapper_to_simulate_pass_by_reference(stuff_to_change):     new_string = something_to_do_with_the_old_string(stuff_to_change[0])     stuff_to_change[0] = new_string  # then you could call it like wrapper = [my_string] use_a_wrapper_to_simulate_pass_by_reference(wrapper)  do_something_with(wrapper[0])   Although this seems a little cumbersome.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "539", "A_Content": "  The problem comes from a misunderstanding of what variables are in Python. If you're used to most traditional languages, you have a mental model of what happens in the following sequence:  a = 1 a = 2   You believe that a is a memory location that stores the value 1, then is updated to store the value 2. That's not how things work in Python. Rather, a starts as a reference to an object with the value 1, then gets reassigned as a reference to an object with the value 2. Those two objects may continue to coexist even though a doesn't refer to the first one anymore; in fact they may be shared by any number of other references within the program.  When you call a function with a parameter, a new reference is created that refers to the object passed in. This is separate from the reference that was used in the function call, so there's no way to update that reference and make it refer to a new object. In your example:  def __init__(self):     self.variable = 'Original'     self.Change(self.variable)  def Change(self, var):     var = 'Changed'   self.variable is a reference to the string object 'Original'. When you call Change you create a second reference var to the object. Inside the function you reassign the reference var to a different string object 'Changed', but the reference self.variable is separate and does not change.  The only way around this is to pass a mutable object. Because both references refer to the same object, any changes to the object are reflected in both places.  def __init__(self):              self.variable = ['Original']     self.Change(self.variable)  def Change(self, var):     var[0] = 'Changed'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "249", "A_Content": "  I found the other answers rather long and complicated, so I created this simple diagram to explain the way Python treats variables and parameters.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "221", "A_Content": "  It is neither pass-by-value or pass-by-reference - it is call-by-object. See this, by Fredrik Lundh:   http://effbot.org/zone/call-by-object.htm  Here is a significant quote:     \"...variables [names] are not objects; they cannot be denoted by other variables or referred to by objects.\"   In your example, when the Change method is called--a namespace is created for it; and var becomes a name, within that namespace, for the string object 'Original'. That object then has a name in two namespaces. Next, var = 'Changed' binds var to a new string object, and thus the method's namespace forgets about 'Original'. Finally, that namespace is forgotten, and the string 'Changed' along with it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "142", "A_Content": "  Think of stuff being passed by assignment instead of by reference/by value. That way, it is allways clear, what is happening as long as you understand what happens during normal assignment.  So, when passing a list to a function/method, the list is assigned to the parameter name. Appending to the list will result in the list being modified. Reassigning the list inside the function will not change the original list, since:  a = [1, 2, 3] b = a b.append(4) b = ['a', 'b'] print a, b      # prints [1, 2, 3, 4] ['a', 'b']   Since immutable types cannot be modified, they seem like being passed by value - passing an int into a function means assigning the int to the functions parameter. You can only ever reassign that, but it won't change the originial variables value.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "54", "A_Content": "  Effbot (aka Fredrik Lundh) has described Python's variable passing style as call-by-object:  http://effbot.org/zone/call-by-object.htm  Objects are allocated on the heap and pointers to them can be passed around anywhere.     When you make an assignment such as x = 1000, a dictionary entry is created that maps the string \"x\" in the current namespace to a pointer to the integer object containing one thousand.    When you update \"x\" with x = 2000, a new integer object is created and the dictionary is updated to point at the new object.  The old one thousand object is unchanged (and may or may not be alive depending on whether anything else refers to the object). When you do a new assignment such as y = x, a new dictionary entry \"y\" is created that points to the same object as the entry for \"x\". Objects like strings and integers are immutable.  This simply means that there are no methods that can change the object after it has been created.  For example, once the integer object one-thousand is created, it will never change.  Math is done by creating new integer objects. Objects like lists are mutable.  This means that the contents of the object can be changed by anything pointing to the object.  For example, x = []; y = x; x.append(10); print y will print [10].  The empty list was created.  Both \"x\" and \"y\" point to the same list.  The append method mutates (updates) the list object (like adding a record to a database) and the result is visible to both \"x\" and \"y\" (just as a database update would be visible to every connection to that database).   Hope that clarifies the issue for you.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "53", "A_Content": "  Technically, Python always uses pass by reference values. I am going to repeat my other answer to support my statement.  Python always uses pass-by-reference values. There isn't any exception. Any variable assignment means copying the reference value. No exception. Any variable is the name bound to the reference value. Always.  You can think about a reference value as the address of the target object. The address is automatically dereferenced when used. This way, working with the reference value, it seems you work directly with the target object. But there always is a reference in between, one step more to jump to the target.  Here is the example that proves that Python uses passing by reference:    If the argument was passed by value, the outer lst could not be modified. The green are the target objects (the black is the value stored inside, the red is the object type), the yellow is the memory with the reference value inside -- drawn as the arrow. The blue solid arrow is the reference value that was passed to the function (via the dashed blue arrow path). The ugly dark yellow is the internal dictionary. (It actually could be drawn also as a green ellipse. The colour and the shape only says it is internal.)  You can use the id() built-in function to learn what the reference value is (that is, the address of the target object).  In compiled languages, a variable is a memory space that is able to capture the value of the type. In Python, a variable is a name (captured internally as a string) bound to the reference variable that holds the reference value to the target object. The name of the variable is the key in the internal dictionary, the value part of that dictionary item stores the reference value to the target.  Reference values are hidden in Python. There isn't any explicit user type for storing the reference value. However, you can use a list element (or element in any other suitable container type) as the reference variable, because all containers do store the elements also as references to the target objects. In other words, elements are actually not contained inside the container -- only the references to elements are.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "39", "A_Content": "  A simple trick I normally use is to just wrap it in a list:  def Change(self, var):     var[0] = 'Changed'  variable = ['Original'] self.Change(variable)       print variable[0]   (Yeah I know this can be inconvenient, but sometimes it is simple enough to do this.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "34", "A_Content": "  (edit - Blair has updated his enormously popular answer so that it is now accurate)  I think it is important to note that the current post with the most votes (by Blair Conrad), while being correct with respect to its result, is misleading and is borderline incorrect based on its definitions.  While there are many languages (like C) that allow the user to either pass by reference or pass by value, Python is not one of them.  David Cournapeau's answer points to the real answer and explains why the behavior in Blair Conrad's post seems to be correct while the definitions are not.  To the extent that Python is pass by value, all languages are pass by value since some piece of data (be it a \"value\" or a \"reference\") must be sent. However, that does not mean that Python is pass by value in the sense that a C programmer would think of it.  If you want the behavior, Blair Conrad's answer is fine.  But if you want to know the nuts and bolts of why Python is neither pass by value or pass by reference, read David Cournapeau's answer.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "26", "A_Content": "  There are no variables in Python  The key to understanding parameter passing is to stop thinking about \"variables\". There are names and objects in Python and together they appear like variables, but it is useful to always distinguish the three.   Python has names and objects. Assignment binds a name to an object. Passing an argument into a function also binds a name (the parameter name of the function) to an object.   That is all there is to it. Mutability is irrelevant for this question.  Example:   a = 1   This binds the name a to an object of type integer that holds the value 1.  b = x   This binds the name b to the same object that the name x is currently bound to. Afterwards, the name b has nothing to do with the name x any more.  See sections 3.1 and 4.2 in the Python 3 language reference.    So in the code shown in the question, the statement self.Change(self.variable) binds the name var (in the scope of function Change) to the object that holds the value 'Original' and the assignment var = 'Changed' (in the body of function Change) assigns that same name again: to some other object (that happens to hold a string as well but could have been something else entirely).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "22", "A_Content": "  You got some really good answers here.  x = [ 2, 4, 4, 5, 5 ] print x  # 2, 4, 4, 5, 5  def go( li ) :   li = [ 5, 6, 7, 8 ]  # re-assigning what li POINTS TO, does not   # change the value of the ORIGINAL variable x  go( x )  print x  # 2, 4, 4, 5, 5  [ STILL! ]   raw_input( 'press any key to continue' )      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "16", "A_Content": "  In this case the variable titled var in the method Change is assigned a reference to self.variable, and you immediately assign a string to var. It's no longer pointing to self.variable. The following code snippet shows what would happen if you modify the data structure pointed to by var and self.variable, in this case a list:  >>> class PassByReference: ...     def __init__(self): ...         self.variable = ['Original'] ...         self.change(self.variable) ...         print self.variable ...          ...     def change(self, var): ...         var.append('Changed') ...  >>> q = PassByReference() ['Original', 'Changed'] >>>    I'm sure someone else could clarify this further.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "15", "A_Content": "  Python\u2019s pass-by-assignment scheme isn\u2019t quite the same as C++\u2019s reference parameters option, but it turns out to be very similar to the argument-passing model of the C language (and others) in practice:   Immutable arguments are effectively passed \u201cby value.\u201d Objects such as integers and strings are passed by object reference instead of by copying, but because you can\u2019t change immutable objects in place anyhow, the effect is much like making a copy. Mutable arguments are effectively passed \u201cby pointer.\u201d Objects such as lists and dictionaries are also passed by object reference, which is similar to the way C passes arrays as pointers\u2014mutable objects can be changed in place in the function, much like C arrays.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "13", "A_Content": "  As you can state you need to have a mutable object, but let me suggest you to check over the global variables as they can help you or even solve this kind of issue!  http://docs.python.org/3/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python  example:  >>> def x(y): ...     global z ...     z = y ...  >>> x <function x at 0x00000000020E1730> >>> y Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> NameError: name 'y' is not defined >>> z Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> NameError: name 'z' is not defined  >>> x(2) >>> x <function x at 0x00000000020E1730> >>> y Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> NameError: name 'y' is not defined >>> z 2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "12", "A_Content": "  A lot of insights in answers here, but i think an additional point is not clearly mentioned here explicitly.   Quoting from python documentation https://docs.python.org/2/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python    \"In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the function\u2019s body, it\u2019s assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as \u2018global\u2019. Though a bit surprising at first, a moment\u2019s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you\u2019d be using global all the time. You\u2019d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects.\"  Even when passing a mutable object to a function this still applies. And to me clearly explains the reason for the difference in behavior between assigning to the object and operating on the object in the function.  def test(l):     print \"Received\", l , id(l)     l = [0, 0, 0]     print \"Changed to\", l, id(l)  # New local object created, breaking link to global l  l= [1,2,3] print \"Original\", l, id(l) test(l) print \"After\", l, id(l)   gives:  Original [1, 2, 3] 4454645632 Received [1, 2, 3] 4454645632 Changed to [0, 0, 0] 4474591928 After [1, 2, 3] 4454645632   The assignment to an global variable that is not declared global therefore creates a new local object and breaks the link to the original object.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "8", "A_Content": "  Here is the simple (I hope) explanation of the concept pass by object used in Python. Whenever you pass an object to the function, the object itself is passed (object in Python is actually what you'd call a value in other programming languages) not the reference to this object. In other words, when you call:  def change_me(list):    list = [1, 2, 3]  my_list = [0, 1] change_me(my_list)   The actual object - [0, 1] (which would be called a value in other programming languages) is being passed. So in fact the function change_me will try to do something like:  [0, 1] = [1, 2, 3]   which obviously will not change the object passed to the function. If the function looked like this:  def change_me(list):    list.append(2)   Then the call would result in:  [0, 1].append(2)   which obviously will change the object. This answer explains it well.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "7", "A_Content": "  Aside from all the great explanations on how this stuff works in Python, I don't see a simple suggestion for the problem. As you seem to do create objects and instances, the pythonic way of handling instance variables and changing them is the following:  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.Change()         print self.variable      def Change(self):         self.variable = 'Changed'   In instance methods, you normally refer to self to access instance attributes. It is normal to set instance attributes in __init__ and read or change them in instance methods. That is also why you pass self als the first argument to def Change.  Another solution would be to create a static method like this:  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.variable = PassByReference.Change(self.variable)         print self.variable      @staticmethod     def Change(var):         var = 'Changed'         return var      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "6", "A_Content": "  There is a little trick to pass an object by reference, even though the language doesn't make it possible. It works in Java too, it's the list with one item. ;-)  class PassByReference:     def __init__(self, name):         self.name = name  def changeRef(ref):     ref[0] = PassByReference('Michael')  obj = PassByReference('Peter') print obj.name  p = [obj] # A pointer to obj! ;-) changeRef(p)  print p[0].name # p->name   It's an ugly hack, but it works. ;-P     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "4", "A_Content": "  I used the following method to quickly convert a couple of Fortran codes to Python.  True, it's not pass by reference as the original question was posed, but is a simple work around in some cases.  a=0 b=0 c=0 def myfunc(a,b,c):     a=1     b=2     c=3     return a,b,c  a,b,c = myfunc(a,b,c) print a,b,c      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "3", "A_Content": "  While pass by reference is nothing that fits well into python and should be rarely used there are some workarounds that actually can work to get the object currently assigned to a local variable or even reassign a local variable from inside of a called function.  The basic idea is to have a function that can do that access and can be passed as object into other functions or stored in a class.  One way is to use global (for global variables) or nonlocal (for local variables in a function) in a wrapper function.  def change(wrapper):     wrapper(7)  x = 5 def setter(val):     global x     x = val print(x)   The same idea works for reading and deleting a variable.  For just reading there is even a shorter way of just using lambda: x which returns a callable that when called returns the current value of x. This is somewhat like \"call by name\" used in languages in the distant past.  Passing 3 wrappers to access a variable is a bit unwieldy so those can be wrapped into a class that has a proxy attribute:  class ByRef:     def __init__(self, r, w, d):         self._read = r         self._write = w         self._delete = d     def set(self, val):         self._write(val)     def get(self):         return self._read()     def remove(self):         self._delete()     wrapped = property(get, set, remove)  # left as an exercise for the reader: define set, get, remove as local functions using global / nonlocal r = ByRef(get, set, remove) r.wrapped = 15   Pythons \"reflection\" support makes it possible to get a object that is capable of reassigning a name/variable in a given scope without defining functions explicitly in that scope:  class ByRef:     def __init__(self, locs, name):         self._locs = locs         self._name = name     def set(self, val):         self._locs[self._name] = val     def get(self):         return self._locs[self._name]     def remove(self):         del self._locs[self._name]     wrapped = property(get, set, remove)  def change(x):     x.wrapped = 7  def test_me():     x = 6     print(x)     change(ByRef(locals(), \"x\"))     print(x)   Here the ByRef class wraps a dictionary access. So attribute access to wrapped is translated to a item access in the passed dictionary. By passing the result of the builtin locals and the name of a local variable this ends up accessing a local variable. The python documentation as of 3.5 advises that changing the dictionary might not work but it seems to work for me.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "3", "A_Content": "  given the way python handles values and references to them, the only way you can reference an arbitrary instance attribute is by name:  class PassByReferenceIsh:     def __init__(self):         self.variable = 'Original'         self.change('variable')         print self.variable      def change(self, var):         self.__dict__[var] = 'Changed'   in real code you would, of course, add error checking on the dict lookup.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "2", "A_Content": "  Since your example happens to be object-oriented, you could make the following change to achieve a similar result:  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change('variable')         print(self.variable)      def change(self, var):         setattr(self, var, 'Changed')  # o.variable will equal 'Changed' o = PassByReference() assert o.variable == 'Changed'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference", "Language": "Python", "Q_Title": "How do I pass a variable by reference?", "Q_Votes": "2086", "Q_Content": "    The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'  class PassByReference:     def __init__(self):         self.variable = 'Original'         self.change(self.variable)         print(self.variable)      def change(self, var):         var = 'Changed'   Is there something I can do to pass the variable by actual reference?     ", "Tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "A_Votes": "0", "A_Content": "  You can merely use an empty class as an instance to store reference objects because internally object attributes are stored in an instance dictionary. See the example.  class RefsObj(object):     \"A class which helps to create references to variables.\"     pass  ...  # an example of usage def change_ref_var(ref_obj):     ref_obj.val = 24  ref_obj = RefsObj() ref_obj.val = 1 print(ref_obj.val) # or print ref_obj.val for python2 change_ref_var(ref_obj) print(ref_obj.val)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "3925", "A_Content": "  key is just a variable name.    for key in d:   will simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:  For Python 2.x:  for key, value in d.iteritems():   For Python 3.x:  for key, value in d.items():   To test for yourself, change the word key to poop.  For Python 3.x, iteritems() has been replaced with simply items(), which returns a set-like view backed by the dict, like iteritems() but even better.  This is also available in 2.7 as viewitems().   The operation items() will work for both 2 and 3, but in 2 it will return a list of the dictionary's (key, value) pairs, which will not reflect changes to the dict that happen after the items() call. If you want the 2.x behavior in 3.x, you can call list(d.items()).     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "330", "A_Content": "  It's not that key is a special word, but that dictionaries implement the iterator protocol.  You could do this in your class, e.g. see this question for how to build class iterators.  In the case of dictionaries, it's implemented at the C level.  The details are available in PEP 234.  In particular, the section titled \"Dictionary Iterators\":        Dictionaries implement a tp_iter slot that returns an efficient   iterator that iterates over the keys of the dictionary. [...] This    means that we can write  for k in dict: ...       which is equivalent to, but much faster than  for k in dict.keys(): ...       as long as the restriction on modifications to the dictionary   (either by the loop or by another thread) are not violated.   Add methods to dictionaries that return different kinds of   iterators explicitly:  for key in dict.iterkeys(): ...  for value in dict.itervalues(): ...  for key, value in dict.iteritems(): ...       This means that for x in dict is shorthand for for x in    dict.iterkeys().         ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "153", "A_Content": "  Iterating over a dict iterates through its keys in no particular order, as you can see here:   Edit: (This is no longer the case in Python3.6, but note that it's not guaranteed behaviour yet)  >>> d = {'x': 1, 'y': 2, 'z': 3}  >>> list(d) ['y', 'x', 'z'] >>> d.keys() ['y', 'x', 'z']   For your example, it is a better idea to use dict.items():  >>> d.items() [('y', 2), ('x', 1), ('z', 3)]   This gives you a list of tuples. When you loop over them like this, each tuple is unpacked into k and v automatically:  for k,v in d.items():     print(k, 'corresponds to', v)   Using k and v as variable names when looping over a dict is quite common if the body of the loop is only a few lines. For more complicated loops it may be a  good idea to use more descriptive names:  for letter, number in d.items():     print(letter, 'corresponds to', number)   It's a good idea to get into the habit of using format strings:  for letter, number in d.items():     print('{0} corresponds to {1}'.format(letter, number))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "51", "A_Content": "  key is simply a variable.  For Python2.X:  d = {'x': 1, 'y': 2, 'z': 3}  for my_var in d:     print my_var, 'corresponds to', d[my_var]   ... or better,  d = {'x': 1, 'y': 2, 'z': 3}  for the_key, the_value in d.iteritems():     print the_key, 'corresponds to', the_value   For Python3.X:  d = {'x': 1, 'y': 2, 'z': 3}  for the_key, the_value in d.items():     print(the_key, 'corresponds to', the_value)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "39", "A_Content": "  When you iterate through dictionaries using the for .. in ..-syntax, it always iterates over the keys (the values are accessible using dictionary[key]).  To iterate over key-value pairs, use for k,v in s.iteritems().      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "20", "A_Content": "  This is a very common looping idiom. in is an operator. For when to use for key in dict and when it must be for key in dict.keys() see David Goodger's Idiomatic Python article.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "9", "A_Content": "  You can use this:  for key,val in d.items():     print key, 'is the key for ', val      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "7", "A_Content": "  I have a use case where I have to iterate through the dict to get the key, value pair, also the index indicating where I am. This is how I do it:  d = {'x': 1, 'y': 2, 'z': 3}  for i, (key, value) in enumerate(d.items()):    print(i, key, value)   Note that the parentheses around the key, value is important, without the parentheses, you get an ValueError \"not enough values to unpack\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "5", "A_Content": "     Iterating over dictionaries using 'for' loops  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     ...       How does Python recognize that it needs only to read the key from the   dictionary? Is key a special word in Python? Or is it simply a   variable?   It's not just for loops. The important word here is \"iterating\".  A dictionary is a mapping of keys to values:  d = {'x': 1, 'y': 2, 'z': 3}    Any time we iterate over it, we iterate over the keys. The variable name key is only intended to be descriptive - and it is quite apt for the purpose.  This happens in a list comprehension:  >>> [k for k in d] ['x', 'y', 'z']   It happens when we pass the dictionary to list (or any other collection type object):  >>> list(d) ['x', 'y', 'z']   The way Python iterates is, in a context where it needs to, it calls the __iter__ method of the object (in this case the dictionary) which returns an iterator (in this case, a keyiterator object):  >>> d.__iter__() <dict_keyiterator object at 0x7fb1747bee08>   We shouldn't use these special methods ourselves, instead, use the respective builtin function to call it, iter:  >>> key_iterator = iter(d) >>> key_iterator <dict_keyiterator object at 0x7fb172fa9188>   Iterators have a __next__ method - but we call it with the builtin function, next:  >>> next(key_iterator) 'x' >>> next(key_iterator) 'y' >>> next(key_iterator) 'z' >>> next(key_iterator) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> StopIteration   When an iterator is exhausted, it raises StopIteration. This is how Python knows to exit a for loop, or a list comprehension, or a generator expression, or any other iterative context. Once an iterator raises StopIteration it will always raise it - if you want to iterate again, you need a new one.  >>> list(key_iterator) [] >>> new_key_iterator = iter(d) >>> list(new_key_iterator) ['x', 'y', 'z']   Returning to dicts  We've seen dicts iterating in many contexts. What we've seen is that any time we iterate over a dict, we get the keys. Back to the original example:   d = {'x': 1, 'y': 2, 'z': 3}  for key in d:    If we change the variable name, we still get the keys. Let's try it:  >>> for each_key in d: ...     print(each_key, '=>', d[each_key]) ...  x => 1 y => 2 z => 3   If we want to iterate over the values, we need to use the .values method of dicts, or for both together, .items:  >>> list(d.values()) [1, 2, 3] >>> list(d.items()) [('x', 1), ('y', 2), ('z', 3)]   In the example given, it would be more efficient to iterate over the items like this:  for a_key, corresponding_value in d.items():     print(a_key, corresponding_value)   But for academic purposes, the question's example is just fine.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "3", "A_Content": "  You can check the implementation of CPython's dicttype on GitHub. This is the signature of method that implements the dict iterator:  _PyDict_Next(PyObject *op, Py_ssize_t *ppos, PyObject **pkey,              PyObject **pvalue, Py_hash_t *phash)   CPython dictobject.c     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3294889/iterating-over-dictionaries-using-for-loops", "Language": "Python", "Q_Title": "Iterating over dictionaries using 'for' loops", "Q_Votes": "2181", "Q_Content": "    I am a bit puzzled by the following code:  d = {'x': 1, 'y': 2, 'z': 3}  for key in d:     print key, 'corresponds to', d[key]   What I don't understand is the key portion. How does Python recognize that it needs only to read the key from the dictionary? Is key a special word in Python? Or is it simply a variable?     ", "Tags": ["python", "python-2.7", "dictionary"], "A_Votes": "2", "A_Content": "  To iterate over keys, it is slower but better to use my_dict.keys(). If you tried to do something like this:  for key in my_dict:     my_dict[key+\"-1\"] = my_dict[key]-1   it would create a runtime error because you are changing the keys while the program is running. If you are absolutely set on reducing time, use the for key in my_dict way, but you have been warned ;).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "3086", "A_Content": "  flat_list = [item for sublist in l for item in sublist]   which means:  for sublist in l:     for item in sublist:         flat_list.append(item)   is faster than the shortcuts posted so far. (l is the list to flatten.)  Here is a the corresponding function:  flatten = lambda l: [item for sublist in l for item in sublist]   For evidence, as always, you can use the timeit module in the standard library:  $ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' '[item for sublist in l for item in sublist]' 10000 loops, best of 3: 143 usec per loop $ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'sum(l, [])' 1000 loops, best of 3: 969 usec per loop $ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'reduce(lambda x,y: x+y,l)' 1000 loops, best of 3: 1.1 msec per loop   Explanation: the shortcuts based on + (including the implied use in sum) are, of necessity, O(L**2) when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So (for simplicity and without actual loss of generality) say you have L sublists of I items each: the first I items are copied back and forth L-1 times, the second I items L-2 times, and so on; total number of copies is I times the sum of x for x from 1 to L excluded, i.e., I * (L**2)/2.  The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "1106", "A_Content": "  You can use itertools.chain():  >>> import itertools >>> list2d = [[1,2,3],[4,5,6], [7], [8,9]] >>> merged = list(itertools.chain(*list2d))   or, on Python >=2.6, use itertools.chain.from_iterable() which doesn't require unpacking the list:  >>> import itertools >>> list2d = [[1,2,3],[4,5,6], [7], [8,9]] >>> merged = list(itertools.chain.from_iterable(list2d))   This approach is arguably more readable than [item for sublist in l for item in sublist] and appears to be faster too:  [me@home]$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99;import itertools' 'list(itertools.chain.from_iterable(l))' 10000 loops, best of 3: 24.2 usec per loop [me@home]$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' '[item for sublist in l for item in sublist]' 10000 loops, best of 3: 45.2 usec per loop [me@home]$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'sum(l, [])' 1000 loops, best of 3: 488 usec per loop [me@home]$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'reduce(lambda x,y: x+y,l)' 1000 loops, best of 3: 522 usec per loop [me@home]$ python --version Python 2.7.3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "647", "A_Content": "  Note from the author: This is inefficient. But fun, because monads are awesome. It's not appropriate for production Python code.  >>> sum(l, []) [1, 2, 3, 4, 5, 6, 7, 8, 9]   This just sums the elements of iterable passed in the first argument, treating second argument as the initial value of the sum (if not given, 0 is used instead and this case will give you an error).  Because you are summing nested lists, you actually get [1,3]+[2,4] as a result of sum([[1,3],[2,4]],[]), which is equal to [1,3,2,4].  Note that only works on lists of lists. For lists of lists of lists, you'll need another solution.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "151", "A_Content": "  I tested most suggested solutions with perfplot (a pet project of mine, essentially a wrapper around timeit), and found    list(itertools.chain.from_iterable(a))   to be the fastest solution (if more than 10 lists are concatenated).      Code to reproduce the plot:    import functools import itertools import numpy import operator import perfplot   def forfor(a):     return [item for sublist in a for item in sublist]   def sum_brackets(a):     return sum(a, [])   def functools_reduce(a):     return functools.reduce(operator.concat, a)   def itertools_chain(a):     return list(itertools.chain.from_iterable(a))   def numpy_flat(a):     return list(numpy.array(a).flat)   def numpy_concatenate(a):     return list(numpy.concatenate(a))   perfplot.show(     setup=lambda n: [list(range(10))] * n,     kernels=[         forfor, sum_brackets, functools_reduce, itertools_chain, numpy_flat,         numpy_concatenate         ],     n_range=[2**k for k in range(16)],     logx=True,     logy=True,     xlabel='num lists'     )      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "104", "A_Content": "  from functools import reduce #python 3  >>> l = [[1,2,3],[4,5,6], [7], [8,9]] >>> reduce(lambda x,y: x+y,l) [1, 2, 3, 4, 5, 6, 7, 8, 9]   The extend() method in your example modifies x instead of returning a useful value (which reduce() expects).  A faster way to do the reduce version would be  >>> import operator >>> l = [[1,2,3],[4,5,6], [7], [8,9]] >>> reduce(operator.concat, l) [1, 2, 3, 4, 5, 6, 7, 8, 9]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "61", "A_Content": "  Here is a general approach that applies to numbers, strings, nested lists and mixed containers.  Code  from collections import Iterable   def flatten(items):     \"\"\"Yield items from any nested iterable; see Reference.\"\"\"     for x in items:         if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):             for sub_x in flatten(x):                 yield sub_x         else:             yield x   Note: in Python 3, yield from flatten(x) can replace for sub_x in flatten(x): yield sub_x  Demo  lst = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] list(flatten(lst))                                         # nested lists # [1, 2, 3, 4, 5, 6, 7, 8, 9]  mixed = [[1, [2]], (3, 4, {5, 6}, 7), 8, \"9\"]              # numbers, strs, nested & mixed list(flatten(mixed)) # [1, 2, 3, 4, 5, 6, 7, 8, '9']   Reference   This solution is modified from a recipe in Beazley, D. and B. Jones.  Recipe 4.14, Python Cookbook 3rd Ed., O'Reilly Media Inc. Sebastopol, CA: 2013. Found an earlier SO post, possibly the original demonstration.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "32", "A_Content": "  I take my statement back. sum is not the winner. Although it is faster when the list is small. But the performance degrades significantly with larger lists.   >>> timeit.Timer(         '[item for sublist in l for item in sublist]',         'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]] * 10000'     ).timeit(100) 2.0440959930419922   The sum version is still running for more than a minute and it hasn't done processing yet!  For medium lists:  >>> timeit.Timer(         '[item for sublist in l for item in sublist]',         'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]] * 10'     ).timeit() 20.126545906066895 >>> timeit.Timer(         'reduce(lambda x,y: x+y,l)',         'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]] * 10'     ).timeit() 22.242258071899414 >>> timeit.Timer(         'sum(l, [])',         'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]] * 10'     ).timeit() 16.449732065200806   Using small lists and timeit: number=1000000  >>> timeit.Timer(         '[item for sublist in l for item in sublist]',         'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]]'     ).timeit() 2.4598159790039062 >>> timeit.Timer(         'reduce(lambda x,y: x+y,l)',         'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]]'     ).timeit() 1.5289170742034912 >>> timeit.Timer(         'sum(l, [])',         'l=[[1, 2, 3], [4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7]]'     ).timeit() 1.0598428249359131      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "27", "A_Content": "  Why do you use extend?  reduce(lambda x, y: x+y, l)   This should work fine.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "19", "A_Content": "  There seems to be a confusion with operator.add! When you add two lists together, the correct term for that is concat, not add. operator.concat is what you need to use.  If you're thinking functional, it is as easy as this::  >>> list2d = ((1,2,3),(4,5,6), (7,), (8,9)) >>> reduce(operator.concat, list2d) (1, 2, 3, 4, 5, 6, 7, 8, 9)   You see reduce respects the sequence type, so when you supply a tuple, you get back a tuple. let's try with a list::  >>> list2d = [[1,2,3],[4,5,6], [7], [8,9]] >>> reduce(operator.concat, list2d) [1, 2, 3, 4, 5, 6, 7, 8, 9]   Aha, you get back a list.  How about performance::  >>> list2d = [[1,2,3],[4,5,6], [7], [8,9]] >>> %timeit list(itertools.chain.from_iterable(list2d)) 1000000 loops, best of 3: 1.36 \u00b5s per loop   from_iterable is pretty fast! But it's no comparison to reduce with concat.  >>> list2d = ((1,2,3),(4,5,6), (7,), (8,9)) >>> %timeit reduce(operator.concat, list2d) 1000000 loops, best of 3: 492 ns per loop      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "18", "A_Content": "  If you want to flatten a data-structure where you don't know how deep it's nested you could use iteration_utilities.deepflatten1  >>> from iteration_utilities import deepflatten  >>> l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] >>> list(deepflatten(l, depth=1)) [1, 2, 3, 4, 5, 6, 7, 8, 9]  >>> l = [[1, 2, 3], [4, [5, 6]], 7, [8, 9]] >>> list(deepflatten(l)) [1, 2, 3, 4, 5, 6, 7, 8, 9]   It's a generator so you need to cast the result to a list or explicitly iterate over it.    To flatten only one level and if each of the items is itself iterable you can also use iteration_utilities.flatten which itself is just a thin wrapper around itertools.chain.from_iterable:  >>> from iteration_utilities import flatten >>> l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] >>> list(flatten(l)) [1, 2, 3, 4, 5, 6, 7, 8, 9]     Just to add some timings (based on Nico Schl\u00f6mer answer that didn't include the function presented in this answer):    It's a log-log plot to accommodate for the huge range of values spanned. For qualitative reasoning: Lower is better.  The results show that if the iterable contains only a few inner iterables then sum will be fastest, however for long iterables only the itertools.chain.from_iterable, iteration_utilities.deepflatten or the nested comprehension have reasonable performance with itertools.chain.from_iterable being the fastest (as already noticed by Nico Schl\u00f6mer).  from itertools import chain from functools import reduce from collections import Iterable  # or from collections.abc import Iterable import operator from iteration_utilities import deepflatten  def nested_list_comprehension(lsts):     return [item for sublist in lsts for item in sublist]  def itertools_chain_from_iterable(lsts):     return list(chain.from_iterable(lsts))  def pythons_sum(lsts):     return sum(lsts, [])  def reduce_add(lsts):     return reduce(lambda x, y: x + y, lsts)  def pylangs_flatten(lsts):     return list(flatten(lsts))  def flatten(items):     \"\"\"Yield items from any nested iterable; see REF.\"\"\"     for x in items:         if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):             yield from flatten(x)         else:             yield x  def reduce_concat(lsts):     return reduce(operator.concat, lsts)  def iteration_utilities_deepflatten(lsts):     return list(deepflatten(lsts, depth=1))   from simple_benchmark import benchmark  b = benchmark(     [nested_list_comprehension, itertools_chain_from_iterable, pythons_sum, reduce_add,      pylangs_flatten, reduce_concat, iteration_utilities_deepflatten],     arguments={2**i: [[0]*5]*(2**i) for i in range(1, 13)},     argument_name='number of inner lists' )  b.plot()     1 Disclaimer: I'm the author of that library     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "14", "A_Content": "  Consider installing the more_itertools package.  > pip install more_itertools   It ships with an implementation for flatten (source, from the itertools recipes):  import more_itertools   lst = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] list(more_itertools.flatten(lst)) # [1, 2, 3, 4, 5, 6, 7, 8, 9]   As of version 2.4, you can flatten more complicated, nested iterables with more_itertools.collapse (source, contributed by  abarnet).  lst = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] list(more_itertools.collapse(lst))  # [1, 2, 3, 4, 5, 6, 7, 8, 9]  lst = [[1, 2, 3], [[4, 5, 6]], [[[7]]], 8, 9]              # complex nesting list(more_itertools.collapse(lst)) # [1, 2, 3, 4, 5, 6, 7, 8, 9]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "13", "A_Content": "  The reason your function didn't work: the extend extends array in-place and doesn't return it. You can still return x from lambda, using some trick:  reduce(lambda x,y: x.extend(y) or x, l)   Note: extend is more efficient than + on lists.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "8", "A_Content": "  An bad feature of Anil's function above is that it requires the user to always manually specify the second argument to be an empty list []. This should instead be a default. Due to the way Python objects work, these should be set inside the function, not in the arguments.  Here's a working function:  def list_flatten(l, a=None):     #check a     if a is None:         #initialize with empty list         a = []      for i in l:         if isinstance(i, list):             list_flatten(i, a)         else:             a.append(i)     return a   Testing:  In [2]: lst = [1, 2, [3], [[4]],[5,[6]]]  In [3]: lst Out[3]: [1, 2, [3], [[4]], [5, [6]]]  In [11]: list_flatten(lst) Out[11]: [1, 2, 3, 4, 5, 6]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "7", "A_Content": "  Following seem simplest to me:  >>> import numpy as np >>> l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] >>> print (np.concatenate(l)) [1 2 3 4 5 6 7 8 9]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "6", "A_Content": "  One can also use NumPy's flat:  import numpy as np list(np.array(l).flat)   Edit 11/02/2016: Only works when sublists have identical dimensions.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "6", "A_Content": "  def flatten(l, a):     for i in l:         if isinstance(i, list):             flatten(i, a)         else:             a.append(i)     return a  print(flatten([[[1, [1,1, [3, [4,5,]]]], 2, 3], [4, 5],6], []))  # [1, 1, 1, 3, 4, 5, 2, 3, 4, 5, 6]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "1651", "A_Content": "  Python 2.7.9+ and 3.4+  Good news! Python 3.4 (released March 2014) and Python 2.7.9 (released December 2014) ship with Pip. This is the best feature of any Python release. It makes the community's wealth of libraries accessible to everyone. Newbies are no longer excluded from using community libraries by the prohibitive difficulty of setup. In shipping with a package manager, Python joins Ruby, Node.js, Haskell, Perl, Go--almost every other contemporary language with a majority open-source community. Thank you Python.  Of course, that doesn't mean Python packaging is problem solved. The experience remains frustrating. I discuss this in Stack Overflow question Does Python have a package/module management system?.  And, alas for everyone using Python 2.7.8 or earlier (a sizable portion of the community). There's no plan to ship Pip to you. Manual instructions follow.  Python 2 \u2264 2.7.8 and Python 3 \u2264 3.3  Flying in the face of its 'batteries included' motto, Python ships without a package manager. To make matters worse, Pip was--until recently--ironically difficult to install.  Official instructions  Per https://pip.pypa.io/en/stable/installing/#do-i-need-to-install-pip:  Download get-pip.py, being careful to save it as a .py file rather than .txt. Then, run it from the command prompt:  python get-pip.py   You possibly need an administrator command prompt to do this. Follow Start a Command Prompt as an Administrator (Microsoft TechNet).  This installs the pip package, which (in Windows) contains ...\\Scripts\\pip.exe that path must be in PATH environment variable to use pip from the command line (see the second part of 'Alternative Instructions' for adding it to your PATH,  Alternative instructions  The official documentation tells users to install Pip and each of its dependencies from source. That's tedious for the experienced and prohibitively difficult for newbies.  For our sake, Christoph Gohlke prepares Windows installers (.msi) for popular Python packages. He builds installers for all Python versions, both 32 and 64 bit. You need to:   Install setuptools Install pip   For me, this installed Pip at C:\\Python27\\Scripts\\pip.exe. Find pip.exe on your computer, then add its folder (for example, C:\\Python27\\Scripts) to your path (Start / Edit environment variables). Now you should be able to run pip from the command line. Try installing a package:  pip install httpie   There you go (hopefully)! Solutions for common problems are given below:  Proxy problems  If you work in an office, you might be behind an HTTP proxy. If so, set the environment variables http_proxy and https_proxy. Most Python applications (and other free software) respect these. Example syntax:  http://proxy_url:port http://username:password@proxy_url:port   If you're really unlucky, your proxy might be a Microsoft NTLM proxy. Free software can't cope. The only solution is to install a free software friendly proxy that forwards to the nasty proxy. http://cntlm.sourceforge.net/  Unable to find vcvarsall.bat  Python modules can be partly written in C or C++. Pip tries to compile from source. If you don't have a C/C++ compiler installed and configured, you'll see this cryptic error message.     Error: Unable to find vcvarsall.bat   You can fix that by installing a C++ compiler such as MinGW or Visual C++. Microsoft actually ships one specifically for use with Python. Or try Microsoft Visual C++ Compiler for Python 2.7.  Often though it's easier to check Christoph's site for your package.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "6", "A_Content": "  matplotlib.cbook.flatten() will work for nested lists even if they nest more deeply than the example.  import matplotlib l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] print(list(matplotlib.cbook.flatten(l))) l2 = [[1, 2, 3], [4, 5, 6], [7], [8, [9, 10, [11, 12, [13]]]]] print list(matplotlib.cbook.flatten(l2))   Result:  [1, 2, 3, 4, 5, 6, 7, 8, 9] [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]   This is 18x faster than underscore._.flatten:  Average time over 1000 trials of matplotlib.cbook.flatten: 2.55e-05 sec Average time over 1000 trials of underscore._.flatten: 4.63e-04 sec (time for underscore._)/(time for matplotlib.cbook) = 18.1233394636      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "5", "A_Content": "  Simple code for underscore.py package fan  from underscore import _ _.flatten([[1, 2, 3], [4, 5, 6], [7], [8, 9]]) # [1, 2, 3, 4, 5, 6, 7, 8, 9]   It solves all flatten problems (none list item or complex nesting)  from underscore import _ # 1 is none list item # [2, [3]] is complex nesting _.flatten([1, [2, [3]], [4, 5, 6], [7], [8, 9]]) # [1, 2, 3, 4, 5, 6, 7, 8, 9]   You can install underscore.py with pip  pip install underscore.py      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "4", "A_Content": "  def flatten(alist):     if alist == []:         return []     elif type(alist) is not list:         return [alist]     else:         return flatten(alist[0]) + flatten(alist[1:])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "3", "A_Content": "  If you are willing to give up a tiny amount of speed for a cleaner look, then you could use numpy.concatenate().tolist() or numpy.concatenate().ravel().tolist():  import numpy  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] * 99  %timeit numpy.concatenate(l).ravel().tolist() 1000 loops, best of 3: 313 \u00b5s per loop  %timeit numpy.concatenate(l).tolist() 1000 loops, best of 3: 312 \u00b5s per loop  %timeit [item for sublist in l for item in sublist] 1000 loops, best of 3: 31.5 \u00b5s per loop   You can find out more here in the docs numpy.concatenate and numpy.ravel     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "3", "A_Content": "  flat_list = [] for i in list_of_list:     flat_list+=i   This Code also works fine as it just extend the list all the way. Although it is much similar but only have one for loop. So It have less complexity than adding 2 for loops.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "3", "A_Content": "  You can use numpy : flat_list = list(np.concatenate(list_of_list))     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "2", "A_Content": "  Fastest solution I have found (for large list anyway):  import numpy as np #turn list into an array and flatten() np.array(l).flatten()   Done! You can of course turn it back into a list by executing list(l)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "2", "A_Content": "  I recently came across a situation where I had a mix of strings and numeric data in sublists such as  test = ['591212948', ['special', 'assoc', 'of', 'Chicago', 'Jon', 'Doe'], ['Jon'], ['Doe'], ['fl'], 92001, 555555555, 'hello', ['hello2', 'a'], 'b', ['hello33', ['z', 'w'], 'b']]   where methods like flat_list = [item for sublist in test for item in sublist] have not worked. So, I came up with the following solution for 1+ level of sublists  def concatList(data):     results = []     for rec in data:         if type(rec) == list:             results += rec             results = concatList(results)         else:             results.append(rec)     return results   And the result  In [38]: concatList(test) Out[38]:  Out[60]: ['591212948', 'special', 'assoc', 'of', 'Chicago', 'Jon', 'Doe', 'Jon', 'Doe', 'fl', 92001, 555555555, 'hello', 'hello2', 'a', 'b', 'hello33', 'z', 'w', 'b']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "2", "A_Content": "  Another unusual approach that works for hetero- and homogeneous lists of integers:  from typing import List   def flatten(l: list) -> List[int]:     \"\"\"Flatten an arbitrary deep nested list of lists of integers.      Examples:         >>> flatten([1, 2, [1, [10]]])         [1, 2, 1, 10]      Args:         l: Union[l, Union[int, List[int]]      Returns:         Flatted list of integer     \"\"\"     return [int(i.strip('[ ]')) for i in str(l).split(',')]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "1", "A_Content": "  You can avoid recursive calls to the stack using an actual stack data structure pretty simply.  alist = [1,[1,2],[1,2,[4,5,6],3, \"33\"]] newlist = []  while len(alist) > 0 :   templist = alist.pop()   if type(templist) == type(list()) :     while len(templist) > 0 :       temp = templist.pop()       if type(temp) == type(list()) :         for x in temp :           templist.append(x)       else :         newlist.append(temp)   else :     newlist.append(templist) print(list(reversed(newlist)))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "1", "A_Content": "  This may not be the most efficient way but I thought to put a one-liner (actually a two-liner). Both versions will work on arbitrary hierarchy nested lists, and exploits language features (Python3.5) and recursion.  def make_list_flat (l):     flist = []     flist.extend ([l]) if (type (l) is not list) else [flist.extend (make_list_flat (e)) for e in l]     return flist  a = [[1, 2], [[[[3, 4, 5], 6]]], 7, [8, [9, [10, 11], 12, [13, 14, [15, [[16, 17], 18]]]]]] flist = make_list_flat(a) print (flist)   The output is  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]   This works in a depth first manner. The recursion goes down until it finds a non-list element, then extends the local variable flist and then rolls back it to the parent. Whenever flist is returned, it is extended to the parent's flist in the list comprehension. Therefore, at the root, a flat list is returned.  The above one creates several local lists and returns them which are used to extend the parent's list. I think the way around for this may be creating a gloabl flist, like below.  a = [[1, 2], [[[[3, 4, 5], 6]]], 7, [8, [9, [10, 11], 12, [13, 14, [15, [[16, 17], 18]]]]]] flist = [] def make_list_flat (l):     flist.extend ([l]) if (type (l) is not list) else [make_list_flat (e) for e in l]  make_list_flat(a) print (flist)   The output is again  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]   Although I am not sure at this time about the efficiency.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "1", "A_Content": "  Note: Below applies to Python 3.3+ because it uses yield_from.  six is also a third-party package, though it is stable.  Alternately, you could use sys.version.    In the case of obj = [[1, 2,], [3, 4], [5, 6]], all of the solutions here are good, including list comprehension and itertools.chain.from_iterable.  However, consider this slightly more complex case:  >>> obj = [[1, 2, 3], [4, 5], 6, 'abc', [7], [8, [9, 10]]]   There are several problems here:   One element, 6, is just a scalar; it's not iterable, so the above routes will fail here. One element, 'abc', is technically iterable (all strs are).  However, reading between the lines a bit, you don't want to treat it as such--you want to treat it as a single element. The final element, [8, [9, 10]] is itself a nested iterable.  Basic list comprehension and chain.from_iterable only extract \"1 level down.\"   You can remedy this as follows:  >>> from collections import Iterable >>> from six import string_types  >>> def flatten(obj): ...     for i in obj: ...         if isinstance(i, Iterable) and not isinstance(i, string_types): ...             yield from flatten(i) ...         else: ...             yield i   >>> list(flatten(obj)) [1, 2, 3, 4, 5, 6, 'abc', 7, 8, 9, 10]   Here, you check that the sub-element (1) is iterable with Iterable, an ABC from itertools, but also want to ensure that (2) the element is not \"string-like.\"     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "0", "A_Content": "  Cleaned up @Deleet example  from collections import Iterable  def flatten(l, a=[]):     for i in l:         if isinstance(i, Iterable):             flatten(i, a)         else:             a.append(i)     return a  daList = [[1,4],[5,6],[23,22,234,2],[2], [ [[1,2],[1,2]],[[11,2],[11,22]] ] ]  print(flatten(daList))   Example: https://repl.it/G8mb/0     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "Language": "Python", "Q_Title": "Making a flat list out of list of lists in Python", "Q_Votes": "2145", "Q_Content": "    I wonder whether there is a shortcut to make a simple list out of list of lists in Python.  I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with reduce, but I get an error.  Code  l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] reduce(lambda x, y: x.extend(y), l)   Error message  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 1, in <lambda> AttributeError: 'NoneType' object has no attribute 'extend'      ", "Tags": ["python", "list", "multidimensional-array", "flatten"], "A_Votes": "0", "A_Content": "  This can be done using toolz.concat or cytoolz.concat (cythonized version, that could be faster in some cases):  from cytoolz import concat l = [[1, 2, 3], [4, 5, 6], [7], [8, 9]] list(concat(l)) # or just `concat(l)` if one only wants to iterate over the items   On my computer, in python 3.6, this seems to time almost as fast as [item for sublist in l for item in sublist] (not counting the import time):  In [611]: %timeit L = [item for sublist in l for item in sublist] 695 ns \u00b1 2.75 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)  In [612]: %timeit L = [item for sublist in l for item in sublist] 701 ns \u00b1 5.5 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)  In [613]: %timeit L = list(concat(l)) 719 ns \u00b1 12 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)  In [614]: %timeit L = list(concat(l)) 719 ns \u00b1 22.9 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)   The toolz version is indeed slower:  In [618]: from toolz import concat  In [619]: %timeit L = list(concat(l)) 845 ns \u00b1 29 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)  In [620]: %timeit L = list(concat(l)) 833 ns \u00b1 8.73 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "291", "A_Content": "  -- Outdated -- use distribute, not setuptools as described here. -- -- Outdated #2 -- use setuptools as distribute is deprecated.  As you mentioned pip doesn't include an independent installer, but you can install it with its predecessor easy_install.  So:   Download the last pip version from here: http://pypi.python.org/pypi/pip#downloads Uncompress it Download the last easy installer for Windows: (download the .exe at the bottom of http://pypi.python.org/pypi/setuptools ). Install it. copy the uncompressed pip folder content into C:\\Python2x\\ folder (don't copy the whole folder into it, just the content), because python command doesn't work outside C:\\Python2x folder and then run:  python setup.py install Add your python C:\\Python2x\\Scripts to the path   You are done.   Now you can use pip install package to easily install packages as in Linux :)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "208", "A_Content": "  2014 UPDATE:  1) If you have installed Python 3.4 or later, pip is included with Python and should already be working on your system.  2) If you are running a version below Python 3.4 or if pip was not installed with Python 3.4 for some reason, then you'd probably use pip's official installation script get-pip.py. The pip installer now grabs setuptools for you, and works regardless of architecture (32-bit or 64-bit).  The installation instructions are detailed here and involve:     To install or upgrade pip, securely download get-pip.py.      Then run the following (which may require administrator access):   python get-pip.py      To upgrade an existing setuptools (or distribute), run pip install -U setuptools   I'll leave the two sets of old instructions below for posterity.  OLD Answers:  For Windows editions of the 64 bit variety - 64-bit Windows + Python used to require a separate installation method due to ez_setup, but I've tested the new distribute method on 64-bit Windows running 32-bit Python and 64-bit Python, and you can now use the same method for all versions of Windows/Python 2.7X:  OLD Method 2 using distribute:   Download distribute - I threw mine in C:\\Python27\\Scripts (feel free to create a Scripts directory if it doesn't exist. Open up a command prompt (on Windows you should check out conemu2 if you don't use PowerShell) and change (cd) to the directory you've downloaded distribute_setup.py to. Run distribute_setup: python distribute_setup.py (This will not work if your python installation directory is not added to your path - go here for help) Change the current directory to the Scripts directory for your Python installation (C:\\Python27\\Scripts) or add that directory, as well as the Python base installation directory to your %PATH% environment variable. Install pip using the newly installed setuptools: easy_install pip   The last step will not work unless you're either in the directory easy_install.exe is located in (C:\\Python27\\Scripts would be the default for Python 2.7), or you have that directory added to your path.  OLD Method 1 using ez_setup:  from the setuptools page --     Download ez_setup.py and run it; it will download the appropriate .egg file and install it for you. (Currently, the provided .exe installer does not support 64-bit versions of Python for Windows, due to a distutils installer compatibility issue.   After this, you may continue with:   Add c:\\Python2x\\Scripts to the Windows path (replace the x in Python2x with the actual version number you have installed) Open a new (!) DOS prompt. From there run easy_install pip      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "187", "A_Content": "  2016+ Update:   These answers are outdated or otherwise wordy and difficult.  If you've got Python 3.4+ or 2.7.9+, it will be installed by default on Windows.  Otherwise, in short:   Download the pip installer:  https://bootstrap.pypa.io/get-pip.py If paranoid, inspect file to confirm it isn't malicious (must b64 decode). Open a console in the download folder as Admin and run get-pip.py.  Alternatively, right-click its icon in Explorer and choose the \"run as Admin...\".   The new binaries pip.exe (and the deprecated easy_install.exe) will be found in the \"%ProgramFiles%\\PythonXX\\Scripts\" folder (or similar), which is likely not in your PATH variable.  I recommend adding it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "42", "A_Content": "  Python 3.4, which  was released in March 2014, comes with pip included: http://docs.python.org/3.4/whatsnew/3.4.html So since the release of Python 3.4, the up-to-date way to install pip on Windows is to just install Python. When sticking to all defaults during installation, pip will be installed to C:\\Python34\\Scripts\\pip3.exe.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "37", "A_Content": "  When I have to use Windows, I use ActivePython, which automatically adds everything to your PATH and includes a package manager called PyPM which provides binary package management making it faster and simpler to install packages.  pip and easy_install aren't exactly the same thing, so there are some things you can get through pip but not easy_install and vice versa.  My recommendation is that you get ActivePython Community Edition and don't worry about the huge hassle of getting everything set up for Python on Windows. Then, you can just use pypm.  In case you want to use pip you have to check the PyPM option in the ActiveState installer. After installation you only need to logoff and log on again, and pip will be available on the commandline, because it is contained in the ActiveState installer PyPM option and the paths have been set by the installer for you already. PyPM will also be available, but you do not have to use it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "34", "A_Content": "  The up-to-date way is to use Windows' package manager Chocolatey.  Once this is installed, all you have to do is open a command prompt and run the following the three commands below, which will install Python 2.7, easy_install and pip. It will automatically detect whether you're on x64 or x86 Windows.  cinst python cinst easy.install cinst pip   All of the other Python packages on the Chocolatey Gallery can be found here.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "27", "A_Content": "  Update March 2015  Python 2.7.9 and later (on the Python 2 series), and Python 3.4 and later include pip by default, so you may have pip already.  If you don't, run this one line command on your prompt (which may require administrator access):  python -c \"exec('try: from urllib2 import urlopen \\nexcept: from urllib.request import urlopen');f=urlopen('https://bootstrap.pypa.io/get-pip.py').read();exec(f)\"   It will install pip. If Setuptools is not already installed, get-pip.py will install it for you too.  As mentioned in comments, the above command will download code from the Pip source code repository at GitHub, and dynamically run it at your environment. So be noticed that this is a shortcut of the steps download, inspect and run, all with a single command using Python itself. If you trust Pip, proceed without doubt.  Be sure that your Windows environment variable PATH includes Python's folders (for Python 2.7.x default install: C:\\Python27 and C:\\Python27\\Scripts, for Python 3.3x: C:\\Python33 and C:\\Python33\\Scripts, and so on).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "23", "A_Content": "  Installers  I've built Windows installers for both distribute and pip here (the goal being to use pip without having to either bootstrap with easy_install or save and run Python scripts):   distribute-0.6.27.win32.exe pip-1.1.win32.exe   On Windows, simply download and install first distribute, then pip from the above links. The distribute link above does contain stub .exe installers, and these are currently 32-bit only. I haven't tested the effect on 64-bit Windows.  Building on Windows  The process to redo this for new versions is not difficult, and I've included it here for reference.  Building distribute  In order to get the stub .exe files, you need to have a Visual C++ compiler (it is apparently compilable with MinGW as well)  hg clone https://bitbucket.org/tarek/distribute cd distribute hg checkout 0.6.27 rem optionally, comment out tag_build and tag_svn_revision in setup.cfg msvc-build-launcher.cmd python setup.py bdist_win32 cd .. echo build is in distribute\\dist   Building pip  git clone https://github.com/pypa/pip.git cd pip git checkout 1.1 python setup.py bdist_win32 cd .. echo build is in pip\\dist      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "16", "A_Content": "  The following works for Python 2.7. Save this script and launch it:   https://raw.github.com/pypa/pip/master/contrib/get-pip.py   Pip is installed, then add the path to your environment :   C:\\Python27\\Scripts   Finally  pip install virtualenv   Also you need Microsoft Visual C++ 2008 Express to get the good compiler and avoid these kind of messages when installing packages:  error: Unable to find vcvarsall.bat   If you have a 64-bit version of Windows 7, you may read 64-bit Python installation issues on 64-bit Windows 7 to successfully install the Python executable package (issue with registry entries).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "14", "A_Content": "  To install pip globally on Python 2.x, easy_install appears to be the best solution as Adri\u00e1n states.  However the installation instructions for pip recommend using virtualenv since every virtualenv has pip installed in it automatically.  This does not require root access or modify your system Python installation.  Installing virtualenv still requires easy_install though.  2018 update:   Python 3.3+ now includes the venv module for easily creating virtual environments like so:  python3 -m venv /path/to/new/virtual/environment  See documentation for different platform methods of activating the environment after creation, but typically one of:  $ source <venv>/bin/activate   C:\\> <venv>\\Scripts\\activate.bat      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "12", "A_Content": "  To use pip, it is not mandatory that you need to install pip in the system directly. You can use it through virtualenv. What you can do is follow these steps:   Download virtualenv tar.gz file from https://pypi.python.org/pypi/virtualenv Unzip it with 7zip or some other tool   We normally need to install Python packages for one particular project. So, now create a project folder, let\u2019s say myproject.   Copy the virtualenv.py file from the decompressed folder of virtualenv, and paste inside the myproject folder   Now create a virtual environment, let\u2019s say myvirtualenv as follows, inside the myproject folder:  python virtualenv.py myvirtualenv   It will show you:  New python executable in myvirtualenv\\Scripts\\python.exe Installing setuptools....................................done. Installing pip.........................done.   Now your virtual environment, myvirtualenv, is created inside your project folder. You might notice, pip is now installed inside you virtual environment. All you need to do is activate the virtual environment with the following command.  myvirtualenv\\Scripts\\activate   You will see the following at the command prompt:  (myvirtualenv) PATH\\TO\\YOUR\\PROJECT\\FOLDER>pip install package_name   Now you can start using pip, but make sure you have activated the virtualenv looking at the left of your prompt.  This is one of the easiest way to install pip i.e. inside virtual environment, but you need to have virtualenv.py file with you.  For more ways to install pip/virtualenv/virtualenvwrapper, you can refer to thegauraw.tumblr.com.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "11", "A_Content": "  I just wanted to add one more solution for those having issues installing setuptools from Windows 64-bit. The issue is discussed in this bug on python.org and is still unresolved as of the date of this comment. A simple workaround is mentioned and it works flawlessly. One registry change did the trick for me.  Link: http://bugs.python.org/issue6792#  Solution that worked for me...:  Add this registry setting for 2.6+ versions of Python:   [HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\Python\\PythonCore\\2.6\\InstallPath]  @=\"C:\\\\Python26\\\\\"   This is most likely the registry setting you will already have for Python 2.6+:   [HKEY_LOCAL_MACHINE\\SOFTWARE\\Python\\PythonCore\\2.6\\InstallPath]  @=\"C:\\\\Python26\\\\\"   Clearly, you will need to replace the 2.6 version with whatever version of Python you are running.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "11", "A_Content": "  Updated at 2016 : Pip should already be included in Python 2.7.9+ or 3.4+, but if for whatever reason it is not there, you can use the following one-liner.   Download https://bootstrap.pypa.io/get-pip.py and run it with Administrator permission python get-pip.py (If you are on Linux, use sudo python get-pip.py)   PS:   This should already be satisfied in most cases but, if necessary, be sure that your environment variable PATH includes Python's folders (for example, Python 2.7.x on Windows default install: C:\\Python27 and C:\\Python27\\Scripts, for Python 3.3x: C:\\Python33 and C:\\Python33\\Scripts, etc) I encounter same problem and then found such perhaps easiest way (one liner!) mentioned on official website here: http://www.pip-installer.org/en/latest/installing.html   Can't believe there are so many lengthy (perhaps outdated?) answers out there. Feeling thankful to them but, please up-vote this short answer to help more new comers!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "2313", "A_Content": "  in is the intended way to test for the existence of a key in a dict.  d = dict()  for i in xrange(100):     key = i % 10     if key in d:         d[key] += 1     else:         d[key] = 1   If you wanted a default, you can always use dict.get():  d = dict()  for i in xrange(100):     key = i % 10     d[key] = d.get(key, 0) + 1   ... and if you wanted to always ensure a default value for any key you can use defaultdict from the collections module, like so:  from collections import defaultdict  d = defaultdict(lambda: 0)  for i in xrange(100):     d[i % 10] += 1   ... but in general, the in keyword is the best way to do it.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "10", "A_Content": "  The best way I found so far, is just two lines of code:  curl http://python-distribute.org/distribute_setup.py | python curl https://raw.github.com/pypa/pip/master/contrib/get-pip.py | python   It was tested on Windows 8 with PowerShell, Cmd, and Git Bash (MinGW).  And you probably want to add the path to your environment. It's somewhere like C:\\Python33\\Scripts.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "10", "A_Content": "  For latest Python Download - I have python 3.6 on windows. You don't have to wonder everything you need is there , take  a breath i will show you how to do it.   make sure where you install python for me its was in the following directory       Now , lets add python and pip into environment variable path settings   if you are on windows, so that typing pip or python anywhere call   python aor pip from where they are installed.   So, PIP is found under the folder in above screen \"SCRIPTS\" Lets add Python and PIP in environment variable path.    Almost Done , Let test with CMD to install goole package using pip.  pip install google     BYE BYE!      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "9", "A_Content": "  PythonXY comes with pip included, among others.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "9", "A_Content": "  Here how to install pip with easy way.   copy and paste these content in a file as get-pip.py copy and paste get-pip.py into python folder.C:\\Python27 Double click to get-pip.py file.it will install pip to your computer. Now you have to add C:\\Python27\\Scripts path to your enviroment variable.Because it includes pip.exe file. Now you are ready to use pip. Open cmd and type as pip install package_name      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "8", "A_Content": "  I use the cross-platform Anaconda package manager from continuum.io on Windows and it is reliable.  It has virtual environment management and a fully featured shell with common utilities (e.g. conda, pip).  > conda install <package>               # access distributed binaries  > pip install <package>                 # access PyPI packages    conda also comes with binaries for libraries with non-Python dependencies, e.g. pandas, numpy, etc.  This proves useful particularly on Windows as it can be  hard to correctly compile C dependencies.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "6", "A_Content": "  I wrote this pip install script that wraps both the ez_setup.py and get-pip.py install scripts that were mentioned in Gringo Suave's answer (and runs a pip install --upgrade setuptools for the latest setuptools version once pip is installed).  Clone the repository with:  git clone https://github.com/chrissimpkins/pip-installer.git   Or download a .zip archive:  https://github.com/chrissimpkins/pip-installer/archive/master.zip  And then run the pipinstall.py script in the top level of the repository directory:  python pipinstall.py   This will give you the latest releases for both applications.  It's safe to remove the script repository after the install.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "6", "A_Content": "  I had some issues installing in different ways when I followed instructions here. I think it's very tricky to install in every Windows environment in the same way. In my case I need Python 2.6, 2.7 and 3.3 in the same machine for different purposes so that's why I think there're more problems. But the following instructions worked perfectly for me, so might be depending on your environment you should try this one:  http://docs.python-guide.org/en/latest/starting/install/win/  Also, due to the different environments I found incredible useful to use Virtual Environments, I had websites that use different libraries and it's much better to encapsulate them into a single folder, check out the instructions, briefly if PIP is installed you just install VirtualEnv:  pip install virtualenv   Into the folder you have all your files run  virtualenv venv   And seconds later you have a virtual environment with everything in venv folder, to activate it run venv/Scripts/activate.bat (deactivate the environment is easy, use deactivate.bat). Every library you install will end up in venv\\Lib\\site-packages and it's easy to move your whole environment somewhere.  The only downside I found is some code editors can't recognize this kind of environments, and you will see warnings in your code because imported libraries are not found. Of course there're tricky ways to do it but it would be nice editors keep in mind Virtual Environments are very normal nowadays.  Hope it helps.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "6", "A_Content": "   Download script: https://raw.github.com/pypa/pip/master/contrib/get-pip.py Save it on drive somewhere like C:\\pip-script\\get-pip.py Navigate to that path from command prompt and run \" python get-pip.py \"   Guide link: http://www.pip-installer.org/en/latest/installing.html#install-pip  Note: Make sure scripts path like this (C:\\Python27\\Scripts) is added int %PATH% environment variable as well.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "3", "A_Content": "  It's very simple:  Step 1: wget https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py Step 2: wget https://raw.github.com/pypa/pip/master/contrib/get-pip.py Step 2: python ez_setup.py Step 3: python get-pip.py   (Make sure your Python and Python script directory (for example, C:\\Python27 and C:\\Python27\\Scripts) are in the PATH.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "3", "A_Content": "  Working as of Feb 04 2014 :):  If you have tried installing pip through the Windows installer file from http://www.lfd.uci.edu/~gohlke/pythonlibs/#pip as suggested by @Colonel Panic, you might have installed the pip package manager successfully, but you might be unable to install any packages with pip. You might also have got the same SSL error as I got when I tried to install Beautiful Soup\u00a04 if you look in the pip.log file:  Downloading/unpacking beautifulsoup4   Getting page https://pypi.python.org/simple/beautifulsoup4/   Could not fetch URL https://pypi.python.org/simple/beautifulsoup4/: **connection error: [Errno 1] _ssl.c:504: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed**   Will skip URL https://pypi.python.org/simple/beautifulsoup4/ when looking for download links for beautifulsoup4   The problem is an issue with an old version of OpenSSL being incompatible with pip 1.3.1 and above versions. The easy workaround for now, is to install pip 1.2.1, which does not require SSL:  Installing Pip on Windows:   Download pip 1.2.1 from https://pypi.python.org/packages/source/p/pip/pip-1.2.1.tar.gz Extract the pip-1.2.1.tar.gz file Change directory to the extracted folder: cd <path to extracted folder>/pip-1.2.1 Run python setup.py install Now make sure C:\\Python27\\Scripts is in PATH because pip is installed in the C:\\Python27\\Scripts directory unlike C:\\Python27\\Lib\\site-packages where Python packages are normally installed   Now try to install any package using pip.  For example, to install the requests package using pip, run this from cmd:  pip install requests   Whola! requests will be successfully installed and you will get a success message.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "3", "A_Content": "  pip is already installed if you're using Python 2 >=2.7.9 or Python 3 >=3.4 binaries downloaded from python.org, but you'll need to upgrade pip.  On Windows upgrade can be done easily   Go to Python command line and run below Python command  python -m pip install -U pip  Installing with get-pip.py  Download get-pip.py in the same folder or any other folder of your choice. I am assuming you will download it in the same folder from you have python.exe file and run this command   python get-pip.py   Pip's installation guide is pretty clean and simple.  Using this you should be able to get started with Pip in under two minutes.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "2", "A_Content": "  Just download setuptools-15.2.zip (md5), from here https://pypi.python.org/pypi/setuptools#windows-simplified , and run ez_setup.py.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "2", "A_Content": "  Alternatively, you can get pip-Win which is an all-in-one installer for pip and virtualenv on Windows and its GUI.   Switch from one Python interpreter (i.e. version) to another (including py and pypy) See all installed packages, and whether they are up-to-date Install or upgrade a package, or upgrade pip itself Create and delete virtual environments, and switch between them Run the IDLE or another Python script, with the selected interpreter      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "2", "A_Content": "  you have to get the get_pip.py file search it on google copy   from there and  save it locally in c drive in pip directory      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "1", "A_Content": "  I think the question makes it seem like the answer is simpler than it really is. Running of pip will sometimes require native compilation of a module (64-bit Numpy is a common example of that). In order for pip's compilation to succeed, you need Python which was compiled with the same version of MSVC as the one pip is using. Standard Python distributions are compiled with MSVC 2008. You can install an Express version of VC2008, but it is not maintained. Your best bet is to get an express version of a later MSVC and compile Python. Then PIP and Python will be using the same MSVC version.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4750806/how-do-i-install-pip-on-windows", "Language": "Python", "Q_Title": "How do I install pip on Windows?", "Q_Votes": "2251", "Q_Content": "    pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?     ", "Tags": ["python", "windows", "installation", "pip", "easy-install"], "A_Votes": "1", "A_Content": "  How to install pip:   Download and install ActivePython Open a command prompt (CMD) Type pypm install pip      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "1129", "A_Content": "  You don't have to call keys:  if 'key1' in dict:   print \"blah\" else:   print \"boo\"   That will be much faster as it uses the dictionary's hashing as opposed to doing a linear search, which calling keys would do.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "232", "A_Content": "  You can test for the presence of a key in a dictionary, using the in keyword:  d = {'a': 1, 'b': 2} 'a' in d # <== evaluates to True 'c' in d # <== evaluates to False   A common use for checking the existence of a key in a dictionary before mutating it is to default-initialize the value (e.g. if your values are lists, for example, and you want to ensure that there is an empty list to which you can append when inserting the first value for a key). In cases such as those, you may find the collections.defaultdict() type to be of interest.  In older code, you may also find some uses of has_key(), a deprecated method for checking the existence of keys in dictionaries (just use key_name in dict_name, instead).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "76", "A_Content": "  You can shorten this:  if 'key1' in dict:     ...   However, this is at best a cosmetic improvement. Why do you believe this is not the best way?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "40", "A_Content": "  I would recommend using the setdefault method instead.  It sounds like it will do everything you want.  >>> d = {'foo':'bar'} >>> q = d.setdefault('foo','baz') #Do not override the existing key >>> print q #The value takes what was originally in the dictionary bar >>> print d {'foo': 'bar'} >>> r = d.setdefault('baz',18) #baz was never in the dictionary >>> print r #Now r has the value supplied above 18 >>> print d #The dictionary's been updated {'foo': 'bar', 'baz': 18}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "35", "A_Content": "  For additional info on speed execution of the accepted answer's proposed methods (10m loops):   'key' in mydict elapsed time 1.07 sec mydict.get('key') elapsed time 1.84 sec mydefaultdict['key'] elapsed time 1.07 sec   Therefore using in or defaultdict are recommended against get.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "21", "A_Content": "  Dictionary in python has a get('key', default) method. So you can just set a default value in case there is no key.   values = {...} myValue = values.get('Key', None)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "18", "A_Content": "  What about using EAFP (easier to ask forgiveness than permission):  try:    blah = dict[\"mykey\"]    # key exists in dict except KeyError:    # key doesn't exist in dict   See other SO posts:  Using try vs if in python or  Checking for member existence in Python     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "16", "A_Content": "  For checking you can use has_key() method   if dict.has_key('key1'):    print \"it is there\"   If you want a value then you can use get() method  a = dict.get('key1', expeced_type)   If you want a tuple or list or dictionary or any string  as a default value as return value, then use get() method  a = dict.get('key1', {}).get('key2', [])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "16", "A_Content": "  Using ternary operator:  message = \"blah\" if 'key1' in dict else \"booh\" print(message)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "13", "A_Content": "  Just an FYI adding to Chris. B (best answer):  d = defaultdict(int)   Works as well; the reason is that calling int() returns 0 which is what defaultdict does behind the scenes (when constructing a dictionary), hence the name \"Factory Function\" in the documentation.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "12", "A_Content": "  The ways in which you can get the results are:   if your_dict.has_key(key) Removed in Python 3 if key in your_dict try/except block   Which is better is dependent on 3 things:   Does the dictionary 'normally has the key' or 'normally does not have the key'. Do you intend to use conditions like if...else...elseif...else? How big is dictionary?   Read More: http://paltman.com/try-except-performance-in-python-a-simple-test/  Use of try/block instead of 'in' or 'if':  try:     my_dict_of_items[key_i_want_to_check] except KeyError:     # Do the operation you wanted to do for \"key not present in dict\". else:     # Do the operation you wanted to do with \"key present in dict.\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "10", "A_Content": "  You can use the has_key() method:  if dict.has_key('xyz')==1:     #update the value for the key else:     pass   Or the dict.get method to set a default value if not found:  mydict = {\"a\": 5}  print mydict[\"a\"]            #prints 5 print mydict[\"b\"]            #Throws KeyError: 'b'  print mydict.get(\"a\", 0)     #prints 5 print mydict.get(\"b\", 0)     #prints 0      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "6", "A_Content": "  print dict.get('key1', 'blah')  Won't print boo for the values in the dict, but accomplishes the goal by printing the value of key1 to confirm it's existence instead.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "3", "A_Content": "  Python dictionary has the method called __contains__. This method will return True if the dictionary has the key else returns False.   >>> temp = {}   >>> help(temp.__contains__)  Help on built-in function __contains__:  __contains__(key, /) method of builtins.dict instance     True if D has a key k, else False.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "2", "A_Content": "  Well.. You will be familiar that searching a element's existence in a list or data means going through everything (at least for unordered list e.g dict.keys ).So Instead using Exception and Errors that arise normally we can avoid that complexity...  d={1:'a',2:'b'} try:     needed=d[3]     print(needed) except:     print(\"Key doesnt exist\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "0", "A_Content": "  Easiest one is if you know which key(key name) is to look for:  # suppose your dictionary is my_dict = {'foo': 1, 'bar': 2} # check if a key is there if 'key' in my_dict.keys():   # it will evaluates to true if that key is present otherwise false.     # do something   or you can also do simply as:  if 'key' in my_dict:   # it will evaluates to true if that key is present otherwise false.     # do something      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "Language": "Python", "Q_Title": "Check if a given key already exists in a dictionary", "Q_Votes": "2260", "Q_Content": "    I wanted to test if a key exists in a dictionary before updating the value for the key. I wrote the following code:  if 'key1' in dict.keys():   print \"blah\" else:   print \"boo\"   I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?     ", "Tags": ["python", "dictionary"], "A_Votes": "0", "A_Content": "  I use the try/except; if an exception is throwed, than the key aren't present at  the dictionary. example:  st = 'sdhfjaks' d = {} try:     print d['st'] except Exception, e:     print 'Key not in the dictionary'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "2204", "A_Content": "  Alex summarized well but, surprisingly, was too succinct.  First, let me reiterate the main points in Alex\u2019s post:   The default implementation is useless (it\u2019s hard to think of one which wouldn\u2019t be, but yeah) __repr__ goal is to be unambiguous __str__ goal is to be readable Container\u2019s __str__ uses contained objects\u2019 __repr__   Default implementation is useless  This is mostly a surprise because Python\u2019s defaults tend to be fairly useful. However, in this case, having a default for __repr__ which would act like:  return \"%s(%r)\" % (self.__class__, self.__dict__)   would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if __repr__ is defined, and __str__ is not, the object will behave as though __str__=__repr__.  This means, in simple terms: almost every object you implement should have a functional __repr__ that\u2019s usable for understanding the object. Implementing __str__ is optional: do that if you need a \u201cpretty print\u201d functionality (for example, used by a report generator).  The goal of __repr__ is to be unambiguous  Let me come right out and say it \u2014 I do not believe in debuggers. I don\u2019t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature \u2014 most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is a  log(INFO, \"I am in the weird function and a is\", a, \"and b is\", b, \"but I got a null C \u2014 using default\", default_c)   But you have to do the last step \u2014 make sure every object you implement has a useful repr, so code like that can just work. This is why the \u201ceval\u201d thing comes up: if you have enough information so eval(repr(c))==c, that means you know everything there is to know about c. If that\u2019s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about c anyway. I usually use an eval-like format: \"MyClass(this=%r,that=%r)\" % (self.this,self.that). It does not mean that you can actually construct MyClass, or that those are the right constructor arguments \u2014 but it is a useful form to express \u201cthis is everything you need to know about this instance\u201d.  Note: I used %r above, not %s. You always want to use repr() [or %r formatting character, equivalently] inside __repr__ implementation, or you\u2019re defeating the goal of repr. You want to be able to differentiate MyClass(3) and MyClass(\"3\").  The goal of __str__ is to be readable  Specifically, it is not intended to be unambiguous \u2014 notice that str(3)==str(\"3\"). Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be \"2010/4/12 15:35:22\", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class \u2014 as long is it supports readability, it is an improvement.  Container\u2019s __str__ uses contained objects\u2019 __repr__  This seems surprising, doesn\u2019t it? It is a little, but how readable would  [moshe is, 3, hello world, this is a list, oh I don't know, containing just 4 elements]   be? Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you\u2019re printing a list, just  print \"[\" + \", \".join(l) + \"]\"   (you can probably also figure out what to do about dictionaries.  Summary  Implement __repr__ for any class you implement. This should be second nature. Implement __str__ if you think it would be useful to have a string version which errs on the side of more readability in favor of more ambiguity.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "377", "A_Content": "  My rule of thumb:  __repr__ is for developers, __str__ is for customers.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "323", "A_Content": "  Unless you specifically act to ensure otherwise, most classes don't have helpful results for either:  >>> class Sic(object): pass ...  >>> print str(Sic()) <__main__.Sic object at 0x8b7d0> >>> print repr(Sic()) <__main__.Sic object at 0x8b7d0> >>>    As you see -- no difference, and no info beyond the class and object's id.  If you only override one of the two...:  >>> class Sic(object):  ...   def __repr__(object): return 'foo' ...  >>> print str(Sic()) foo >>> print repr(Sic()) foo >>> class Sic(object): ...   def __str__(object): return 'foo' ...  >>> print str(Sic()) foo >>> print repr(Sic()) <__main__.Sic object at 0x2617f0> >>>    as you see, if you override __repr__, that's ALSO used for __str__, but not vice versa.  Other crucial tidbits to know: __str__ on a built-on container uses the __repr__, NOT the __str__, for the items it contains. And, despite the words on the subject found in typical docs, hardly anybody bothers making the __repr__ of objects be a string that eval may use to build an equal object (it's just too hard, AND not knowing how the relevant module was actually imported makes it actually flat out impossible).  So, my advice: focus on making __str__ reasonably human-readable, and __repr__ as unambiguous as you possibly can, even if that interferes with the fuzzy unattainable goal of making __repr__'s returned value acceptable as input to __eval__!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "143", "A_Content": "  __repr__: representation of python object usually eval will convert it back to that object  __str__: is whatever you think is that object in text form  e.g.  >>> s=\"\"\"w'o\"w\"\"\" >>> repr(s) '\\'w\\\\\\'o\"w\\'' >>> str(s) 'w\\'o\"w' >>> eval(str(s))==s Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<string>\", line 1     w'o\"w        ^ SyntaxError: EOL while scanning single-quoted string >>> eval(repr(s))==s True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "117", "A_Content": "     In short, the goal of __repr__ is to be unambiguous and __str__ is to be   readable.   Here is a good example:  >>> import datetime >>> today = datetime.datetime.now() >>> str(today) '2012-03-14 09:21:58.130922' >>> repr(today) 'datetime.datetime(2012, 3, 14, 9, 21, 58, 130922)'   Read this documentation for repr:     repr(object)      Return a string containing a printable representation of an object. This is the same value yielded by conversions (reverse   quotes). It is sometimes useful to be able to access this operation as   an ordinary function. For many types, this function makes an attempt   to return a string that would yield an object with the same value when   passed to eval(), otherwise the representation is a string enclosed in   angle brackets that contains the name of the type of the object   together with additional information often including the name and   address of the object. A class can control what this function returns   for its instances by defining a __repr__() method.   Here is the documentation for str:     str(object='')      Return a string containing a nicely printable   representation of an object. For strings, this returns the string   itself. The difference with repr(object) is that str(object) does not   always attempt to return a string that is acceptable to eval(); its   goal is to return a printable string. If no argument is given, returns   the empty string, ''.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "86", "A_Content": "     What is the difference between __str__ and __repr__ in Python?   __str__ (read as \"dunder (double-underscore) string\") and __repr__ (read as \"dunder-repper\" (for \"representation\")) are both special methods that return strings based on the state of the object.   __repr__ provides backup behavior if __str__ is missing.   So one should first write a __repr__ that allows you to reinstantiate an equivalent object from the string it returns e.g. using eval or by typing it in character-for-character in a Python shell.   At any time later, one can write a __str__ for a user-readable string representation of the instance, when one believes it to be necessary.  __str__  If you print an object, or pass it to format, str.format, or str, then if a __str__ method is defined, that method will be called, otherwise, __repr__ will be used.   __repr__  The __repr__ method is called by the builtin function repr and is what is echoed on your python shell when it evaluates an expression that returns an object.   Since it provides a backup for __str__, if you can only write one, start with __repr__  Here's the builtin help on repr:  repr(...)     repr(object) -> string      Return the canonical string representation of the object.     For most object types, eval(repr(object)) == object.   That is, for most objects, if you type in what is printed by repr, you should be able to create an equivalent object. But this is not the default implementation.  Default Implementation of __repr__  The default object __repr__ is (C Python source) something like:  def __repr__(self):     return '<{0}.{1} object at {2}>'.format(       self.__module__, type(self).__name__, hex(id(self)))   That means by default you'll print the module the object is from, the class name, and the hexadecimal representation of its location in memory - for example:  <__main__.Foo object at 0x7f80665abdd0>   This information isn't very useful, but there's no way to derive how one might accurately create a canonical representation of any given instance, and it's better than nothing, at least telling us how we might uniquely identify it in memory.  How can __repr__ be useful?  Let's look at how useful it can be, using the Python shell and datetime objects. First we need to import the datetime module:  import datetime   If we call datetime.now in the shell, we'll see everything we need to recreate an equivalent datetime object. This is created by the datetime __repr__:  >>> datetime.datetime.now() datetime.datetime(2015, 1, 24, 20, 5, 36, 491180)   If we print a datetime object, we see a nice human readable (in fact, ISO) format. This is implemented by datetime's __str__:  >>> print(datetime.datetime.now()) 2015-01-24 20:05:44.977951   It is a simple matter to recreate the object we lost because we didn't assign it to a variable by copying and pasting from the __repr__ output, and then printing it, and we get it in the same human readable output as the other object:  >>> the_past = datetime.datetime(2015, 1, 24, 20, 5, 36, 491180) >>> print(the_past) 2015-01-24 20:05:36.491180   How do I implement them?  As you're developing, you'll want to be able to reproduce objects in the same state, if possible. This, for example, is how the datetime object defines __repr__ (Python source). It is fairly complex, because of all of the attributes needed to reproduce such an object:  def __repr__(self):     \"\"\"Convert to formal string, for repr().\"\"\"     L = [self._year, self._month, self._day, # These are never zero          self._hour, self._minute, self._second, self._microsecond]     if L[-1] == 0:         del L[-1]     if L[-1] == 0:         del L[-1]     s = \", \".join(map(str, L))     s = \"%s(%s)\" % ('datetime.' + self.__class__.__name__, s)     if self._tzinfo is not None:         assert s[-1:] == \")\"         s = s[:-1] + \", tzinfo=%r\" % self._tzinfo + \")\"     return s   If you want your object to have a more human readable representation, you can implement __str__ next. Here's how the datetime object (Python source) implements __str__, which it easily does because it already has a function to display it in ISO format:  def __str__(self):     \"Convert to string, for str().\"     return self.isoformat(sep=' ')   Set __repr__ = __str__?  This is a critique of another answer here that suggests setting __repr__ = __str__.  Setting __repr__ = __str__ is silly - __repr__ is a fallback for __str__ and a __repr__, written for developers usage in debugging, should be written before you write a __str__.  You need a __str__ only when you need a textual representation of the object.  Conclusion  Define __repr__ for objects you write so you and other developers have a reproducible example when using it as you develop. Define __str__ when you need a human readable string representation of it.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "13", "A_Content": "  Apart from all the answers given, I would like to add few points :-  1) __repr__() is invoked when you simply write object's name on interactive python console and press enter.  2) __str__() is invoked when you use object with print statement.  3) In case, if __str__ is missing, then print and any function using str() invokes __repr__() of object.  4) __str__() of containers, when invoked will execute __repr__() method of its contained elements.  5) str() called within __str__() could potentially recurse without a base case, and error on maximum recursion depth.  6) __repr__() can call repr() which will attempt to avoid infinite recursion automatically, replacing an already represented object with ....     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "11", "A_Content": "  In all honesty, eval(repr(obj)) is never used. If you find yourself using it, you should stop, because eval is dangerous, and strings are a very inefficient way to serialize your objects (use pickle instead).   Therefore, I would recommend setting __repr__ = __str__. The reason is that str(list) calls repr on the elements (I consider this to be one of the biggest design flaws of Python that was not addressed by Python 3). An actual repr will probably not be very helpful as the output of print [your, objects].   To qualify this, in my experience, the most useful use case of the repr function is to put a string inside another string (using string formatting). This way, you don't have to worry about escaping quotes or anything. But note that there is no eval happening here.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "11", "A_Content": "  On page 358 of the book Python scripting for computational science by Hans Petter Langtangen, it clearly states that    The __repr__ aims at a complete string representation of the object; The __str__ is to return a nicely string for printing.   So, I prefer to understand them as   repr = reproduce str = string (representation)   from the user point of view although this is a misunderstanding i made when learning python.  A small but good example is also given on the same page as follows:  Example  In [38]: str('s') Out[38]: 's'  In [39]: repr('s') Out[39]: \"'s'\"  In [40]: eval(str('s')) Traceback (most recent call last):    File \"<ipython-input-40-abd46c0c43e7>\", line 1, in <module>     eval(str('s'))    File \"<string>\", line 1, in <module>  NameError: name 's' is not defined   In [41]: eval(repr('s')) Out[41]: 's'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "10", "A_Content": "  To put it simply:  __str__ is used in to show a string representation of your object to be read easily by others.  __repr__ is used to show a string representation of the object.  Let's say I want to create a Fraction class where the string representation of a fraction is '(1/2)' and the object (Fraction class) is to be represented as 'Fraction (1,2)'  So we can create a simple Fraction class:  class Fraction:     def __init__(self, num, den):         self.__num = num         self.__den = den      def __str__(self):         return '(' + str(self.__num) + '/' + str(self.__den) + ')'      def __repr__(self):         return 'Fraction (' + str(self.__num) + ',' + str(self.__den) + ')'    f = Fraction(1,2) print('I want to represent the Fraction STRING as ' + str(f)) # (1/2) print('I want to represent the Fraction OBJECT as ', repr(f)) # Fraction (1,2)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "9", "A_Content": "  From http://pyref.infogami.com/__str__ by effbot:  __str__ \"computes the \"informal\" string representation of an object. This differs from __repr__ in that it does not have to be a valid Python expression: a more convenient or concise representation may be used instead.\"     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "6", "A_Content": "  One aspect that is missing in other answers. It's true that in general the pattern is:   Goal of __str__: human-readable Goal of __repr__: unambiguous, possibly machine-readable via eval   Unfortunately, this differentiation is flawed, because the Python REPL and also IPython use __repr__ for printing objects in a REPL console (see related questions for Python and IPython). Thus, projects which are targeted for interactive console work (e.g., Numpy or Pandas) have started to ignore above rules and provide a human-readable __repr__ implementation instead.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "5", "A_Content": "  str - Creates a new string object from the given object.  repr - Returns the canonical string representation of the object.  The differences:  str():   makes object readable generates output for end-user   repr():   needs code that reproduces object generates output for developer      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "4", "A_Content": "  Excellent answers already cover the difference between __str__ and __repr__, which for me boils down to the former being readable even by an end user, and the latter being as useful as possible to developers. Given that, I find that the default implementation of __repr__ often fails to achieve this goal because it omits information useful to developers.  For this reason, if I have a simple enough __str__, I generally just try to get the best of both worlds with something like:  def __repr__(self):     return '{0} ({1})'.format(object.__repr__(self), str(self))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "3", "A_Content": "  >>> print(decimal.Decimal(23) / decimal.Decimal(\"1.05\")) 21.90476190476190476190476190 >>> decimal.Decimal(23) / decimal.Decimal(\"1.05\") Decimal('21.90476190476190476190476190')   When print() is called on the result of decimal.Decimal(23) / deci- mal.Decimal(\"1.05\") the raw number is printed; this output is in string form which can be achieved with __str __(). If we simply enter the expression we get a decimal.Decimal output\u2014this output is in representational form which can be achieved with __repr __(). All Python objects have two output forms. String form is designed to be human-readable. Representational form is designed to produce output that if fed to a Python interpreter would (when possible) re- produce the represented object     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "3", "A_Content": "     One important thing to keep in mind is that container's __str__ uses contained objects' __repr__.   >>> from datetime import datetime >>> from decimal import Decimal >>> print (Decimal('52'), datetime.now()) (Decimal('52'), datetime.datetime(2015, 11, 16, 10, 51, 26, 185000)) >>> str((Decimal('52'), datetime.now())) \"(Decimal('52'), datetime.datetime(2015, 11, 16, 10, 52, 22, 176000))\"   Python favors unambiguity over readability, the __str__ call of a tuple calls the contained objects' __repr__, the \"formal\" representation of an object. Although the formal representation is harder to read than an informal one, it is unambiguous and more robust against bugs.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "3", "A_Content": "  \"A basic requirement for a Python object is to provide usable   string   representations of itself, one used for debugging and  logging, another for presentation to end users. That is why the    special methods __repr__ and __str__ exist in the data model.\"   From the book: Fluent Python     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "2", "A_Content": "  In a nutshell:  class Demo:   def __repr__(self):     return 'repr'   def __str__(self):     return 'str'  demo = Demo() print(demo) # use __str__, output 'str' to stdout  s = str(demo) # __str__ is used, return 'str' r = repr(demo) # __repr__ is used, return 'repr'  import logging logger = logging.getLogger(logging.INFO) logger.info(demo) # use __str__, output 'str' to stdout  from pprint import pprint, pformat pprint(demo) # use __repr__, output 'repr' to stdout result = pformat(demo) # use __repr__, result is string which value is 'str'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "1", "A_Content": "  Understand __str__ and __repr__ intuitively and permanently distinguish them at all.  __str__ return the string disguised body of a given object for readable of eyes __repr__ return the real flesh body of a given object (return itself) for unambiguity to identify.  See it in an example  In [30]: str(datetime.datetime.now()) Out[30]: '2017-12-07 15:41:14.002752' Disguised in string form   As to __repr__  In [32]: datetime.datetime.now() Out[32]: datetime.datetime(2017, 12, 7, 15, 43, 27, 297769) Presence in real body which allows to be manipulated directly.   We can do arithmetic operation on __repr__ results conveniently.  In [33]: datetime.datetime.now() Out[33]: datetime.datetime(2017, 12, 7, 15, 47, 9, 741521) In [34]: datetime.datetime(2017, 12, 7, 15, 47, 9, 741521) - datetime.datetime(2     ...: 017, 12, 7, 15, 43, 27, 297769) Out[34]: datetime.timedelta(0, 222, 443752)   if apply the operation on __str__  In [35]: '2017-12-07 15:43:14.002752' - '2017-12-07 15:41:14.002752' TypeError: unsupported operand type(s) for -: 'str' and 'str'   Returns nothing but error.  Another example.  In [36]: str('string_body') Out[36]: 'string_body' # in string form  In [37]: repr('real_body') Out[37]: \"'real_body'\" #its real body hide inside   Hope this help you build concrete grounds to explore more answers.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "1", "A_Content": "  So much clearer from blog   str is like toString. created so you can print the data repr is like serialize, or pickle. How do i recreate this object if i need to do so using eval()  >>> import datetime >>> now = datetime.datetime.now()  >>> str(now) '2015-04-04 20:51:31.766862' >>> repr(now) 'datetime.datetime(2015, 4, 4, 20, 51, 31, 766862)' >>mydate = eval(repr(now))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1436703/difference-between-str-and-repr", "Language": "Python", "Q_Title": "Difference between __str__ and __repr__?", "Q_Votes": "2147", "Q_Content": "    What is the difference between __str__ and __repr__ in Python?     ", "Tags": ["python", "magic-methods", "repr"], "A_Votes": "0", "A_Content": "  __repr__ is used everywhere, except by print and str when a __str__is defined     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "1373", "A_Content": "  Actually, this is not a design flaw, and it is not because of internals, or performance. It comes simply from the fact that functions in Python are first-class objects, and not only a piece of code.  As soon as you get to think into this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of \"member data\" and therefore their state may change from one call to the other - exactly as in any other object.  In any case, Effbot has a very nice explanation of the reasons for this behavior in Default Parameter Values in Python. I found it very clear, and I really suggest reading it for a better knowledge of how function objects work.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "235", "A_Content": "  Suppose you have the following code  fruits = (\"apples\", \"bananas\", \"loganberries\")  def eat(food=fruits):     ...   When I see the declaration of eat, the least astonishing thing is to think that if the first parameter is not given, that it will be equal to the tuple (\"apples\", \"bananas\", \"loganberries\")  However, supposed later on in the code, I do something like  def some_random_function():     global fruits     fruits = (\"blueberries\", \"mangos\")   then if default parameters were bound at function execution rather than function declaration then I would be astonished (in a very bad way) to discover that fruits had been changed.  This would be more astonishing IMO than discovering that your foo function above was mutating the list.  The real problem lies with mutable variables, and all languages have this problem to some extent. Here's a question: suppose in Java I have the following code:  StringBuffer s = new StringBuffer(\"Hello World!\"); Map<StringBuffer,Integer> counts = new HashMap<StringBuffer,Integer>(); counts.put(s, 5); s.append(\"!!!!\"); System.out.println( counts.get(s) );  // does this work?   Now, does my map use the value of the StringBuffer key when it was placed into the map, or does it store the key by reference?  Either way, someone is astonished; either the person who tried to get the object out of the Map using a value identical to the one they put it in with, or the person who can't seem to retrieve their object even though the key they're using is literally the same object that was used to put it into the map (this is actually why Python doesn't allow its mutable built-in data types to be used as dictionary keys).  Your example is a good one of a case where Python newcomers will be surprised and bitten.  But I'd argue that if we \"fixed\" this, then that would only create a different situation where they'd be bitten instead, and that one would be even less intuitive. Moreover, this is always the case when dealing with mutable variables; you always run into cases where someone could intuitively expect one or the opposite behavior depending on what code they're writing.  I personally like Python's current approach: default function arguments are evaluated when the function is defined and that object is always the default. I suppose they could special-case using an empty list, but that kind of special casing would cause even more astonishment, not to mention be backwards incompatible.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "198", "A_Content": "  AFAICS no one has yet posted the relevant part of the documentation:     Default parameter values are evaluated when the function definition is executed. This means that the expression is evaluated once, when the function is defined, and that the same \u201cpre-computed\u201d value is used for each call. This is especially important to understand when a default parameter is a mutable object, such as a list or a dictionary: if the function modifies the object (e.g. by appending an item to a list), the default value is in effect modified. This is generally not what was intended. A way around this is to use None as the default, and explicitly test for it in the body of the function [...]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "99", "A_Content": "  I know nothing about the Python interpreter inner workings (and I'm not an expert in compilers and interpreters either) so don't blame me if I propose anything unsensible or impossible.  Provided that python objects are mutable I think that this should be taken into account when designing the default arguments stuff. When you instantiate a list:  a = []   you expect to get a new list referenced by a.  Why should the a=[] in  def x(a=[]):   instantiate a new list on function definition and not on invocation? It's just like you're asking \"if the user doesn't provide the argument then instantiate a new list and use it as if it was produced by the caller\". I think this is ambiguous instead:  def x(a=datetime.datetime.now()):   user, do you want a to default to the datetime corresponding to when you're defining or executing x? In this case, as in the previous one, I'll keep the same behaviour as if the default argument \"assignment\" was the first instruction of the function (datetime.now() called on function invocation). On the other hand, if the user wanted the definition-time mapping he could write:  b = datetime.datetime.now() def x(a=b):   I know, I know: that's a closure. Alternatively Python might provide a keyword to force definition-time binding:  def x(static a=b):      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "73", "A_Content": "  Well, the reason is quite simply that bindings are done when code is executed, and the function definition is executed, well... when the functions is defined.  Compare this:  class BananaBunch:     bananas = []      def addBanana(self, banana):         self.bananas.append(banana)   This code suffers from the exact same unexpected happenstance. bananas is a class attribute, and hence, when you add things to it, it's added to all instances of that class. The reason is exactly the same.  It's just \"How It Works\", and making it work differently in the function case would probably be complicated, and in the class case likely impossible, or at least slow down object instantiation a lot, as you would have to keep the class code around and execute it when objects are created.  Yes, it is unexpected. But once the penny drops, it fits in perfectly with how Python works in general. In fact, it's a good teaching aid, and once you understand why this happens, you'll grok python much better.  That said it should feature prominently in any good Python tutorial. Because as you mention, everyone runs into this problem sooner or later.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "52", "A_Content": "  I used to think that creating the objects at runtime would be the better approach.  I'm less certain now, since you do lose some useful features, though it may be worth it regardless simply to prevent newbie confusion.  The disadvantages of doing so are:  1. Performance  def foo(arg=something_expensive_to_compute())):     ...   If call-time evaluation is used, then the expensive function is called every time your function is used without an argument.  You'd either pay an expensive price on each call, or need to manually cache the value externally, polluting your namespace and adding verbosity.  2. Forcing bound parameters  A useful trick is to bind parameters of a lambda to the current binding of a variable when the lambda is created.  For example:  funcs = [ lambda i=i: i for i in range(10)]   This returns a list of functions that return 0,1,2,3... respectively.  If the behaviour is changed, they will instead bind i to the call-time value of i, so you would get a list of functions that all returned 9.  The only way to implement this otherwise would be to create a further closure with the i bound, ie:  def make_func(i): return lambda: i funcs = [make_func(i) for i in range(10)]   3. Introspection  Consider the code:  def foo(a='test', b=100, c=[]):    print a,b,c   We can get information about the arguments and defaults using the inspect module, which   >>> inspect.getargspec(foo) (['a', 'b', 'c'], None, None, ('test', 100, []))   This information is very useful for things like document generation, metaprogramming, decorators etc.  Now, suppose the behaviour of defaults could be changed so that this is the equivalent of:  _undefined = object()  # sentinel value  def foo(a=_undefined, b=_undefined, c=_undefined)     if a is _undefined: a='test'     if b is _undefined: b=100     if c is _undefined: c=[]   However, we've lost the ability to introspect, and see what the default arguments are.  Because the objects haven't been constructed, we can't ever get hold of them without actually calling the function.  The best we could do is to store off the source code and return that as a string.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "49", "A_Content": "  5 points in defense of Python   Simplicity: The behavior is simple in the following sense: Most people fall into this trap only once, not several times. Consistency: Python always passes objects, not names. The default parameter is, obviously, part of the function  heading (not the function body). It therefore ought to be evaluated at module load time (and only at module load time, unless nested), not at function call time. Usefulness: As Frederik Lundh points out in his explanation of \"Default Parameter Values in Python\", the current behavior can be quite useful for advanced programming. (Use sparingly.) Sufficient documentation: In the most basic Python documentation, the tutorial, the issue is loudly announced as an \"Important warning\" in the first subsection of Section \"More on Defining Functions\". The warning even uses boldface, which is rarely applied outside of headings. RTFM: Read the fine manual. Meta-learning: Falling into the trap is actually a very helpful moment (at least if you are a reflective learner), because you will subsequently better understand the point  \"Consistency\" above and that will teach you a great deal about Python.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "45", "A_Content": "  Why don't you introspect?  I'm really surprised no one has performed the insightful introspection offered by Python (2 and 3 apply) on callables.   Given a simple little function func defined as:  >>> def func(a = []): ...    a.append(5)   When Python encounters it, the first thing it will do is compile it in order to create a code object for this function. While this compilation step is done, Python evaluates* and then stores the default arguments (an empty list [] here) in the function object itself. As the top answer mentioned: the list a can now be considered a member of the function func.  So, let's do some introspection, a before and after to examine how the list gets expanded inside the function object. I'm using Python 3.x for this, for Python 2 the same applies (use __defaults__ or func_defaults in Python 2; yes, two names for the same thing).  Function Before Execution:  >>> def func(a = []): ...     a.append(5) ...        After Python executes this definition it will take any default parameters specified (a = [] here) and cram them in the __defaults__ attribute for the function object (relevant section: Callables):       >>> func.__defaults__ ([],)   O.k, so an empty list as the single entry in __defaults__, just as expected.   Function After Execution:  Let's now execute this function:  >>> func()   Now, let's see those __defaults__ again:   >>> func.__defaults__ ([5],)   Astonished? The value inside the object changes! Consecutive calls to the function will now simply append to that embedded list object:  >>> func(); func(); func() >>> func.__defaults__ ([5, 5, 5, 5],)   So, there you have it, the reason why this 'flaw' happens, is because default arguments are part of the function object. There's nothing weird going on here, it's all just a bit surprising.  The common solution to combat this is to usual None as the default and then initialize in the function body:  def func(a = None):     # or: a = [] if a is None else a     if a is None:         a = []   Since the function body is executed anew each time, you always get a fresh new empty list if no argument was passed for a.    To further verify that the list in __defaults__ is the same as that used in the function func you can just change your function to return the id of the list a used inside the function body. Then, compare it to the list in __defaults__ (position [0] in __defaults__) and you'll see how these are indeed refering to the same list instance:  >>> def func(a = []):  ...     a.append(5) ...     return id(a) >>> >>> id(func.__defaults__[0]) == func() True   All with the power of introspection!     * To verify that Python evaluates the default arguments during compilation of the function, try executing the following:  def bar(a=input('Did you just see me without calling the function?')):      pass  # use raw_input in Py2   as you'll notice, input() is called before the process of building the function and binding it to the name bar is made.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "41", "A_Content": "  This behavior is easy explained by:   function (class etc.) declaration is executed only once, creating all default value objects everything is passed by reference   So:  def x(a=0, b=[], c=[], d=0):     a = a + 1     b = b + [1]     c.append(1)     print a, b, c    a doesn't change - every assignment call creates new int object - new object is printed b doesn't change - new array is build from default value and printed c changes - operation is performed on same object - and it is printed      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "31", "A_Content": "  What you're asking is why this:  def func(a=[], b = 2):     pass   isn't internally equivalent to this:  def func(a=None, b = None):     a_default = lambda: []     b_default = lambda: 2     def actual_func(a=None, b=None):         if a is None: a = a_default()         if b is None: b = b_default()     return actual_func func = func()   except for the case of explicitly calling func(None, None), which we'll ignore.  In other words, instead of evaluating default parameters, why not store each of them, and evaluate them when the function is called?  One answer is probably right there--it would effectively turn every function with default parameters into a closure.  Even if it's all hidden away in the interpreter and not a full-blown closure, the data's got to be stored somewhere.  It'd be slower and use more memory.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "29", "A_Content": "  1)  The so-called problem of \"Mutable Default Argument\" is in general a special example demonstrating that: \"All functions with this problem suffer also from similar side effect problem on the actual parameter,\" That is against the rules of functional programming, usually undesiderable and should be fixed both together.  Example:  def foo(a=[]):                 # the same problematic function     a.append(5)     return a  >>> somevar = [1, 2]           # an example without a default parameter >>> foo(somevar) [1, 2, 5] >>> somevar [1, 2, 5]                      # usually expected [1, 2]   Solution:  a copy An absolutely safe solution is to copy or deepcopy the input object first and then to do whatever with the copy.  def foo(a=[]):     a = a[:]     # a copy     a.append(5)     return a     # or everything safe by one line: \"return a + [5]\"   Many builtin mutable types have a copy method like some_dict.copy() or some_set.copy() or can be copied easy like somelist[:] or list(some_list). Every object can be also copied by copy.copy(any_object) or more thorough by copy.deepcopy() (the latter useful if the mutable object is composed from mutable objects). Some objects are fundamentally based on side effects like \"file\" object and can not be meaningfully reproduced by copy. copying  Example problem for a similar SO question  class Test(object):            # the original problematic class   def __init__(self, var1=[]):     self._var1 = var1  somevar = [1, 2]               # an example without a default parameter t1 = Test(somevar) t2 = Test(somevar) t1._var1.append([1]) print somevar                  # [1, 2, [1]] but usually expected [1, 2] print t2._var1                 # [1, 2, [1]] but usually expected [1, 2]   It shouldn't be neither saved in any public attribute of an instance returned by this function. (Assuming that private attributes of instance should not be modified from outside of this class or subclasses by convention. i.e. _var1 is a private attribute )  Conclusion: Input parameters objects shouldn't be modified in place (mutated) nor they should not be binded into an object returned by the function. (If we prefere programming without side effects which is strongly recommended. see Wiki about \"side effect\" (The first two paragraphs are relevent in this context.) .)  2) Only if the side effect on the actual parameter is required but unwanted on the default parameter then the useful solution is def ...(var1=None): if var1 is None: var1 = [] More..  3) In some cases is the mutable behavior of default parameters useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "25", "A_Content": "  This actually has nothing to do with default values, other than that it often comes up as an unexpected behaviour when you write functions with mutable default values.  >>> def foo(a):     a.append(5)     print a  >>> a  = [5] >>> foo(a) [5, 5] >>> foo(a) [5, 5, 5] >>> foo(a) [5, 5, 5, 5] >>> foo(a) [5, 5, 5, 5, 5]   No default values in sight in this code, but you get exactly the same problem.  The problem is that foo is modifying a mutable variable passed in from the caller, when the caller doesn't expect this. Code like this would be fine if the function was called something like append_5; then the caller would be calling the function in order to modify the value they pass in, and the behaviour would be expected. But such a function would be very unlikely to take a default argument, and probably wouldn't return the list (since the caller already has a reference to that list; the one it just passed in).  Your original foo, with a default argument, shouldn't be modifying a whether it was explicitly passed in or got the default value. Your code should leave mutable arguments alone unless it is clear from the context/name/documentation that the arguments are supposed to be modified. Using mutable values passed in as arguments as local temporaries is an extremely bad idea, whether we're in Python or not and whether there are default arguments involved or not.  If you need to destructively manipulate a local temporary in the course of computing something, and you need to start your manipulation from an argument value, you need to make a copy.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "24", "A_Content": "  It's a performance optimization.  As a result of this functionality, which of these two function calls do you think is faster?  def print_tuple(some_tuple=(1,2,3)):     print some_tuple  print_tuple()        #1 print_tuple((1,2,3)) #2   I'll give you a hint.  Here's the disassembly (see http://docs.python.org/library/dis.html):  #1  0 LOAD_GLOBAL              0 (print_tuple) 3 CALL_FUNCTION            0 6 POP_TOP 7 LOAD_CONST               0 (None) 10 RETURN_VALUE   #2   0 LOAD_GLOBAL              0 (print_tuple)  3 LOAD_CONST               4 ((1, 2, 3))  6 CALL_FUNCTION            1  9 POP_TOP 10 LOAD_CONST               0 (None) 13 RETURN_VALUE      I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs ?)   As you can see, there is a performance benefit when using immutable default arguments.  This can make a difference if it's a frequently called function or the default argument takes a long time to construct.  Also, bear in mind that Python isn't C.  In C you have constants that are pretty much free.  In Python you don't have this benefit.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "22", "A_Content": "  Already busy topic, but from what I read here, the following helped me realizing how it's working internally:  def bar(a=[]):      print id(a)      a = a + [1]      print id(a)      return a  >>> bar() 4484370232 4484524224 [1] >>> bar() 4484370232 4484524152 [1] >>> bar() 4484370232 # Never change, this is 'class property' of the function 4484523720 # Always a new object  [1] >>> id(bar.func_defaults[0]) 4484370232      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "18", "A_Content": "  A simple workaround using None  >>> def bar(b, data=None): ...     data = data or [] ...     data.append(b) ...     return data ...  >>> bar(3) [3] >>> bar(3) [3] >>> bar(3) [3] >>> bar(3, [34]) [34, 3] >>> bar(3, [34]) [34, 3]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "18", "A_Content": "  This behavior is not surprising if you take the following into consideration:   The behavior of read-only class attributes upon assignment attempts, and that Functions are objects (explained well in the accepted answer).    The role of (2) has been covered extensively in this thread. (1) is likely the astonishment causing factor, as this behavior is not \"intuitive\" when coming from other languages.  (1) is described in the Python tutorial on classes. In an attempt to assign a value to a read-only class attribute:     ...all variables found outside of the innermost scope are   read-only (an attempt to write to such a variable will simply create a   new local variable in the innermost scope, leaving the identically   named outer variable unchanged).   Look back to the original example and consider the above points:  def foo(a=[]):     a.append(5)     return a   Here foo is an object and a is an attribute of foo (available at foo.func_defs[0]). Since a is a list, a is mutable and is thus a read-write attribute of foo. It is initialized to the empty list as specified by the signature when the function is instantiated, and is available for reading and writing as long as the function object exists.   Calling foo without overriding a default uses that default's value from foo.func_defs. In this case, foo.func_defs[0] is used for a within function object's code scope. Changes to a change foo.func_defs[0], which is part of the foo object and persists between execution of the code in foo.  Now, compare this to the example from the documentation on emulating the default argument behavior of other languages, such that the function signature defaults are used every time the function is executed:  def foo(a, L=None):     if L is None:         L = []     L.append(a)     return L   Taking (1) and (2) into account, one can see why this accomplishes the the desired behavior:    When the foo function object is instantiated, foo.func_defs[0] is set to None, an immutable object. When the function is executed with defaults (with no parameter specified for L in the function call), foo.func_defs[0] (None) is available in the local scope as L. Upon L = [], the assignment cannot succeed at foo.func_defs[0], because that attribute is read-only.  Per (1), a new local variable also named L is created in the local scope and used for the remainder of the function call. foo.func_defs[0] thus remains unchanged for future invocations of foo.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "18", "A_Content": "  Python: The Mutable Default Argument  Default arguments get evaluated at the time the function is compiled into a function object. When used by the function, multiple times by that function, they are and remain the same object.   When they are mutable, when mutated (for example, by adding an element to it) they remain mutated on consecutive calls.  They stay mutated because they are the same object each time.  Equivalent code:  Since the list is bound to the function when the function object is compiled and instantiated, this:  def foo(mutable_default_argument=[]): # make a list the default argument     \"\"\"function that uses a list\"\"\"   is almost exactly equivalent to this:  _a_list = [] # create a list in the globals  def foo(mutable_default_argument=_a_list): # make it the default argument     \"\"\"function that uses a list\"\"\"  del _a_list # remove globals name binding   Demonstration  Here's a demonstration - you can verify that they are the same object each time they are referenced by    seeing that the list is created before the function has finished compiling to a function object, observing that the id is the same each time the list is referenced, observing that the list stays changed when the function that uses it is called a second time, observing the order in which the output is printed from the source (which I conveniently numbered for you):   example.py  print('1. Global scope being evaluated')  def create_list():     '''noisily create a list for usage as a kwarg'''     l = []     print('3. list being created and returned, id: ' + str(id(l)))     return l  print('2. example_function about to be compiled to an object')  def example_function(default_kwarg1=create_list()):     print('appending \"a\" in default default_kwarg1')     default_kwarg1.append(\"a\")     print('list with id: ' + str(id(default_kwarg1)) +            ' - is now: ' + repr(default_kwarg1))  print('4. example_function compiled: ' + repr(example_function))   if __name__ == '__main__':     print('5. calling example_function twice!:')     example_function()     example_function()   and running it with python example.py:  1. Global scope being evaluated 2. example_function about to be compiled to an object 3. list being created and returned, id: 140502758808032 4. example_function compiled: <function example_function at 0x7fc9590905f0> 5. calling example_function twice!: appending \"a\" in default default_kwarg1 list with id: 140502758808032 - is now: ['a'] appending \"a\" in default default_kwarg1 list with id: 140502758808032 - is now: ['a', 'a']   Does this violate the principle of \"Least Astonishment\"?  This order of execution is frequently confusing to new users of Python. If you understand the Python execution model, then it becomes quite expected.   The usual instruction to new Python users:  But this is why the usual instruction to new users is to create their default arguments like this instead:  def example_function_2(default_kwarg=None):     if default_kwarg is None:         default_kwarg = []   This uses the None singleton as a sentinel object to tell the function whether or not we've gotten an argument other than the default. If we get no argument, then we actually want to use a new empty list, [], as the default.  As the tutorial section on control flow says:     If you don\u2019t want the default to be shared between subsequent calls,   you can write the function like this instead:  def f(a, L=None):     if L is None:         L = []     L.append(a)     return L       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "17", "A_Content": "  The solutions here are:   Use None as your default value (or a nonce object), and switch on that to create your values at runtime; or Use a lambda as your default parameter, and call it within a try block to get the default value (this is the sort of thing that lambda abstraction is for).   The second option is nice because users of the function can pass in a callable, which may be already existing (such as a type)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "17", "A_Content": "  The shortest answer would probably be \"definition is execution\", therefore the whole argument makes no strict sense. As a more contrived example, you may cite this:  def a(): return []  def b(x=a()):     print x   Hopefully it's enough to show that not executing the default argument expressions at the execution time of the def statement isn't easy or doesn't make sense, or both.  I agree it's a gotcha when you try to use default constructors, though.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "16", "A_Content": "  I sometimes exploit this behavior as an alternative to the following pattern:  singleton = None  def use_singleton():     global singleton      if singleton is None:         singleton = _make_singleton()      return singleton.use_me()   If singleton is only used by use_singleton, I like the following pattern as a replacement:  # _make_singleton() is called only once when the def is executed def use_singleton(singleton=_make_singleton()):     return singleton.use_me()   I've used this for instantiating client classes that access external resources, and also for creating dicts or lists for memoization.  Since I don't think this pattern is well known, I do put a short comment in to guard against future misunderstandings.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "16", "A_Content": "  I am going to demonstrate an alternative structure to pass a default list value to a function (it works equally well with dictionaries).    As others have extensively commented, the list parameter is bound to the function when it is defined as opposed to when it is executed.  Because lists and dictionaries are mutable, any alteration to this parameter will affect other calls to this function.  As a result, subsequent calls to the function will receive this shared list which may have been altered by any other calls to the function.  Worse yet, two parameters are using this function's shared parameter at the same time oblivious to the changes made by the other.  Wrong Method (probably...):  def foo(list_arg=[5]):     return list_arg  a = foo() a.append(6) >>> a [5, 6]  b = foo() b.append(7) # The value of 6 appended to variable 'a' is now part of the list held by 'b'. >>> b [5, 6, 7]    # Although 'a' is expecting to receive 6 (the last element it appended to the list), # it actually receives the last element appended to the shared list. # It thus receives the value 7 previously appended by 'b'. >>> a.pop()              7   You can verify that they are one and the same object by using id:  >>> id(a) 5347866528  >>> id(b) 5347866528   Per Brett Slatkin's \"Effective Python: 59 Specific Ways to Write Better Python\", Item 20: Use None and Docstrings to specify dynamic default arguments (p. 48)     The convention for achieving the desired result in Python is to   provide a default value of None and to document the actual behaviour   in the docstring.   This implementation ensures that each call to the function either receives the default list or else the list passed to the function.  Preferred Method:  def foo(list_arg=None):    \"\"\"    :param list_arg:  A list of input values.                       If none provided, used a list with a default value of 5.    \"\"\"    if not list_arg:        list_arg = [5]    return list_arg  a = foo() a.append(6) >>> a [5, 6]  b = foo() b.append(7) >>> b [5, 7]  c = foo([10]) c.append(11) >>> c [10, 11]   There may be legitimate use cases for the 'Wrong Method' whereby the programmer intended the default list parameter to be shared, but this is more likely the exception than the rule.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "15", "A_Content": "  You can get round this by replacing the object (and therefore the tie with the scope):  def foo(a=[]):     a = list(a)     a.append(5)     return a   Ugly, but it works.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "14", "A_Content": "  When we do this:  def foo(a=[]):     ...   ... we assign the argument a to an unnamed list, if the caller does not pass the value of a.  To make things simpler for this discussion, let's temporarily give the unnamed list a name. How about pavlo ?  def foo(a=pavlo):    ...   At any time, if the caller doesn't tell us what a is, we reuse pavlo.  If pavlo is mutable (modifiable), and foo ends up modifying it, an effect we notice the next time foo is called without specifying a.  So this is what you see (Remember, pavlo is initialized to []):   >>> foo()  [5]   Now, pavlo is [5].  Calling foo() again modifies pavlo again:  >>> foo() [5, 5]   Specifying a when calling foo() ensures pavlo is not touched.  >>> ivan = [1, 2, 3, 4] >>> foo(a=ivan) [1, 2, 3, 4, 5] >>> ivan [1, 2, 3, 4, 5]   So, pavlo is still [5, 5].  >>> foo() [5, 5, 5]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "11", "A_Content": "  It may be true that:   Someone is using every language/library feature, and Switching the behavior here would be ill-advised, but   it is entirely consistent to hold to both of the features above and still make another point:   It is a confusing feature and it is unfortunate in Python.   The other answers, or at least some of them either make points 1 and 2 but not 3, or make point 3 and downplay points 1 and 2. But all three are true.  It may be true that switching horses in midstream here would be asking for significant breakage, and that there could be more problems created by changing Python to intuitively handle Stefano's opening snippet. And it may be true that someone who knew Python internals well could explain a minefield of consequences. However,  The existing behavior is not Pythonic, and Python is successful because very little about the language violates the principle of least astonishment anywhere near this badly. It is a real problem, whether or not it would be wise to uproot it. It is a design flaw. If you understand the language much better by trying to trace out the behavior, I can say that C++ does all of this and more; you learn a lot by navigating, for instance, subtle pointer errors. But this is not Pythonic: people who care about Python enough to persevere in the face of this behavior are people who are drawn to the language because Python has far fewer surprises than other language. Dabblers and the curious become Pythonistas when they are astonished at how little time it takes to get something working--not because of a design fl--I mean, hidden logic puzzle--that cuts against the intuitions of programmers who are drawn to Python because it Just Works.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "9", "A_Content": "  This \"bug\" gave me a lot of overtime work hours! But I'm beginning to see a potential use of it (but I would have liked it to be at the execution time, still)  I'm gonna give you what I see as a useful example.  def example(errors=[]):     # statements     # Something went wrong     mistake = True     if mistake:         tryToFixIt(errors)         # Didn't work.. let's try again         tryToFixItAnotherway(errors)         # This time it worked     return errors  def tryToFixIt(err):     err.append('Attempt to fix it')  def tryToFixItAnotherway(err):     err.append('Attempt to fix it by another way')  def main():     for item in range(2):         errors = example()     print '\\n'.join(errors)  main()   prints the following  Attempt to fix it Attempt to fix it by another way Attempt to fix it Attempt to fix it by another way      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "8", "A_Content": "  I think the answer to this question lies in how python pass data to parameter (pass by value or by reference), not mutability or how python handle the \"def\" statement.  A brief introduction. First, there are two type of data types in python, one is simple elementary data type, like numbers, and another data type is objects. Second, when passing data to parameters, python pass elementary data type by value, i.e., make a local copy of the value to a local variable, but pass object by reference, i.e., pointers to the object.  Admitting the above two points, let's explain what happened to the python code. It's only because of passing by reference for objects, but has nothing to do with mutable/immutable, or arguably the fact that \"def\" statement is executed only once when it is defined.  [] is an object, so python pass the reference of [] to a, i.e., a is only a pointer to [] which lies in memory as an object. There is only one copy of [] with, however, many references to it. For the first foo(), the list [] is changed to 1 by append method. But Note that there is only one copy of the list object and this object now becomes 1. When running the second foo(), what effbot webpage says (items is not evaluated any more) is wrong. a is evaluated to be the list object, although now the content of the object is 1. This is the effect of passing by reference! The result of foo(3) can be easily derived in the same way.  To further validate my answer, let's take a look at two additional codes.  ====== No. 2 ========  def foo(x, items=None):     if items is None:         items = []     items.append(x)     return items  foo(1)  #return [1] foo(2)  #return [2] foo(3)  #return [3]   [] is an object, so is None (the former is mutable while the latter is immutable. But the mutability has nothing to do with the question). None is somewhere in the space but we know it's there and there is only one copy of None there. So every time foo is invoked, items is evaluated (as opposed to some answer that it is only evaluated once) to be None, to be clear, the reference (or the address) of None. Then in the foo, item is changed to [], i.e., points to another object which has a different address.   ====== No. 3 =======  def foo(x, items=[]):     items.append(x)     return items  foo(1)    # returns [1] foo(2,[]) # returns [2] foo(3)    # returns [1,3]   The invocation of foo(1) make items point to a list object [] with an address, say, 11111111. the content of the list is changed to 1 in the foo function in the sequel, but the address is not changed, still 11111111. Then foo(2,[]) is coming. Although the [] in foo(2,[]) has the same content as the default parameter [] when calling foo(1), their address are different! Since we provide the parameter explicitly, items has to take the address of this new [], say 2222222, and return it after making some change. Now foo(3) is executed. since only x is provided, items has to take its default value again. What's the default value? It is set when defining the foo function: the list object located in 11111111. So the items is evaluated to be the address 11111111 having an element 1. The list located at 2222222 also contains one element 2, but it is not pointed by items any more. Consequently, An append of 3 will make items [1,3].   From the above explanations, we can see that the effbot webpage recommended in the accepted answer failed to give a relevant answer to this question. What is more, I think a point in the effbot webpage is wrong. I think the code regarding the UI.Button is correct:  for i in range(10):     def callback():         print \"clicked button\", i     UI.Button(\"button %s\" % i, callback)   Each button can hold a distinct callback function which will display different value of i. I can provide an example to show this:  x=[] for i in range(10):     def callback():         print(i)     x.append(callback)    If we execute x[7]() we'll get 7 as expected, and x[9]() will gives 9, another value of i.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "6", "A_Content": "  This is not a design flaw. Anyone who trips over this is doing something wrong.  There are 3 cases I see where you might run into this problem:   You intend to modify the argument as a side effect of the function. In this case it never makes sense to have a default argument. The only exception is when you're abusing the argument list to have function attributes, e.g. cache={}, and you wouldn't be expected to call the function with an actual argument at all. You intend to leave the argument unmodified, but you accidentally did modify it. That's a bug, fix it. You intend to modify the argument for use inside the function, but didn't expect the modification to be viewable outside of the function. In that case you need to make a copy of the argument, whether it was the default or not! Python is not a call-by-value language so it doesn't make the copy for you, you need to be explicit about it.   The example in the question could fall into category 1 or 3. It's odd that it both modifies the passed list and returns it; you should pick one or the other.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "4", "A_Content": "  >>> def a(): >>>    print \"a executed\" >>>    return [] >>> x =a() a executed >>> def b(m=[]): >>>    m.append(5) >>>    print m >>> b(x) [5] >>> b(x) [5, 5]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "4", "A_Content": "  Just change the function to be:  def notastonishinganymore(a = []):      '''The name is just a joke :)'''     a = a[:]     a.append(5)     return a      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument", "Language": "Python", "Q_Title": "\u201cLeast Astonishment\u201d and the Mutable Default Argument", "Q_Votes": "2092", "Q_Content": "    Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:  def foo(a=[]):     a.append(5)     return a   Python novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):  >>> foo() [5] >>> foo() [5, 5] >>> foo() [5, 5, 5] >>> foo() [5, 5, 5, 5] >>> foo()   A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)  Edit:   Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:  >>> def a(): ...     print(\"a executed\") ...     return [] ...  >>>             >>> def b(x=a()): ...     x.append(5) ...     print(x) ...  a executed >>> b() [5] >>> b() [5, 5]   To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?  Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.  The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.     ", "Tags": ["python", "language-design", "least-astonishment"], "A_Votes": "-2", "A_Content": "  Architecture  Assigning default values in a function call is a code smell.  def a(b=[]):     pass   This is a signature of a function that is up to no good. Not just because of the problems described by other answers. I won't go in to that here.  This function aims to do two things. Create a new list, and execute a functionality, most likely on said list.  Functions that do two things are bad functions, as we learn from clean code practices.  Attacking this problem with polymorphism, we would extend the python list or wrap one in a class, then perform our function upon it.  But wait you say, I like my one-liners.  Well, guess what. Code is more than just a way to control the behavior of hardware. It's a way of:   communicating with other developers, working on the same code. being able to change the behavior of the hardware when new requirements arises. being able to understand the flow of the program after you pick up the code again after two years to make the change mentioned above.   Don't leave time-bombs for yourself to pick up later.  Separating this function into the two things it does, we need a class  class ListNeedsFives(object):     def __init__(self, b=None):         if b is None:             b = []         self.b = b      def foo():         self.b.append(5)   Executed by  a = ListNeedsFives() a.foo() a.b   And why is this better than mashing all the above code into a single function.  def dontdothis(b=None):     if b is None:         b = []     b.append(5)     return b   Why not do this?  Unless you fail in your project, your code will live on. Most likely your function will be doing more than this. The proper way of making maintainable code is to separate code into atomic parts with a properly limited scope.  The constructor of a class is a very commonly recognized component to anyone who has done Object Oriented Programming. Placing the logic that handles the list instantiation in the constructor makes the cognitive load of understanding what the code does smaller.  The method foo() does not return the list, why not?  In returning a stand alone list, you could assume that it's safe to do what ever you feel like to it. But it may not be, since it is also shared by the object a. Forcing the user to refer to it as a.b reminds them where the list belongs. Any new code that wants to modify a.b will naturally be placed in the class, where it belongs.  the def dontdothis(b=None): signature function has none of these advantages.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "3373", "A_Content": "  >>> [\"foo\", \"bar\", \"baz\"].index(\"bar\") 1   Reference: Data Structures > More on Lists  Caveats follow  Note that while this is perhaps the cleanest way to answer the question as asked, index is a rather weak component of the list API, and I can't remember the last time I used it in anger. It's been pointed out to me in the comments that because this answer is heavily referenced, it should be made more complete. Some caveats about list.index follow. It is probably worth initially taking a look at the docstring for it:  >>> print(list.index.__doc__) L.index(value, [start, [stop]]) -> integer -- return first index of value. Raises ValueError if the value is not present.   Linear time-complexity in list length  An index call checks every element of the list in order, until it finds a match. If your list is long, and you don't know roughly where in the list it occurs, this search could become a bottleneck. In that case, you should consider a different data structure. Note that if you know roughly where to find the match, you can give index a hint. For instance, in this snippet, l.index(999_999, 999_990, 1_000_000) is roughly five orders of magnitude faster than straight l.index(999_999), because the former only has to search 10 entries, while the latter searches a million:  >>> import timeit >>> timeit.timeit('l.index(999_999)', setup='l = list(range(0, 1_000_000))', number=1000) 9.356267921015387 >>> timeit.timeit('l.index(999_999, 999_990, 1_000_000)', setup='l = list(range(0, 1_000_000))', number=1000) 0.0004404920036904514   Only returns the index of the first match to its argument  A call to index searches through the list in order until it finds a match, and stops there. If you expect to need indices of more matches, you should use a list comprehension, or generator expression.  >>> [1, 1].index(1) 0 >>> [i for i, e in enumerate([1, 2, 1]) if e == 1] [0, 2] >>> g = (i for i, e in enumerate([1, 2, 1]) if e == 1) >>> next(g) 0 >>> next(g) 2   Most places where I once would have used index, I now use a list comprehension or generator expression because they're more generalizable. So if you're considering reaching for index, take a look at these excellent python features.  Throws if element not present in list  A call to index results in a ValueError if the item's not present.  >>> [1, 1].index(2) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ValueError: 2 is not in list   If the item might not be present in the list, you should either    Check for it first with item in my_list (clean, readable approach), or Wrap the index call in a try/except block which catches ValueError (probably faster, at least when the list to search is long, and the item is usually present.)      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "793", "A_Content": "  One thing that is really helpful in learning Python is to use the interactive help function:  >>> help([\"foo\", \"bar\", \"baz\"]) Help on list object:  class list(object)  ...   |  |  index(...)  |      L.index(value, [start, [stop]]) -> integer -- return first index of value  |   which will often lead you to the method you are looking for.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "455", "A_Content": "  The majority of answers explain how to find a single index, but their methods do not return multiple indexes if the item is in the list multiple times. Use enumerate():  for i, j in enumerate(['foo', 'bar', 'baz']):     if j == 'bar':         print(i)   The index() function only returns the first occurrence, while enumerate() returns all occurrences.  As a list comprehension:  [i for i, j in enumerate(['foo', 'bar', 'baz']) if j == 'bar']     Here's also another small solution with itertools.count() (which is pretty much the same approach as enumerate):  from itertools import izip as zip, count # izip for maximum efficiency [i for i, j in zip(count(), ['foo', 'bar', 'baz']) if j == 'bar']   This is more efficient for larger lists than using enumerate():  $ python -m timeit -s \"from itertools import izip as zip, count\" \"[i for i, j in zip(count(), ['foo', 'bar', 'baz']*500) if j == 'bar']\" 10000 loops, best of 3: 174 usec per loop $ python -m timeit \"[i for i, j in enumerate(['foo', 'bar', 'baz']*500) if j == 'bar']\" 10000 loops, best of 3: 196 usec per loop      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "127", "A_Content": "  To get all indexes:   indexes = [i for i,x in enumerate(xs) if x == 'foo']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "108", "A_Content": "  index() returns the first index of value!     |  index(...)    |      L.index(value, [start, [stop]]) -> integer -- return first index of value   def all_indices(value, qlist):     indices = []     idx = -1     while True:         try:             idx = qlist.index(value, idx+1)             indices.append(idx)         except ValueError:             break     return indices  all_indices(\"foo\", [\"foo\",\"bar\",\"baz\",\"foo\"])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "67", "A_Content": "  A problem will arise if the element is not in the list. This function handles the issue:  # if element is found it returns index of element else returns None  def find_element_in_list(element, list_element):     try:         index_element = list_element.index(element)         return index_element     except ValueError:         return None      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "57", "A_Content": "  a = [\"foo\",\"bar\",\"baz\",'bar','any','much']  indexes = [index for index in range(len(a)) if a[index] == 'bar']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "40", "A_Content": "  You have to set a condition to check if the element you're searching is in the list  if 'your_element' in mylist:     print mylist.index('your_element') else:     print None      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "35", "A_Content": "  All of the proposed functions here reproduce inherent language behavior but obscure what's going on.  [i for i in range(len(mylist)) if mylist[i]==myterm]  # get the indices  [each for each in mylist if each==myterm]             # get the items  mylist.index(myterm) if myterm in mylist else None    # get the first index and fail quietly   Why write a function with exception handling if the language provides the methods to do what you want itself?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "28", "A_Content": "  If you want all indexes, then you can use NumPy:  import numpy as np  array = [1, 2, 1, 3, 4, 5, 1] item = 1 np_array = np.array(array) item_index = np.where(np_array==item) print item_index # Out: (array([0, 2, 6], dtype=int64),)   It is clear, readable solution.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "22", "A_Content": "     Finding the index of an item given a list containing it in Python      For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", what's the cleanest way to get its index (1) in Python?   Well, sure, there's the index method, which returns the index of the first occurrence:  >>> l = [\"foo\", \"bar\", \"baz\"] >>> l.index('bar') 1   There are a couple of issues with this method:   if the value isn't in the list, you'll get a ValueError if more than one of the value is in the list, you only get the index for the first one   No values  If the value could be missing, you need to catch the ValueError.   You can do so with a reusable definition like this:  def index(a_list, value):     try:         return a_list.index(value)     except ValueError:         return None   And use it like this:  >>> print(index(l, 'quux')) None >>> print(index(l, 'bar')) 1   And the downside of this is that you will probably have a check for if the returned value is or is not None:  result = index(a_list, value) if result is not None:     do_something(result)   More than one value in the list  If you could have more occurrences, you'll not get complete information with list.index:  >>> l.append('bar') >>> l ['foo', 'bar', 'baz', 'bar'] >>> l.index('bar')              # nothing at index 3? 1   You might enumerate into a list comprehension the indexes:  >>> [index for index, v in enumerate(l) if v == 'bar'] [1, 3] >>> [index for index, v in enumerate(l) if v == 'boink'] []   If you have no occurrences, you can check for that with boolean check of the result, or just do nothing if you loop over the results:  indexes = [index for index, v in enumerate(l) if v == 'boink'] for index in indexes:     do_something(index)   Better data munging with pandas  If you have pandas, you can easily get this information with a Series object:  >>> import pandas as pd >>> series = pd.Series(l) >>> series 0    foo 1    bar 2    baz 3    bar dtype: object   A comparison check will return a series of booleans:  >>> series == 'bar' 0    False 1     True 2    False 3     True dtype: bool   Pass that series of booleans to the series via subscript notation, and you get just the matching members:  >>> series[series == 'bar'] 1    bar 3    bar dtype: object   If you want just the indexes, the index attribute returns a series of integers:  >>> series[series == 'bar'].index Int64Index([1, 3], dtype='int64')   And if you want them in a list or tuple, just pass them to the constructor:  >>> list(series[series == 'bar'].index) [1, 3]   Yes, you could use a list comprehension with enumerate too, but that's just not as elegant, in my opinion - you're doing tests for equality in Python, instead of letting builtin code written in C handle it:  >>> [i for i, value in enumerate(l) if value == 'bar'] [1, 3]   Is this an XY problem?     The XY problem is asking about your attempted solution rather than your actual problem.   Why do you think you need the index given an element in a list?   If you already know the value, why do you care where it is in a list?  If the value isn't there, catching the ValueError is rather verbose - and I prefer to avoid that.  I'm usually iterating over the list anyways, so I'll usually keep a pointer to any interesting information, getting the index with enumerate.  If you're munging data, you should probably be using pandas - which has far more elegant tools than the pure Python workarounds I've shown.  I do not recall needing list.index, myself. However, I have looked through the Python standard library, and I see some excellent uses for it.   There are many, many uses for it in idlelib, for GUI and text parsing.  The keyword module uses it to find comment markers in the module to automatically regenerate the list of keywords in it via metaprogramming.  In Lib/mailbox.py it seems to be using it like an ordered mapping:  key_list[key_list.index(old)] = new   and  del key_list[key_list.index(key)]   In Lib/http/cookiejar.py, seems to be used to get the next month:  mon = MONTHS_LOWER.index(mon.lower())+1   In Lib/tarfile.py similar to distutils to get a slice up to an item:  members = members[:members.index(tarinfo)]   In Lib/pickletools.py:  numtopop = before.index(markobject)   What these usages seem to have in common is that they seem to operate on lists of constrained sizes (important because of O(n) lookup time for list.index), and they're mostly used in parsing (and UI in the case of Idle).   While there are use-cases for it, they are fairly uncommon. If you find yourself looking for this answer, ask yourself if what you're doing is the most direct usage of the tools provided by the language for your use-case.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "18", "A_Content": "  All indexes with the zip function:  get_indexes = lambda x, xs: [i for (y, i) in zip(xs, range(len(xs))) if x == y]  print get_indexes(2, [1, 2, 3, 4, 5, 6, 3, 2, 3, 2]) print get_indexes('f', 'xsfhhttytffsafweef')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "15", "A_Content": "  Simply you can go with  a = [['hand', 'head'], ['phone', 'wallet'], ['lost', 'stock']] b = ['phone', 'lost']  res = [[x[0] for x in a].index(y) for y in b]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "15", "A_Content": "  Another option  >>> a = ['red', 'blue', 'green', 'red'] >>> b = 'red' >>> offset = 0; >>> indices = list() >>> for i in range(a.count(b)): ...     indices.append(a.index(b,offset)) ...     offset = indices[-1]+1 ...  >>> indices [0, 3] >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "13", "A_Content": "  A variant on the answer from FMc and user7177 will give a dict that can return all indices for any entry:  >>> a = ['foo','bar','baz','bar','any', 'foo', 'much'] >>> l = dict(zip(set(a), map(lambda y: [i for i,z in enumerate(a) if z is y ], set(a)))) >>> l['foo'] [0, 5] >>> l ['much'] [6] >>> l {'baz': [2], 'foo': [0, 5], 'bar': [1, 3], 'any': [4], 'much': [6]} >>>    You could also use this as a one liner to get all indices for a single entry. There are no guarantees for efficiency, though I did use set(a) to reduce the number of times the lambda is called.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "13", "A_Content": "  And now, for something completely different...    ... like confirming the existence of the item before getting the index.  The nice thing about this approach is the function always returns a list of indices -- even if it is an empty list.  It works with strings as well.  def indices(l, val):     \"\"\"Always returns a list containing the indices of val in the_list\"\"\"     retval = []     last = 0     while val in l[last:]:             i = l[last:].index(val)             retval.append(last + i)             last += i + 1        return retval  l = ['bar','foo','bar','baz','bar','bar'] q = 'bar' print indices(l,q) print indices(l,'bat') print indices('abcdaababb','a')   When pasted into an interactive python window:  Python 2.7.6 (v2.7.6:3a1db0d2747e, Nov 10 2013, 00:42:54)  [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> def indices(the_list, val): ...     \"\"\"Always returns a list containing the indices of val in the_list\"\"\" ...     retval = [] ...     last = 0 ...     while val in the_list[last:]: ...             i = the_list[last:].index(val) ...             retval.append(last + i) ...             last += i + 1    ...     return retval ...  >>> l = ['bar','foo','bar','baz','bar','bar'] >>> q = 'bar' >>> print indices(l,q) [0, 2, 4, 5] >>> print indices(l,'bat') [] >>> print indices('abcdaababb','a') [0, 4, 5, 7] >>>    Update  After another year of heads-down python development, I'm a bit embarrassed by my original answer, so to set the record straight, one can certainly use the above code; however, the much more idiomatic way to get the same behavior would be to use list comprehension, along with the enumerate() function.    Something like this:    def indices(l, val):     \"\"\"Always returns a list containing the indices of val in the_list\"\"\"     return [index for index, value in enumerate(l) if value == val]  l = ['bar','foo','bar','baz','bar','bar'] q = 'bar' print indices(l,q) print indices(l,'bat') print indices('abcdaababb','a')   Which, when pasted into an interactive python window yields:  Python 2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 11:07:58)  [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> def indices(l, val): ...     \"\"\"Always returns a list containing the indices of val in the_list\"\"\" ...     return [index for index, value in enumerate(l) if value == val] ...  >>> l = ['bar','foo','bar','baz','bar','bar'] >>> q = 'bar' >>> print indices(l,q) [0, 2, 4, 5] >>> print indices(l,'bat') [] >>> print indices('abcdaababb','a') [0, 4, 5, 7] >>>    And now, after reviewing this question and all the answers, I realize that this is exactly what FMc suggested in his earlier answer.  At the time I originally answered this question, I didn't even see that answer, because I didn't understand it.  I hope that my somewhat more verbose example will aid understanding.    If the single line of code above still doesn't make sense to you, I highly recommend you Google 'python list comprehension' and take a few minutes to familiarize yourself.  It's just one of the many powerful features that make it a joy to use Python to develop code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "12", "A_Content": "  Getting all the occurrences and the position of one or more (identical) items in a list  With enumerate(alist) you can store the first element (n) that is the index of the list when the element x is equal to what you look for.  >>> alist = ['foo', 'spam', 'egg', 'foo'] >>> foo_indexes = [n for n,x in enumerate(alist) if x=='foo'] >>> foo_indexes [0, 3] >>>   Let's make our function findindex  This function takes the item and the list as arguments and return the position of the item in the list, like we saw before.  def indexlist(item2find, list_or_string):   \"Returns all indexes of an item in a list or a string\"   return [n for n,item in enumerate(list_or_string) if item==item2find]  print(indexlist(\"1\", \"010101010\"))        Output     [1, 3, 5, 7]   Simple  for n, i in enumerate([1, 2, 3, 4, 1]):     if i == 1:         print(n)   Output:  0 4      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "3176", "A_Content": "  It's pretty simple really:  a[start:end] # items start through end-1 a[start:]    # items start through the rest of the array a[:end]      # items from the beginning through end-1 a[:]         # a copy of the whole array   There is also the step value, which can be used with any of the above:  a[start:end:step] # start through not past end, by step   The key point to remember is that the :end value represents the first value that is not in the selected slice. So, the difference beween end and start is the number of elements selected (if step is 1, the default).  The other feature is that start or end may be a negative number, which means it counts from the end of the array instead of the beginning. So:  a[-1]    # last item in the array a[-2:]   # last two items in the array a[:-2]   # everything except the last two items   Similarly, step may be a negative number:  a[::-1]    # all items in the array, reversed a[1::-1]   # the first two items, reversed a[:-3:-1]  # the last two items, reversed a[-3::-1]  # everything except the last two items, reversed   Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for a[:-2] and a only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "10", "A_Content": "  This solution is not as powerful as others, but if you're a beginner and only know about forloops it's still possible to find the first index of an item while avoiding the ValueError:  def find_element(p,t):     i = 0     for e in p:         if e == t:             return i         else:             i +=1     return -1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "5", "A_Content": "  name =\"bar\" list = [[\"foo\", 1], [\"bar\", 2], [\"baz\", 3]] new_list=[] for item in list:     new_list.append(item[0]) print(new_list) try:     location= new_list.index(name) except:     location=-1 print (location)   This accounts for if the string is not in the list too, if it isn't in the list then location = -1     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "5", "A_Content": "  Since Python lists are zero-based, we can use the zip built-in function as follows:  >>> [i for i,j in zip(range(len(haystack)), haystack) if j == 'needle' ]   where \"haystack\" is the list in question and \"needle\" is the item to look for.  (Note: Here we are iterating using i to get the indexes, but if we need rather to focus on the items we can switch to j.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "3", "A_Content": "  There is a more functional answer to this.  list(filter(lambda x: x[1]==\"bar\",enumerate([\"foo\", \"bar\", \"baz\", \"bar\", \"baz\", \"bar\", \"a\", \"b\", \"c\"])))   More generic form:  def get_index_of(lst, element):     return list(map(lambda x: x[0],\\        (list(filter(lambda x: x[1]==element, enumerate(lst))))))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "3", "A_Content": "  Python index() method throws an error if the item was not found, which sucks!  So instead you can make it similar to the indexOf() function of JavaScript which returns -1 if the item was not found:      try:         index = array.index('search_keyword')     except ValueError:         index = -1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "2", "A_Content": "  Finding index of item x in list L:  idx = L.index(x) if (x in L) else -1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  For those coming from another language like me, maybe with a simple loop it's easier to understand and use it:  mylist = [\"foo\", \"bar\", \"baz\", \"bar\"] newlist = enumerate(mylist) for index, item in newlist:   if item == \"bar\":     print(index, item)   I am thankful for So what exactly does enumerate do?. That helped me to understand.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "Language": "Python", "Q_Title": "Finding the index of an item given a list containing it in Python", "Q_Votes": "2307", "Q_Content": "    For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index (1) in Python?     ", "Tags": ["python", "list"], "A_Votes": "0", "A_Content": "  If performance is of concern:  It is mentioned in numerous answers that the built-in method of list.index(item) method is an O(n) algorithm. It is fine if you need to perform this once. But if you need to access the indices of elements a number of times, it makes more sense to first create a dictionary (O(n)) of item-index pairs, and then access the index at O(1) every time you need it.  If you are sure that the items in your list are never repeated, you can easily:  myList = [\"foo\", \"bar\", \"baz\"]  # Create the dictionary myDict = dict((e,i) for i,e in enumerate(myList))  # Lookup myDict[\"bar\"] # Returns 1 # myDict.get(\"blah\") if you don't want an error to be raised if element not found.   If you may have duplicate elements, and need to return all of their indices:  from collections import defaultdict as dd myList = [\"foo\", \"bar\", \"bar\", \"baz\", \"foo\"]  # Create the dictionary myDict = dd(list) for i,e in enumerate(myList):     myDict[e].append(i)  # Lookup myDict[\"foo\"] # Returns [0, 4]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "404", "A_Content": "  The Python tutorial talks about it (scroll down a bit until you get to the part about slicing).  The ASCII art diagram is helpful too for remembering how slices work:   +---+---+---+---+---+---+  | P | y | t | h | o | n |  +---+---+---+---+---+---+  0   1   2   3   4   5   6 -6  -5  -4  -3  -2  -1      One way to remember how slices work is to think of the indices as pointing between characters, with the left edge of the first character numbered 0. Then the right edge of the last character of a string of n characters has index n.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "317", "A_Content": "  Enumerating the possibilities allowed by the grammar:  >>> seq[:]                # [seq[0],   seq[1],          ..., seq[-1]    ] >>> seq[low:]             # [seq[low], seq[low+1],      ..., seq[-1]    ] >>> seq[:high]            # [seq[0],   seq[1],          ..., seq[high-1]] >>> seq[low:high]         # [seq[low], seq[low+1],      ..., seq[high-1]] >>> seq[::stride]         # [seq[0],   seq[stride],     ..., seq[-1]    ] >>> seq[low::stride]      # [seq[low], seq[low+stride], ..., seq[-1]    ] >>> seq[:high:stride]     # [seq[0],   seq[stride],     ..., seq[high-1]] >>> seq[low:high:stride]  # [seq[low], seq[low+stride], ..., seq[high-1]]   Of course, if (high-low)%stride != 0, then the end point will be a little lower than high-1.  If stride is negative, the ordering is changed a bit since we're counting down:  >>> seq[::-stride]        # [seq[-1],   seq[-1-stride],   ..., seq[0]    ] >>> seq[high::-stride]    # [seq[high], seq[high-stride], ..., seq[0]    ] >>> seq[:low:-stride]     # [seq[-1],   seq[-1-stride],   ..., seq[low+1]] >>> seq[high:low:-stride] # [seq[high], seq[high-stride], ..., seq[low+1]]   Extended slicing (with commas and ellipses) are mostly used only by special data structures (like Numpy); the basic sequences don't support them.  >>> class slicee: ...     def __getitem__(self, item): ...         return `item` ... >>> slicee()[0, 1:2, ::5, ...] '(0, slice(1, 2, None), slice(None, None, 5), Ellipsis)'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "201", "A_Content": "  The answers above don't discuss slice assignment:  >>> r=[1,2,3,4] >>> r[1:1] [] >>> r[1:1]=[9,8] >>> r [1, 9, 8, 2, 3, 4] >>> r[1:1]=['blah'] >>> r [1, 'blah', 9, 8, 2, 3, 4]   This may also clarify the difference between slicing and indexing.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "192", "A_Content": "     Explain Python's slice notation   In short, the colons (:) in subscript notation (subscriptable[subscriptarg]) make slice notation - which has the optional arguments, start, stop, step:  sliceable[start:stop:step]   Python slicing is a computationally fast way to methodically access parts of your data. In my opinion, to be even an intermediate Python programmer, it's one aspect of the language that it is necessary to be familiar with.  Important Definitions  To begin with, let's define a few terms:     start: the beginning index of the slice, it will include the element at this index unless it is the same as stop, defaults to 0, i.e. the first index. If it's negative, it means to start n items from the end.      stop: the ending index of the slice, it does not include the element at this index, defaults to length of the sequence being sliced, that is, up to and including the end.      step: the amount by which the index increases, defaults to 1. If it's negative, you're slicing over the iterable in reverse.   How Indexing Works  You can make any of these positive or negative numbers. The meaning of the positive numbers is straightforward, but for negative numbers, just like indexes in Python, you count backwards from the end for the start and stop, and for the step, you simply decrement your index. This example is from the documentation's tutorial, but I've modified it slightly to indicate which item in a sequence each index references:   +---+---+---+---+---+---+  | P | y | t | h | o | n |  +---+---+---+---+---+---+    0   1   2   3   4   5    -6  -5  -4  -3  -2  -1   How Slicing Works  To use slice notation with a sequence that supports it, you must include at least one colon in the square brackets that follow the sequence (which actually implement the __getitem__ method of the sequence, according to the Python data model.)  Slice notation works like this:  sequence[start:stop:step]   And recall that there are defaults for start, stop, and step, so to access the defaults, simply leave out the argument.  Slice notation to get the last nine elements from a list (or any other sequence that supports it, like a string) would look like this:  my_list[-9:]   When I see this, I read the part in the brackets as \"9th from the end, to the end.\" (Actually, I abbreviate it mentally as \"-9, on\")  Explanation:  The full notation is   my_list[-9:None:None]   and to substitute the defaults (actually when step is negative, stop's default is -len(my_list) - 1, so None for stop really just means it goes to whichever end step takes it to):  my_list[-9:len(my_list):1]   The colon, :,  is what tells Python you're giving it a slice and not a regular index. That's why the idiomatic way of making a shallow copy of lists in Python 2 is  list_copy = sequence[:]   And clearing them is with:  del my_list[:]   (Python 3 gets a list.copy and list.clear method.)  When step is negative, the defaults for start and stop change  By default, when the step argument is empty (or None), it is assigned to +1.  But you can pass in a negative integer, and the list (or most other standard slicables) will be sliced from the end to the beginning.  Thus a negative slice will change the defaults for start and stop!  Confirming this in the source  I like to encourage users to read the source as well as the documentation. The source code for slice objects and this logic is found here. First we determine if step is negative:    step_is_negative = step_sign < 0;    If so, the lower bound is -1  meaning we slice all the way up to and including the beginning, and the upper bound is the length minus 1, meaning we start at the end. (Note that the semantics of this -1 is different from a -1 that users may pass indexes in Python indicating the last item.)   if (step_is_negative) {     lower = PyLong_FromLong(-1L);     if (lower == NULL)         goto error;      upper = PyNumber_Add(length, lower);     if (upper == NULL)         goto error; }    Otherwise step is positive, and the lower bound will be zero and the upper bound (which we go up to but not including) the length of the sliced list.   else {     lower = _PyLong_Zero;     Py_INCREF(lower);     upper = length;     Py_INCREF(upper); }    Then, we may need to apply the defaults for start and stop - the default then for start is calculated as the upper bound when step is negative:   if (self->start == Py_None) {     start = step_is_negative ? upper : lower;     Py_INCREF(start); }    and stop, the lower bound:   if (self->stop == Py_None) {     stop = step_is_negative ? lower : upper;     Py_INCREF(stop); }    Give your slices a descriptive name!  You may find it useful to separate forming the slice from passing it to the list.__getitem__ method (that's what the square brackets do). Even if you're not new to it, it keeps your code more readable so that others that may have to read your code can more readily understand what you're doing.  However, you can't just assign some integers separated by colons to a variable. You need to use the slice object:  last_nine_slice = slice(-9, None)   The second argument, None, is required, so that the first argument is interpreted as the start argument otherwise it would be the stop argument.   You can then pass the slice object to your sequence:  >>> list(range(100))[last_nine_slice] [91, 92, 93, 94, 95, 96, 97, 98, 99]   It's interesting that ranges also take slices:  >>> range(100)[last_nine_slice] range(91, 100)   Memory Considerations:  Since slices of Python lists create new objects in memory, another important function to be aware of is itertools.islice. Typically you'll want to iterate over a slice, not just have it created statically in memory. islice is perfect for this. A caveat, it doesn't support negative arguments to start, stop, or step, so if that's an issue you may need to calculate indices or reverse the iterable in advance.  length = 100 last_nine_iter = itertools.islice(list(range(length)), length-9, None, 1) list_last_nine = list(last_nine_iter)   and now:  >>> list_last_nine [91, 92, 93, 94, 95, 96, 97, 98, 99]   The fact that list slices make a copy is a feature of lists themselves. If you're slicing advanced objects like a Pandas DataFrame, it may return a view on the original, and not a copy.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "126", "A_Content": "  And a couple of things that weren't immediately obvious to me when I first saw the slicing syntax:  >>> x = [1,2,3,4,5,6] >>> x[::-1] [6,5,4,3,2,1]   Easy way to reverse sequences!  And if you wanted, for some reason, every second item in the reversed sequence:  >>> x = [1,2,3,4,5,6] >>> x[::-2] [6,4,2]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "86", "A_Content": "  Found this great table at http://wiki.python.org/moin/MovingToPythonFromOtherLanguages  Python indexes and slices for a six-element list. Indexes enumerate the elements, slices enumerate the spaces between the elements.  Index from rear:    -6  -5  -4  -3  -2  -1      a=[0,1,2,3,4,5]    a[1:]==[1,2,3,4,5] Index from front:    0   1   2   3   4   5      len(a)==6          a[:5]==[0,1,2,3,4]                    +---+---+---+---+---+---+    a[0]==0            a[:-2]==[0,1,2,3]                    | a | b | c | d | e | f |    a[5]==5            a[1:2]==[1]                    +---+---+---+---+---+---+    a[-1]==5           a[1:-1]==[1,2,3,4] Slice from front:  :   1   2   3   4   5   :    a[-2]==4 Slice from rear:   :  -5  -4  -3  -2  -1   :                                                 b=a[:]                                                 b==[0,1,2,3,4,5] (shallow copy of a)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "85", "A_Content": "  In Python 2.7  Slicing in Python  [a:b:c]  len = length of string, tuple or list  c -- default is +1. The sign of c indicates forward or backward, absolute value of c indicates steps. Default is forward with step size 1. Positive means forward, negative means backward.  a --  When c is positive or blank, default is 0. When c is negative, default is -1.  b --  When c is positive or blank, default is len. When c is negative, default is -(len+1).   Understanding index assignment is very important.  In forward direction, starts at 0 and ends at len-1  In backward direction, starts at -1 and ends at -len   When you say [a:b:c], you are saying depending on the sign of c (forward or backward), start at a and end at b (excluding element at bth index). Use the indexing rule above and remember you will only find elements in this range:  -len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1   But this range continues in both directions infinitely:  ...,-len -2 ,-len-1,-len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1, len, len +1, len+2 , ....   For example:               0    1    2   3    4   5   6   7   8   9   10   11              a    s    t   r    i   n   g     -9  -8  -7   -6   -5  -4   -3  -2  -1   If your choice of a, b, and c allows overlap with the range above as you traverse using rules for a,b,c above you will either get a list with elements (touched during traversal) or you will get an empty list.  One last thing: if a and b are equal, then also you get an empty list:  >>> l1 [2, 3, 4]  >>> l1[:] [2, 3, 4]  >>> l1[::-1] # a default is -1 , b default is -(len+1) [4, 3, 2]  >>> l1[:-4:-1] # a default is -1 [4, 3, 2]  >>> l1[:-3:-1] # a default is -1 [4, 3]  >>> l1[::] # c default is +1, so a default is 0, b default is len [2, 3, 4]  >>> l1[::-1] # c is -1 , so a default is -1 and b default is -(len+1) [4, 3, 2]   >>> l1[-100:-200:-1] # Interesting []  >>> l1[-1:-200:-1] # Interesting [4, 3, 2]   >>> l1[-1:-1:1] []   >>> l1[-1:5:1] # Interesting [4]   >>> l1[1:-7:1] []  >>> l1[1:-7:-1] # Interesting [3, 2]  >>> l1[:-2:-2] # a default is -1, stop(b) at -2 , step(c) by 2 in reverse direction [4]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "48", "A_Content": "  After using it a bit I realise that the simplest description is that it is exactly the same as the arguments in a for loop...  (from:to:step)   any of them are optional  (:to:step) (from::step) (from:to)   then the negative indexing just needs you to add the length of the string to the negative indices to understand it.  This works for me anyway...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "33", "A_Content": "  I find it easier to remember how it's works, then I can figure out any specific start/stop/step combination.  It's instructive to understand range() first:  def range(start=0, stop, step=1):  # illegal syntax, but that's the effect     i = start     while (i < stop if step > 0 else i > stop):         yield i         i += step   Begin from start, increment by step, do not reach stop.  Very simple.  The thing to remember about negative step is that stop is always the excluded end, whether it's higher or lower. If you want same slice in opposite order, it's much cleaner to do the reversal separately: e.g. 'abcde'[1:-2][::-1] slices off one char from left, two from right, then reverses. (See also reversed().)  Sequence slicing is same, except it first normalizes negative indexes, and can never go outside the sequence:  TODO: The code below had a bug with \"never go outside the sequence\" when abs(step)>1; I think I patched it to be correct, but it's hard to understand.  def this_is_how_slicing_works(seq, start=None, stop=None, step=1):     if start is None:         start = (0 if step > 0 else len(seq)-1)     elif start < 0:         start += len(seq)     if not 0 <= start < len(seq):  # clip if still outside bounds         start = (0 if step > 0 else len(seq)-1)     if stop is None:         stop = (len(seq) if step > 0 else -1)  # really -1, not last element     elif stop < 0:         stop += len(seq)     for i in range(start, stop, step):         if 0 <= i < len(seq):             yield seq[i]   Don't worry about the is None details - just remember that omitting start and/or stop always does the right thing to give you the whole sequence.  Normalizing negative indexes first allows start and/or stop to be counted from the end independently: 'abcde'[1:-2] == 'abcde'[1:3] == 'bc' despite range(1,-2) == []. The normalization is sometimes thought of as \"modulo the length\" but note it adds the length just once: e.g. 'abcde'[-53:42] is just the whole string.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "31", "A_Content": "  I use the \"an index points between elements\" method of thinking about it myself, but one way of describing it which sometimes helps others get it is this:  mylist[X:Y]   X is the index of the first element you want. Y is the index of the first element you don't want.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "30", "A_Content": "  Index:       ------------>   0   1   2   3   4 +---+---+---+---+---+ | a | b | c | d | e | +---+---+---+---+---+   0  -4  -3  -2  -1       <------------  Slice:     <---------------| |---------------> :   1   2   3   4   : +---+---+---+---+---+ | a | b | c | d | e | +---+---+---+---+---+ :  -4  -3  -2  -1   : |--------------->     <---------------|   I hope this will help you to model the list in Python.  Reference: http://wiki.python.org/moin/MovingToPythonFromOtherLanguages     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "28", "A_Content": "  Python slicing notation:  a[start:end:step]    For start and end, negative values are interpreted as being relative to the end of the sequence. Positive indices for end indicate the position after the last element to be included. Blank values are defaulted as follows: [+0:-0:1]. Using a negative step reverses the interpretation of start and end   The notation extends to (numpy) matrices and multidimensional arrays.  For example, to slice entire columns you can use:  m[::,0:2:] ## slice the first two columns   Slices hold references, not copies, of the array elements.  If you want to make a separate copy an array, you can use deepcopy().     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "25", "A_Content": "  You can also use slice assignment to remove one or more elements from a list:  r = [1, 'blah', 9, 8, 2, 3, 4] >>> r[1:4] = [] >>> r [1, 2, 3, 4]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "25", "A_Content": "  This is just for some extra info... Consider the list below   >>> l=[12,23,345,456,67,7,945,467]   Few other tricks for reversing the list:  >>> l[len(l):-len(l)-1:-1] [467, 945, 7, 67, 456, 345, 23, 12]  >>> l[:-len(l)-1:-1] [467, 945, 7, 67, 456, 345, 23, 12]  >>> l[len(l)::-1] [467, 945, 7, 67, 456, 345, 23, 12]  >>> l[::-1] [467, 945, 7, 67, 456, 345, 23, 12]  >>> l[-1:-len(l)-1:-1] [467, 945, 7, 67, 456, 345, 23, 12]   See abc's answer above     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "24", "A_Content": "  This is how I teach slices to newbies:  Understanding difference between indexing and slicing:  Wiki Python has this amazing picture which clearly distinguishes indexing and slicing.    It is a list with 6 elements in it. To understand slicing better, consider that list as a set of six boxes placed together. Each box has an alphabet in it.  Indexing is like dealing with the contents of box. You can check contents of any box. But You can't check contents of multiple boxes at once. You can even replace contents of the box. But You can't place 2 balls in 1 box or replace 2 balls at a time.  In [122]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']  In [123]: alpha Out[123]: ['a', 'b', 'c', 'd', 'e', 'f']  In [124]: alpha[0] Out[124]: 'a'  In [127]: alpha[0] = 'A'  In [128]: alpha Out[128]: ['A', 'b', 'c', 'd', 'e', 'f']  In [129]: alpha[0,1] --------------------------------------------------------------------------- TypeError                                 Traceback (most recent call last) <ipython-input-129-c7eb16585371> in <module>() ----> 1 alpha[0,1]  TypeError: list indices must be integers, not tuple   Slicing is like dealing with boxes itself. You can pickup first box and place it on another table. To pickup the box all You need to know is the position of beginning  & ending of the box.  You can even pickup first 3 boxes or last 2 boxes or all boxes between 1 & 4. So, You can pick any set of boxes if You know beginning & ending. This positions are called start & stop positions.  The interesting thing is that You can replace multiple boxes at once. Also You can place multiple boxes where ever You like.  In [130]: alpha[0:1] Out[130]: ['A']  In [131]: alpha[0:1] = 'a'  In [132]: alpha Out[132]: ['a', 'b', 'c', 'd', 'e', 'f']  In [133]: alpha[0:2] = ['A', 'B']  In [134]: alpha Out[134]: ['A', 'B', 'c', 'd', 'e', 'f']  In [135]: alpha[2:2] = ['x', 'xx']  In [136]: alpha Out[136]: ['A', 'B', 'x', 'xx', 'c', 'd', 'e', 'f']   Slicing With Step:  Till now You have picked boxes continuously. But some times You need to pickup discretely. For example You can pickup every second box. You can even pickup every third box from the end. This value is called step size. This represents the gap between Your successive pickups. The step size should be positive if You are picking boxes from the beginning to end and vice versa.  In [137]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']  In [142]: alpha[1:5:2]  Out[142]: ['b', 'd']  In [143]: alpha[-1:-5:-2] Out[143]: ['f', 'd']  In [144]: alpha[1:5:-2] Out[144]: []  In [145]: alpha[-1:-5:2]       Out[145]: []   How Python Figures Out Missing Parameters:  When slicing if You leave out any parameter, Python tries to figure it out automatically.  If You check source code of CPython, You will find a function called PySlice_GetIndicesEx which figures out indices to a slice for any given parameters. Here is the logical equivalent code in Python.  This function takes a Python object & optional parameters for slicing and returns start, stop, step & slice length for the requested slice.  def py_slice_get_indices_ex(obj, start=None, stop=None, step=None):      length = len(obj)      if step is None:         step = 1     if step == 0:         raise Exception(\"Step cannot be zero.\")      if start is None:         start = 0 if step > 0 else length - 1     else:         if start < 0:             start += length         if start < 0:             start = 0 if step > 0 else -1         if start >= length:             start = length if step > 0 else length - 1      if stop is None:         stop = length if step > 0 else -1     else:         if stop < 0:             stop += length         if stop < 0:             stop = 0 if step > 0 else -1         if stop >= length:             stop = length if step > 0 else length - 1      if (step < 0 and stop >= start) or (step > 0 and start >= stop):         slice_length = 0     elif step < 0:         slice_length = (stop - start + 1)/(step) + 1     else:         slice_length = (stop - start - 1)/(step) + 1      return (start, stop, step, slice_length)   This is the intelligence that is present behind slices. Since Python has inbuilt function called slice, You can pass some parameters & check how smartly it calculates missing parameters.  In [21]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']  In [22]: s = slice(None, None, None)  In [23]: s Out[23]: slice(None, None, None)  In [24]: s.indices(len(alpha))  Out[24]: (0, 6, 1)  In [25]: range(*s.indices(len(alpha))) Out[25]: [0, 1, 2, 3, 4, 5]  In [26]: s = slice(None, None, -1)   In [27]: range(*s.indices(len(alpha))) Out[27]: [5, 4, 3, 2, 1, 0]  In [28]: s = slice(None, 3, -1)          In [29]: range(*s.indices(len(alpha))) Out[29]: [5, 4]   Note: This post is originally written in my blog http://www.avilpage.com/2015/03/a-slice-of-python-intelligence-behind.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "21", "A_Content": "  As a general rule, writing code with a lot of hardcoded index values leads to a readability and maintenance mess. For example, if you come back to the code a year later, you\u2019ll look at it and wonder what you were thinking when you wrote it. The solution shown is simply a way of more clearly stating what your code is actually doing. In general, the built-in slice() creates a slice object that can be used anywhere a slice is allowed. For example:  >>> items = [0, 1, 2, 3, 4, 5, 6] >>> a = slice(2, 4) >>> items[2:4] [2, 3] >>> items[a] [2, 3] >>> items[a] = [10,11] >>> items [0, 1, 10, 11, 4, 5, 6] >>> del items[a] >>> items [0, 1, 4, 5, 6]   If you have a slice instance s, you can get more information about it by looking at its s.start, s.stop, and s.step attributes, respectively. For example:   >>> a = slice(10, 50, 2) >>> a.start 10 >>> a.stop 50 >>> a.step 2 >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "20", "A_Content": "  1. Slice Notation  To make it simple, remember slice has only one form\uff1a  s[start:end:step]   and here is how it works:   s: an object that can be sliced start: first index to start iteration end: last index, NOTE that end index will not be included in the resulted slice step: pick element every step index   Another import thing: all start,end, step can be omitted! And if they are omitted, their default value will be used: 0,len(s),1 accordingly.  So possible variations are:  # mostly used variations s[start:end] s[start:] s[:end]  # step related variations s[:end:step] s[start::step] s[::step]  # make a copy s[:]   NOTE: If start>=end(considering only when step>0), python will return a empty slice [].  2. Pitfalls  The above part explains the core features on how slice works, it will work on most occasions. However there can be pitfalls you should watch out, and this part explains them.  Negative indexes  The very first thing confuses python learners is that index can be negative!  Don't panic: negative index means count from backwards.  For example:  s[-5:]    # start at the 5th index from the end of array,            # thus returns the last 5 elements s[:-5]    # start at index 0, end until the 5th index from end of array,            # thus returns s[0:len(s)-5]   Negative step  Make things more confusing is that step can be negative too!   Negative step means iterate the array backwards: from end to start, with end index included, and start index excluded from result.  NOTE: when step is negative, the default value for start to len(s)(while end does not equal to 0, because s[::-1] contains s[0]). For example:  s[::-1]            # reversed slice s[len(s)::-1]      # same as above, reversed slice s[0:len(s):-1]     # empty list   Out of range error?  Be surprised: slice does not raise IndexError when index is out of range!  If the index is out of range, python will try its best set the index to 0 or len(s) according to the situation. For example:  s[:len(s)+5]      # same as s[:len(s)] s[-len(s)-5::]    # same as s[0:] s[len(s)+5::-1]   # same as s[len(s)::-1], same as s[::-1]   3. Examples  Let's finish this answer with examples explains everything we have discussed:  # create our array for demonstration In [1]: s = [i for i in range(10)]  In [2]: s Out[2]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  In [3]: s[2:]   # from index 2 to last index Out[3]: [2, 3, 4, 5, 6, 7, 8, 9]  In [4]: s[:8]   # from index 0 up to index 8 Out[4]: [0, 1, 2, 3, 4, 5, 6, 7]  In [5]: s[4:7]  # from index 4(included) up to index 7(excluded) Out[5]: [4, 5, 6]  In [6]: s[:-2]  # up to second last index(negative index) Out[6]: [0, 1, 2, 3, 4, 5, 6, 7]  In [7]: s[-2:]  # from second last index(negative index) Out[7]: [8, 9]  In [8]: s[::-1] # from last to first in reverse order(negative step) Out[8]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]  In [9]: s[::-2] # all odd numbers in reversed order Out[9]: [9, 7, 5, 3, 1]  In [11]: s[-2::-2] # all even numbers in reversed order Out[11]: [8, 6, 4, 2, 0]  In [12]: s[3:15]   # end is out of range, python will set it to len(s) Out[12]: [3, 4, 5, 6, 7, 8, 9]  In [14]: s[5:1]    # start > end, return empty list Out[14]: []  In [15]: s[11]     # access index 11(greater than len(s)) will raise IndexError --------------------------------------------------------------------------- IndexError                                Traceback (most recent call last) <ipython-input-15-79ffc22473a3> in <module>() ----> 1 s[11]  IndexError: list index out of range      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "14", "A_Content": "  The answers above don't discuss multi-dimentional array slicing which is possible using the famous numpy package:  Slicing also apply to multi-dimentional arrays.  # Here, a is a numpy array  >>> a array([[ 1,  2,  3,  4],        [ 5,  6,  7,  8],        [ 9, 10, 11, 12]]) >>> a[:2,0:3:2] array([[1, 3],        [5, 7]])   The \":2\" before comma operates on the first dimension and the \"0:3:2\" after the comma operates on the second dimension.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "11", "A_Content": "  To get a certain piece of an iterable (like a list), here is an example:  variable[number1:number2]   In this example, a positive number for number 1 is how many components you take off the front. A negative number is the exact opposite, how many you keep from the end. A positive number for number 2 indicates how many components you intend to keep from the beginning, and a negative is how many you intend to take off from the end. This is somewhat counter intuitive, but you are correct in supposing that list slicing is extremely useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "11", "A_Content": "  My brain seems happy to accept that lst[start:end] contains the start-th item. I might even say that it is a 'natural assumption'.  But occasionally a doubt creeps in and my brain asks for reassurance that it does not contain the end-th element.  In these moments I rely on this simple theorem:  for any n,    lst = lst[:n] + lst[n:]   This pretty property tells me that lst[start:end] does not contain the end-th item because it is in lst[end:].  Note that this theorem is true for any n at all. For example, you can check that  lst = range(10) lst[:-42] + lst[-42:] == lst   returns True.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "10", "A_Content": "  #!/usr/bin/env python  def slicegraphical(s, lista):      if len(s) > 9:         print \"\"\"Enter a string of maximum 9 characters,     so the printig would looki nice\"\"\"         return 0;     # print \" \",     print '  '+'+---' * len(s) +'+'     print ' ',     for letter in s:         print '| {}'.format(letter),     print '|'     print \" \",; print '+---' * len(s) +'+'      print \" \",     for letter in range(len(s) +1):         print '{}  '.format(letter),     print \"\"     for letter in range(-1*(len(s)), 0):         print ' {}'.format(letter),     print ''     print ''       for triada in lista:         if len(triada) == 3:             if triada[0]==None and triada[1] == None and triada[2] == None:                 # 000                 print s+'[   :   :   ]' +' = ', s[triada[0]:triada[1]:triada[2]]             elif triada[0] == None and triada[1] == None and triada[2] != None:                 # 001                 print s+'[   :   :{0:2d} ]'.format(triada[2], '','') +' = ', s[triada[0]:triada[1]:triada[2]]             elif triada[0] == None and triada[1] != None and triada[2] == None:                 # 010                 print s+'[   :{0:2d} :   ]'.format(triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]             elif triada[0] == None and triada[1] != None and triada[2] != None:                 # 011                 print s+'[   :{0:2d} :{1:2d} ]'.format(triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]             elif triada[0] != None and triada[1] == None and triada[2] == None:                 # 100                 print s+'[{0:2d} :   :   ]'.format(triada[0]) +' = ', s[triada[0]:triada[1]:triada[2]]             elif triada[0] != None and triada[1] == None and triada[2] != None:                 # 101                 print s+'[{0:2d} :   :{1:2d} ]'.format(triada[0], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]             elif triada[0] != None and triada[1] != None and triada[2] == None:                 # 110                 print s+'[{0:2d} :{1:2d} :   ]'.format(triada[0], triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]             elif triada[0] != None and triada[1] != None and triada[2] != None:                 # 111                 print s+'[{0:2d} :{1:2d} :{2:2d} ]'.format(triada[0], triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]          elif len(triada) == 2:             if triada[0] == None and triada[1] == None:                 # 00                 print s+'[   :   ]    ' + ' = ', s[triada[0]:triada[1]]             elif triada[0] == None and triada[1] != None:                 # 01                 print s+'[   :{0:2d} ]    '.format(triada[1]) + ' = ', s[triada[0]:triada[1]]             elif triada[0] != None and triada[1] == None:                 # 10                 print s+'[{0:2d} :   ]    '.format(triada[0]) + ' = ', s[triada[0]:triada[1]]             elif triada[0] != None and triada[1] != None:                 # 11                 print s+'[{0:2d} :{1:2d} ]    '.format(triada[0],triada[1]) + ' = ', s[triada[0]:triada[1]]          elif len(triada) == 1:             print s+'[{0:2d} ]        '.format(triada[0]) + ' = ', s[triada[0]]   if __name__ == '__main__':     # Change \"s\" to what ever string you like, make it 9 characters for     # better representation.     s = 'COMPUTERS'      # add to this list different lists to experement with indexes     # to represent ex. s[::], use s[None, None,None], otherwise you get an error     # for s[2:] use s[2:None]      lista = [[4,7],[2,5,2],[-5,1,-1],[4],[-4,-6,-1], [2,-3,1],[2,-3,-1], [None,None,-1],[-5,None],[-5,0,-1],[-5,None,-1],[-1,1,-2]]      slicegraphical(s, lista)   You can run this script and experiment with it, below is some samples that I got from the script.    +---+---+---+---+---+---+---+---+---+   | C | O | M | P | U | T | E | R | S |   +---+---+---+---+---+---+---+---+---+   0   1   2   3   4   5   6   7   8   9     -9  -8  -7  -6  -5  -4  -3  -2  -1   COMPUTERS[ 4 : 7 ]     =  UTE COMPUTERS[ 2 : 5 : 2 ] =  MU COMPUTERS[-5 : 1 :-1 ] =  UPM COMPUTERS[ 4 ]         =  U COMPUTERS[-4 :-6 :-1 ] =  TU COMPUTERS[ 2 :-3 : 1 ] =  MPUT COMPUTERS[ 2 :-3 :-1 ] =   COMPUTERS[   :   :-1 ] =  SRETUPMOC COMPUTERS[-5 :   ]     =  UTERS COMPUTERS[-5 : 0 :-1 ] =  UPMO COMPUTERS[-5 :   :-1 ] =  UPMOC COMPUTERS[-1 : 1 :-2 ] =  SEUM [Finished in 0.9s]   When using a negative step, notice that the answer is shifted to the right by 1.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "7", "A_Content": "  In Python, the most basic form for slicing is the following:  l[start:end]  where l is some collection, start is an inclusive index and end is an exclusive index.  In [1]: l = list(range(10))  In [2]: l[:5] # first five elements Out[2]: [0, 1, 2, 3, 4]  In [3]: l[-5:] # last five elements Out[3]: [5, 6, 7, 8, 9]   When slicing from start, you can omit the zero index, and when slicing to the end, you can omit the final index since it is redundant, so do not be verbose:  In [5]: l[:3] == l[0:3] Out[5]: True  In [6]: l[7:] == l[7:len(l)] Out[6]: True   Negative integers are useful when doing offsets relative to the end of a collection:  In [7]: l[:-1] # include all elements but the last one Out[7]: [0, 1, 2, 3, 4, 5, 6, 7, 8]  In [8]: l[-3:] # take the last 3 elements Out[8]: [7, 8, 9]   It is possible to provide indices that are out of bounds when slicing such as:  In [9]: l[:20] # 20 is out of index bounds, l[20] will raise an IndexError exception Out[9]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  In [11]: l[-20:] # -20 is out of index bounds, l[-20] will raise an IndexError exception Out[11]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]   Keep in mind that the result of slicing a collection is a whole new collection. In addition, when using slice notation in assignments, the length of the slice assignment do not need to be the same. The values before and after the assigned slice will be kept, and the collection will shrink or grow to contain the new values:  In [16]: l[2:6] = list('abc') # assigning less elements than the ones contained in the sliced collection l[2:6]  In [17]: l Out[17]: [0, 1, 'a', 'b', 'c', 6, 7, 8, 9]  In [18]: l[2:5] = list('hello') # assigning more elements than the ones contained in the sliced collection l [2:5]  In [19]: l Out[19]: [0, 1, 'h', 'e', 'l', 'l', 'o', 6, 7, 8, 9]   If you omit the start and end index, you will make a copy of the collection:  In [14]: l_copy = l[:]  In [15]: l == l_copy and l is not l_copy Out[15]: True   If the start and end indexes are omitted when performing an assignment operation, the entire content of the collection will be replaced with a copy of what is referenced:  In [20]: l[:] = list('hello...')  In [21]: l Out[21]: ['h', 'e', 'l', 'l', 'o', '.', '.', '.']   Besides basic slicing, it is also possible to apply the following notation:  l[start:end:step]   where l is a collection, start is an inclusive index, end is an exclusive index, and step is a stride that can be used to take every nth item in l.  In [22]: l = list(range(10))  In [23]: l[::2] # take the elements which indexes are even Out[23]: [0, 2, 4, 6, 8]  In [24]: l[1::2] # take the elements which indexes are odd Out[24]: [1, 3, 5, 7, 9]   Using step provides a useful trick to reverse a collection in Python:  In [25]: l[::-1] Out[25]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]   It is also possible to use negative integers for step as the following example:  In[28]:  l[::-2] Out[28]: [9, 7, 5, 3, 1]   However, using a negative value for step could become very confusing. Moreover, in order to be Pythonic, you should avoid using start, end, and step in a single slice. In case this is required, consider doing this in two assignments (one to slice, and the other to stride).  In [29]: l = l[::2] # this step is for striding  In [30]: l Out[30]: [0, 2, 4, 6, 8]  In [31]: l = l[1:-1] # this step is for slicing  In [32]: l Out[32]: [2, 4, 6]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "6", "A_Content": "  The below is the example of index of a string   +---+---+---+---+---+  | H | e | l | p | A |  +---+---+---+---+---+  0   1   2   3   4   5 -5  -4  -3  -2  -1  str=\"Name string\"   slicing example: [start:end:step]   str[start:end] # items start through end-1 str[start:]    # items start through the rest of the array str[:end]      # items from the beginning through end-1 str[:]         # a copy of the whole array   Below is the example usage   print str[0]=N print str[0:2]=Na print str[0:7]=Name st print str[0:7:2]=Nm t print str[0:-1:2]=Nm ti      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "6", "A_Content": "  Most of the above answers clears about Slice notation. Extended indexing syntax used for slicing is aList[start:stop:step] basic examples are  :  More Slicing examples: 15 Extended Slices     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "4", "A_Content": "  I want to add one Hello world example that explains the basics of slices for the very beginners. It helped me a lot.  Let's have a list with six values ['P', 'Y', 'T', 'H', 'O', 'N']:  +---+---+---+---+---+---+ | P | Y | T | H | O | N | +---+---+---+---+---+---+   0   1   2   3   4   5    Now the simplest slices of that list are its sublists. The notation is [<index>:<index>] and the key is to read it like this:  [ start cutting before this index : end cutting before this index ]   Now if you make a slice [2:5] of the list above, this will happen:          |           | +---+---|---+---+---|---+ | P | Y | T | H | O | N | +---+---|---+---+---|---+   0   1 | 2   3   4 | 5    You made a cut before the element with index 2 and another cut before the element with index 5. So the result will be a slice between those two cuts, a list ['T', 'H', 'O'].     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "3", "A_Content": "  Hehehe, it is kind of strange to see myself trying to provide a better and simpler explanation after 2600+ votes on what's been marked as the right answer from Grew Hewgill.  Here we go ...  In my opinion, you will understand and memorize better the Python string slicing notation if you look at it the following way (read on).  Let's work with the following string ...  azString = \"abcdefghijklmnopqrstuvwxyz\"   For those who don't know, you can create any substring from azString using the notation azString[x:y]  Coming from other programming languages, that's when the common sense gets compromised. What are x and y?  I had to sit down and run several scenarios in my quest for a memorization technique that will help me remember what x and y are and help me slice strings properly at the first attempt.  My conclusion is that x and y should be seen as the boundary indexes that are surrounding the strings that we want to extra. So we should see the expression as azString[index1, index2] or even more clearer as azString[index_of_first_character, index_after_the_last_character].  Here is an example visualization of that ...   Letters   a b c d e f g h i j ...          ^ ^ ^ ^ ^ ^ ^ ^ ^ ^  Indexes  0 1 2 3 4 5 6 7 8 9 ...               |           | cdefgh    index1       index2   So all you have to do if to set index1 and index2 to the values that will surround the desired substring. For instance, to get the substring \"cdefgh\", you can use azString[2:8] because the index on the left side of \"c\" is 2 and the one on the right size of \"h\" is 8.  Remember, we are setting the boundaries.  That trick works all the time and is easy to memorize.  Hopefuly this will help.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "3", "A_Content": "  Slice :-  snake appears near your foot. It moves from the invisible to the visible. Our vision reveals (like a slice) only a part of the world. similarly A Python slice extracts elements, based on a start and stop. We take slices on many types in Python. We specify an optional first index, an optional last index, and an optional step.  values[1:3]  Index 1 through index 3. values[2:-1] Index 2 through index one from last. values[:2]   Start through index 2. values[2:]   Index 2 through end. values[::2]  Start through end, skipping ahead 2 places each time.   you can get good examples at below link:- python slice notation example     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "3", "A_Content": "  If you feel negative indices in slicing is confusing, here's very easy way to think about it: just replace negative index with len - index. So for example, replace -3 with len(list) - 3.   The best way to illustrate what slicing does internally is just show it in code that implements this operation:  def slice(list, start = None, end = None, step = 1):   # take care of missing start/end parameters   start = 0 if start is None else start   end = len(list) if end is None else end    # take care of negative start/end parameters   start = len(list) + start if start < 0 else start   end = len(list) + end if end < 0 else end    # now just execute for-loop with start, end and step   return [list[i] for i in range(start, end, step)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/509211/understanding-pythons-slice-notation", "Language": "Python", "Q_Title": "Understanding Python's slice notation", "Q_Votes": "2348", "Q_Content": "    I need a good explanation (references are a plus) on Python's slice notation.   To me, this notation needs a bit of picking up.   It looks extremely powerful, but I haven't quite got my head around it.     ", "Tags": ["python", "list", "slice"], "A_Votes": "0", "A_Content": "  The basic slicing technique is to define the starting point, the stopping point, and the step size - also known as stride.  First, we will create a list of values to use in our slicing.  Create two lists to slice, the first is a numeric list from 1 to 9 (List A). The second is also a numeric list, from 0 to 9 (List B)  A = list(range(1,10,1)) # start,stop,step B = list(range(9))  print(\"This is List A:\",A) print(\"This is List B:\",B)   Index the number 3 from A and the number 6 from B.  print(A[2]) print(B[6])   Basic Slicing  Extended indexing syntax used for slicing is aList[start:stop:step]. The start argument and the step argument both default to none - the only required argument is stop. Did you notice this is similar to how range was used to define lists A and B? This is because the slice object represents the set of indices specified by range(start, stop, step). Python 3.4 documentation  As you can see, defining only stop returns one element. Since the start defaults to none, this translates into retrieving only one element.  It is important to note, the first element is index 0, NOT index 1. This is why we are using 2 lists for this exercise. List A's elements are numbered according to the ordinal position (the first element is 1, the second element is 2, etc) while List B's elements are the numbers that would be used to index them ([0] for the first element 0, etc).  With extended indexing syntax, we retrieve a range of values. For example, all values are retrieved with a colon.  A[:]   To retrieve a subset of elements, the start and stop positions need to be defined.  Given the pattern aList[start:stop], retrieve the first two elements from List A     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "3555", "A_Content": "  You can use a global variable in other functions by declaring it as global in each function that assigns to it:  globvar = 0  def set_globvar_to_one():     global globvar    # Needed to modify global copy of globvar     globvar = 1  def print_globvar():     print(globvar)     # No need for global declaration to read value of globvar  set_globvar_to_one() print_globvar()       # Prints 1   I imagine the reason for it is that, since global variables are so dangerous, Python wants to make sure that you really know that's what you're playing with by explicitly requiring the global keyword.  See other answers if you want to share a global variable across modules.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "4539", "A_Content": "  Using an additional state variable, such as an index variable (which you would normally use in languages such as C or PHP), is considered non-pythonic.  The better option is to use the built-in function enumerate(), available in both Python 2 and 3:  for idx, val in enumerate(ints):     print(idx, val)   Check out PEP 279 for more.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "668", "A_Content": "  If I'm understanding your situation correctly, what you're seeing is the result of how Python handles local (function) and global (module) namespaces.  Say you've got a module like this:  # sample.py myGlobal = 5  def func1():     myGlobal = 42  def func2():     print myGlobal  func1() func2()   You might expecting this to print 42, but instead it prints 5.  As has already been mentioned, if you add a 'global' declaration to func1(), then func2() will print 42.  def func1():     global myGlobal     myGlobal = 42   What's going on here is that Python assumes that any name that is assigned to, anywhere within a function, is local to that function unless explicitly told otherwise.  If it is only reading from a name, and the name doesn't exist locally, it will try to look up the name in any containing scopes (e.g. the module's global scope).  When you assign 42 to the name myGlobal, therefore, Python creates a local variable that shadows the global variable of the same name.  That local goes out of scope and is garbage-collected when func1() returns; meanwhile, func2() can never see anything other than the (unmodified) global name.  Note that this namespace decision happens at compile time, not at runtime -- if you were to read the value of myGlobal inside func1() before you assign to it, you'd get an UnboundLocalError, because Python has already decided that it must be a local variable but it has not had any value associated with it yet.  But by using the 'global' statement, you tell Python that it should look elsewhere for the name instead of assigning to it locally.  (I believe that this behavior originated largely through an optimization of local namespaces -- without this behavior,  Python's VM would need to perform at least three name lookups each time a new name is assigned to inside a function (to ensure that the name didn't already exist at module/builtin level), which would significantly slow down a very common operation.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "178", "A_Content": "  You may want to explore the notion of namespaces. In Python, the module is the natural place for global data:     Each module has its own private symbol table, which is used as the global symbol table by all functions defined in the module. Thus, the author of a module can use global variables in the module without worrying about accidental clashes with a user\u2019s global variables. On the other hand, if you know what you are doing you can touch a module\u2019s global variables with the same notation used to refer to its functions, modname.itemname.   A specific use of global-in-a-module is described here - how-do-i-share-global-variables-across-modules, and for completeness the contents are shared here:     The canonical way to share information across modules within a single program is to create a special configuration module (often called config or cfg). Just import the configuration module in all modules of your application; the module then becomes available as a global name. Because there is only one instance of each module, any changes made to the module object get reflected everywhere. For example:      File: config.py   x = 0   # Default value of the 'x' configuration setting      File: mod.py   import config config.x = 1      File: main.py   import config import mod print config.x      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "75", "A_Content": "  Python uses a simple heuristic to decide which scope it should load a variable from, between local and global.  If a variable name appears on the left hand side of an assignment, but is not declared global, it is assumed to be local.  If it does not appear on the left hand side of an assignment, it is assumed to be global.    >>> import dis >>> def foo(): ...     global bar ...     baz = 5 ...     print bar ...     print baz ...     print quux ...  >>> dis.disassemble(foo.func_code)   3           0 LOAD_CONST               1 (5)               3 STORE_FAST               0 (baz)    4           6 LOAD_GLOBAL              0 (bar)               9 PRINT_ITEM                        10 PRINT_NEWLINE           5          11 LOAD_FAST                0 (baz)              14 PRINT_ITEM                        15 PRINT_NEWLINE           6          16 LOAD_GLOBAL              1 (quux)              19 PRINT_ITEM                        20 PRINT_NEWLINE                     21 LOAD_CONST               0 (None)              24 RETURN_VALUE         >>>    See how baz, which appears on the left side of an assignment in foo(), is the only LOAD_FAST variable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "49", "A_Content": "  If you want to refer to a global variable in a function, you can use the global keyword to declare which variables are global. You don't have to use it in all cases (as someone here incorrectly claims) - if the name referenced in an expression cannot be found in local scope or scopes in the functions in which this function is defined, it is looked up among global variables.  However, if you assign to a new variable not declared as global in the function, it is implicitly declared as local, and it can overshadow any existing global variable with the same name.  Also, global variables are useful, contrary to some OOP zealots who claim otherwise - especially for smaller scripts, where OOP is overkill.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "36", "A_Content": "  In addition to already existing answers and to make this more confusing:     In Python, variables that are only referenced inside a function are   implicitly global. If a variable is assigned a new value anywhere   within the function\u2019s body, it\u2019s assumed to be a local. If a variable   is ever assigned a new value inside the function, the variable is   implicitly local, and you need to explicitly declare it as \u2018global\u2019.      Though a bit surprising at first, a moment\u2019s consideration explains   this. On one hand, requiring global for assigned variables provides a   bar against unintended side-effects. On the other hand, if global was   required for all global references, you\u2019d be using global all the   time. You\u2019d have to declare as global every reference to a built-in   function or to a component of an imported module. This clutter would   defeat the usefulness of the global declaration for identifying   side-effects.   Source: What are the rules for local and global variables in Python?.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "31", "A_Content": "     If I create a global variable in one function, how can I use that variable in another function?   We can create a global with the following function:  def create_global_variable():     global global_variable # must declare it to be a global first     # modifications are thus reflected on the module's global scope     global_variable = 'Foo'    Writing a function does not actually run its code. So we call the create_global_variable function:  >>> create_global_variable()   Using globals without modification  You can just use it, so long as you don't expect to change which object it points to:   For example,   def use_global_variable():     return global_variable + '!!!'   and now we can use the global variable:  >>> use_global_variable() 'Foo!!!'   Modification of the global variable from inside a function  To point the global variable at a different object, you are required to use the global keyword again:  def change_global_variable():     global global_variable     global_variable = 'Bar'   Note that after writing this function, the code actually changing it has still not run:  >>> use_global_variable() 'Foo!!!'   So after calling the function:  >>> change_global_variable()   we can see that the global variable has been changed. The global_variable name now points to 'Bar':  >>> use_global_variable() 'Bar!!!'   Note that \"global\" in Python is not truly global - it's only global to the module level. So it is only available to functions written in the modules in which it is global. Functions remember the module in which they are written, so when they are exported into other modules, they still look in the module in which they were created to find global variables.  Local variables with the same name  If you create a local variable with the same name, it will overshadow a global variable:  def use_local_with_same_name_as_global():     # bad name for a local variable, though.     global_variable = 'Baz'      return global_variable + '!!!'  >>> use_local_with_same_name_as_global() 'Baz!!!'   But using that misnamed local variable does not change the global variable:  >>> use_global_variable() 'Bar!!!'   Note that you should avoid using the local variables with the same names as globals unless you know precisely what you are doing and have a very good reason to do so. I have not yet encountered such a reason.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "28", "A_Content": "  With parallel execution, global variables can cause unexpected results if you don't understand what is happening. Here is an example of using a global variable within multiprocessing. We can clearly see that each process works with its own copy of the variable:  import multiprocessing import os import random import sys import time  def worker(new_value):     old_value = get_value()     set_value(random.randint(1, 99))     print('pid=[{pid}] '           'old_value=[{old_value:2}] '           'new_value=[{new_value:2}] '           'get_value=[{get_value:2}]'.format(           pid=str(os.getpid()),           old_value=old_value,           new_value=new_value,           get_value=get_value()))  def get_value():     global global_variable     return global_variable  def set_value(new_value):     global global_variable     global_variable = new_value  global_variable = -1  print('before set_value(), get_value() = [%s]' % get_value()) set_value(new_value=-2) print('after  set_value(), get_value() = [%s]' % get_value())  processPool = multiprocessing.Pool(processes=5) processPool.map(func=worker, iterable=range(15))   Output:  before set_value(), get_value() = [-1] after  set_value(), get_value() = [-2] pid=[53970] old_value=[-2] new_value=[ 0] get_value=[23] pid=[53971] old_value=[-2] new_value=[ 1] get_value=[42] pid=[53970] old_value=[23] new_value=[ 4] get_value=[50] pid=[53970] old_value=[50] new_value=[ 6] get_value=[14] pid=[53971] old_value=[42] new_value=[ 5] get_value=[31] pid=[53972] old_value=[-2] new_value=[ 2] get_value=[44] pid=[53973] old_value=[-2] new_value=[ 3] get_value=[94] pid=[53970] old_value=[14] new_value=[ 7] get_value=[21] pid=[53971] old_value=[31] new_value=[ 8] get_value=[34] pid=[53972] old_value=[44] new_value=[ 9] get_value=[59] pid=[53973] old_value=[94] new_value=[10] get_value=[87] pid=[53970] old_value=[21] new_value=[11] get_value=[21] pid=[53971] old_value=[34] new_value=[12] get_value=[82] pid=[53972] old_value=[59] new_value=[13] get_value=[ 4] pid=[53973] old_value=[87] new_value=[14] get_value=[70]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "19", "A_Content": "  You need to reference the global variable in every function you want to use.  As follows:  var = \"test\"  def printGlobalText():     global var #wWe are telling to explicitly use the global version     var = \"global from printGlobalText fun.\"     print \"var from printGlobalText: \" + var  def printLocalText():     #We are NOT telling to explicitly use the global version, so we are creating a local variable     var = \"local version from printLocalText fun\"     print \"var from printLocalText: \" + var  printGlobalText() printLocalText() \"\"\" Output Result: var from printGlobalText: global from printGlobalText fun. var from printLocalText: local version from printLocalText [Finished in 0.1s] \"\"\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "19", "A_Content": "  What you are saying is to use the method like this:  globvar = 5  def f():     var = globvar     print(var)  f()  # Prints 5   But the better way is to use the global variable like this:  globavar = 5 def f():     global globvar     print(globvar) f()   #prints 5   Both give the same output.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "17", "A_Content": "  You're not actually storing the global in a local variable, just creating a local reference to the same object that your original global reference refers to. Remember that pretty much everything in Python is a name referring to an object, and nothing gets copied in usual operation.  If you didn't have to explicitly specify when an identifier was to refer to a predefined global, then you'd presumably have to explicitly specify when an identifier is a new local variable instead (for example, with something like the 'var' command seen in JavaScript). Since local variables are more common than global variables in any serious and non-trivial system, Python's system makes more sense in most cases.  You could have a language which attempted to guess, using a global variable if it existed or creating a local variable if it didn't. However, that would be very error-prone. For example, importing another module could inadvertently introduce a global variable by that name, changing the behaviour of your program.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "16", "A_Content": "  As it turns out the answer is always simple.  Here is a small sample module. It is is a way to show it in a main definition:  def five(enterAnumber,sumation):     global helper     helper  = enterAnumber + sumation  def isTheNumber():     return helper   Here is a way to show it in a main definition:  import TestPy  def main():     atest  = TestPy     atest.five(5,8)     print(atest.isTheNumber())  if __name__ == '__main__':     main()   This simple code works just like that, and it will execute. I hope it helps.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "14", "A_Content": "  Try this:  def x1():     global x     x = 6  def x2():     global x     x = x+1     print x  x = 5 x1() x2()  # output --> 7      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "11", "A_Content": "  Following on and as an add on, use a file to contain all global variables all declared locally and then 'import as':  File initval.py  Stocksin = 300 Prices = []   File getstocks.py  import  initval as  iv  Def   getmystocks ():       iv.Stocksin  = getstockcount ()   Def getmycharts ():     For ic in range (0,iv.Stocksin):   .....     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "528", "A_Content": "     Using a for loop, how do I access the loop index, from 1 to 5 in this case?   Use enumerate to get the index with the element as you iterate:  for index, item in enumerate(items):     print(index, item)   And note that Python's indexes start at zero, so you would get 0 to 4 with the above. If you want the count, 1 to 5, do this:  for count, item in enumerate(items, start=1):     print(count, item)   Unidiomatic control flow  What you are asking for is the Pythonic equivalent of the following, which is the algorithm most programmers of lower-level languages would use:   index = 0            # Python's indexing starts at zero for item in items:   # Python's for loops are a \"for each\" loop      print(index, item)     index += 1    Or in languages that do not have a for-each loop:   index = 0 while index < len(items):     print(index, items[index])     index += 1    or sometimes more commonly (but unidiomatically) found in Python:   for index in range(len(items)):     print(index, items[index])    Use the Enumerate Function  Python's enumerate function reduces the visual clutter by hiding the accounting for the indexes, and encapsulating the iterable into another iterable (an enumerate object) that yields a two-item tuple of the index and the item that the original iterable would provide. That looks like this:  for index, item in enumerate(items, start=0):   # default is zero     print(index, item)   This code sample is fairly well the canonical example of the difference between code that is idiomatic of Python and code that is not. Idiomatic code is sophisticated (but not complicated) Python, written in the way that it was intended to be used. Idiomatic code is expected by the designers of the language, which means that usually this code is not just more readable, but also more efficient.  Getting a count  Even if you don't need indexes as you go, but you need a count of the iterations (sometimes desirable) you can start with 1 and the final number will be your count.  for count, item in enumerate(items, start=1):   # default is zero     print(item)  print('there were {0} items printed'.format(count))   The count seems to be more what you intend to ask for (as opposed to index) when you said you wanted from 1 to 5.    Breaking it down - a step by step explanation  To break these examples down, say we have a list of items that we want to iterate over with an index:  items = ['a', 'b', 'c', 'd', 'e']   Now we pass this iterable to enumerate, creating an enumerate object:  enumerate_object = enumerate(items) # the enumerate object   We can pull the first item out of this iterable that we would get in a loop with the next function:  iteration = next(enumerate_object) # first iteration from enumerate print(iteration)   And we see we get a tuple of 0, the first index, and 'a', the first item:  (0, 'a')   we can use what is referred to as \"sequence unpacking\" to extract the elements from this two-tuple:  index, item = iteration #   0,  'a' = (0, 'a') # essentially this.   and when we inspect index, we find it refers to the first index, 0, and item refers to the first item, 'a'.  >>> print(index) 0 >>> print(item) a   Conclusion   Python indexes start at zero To get these indexes from an iterable as you iterate over it, use the enumerate function Using enumerate in the idiomatic way (along with tuple unpacking) creates code that is more readable and maintainable:   So do this:  for index, item in enumerate(items, start=0):   # Python indexes start at zero     print(index, item)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "105", "A_Content": "  It's pretty simple to start it from 1 other than 0:  for index, item in enumerate(iterable, start=1):    print index, item   Note  Important hint, though a little misleading since index will be a tuple (idx, item) here. Good to go.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "68", "A_Content": "  for i in range(len(ints)):    print i, ints[i]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "36", "A_Content": "  As is the norm in Python there are several ways to do this. In all examples assume: lst = [1, 2, 3, 4, 5]  1. Using enumerate (considered most idiomatic)  for index, element in enumerate(lst):     # do the things that need doing here   This is also the safest option in my opinion because the chance of going into infinite recursion has been eliminated. Both the item and its index are held in variables and there is no need to write any further code to access the item.  2. Creating a variable to hold the index (using for)  for index in range(len(lst)):   # or xrange     # you will have to write extra code to get the element   3. Creating a variable to hold the index (using while)  index = 0 while index < len(lst):     # you will have to write extra code to get the element     index += 1  # escape infinite recursion   4. There is always another way  As explained before, there are other ways to do this that have not been explained here and they may even apply more in other situations. e.g using itertools.chain with for. It handles nested loops better than the other examples.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "21", "A_Content": "  Old fashioned way:  for ix in range(len(ints)):     print ints[ix]   List comprehension:  [ (ix, ints[ix]) for ix in range(len(ints))]  >>> ints [1, 2, 3, 4, 5] >>> for ix in range(len(ints)): print ints[ix] ...  1 2 3 4 5 >>> [ (ix, ints[ix]) for ix in range(len(ints))] [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)] >>> lc = [ (ix, ints[ix]) for ix in range(len(ints))] >>> for tup in lc: ...     print tup ...  (0, 1) (1, 2) (2, 3) (3, 4) (4, 5) >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "16", "A_Content": "  The fastest way to access indexes of list within loop in Python 2.7 is to use the range method for small lists and enumerate method for medium and huge size lists.  Please see different approaches which can be used to iterate over list and access index value and their performance metrics (which I suppose would be useful for you) in code samples below:  from timeit import timeit  # Using range def range_loop(iterable):     for i in range(len(iterable)):         1 + iterable[i]  # Using xrange def xrange_loop(iterable):     for i in xrange(len(iterable)):         1 + iterable[i]  # Using enumerate def enumerate_loop(iterable):     for i, val in enumerate(iterable):         1 + val  # Manual indexing def manual_indexing_loop(iterable):     index = 0     for item in iterable:         1 + item         index += 1   See performance metrics for each method below:  from timeit import timeit  def measure(l, number=10000): print \"Measure speed for list with %d items\" % len(l) print \"xrange: \", timeit(lambda :xrange_loop(l), number=number) print \"range: \", timeit(lambda :range_loop(l), number=number) print \"enumerate: \", timeit(lambda :enumerate_loop(l), number=number) print \"manual_indexing: \", timeit(lambda :manual_indexing_loop(l), number=number)  measure(range(1000)) # Measure speed for list with 1000 items # xrange:  0.758321046829 # range:  0.701184988022 # enumerate:  0.724966049194 # manual_indexing:  0.894635915756  measure(range(10000)) # Measure speed for list with 100000 items # xrange:  81.4756360054 # range:  75.0172479153 # enumerate:  74.687623024 # manual_indexing:  91.6308541298  measure(range(10000000), number=100) # Measure speed for list with 10000000 items # xrange:  82.267786026 # range:  84.0493988991 # enumerate:  78.0344707966 # manual_indexing:  95.0491430759   As the result, using range method is the fastest one up to list with 1000 items. For list with size > 10 000 items enumerate is the winner.  Adding some useful links below:   What is the difference between range and xrange functions in Python 2.X? What is faster for loop using enumerate or for loop using xrange in Python? range(len(list)) or enumerate(list)?      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "16", "A_Content": "  I don't know if the following is pythonic or not, but it uses the Python function enumerate and prints the index and the value.  int_list = [8, 23, 45, 12, 78] for index, value in enumerate(int_list):    print(index, value)   Output:  0 8 1 23 2 45 3 12 4 78      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "15", "A_Content": "  ints = [9, 23, 45, 12, 78] ints.extend([1,2,3,4,5,6,7,8]) for idx, val in enumerate(ints):     print(idx,val)   This way you can extend a list. Extend means you can add multiple values at a time.  To append this list you have to write the code given below:  ints = [9, 23, 45, 12, 78] ints.append([1]) for idx, val in enumerate(ints):     print(idx,val)   This way you can add a single value at a time. If you write ints.append([1]) so this will create a sub list for this element.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "11", "A_Content": "  First of all, the indexes will be from 0 to 4. Programming languages start counting from 0; don't forget that or you will come across an index out of bounds exception. All you need in the for loop is a variable counting from 0 to 4 like so:  for x in range(0, 5):   Keep in mind that I wrote 0 to 5 because the loop stops one number before the max. :)  To get the value of an index use  list[index]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "9", "A_Content": "  According to this discussion: http://bytes.com/topic/python/answers/464012-objects-list-index  Loop counter iteration  The current idiom for looping over the indices makes use of the built-in 'range' function:  for i in range(len(sequence)):     # work with index i   Looping over both elements and indices can be achieved either by the old idiom or by using the new 'zip' built-in function[2]:  for i in range(len(sequence)):     e = sequence[i]     # work with index i and element e   or  for i, e in zip(range(len(sequence)), sequence):     # work with index i and element e   via http://www.python.org/dev/peps/pep-0212/     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "9", "A_Content": "  You can do it with this code:  ints = [8, 23, 45, 12, 78] index = 0  for value in (ints):     index +=1     print index, value   Use this code if you need to reset the index value at the end of the loop:  ints = [8, 23, 45, 12, 78] index = 0  for value in (ints):     index +=1     print index, value     if index >= len(ints)-1:         index = 0      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "8", "A_Content": "  Best solution for this problem is use enumerate in-build python function.  enumerate return tuple  first value is index  second value is element of array at that index  In [1]: ints = [8, 23, 45, 12, 78]  In [2]: for idx, val in enumerate(ints):    ...:         print(idx, val)    ...:      (0, 8) (1, 23) (2, 45) (3, 12) (4, 78)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "3", "A_Content": "  You can also try this:  data = ['itemA.ABC', 'itemB.defg', 'itemC.drug', 'itemD.ashok'] x = [] for (i, item) in enumerate(data):       a = (i, str(item).split('.'))       x.append(a) for index, value in x:      print(index, value)   The output is   0 ['itemA', 'ABC'] 1 ['itemB', 'defg'] 2 ['itemC', 'drug'] 3 ['itemD', 'ashok']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "1", "A_Content": "  You can use the index method  ints = [8, 23, 45, 12, 78] inds = [ints.index(i) for i in ints]   EDIT Highlighted in the comment that this method doesn\u2019t work if there are duplicates in ints, the method below should work for any values in ints:  ints = [8, 8, 8, 23, 45, 12, 78] inds = [tup[0] for tup in enumerate(ints)]   Or alternatively  ints = [8, 8, 8, 23, 45, 12, 78] inds = [tup for tup in enumerate(ints)]   if you want to get both the index and the value in ints as a list of tuples.  It uses the method of enumerate in the selected answer to this question, but with list comprehension, making it faster with less code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "1", "A_Content": "  If I were to iterate nums = [1,2,3,4,5] I would do  for i, num in enumerate(nums, start = 1):     print(i, num)   Or get the length as l = len(nums)  for i, num in range(1, l + 1):     print(i, nums[i])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "9", "A_Content": "  Writing to explicit elements of a global array does not apparently need the global declaration, though writing to it \"wholesale\" does have that requirement:  import numpy as np  hostValue = 3.14159 hostArray = np.array([2., 3.]) hostMatrix = np.array([[1.0, 0.0],[ 0.0, 1.0]])  def func1():     global hostValue    # mandatory, else local.     hostValue = 2.0  def func2():     global hostValue    # mandatory, else UnboundLocalError.     hostValue += 1.0  def func3():     global hostArray    # mandatory, else local.     hostArray = np.array([14., 15.])  def func4():            # no need for globals     hostArray[0] = 123.4  def func5():            # no need for globals     hostArray[1] += 1.0  def func6():            # no need for globals     hostMatrix[1][1] = 12.  def func7():            # no need for globals     hostMatrix[0][0] += 0.33  func1() print \"After func1(), hostValue = \", hostValue func2() print \"After func2(), hostValue = \", hostValue func3() print \"After func3(), hostArray = \", hostArray func4() print \"After func4(), hostArray = \", hostArray func5() print \"After func5(), hostArray = \", hostArray func6() print \"After func6(), hostMatrix = \\n\", hostMatrix func7() print \"After func7(), hostMatrix = \\n\", hostMatrix      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "8", "A_Content": "  In case you have a local variable with the same name, you might want to use the globals() function.  globals()['your_global_var'] = 42      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "4", "A_Content": "  Reference the class namespace where you want the change to show up.    In this example, runner is using max from the file config. I want my test to change the value of max when runner is using it.  main/config.py  max = 15000   main/runner.py  from main import config def check_threads():     return max < thread_count    tests/runner_test.py  from main import runner                # <----- 1. add file from main.runner import check_threads class RunnerTest(unittest):    def test_threads(self):        runner.max = 0                  # <----- 2. set global         check_threads()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/423379/using-global-variables-in-a-function", "Language": "Python", "Q_Title": "Using global variables in a function", "Q_Votes": "2516", "Q_Content": "    How can I create or use a global variable in a function?  If I create a global variable in one function, how can I use that global variable in another function? Do I need to store the global variable in a local variable of the function which needs its access?     ", "Tags": ["python", "global-variables", "scope"], "A_Votes": "4", "A_Content": "  I'm adding this as I haven't seen it in any of the other answers and it might be useful for someone struggling with something similar. The globals() function returns a mutable global symbol dictionary where you can \"magically\" make data available for the rest of your code.  For example:  from pickle import load def loaditem(name):     with open(r\"C:\\pickle\\file\\location\"+\"\\{}.dat\".format(name), \"rb\") as openfile:         globals()[name] = load(openfile)     return True   and   from pickle import dump def dumpfile(name):     with open(name+\".dat\", \"wb\") as outfile:         dump(globals()[name], outfile)     return True   Will just let you dump/load variables out of and into the global namespace. Super convenient, no muss, no fuss. Pretty sure it's python 3 only.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "2674", "A_Content": "  Check out the documentation to see how decorators work. Here is what you asked for:  def makebold(fn):     def wrapped():         return \"<b>\" + fn() + \"</b>\"     return wrapped  def makeitalic(fn):     def wrapped():         return \"<i>\" + fn() + \"</i>\"     return wrapped  @makebold @makeitalic def hello():     return \"hello world\"  print hello() ## returns \"<b><i>hello world</i></b>\"      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "1", "A_Content": "  If there is no duplicate value in list:  for i in ints:         indx=ints.index(i)         print(i,indx)   Instead use enumerate.   for counter, value in enumerate(ints):     print(counter, value)   OR use below:  for counter in range(len(ints)):     print(counter,ints[counter])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "0", "A_Content": "  You've received a number of answers explaining enumerate, but if you only need the index for accessing matching entries in two lists, there's another way that's cleaner and simpler in Python 3: zip.  For example, if you're using the index to pull out corresponding names for the numbers in your list, you could do it like this:  ints = [8, 23, 45, 12, 78] names = [\"John\", \"Sue\", \"Johannes\", \"Patel\", \"Ian\"] for int, name = zip(ints, names):     print(\"{} - {}\".format(name, int)   That would produce  8 - John 23 - Sue 45 - Johannes 12 - Patel 78 - Ian      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "0", "A_Content": "  In you question, you write \"how do I access the loop index, from 1 to 5 in this case?\"  However, the index for a list, runs from zero.  So, then we need to known if what you actually want is the index and item for each item in a list, or whether you really want numbers starting from 1.  Fortunately, in python it is easy to do either or both.  First, to clarify, the enumerate function, iteratively returns the index and corresponding item for each item in a list.  alist = [ 1, 2, 3, 4, 5 ]  for n,a in enumerate(alist):     print( \"%d %d\"%(n,a) )   The output for the above is then,  0 1 1 2 2 3 3 4 4 5   Notice that the index runs from 0.  This kind of indexing is common among modern programming languages including python and c.  If you want your loop to span a part of the list, you can use the standard python syntax for a part of the list. For example, to loop from the second item in a list up to but not including the last item, you could use  for n,a in enumerate(alist[1:-1]):     print( \"%d %d\"%(n,a) )   Note that once again, the output index runs from 0,  0 2 1 3 2 4   That brings us to the start=n switch for enumerate().  This simply offsets the index, you can equivalently simply add a number to the index inside the loop.  for n,a in enumerate(alist,start=1):     print( \"%d %d\"%(n,a) )   for which the output is  1 1 2 2 3 3 4 4 5 5      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "-1", "A_Content": "  To print tuple of (index, value) in list comprehension using a for loop:  ints = [8, 23, 45, 12, 78] print [(i,ints[i]) for i in range(len(ints))]   Output:  [(0, 8), (1, 23), (2, 45), (3, 12), (4, 78)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/522563/accessing-the-index-in-for-loops", "Language": "Python", "Q_Title": "Accessing the index in 'for' loops?", "Q_Votes": "2622", "Q_Content": "    How do I access the index itself for a list like the following?  ints = [8, 23, 45, 12, 78]   When I loop through it using a for loop, how do I access the loop index, from 1 to 5 in this case?     ", "Tags": ["python", "loops", "list"], "A_Votes": "-1", "A_Content": "  This serves the purpose well enough:  list1 = [10, 'sumit', 43.21, 'kumar', '43', 'test', 3] for x in list1:     print('index:', list1.index(x), 'value:', x)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "3843", "A_Content": "  If you are not into long explanations, see Paolo Bergantino\u2019s answer.  Decorator Basics  Python\u2019s functions are objects  To understand decorators, you must first understand that functions are objects in Python. This has important consequences. Let\u2019s see why with a simple example :  def shout(word=\"yes\"):     return word.capitalize()+\"!\"  print(shout()) # outputs : 'Yes!'  # As an object, you can assign the function to a variable like any other object  scream = shout  # Notice we don't use parentheses: we are not calling the function, # we are putting the function \"shout\" into the variable \"scream\". # It means you can then call \"shout\" from \"scream\":  print(scream()) # outputs : 'Yes!'  # More than that, it means you can remove the old name 'shout', #\u00a0and the function will still be accessible from 'scream'  del shout try:     print(shout()) except NameError, e:     print(e)     #outputs: \"name 'shout' is not defined\"  print(scream()) # outputs: 'Yes!'   Keep this in mind. We\u2019ll circle back to it shortly.   Another interesting property of Python functions is they can be defined inside another function!  def talk():      # You can define a function on the fly in \"talk\" ...     def whisper(word=\"yes\"):         return word.lower()+\"...\"      # ... and use it right away!     print(whisper())  # You call \"talk\", that defines \"whisper\" EVERY TIME you call it, then # \"whisper\" is called in \"talk\".  talk() # outputs:  # \"yes...\"  # But \"whisper\" DOES NOT EXIST outside \"talk\":  try:     print(whisper()) except NameError, e:     print(e)     #outputs : \"name 'whisper' is not defined\"*     #Python's functions are objects   Functions references  Okay, still here? Now the fun part...  You\u2019ve seen that functions are objects. Therefore, functions:   can be assigned to a variable can be defined in another function   That means that a function can return another function.  def getTalk(kind=\"shout\"):      # We define functions on the fly     def shout(word=\"yes\"):         return word.capitalize()+\"!\"      def whisper(word=\"yes\") :         return word.lower()+\"...\";      # Then we return one of them     if kind == \"shout\":         # We don't use \"()\", we are not calling the function,         # we are returning the function object         return shout       else:         return whisper  # How do you use this strange beast?  # Get the function and assign it to a variable talk = getTalk()        # You can see that \"talk\" is here a function object: print(talk) #outputs : <function shout at 0xb7ea817c>  # The object is the one returned by the function: print(talk()) #outputs : Yes!  # And you can even use it directly if you feel wild: print(getTalk(\"whisper\")()) #outputs : yes...   There\u2019s more!   If you can return a function, you can pass one as a parameter:  def doSomethingBefore(func):      print(\"I do something before then I call the function you gave me\")     print(func())  doSomethingBefore(scream) #outputs:  #I do something before then I call the function you gave me #Yes!   Well, you just have everything needed to understand decorators. You see, decorators are \u201cwrappers\u201d, which means that they let you execute code before and after the function they decorate without modifying the function itself.  Handcrafted decorators  How you\u2019d do it manually:  # A decorator is a function that expects ANOTHER function as parameter def my_shiny_new_decorator(a_function_to_decorate):      # Inside, the decorator defines a function on the fly: the wrapper.     # This function is going to be wrapped around the original function     # so it can execute code before and after it.     def the_wrapper_around_the_original_function():          # Put here the code you want to be executed BEFORE the original function is called         print(\"Before the function runs\")          # Call the function here (using parentheses)         a_function_to_decorate()          # Put here the code you want to be executed AFTER the original function is called         print(\"After the function runs\")      # At this point, \"a_function_to_decorate\" HAS NEVER BEEN EXECUTED.     # We return the wrapper function we have just created.     # The wrapper contains the function and the code to execute before and after. It\u2019s ready to use!     return the_wrapper_around_the_original_function  # Now imagine you create a function you don't want to ever touch again. def a_stand_alone_function():     print(\"I am a stand alone function, don't you dare modify me\")  a_stand_alone_function()  #outputs: I am a stand alone function, don't you dare modify me  # Well, you can decorate it to extend its behavior. # Just pass it to the decorator, it will wrap it dynamically in  # any code you want and return you a new function ready to be used:  a_stand_alone_function_decorated = my_shiny_new_decorator(a_stand_alone_function) a_stand_alone_function_decorated() #outputs: #Before the function runs #I am a stand alone function, don't you dare modify me #After the function runs   Now, you probably want that every time you call a_stand_alone_function, a_stand_alone_function_decorated is called instead. That\u2019s easy, just overwrite a_stand_alone_function with the function returned by my_shiny_new_decorator:  a_stand_alone_function = my_shiny_new_decorator(a_stand_alone_function) a_stand_alone_function() #outputs: #Before the function runs #I am a stand alone function, don't you dare modify me #After the function runs  # That\u2019s EXACTLY what decorators do!   Decorators demystified  The previous example, using the decorator syntax:  @my_shiny_new_decorator def another_stand_alone_function():     print(\"Leave me alone\")  another_stand_alone_function()   #outputs:   #Before the function runs #Leave me alone #After the function runs   Yes, that\u2019s all, it\u2019s that simple. @decorator is just a shortcut to:  another_stand_alone_function = my_shiny_new_decorator(another_stand_alone_function)   Decorators are just a pythonic variant of the decorator design pattern. There are several classic design patterns embedded in Python to ease development (like iterators).  Of course, you can accumulate decorators:  def bread(func):     def wrapper():         print(\"</''''''\\>\")         func()         print(\"<\\______/>\")     return wrapper  def ingredients(func):     def wrapper():         print(\"#tomatoes#\")         func()         print(\"~salad~\")     return wrapper  def sandwich(food=\"--ham--\"):     print(food)  sandwich() #outputs: --ham-- sandwich = bread(ingredients(sandwich)) sandwich() #outputs: #</''''''\\> # #tomatoes# # --ham-- # ~salad~ #<\\______/>   Using the Python decorator syntax:  @bread @ingredients def sandwich(food=\"--ham--\"):     print(food)  sandwich() #outputs: #</''''''\\> # #tomatoes# # --ham-- # ~salad~ #<\\______/>   The order you set the decorators MATTERS:  @ingredients @bread def strange_sandwich(food=\"--ham--\"):     print(food)  strange_sandwich() #outputs: ##tomatoes# #</''''''\\> # --ham-- #<\\______/> # ~salad~     Now: to answer the question...  As a conclusion, you can easily see how to answer the question:  # The decorator to make it bold def makebold(fn):     # The new function the decorator returns     def wrapper():         # Insertion of some code before and after         return \"<b>\" + fn() + \"</b>\"     return wrapper  # The decorator to make it italic def makeitalic(fn):     # The new function the decorator returns     def wrapper():         # Insertion of some code before and after         return \"<i>\" + fn() + \"</i>\"     return wrapper  @makebold @makeitalic def say():     return \"hello\"  print(say()) #outputs: <b><i>hello</i></b>  # This is the exact equivalent to  def say():     return \"hello\" say = makebold(makeitalic(say))  print(say()) #outputs: <b><i>hello</i></b>   You can now just leave happy, or burn your brain a little bit more and see advanced uses of decorators.    Taking decorators to the next level  Passing arguments to the decorated function  # It\u2019s not black magic, you just have to let the wrapper  # pass the argument:  def a_decorator_passing_arguments(function_to_decorate):     def a_wrapper_accepting_arguments(arg1, arg2):         print(\"I got args! Look: {0}, {1}\".format(arg1, arg2))         function_to_decorate(arg1, arg2)     return a_wrapper_accepting_arguments  # Since when you are calling the function returned by the decorator, you are # calling the wrapper, passing arguments to the wrapper will let it pass them to  # the decorated function  @a_decorator_passing_arguments def print_full_name(first_name, last_name):     print(\"My name is {0} {1}\".format(first_name, last_name))  print_full_name(\"Peter\", \"Venkman\") # outputs: #I got args! Look: Peter Venkman #My name is Peter Venkman   Decorating methods  One nifty thing about Python is that methods and functions are really the same.  The only difference is that methods expect that their first argument is a reference to the current object (self).   That means you can build a decorator for methods the same way! Just remember to take self into consideration:  def method_friendly_decorator(method_to_decorate):     def wrapper(self, lie):         lie = lie - 3 # very friendly, decrease age even more :-)         return method_to_decorate(self, lie)     return wrapper   class Lucy(object):      def __init__(self):         self.age = 32      @method_friendly_decorator     def sayYourAge(self, lie):         print(\"I am {0}, what did you think?\".format(self.age + lie))  l = Lucy() l.sayYourAge(-3) #outputs: I am 26, what did you think?   If you\u2019re making general-purpose decorator--one you\u2019ll apply to any function or method, no matter its arguments--then just use *args, **kwargs:  def a_decorator_passing_arbitrary_arguments(function_to_decorate):     # The wrapper accepts any arguments     def a_wrapper_accepting_arbitrary_arguments(*args, **kwargs):         print(\"Do I have args?:\")         print(args)         print(kwargs)         # Then you unpack the arguments, here *args, **kwargs         # If you are not familiar with unpacking, check:         # http://www.saltycrane.com/blog/2008/01/how-to-use-args-and-kwargs-in-python/         function_to_decorate(*args, **kwargs)     return a_wrapper_accepting_arbitrary_arguments  @a_decorator_passing_arbitrary_arguments def function_with_no_argument():     print(\"Python is cool, no argument here.\")  function_with_no_argument() #outputs #Do I have args?: #() #{} #Python is cool, no argument here.  @a_decorator_passing_arbitrary_arguments def function_with_arguments(a, b, c):     print(a, b, c)  function_with_arguments(1,2,3) #outputs #Do I have args?: #(1, 2, 3) #{} #1 2 3   @a_decorator_passing_arbitrary_arguments def function_with_named_arguments(a, b, c, platypus=\"Why not ?\"):     print(\"Do {0}, {1} and {2} like platypus? {3}\".format(a, b, c, platypus))  function_with_named_arguments(\"Bill\", \"Linus\", \"Steve\", platypus=\"Indeed!\") #outputs #Do I have args ? : #('Bill', 'Linus', 'Steve') #{'platypus': 'Indeed!'} #Do Bill, Linus and Steve like platypus? Indeed!  class Mary(object):      def __init__(self):         self.age = 31      @a_decorator_passing_arbitrary_arguments     def sayYourAge(self, lie=-3): # You can now add a default value         print(\"I am {0}, what did you think?\".format(self.age + lie))  m = Mary() m.sayYourAge() #outputs # Do I have args?: #(<__main__.Mary object at 0xb7d303ac>,) #{} #I am 28, what did you think?   Passing arguments to the decorator  Great, now what would you say about passing arguments to the decorator itself?   This can get somewhat twisted, since a decorator must accept a function as an argument. Therefore, you cannot pass the decorated function\u2019s arguments directly to the decorator.  Before rushing to the solution, let\u2019s write a little reminder:   # Decorators are ORDINARY functions def my_decorator(func):     print(\"I am an ordinary function\")     def wrapper():         print(\"I am function returned by the decorator\")         func()     return wrapper  # Therefore, you can call it without any \"@\"  def lazy_function():     print(\"zzzzzzzz\")  decorated_function = my_decorator(lazy_function) #outputs: I am an ordinary function  # It outputs \"I am an ordinary function\", because that\u2019s just what you do: # calling a function. Nothing magic.  @my_decorator def lazy_function():     print(\"zzzzzzzz\")  #outputs: I am an ordinary function   It\u2019s exactly the same. \"my_decorator\" is called. So when you @my_decorator, you are telling Python to call the function 'labelled by the variable \"my_decorator\"'.   This is important! The label you give can point directly to the decorator\u2014or not.   Let\u2019s get evil. \u263a  def decorator_maker():      print(\"I make decorators! I am executed only once: \"           \"when you make me create a decorator.\")      def my_decorator(func):          print(\"I am a decorator! I am executed only when you decorate a function.\")          def wrapped():             print(\"I am the wrapper around the decorated function. \"                   \"I am called when you call the decorated function. \"                   \"As the wrapper, I return the RESULT of the decorated function.\")             return func()          print(\"As the decorator, I return the wrapped function.\")          return wrapped      print(\"As a decorator maker, I return a decorator\")     return my_decorator  # Let\u2019s create a decorator. It\u2019s just a new function after all. new_decorator = decorator_maker()        #outputs: #I make decorators! I am executed only once: when you make me create a decorator. #As a decorator maker, I return a decorator  # Then we decorate the function  def decorated_function():     print(\"I am the decorated function.\")  decorated_function = new_decorator(decorated_function) #outputs: #I am a decorator! I am executed only when you decorate a function. #As the decorator, I return the wrapped function  # Let\u2019s call the function: decorated_function() #outputs: #I am the wrapper around the decorated function. I am called when you call the decorated function. #As the wrapper, I return the RESULT of the decorated function. #I am the decorated function.   No surprise here.   Let\u2019s do EXACTLY the same thing, but skip all the pesky intermediate variables:  def decorated_function():     print(\"I am the decorated function.\") decorated_function = decorator_maker()(decorated_function) #outputs: #I make decorators! I am executed only once: when you make me create a decorator. #As a decorator maker, I return a decorator #I am a decorator! I am executed only when you decorate a function. #As the decorator, I return the wrapped function.  # Finally: decorated_function()     #outputs: #I am the wrapper around the decorated function. I am called when you call the decorated function. #As the wrapper, I return the RESULT of the decorated function. #I am the decorated function.   Let\u2019s make it even shorter:  @decorator_maker() def decorated_function():     print(\"I am the decorated function.\") #outputs: #I make decorators! I am executed only once: when you make me create a decorator. #As a decorator maker, I return a decorator #I am a decorator! I am executed only when you decorate a function. #As the decorator, I return the wrapped function.  #Eventually:  decorated_function()     #outputs: #I am the wrapper around the decorated function. I am called when you call the decorated function. #As the wrapper, I return the RESULT of the decorated function. #I am the decorated function.   Hey, did you see that? We used a function call with the \"@\" syntax! :-)  So, back to decorators with arguments. If we can use functions to generate the decorator on the fly, we can pass arguments to that function, right?  def decorator_maker_with_arguments(decorator_arg1, decorator_arg2):      print(\"I make decorators! And I accept arguments: {0}, {1}\".format(decorator_arg1, decorator_arg2))      def my_decorator(func):         # The ability to pass arguments here is a gift from closures.         # If you are not comfortable with closures, you can assume it\u2019s ok,         # or read: https://stackoverflow.com/questions/13857/can-you-explain-closures-as-they-relate-to-python         print(\"I am the decorator. Somehow you passed me arguments: {0}, {1}\".format(decorator_arg1, decorator_arg2))          # Don't confuse decorator arguments and function arguments!         def wrapped(function_arg1, function_arg2) :             print(\"I am the wrapper around the decorated function.\\n\"                   \"I can access all the variables\\n\"                   \"\\t- from the decorator: {0} {1}\\n\"                   \"\\t- from the function call: {2} {3}\\n\"                   \"Then I can pass them to the decorated function\"                   .format(decorator_arg1, decorator_arg2,                           function_arg1, function_arg2))             return func(function_arg1, function_arg2)          return wrapped      return my_decorator  @decorator_maker_with_arguments(\"Leonard\", \"Sheldon\") def decorated_function_with_arguments(function_arg1, function_arg2):     print(\"I am the decorated function and only knows about my arguments: {0}\"            \" {1}\".format(function_arg1, function_arg2))  decorated_function_with_arguments(\"Rajesh\", \"Howard\") #outputs: #I make decorators! And I accept arguments: Leonard Sheldon #I am the decorator. Somehow you passed me arguments: Leonard Sheldon #I am the wrapper around the decorated function.  #I can access all the variables  #   - from the decorator: Leonard Sheldon  #   - from the function call: Rajesh Howard  #Then I can pass them to the decorated function #I am the decorated function and only knows about my arguments: Rajesh Howard   Here it is: a decorator with arguments. Arguments can be set as variable:  c1 = \"Penny\" c2 = \"Leslie\"  @decorator_maker_with_arguments(\"Leonard\", c1) def decorated_function_with_arguments(function_arg1, function_arg2):     print(\"I am the decorated function and only knows about my arguments:\"            \" {0} {1}\".format(function_arg1, function_arg2))  decorated_function_with_arguments(c2, \"Howard\") #outputs: #I make decorators! And I accept arguments: Leonard Penny #I am the decorator. Somehow you passed me arguments: Leonard Penny #I am the wrapper around the decorated function.  #I can access all the variables  #   - from the decorator: Leonard Penny  #   - from the function call: Leslie Howard  #Then I can pass them to the decorated function #I am the decorated function and only know about my arguments: Leslie Howard   As you can see, you can pass arguments to the decorator like any function using this trick. You can even use *args, **kwargs if you wish. But remember decorators are called only once. Just when Python imports the script. You can't dynamically set the arguments afterwards. When you do \"import x\", the function is already decorated, so you can't change anything.    Let\u2019s practice: decorating a decorator  Okay, as a bonus, I'll give you a snippet to make any decorator accept generically any argument. After all, in order to accept arguments, we created our decorator using another function.   We wrapped the decorator.  Anything else we saw recently that wrapped function?  Oh yes, decorators!  Let\u2019s have some fun and write a decorator for the decorators:  def decorator_with_args(decorator_to_enhance):     \"\"\"      This function is supposed to be used as a decorator.     It must decorate an other function, that is intended to be used as a decorator.     Take a cup of coffee.     It will allow any decorator to accept an arbitrary number of arguments,     saving you the headache to remember how to do that every time.     \"\"\"      # We use the same trick we did to pass arguments     def decorator_maker(*args, **kwargs):          # We create on the fly a decorator that accepts only a function         # but keeps the passed arguments from the maker.         def decorator_wrapper(func):              # We return the result of the original decorator, which, after all,              # IS JUST AN ORDINARY FUNCTION (which returns a function).             # Only pitfall: the decorator must have this specific signature or it won't work:             return decorator_to_enhance(func, *args, **kwargs)          return decorator_wrapper      return decorator_maker   It can be used as follows:  # You create the function you will use as a decorator. And stick a decorator on it :-) # Don't forget, the signature is \"decorator(func, *args, **kwargs)\" @decorator_with_args  def decorated_decorator(func, *args, **kwargs):      def wrapper(function_arg1, function_arg2):         print(\"Decorated with {0} {1}\".format(args, kwargs))         return func(function_arg1, function_arg2)     return wrapper  # Then you decorate the functions you wish with your brand new decorated decorator.  @decorated_decorator(42, 404, 1024) def decorated_function(function_arg1, function_arg2):     print(\"Hello {0} {1}\".format(function_arg1, function_arg2))  decorated_function(\"Universe and\", \"everything\") #outputs: #Decorated with (42, 404, 1024) {} #Hello Universe and everything  # Whoooot!   I know, the last time you had this feeling, it was after listening a guy saying: \"before understanding recursion, you must first understand recursion\". But now, don't you feel good about mastering this?    Best practices: decorators   Decorators were introduced in Python 2.4, so be sure your code will be run on >= 2.4.  Decorators slow down the function call. Keep that in mind. You cannot un-decorate a function. (There are hacks to create decorators that can be removed, but nobody uses them.) So once a function is decorated, it\u2019s decorated for all the code. Decorators wrap functions, which can make them hard to debug.  (This gets better from Python >= 2.5; see below.)   The functools module was introduced in Python 2.5. It includes the function functools.wraps(), which copies the name, module, and docstring of the decorated function to its wrapper.   (Fun fact: functools.wraps() is a decorator! \u263a)  # For debugging, the stacktrace prints you the function __name__ def foo():     print(\"foo\")  print(foo.__name__) #outputs: foo  # With a decorator, it gets messy     def bar(func):     def wrapper():         print(\"bar\")         return func()     return wrapper  @bar def foo():     print(\"foo\")  print(foo.__name__) #outputs: wrapper  # \"functools\" can help for that  import functools  def bar(func):     # We say that \"wrapper\", is wrapping \"func\"     # and the magic begins     @functools.wraps(func)     def wrapper():         print(\"bar\")         return func()     return wrapper  @bar def foo():     print(\"foo\")  print(foo.__name__) #outputs: foo     How can the decorators be useful?  Now the big question: What can I use decorators for?   Seem cool and powerful, but a practical example would be great. Well, there are 1000 possibilities. Classic uses are extending a function behavior from an external lib (you can't modify it), or for debugging (you don't want to modify it because it\u2019s temporary).   You can use them to extend several functions in a DRY\u2019s way, like so:  def benchmark(func):     \"\"\"     A decorator that prints the time a function takes     to execute.     \"\"\"     import time     def wrapper(*args, **kwargs):         t = time.clock()         res = func(*args, **kwargs)         print(\"{0} {1}\".format(func.__name__, time.clock()-t))         return res     return wrapper   def logging(func):     \"\"\"     A decorator that logs the activity of the script.     (it actually just prints it, but it could be logging!)     \"\"\"     def wrapper(*args, **kwargs):         res = func(*args, **kwargs)         print(\"{0} {1} {2}\".format(func.__name__, args, kwargs))         return res     return wrapper   def counter(func):     \"\"\"     A decorator that counts and prints the number of times a function has been executed     \"\"\"     def wrapper(*args, **kwargs):         wrapper.count = wrapper.count + 1         res = func(*args, **kwargs)         print(\"{0} has been used: {1}x\".format(func.__name__, wrapper.count))         return res     wrapper.count = 0     return wrapper  @counter @benchmark @logging def reverse_string(string):     return str(reversed(string))  print(reverse_string(\"Able was I ere I saw Elba\")) print(reverse_string(\"A man, a plan, a canoe, pasta, heros, rajahs, a coloratura, maps, snipe, percale, macaroni, a gag, a banana bag, a tan, a tag, a banana bag again (or a camel), a crepe, pins, Spam, a rut, a Rolo, cash, a jar, sore hats, a peon, a canal: Panama!\"))  #outputs: #reverse_string ('Able was I ere I saw Elba',) {} #wrapper 0.0 #wrapper has been used: 1x  #ablE was I ere I saw elbA #reverse_string ('A man, a plan, a canoe, pasta, heros, rajahs, a coloratura, maps, snipe, percale, macaroni, a gag, a banana bag, a tan, a tag, a banana bag again (or a camel), a crepe, pins, Spam, a rut, a Rolo, cash, a jar, sore hats, a peon, a canal: Panama!',) {} #wrapper 0.0 #wrapper has been used: 2x #!amanaP :lanac a ,noep a ,stah eros ,raj a ,hsac ,oloR a ,tur a ,mapS ,snip ,eperc a ,)lemac a ro( niaga gab ananab a ,gat a ,nat a ,gab ananab a ,gag a ,inoracam ,elacrep ,epins ,spam ,arutaroloc a ,shajar ,soreh ,atsap ,eonac a ,nalp a ,nam A   Of course the good thing with decorators is that you can use them right away on almost anything without rewriting. DRY, I said:  @counter @benchmark @logging def get_random_futurama_quote():     from urllib import urlopen     result = urlopen(\"http://subfusion.net/cgi-bin/quote.pl?quote=futurama\").read()     try:         value = result.split(\"<br><b><hr><br>\")[1].split(\"<br><br><hr>\")[0]         return value.strip()     except:         return \"No, I'm ... doesn't!\"   print(get_random_futurama_quote()) print(get_random_futurama_quote())  #outputs: #get_random_futurama_quote () {} #wrapper 0.02 #wrapper has been used: 1x #The laws of science be a harsh mistress. #get_random_futurama_quote () {} #wrapper 0.01 #wrapper has been used: 2x #Curse you, merciful Poseidon!   Python itself provides several decorators: property, staticmethod, etc.    Django uses decorators to manage caching and view permissions.  Twisted to fake inlining asynchronous functions calls.   This really is a large playground.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "132", "A_Content": "  Alternatively, you could write a factory function which return a decorator which wraps the return value of the decorated function in a tag passed to the factory function. For example:  from functools import wraps  def wrap_in_tag(tag):     def factory(func):         @wraps(func)         def decorator():             return '<%(tag)s>%(rv)s</%(tag)s>' % (                 {'tag': tag, 'rv': func()})         return decorator     return factory   This enables you to write:  @wrap_in_tag('b') @wrap_in_tag('i') def say():     return 'hello'   or  makebold = wrap_in_tag('b') makeitalic = wrap_in_tag('i')  @makebold @makeitalic def say():     return 'hello'   Personally I would have written the decorator somewhat differently:  from functools import wraps  def wrap_in_tag(tag):     def factory(func):         @wraps(func)         def decorator(val):             return func('<%(tag)s>%(val)s</%(tag)s>' %                         {'tag': tag, 'val': val})         return decorator     return factory   which would yield:  @wrap_in_tag('b') @wrap_in_tag('i') def say(val):     return val say('hello')   Don't forget the construction for which decorator syntax is a shorthand:  say = wrap_in_tag('b')(wrap_in_tag('i')(say)))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "103", "A_Content": "  It looks like the other people have already told you how to solve the problem. I hope this will help you understand what decorators are.  Decorators are just syntactical sugar.  This  @decorator def func():     ...   expands to      def func():     ... func = decorator(func)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "59", "A_Content": "  And of course you can return lambdas as well from a decorator function:  def makebold(f):      return lambda: \"<b>\" + f() + \"</b>\" def makeitalic(f):      return lambda: \"<i>\" + f() + \"</i>\"  @makebold @makeitalic def say():     return \"Hello\"  print say()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "56", "A_Content": "  Python decorators add extra functionality to another function  An italics decorator could be like  def makeitalic(fn):     def newFunc():         return \"<i>\" + fn() + \"</i>\"     return newFunc   Note that a function is defined inside a function. What it basically does is replace a function with the newly defined one. For example, I have this class  class foo:     def bar(self):         print \"hi\"     def foobar(self):         print \"hi again\"   Now say, I want both functions to print \"---\" after and before they are done. I could add a print \"---\" before and after each print statement. But because I don't like repeating myself, I will make a decorator  def addDashes(fn): # notice it takes a function as an argument     def newFunction(self): # define a new function         print \"---\"         fn(self) # call the original function         print \"---\"     return newFunction     # Return the newly defined function - it will \"replace\" the original   So now I can change my class to   class foo:     @addDashes     def bar(self):         print \"hi\"      @addDashes     def foobar(self):         print \"hi again\"   For more on decorators, check http://www.ibm.com/developerworks/linux/library/l-cpdecor.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "25", "A_Content": "  You could make two separate decorators that do what you want as illustrated directly below. Note the use of *args, **kwargs in the declaration of the wrapped() function which supports the decorated function having multiple arguments (which isn't really necessary for the example say() function, but is included for generality).  For similar reasons, the functools.wraps decorator is used to change the meta attributes of the wrapped function to be those of the one being decorated. This makes error messages and embedded function documentation (func.__doc__) be those of the decorated function instead of wrapped()'s.  from functools import wraps  def makebold(fn):     @wraps(fn)     def wrapped(*args, **kwargs):         return \"<b>\" + fn(*args, **kwargs) + \"</b>\"     return wrapped  def makeitalic(fn):     @wraps(fn)     def wrapped(*args, **kwargs):         return \"<i>\" + fn(*args, **kwargs) + \"</i>\"     return wrapped  @makebold @makeitalic def say():     return 'Hello'  print(say())  # -> <b><i>Hello</i></b>   Refinements  As you can see there's a lot of duplicate code in these two decorators. Given this similarity it would be better for you to instead make a generic one that was actually a decorator factory\u2014in other words, a decorator that makes other decorators. That way there would be less code repetition\u2014and allow the DRY principle to be followed.  def html_deco(tag):     def decorator(fn):         @wraps(fn)         def wrapped(*args, **kwargs):             return '<%s>' % tag + fn(*args, **kwargs) + '</%s>' % tag         return wrapped     return decorator  @html_deco('b') @html_deco('i') def greet(whom=''):     return 'Hello' + (' ' + whom) if whom else ''  print(greet('world'))  # -> <b><i>Hello world</i></b>   To make the code more readable, you can assign a more descriptive name to the factory-generated decorators:  makebold = html_deco('b') makeitalic = html_deco('i')  @makebold @makeitalic def greet(whom=''):     return 'Hello' + (' ' + whom) if whom else ''  print(greet('world'))  # -> <b><i>Hello world</i></b>   or even combine them like this:  makebolditalic = lambda fn: makebold(makeitalic(fn))  @makebolditalic def greet(whom=''):     return 'Hello' + (' ' + whom) if whom else ''  print(greet('world'))  # -> <b><i>Hello world</i></b>   Efficiency  While the above examples do all work, the code generated involves a fair amount of overhead in the form of extraneous function calls when multiple decorator are applied at once. This may not matter, depending the exact usage (which might be I/O-bound, for instance).  If speed of the decorated function is important, the overhead can be kept to a single extra function call by writing a slightly different decorator factory-function which implements adding all the tags at once, so it can generate code that avoids the addtional function calls incurred by using separate decorators for each tag.  This requires more code in the decorator itself, but this only runs when it's being appled to function definitions, not later when they themselves are called. This also applies when creating more readable names by using lambda functions as previously illustrated. Sample:  def multi_html_deco(*tags):     start_tags, end_tags = [], []     for tag in tags:         start_tags.append('<%s>' % tag)         end_tags.append('</%s>' % tag)     start_tags = ''.join(start_tags)     end_tags = ''.join(reversed(end_tags))      def decorator(fn):         @wraps(fn)         def wrapped(*args, **kwargs):             return start_tags + fn(*args, **kwargs) + end_tags         return wrapped     return decorator  makebolditalic = multi_html_deco('b', 'i')  @makebolditalic def greet(whom=''):     return 'Hello' + (' ' + whom) if whom else ''  print(greet('world'))  # -> <b><i>Hello world</i></b>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "18", "A_Content": "  Another way of doing the same thing:  class bol(object):   def __init__(self, f):     self.f = f   def __call__(self):     return \"<b>{}</b>\".format(self.f())  class ita(object):   def __init__(self, f):     self.f = f   def __call__(self):     return \"<i>{}</i>\".format(self.f())  @bol @ita def sayhi():   return 'hi'   Or, more flexibly:  class sty(object):   def __init__(self, tag):     self.tag = tag   def __call__(self, f):     def newf():       return \"<{tag}>{res}</{tag}>\".format(res=f(), tag=self.tag)     return newf  @sty('b') @sty('i') def sayhi():   return 'hi'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "15", "A_Content": "     How can I make two decorators in Python that would do the following?   You want the following function, when called:   @makebold @makeitalic def say():     return \"Hello\"    To return:   <b><i>Hello</i></b>    Simple solution  To most simply do this, make decorators that return lambdas (anonymous functions) that close over the function (closures) and call it:  def makeitalic(fn):     return lambda: '<i>' + fn() + '</i>'  def makebold(fn):     return lambda: '<b>' + fn() + '</b>'   Now use them as desired:  @makebold @makeitalic def say():     return 'Hello'   and now:  >>> say() '<b><i>Hello</i></b>'   Problems with the simple solution  But we seem to have nearly lost the original function.   >>> say <function <lambda> at 0x4ACFA070>   To find it, we'd need to dig into the closure of each lambda, one of which is buried in the other:  >>> say.__closure__[0].cell_contents <function <lambda> at 0x4ACFA030> >>> say.__closure__[0].cell_contents.__closure__[0].cell_contents <function say at 0x4ACFA730>   So if we put documentation on this function, or wanted to be able to decorate functions that take more than one argument, or we just wanted to know what function we were looking at in a debugging session, we need to do a bit more with our wrapper.  Full featured solution - overcoming most of these problems  We have the decorator wraps from the functools module in the standard library!   from functools import wraps  def makeitalic(fn):     # must assign/update attributes from wrapped function to wrapper     # __module__, __name__, __doc__, and __dict__ by default     @wraps(fn) # explicitly give function whose attributes it is applying     def wrapped(*args, **kwargs):         return '<i>' + fn(*args, **kwargs) + '</i>'     return wrapped  def makebold(fn):     @wraps(fn)     def wrapped(*args, **kwargs):         return '<b>' + fn(*args, **kwargs) + '</b>'     return wrapped   It is unfortunate that there's still some boilerplate, but this is about as simple as we can make it.   In Python 3, you also get __qualname__ and __annotations__ assigned by default.  So now:  @makebold @makeitalic def say():     \"\"\"This function returns a bolded, italicized 'hello'\"\"\"     return 'Hello'   And now:  >>> say <function say at 0x14BB8F70> >>> help(say) Help on function say in module __main__:  say(*args, **kwargs)     This function returns a bolded, italicized 'hello'   Conclusion  So we see that wraps makes the wrapping function do almost everything except tell us exactly what the function takes as arguments.   There are other modules that may attempt to tackle the problem, but the solution is not yet in the standard library.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "10", "A_Content": "  A decorator takes the function definition and creates a new function that executes this function and transforms the result.  @deco def do():     ...   is eqivarent to:  do = deco(do)   Example:  def deco(func):     def inner(letter):         return func(letter).upper()  #upper     return inner   This  @deco def do(number):     return chr(number)  # number to letter   is eqivalent to this     def do2(number):         return chr(number)  do2 = deco(do2)   65 <=> 'a'  print(do(65)) print(do2(65)) >>> B >>> B   To understand the decorator, it is important to notice, that decorator created a new function do which is inner that executes func and transforms the result.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "8", "A_Content": "  To explain decorator in a simpler way:  With:  @decor1 @decor2 def func(*args, **kwargs):     pass   When do:  func(*args, **kwargs)   You really do:  decor1(decor2(func))(*args, **kwargs)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "4", "A_Content": "  #decorator.py def makeHtmlTag(tag, *args, **kwds):     def real_decorator(fn):         css_class = \" class='{0}'\".format(kwds[\"css_class\"]) \\                                  if \"css_class\" in kwds else \"\"         def wrapped(*args, **kwds):             return \"<\"+tag+css_class+\">\" + fn(*args, **kwds) + \"</\"+tag+\">\"         return wrapped     # return decorator dont call it     return real_decorator  @makeHtmlTag(tag=\"b\", css_class=\"bold_css\") @makeHtmlTag(tag=\"i\", css_class=\"italic_css\") def hello():     return \"hello world\"  print hello()   You can also write decorator in Class  #class.py class makeHtmlTagClass(object):     def __init__(self, tag, css_class=\"\"):         self._tag = tag         self._css_class = \" class='{0}'\".format(css_class) \\                                        if css_class != \"\" else \"\"      def __call__(self, fn):         def wrapped(*args, **kwargs):             return \"<\" + self._tag + self._css_class+\">\"  \\                        + fn(*args, **kwargs) + \"</\" + self._tag + \">\"         return wrapped  @makeHtmlTagClass(tag=\"b\", css_class=\"bold_css\") @makeHtmlTagClass(tag=\"i\", css_class=\"italic_css\") def hello(name):     return \"Hello, {}\".format(name)  print hello(\"Your name\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "3", "A_Content": "  Speaking of the counter example - as given above, the counter will be shared between all functions that use the decorator:  def counter(func):     def wrapped(*args, **kws):         print 'Called #%i' % wrapped.count         wrapped.count += 1         return func(*args, **kws)     wrapped.count = 0     return wrapped   That way, your decorator can be reused for different functions (or used to decorate the same function multiple times: func_counter1 = counter(func); func_counter2 = counter(func)), and the counter variable will remain private to each.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "3", "A_Content": "  Here is a simple example of chaining decorators.  Note the last line - it shows what is going on under the covers.  ############################################################ # #    decorators # ############################################################  def bold(fn):     def decorate():         # surround with bold tags before calling original function         return \"<b>\" + fn() + \"</b>\"     return decorate   def uk(fn):     def decorate():         # swap month and day         fields = fn().split('/')         date = fields[1] + \"/\" + fields[0] + \"/\" + fields[2]         return date     return decorate  import datetime def getDate():     now = datetime.datetime.now()     return \"%d/%d/%d\" % (now.day, now.month, now.year)  @bold def getBoldDate():      return getDate()  @uk def getUkDate():     return getDate()  @bold @uk def getBoldUkDate():     return getDate()   print getDate() print getBoldDate() print getUkDate() print getBoldUkDate() # what is happening under the covers print bold(uk(getDate))()   The output looks like:  17/6/2013 <b>17/6/2013</b> 6/17/2013 <b>6/17/2013</b> <b>6/17/2013</b>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators", "Language": "Python", "Q_Title": "How to make a chain of function decorators?", "Q_Votes": "2407", "Q_Content": "    How can I make two decorators in Python that would do the following?  @makebold @makeitalic def say():    return \"Hello\"   ...which should return:  \"<b><i>Hello</i></b>\"   I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.     ", "Tags": ["python", "decorator", "python-decorators"], "A_Votes": "2", "A_Content": "  Decorate functions with different number of arguments:  def frame_tests(fn):     def wrapper(*args):         print \"\\nStart: %s\" %(fn.__name__)         fn(*args)         print \"End: %s\\n\" %(fn.__name__)     return wrapper  @frame_tests def test_fn1():     print \"This is only a test!\"  @frame_tests def test_fn2(s1):     print \"This is only a test! %s\" %(s1)  @frame_tests def test_fn3(s1, s2):     print \"This is only a test! %s %s\" %(s1, s2)  if __name__ == \"__main__\":     test_fn1()     test_fn2('OK!')     test_fn3('OK!', 'Just a test!')   Result:    Start: test_fn1   This is only a test!   End: test_fn1     Start: test_fn2   This is only a test! OK!   End: test_fn2     Start: test_fn3   This is only a test! OK! Just a test!   End: test_fn3        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "2371", "A_Content": "  Maybe a bit of example code will help: Notice the difference in the call signatures of foo, class_foo and static_foo:  class A(object):     def foo(self,x):         print \"executing foo(%s,%s)\"%(self,x)      @classmethod     def class_foo(cls,x):         print \"executing class_foo(%s,%s)\"%(cls,x)      @staticmethod     def static_foo(x):         print \"executing static_foo(%s)\"%x      a=A()   Below is the usual way an object instance calls a method. The object instance, a, is implicitly passed as the first argument.  a.foo(1) # executing foo(<__main__.A object at 0xb7dbef0c>,1)     With classmethods, the class of the object instance is implicitly passed as the first argument instead of self.  a.class_foo(1) # executing class_foo(<class '__main__.A'>,1)   You can also call class_foo using the class. In fact, if you define something to be a classmethod, it is probably because you intend to call it from the class rather than from a class instance. A.foo(1) would have raised a TypeError, but A.class_foo(1) works just fine:  A.class_foo(1) # executing class_foo(<class '__main__.A'>,1)   One use people have found for class methods is to create inheritable alternative constructors.    With staticmethods, neither self (the object instance) nor  cls (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:  a.static_foo(1) # executing static_foo(1)  A.static_foo('hi') # executing static_foo(hi)   Staticmethods are used to group functions which have some logical connection with a class to the class.    foo is just a function, but when you call a.foo you don't just get the function, you get a \"partially applied\" version of the function with the object instance a bound as the first argument to the function. foo expects 2 arguments, while a.foo only expects 1 argument.  a is bound to foo. That is what is meant by the term \"bound\" below:  print(a.foo) # <bound method A.foo of <__main__.A object at 0xb7d52f0c>>   With a.class_foo, a is not bound to class_foo, rather the class A is bound to class_foo.  print(a.class_foo) # <bound method type.class_foo of <class '__main__.A'>>   Here, with a staticmethod, even though it is a method, a.static_foo just returns a good 'ole function with no arguments bound. static_foo expects 1 argument, and a.static_foo expects 1 argument too.  print(a.static_foo) # <function static_foo at 0xb7d479cc>   And of course the same thing happens when you call static_foo with the class A instead.  print(A.static_foo) # <function static_foo at 0xb7d479cc>      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "665", "A_Content": "  A staticmethod is a method that knows nothing about the class or instance it was called on. It just gets the arguments that were passed, no implicit first argument. It is basically useless in Python -- you can just use a module function instead of a staticmethod.  A classmethod, on the other hand, is a method that gets passed the class it was called on, or the class of the instance it was called on, as first argument. This is useful when you want the method to be a factory for the class: since it gets the actual class it was called on as first argument, you can always instantiate the right class, even when subclasses are involved. Observe for instance how dict.fromkeys(), a classmethod, returns an instance of the subclass when called on a subclass:  >>> class DictSubclass(dict): ...     def __repr__(self): ...         return \"DictSubclass\" ...  >>> dict.fromkeys(\"abc\") {'a': None, 'c': None, 'b': None} >>> DictSubclass.fromkeys(\"abc\") DictSubclass >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "113", "A_Content": "  Basically @classmethod makes a method whose first argument is the class it's called from (rather than the class instance), @staticmethod does not have any implicit arguments.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "76", "A_Content": "  Official python docs:  @classmethod     A class method receives the class as   implicit first argument, just like an   instance method receives the instance.   To declare a class method, use this   idiom:  class C:     @classmethod     def f(cls, arg1, arg2, ...): ...        The @classmethod form is a function   decorator \u2013 see the description of   function definitions in Function   definitions for details.      It can be called either on the class   (such as C.f()) or on an instance   (such as C().f()). The instance is   ignored except for its class. If a   class method is called for a derived   class, the derived class object is   passed as the implied first argument.      Class methods are different than C++   or Java static methods. If you want   those, see staticmethod() in this   section.   @staticmethod     A static method does not receive an   implicit first argument. To declare a   static method, use this idiom:  class C:     @staticmethod     def f(arg1, arg2, ...): ...        The @staticmethod form is a function   decorator \u2013 see the description of   function definitions in Function   definitions for details.      It can be called either on the class   (such as C.f()) or on an instance   (such as C().f()). The instance is   ignored except for its class.      Static methods in Python are similar   to those found in Java or C++. For a   more advanced concept, see   classmethod() in this section.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "57", "A_Content": "  Here is a short article on this question     @staticmethod function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It\u2019s definition is immutable via inheritance.      @classmethod function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance. That\u2019s because the first argument for @classmethod function must always be cls (class).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "45", "A_Content": "  To decide whether to use @staticmethod or @classmethod you have to look inside your method. If your method accesses other variables/methods in your class then use @classmethod. On the other hand, if your method does not touches any other parts of the class then use @staticmethod.  class Apple:      _counter = 0      @staticmethod     def about_apple():         print('Apple is good for you.')          # note you can still access other member of the class         # but you have to use the class instance          # which is not very nice, because you have repeat yourself         #          # For example:         # @staticmethod         #    print('Number of apples have been juiced: %s' % Apple._counter)         #         # @classmethod         #    print('Number of apples have been juiced: %s' % cls._counter)         #         #    @classmethod is especially useful when you move your function to other class,         #       you don't have to rename the class reference       @classmethod     def make_apple_juice(cls, number_of_apples):         print('Make juice:')         for i in range(number_of_apples):             cls._juice_this(i)      @classmethod     def _juice_this(cls, apple):         print('Juicing %d...' % apple)         cls._counter += 1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "39", "A_Content": "     What is the difference between @staticmethod and @classmethod in Python?   You may have seen Python code like this pseudocode, which demonstrates the signatures of the various method types and provides a docstring to explain each:  class Foo(object):      def a_normal_instance_method(self, arg_1, kwarg_2=None):         '''         Return a value that is a function of the instance with its         attributes, and other arguments such as arg_1 and kwarg2         '''      @staticmethod     def a_static_method(arg_0):         '''         Return a value that is a function of arg_0. It does not know the          instance or class it is called from.         '''      @classmethod     def a_class_method(cls, arg1):         '''         Return a value that is a function of the class and other arguments.         respects subclassing, it is called with the class it is called from.         '''   The Normal Instance Method  First I'll explain a_normal_instance_method. This is precisely called an \"instance method\". When an instance method is used, it is used as a partial function (as opposed to a total function, defined for all values when viewed in source code) that is, when used, the first of the arguments is predefined as the instance of the object, with all of its given attributes. It has the instance of the object bound to it, and it must be called from an instance of the object. Typically, it will access various attributes of the instance.  For example, this is an instance of a string:  ', '   if we use the instance method, join on this string, to join another iterable, it quite obviously is a function of the instance, in addition to being a function of the iterable list, ['a', 'b', 'c']:  >>> ', '.join(['a', 'b', 'c']) 'a, b, c'   Bound methods  Instance methods can be bound via a dotted lookup for use later.  For example, this binds the str.join method to the ':' instance:  >>> join_with_colons = ':'.join    And later we can use this as a function that already has the first argument bound to it. In this way, it works like a partial function on the instance:  >>> join_with_colons('abcde') 'a:b:c:d:e' >>> join_with_colons(['FF', 'FF', 'FF', 'FF', 'FF', 'FF']) 'FF:FF:FF:FF:FF:FF'   Static Method  The static method does not take the instance as an argument.   It is very similar to a module level function.   However, a module level function must live in the module and be specially imported to other places where it is used.   If it is attached to the object, however, it will follow the object conveniently through importing and inheritance as well.  An example of a static method is str.maketrans, moved from the string module in Python 3.  It makes a translation table suitable for consumption by str.translate. It does seem rather silly when used from an instance of a string, as demonstrated below, but importing the function from the string module is rather clumsy, and it's nice to be able to call it from the class, as in str.maketrans  # demonstrate same function whether called from instance or not: >>> ', '.maketrans('ABC', 'abc') {65: 97, 66: 98, 67: 99} >>> str.maketrans('ABC', 'abc') {65: 97, 66: 98, 67: 99}   In python 2, you have to import this function from the increasingly less useful string module:  >>> import string >>> 'ABCDEFG'.translate(string.maketrans('ABC', 'abc')) 'abcDEFG'   Class Method  A class method is a similar to an instance method in that it takes an implicit first argument, but instead of taking the instance, it takes the class. Frequently these are used as alternative constructors for better semantic usage and it will support inheritance.  The most canonical example of a builtin classmethod is dict.fromkeys. It is used as an alternative constructor of dict, (well suited for when you know what your keys are and want a default value for them.)  >>> dict.fromkeys(['a', 'b', 'c']) {'c': None, 'b': None, 'a': None}   When we subclass dict, we can use the same constructor, which creates an instance of the subclass.  >>> class MyDict(dict): 'A dict subclass, use to demo classmethods' >>> md = MyDict.fromkeys(['a', 'b', 'c']) >>> md {'a': None, 'c': None, 'b': None} >>> type(md) <class '__main__.MyDict'>   See the pandas source code for other similar examples of alternative constructors, and see also the official Python documentation on classmethod and staticmethod.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "27", "A_Content": "  @decorators were added in python 2.4 If you're using python < 2.4 you can use the classmethod() and staticmethod() function.  For example, if you want to create a factory method (A function returning an instance of a different implementation of a class depending on what argument it gets) you can do something like:  class Cluster(object):      def _is_cluster_for(cls, name):         \"\"\"         see if this class is the cluster with this name         this is a classmethod         \"\"\"          return cls.__name__ == name     _is_cluster_for = classmethod(_is_cluster_for)      #static method     def getCluster(name):         \"\"\"         static factory method, should be in Cluster class         returns a cluster object for the given name         \"\"\"         for cls in Cluster.__subclasses__():             if cls._is_cluster_for(name):                 return cls()     getCluster = staticmethod(getCluster)   Also observe that this is a good example for using a classmethod and a static method, The static method clearly belongs to the class, since it uses the class Cluster internally. The classmethod only needs information about the class, and no instance of the object.  Another benefit of making the _is_cluster_for method a classmethod is so a subclass can decide to change it's implementation, maybe because it is pretty generic and can handle more than one type of cluster, so just checking the name of the class would not be enough.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "26", "A_Content": "  I think a better question is \"When would you use @classmethod vs @staticmethod?\"  @classmethod allows you easy access to private members that are associated to the class definition. this is a great way to do singletons, or factory classes that control the number of instances of the created objects exist.  @staticmethod provides marginal performance gains, but I have yet to see a productive use of a static method within a class that couldn't be achieved as a standalone function outside the class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "23", "A_Content": "  Static Methods:   Simple functions with no self argument.  Work on class attributes; not on instance attributes. Can be called through both class and instance. The built-in function staticmethod()is used to create them.   Benefits of Static Methods:   It localizes the function name in the classscope It moves the function code closer to where it is used More convenient to import versus module-level functions since each method does not have to be specially imported  @staticmethod def some_static_method(*args, **kwds):     pass    Class Methods:   Functions that have first argument as classname. Can be called through both class and instance. These are created with classmethod in-built function.   @classmethod  def some_class_method(cls, *args, **kwds):      pass       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "19", "A_Content": "  @staticmethod just disables the default function as method descriptor.  classmethod wraps your function in a container callable that passes a reference to the owning class as first argument:  >>> class C(object): ...  pass ...  >>> def f(): ...  pass ...  >>> staticmethod(f).__get__(None, C) <function f at 0x5c1cf0> >>> classmethod(f).__get__(None, C) <bound method type.f of <class '__main__.C'>>   As a matter of fact, classmethod has a runtime overhead but makes it possible to access the owning class.  Alternatively I recommend using a metaclass and putting the class methods on that metaclass:  >>> class CMeta(type): ...  def foo(cls): ...   print cls ...  >>> class C(object): ...  __metaclass__ = CMeta ...  >>> C.foo() <class '__main__.C'>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "18", "A_Content": "  The definitive guide on how to use static, class or abstract methods in Python is one good link for this topic, and summary it as following.  @staticmethod function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It\u2019s definition is immutable via inheritance.   Python does not have to instantiate a bound-method for object. It eases the readability of the code, and it does not depend on the state of object itself;   @classmethod function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance, can be overridden by subclass. That\u2019s because the first argument for @classmethod function must always be cls (class).   Factory methods, that are used to create an instance for a class using for example some sort of pre-processing. Static methods calling static methods: if you split a static methods in several static methods, you shouldn't hard-code the class name but use class methods      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "16", "A_Content": "  @classmethod means: when this method is called, we pass the class as the first argument instead of the instance of that class (as we normally do with methods). This means you can use the class and its properties inside that method rather than a particular instance.  @staticmethod means: when this method is called, we don't pass an instance of the class to it (as we normally do with methods). This means you can put a function inside a class but you can't access the instance of that class (this is useful when your method does not use the instance).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "10", "A_Content": "  Another consideration with respect to staticmethod vs classmethod comes up with inheritance.  Say you have the following class:  class Foo(object):     @staticmethod     def bar():         return \"In Foo\"   And you then want to override bar() in a child class:  class Foo2(Foo):     @staticmethod     def bar():         return \"In Foo2\"   This works, but note that now the bar() implementation in the child class (Foo2) can no longer take advantage of anything specific to that class.  For example, say Foo2 had a method called magic() that you want to use in the Foo2 implementation of bar():  class Foo2(Foo):     @staticmethod     def bar():         return \"In Foo2\"     @staticmethod     def magic():         return \"Something useful you'd like to use in bar, but now can't\"    The workaround here would be to call Foo2.magic() in bar(), but then you're repeating yourself (if the name of Foo2 changes, you'll have to remember to update that bar() method).  To me, this is a slight violation of the open/closed principle, since a decision made in Foo is impacting your ability to refactor common code in a derived class (ie it's less open to extension).  If bar() were a classmethod we'd be fine:  class Foo(object):     @classmethod     def bar(cls):         return \"In Foo\"  class Foo2(Foo):     @classmethod     def bar(cls):         return \"In Foo2 \" + cls.magic()     @classmethod     def magic(cls):         return \"MAGIC\"  print Foo2().bar()   Gives: In Foo2 MAGIC     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "8", "A_Content": "  I will try to explain the basic difference using an example.  class A(object):     x = 0      def say_hi(self):         pass      @staticmethod     def say_hi_static():         pass      @classmethod     def say_hi_class(cls):         pass      def run_self(self):         self.x += 1         print self.x # outputs 1         self.say_hi()         self.say_hi_static()         self.say_hi_class()      @staticmethod     def run_static():         print A.x  # outputs 0         # A.say_hi() #  wrong         A.say_hi_static()         A.say_hi_class()      @classmethod     def run_class(cls):         print cls.x # outputs 0         # cls.say_hi() #  wrong         cls.say_hi_static()         cls.say_hi_class()   1 - we can directly call static and classmethods without initializing  # A.run_self() #  wrong A.run_static() A.run_class()   2- Static method cannot call self method but can call other static and classmethod  3- Static method belong to class and will not use object at all.  4- Class method are not bound to an object but to a class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "8", "A_Content": "  I started learning programming language with C++ and then Java and then Python and so this question bothered me a lot as well, until I understand the simple usage of each.   Class Method: Python unlike Java and C++ doesn't have constructor overloading.  And so so to achieve this you could use classmethod. following example will explain this   Let's consider we have a Person class which takes two argument first_name and last_name and creates the instance of Person.   class Person(object):      def __init__(self, first_name, last_name):         self.first_name = first_name         self.last_name = last_name   Now, if the requirement comes where you need to create a class using a single name only, just a first_name. you can't do something like this in python.   This will give you an error when you will try to create an object (instance).  class Person(object):      def __init__(self, first_name, last_name):         self.first_name = first_name         self.last_name = last_name      def __init__(self, first_name):         self.first_name = first_name   However, you could achieve the same thing using @classmethod as mentioned below   class Person(object):      def __init__(self, first_name, last_name):         self.first_name = first_name         self.last_name = last_name      @classmethod     def get_person(cls, first_name):         return cls(first_name, \"\")   Static Method:: This is rather simple, it's not bound to instance or class and you can simple call that using class name.   So let's say in above example you need a validation that first_name should not exceed 20 characters, you can simply do this.   @staticmethod   def validate_name(name):     return len(name) <= 20   and you could simply call using Class Name   Person.validate_name(\"Gaurang Shah\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "6", "A_Content": "  In Python, a classmethod receives a class as the implicit first argument. The class of the object instance is implicitly passed as the first argument. This can be useful when one wants the method to be a factory of the class as it gets the actual class (which called the method) as the first argument, one can instantiate the right class, even if subclasses are also concerned.  A staticmethod is just a function defined inside a class. It does not  know anything about the class or instance it was called on and only gets  the arguments that were passed without any implicit first argument. Example:  class Test(object):     def foo(self, a):         print \"testing (%s,%s)\"%(self,a)      @classmethod     def foo_classmethod(cls, a):         print \"testing foo_classmethod(%s,%s)\"%(cls,a)      @staticmethod     def foo_staticmethod(a):         print \"testing foo_staticmethod(%s)\"%a  test = Test()   staticmethods are used to group functions which have some logical connection with a class to the class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "5", "A_Content": "  Let me first tell the similarity between a method decorated with @classmethod vs @staticmethod first.  Similarity: Both of them can be called on the Class itself, rather than just the instance of the class. So, both of them in a sense are Class's methods.   Difference: A classmethod will receive the class itself as the first argument, while a staticmethod does not.  So a static method is, in a sense, not bound to the Class itself and is just hanging in there just because it may have a related functionality.   >>> class Klaus:         @classmethod         def classmthd(*args):             return args          @staticmethod         def staticmthd(*args):             return args  # 1. Call classmethod without any arg >>> Klaus.classmthd()   (__main__.Klaus,)  # the class gets passed as the first argument  # 2. Call classmethod with 1 arg >>> Klaus.classmthd('chumma') (__main__.Klaus, 'chumma')  # 3. Call staticmethod without any arg >>> Klaus.staticmthd()   ()  # 4. Call staticmethod with 1 arg >>> Klaus.staticmthd('chumma') ('chumma',)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "4", "A_Content": "  class method vs static method in Python  Class Method  The @classmethod decorator, is a builtin function decorator that is an expression that gets evaluated after your function is defined. The result of that evaluation shadows your function definition.  A class method receives the class as implicit first argument, just like an instance method receives the instance  Syntax:  class C(object):     @classmethod     def fun(cls, arg1, arg2, ...):        ....  fun: function that needs to be converted into a class method returns: a class method for function.    A class method is a method which is bound to the class and not the object of the class. They have the access to the state of the class as it takes a class parameter that points to the class and not the object instance. It can modify a class state that would apply across all the instances of the class.  For example it can modify a class variable that will be applicable to all the instances.   Static Method  A static method does not receive an implicit first argument.  Syntax:  class C(object):     @staticmethod     def fun(arg1, arg2, ...):         ... returns: a static method for function fun.    A static method is also a method which is bound to the class and not the object of the class. A static method can\u2019t access or modify class state. It is present in a class because it makes sense for the method to be present in class.   Class method vs Static Method   A class method takes cls as first parameter while a static method needs no specific parameters. A class method can access or modify class state while a static method can\u2019t access or modify it. We use @classmethod decorator in python to create a class method and we use @staticmethod decorator to create a static method in python.   When to use what?   We generally use class method to create factory methods. Factory methods return class object ( similar to a constructor ) for different use cases. We generally use static methods to create utility functions.   How to define a class method and a static method?  To define a class method in python, we use @classmethod decorator and to define a static method we use @staticmethod decorator.  Let us look at an example to understand the difference between both of them.  Let us say we want to create a class Person. Now, python doesn\u2019t support method overloading like C++ or Java so we use class methods to create factory methods. In the below example we use a class method to create a person object from birth year.  As explained above we use static methods to create utility functions. In the below example we use a static method to check if a person is adult or not.  Implementation  # Python program to demonstrate  # use of class method and static method. from datetime import date  class Person:     def __init__(self, name, age):         self.name = name         self.age = age      # a class method to create a Person object by birth year.     @classmethod     def fromBirthYear(cls, name, year):         return cls(name, date.today().year - year)      # a static method to check if a Person is adult or not.     @staticmethod     def isAdult(age):         return age > 18  person1 = Person('mayank', 21) person2 = Person.fromBirthYear('mayank', 1996)  print person1.age print person2.age  # print the result print Person.isAdult(22)   Output  21 21 True   Reference     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "3", "A_Content": "  @classmethod : can be used to create a shared global access to all the instances created of that class..... like updating a record by multiple users.... I particulary found it use ful when creating singletons as well..:)  @static method:  has nothing to do with the class or instance being associated with ...but for readability can use static method     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "1", "A_Content": "  Class methods, as the name suggests, are used to make changes to classes and not the objects. To make changes to classes, they will modify the class attributes(not object attributes), since that is how you update classes. This is the reason that class methods take the class(conventionally denoted by 'cls') as the first argument.  class A(object):     m=54      @classmethod     def class_method(cls):         print \"m is %d\" % cls.m   Static methods on the other hand, are used to perform functionalities that are not bound to the class i.e. they will not read or write class variables. Hence, static methods do not take classes as arguments. They are used so that classes can perform functionalities that are not directly related to the purpose of the class.  class X(object):     m=54 #will not be referenced      @staticmethod     def static_method():         print \"Referencing/calling a variable or function outside this class. E.g. Some global variable/function.\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "1", "A_Content": "  Analyze @staticmethod literally providing different insights.  A normal method of a class is an implicit dynamic method which takes the instance as first argument. In contrast, a staticmethod does not take the instance as first argument, so is called 'static'.  A staticmethod is indeed such a normal function the same as those outside a class definition. It is luckily grouped into the class just in order to stand closer where it is applied, or you might scroll around to find it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "Language": "Python", "Q_Title": "What is the difference between @staticmethod and @classmethod in Python?", "Q_Votes": "2735", "Q_Content": "    What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?     ", "Tags": ["python", "oop", "methods", "python-decorators"], "A_Votes": "1", "A_Content": "  My contribution demonstrates the difference amongst @classmethod, @staticmethod, and instance methods, including how an instance can indirectly call a @staticmethod. But instead of indirectly calling a @staticmethod from an instance, making it private may be more \"pythonic.\" Getting something from a private method isn't demonstrated here but it's basically the same concept.  #!python3  from os import system system('cls') # %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %  class DemoClass(object):     # instance methods need a class instance and     # can access the instance through 'self'     def instance_method_1(self):         return 'called from inside the instance_method_1()'      def instance_method_2(self):         # an instance outside the class indirectly calls the static_method         return self.static_method() + ' via instance_method_2()'      # class methods don't need a class instance, they can't access the     # instance (self) but they have access to the class itself via 'cls'     @classmethod     def class_method(cls):         return 'called from inside the class_method()'      # static methods don't have access to 'cls' or 'self', they work like     # regular functions but belong to the class' namespace     @staticmethod     def static_method():         return 'called from inside the static_method()' # %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %  # works even if the class hasn't been instantiated print(DemoClass.class_method() + '\\n') ''' called from inside the class_method() '''  # works even if the class hasn't been instantiated print(DemoClass.static_method() + '\\n') ''' called from inside the static_method() ''' # %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %   %  # >>>>> all methods types can be called on a class instance <<<<< # instantiate the class democlassObj = DemoClass()  # call instance_method_1() print(democlassObj.instance_method_1() + '\\n') ''' called from inside the instance_method_1() '''  # # indirectly call static_method through instance_method_2(), there's really no use # for this since a @staticmethod can be called whether the class has been # instantiated or not print(democlassObj.instance_method_2() + '\\n') ''' called from inside the static_method() via instance_method_2() '''  # call class_method() print(democlassObj.class_method() + '\\n') '''  called from inside the class_method() '''  # call static_method() print(democlassObj.static_method()) ''' called from inside the static_method() '''  \"\"\" # whether the class is instantiated or not, this doesn't work print(DemoClass.instance_method_1() + '\\n') ''' TypeError: TypeError: unbound method instancemethod() must be called with DemoClass instance as first argument (got nothing instead) ''' \"\"\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "4161", "A_Content": "  append: Appends object at the end.  x = [1, 2, 3] x.append([4, 5]) print (x)   gives you: [1, 2, 3, [4, 5]]    extend: Extends list by appending elements from the iterable.  x = [1, 2, 3] x.extend([4, 5]) print (x)   gives you: [1, 2, 3, 4, 5]     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "533", "A_Content": "  append adds an element to a list, and extend concatenates the first list with another list (or another iterable, not necessarily a list.)  >>> li = ['a', 'b', 'mpilgrim', 'z', 'example'] >>> li ['a', 'b', 'mpilgrim', 'z', 'example']  >>> li.append(\"new\") >>> li ['a', 'b', 'mpilgrim', 'z', 'example', 'new']  >>> li.insert(2, \"new\") >>> li ['a', 'b', 'new', 'mpilgrim', 'z', 'example', 'new']  >>> li.extend([\"two\", \"elements\"]) >>> li ['a', 'b', 'new', 'mpilgrim', 'z', 'example', 'new', 'two', 'elements']   From Dive into Python.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "282", "A_Content": "     What is the difference between the list methods append and extend?    append adds its argument as a single element to the end of a list. The length of the list itself will increase by one. extend iterates over its argument adding each element to the list, extending the list. The length of the list will increase by however many elements were in the iterable argument.   append  The list.append method appends an object to the end of the list.  my_list.append(object)    Whatever the object is, whether a number, a string, another list, or something else, it gets added onto the end of my_list as a single entry on the list.   >>> my_list ['foo', 'bar'] >>> my_list.append('baz') >>> my_list ['foo', 'bar', 'baz']   So keep in mind that a list is an object. If you append another list onto a list, the first list will be a single object at the end of the list (which may not be what you want):  >>> another_list = [1, 2, 3] >>> my_list.append(another_list) >>> my_list ['foo', 'bar', 'baz', [1, 2, 3]]                      #^^^^^^^^^--- single item on end of list.   extend  The list.extend method extends a list by appending elements from an iterable:  my_list.extend(iterable)   So with extend, each element of the iterable gets appended onto the list. For example:  >>> my_list ['foo', 'bar'] >>> another_list = [1, 2, 3] >>> my_list.extend(another_list) >>> my_list ['foo', 'bar', 1, 2, 3]   Keep in mind that a string is an iterable, so if you extend a list with a string, you'll append each character as you iterate over the string (which may not be what you want):  >>> my_list.extend('baz') >>> my_list ['foo', 'bar', 1, 2, 3, 'b', 'a', 'z']   Operator Overload, __add__, (+) and __iadd__ (+=)  Both + and += operators are defined for list. They are semantically similar to extend.  my_list + another_list creates a third list in memory, so you can return the result of it, but it requires that the second iterable be a list.   my_list += another_list modifies the list in-place (it is the in-place operator, and lists are mutable objects, as we've seen) so it does not create a new list. It also works like extend, in that the second iterable can be any kind of iterable.  Don't get confused - my_list = my_list + another_list is not equivalent to += - it gives you a brand new list assigned to my_list.  Time Complexity  Append has constant time complexity, O(1).   Extend has time complexity, O(k).   Iterating through the multiple calls to append adds to the complexity, making it equivalent to that of extend, and since extend's iteration is implemented in C, it will always be faster if you intend to append successive items from an iterable onto a list.  Performance  You may wonder what is more performant, since append can be used to achieve the same outcome as extend. The following functions do the same thing:  def append(alist, iterable):     for item in iterable:         alist.append(item)  def extend(alist, iterable):     alist.extend(iterable)   So let's time them:  import timeit  >>> min(timeit.repeat(lambda: append([], \"abcdefghijklmnopqrstuvwxyz\"))) 2.867846965789795 >>> min(timeit.repeat(lambda: extend([], \"abcdefghijklmnopqrstuvwxyz\"))) 0.8060121536254883   Addressing a comment on timings  A commenter said:     Perfect answer, I just miss the timing of comparing adding only one element   Do the semantically correct thing. If you want to append all elements in an iterable, use extend. If you're just adding one element, use append.  Ok, so let's create an experiment to see how this works out in time:  def append_one(a_list, element):     a_list.append(element)  def extend_one(a_list, element):     \"\"\"creating a new list is semantically the most direct     way to create an iterable to give to extend\"\"\"     a_list.extend([element])  import timeit   And we see that going out of our way to create an iterable just to use extend is a (minor) waste of time:  >>> min(timeit.repeat(lambda: append_one([], 0))) 0.2082819009956438 >>> min(timeit.repeat(lambda: extend_one([], 0))) 0.2397019260097295   We learn from this that there's nothing gained from using extend when we have only one element to append.  Also, these timings are not that important. I am just showing them to make the point that, in Python, doing the semantically correct thing is doing things the Right Way\u2122.  It's conceivable that you might test timings on two comparable operations and get an ambiguous or inverse result. Just focus on doing the semantically correct thing.  Conclusion  We see that extend is semantically clearer, and that it can run much faster than append, when you intend to append each element in an iterable to a list.   If you only have a single element (not in an iterable) to add to the list, use append.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "97", "A_Content": "  append appends a single element. extend appends a list of elements.  Note that if you pass a list to append, it still adds one element:  >>> a = [1, 2, 3] >>> a.append([4, 5, 6]) >>> a [1, 2, 3, [4, 5, 6]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "45", "A_Content": "  The following two snippets are semantically equivalent:  for item in iterator:     a_list.append(item)   and  a_list.extend(iterator)   The latter may be faster as the loop is implemented in C.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "32", "A_Content": "  The append() method adds a single item to the end of the list.  x = [1, 2, 3] x.append([4, 5]) x.append('abc') print(x) # gives you [1, 2, 3, [4, 5], 'abc']   The extend() method takes one argument, a list, and appends each of the items of the argument to the original list. (Lists are implemented as classes. \u201cCreating\u201d a list is really instantiating a class. As such, a list has methods that operate on it.)  x = [1, 2, 3] x.extend([4, 5]) x.extend('abc') print(x) # gives you [1, 2, 3, 4, 5, 'a', 'b', 'c']   From Dive Into Python.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "31", "A_Content": "  You can use \"+\" for returning extend, instead of extending in place.  l1=range(10)  l1+[11]  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11]  l2=range(10,1,-1)  l1+l2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 8, 7, 6, 5, 4, 3, 2]   Similarly += for in place behavior, but with slight differences from append & extend. One of the biggest differences of += from append and extend is when it is used in function scopes, see this blog post.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "19", "A_Content": "      Append vs Extend         With append you can append a single element that will extend the list:  >>> a = [1,2] >>> a.append(3) >>> a [1,2,3]   If you want to extend more than one element you should use extend, because you can only append one elment or one list of element:  >>> a.append([4,5]) >>> a >>> [1,2,3,[4,5]]   So that you get a nested list  Instead with extend you can extend a single element like this  >>> a = [1,2] >>> a.extend([3]) >>> a [1,2,3]   Or, differently from append, extend more elements in one time without nesting the list into the original one (that's the reason of the name extend)  >>> a.extend([4,5,6]) >>> a [1,2,3,4,5,6]    Adding one element with both methods     append 1 element   >>> x = [1,2] >>> x.append(3) >>> x [1,2,3]    extend one element   >>> x = [1,2] >>> x.extend([3]) >>> x [1,2,3,4]       Adding more elements... with different results    If you use append for more than one element, you have to pass a list of elements as arguments and you will obtain a NESTED list!  >>> x = [1,2] >>> x.append([3,4]) >>> x [1,2,[3,4]]   With extend, instead, you pass a list as argument, but you will obtain a list with the new element that are not nested in the old one.  >>> z = [1,2]  >>> z.extend([3,4]) >>> z [1,2,3,4]   So, with more elements, you will use extend to get a list with more items. You will use append, to append not more elements to the list, but one element that is a nested list as you can clearly see in the output of the code.         ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "18", "A_Content": "  append(object) - Updates the list by adding an object to the list.  x = [20] # List passed to the append(object) method is treated as a single object. x.append([21, 22, 23]) # Hence the resultant list length will be 2 print(x) --> [20, [21, 22, 23]]   extend(list) - Essentially concatenates two lists.  x = [20] # The parameter passed to extend(list) method is treated as a list. # Eventually it is two lists being concatenated. x.extend([21, 22, 23]) # Here the resultant list's length is 4 print(x) [20, 21, 22, 23]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "17", "A_Content": "  extend() can be used with an iterator argument. Here is an example. You wish to make a list out of a list of lists this way:  From  list2d = [[1,2,3],[4,5,6], [7], [8,9]]   you want  >>> [1, 2, 3, 4, 5, 6, 7, 8, 9]   You may use itertools.chain.from_iterable() to do so. This method's output is an iterator. Its implementation is equivalent to  def from_iterable(iterables):     # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F     for it in iterables:         for element in it:             yield element   Back to our example, we can do  import itertools list2d = [[1,2,3],[4,5,6], [7], [8,9]] merged = list(itertools.chain.from_iterable(list2d))   and get the wanted list.  Here is how equivalently extend() can be used with an iterator argument:  merged = [] merged.extend(itertools.chain.from_iterable(list2d)) print(merged) >>> [1, 2, 3, 4, 5, 6, 7, 8, 9]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "15", "A_Content": "  This is the equivalent of append and extend using the + operator:  >>> x = [1,2,3] >>> x [1, 2, 3] >>> x = x + [4,5,6] # Extend >>> x [1, 2, 3, 4, 5, 6] >>> x = x + [[7,8]] # Append >>> x [1, 2, 3, 4, 5, 6, [7, 8]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "12", "A_Content": "  append(): It is basically used in Python to add one element.     Example 1:   >> a = [1, 2, 3, 4] >> a.append(5) >> print(a) >> a = [1, 2, 3, 4, 5]      Example 2:   >> a = [1, 2, 3, 4] >> a.append([5, 6]) >> print(a) >> a = [1, 2, 3, 4, [5, 6]]   extend(): Where extend(), is used to merge two lists or insert multiple elements in one list.     Example 1:   >> a = [1, 2, 3, 4] >> b = [5, 6, 7, 8] >> a.extend(b) >> print(a) >> a = [1, 2, 3, 4, 5, 6, 7, 8]      Example 2:   >> a = [1, 2, 3, 4] >> a.extend([5, 6]) >> print(a) >> a = [1, 2, 3, 4, 5, 6]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "10", "A_Content": "  An interesting point that has been hinted, but not explained, is that extend is faster than append. For any loop that has append inside should be considered to be replaced by list.extend(processed_elements).  Bear in mind that apprending new elements might result in the realloaction of the whole list to a better location in memory. If this is done several times because we are appending 1 element at a time, overall performance suffers. In this sense, list.extend is analogous to \"\".join(stringlist).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "10", "A_Content": "  Append adds the entire data at once. The whole data will be added to the newly created index. On the other hand, extend, as it name suggests, extends the current array.   For example  list1 = [123, 456, 678] list2 = [111, 222]   With append we get:  result = [123, 456, 678, [111, 222]]   While on extend we get:  result = [123, 456, 678, 111, 222]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "4", "A_Content": "  I hope I can make a useful supplement to this question. If your list stores a specific type object, for example Info, here is a situation that extend method is not suitable: In a for loop and and generating an Info object every time and using extend to store it into your list, it will fail. The exception is like below:     TypeError: 'Info' object is not iterable   But if you use the append method, the result is OK. Because every time using the extend method, it will always treat it as a list or any other collection type, iterate it, and place it after the previous list. A specific object can not be iterated, obviously.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "4", "A_Content": "  Append a dictionary to another one:  >>>def foo():     dic = {1:'a', 2:'b', 3:'c', 4:'a'}     newdic = {5:'v', 1:'aa'}     for i in dic.keys():         if not newdic.has_key(dic[i]):             newdic[i] = dic[i]     print \"Appended one:\", newdic  >>>foo() Appended one: {1: 'a', 2: 'b', 3: 'c', 4: 'a', 5: 'v'}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "4", "A_Content": "  An English dictionary define the words append and extend as:  append: add (something) to the end of a written document.  extend: make larger. Enlarge or expand    With that knowledge, now let's understand  1) The difference between append and extend  append:   Appends any Python object as-is to the end of the list (i.e. as a last element in the list). The resulting list may be nested and contain heterogeneous elements (i.e. list, string, tuple, dictionary, set, etc.)   extend:   Accepts any iterable as its argument and makes the list larger. The resulting list is always one dimensional list (i.e. no nesting) and it may contain heterogeneous elements in it (e.g. characters, integers, float) as a result of applying list(iterable).   2) Similarity between append and extend   Both takes exactly one argument. Both modify the list in-place. As a result, both returns None.     Example  lis = [1, 2, 3]  # 'extend' is equivalent to this lis = lis + list(iterable)  # 'append' simply appends its argument as the last element to the list # as long as the argument is a valid Python object lis.append(object)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "3", "A_Content": "  The method \"append\" adds its parameter as a single element to the list, while \"extend\" gets a list and adds its content.  For example,     extend       letters = ['a', 'b']     letters.extend(['c', 'd'])     print(letters) # ['a', 'b', 'c', 'd']      append       letters.append(['e', 'f'])     print(letters) # ['a', 'b', 'c', 'd', ['e', 'f']]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "2", "A_Content": "  To distinguish them intuitively  l1 = ['a', 'b', 'c'] l2 = ['d', 'e', 'f'] l1.append(l2) l1 ['a', 'b', 'c', ['d', 'e', 'f']]   It's like l1 reproduce a body inside her body(nested).  # Reset l1 = ['a', 'b', 'c'] l1.extend(l2) l1 ['a', 'b', 'c', 'd', 'e', 'f']   It's like that two separated individuals get married and construct an united family.  Besides I make an exhaustive cheatsheet of all list's methods for your reference.  list_methods = {'Add': {'extend', 'append', 'insert'},                 'Remove': {'pop', 'remove', 'clear'}                 'Sort': {'reverse', 'sort'},                 'Search': {'count', 'index'},                 'Copy': {'copy'},                 }      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "1", "A_Content": "  This helped me upderstand what really happens when you use append and extend:  a = [[1,2,3],[4,5,6]] print(a) >>> [[1, 2, 3], [4, 5, 6]] a.append([6,7,8]) print(a) >>> [[1, 2, 3], [4, 5, 6], [6, 7, 8]] a.extend([0,1,2]) print(a) >>> [[1, 2, 3], [4, 5, 6], [6, 7, 8], 0, 1, 2] a=a+[8,9,10] print(a) >>> [[1, 2, 3], [4, 5, 6], [6, 7, 8], 0, 1, 2, 8, 9, 10]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "0", "A_Content": "  extend(L) extends the list by appending all the items in the given list L.   >>> a [1, 2, 3] a.extend([4]) # it is equivalent to a[len(a):] = [4] or a.append(4)  >>>a [1, 2, 3, 4]  >>> a = [1  >>> a [1, 2, 3]  >>> a[len(a)] = [4]  >>> a [1, 2, 3, 4]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "0", "A_Content": "  Append and extend are one of the extensibility mechanisms in python.   Append: Adds an element to the end of the list.   my_list = [1,2,3,4]   To add a new element to the list, we can use append method in the following way.  my_list.append(5)   The default location that the new element will be added is always in the (length+1) position.   Insert: The insert method was used to overcome the limitations of append. With insert, we can explicitly define the exact position we want our new element to be inserted at.   Method descriptor of insert(index, object). It takes two arguments, first being the index we want to insert our element and second the element itself.   Example: my_list = [1,2,3,4] my_list[4, 'a'] my_list [1,2,3,4,'a']   Extend: This is very useful when we want to join two or more lists into a single list. Without extend, if we want to join two lists, the resulting object will contain a list of lists.   a = [1,2] b = [3] a.append(b) print (a) [1,2,[3]]   If we try to access the element at pos 2, we get a list ([3]), instead of the element. To join two lists, we'll have to use append.   a = [1,2] b = [3] a.extend(b) print (a) [1,2,3]   To join multiple lists  a = [1] b = [2] c = [3] a.extend(b+c) print (a) [1,2,3]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python", "Language": "Python", "Q_Title": "Difference between append vs. extend list methods in Python", "Q_Votes": "2745", "Q_Content": "    What's the difference between the list methods append() and extend()?     ", "Tags": ["python", "list", "data-structures", "append", "extend"], "A_Votes": "-1", "A_Content": "  append \"extends\" the list (in place) by only one item, the single object passed (as argument).  extend \"extends\" the list (in place) by as many items as the object passed (as argument) contains.  This may be slightly confusing for str objects.   If you pass a string as argument: append will add a single string item at the end but extend will add as many \"single\" 'str' items as the length of that string. If you pass a list of strings as argument: append will still add a single 'list' item at the end and extend will add as many 'list' items as the length of the passed list.    def append_o(a_list, element):     a_list.append(element)     print('append:', end = ' ')     for item in a_list:         print(item, end = ',')     print()  def extend_o(a_list, element):     a_list.extend(element)     print('extend:', end = ' ')     for item in a_list:         print(item, end = ',')     print() append_o(['ab'],'cd')  extend_o(['ab'],'cd') append_o(['ab'],['cd', 'ef']) extend_o(['ab'],['cd', 'ef']) append_o(['ab'],['cd']) extend_o(['ab'],['cd'])    produces:  append: ab,cd, extend: ab,c,d, append: ab,['cd', 'ef'], extend: ab,cd,ef, append: ab,['cd'], extend: ab,cd,      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "4499", "A_Content": "  You can use the in operator:  if \"blah\" not in somestring:      continue      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "474", "A_Content": "  If it's just a substring search you can use string.find(\"substring\").  You do have to be a little careful with find, index, and in though, as they are substring searches. In other words, this:  s = \"This be a string\" if s.find(\"is\") == -1:     print \"No 'is' here!\" else:     print \"Found 'is' in the string.\"   It would print Found 'is' in the string. Similarly, if \"is\" in s: would evaluate to True. This may or may not be what you want.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "128", "A_Content": "  if needle in haystack: is the normal use, as @Michael says -- it relies on the in operator, more readable and faster than a method call.  If you truly need a method instead of an operator (e.g. to do some weird key= for a very peculiar sort...?), that would be 'haystack'.__contains__.  But since your example is for use in an if, I guess you don't really mean what you say;-).  It's not good form (nor readable, nor efficient) to use special methods directly -- they're meant to be used, instead, through the operators and builtins that delegate to them.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "104", "A_Content": "  Basically, you want to find a substring in a string in python. There are two ways to search for a substring in a string in Python.  Method 1: in operator  You can use the Python's in operator to check for a substring. It's quite simple and intuitive. It will return True if the substring was found in the string else False.  >>> \"King\" in \"King's landing\" True  >>> \"Jon Snow\" in \"King's landing\" False   Method 2: str.find() method  The second method is to use the str.find() method. Here, we call the .find() method on the string in which substring is to found. We pass the substring to the find() method and check its return value. If its value is other than -1, the substring was found in the string, otherwise not. The value returned is the index where substring was found.  >>> some_string = \"valar morghulis\"  >>> some_string.find(\"morghulis\") 6  >>> some_string.find(\"dohaeris\") -1   I would recommend you to use the first method as it is more Pythonic and intuitive.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "96", "A_Content": "     Does Python have a string contains substring method?   Yes, but Python has a comparison operator that you should use instead, because the language intends its usage, and other programmers will expect you to use it. That keyword is in, which is used as a comparison operator:  >>> 'foo' in '**foo**' True   The opposite (complement), which the original question asks for, is not in:  >>> 'foo' not in '**foo**' # returns False False   This is semantically the same as not 'foo' in '**foo**' but it's much more readable and explicitly provided for in the language as a readability improvement.  Avoid using __contains__, find, and index  As promised, here's the contains method:  str.__contains__('**foo**', 'foo')   returns True. You could also call this function from the instance of the superstring:  '**foo**'.__contains__('foo')   But don't. Methods that start with underscores are considered semantically private. The only reason to use this is when extending the in and not in functionality (e.g. if subclassing str):   class NoisyString(str):     def __contains__(self, other):         print('testing if \"{0}\" in \"{1}\"'.format(other, self))         return super(NoisyString, self).__contains__(other)  ns = NoisyString('a string with a substring inside')   and now:  >>> 'substring' in ns testing if \"substring\" in \"a string with a substring inside\" True   Also, avoid the following string methods:  >>> '**foo**'.index('foo') 2 >>> '**foo**'.find('foo') 2  >>> '**oo**'.find('foo') -1 >>> '**oo**'.index('foo')  Traceback (most recent call last):   File \"<pyshell#40>\", line 1, in <module>     '**oo**'.index('foo') ValueError: substring not found   Other languages may have no methods to directly test for substrings, and so you would have to use these types of methods, but with Python, it is much more efficient to use the in comparison operator.  Performance comparisons  We can compare various ways of accomplishing the same goal.  import timeit  def in_(s, other):     return other in s  def contains(s, other):     return s.__contains__(other)  def find(s, other):     return s.find(other) != -1  def index(s, other):     try:         s.index(other)     except ValueError:         return False     else:         return True    perf_dict = { 'in:True': min(timeit.repeat(lambda: in_('superstring', 'str'))), 'in:False': min(timeit.repeat(lambda: in_('superstring', 'not'))), '__contains__:True': min(timeit.repeat(lambda: contains('superstring', 'str'))), '__contains__:False': min(timeit.repeat(lambda: contains('superstring', 'not'))), 'find:True': min(timeit.repeat(lambda: find('superstring', 'str'))), 'find:False': min(timeit.repeat(lambda: find('superstring', 'not'))), 'index:True': min(timeit.repeat(lambda: index('superstring', 'str'))), 'index:False': min(timeit.repeat(lambda: index('superstring', 'not'))), }   And now we see that using in is much faster than the others. Less time to do an equivalent operation is better:  >>> perf_dict {'in:True': 0.16450627865128808,  'in:False': 0.1609668098178645,  '__contains__:True': 0.24355481654697542,  '__contains__:False': 0.24382793854783813,  'find:True': 0.3067379407923454,  'find:False': 0.29860888058124146,  'index:True': 0.29647137792585454,  'index:False': 0.5502287584545229}        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "62", "A_Content": "  No, there isn't any string.contains(str) method, but there is the in operator:  if substring in someString:     print \"It's there!!!\"   Here is a more complex working example:  # Print all files with dot in home directory import commands (st, output) = commands.getstatusoutput('ls -a ~') print [f for f in output.split('\\n') if '.' in f ]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "31", "A_Content": "  in Python strings and lists  Here are a few useful examples that speak for themselves concerning the in method:  \"foo\" in \"foobar\" True  \"foo\" in \"Foobar\" False  \"foo\" in \"Foobar\".lower() True  \"foo\".capitalize() in \"Foobar\" True  \"foo\" in [\"bar\", \"foo\", \"foobar\"] True  \"foo\" in [\"fo\", \"o\", \"foobar\"] False   Caveat. Lists are iterables, and the in method acts on iterables, not just strings.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "21", "A_Content": "  So apparently there is nothing similar for vector-wise comparison. An obvious Python way to do so would be:  names = ['bob', 'john', 'mike'] any(st in 'bob and john' for st in names)  >> True  any(st in 'mary and jane' for st in names)  >> False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "17", "A_Content": "  Another way to find whether a string contains a few characters or not with the Boolean return value (i.e. True or `False):  str1 = \"This be a string\" find_this = \"tr\" if find_this in str1:     print find_this, \" is been found in \", str1 else:     print find_this, \" is not found in \", str1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "9", "A_Content": "  In Python there are two simple ways you can achieve this:  The Pythonic way: Using Python's 'in' Keyword-  in takes two \"arguments\", one on the left(substring) and one on the right, and returns True if the left argument is contained within the rightside argument and if not,it returns False.  example_string = \"This is an example string\" substring = \"example\" print(substring in example_string)   Output:  True   The non-Pythonic way: Using Python's str.find:  The find method returns the position of the string within the string or -1 if it's not found. But simply check if the position is not -1.  if example_string.find(substring) != -1:     print('Substring found!') else:     print('Substring not found!')   Output:  Substring found!      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "8", "A_Content": "  If you are happy with \"blah\" in somestring but want it to be a function call, you can probably do this  import operator  if not operator.contains(somestring, \"blah\"):     continue   All operators in Python can be more or less found in the operator module including in.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "8", "A_Content": "  Here is your answer:  if \"insert_char_or_string_here\" in \"insert_string_to_search_here\":     #DOSTUFF   For checking if it is false:  if not \"insert_char_or_string_here\" in \"insert_string_to_search_here\":     #DOSTUFF   OR:  if \"insert_char_or_string_here\" not in \"insert_string_to_search_here\":     #DOSTUFF      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "5", "A_Content": "  If you're looking for case-insensitive search for whole words, rather than a substring contained within another word:  import string  s = 'This is my text example' if 'is' not in (word.lower()      for split_char in string.punctuation + string.whitespace      for word in s.split(split_char)):     # do something      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3437059/does-python-have-a-string-contains-substring-method", "Language": "Python", "Q_Title": "Does Python have a string 'contains' substring method?", "Q_Votes": "2982", "Q_Content": "    I'm looking for a string.contains or string.indexof method in Python.  I want to do:  if not somestring.contains(\"blah\"):    continue      ", "Tags": ["python", "string", "substring", "contains"], "A_Votes": "3", "A_Content": "  I see there are already answers but I want to add my two cents as well.  In Python there are functions to do this but the most simple (and mostly preferred) method is to use the keyword  in :  \"test\" in \"testtext\" True  \"abc\" in \"abcdefg\" True  \"abc\" in \"Abc\" False  \"ABC\" in \"abc\" False  \"abc\" in \"def\" False  \"abc\" in [\"abc\", \"def\", \"ghi\"] True     There are some string methods as well:  \"xxabcxx\".find(\"abc\") 2 #returns the index of the first match  \"xxabcxx\".find(\"cde\") -1 #returns -1 if the substring  #could not be found in the string  # and:  \"xxabcxx\".index(\"abc\") 2  \"xxabcxx\".index(\"cde\") ValueError: substring not found #raises ValueError...   About performance:  In general in is the fasted method to find a substring...   find is slightly faster than index    Hope I could help!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "3984", "A_Content": "  if not a:   print(\"List is empty\")   Using the implicit booleanness of the empty list is quite pythonic.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "881", "A_Content": "  The pythonic way to do it is from the PEP 8 style guide (where Yes means \u201crecommended\u201d and No means \u201cnot recommended\u201d):     For sequences, (strings, lists, tuples), use the fact that empty sequences are false.     Yes: if not seq:      if seq:  No:  if len(seq):      if not len(seq):       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "534", "A_Content": "  I prefer it explicitly:  if len(li) == 0:     print('the list is empty')   This way it's 100% clear that li is a sequence (list) and we want to test its size. My problem with if not li: ... is that it gives the false impression that li is a boolean variable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "214", "A_Content": "  Other people seem to be generalizing the question beyond just lists, so I thought I'd add a caveat for a different type of sequence that a lot of people might use, especially since this is the first google hit for \"python test empty array\".  Other methods don't work for numpy arrays  You need to be careful with numpy arrays, because other methods that work fine for lists or other standard containers fail for numpy arrays.  I explain why below, but in short, the preferred method is to use size.  The \"pythonic\" way doesn't work: Part 1  The \"pythonic\" way fails with numpy arrays because numpy tries to cast the array to an array of bools, and if x tries to evaluate all of those bools at once for some kind of aggregate truth value.  But this doesn't make any sense, so you get a ValueError:  >>> x = numpy.array([0,1]) >>> if x: print(\"x\") ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()   The \"pythonic\" way doesn't work: Part 2  But at least the case above tells you that it failed.  If you happen to have a numpy array with exactly one element, the if statement will \"work\", in the sense that you don't get an error.  However, if that one element happens to be 0 (or 0.0, or false, ...), the if statement will incorrectly result in false:  >>> x = numpy.array([0,]) >>> if x: print(\"x\") ... else: print(\"No x\") No x   But clearly x exists and is not empty!  This result is not what you wanted.  Using len can give unexpected results  For example,  len( numpy.zeros((1,0)) )   returns 1, even though the array has zero elements.  The numpythonic way  As explained in the scipy FAQ, the correct method in all cases where you know you have a numpy array is to use if x.size:  >>> x = numpy.array([0,1]) >>> if x.size: print(\"x\") x  >>> x = numpy.array([0,]) >>> if x.size: print(\"x\") ... else: print(\"No x\") x  >>> x = numpy.zeros((1,0)) >>> if x.size: print(\"x\") ... else: print(\"No x\") No x   If you're not sure whether it might be a list, a numpy array, or something else, you could combine this approach with the answer @dubiousjim gives to make sure the right test is used for each type.  Not very \"pythonic\", but it turns out that numpy intentionally broke pythonicity in at least this sense.  If you need to do more than just check if the input is empty, and you're using other numpy features like indexing or math operations, it's probably more efficient (and certainly more common) to force the input to be a numpy array.  There are a few nice functions for doing this quickly \u2014\u00a0most importantly numpy.asarray.  This takes your input, does nothing if it's already an array, or wraps your input into an array if it's a list, tuple, etc., and optionally converts it to your chosen dtype.  So it's very quick whenever it can be, and it ensures that you just get to assume the input is a numpy array.  We usually even just use the same name, as the conversion to an array won't make it back outside of the current scope:  x = numpy.asarray(x, dtype=numpy.double)   This will make the x.size check work in all cases I see on this page.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "107", "A_Content": "  An empty list is itself considered false in true value testing (see python documentation):  a = [] if a:      print \"not empty\"   @Daren Thomas     EDIT: Another point against testing   the empty list as False: What about   polymorphism? You shouldn't depend on   a list being a list. It should just   quack like a duck - how are you going   to get your duckCollection to quack   ''False'' when it has no elements?   Your duckCollection should implement __nonzero__ or __len__ so the if a: will work without problems.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "90", "A_Content": "     Best way to check if a list is empty      For example, if passed the following:  a = []       How do I check to see if a is empty?   Short Answer:  Place the list in a boolean context (for example, with an if or while statement). It will test False if it is empty, and True otherwise. For example:  if not a:                           # do this!     print('a is an empty list')   Appeal to Authority  PEP 8, the official Python style guide for Python code in Python's standard library, asserts:     For sequences, (strings, lists, tuples), use the fact that empty sequences are false.  Yes: if not seq:      if seq:  No: if len(seq):     if not len(seq):    We should expect that standard library code should be as performant and correct as possible. But why is that the case, and why do we need this guidance?  Explanation  I frequently see code like this from experienced programmers new to Python:  if len(a) == 0:                     # Don't do this!     print('a is an empty list')   And users of lazy languages may be tempted to do this:  if a == []:                         # Don't do this!     print('a is an empty list')   These are correct in their respective other languages. And this is even semantically correct in Python.   But we consider it un-Pythonic because Python supports these semantics directly in the list object's interface via boolean coercion.  From the docs (and note specifically the inclusion of the empty list, []):     By default, an object is considered true unless its class defines   either a __bool__() method that returns False or a __len__() method   that returns zero, when called with the object. Here are most of the built-in objects considered false:         constants defined to be false: None and False.   zero of any numeric type: 0, 0.0, 0j, Decimal(0), Fraction(0, 1)   empty sequences and collections: '', (), [], {}, set(), range(0)      And the datamodel documentation:     object.__bool__(self)      Called to implement truth value testing and the built-in operation bool(); should return False or True. When this method is not defined,   __len__() is called, if it is defined, and the object is considered true if its result is nonzero. If a class defines neither __len__()   nor __bool__(), all its instances are considered true.   and      object.__len__(self)      Called to implement the built-in function len(). Should return the length of the object, an integer >= 0. Also, an object that doesn\u2019t define a __bool__() method and whose __len__() method returns zero is considered to be false in a Boolean context.   So instead of this:  if len(a) == 0:                     # Don't do this!     print('a is an empty list')   or this:  if a == []:                     # Don't do this!     print('a is an empty list')   Do this:  if not a:     print('a is an empty list')   Doing what's Pythonic usually pays off in performance:  Does it pay off? (Note that less time to perform an equivalent operation is better:)  >>> import timeit >>> min(timeit.repeat(lambda: len([]) == 0, repeat=100)) 0.13775854044661884 >>> min(timeit.repeat(lambda: [] == [], repeat=100)) 0.0984637276455409 >>> min(timeit.repeat(lambda: not [], repeat=100)) 0.07878462291455435   For scale, here's the cost of calling the function and constructing and returning an empty list, which you might subtract from the costs of the emptiness checks used above:  >>> min(timeit.repeat(lambda: [], repeat=100)) 0.07074015751817342   We see that either checking for length with the builtin function len compared to 0 or checking against an empty list is much less performant than using the builtin syntax of the language as documented.  Why?  For the len(a) == 0 check:  First Python has to check the globals to see if len is shadowed.   Then it must call the function, load 0, and do the equality comparison in Python (instead of with C):  >>> import dis >>> dis.dis(lambda: len([]) == 0)   1           0 LOAD_GLOBAL              0 (len)               2 BUILD_LIST               0               4 CALL_FUNCTION            1               6 LOAD_CONST               1 (0)               8 COMPARE_OP               2 (==)              10 RETURN_VALUE   And for the [] == [] it has to build an unnecessary list and then, again, do the comparison operation in Python's virtual machine (as opposed to C)  >>> dis.dis(lambda: [] == [])   1           0 BUILD_LIST               0               2 BUILD_LIST               0               4 COMPARE_OP               2 (==)               6 RETURN_VALUE   The \"Pythonic\" way is a much simpler and faster check since the length of the list is cached in the object instance header:  >>> dis.dis(lambda: not [])   1           0 BUILD_LIST               0               2 UNARY_NOT               4 RETURN_VALUE   Evidence from the C source and documentation     PyVarObject      This is an extension of PyObject that adds the ob_size field. This is only used for objects that have some notion of length. This type does not often appear in the Python/C API. It corresponds to the fields defined by the expansion of the PyObject_VAR_HEAD macro.   From the c source in Include/listobject.h:  typedef struct {     PyObject_VAR_HEAD     /* Vector of pointers to list elements.  list[0] is ob_item[0], etc. */     PyObject **ob_item;      /* ob_item contains space for 'allocated' elements.  The number      * currently in use is ob_size.      * Invariants:      *     0 <= ob_size <= allocated      *     len(list) == ob_size   I have enjoyed researching this and I spend a lot of time curating my answers. If you think I'm leaving something out, please let me know in a comment.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "81", "A_Content": "  Patrick's (accepted) answer is right: if not a: is the right way to do it. Harley Holcombe's answer is right that this is in the PEP 8 style guide. But what none of the answers explain is why it's a good idea to follow the idiom\u2014even if you personally find it's not explicit enough or confusing to Ruby users or whatever.  Python code, and the Python community, has very strong idioms. Following those idioms makes your code easier to read for anyone experienced in Python. And when you violate those idioms, that's a strong signal.  It's true that if not a: doesn't distinguish empty lists from None, or numeric 0, or empty tuples, or empty user-created collection types, or empty user-created not-quite-collection types, or single-element NumPy array acting as scalars with falsey values, etc. And sometimes it's important to be explicit about that. And in that case, you know what you want to be explicit about, so you can test for exactly that. For example, if not a and a is not None: means \"anything falsey except None\", while if len(a) != 0: means \"only empty sequences\u2014and anything besides a sequence is an error here\", and so on. Besides testing for exactly what you want to test, this also signals to the reader that this test is important.  But when you don't have anything to be explicit about, anything other than if not a: is misleading the reader. You're signaling something as important when it isn't. (You may also be making the code less flexible, or slower, or whatever, but that's all less important.) And if you habitually mislead the reader like this, then when you do need to make a distinction, it's going to pass unnoticed because you've been \"crying wolf\" all over your code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "64", "A_Content": "  I have seen the below as preferred:  if not a:     print(\"The list is empty or null\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "53", "A_Content": "  Why check at all?  No one seems to have addressed questioning your need to test the list in the first place.  Because you provided no additional context, I can imagine that you may not need to do this check in the first place, but are unfamiliar with list processing in Python.  I would argue that the most pythonic way is to not check at all, but rather to just process the list.  That way it will do the right thing whether empty or full.  a = []  for item in a:     <do something with item>  <rest of code>   This has the benefit of handling any contents of a, while not requiring a specific check for emptiness.  If a is empty, the dependent block will not execute and the interpreter will fall through to the next line.  If you do actually need to check the array for emptiness, the other answers are sufficient.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "46", "A_Content": "  len() is an O(1) operation for Python lists, strings, dicts, and sets. Python internally keeps track of the number of elements in these containers.  JavaScript has a similar notion of truthy/falsy.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "29", "A_Content": "  I had written:  if isinstance(a, (list, some, other, types, i, accept)) and not a:     do_stuff   which was voted -1. I'm not sure if that's because readers objected to the strategy or thought the answer wasn't helpful as presented. I'll pretend it was the latter, since---whatever counts as \"pythonic\"---this is the correct strategy. Unless you've already ruled out, or are prepared to handle cases where a is, for example, False, you need a test more restrictive than just if not a:. You could use something like this:  if isinstance(a, numpy.ndarray) and not a.size:     do_stuff elif isinstance(a, collections.Sized) and not a:     do_stuff   the first test is in response to @Mike's answer, above. The third line could also be replaced with:  elif isinstance(a, (list, tuple)) and not a:   if you only want to accept instances of particular types (and their subtypes), or with:  elif isinstance(a, (list, tuple)) and not len(a):   You can get away without the explicit type check, but only if the surrounding context already assures you that a is a value of the types you're prepared to handle, or if you're sure that types you're not prepared to handle are going to raise errors (e.g., a TypeError if you call len on a value for which it's undefined) that you're prepared to handle. In general, the \"pythonic\" conventions seem to go this last way. Squeeze it like a duck and let it raise a DuckError if it doesn't know how to quack. You still have to think about what type assumptions you're making, though, and whether the cases you're not prepared to handle properly really are going to error out in the right places. The Numpy arrays are a good example where just blindly relying on len or the boolean typecast may not do precisely what you're expecting.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "25", "A_Content": "  Python is very uniform about the treatment of emptiness. Given the following:  a = []  . . .  if a:    print(\"List is not empty.\") else:    print(\"List is empty.\")   You simply check list a with an \"if\" statement to see if it is empty.  From what I have read and been taught, this is the \"Pythonic\" way to see if a list or tuple is empty.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "19", "A_Content": "  From documentation on truth value testing:  All values other than what is listed here are considered True   None False zero of any numeric type, for example, 0, 0.0, 0j. any empty sequence, for example, '', (), []. any empty mapping, for example, {}. instances of user-defined classes, if the class defines a __bool__() or __len__() method, when that method returns the integer zero or bool value False.   As can be seen, empty list [] is falsy, so doing what would be done to a boolean value sounds most efficient:  if not a:     print('\"a\" is empty!')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "19", "A_Content": "  Some methods that I use:  if not a:     print \"list is empty\"   if len(a) == 0:     print \"list is empty\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "16", "A_Content": "  Here are a few ways you can check if a list is empty:  a = [] #the list   1) The pretty simple pythonic way:  if not a:     print(\"a is empty\")   In Python, empty containers such as lists,tuples,sets,dicts,variables etc are seen as False. One could simply treat the list as a predicate (returning a Boolean value). And  a True value would indicate that it's non-empty.  2) A much explicit way: using the len() to find the length and check if it equals to 0:  if len(a) == 0:     print(\"a is empty\")   3) Or comparing it to an anonymous empty list:  if a == []:     print(\"a is empty\")   4) Another yet silly way to do is using exception and iter():  try:     next(iter(a))     # list has elements except StopIteration:     print(\"Error: a is empty\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "9", "A_Content": "  I prefer the following:  if a == []:    print \"The list is empty.\"   Readable and you don't have to worry about calling a function like len() to iterate through the variable. Although I'm not entirely sure what the BigO notation of something like this is... but Python's so blazingly fast I doubt it'd matter unless a was gigantic.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "6", "A_Content": "  def list_test (L):     if   L is None  : print 'list is None'     elif not L      : print 'list is empty'     else: print 'list has %d elements' % len(L)  list_test(None) list_test([]) list_test([1,2,3])   It is sometimes good to test for None and for emptiness separately as those are two different states. The code above produces the following output:  list is None  list is empty  list has 3 elements   Although it's worth nothing that None is falsy. So if you don't want to separate test for None-ness, you don't have to do that.   def list_test2 (L):     if not L      : print 'list is empty'     else: print 'list has %d elements' % len(L)  list_test2(None) list_test2([]) list_test2([1,2,3])   produces expected  list is empty list is empty list has 3 elements      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "2", "A_Content": "  Another simple way could be  a = [] if len(a) == 0:   print(\"Empty\") else:   print(\" Not empty\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "1", "A_Content": "  You can even try using bool() like this      a = [1,2,3];     print bool(a); # it will return True     a = [];     print bool(a); # it will return False   I love this way for checking list is empty or not.   Very handy and useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "1", "A_Content": "  Being inspired by @dubiousjim's solution, I propose to use an additional general check of whether is it something iterable  import collections def is_empty(a):     return not a and isinstance(a, collections.Iterable)   Note: a string is considered to be iterable. - add and not isinstance(a,(str,unicode)) if you want the empty string to be excluded  Test:  >>> is_empty('sss') False >>> is_empty(555) False >>> is_empty(0) False >>> is_empty('') True >>> is_empty([3]) False >>> is_empty([]) True >>> is_empty({}) True >>> is_empty(()) True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "1", "A_Content": "  If you want to check if list is empty;  l = [] if l:     # do your stuff.   If you want to check weather all the values in list is empty.  l = [\"\", False, 0, '', [], {}, ()] if all(bool(x) for x in l):     # do your stuff.   However this will be True for empty list.  def empty_list(lst):     if len(lst) ==0:         return false     else:         return all(bool(x) for x in l)   Now you can use:  if empty_list(lst):     # do your stuff.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "0", "A_Content": "  Simply use is_empty() or make function like:-   def is_empty(any_structure):     if any_structure:         print('Structure is not empty.')         return True     else:         print('Structure is empty.')         return False     It can be used for any data_structure like a list,tuples, dictionary and many more. By these, you can call it many times using just is_empty(any_structure).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "0", "A_Content": "  The truth value of an empty list is False whereas for a non-empty list it is True.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "-1", "A_Content": "  An unofficial approach :   a = []  try:   print(a[-1])  except IndexError:   print(\"List is empty\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "-2", "A_Content": "  Look at the following code executed on Python interactive terminal.  >>> a = [] >>> if a: ...     print \"List is not empty\"; ... else: ...     print \"List is empty\" ...  List is empty >>>  >>> a = [1, 4, 9] >>> if a: ...     print \"List is not empty\"; ... else: ...     print \"List is empty\" ...  List is not empty >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53513/how-do-i-check-if-a-list-is-empty", "Language": "Python", "Q_Title": "How do I check if a list is empty?", "Q_Votes": "2797", "Q_Content": "    For example, if passed the following:  a = []   How do I check to see if a is empty?     ", "Tags": ["python", "list", "is-empty"], "A_Votes": "-2", "A_Content": "  You could just do:  lst = [] any(lst)   ##this returns False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "3768", "A_Content": "  I see two answers with good qualities, each with a small flaw, so I will give my take on it:  Try os.path.exists, and consider os.makedirs for the creation.  import os if not os.path.exists(directory):     os.makedirs(directory)   As noted in comments and elsewhere, there's a race condition - if the directory is created between the os.path.exists and the os.makedirs calls, the os.makedirs will fail with an OSError. Unfortunately, blanket-catching OSError and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.  One option would be to trap the OSError and examine the embedded error code (see Is there a cross-platform way of getting information from Python\u2019s OSError):  import os, errno  try:     os.makedirs(directory) except OSError as e:     if e.errno != errno.EEXIST:         raise   Alternatively, there could be a second os.path.exists, but suppose another created the directory after the first check, then removed it before the second one - we could still be fooled.   Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "843", "A_Content": "  Python 3.5+:  import pathlib pathlib.Path('/my/directory').mkdir(parents=True, exist_ok=True)    pathlib.Path.mkdir as used above recursively creates the directory and does not raise an exception if the directory already exists. If you don't need or want the parents to be created, skip the parents argument.  Python 3.2+:  Using pathlib:  If you can, install the current pathlib backport named pathlib2. Do not install the older unmaintained backport named pathlib. Next, refer to the Python 3.5+ section above and use it the same.  If using Python 3.4, even though it comes with pathlib, it is missing the useful exist_ok option. The backport is intended to offer a newer and superior implementation of mkdir which includes this missing option.  Using os:  import os os.makedirs(path, exist_ok=True)   os.makedirs as used above recursively creates the directory and does not raise an exception if the directory already exists. It has the optional exist_ok argument only if using Python 3.2+, with a default value of False. This argument does not exist in Python 2.x up to 2.7. As such, there is no need for manual exception handling as with Python 2.7.  Python 2.7+:  Using pathlib:  If you can, install the current pathlib backport named pathlib2. Do not install the older unmaintained backport named pathlib. Next, refer to the Python 3.5+ section above and use it the same.  Using os:  import os try:      os.makedirs(path) except OSError:     if not os.path.isdir(path):         raise   While a naive solution may first use os.path.isdir followed by os.makedirs, the solution above reverses the order of the two operations. In doing so, it prevents a common race condition having to do with a duplicated attempt at creating the directory, and also disambiguates files from directories.  Note that capturing the exception and using errno is of limited usefulness because OSError: [Errno 17] File exists, i.e. errno.EEXIST, is raised for both files and directories. It is more reliable simply to check if the directory exists.  Alternative:  mkpath creates the nested directory, and does nothing if the directory already exists. This works in both Python 2 and 3.  import distutils.dir_util distutils.dir_util.mkpath(path)   Per Bug 10948, a severe limitation of this alternative is that it works only once per python process for a given path. In other words, if you use it to create a directory, then delete the directory from inside or outside Python, then use mkpath again to recreate the same directory, mkpath will simply silently use its invalid cached info of having previously created the directory, and will not actually make the directory again. In contrast, os.makedirs doesn't rely on any such cache. This limitation may be okay for some applications.    With regard to the directory's mode, please refer to the documentation if you care about it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "577", "A_Content": "  Using try except and the right error code from errno module gets rid of the race condition and is cross-platform:  import os import errno  def make_sure_path_exists(path):     try:         os.makedirs(path)     except OSError as exception:         if exception.errno != errno.EEXIST:             raise   In other words, we try to create the directories, but if they already exist we ignore the error. On the other hand, any other error gets reported. For example, if you create dir 'a' beforehand and remove all permissions from it, you will get an OSError raised with errno.EACCES (Permission denied, error 13).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "87", "A_Content": "  I would personally recommend that you use os.path.isdir() to test instead of os.path.exists().  >>> os.path.exists('/tmp/dirname') True >>> os.path.exists('/tmp/dirname/filename.etc') True >>> os.path.isdir('/tmp/dirname/filename.etc') False >>> os.path.isdir('/tmp/fakedirname') False   If you have:  >>> dir = raw_input(\":: \")   And a foolish user input:  :: /tmp/dirname/filename.etc   ... You're going to end up with a directory named filename.etc when you pass that argument to os.makedirs() if you test with os.path.exists().     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "58", "A_Content": "  Check os.makedirs:  (It makes sure the complete path exists.)  To handle the fact the directory might exist, catch OSError. (If exist_ok is False (the default), an OSError is raised if the target directory already exists.)  import os try:     os.makedirs('./path/to/somewhere') except OSError:     pass      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "30", "A_Content": "  Insights on the specifics of this situation  You give a particular file at a certain path and you pull the directory from the file path. Then after making sure you have the directory, you attempt to open a file for reading. To comment on this code:   filename = \"/my/directory/filename.txt\" dir = os.path.dirname(filename)    We want to avoid overwriting the builtin function, dir. Also, filepath or perhaps fullfilepath is probably a better semantic name than filename so this would be better written:  import os filepath = '/my/directory/filename.txt' directory = os.path.dirname(filepath)   Your end goal is to open this file, you initially state, for writing, but you're essentially approaching this goal (based on your code) like this, which opens the file for reading:   if not os.path.exists(directory):     os.makedirs(directory) f = file(filename)    Assuming opening for reading  Why would you make a directory for a file that you expect to be there and be able to read?   Just attempt to open the file.  with open(filepath) as my_file:     do_stuff(my_file)   If the directory or file isn't there, you'll get an IOError with an associated error number: errno.ENOENT will point to the correct error number regardless of your platform. You can catch it if you want, for example:  import errno try:     with open(filepath) as my_file:         do_stuff(my_file) except IOError as error:     if error.errno == errno.ENOENT:         print 'ignoring error because directory or file is not there'     else:         raise   Assuming we're opening for writing  This is probably what you're wanting.  In this case, we probably aren't facing any race conditions. So just do as you were, but note that for writing, you need to open with the w mode (or a to append). It's also a Python best practice to use the context manager for opening files.  import os if not os.path.exists(directory):     os.makedirs(directory) with open(filepath, 'w') as my_file:     do_stuff(my_file)   However, say we have several Python processes that attempt to put all their data into the same directory. Then we may have contention over creation of the directory. In that case it's best to wrap the makedirs call in a try-except block.  import os import errno if not os.path.exists(directory):     try:         os.makedirs(directory)     except OSError as error:         if error.errno != errno.EEXIST:             raise with open(filepath, 'w') as my_file:     do_stuff(my_file)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "29", "A_Content": "  Starting from Python 3.5, pathlib.Path.mkdir has an exist_ok flag:  from pathlib import Path path = Path('/my/directory/filename.txt') path.parent.mkdir(parents=True, exist_ok=True)  # path.parent ~ os.path.dirname(path)   This recursively creates the directory and does not raise an exception if the directory already exists.  (just as os.makedirs got an exists_ok flag starting from python 3.2).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "23", "A_Content": "  I have put the following down. It's not totally foolproof though.  import os  dirname = 'create/me'  try:     os.makedirs(dirname) except OSError:     if os.path.exists(dirname):         # We are nearly safe         pass     else:         # There was an error on creation, so make sure we know about it         raise   Now as I say, this is not really foolproof, because we have the possiblity of failing to create the directory, and another process creating it during that period.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "23", "A_Content": "  Try the os.path.exists function  if not os.path.exists(dir):     os.mkdir(dir)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "16", "A_Content": "     Check if a directory exists and create it if necessary?   The direct answer to this is, assuming a simple situation where you don't expect other users or processes to be messing with your directory:  if not os.path.exists(d):     os.makedirs(d)   or if making the directory is subject to race conditions (i.e. if after checking the path exists, something else may have already made it) do this:  import errno try:     os.makedirs(d) except OSError as exception:     if exception.errno != errno.EEXIST:         raise   But perhaps an even better approach is to sidestep the resource contention issue, by using temporary directories via tempfile:  import tempfile  d = tempfile.mkdtemp()   Here's the essentials from the online doc:   mkdtemp(suffix='', prefix='tmp', dir=None)     User-callable function to create and return a unique temporary     directory.  The return value is the pathname of the directory.      The directory is readable, writable, and searchable only by the     creating user.      Caller is responsible for deleting the directory when done with it.    New in Python 3.5: pathlib.Path with exist_ok  There's a new Path object (as of 3.4) with lots of methods one would want to use with paths - one of which is mkdir.  (For context, I'm tracking my weekly rep with a script. Here's the relevant parts of code from the script that allow me to avoid hitting Stack Overflow more than once a day for the same data.)  First the relevant imports:  from pathlib import Path import tempfile   We don't have to deal with os.path.join now - just join path parts with a /:  directory = Path(tempfile.gettempdir()) / 'sodata'   Then I idempotently ensure the directory exists - the exist_ok argument shows up in Python 3.5:  directory.mkdir(exist_ok=True)   Here's the relevant part of the documentation:     If exist_ok is true, FileExistsError exceptions will be ignored (same behavior as the POSIX mkdir -p command), but only if the last path component is not an existing non-directory file.   Here's a little more of the script - in my case, I'm not subject to a race condition, I only have one process that expects the directory (or contained files) to be there, and I don't have anything trying to remove the directory.   todays_file = directory / str(datetime.datetime.utcnow().date()) if todays_file.exists():     logger.info(\"todays_file exists: \" + str(todays_file))     df = pd.read_json(str(todays_file))   Path objects have to be coerced to str before other APIs that expect str paths can use them.  Perhaps Pandas should be updated to accept instances of the abstract base class, os.PathLike.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "15", "A_Content": "  In Python 3.4 you can also use the brand new pathlib module:  from pathlib import Path path = Path(\"/my/directory/filename.txt\") try:     if not path.parent.exists():         path.parent.mkdir(parents=True) except OSError:     # handle error; you can also catch specific errors like     # FileExistsError and so on.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "8", "A_Content": "  The relevant Python documentation suggests the use of the EAFP coding style (Easier to Ask for Forgiveness than Permission). This means that the code  try:     os.makedirs(path) except OSError as exception:     if exception.errno != errno.EEXIST:         raise     else:         print \"\\nBE CAREFUL! Directory %s already exists.\" % path   is better than the alternative  if not os.path.exists(path):     os.makedirs(path) else:     print \"\\nBE CAREFUL! Directory %s already exists.\" % path   The documentation suggests this exactly because of the race condition discussed in this question. In addition, as others mention here, there is a performance advantage in querying once instead of twice the OS. Finally, the argument placed forward, potentially, in favour of the second code in some cases --when the developer knows the environment the application is running-- can only be advocated in the special case that the program has set up a private environment for itself (and other instances of the same program).  Even in that case, this is a bad practice and can lead to long useless debugging. For example, the fact we set the permissions for a directory should not leave us with the impression permissions are set appropriately for our purposes. A parent directory could be mounted with other permissions. In general, a program should always work correctly and the programmer should not expect one specific environment.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "7", "A_Content": "  You can use mkpath  # Create a directory and any missing ancestor directories.  # If the directory already exists, do nothing.  from distutils.dir_util import mkpath mkpath(\"test\")       Note that it will create the ancestor directories as well.   It works for Python 2 and 3.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "6", "A_Content": "  In Python3, os.makedirs supports setting exist_ok. The default setting is False, which means an OSError will be raised if the target directory already exists. By setting exist_ok to True, OSError (directory exists) will be ignored and the directory will not be created.  os.makedirs(path,exist_ok=True)   In Python2, os.makedirs doesn't support setting exist_ok. You can use the approach in heikki-toivonen's answer:  import os import errno  def make_sure_path_exists(path):     try:         os.makedirs(path)     except OSError as exception:         if exception.errno != errno.EEXIST:             raise      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "5", "A_Content": "  For a one-liner solution, you can use IPython.utils.path.ensure_dir_exists():  from IPython.utils.path import ensure_dir_exists ensure_dir_exists(dir)   From the documentation: Ensure that a directory exists. If it doesn\u2019t exist, try to create it and protect against a race condition if another process is doing the same.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "5", "A_Content": "  I use os.path.exists(), here is a Python 3 script that can be used to check if a directory exists, create one if it does not exist, and delete it if it does exist (if desired).  It prompts users for input of the directory and can be easily modified.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "4", "A_Content": "  I found this Q/A and I was initially puzzled by some of the failures and errors I was getting. I am working in Python 3 (v.3.5 in an Anaconda virtual environment on an Arch Linux x86_64 system).  Consider this directory structure:  \u2514\u2500\u2500 output/         ## dir    \u251c\u2500\u2500 corpus       ## file    \u251c\u2500\u2500 corpus2/     ## dir    \u2514\u2500\u2500 subdir/      ## dir   Here are my experiments/notes, which clarifies things:  # ---------------------------------------------------------------------------- # [1] https://stackoverflow.com/questions/273192/how-can-i-create-a-directory-if-it-does-not-exist  import pathlib  \"\"\" Notes:         1.  Include a trailing slash at the end of the directory path             (\"Method 1,\" below).         2.  If a subdirectory in your intended path matches an existing file             with same name, you will get the following error:             \"NotADirectoryError: [Errno 20] Not a directory:\" ... \"\"\" # Uncomment and try each of these \"out_dir\" paths, singly:  # ---------------------------------------------------------------------------- # METHOD 1: # Re-running does not overwrite existing directories and files; no errors.  # out_dir = 'output/corpus3'                ## no error but no dir created (missing tailing /) # out_dir = 'output/corpus3/'               ## works # out_dir = 'output/corpus3/doc1'           ## no error but no dir created (missing tailing /) # out_dir = 'output/corpus3/doc1/'          ## works # out_dir = 'output/corpus3/doc1/doc.txt'   ## no error but no file created (os.makedirs creates dir, not files!  ;-) # out_dir = 'output/corpus2/tfidf/'         ## fails with \"Errno 20\" (existing file named \"corpus2\") # out_dir = 'output/corpus3/tfidf/'         ## works # out_dir = 'output/corpus3/a/b/c/d/'       ## works  # [2] https://docs.python.org/3/library/os.html#os.makedirs  # Uncomment these to run \"Method 1\":  #directory = os.path.dirname(out_dir) #os.makedirs(directory, mode=0o777, exist_ok=True)  # ---------------------------------------------------------------------------- # METHOD 2: # Re-running does not overwrite existing directories and files; no errors.  # out_dir = 'output/corpus3'                ## works # out_dir = 'output/corpus3/'               ## works # out_dir = 'output/corpus3/doc1'           ## works # out_dir = 'output/corpus3/doc1/'          ## works # out_dir = 'output/corpus3/doc1/doc.txt'   ## no error but creates a .../doc.txt./ dir # out_dir = 'output/corpus2/tfidf/'         ## fails with \"Errno 20\" (existing file named \"corpus2\") # out_dir = 'output/corpus3/tfidf/'         ## works # out_dir = 'output/corpus3/a/b/c/d/'       ## works  # Uncomment these to run \"Method 2\":  #import os, errno #try: #       os.makedirs(out_dir) #except OSError as e: #       if e.errno != errno.EEXIST: #               raise # ----------------------------------------------------------------------------   Conclusion: in my opinion, \"Method 2\" is more robust.  [1] How can I create a directory if it does not exist?  [2] https://docs.python.org/3/library/os.html#os.makedirs     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "4", "A_Content": "  I saw Heikki Toivonen and A-B-B's answers and thought of this variation.  import os import errno  def make_sure_path_exists(path):     try:         os.makedirs(path)     except OSError as exception:         if exception.errno != errno.EEXIST or not os.path.isdir(path):             raise      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "3", "A_Content": "  You can use os.listdir for this:  import os if 'dirName' in os.listdir('parentFolderPath')     print('Directory Exists')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "3", "A_Content": "  When working with file I/O, the important thing to consider is  TOCTTOU (time of check to time of use)  So doing a check with if and then reading or writing later may end up in an unhandled I/O exception. The best way to do it is:  try:     os.makedirs(dir_path) except OSError as e:     if e.errno != errno.EEXIS:         raise      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "1", "A_Content": "  If you consider the following:   os.path.isdir('/tmp/dirname')   means a directory (path) exists AND is a directory. So for me this way does what I need. So I can make sure it is folder (not a file) and exists.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "0", "A_Content": "  Use this command check and create dir   if not os.path.isdir(test_img_dir):      os.mkdir(str(\"./\"+test_img_dir))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "0", "A_Content": "  Call the function create_dir() at the entry point of your program/project.  import os  def create_dir(directory):     if not os.path.exists(directory):         print('Creating Directory '+directory)         os.makedirs(directory)  create_dir('Project directory')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "0", "A_Content": "  Why not use subprocess module if running on a machine that supports shell languages?  Works on python 2.7 and python 3.6  from subprocess import call call(['mkdir', '-p', 'path1/path2/path3'])   Should do the trick on most systems.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python", "Language": "Python", "Q_Title": "How can I safely create a nested directory in Python?", "Q_Votes": "3050", "Q_Content": "    What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:  import os  file_path = \"/my/directory/filename.txt\" directory = os.path.dirname(file_path)  try:     os.stat(directory) except:     os.mkdir(directory)         f = file(filename)   Somehow, I missed os.path.exists (thanks kanja, Blair, and Douglas). This is what I have now:  def ensure_dir(file_path):     directory = os.path.dirname(file_path)     if not os.path.exists(directory):         os.makedirs(directory)   Is there a flag for \"open\", that makes this happen automatically?     ", "Tags": ["python", "exception", "path", "directory", "operating-system"], "A_Votes": "-2", "A_Content": "  import os if os.path.isfile(filename):     print \"file exists\" else:     \"Your code here\"      Where your code here is use the (touch) command   This will check if the file is there if it is not then it will create it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "3599", "A_Content": "  It is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list\u2014probably a list of tuples.  For instance,  import operator x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0} sorted_x = sorted(x.items(), key=operator.itemgetter(1))   sorted_x will be a list of tuples sorted by the second element in each tuple. dict(sorted_x) == x.  And for those wishing to sort on keys instead of values:  import operator x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0} sorted_x = sorted(x.items(), key=operator.itemgetter(0))   In Python3 since unpacking is not allowed [1] we can use   x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0} sorted_by_value = sorted(x.items(), key=lambda kv: kv[1])      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "977", "A_Content": "  As simple as: sorted(dict1, key=dict1.get)  Well, it is actually possible to do a \"sort by dictionary values\". Recently I had to do that in a Code Golf (Stack Overflow question Code golf: Word frequency chart). Abridged, the problem was of the kind: given a text, count how often each word is encountered and display a list of the top words, sorted by decreasing frequency.   If you construct a dictionary with the words as keys and the number of occurrences of each word as value, simplified here as:  from collections import defaultdict d = defaultdict(int) for w in text.split():   d[w] += 1   then you can get a list of the words, ordered by frequency of use with sorted(d, key=d.get) - the sort iterates over the dictionary keys, using the number of word occurrences as a sort key .   for w in sorted(d, key=d.get, reverse=True):   print w, d[w]   I am writing this detailed explanation to illustrate what people often mean by \"I can easily sort a dictionary by key, but how do I sort by value\" - and I think the OP was trying to address such an issue. And the solution is to do sort of list of the keys, based on the values, as shown above.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "612", "A_Content": "  You could use:  sorted(d.items(), key=lambda x: x[1])  This will sort the dictionary by the values of each entry within the dictionary from smallest to largest.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "170", "A_Content": "  Dicts can't be sorted, but you can build a sorted list from them.  A sorted list of dict values:  sorted(d.values())   A list of (key, value) pairs, sorted by value:  from operator import itemgetter sorted(d.items(), key=itemgetter(1))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "130", "A_Content": "  In recent Python 2.7, we have the new OrderedDict type, which remembers the order in which the items were added.  >>> d = {\"third\": 3, \"first\": 1, \"fourth\": 4, \"second\": 2}  >>> for k, v in d.items(): ...     print \"%s: %s\" % (k, v) ... second: 2 fourth: 4 third: 3 first: 1  >>> d {'second': 2, 'fourth': 4, 'third': 3, 'first': 1}   To make a new ordered dictionary from the original, sorting by the values:  >>> from collections import OrderedDict >>> d_sorted_by_value = OrderedDict(sorted(d.items(), key=lambda x: x[1]))   The OrderedDict behaves like a normal dict:  >>> for k, v in d_sorted_by_value.items(): ...     print \"%s: %s\" % (k, v) ... first: 1 second: 2 third: 3 fourth: 4  >>> d_sorted_by_value OrderedDict([('first': 1), ('second': 2), ('third': 3), ('fourth': 4)])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "77", "A_Content": "  UPDATE: 5 DECEMBER 2015 using Python 3.5  Whilst I found the accepted answer useful, I was also surprised that it hasn't been updated to reference OrderedDict from the standard library collections module as a viable, modern alternative - designed to solve exactly this type of problem.  from operator import itemgetter from collections import OrderedDict  x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0} sorted_x = OrderedDict(sorted(x.items(), key=itemgetter(1))) # OrderedDict([(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)])   The official OrderedDict documentation offers a very similar example too, but using a lambda for the sort function:  # regular unsorted dictionary d = {'banana': 3, 'apple':4, 'pear': 1, 'orange': 2}  # dictionary sorted by value OrderedDict(sorted(d.items(), key=lambda t: t[1])) # OrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "66", "A_Content": "  It can often be very handy to use namedtuple. For example, you have a dictionary of 'name' as keys and 'score' as values and you want to sort on 'score':  import collections Player = collections.namedtuple('Player', 'score name') d = {'John':5, 'Alex':10, 'Richard': 7}   sorting with lowest score first:  worst = sorted(Player(v,k) for (k,v) in d.items())   sorting with highest score first:  best = sorted([Player(v,k) for (k,v) in d.items()], reverse=True)   Now you can get the name and score of, let's say the second-best player (index=1) very Pythonically like this:  player = best[1] player.name     'Richard' player.score     7      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "59", "A_Content": "  Pretty much the same as Hank Gay's answer;        sorted([(value,key) for (key,value) in mydict.items()])    Or optimized a bit as suggested by  John Fouhy;        sorted((value,key) for (key,value) in mydict.items())       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "52", "A_Content": "  As of Python 3.6 the built-in dict will be ordered  Good news, so the OP's original use case of mapping pairs retrieved from a database with unique string ids as keys and numeric values as values into a built-in Python v3.6+ dict, should now respect the insert order.  If say the resulting two column table expressions from a database query like:  SELECT a_key, a_value FROM a_table ORDER BY a_value;   would be stored in two Python tuples, k_seq and v_seq (aligned by numerical index and with the same length of course), then:  k_seq = ('foo', 'bar', 'baz') v_seq = (0, 1, 42) ordered_map = dict(zip(k_seq, v_seq))   Allow to output later as:  for k, v in ordered_map.items():     print(k, v)   yielding in this case (for the new Python 3.6+ built-in dict!):  foo 0 bar 1 baz 42   in the same ordering per value of v.  Where in the Python 3.5 install on my machine it currently yields:  bar 1 foo 0 baz 42   Details:  As proposed in 2012 by Raymond Hettinger (cf. mail on python-dev with subject \"More compact dictionaries with faster iteration\") and now (in 2016) announced in a mail by Victor Stinner to python-dev with subject \"Python 3.6 dict becomes compact and gets a private version; and keywords become ordered\" due to the fix/implementation of issue 27350 \"Compact and ordered dict\" in Python 3.6 we will now be able, to use a built-in dict to maintain insert order!!  Hopefully this will lead to a thin layer OrderedDict implementation as a first step. As @JimFasarakis-Hilliard indicated, some see use cases for the OrderedDict type also in the future. I think the Python community at large will carefully inspect, if this will stand the test of time, and what the next steps will be.  Time to rethink our coding habits to not miss the possibilities opened by stable ordering of:   Keyword arguments and (intermediate) dict storage   The first because it eases dispatch in the implementation of functions and methods in some cases.  The second as it encourages to more easily use dicts as intermediate storage in processing pipelines.  Raymond Hettinger kindly provided documentation explaining \"The Tech Behind Python 3.6 Dictionaries\" - from his San Francisco Python Meetup Group presentation 2016-DEC-08.  And maybe quite some Stack Overflow high decorated question and answer pages will receive variants of this information and many high quality answers will require a per version update too.  Caveat Emptor (but also see below update 2017-12-15):  As @ajcr rightfully notes: \"The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon.\" (from the whatsnew36) not nit picking, but the citation was cut a bit pessimistic ;-). It continues as \" (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5).\"  So as in some human languages (e.g. German), usage shapes the language, and the will now has been declared ... in whatsnew36.  Update 2017-12-15:  In a mail to the python-dev list, Guido van Rossum declared:     Make it so. \"Dict keeps insertion order\" is the ruling. Thanks!    So, the version 3.6 CPython side-effect of dict insertion ordering is now becoming part of the language spec (and not anymore only an implementation detail). That mail thread also surfaced some distinguishing design goals for collections.OrderedDict as reminded by Raymond Hettinger during discussion.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "41", "A_Content": "  Given dictionary  e = {1:39, 4:34, 7:110, 2:87}   Sorting  sred = sorted(e.items(), key=lambda value: value[1])   Result   [(4, 34), (1, 39), (2, 87), (7, 110)]   You can use a lambda function to sort things up by value and store them processed inside a variable, in this case sred with e the original dictionary.  Hope that helps!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "37", "A_Content": "  I had the same problem, and I solved it like this:  WantedOutput = sorted(MyDict, key=lambda x : MyDict[x])    (People who answer \"It is not possible to sort a dict\" did not read the question! In fact, \"I can sort on the keys, but how can I sort based on the values?\" clearly means that he wants a list of the keys sorted according to the value of their values.)  Please notice that the order is not well defined (keys with the same value will be in an arbitrary order in the output list).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "31", "A_Content": "  In Python 2.7, simply do:  from collections import OrderedDict # regular unsorted dictionary d = {'banana': 3, 'apple':4, 'pear': 1, 'orange': 2}  # dictionary sorted by key OrderedDict(sorted(d.items(), key=lambda t: t[0])) OrderedDict([('apple', 4), ('banana', 3), ('orange', 2), ('pear', 1)])  # dictionary sorted by value OrderedDict(sorted(d.items(), key=lambda t: t[1])) OrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])   copy-paste from : http://docs.python.org/dev/library/collections.html#ordereddict-examples-and-recipes  Enjoy ;-)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "23", "A_Content": "  This is the code:  import operator origin_list = [     {\"name\": \"foo\", \"rank\": 0, \"rofl\": 20000},     {\"name\": \"Silly\", \"rank\": 15, \"rofl\": 1000},     {\"name\": \"Baa\", \"rank\": 300, \"rofl\": 20},     {\"name\": \"Zoo\", \"rank\": 10, \"rofl\": 200},     {\"name\": \"Penguin\", \"rank\": -1, \"rofl\": 10000} ] print \">> Original >>\" for foo in origin_list:     print foo  print \"\\n>> Rofl sort >>\" for foo in sorted(origin_list, key=operator.itemgetter(\"rofl\")):     print foo  print \"\\n>> Rank sort >>\" for foo in sorted(origin_list, key=operator.itemgetter(\"rank\")):     print foo   Here are the results:  Original  {'name': 'foo', 'rank': 0, 'rofl': 20000} {'name': 'Silly', 'rank': 15, 'rofl': 1000} {'name': 'Baa', 'rank': 300, 'rofl': 20} {'name': 'Zoo', 'rank': 10, 'rofl': 200} {'name': 'Penguin', 'rank': -1, 'rofl': 10000}   Rofl  {'name': 'Baa', 'rank': 300, 'rofl': 20} {'name': 'Zoo', 'rank': 10, 'rofl': 200} {'name': 'Silly', 'rank': 15, 'rofl': 1000} {'name': 'Penguin', 'rank': -1, 'rofl': 10000} {'name': 'foo', 'rank': 0, 'rofl': 20000}   Rank   {'name': 'Penguin', 'rank': -1, 'rofl': 10000} {'name': 'foo', 'rank': 0, 'rofl': 20000} {'name': 'Zoo', 'rank': 10, 'rofl': 200} {'name': 'Silly', 'rank': 15, 'rofl': 1000} {'name': 'Baa', 'rank': 300, 'rofl': 20}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "22", "A_Content": "  If values are numeric you may also use Counter from collections  from collections import Counter  x={'hello':1,'python':5, 'world':3} c=Counter(x) print c.most_common()   >> [('python', 5), ('world', 3), ('hello', 1)]          ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "20", "A_Content": "  Technically, dictionaries aren't sequences, and therefore can't be sorted. You can do something like  sorted(a_dictionary.values())   assuming performance isn't a huge deal.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "18", "A_Content": "  You can create an \"inverted index\", also  from collections import defaultdict inverse= defaultdict( list ) for k, v in originalDict.items():     inverse[v].append( k )   Now your inverse has the values; each value has a list of applicable keys.  for k in sorted(inverse):     print k, inverse[k]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "2895", "A_Content": "  os.listdir() will get you everything that's in a directory - files and directories.  If you want just files, you could either filter this down using os.path:  from os import listdir from os.path import isfile, join onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]   or you could use os.walk() which will yield two lists for each directory it visits - splitting into files and dirs for you. If you only want the top directory you can just break the first time it yields  from os import walk  f = [] for (dirpath, dirnames, filenames) in walk(mypath):     f.extend(filenames)     break   And lastly, as that example shows, adding one list to another you can either use .extend() or   >>> q = [1, 2, 3] >>> w = [4, 5, 6] >>> q = q + w >>> q [1, 2, 3, 4, 5, 6]   Personally, I prefer .extend()     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "18", "A_Content": "  You can use the collections.Counter. Note, this will work for both numeric and non-numeric values.  >>> x = {1: 2, 3: 4, 4:3, 2:1, 0:0} >>> from collections import Counter >>> #To sort in reverse order >>> Counter(x).most_common() [(3, 4), (4, 3), (1, 2), (2, 1), (0, 0)] >>> #To sort in ascending order >>> Counter(x).most_common()[::-1] [(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)] >>> #To get a dictionary sorted by values >>> from collections import OrderedDict >>> OrderedDict(Counter(x).most_common()[::-1]) OrderedDict([(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "18", "A_Content": "  Try the following approach. Let us define a dictionary called mydict with the following data:  mydict = {'carl':40,           'alan':2,           'bob':1,           'danny':3}   If one wanted to sort the dictionary by keys, one could do something like:  for key in sorted(mydict.iterkeys()):     print \"%s: %s\" % (key, mydict[key])   This should return the following output:  alan: 2 bob: 1 carl: 40 danny: 3   On the other hand, if one wanted to sort a dictionary by value (as is asked in the question), one could do the following:  for key, value in sorted(mydict.iteritems(), key=lambda (k,v): (v,k)):     print \"%s: %s\" % (key, value)   The result of this command (sorting the dictionary by value) should return the following:  bob: 1 alan: 2 danny: 3 carl: 40      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "14", "A_Content": "  You can use a skip dict which is a dictionary that's permanently sorted by value.  >>> data = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0} >>> SkipDict(data) {0: 0.0, 2: 1.0, 1: 2.0, 4: 3.0, 3: 4.0}   If you use keys(), values() or items() then you'll iterate in sorted order by value.  It's implemented using the skip list datastructure.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "14", "A_Content": "  This returns the list of key-value pairs in the dictionary, sorted by value from highest to lowest:  sorted(d.items(), key=lambda x: x[1], reverse=True)   For the dictionary sorted by key, use the following:  sorted(d.items(), reverse=True)   The return is a list of tuples because dictionaries themselves can't be sorted.  This can be both printed or sent into further computation.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "13", "A_Content": "  from django.utils.datastructures import SortedDict  def sortedDictByKey(self,data):     \"\"\"Sorted dictionary order by key\"\"\"     sortedDict = SortedDict()     if data:         if isinstance(data, dict):             sortedKey = sorted(data.keys())             for k in sortedKey:                 sortedDict[k] = data[k]     return sortedDict      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "12", "A_Content": "  You can also use custom function that can be passed to key.  def dict_val(x):     return x[1] x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0} sorted_x = sorted(x.items(), key=dict_val)   One more way to do is to use labmda function  x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0} sorted_x = sorted(x.items(), key=lambda t: t[1])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "9", "A_Content": "  Here is a solution using zip on d.values() and d.keys().  A few lines down this link (on Dictionary view objects) is:     This allows the creation of (value, key) pairs using zip(): pairs = zip(d.values(), d.keys()).   So we can do the following:  d = {'key1': 874.7, 'key2': 5, 'key3': 8.1}  d_sorted = sorted(zip(d.values(), d.keys()))  print d_sorted  # prints: [(5, 'key2'), (8.1, 'key3'), (874.7, 'key1')]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "7", "A_Content": "  Use ValueSortedDict from dicts:  from dicts.sorteddict import ValueSortedDict d = {1: 2, 3: 4, 4:3, 2:1, 0:0} sorted_dict = ValueSortedDict(d) print sorted_dict.items()   [(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "6", "A_Content": "  Iterate through a dict and sort it by its values in descending order:  $ python --version Python 3.2.2  $ cat sort_dict_by_val_desc.py  dictionary = dict(siis = 1, sana = 2, joka = 3, tuli = 4, aina = 5) for word in sorted(dictionary, key=dictionary.get, reverse=True):   print(word, dictionary[word])  $ python sort_dict_by_val_desc.py  aina 5 tuli 4 joka 3 sana 2 siis 1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "6", "A_Content": "  I came up with this one,   import operator     x = {1: 2, 3: 4, 4:3, 2:1, 0:0} sorted_x = {k[0]:k[1] for k in sorted(x.items(), key=operator.itemgetter(1))}   For Python 3.x: x.items() replacing iteritems().  >>> sorted_x {0: 0, 1: 2, 2: 1, 3: 4, 4: 3}   Or try with collections.OrderedDict!  x = {1: 2, 3: 4, 4:3, 2:1, 0:0} from collections import OrderedDict  od1 = OrderedDict(sorted(x.items(), key=lambda t: t[1]))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "6", "A_Content": "  You can use the sorted function of Python  sorted(iterable[, cmp[, key[, reverse]]])  Thus you can use:  sorted(dictionary.items(),key = lambda x :x[1])  Visit this link for more information on sorted function: https://docs.python.org/2/library/functions.html#sorted     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "6", "A_Content": "  Of course, remember, you need to use OrderedDict because regular Python dictionaries don't keep the original order.   from collections import OrderedDict a = OrderedDict(sorted(originalDict.items(), key = lambda x: x[1]))     If you do not have Python 2.7 or higher, the best you can do is iterate over the values in a generator function. (There is an OrderedDict for 2.4 and 2.6  here, but   a) I don't know about how well it works    and   b) You have to download and install it of course. If you do not have administrative access, then I'm afraid the option's out.)     def gen(originalDict):     for x,y in sorted(zip(originalDict.keys(), originalDict.values()), key = lambda z: z[1]):         yield (x, y)     #Yields as a tuple with (key, value). You can iterate with conditional clauses to get what you want.   for bleh, meh in gen(myDict):     if bleh == \"foo\":         print(myDict[bleh])     You can also print out every value  for bleh, meh in gen(myDict):     print(bleh,meh)   Please remember to remove the parentheses after print if not using Python 3.0 or above     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "6", "A_Content": "  As pointed out by Dilettant, Python 3.6 will now keep the order! I thought I'd share a function I wrote that eases the sorting of an iterable (tuple, list, dict). In the latter case, you can sort either on keys or values, and it can take numeric comparison into account. Only for >= 3.6!  When you try using sorted on an iterable that holds e.g. strings as well as ints, sorted() will fail. Of course you can force string comparison with str(). However, in some cases you want to do actual numeric comparison where 12 is smaller than 20 (which is not the case in string comparison). So I came up with the following. When you want explicit numeric comparison you can use the flag num_as_num which will try to do explicit numeric sorting by trying to convert all values to floats. If that succeeds, it will do numeric sorting, otherwise it'll resort to string comparison.  Comments for improvement or push requests welcome.  def sort_iterable(iterable, sort_on=None, reverse=False, num_as_num=False):     def _sort(i):       # sort by 0 = keys, 1 values, None for lists and tuples       try:         if num_as_num:           if i is None:             _sorted = sorted(iterable, key=lambda v: float(v), reverse=reverse)           else:             _sorted = dict(sorted(iterable.items(), key=lambda v: float(v[i]), reverse=reverse))         else:           raise TypeError       except (TypeError, ValueError):         if i is None:           _sorted = sorted(iterable, key=lambda v: str(v), reverse=reverse)         else:           _sorted = dict(sorted(iterable.items(), key=lambda v: str(v[i]), reverse=reverse))        return _sorted      if isinstance(iterable, list):       sorted_list = _sort(None)       return sorted_list     elif isinstance(iterable, tuple):       sorted_list = tuple(_sort(None))       return sorted_list     elif isinstance(iterable, dict):       if sort_on == 'keys':         sorted_dict = _sort(0)         return sorted_dict       elif sort_on == 'values':         sorted_dict = _sort(1)         return sorted_dict       elif sort_on is not None:         raise ValueError(f\"Unexpected value {sort_on} for sort_on. When sorting a dict, use key or values\")     else:       raise TypeError(f\"Unexpected type {type(iterable)} for iterable. Expected a list, tuple, or dict\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value", "Language": "Python", "Q_Title": "How do I sort a dictionary by value?", "Q_Votes": "2982", "Q_Content": "    I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.  I can sort on the keys, but how can I sort based on the values?  Note: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.     ", "Tags": ["python", "sorting", "dictionary"], "A_Votes": "5", "A_Content": "  If your values are integers, and you use Python 2.7 or newer, you can use collections.Counter instead of dict. The most_common method will give you all items, sorted by the value.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "1169", "A_Content": "  I prefer using the glob module, as it does pattern matching and expansion.  import glob print(glob.glob(\"/home/adam/*.txt\"))   It will return a list with the queried files:  ['/home/adam/file1.txt', '/home/adam/file2.txt', .... ]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "529", "A_Content": "  import os os.listdir(\"somedirectory\")   will return a list of all files and directories in \"somedirectory\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "354", "A_Content": "  Get a list of files with Python 2 and 3    I have also made a short video here:  Python: how to get a list of file in a directory    os.listdir()  or..... hot to get all the files (and directories) in current directory (Python 3)  The simplest way to have the file in the current directory in Python 3 is this. It's really simple; use the os module and the listdir() function and you'll have the file in that directory (and eventual folders that are in the directory, but you will not have the file in the subdirectory, for that you can use walk - I will talk about it later).  >>> import os >>> arr = os.listdir() >>> arr ['$RECYCLE.BIN', 'work.txt', '3ebooks.txt', 'documents']     Using glob  I found glob easier to select file of the same type or with something in common. Look at the following example:  import glob  txtfiles = [] for file in glob.glob(\"*.txt\"):     txtfiles.append(file)   Using list comprehension  import glob  mylist = [f for f in glob.glob(\"*.txt\")]   Getting the full path name with os.path.abspath  As you noticed, you don't have the full path of the file in the code above. If you need to have the absolute path, you can use another function of the os.path module called _getfullpathname, putting the file that you get from os.listdir() as an argument. There are other ways to have the full path, as we will check later (I replaced, as suggested by mexmex, _getfullpathname with abspath).  >>> import os >>> files_path = [os.path.abspath(x) for x in os.listdir()] >>> files_path ['F:\\\\documenti\\applications.txt', 'F:\\\\documenti\\collections.txt']     Get the full path name of a type of file into all subdirectories with walk  I find this very useful to find stuff in many directories, and it helped me finding a file about which I didn't remember the name:  import os  # Getting the current work directory (cwd) thisdir = os.getcwd()  # r=root, d=directories, f = files for r, d, f in os.walk(thisdir):     for file in f:         if \".docx\" in file:             print(os.path.join(r, file))   os.listdir(): get files in the current directory (Python 2)  In Python 2 you, if you want the list of the files in the current directory, you have to give the argument as '.' or os.getcwd() in the os.listdir method.  >>> import os >>> arr = os.listdir('.') >>> arr ['$RECYCLE.BIN', 'work.txt', '3ebooks.txt', 'documents']   To go up in the directory tree  >>> # Method 1 >>> x = os.listdir('..')  # Method 2 >>> x= os.listdir('/')   Get files: os.listdir() in a particular directory (Python 2 and 3)  >>> import os >>> arr = os.listdir('F:\\\\python') >>> arr ['$RECYCLE.BIN', 'work.txt', '3ebooks.txt', 'documents']   Get files of a particular subdirectory with os.listdir()  import os  x = os.listdir(\"./content\")   os.walk('.') - current directory  >>> import os >>> arr = next(os.walk('.'))[2] >>> arr ['5bs_Turismo1.pdf', '5bs_Turismo1.pptx', 'esperienza.txt']   glob module - all files  import glob print(glob.glob(\"*\"))  out:['content', 'start.py']   next(os.walk('.')) and os.path.join('dir','file')  >>> import os >>> arr = [] >>> for d,r,f in next(os.walk(\"F:\\_python\")): >>>     for file in f: >>>         arr.append(os.path.join(r,file)) ... >>> for f in arr: >>>     print(files)  >output  F:\\\\_python\\\\dict_class.py F:\\\\_python\\\\programmi.txt   next(os.walk('F:\\') - get the full path - list comprehension  >>> [os.path.join(r,file) for r,d,f in next(os.walk(\"F:\\\\_python\")) for file in f] ['F:\\\\_python\\\\dict_class.py', 'F:\\\\_python\\\\programmi.txt']   os.walk - get full path - all files in sub dirs  x = [os.path.join(r,file) for r,d,f in os.walk(\"F:\\\\_python\") for file in f]  >>>x ['F:\\\\_python\\\\dict.py', 'F:\\\\_python\\\\progr.txt', 'F:\\\\_python\\\\readl.py']   os.listdir() - get only txt files  >>> arr_txt = [x for x in os.listdir() if x.endswith(\".txt\")] >>> print(arr_txt) ['work.txt', '3ebooks.txt']   glob - get only txt files  >>> import glob >>> x = glob.glob(\"*.txt\") >>> x ['ale.txt', 'alunni2015.txt', 'assenze.text.txt', 'text2.txt', 'untitled.txt']   Using glob to get the full path of the files  If I should need the absolute path of the files:  >>> from path import path >>> from glob import glob >>> x = [path(f).abspath() for f in glob(\"F:\\*.txt\")] >>> for f in x: ...  print(f) ... F:\\acquistionline.txt F:\\acquisti_2018.txt F:\\bootstrap_jquery_ecc.txt   Other use of glob  If I want all the files in the directory:  >>> x = glob.glob(\"*\")   Using os.path.isfile to avoid directories in the list  import os.path listOfFiles = [f for f in os.listdir() if os.path.isfile(f)] print(listOfFiles)  > output  ['a simple game.py', 'data.txt', 'decorator.py']   Using pathlib from (Python 3.4)  import pathlib  >>> flist = [] >>> for p in pathlib.Path('.').iterdir(): ...  if p.is_file(): ...   print(p) ...   flist.append(p) ... error.PNG exemaker.bat guiprova.mp3 setup.py speak_gui2.py thumb.PNG   If you want to use list comprehension  >>> flist = [p for p in pathlib.Path('.').iterdir() if p.is_file()]   *You can use also just pathlib.Path() instead of pathlib.Path(\".\")  Use glob method in pathlib.Path()  import pathlib  py = pathlib.Path().glob(\"*.py\") for file in py:     print(file)   output:  stack_overflow_list.py stack_overflow_list_tkinter.py   Get all and only files with os.walk  import os x = [i[2] for i in os.walk('.')] y=[] for t in x:     for f in t:         y.append(f)  >>> y ['append_to_list.py', 'data.txt', 'data1.txt', 'data2.txt', 'data_180617', 'os_walk.py', 'READ2.py', 'read_data.py', 'somma_defaltdic.py', 'substitute_words.py', 'sum_data.py', 'data.txt', 'data1.txt', 'data_180617']   Get only files with next and walk in a directory  >>> import os >>> x = next(os.walk('F://python'))[2] >>> x ['calculator.bat','calculator.py']   Get only directories with next and walk in a directory  >>> import os >>> next(os.walk('F://python'))[1] # for the current dir use ('.') ['python3','others']   Get all the subdir names with walk  >>> for r,d,f in os.walk(\"F:\\_python\"): ...  for dirs in d: ...   print(dirs) ... .vscode pyexcel pyschool.py subtitles _metaprogramming .ipynb_checkpoints   os.scandir() from Python 3.5 on  >>> import os >>> x = [f.name for f in os.scandir() if f.is_file()] >>> x ['calculator.bat','calculator.py']  # Another example with scandir (a little variation from docs.python.org) # This one is more efficient than os.listdir. # In this case, it shows the files only in the current directory # where the script is executed.  >>> import os >>> with os.scandir() as i: ...  for entry in i: ...   if entry.is_file(): ...    print(entry.name) ... ebookmaker.py error.PNG exemaker.bat guiprova.mp3 setup.py speakgui4.py speak_gui2.py speak_gui3.py thumb.PNG >>>     Ex. 1: How many files are there in the subdirectories?  In this example, we look for the number of files that are included in all the directory and its subdirectories.  import os  def count(dir, counter=0):     \"returns number of files in dir and subdirs\"     for pack in os.walk(dir):         for f in pack[2]:             counter += 1     return dir + \" : \" + str(counter) + \"files\"  print(count(\"F:\\\\python\"))  > output  >'F:\\\\\\python' : 12057 files'   Ex.2: How to copy all files from a directory to another?  A script to make order in your computer finding all files of a type (default: pptx) and copying them in a new folder.  import os import shutil from path import path  destination = \"F:\\\\file_copied\" # os.makedirs(destination)  def copyfile(dir, filetype='pptx', counter=0):     \"Searches for pptx (or other - pptx is the default) files and copies them\"     for pack in os.walk(dir):         for f in pack[2]:             if f.endswith(filetype):                 fullpath = pack[0] + \"\\\\\" + f                 print(fullpath)                 shutil.copy(fullpath, destination)                 counter += 1     if counter > 0:         print(\"------------------------\")         print(\"\\t==> Found in: `\" + dir + \"` : \" + str(counter) + \" files\\n\")  for dir in os.listdir():     \"searches for folders that starts with `_`\"     if dir[0] == '_':         # copyfile(dir, filetype='pdf')         copyfile(dir, filetype='txt')   > Output  _compiti18\\Compito Contabilit\u00e0 1\\conti.txt _compiti18\\Compito Contabilit\u00e0 1\\modula4.txt _compiti18\\Compito Contabilit\u00e0 1\\moduloa4.txt ------------------------ ==> Found in: `_compiti18` : 3 files   Ex. 3: How to get all the files in a txt file  In case you want to create a txt file with all the file names:  import os mylist = \"\" with open(\"filelist.txt\", \"w\", encoding=\"utf-8\") as file:     for eachfile in os.listdir():         mylist += eachfile + \"\\n\"     file.write(mylist)   Example: txt with all the files of an hard drive  \"\"\"We are going to save a txt file with all the files in your directory. We will use the function walk()  \"\"\"  import os  # see all the methos of os # print(*dir(os), sep=\", \") listafile = [] percorso = [] with open(\"lista_file.txt\", \"w\", encoding='utf-8') as testo:     for root, dirs, files in os.walk(\"D:\\\\\"):         for file in files:             listafile.append(file)             percorso.append(root + \"\\\\\" + file)             testo.write(file + \"\\n\") listafile.sort() print(\"N. of files\", len(listafile)) with open(\"lista_file_ordinata.txt\", \"w\", encoding=\"utf-8\") as testo_ordinato:     for file in listafile:         testo_ordinato.write(file + \"\\n\")  with open(\"percorso.txt\", \"w\", encoding=\"utf-8\") as file_percorso:     for file in percorso:         file_percorso.write(file + \"\\n\")  os.system(\"lista_file.txt\") os.system(\"lista_file_ordinata.txt\") os.system(\"percorso.txt\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "145", "A_Content": "  A one-line solution to get only list of files (no subdirectories):  filenames = next(os.walk(path))[2]   or absolute pathnames:  paths = [os.path.join(path,fn) for fn in next(os.walk(path))[2]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "110", "A_Content": "  Getting Full File Paths From a Directory and All Its Subdirectories  import os  def get_filepaths(directory):     \"\"\"     This function will generate the file names in a directory      tree by walking the tree either top-down or bottom-up. For each      directory in the tree rooted at directory top (including top itself),      it yields a 3-tuple (dirpath, dirnames, filenames).     \"\"\"     file_paths = []  # List which will store all of the full filepaths.      # Walk the tree.     for root, directories, files in os.walk(directory):         for filename in files:             # Join the two strings in order to form the full filepath.             filepath = os.path.join(root, filename)             file_paths.append(filepath)  # Add it to the list.      return file_paths  # Self-explanatory.  # Run the above function and store its results in a variable.    full_file_paths = get_filepaths(\"/Users/johnny/Desktop/TEST\")      The path I provided in the above function contained 3 files\u2014 two of them in the root directory, and another in a subfolder called \"SUBFOLDER.\"  You can now do things like: print full_file_paths which will print the list:   ['/Users/johnny/Desktop/TEST/file1.txt', '/Users/johnny/Desktop/TEST/file2.txt', '/Users/johnny/Desktop/TEST/SUBFOLDER/file3.dat']    If you'd like, you can open and read the contents, or focus only on files with the extension \".dat\" like in the code below:  for f in full_file_paths:   if f.endswith(\".dat\"):     print f   /Users/johnny/Desktop/TEST/SUBFOLDER/file3.dat     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "57", "A_Content": "  Since version 3.4 there are builtin iterators for this which are a lot more efficient than os.listdir():  pathlib: New in version 3.4.  >>> import pathlib >>> [p for p in pathlib.Path('.').iterdir() if p.is_file()]   According to PEP 428, the aim of the pathlib library is to provide a simple hierarchy of classes to handle filesystem paths and the common operations users do over them.  os.scandir(): New in version 3.5.  >>> import os >>> [entry for entry in os.scandir('.') if entry.is_file()]   Note that os.walk() uses os.scandir() instead of os.listdir() from version 3.5, and its speed got increased by 2-20 times according to PEP 471.  Let me also recommend reading ShadowRanger's comment below.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "45", "A_Content": "  I really liked adamk's answer, suggesting that you use glob(), from the module of the same name. This allows you to have pattern matching with *s.  But as other people pointed out in the comments, glob() can get tripped up over inconsistent slash directions. To help with that, I suggest you use the join() and expanduser() functions in the os.path module, and perhaps the getcwd() function in the os module, as well.  As examples:  from glob import glob  # Return everything under C:\\Users\\admin that contains a folder called wlp. glob('C:\\Users\\admin\\*\\wlp')   The above is terrible - the path has been hardcoded and will only ever work on Windows between the drive name and the \\s being hardcoded into the path.  from glob    import glob from os.path import join  # Return everything under Users, admin, that contains a folder called wlp. glob(join('Users', 'admin', '*', 'wlp'))   The above works better, but it relies on the folder name Users which is often found on Windows and not so often found on other OSs. It also relies on the user having a specific name, admin.  from glob    import glob from os.path import expanduser, join  # Return everything under the user directory that contains a folder called wlp. glob(join(expanduser('~'), '*', 'wlp'))   This works perfectly across all platforms.  Another great example that works perfectly across platforms and does something a bit different:  from glob    import glob from os      import getcwd from os.path import join  # Return everything under the current directory that contains a folder called wlp. glob(join(getcwd(), '*', 'wlp'))   Hope these examples help you see the power of a few of the functions you can find in the standard Python library modules.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "33", "A_Content": "  def list_files(path):     # returns a list of names (with extension, without full path) of all files      # in folder path     files = []     for name in os.listdir(path):         if os.path.isfile(os.path.join(path, name)):             files.append(name)     return files       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "27", "A_Content": "  You should use os module for listing directory content.os.listdir(\".\") returns all the contents of the directory. We iterate over the result and append to the list.  import os  content_list = []  for content in os.listdir(\".\"): # \".\" means current directory     content_list.append(content)  print content_list      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "24", "A_Content": "  Part One 1  Preliminary notes   Although there's a clear differentiation between file and directory terms in the question text, some may argue that directories are actually special files The statement: \"all files of a directory\" can be interpreted in two ways:   All direct (or level 1) descendants only All descendants in the whole directory tree (including the ones in sub-directories)  When the question was asked, I imagine that Python 2, was the LTS version, however the code samples will be run by Python 3(.5) (I'll keep them as Python 2 compliant as possible; also, any code belonging to Python that I'm going to post, is from v3.5.4 - unless otherwise specified). That has consequences related to another keyword in the question: \"add them into a list\":   In pre Python 2.2 versions, sequences (iterables) were mostly represented by lists (tuples, sets, ...) In Python 2.2, the concept of generator ([Python]: Generators) - courtesy of [Python]: The yield statement) - was introduced. As time passed, generator counterparts started to appear for functions that returned/worked with lists In Python 3, generator is the default behavior Now, I don't know if returning a list is still mandatory (or a generator would do as well), but passing a generator to the list constructor, will create a list out of it (and also consume it). The example below illustrates the differences on [Python]: map(function, iterable, ...)    Python 2.7.10 (default, Mar  8 2016, 15:02:46) [MSC v.1600 64 bit (AMD64)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> m = map(lambda x: x, [1, 2, 3])  # Just a dummy lambda function >>> m, type(m) ([1, 2, 3], <type 'list'>) >>> len(m) 3       Python 3.5.4 (v3.5.4:3f56838, Aug  8 2017, 02:17:05) [MSC v.1900 64 bit (AMD64)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> m = map(lambda x: x, [1, 2, 3]) >>> m, type(m) (<map object at 0x000001B4257342B0>, <class 'map'>) >>> len(m) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: object of type 'map' has no len() >>> lm0 = list(m)  # Construct a list out of the generator >>> lm0, type(lm0) ([1, 2, 3], <class 'list'>) >>> >>> lm1 = list(m)  # Construct a list out of the same generator >>> lm1, type(lm1)  # Empty list this time - generator already consumed ([], <class 'list'>)   The examples will be based on a directory called root_dir with the following structure (this example is for Win, but I have duplicated the folder tree for Ux(Lnx) as well):   E:\\Work\\Dev\\StackOverflow\\q003207219>tree /f \"root_dir\" Folder PATH listing for volume Work Volume serial number is 00000029 3655:6FED E:\\WORK\\DEV\\STACKOVERFLOW\\Q003207219\\ROOT_DIR \u2502   file0 \u2502   file1 \u2502 \u251c\u2500\u2500\u2500dir0 \u2502   \u251c\u2500\u2500\u2500dir00 \u2502   \u2502   \u2502   file000 \u2502   \u2502   \u2502 \u2502   \u2502   \u2514\u2500\u2500\u2500dir000 \u2502   \u2502           file0000 \u2502   \u2502 \u2502   \u251c\u2500\u2500\u2500dir01 \u2502   \u2502       file010 \u2502   \u2502       file011 \u2502   \u2502 \u2502   \u2514\u2500\u2500\u2500dir02 \u2502       \u2514\u2500\u2500\u2500dir020 \u2502           \u2514\u2500\u2500\u2500dir0200 \u251c\u2500\u2500\u2500dir1 \u2502       file10 \u2502       file11 \u2502       file12 \u2502 \u251c\u2500\u2500\u2500dir2 \u2502   \u2502   file20 \u2502   \u2502 \u2502   \u2514\u2500\u2500\u2500dir20 \u2502           file200 \u2502 \u2514\u2500\u2500\u2500dir3       Solutions  Programmatic approaches:   [Python]: os.listdir(path='.')     Return a list containing the names of the entries in the directory given by path. The list is in arbitrary order, and does not include the special entries '.' and '..' ...      >>> import os >>> root_dir = \"root_dir\"  # Path relative to current dir (os.getcwd()) >>> >>> os.listdir(root_dir)  # List all the items in root_dir ['dir0', 'dir1', 'dir2', 'dir3', 'file0', 'file1'] >>> >>> [item for item in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, item))]  # Filter the items and only keep files (strip out directories) ['file0', 'file1']    Here's a more elaborate example (code_os_listdir.py):  import os from pprint import pformat   def _get_dir_content(path, include_folders, recursive):     entries = os.listdir(path)     for entry in entries:         entry_with_path = os.path.join(path, entry)         if os.path.isdir(entry_with_path):             if include_folders:                 yield entry_with_path             if recursive:                 for sub_entry in _get_dir_content(entry_with_path, include_folders, recursive):                     yield sub_entry         else:             yield entry_with_path   def get_dir_content(path, include_folders=True, recursive=True, prepend_folder_name=True):     path_len = len(path) + len(os.path.sep)     for item in _get_dir_content(path, include_folders, recursive):         yield item if prepend_folder_name else item[path_len:]   def _get_dir_content_old(path, include_folders, recursive):     entries = os.listdir(path)     ret = list()     for entry in entries:         entry_with_path = os.path.join(path, entry)         if os.path.isdir(entry_with_path):             if include_folders:                 ret.append(entry_with_path)             if recursive:                 ret.extend(_get_dir_content_old(entry_with_path, include_folders, recursive))         else:             ret.append(entry_with_path)     return ret   def get_dir_content_old(path, include_folders=True, recursive=True, prepend_folder_name=True):     path_len = len(path) + len(os.path.sep)     return [item if prepend_folder_name else item[path_len:] for item in _get_dir_content_old(path, include_folders, recursive)]   def main():     root_dir = \"root_dir\"     ret0 = get_dir_content(root_dir, include_folders=True, recursive=True, prepend_folder_name=True)     lret0 = list(ret0)     print(ret0, len(lret0), pformat(lret0))     ret1 = get_dir_content_old(root_dir, include_folders=False, recursive=True, prepend_folder_name=False)     print(len(ret1), pformat(ret1))   if __name__ == \"__main__\":     main()   Notes:   There are two implementations:   One that uses generators (of course in this example it seems useless, since I convert the result to a list immediately) The classic one (function names ending in _old)  Recursion is used (to get into subdirectories) For each implementations there are two functions:   One that starts with an underscore (_): \"private\" (should not be called directly) - that does all the work The public one (wrapper over previous): it just strips off the initial path (if required) from the returned entries. It's an ugly implementation, but it's the only idea that I could come with at this point  In terms of performance, generators are generally a little bit faster (considering both creation and  iteration times), but I didn't test them in recursive functions, and also I am iterating inside the function over inner generators - don't know how performance friendly is that Play with the arguments to get different results     Output:   (py35x64_test) E:\\Work\\Dev\\StackOverflow\\q003207219>\"e:\\Work\\Dev\\VEnvs\\py35x64_test\\Scripts\\python.exe\" \"code_os_listdir.py\" <generator object get_dir_content at 0x000001BDDBB3DF10> 22 ['root_dir\\\\dir0',  'root_dir\\\\dir0\\\\dir00',  'root_dir\\\\dir0\\\\dir00\\\\dir000',  'root_dir\\\\dir0\\\\dir00\\\\dir000\\\\file0000',  'root_dir\\\\dir0\\\\dir00\\\\file000',  'root_dir\\\\dir0\\\\dir01',  'root_dir\\\\dir0\\\\dir01\\\\file010',  'root_dir\\\\dir0\\\\dir01\\\\file011',  'root_dir\\\\dir0\\\\dir02',  'root_dir\\\\dir0\\\\dir02\\\\dir020',  'root_dir\\\\dir0\\\\dir02\\\\dir020\\\\dir0200',  'root_dir\\\\dir1',  'root_dir\\\\dir1\\\\file10',  'root_dir\\\\dir1\\\\file11',  'root_dir\\\\dir1\\\\file12',  'root_dir\\\\dir2',  'root_dir\\\\dir2\\\\dir20',  'root_dir\\\\dir2\\\\dir20\\\\file200',  'root_dir\\\\dir2\\\\file20',  'root_dir\\\\dir3',  'root_dir\\\\file0',  'root_dir\\\\file1'] 11 ['dir0\\\\dir00\\\\dir000\\\\file0000',  'dir0\\\\dir00\\\\file000',  'dir0\\\\dir01\\\\file010',  'dir0\\\\dir01\\\\file011',  'dir1\\\\file10',  'dir1\\\\file11',  'dir1\\\\file12',  'dir2\\\\dir20\\\\file200',  'dir2\\\\file20',  'file0',  'file1']        [Python]: os.scandir(path='.') (!!! Python 3.5+ !!! although I think that for earlier versions it was a separate module (also ported to Python 2))     Return an iterator of os.DirEntry objects corresponding to the entries in the directory given by path. The entries are yielded in arbitrary order, and the special entries '.' and '..' are not included.      Using scandir() instead of listdir() can significantly increase the performance of code that also needs file type or file attribute information, because os.DirEntry objects expose this information if the operating system provides it when scanning a directory. All os.DirEntry methods may perform a system call, but is_dir() and is_file() usually only require a system call for symbolic links; os.DirEntry.stat() always requires a system call on Unix but only requires one for symbolic links on Windows.      >>> import os >>> root_dir = os.path.join(\".\", \"root_dir\")  # Explicitly prepending current directory >>> root_dir '.\\\\root_dir' >>> >>> scandir_iterator = os.scandir(root_dir) >>> scandir_iterator <nt.ScandirIterator object at 0x00000268CF4BC140> >>> [item.path for item in scandir_iterator] ['.\\\\root_dir\\\\dir0', '.\\\\root_dir\\\\dir1', '.\\\\root_dir\\\\dir2', '.\\\\root_dir\\\\dir3', '.\\\\root_dir\\\\file0', '.\\\\root_dir\\\\file1'] >>> >>> [item.path for item in scandir_iterator]  # Will yield an empty list as it was consumed by previous iteration (automatically performed by the list comprehension) [] >>> >>> scandir_iterator = os.scandir(root_dir)  # Reinitialize the generator >>> for item in scandir_iterator : ...     if os.path.isfile(item.path): ...             print(item.name) ... file0 file1    Notes:   It's similar to os.listdir But it's also more flexible (and offers more functionality), more Pythonic (and in some cases, faster)       [Python]: os.walk(top, topdown=True, onerror=None, followlinks=False)     Generate the file names in a directory tree by walking the tree either top-down or bottom-up. For each directory in the tree rooted at directory top (including top itself), it yields a 3-tuple (dirpath, dirnames, filenames).      >>> import os >>> root_dir = os.path.join(os.getcwd(), \"root_dir\")  # Specify the full path >>> root_dir 'E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir' >>> >>> walk_generator = os.walk(root_dir) >>> root_dir_entry = next(walk_generator)  # First entry corresponds to the root dir (that was passed as an argument) >>> root_dir_entry ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir', ['dir0', 'dir1', 'dir2', 'dir3'], ['file0', 'file1']) >>> >>> root_dir_entry[1] + root_dir_entry[2]  # Display the dirs and the files (that are direct descendants) in a single list ['dir0', 'dir1', 'dir2', 'dir3', 'file0', 'file1'] >>> >>> [os.path.join(root_dir_entry[0], item) for item in root_dir_entry[1] + root_dir_entry[2]]  # Display all the entries in the previous list by their full path ['E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir0', 'E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir1', 'E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir2', 'E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir3', 'E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\file0', 'E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\file1'] >>> >>> for entry in walk_generator:  # Display the rest of the elements (corresponding to every subdir) ...     print(entry) ... ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir0', ['dir00', 'dir01', 'dir02'], []) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir0\\\\dir00', ['dir000'], ['file000']) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir0\\\\dir00\\\\dir000', [], ['file0000']) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir0\\\\dir01', [], ['file010', 'file011']) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir0\\\\dir02', ['dir020'], []) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir0\\\\dir02\\\\dir020', ['dir0200'], []) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir0\\\\dir02\\\\dir020\\\\dir0200', [], []) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir1', [], ['file10', 'file11', 'file12']) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir2', ['dir20'], ['file20']) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir2\\\\dir20', [], ['file200']) ('E:\\\\Work\\\\Dev\\\\StackOverflow\\\\q003207219\\\\root_dir\\\\dir3', [], [])    Notes:   Under the scenes, it uses os.listdir (os.scandir where available) It does the heavy lifting by recurring in subfolders       [Python]: glob.glob(pathname, *, recursive=False) ([Python]: glob.iglob(pathname, *, recursive=False))     Return a possibly-empty list of path names that match pathname, which must be a string containing a path specification. pathname can be either absolute (like /usr/src/Python-1.5/Makefile) or relative (like ../../Tools/*/*.gif), and can contain shell-style wildcards. Broken symlinks are included in the results (as in the shell)....Changed in version 3.5: Support for recursive globs using \u201c**\u201d.      >>> import glob, os >>> wildcard_pattern = \"*\" >>> root_dir = os.path.join(\"root_dir\", wildcard_pattern)  # Match every file/dir name >>> root_dir 'root_dir\\\\*' >>> >>> glob_list = glob.glob(root_dir) >>> glob_list ['root_dir\\\\dir0', 'root_dir\\\\dir1', 'root_dir\\\\dir2', 'root_dir\\\\dir3', 'root_dir\\\\file0', 'root_dir\\\\file1'] >>> >>> [item.replace(\"root_dir\" + os.path.sep, \"\") for item in glob_list]  # Strip the dir name and the path separator from begining ['dir0', 'dir1', 'dir2', 'dir3', 'file0', 'file1'] >>> >>> for entry in glob.iglob(root_dir + \"*\", recursive=True): ...     print(entry) ... root_dir\\ root_dir\\dir0 root_dir\\dir0\\dir00 root_dir\\dir0\\dir00\\dir000 root_dir\\dir0\\dir00\\dir000\\file0000 root_dir\\dir0\\dir00\\file000 root_dir\\dir0\\dir01 root_dir\\dir0\\dir01\\file010 root_dir\\dir0\\dir01\\file011 root_dir\\dir0\\dir02 root_dir\\dir0\\dir02\\dir020 root_dir\\dir0\\dir02\\dir020\\dir0200 root_dir\\dir1 root_dir\\dir1\\file10 root_dir\\dir1\\file11 root_dir\\dir1\\file12 root_dir\\dir2 root_dir\\dir2\\dir20 root_dir\\dir2\\dir20\\file200 root_dir\\dir2\\file20 root_dir\\dir3 root_dir\\file0 root_dir\\file1    Notes:   Uses os.listdir For large trees (especially if recursive is on), iglob is preferred Allows advanced filtering based on name (due to the wildcard)       [Python]: class pathlib.Path(*pathsegments) (!!! Python3+ !!! don't know if backported)   >>> import pathlib >>> root_dir = \"root_dir\" >>> root_dir_instance = pathlib.Path(root_dir) >>> root_dir_instance WindowsPath('root_dir') >>> root_dir_instance.name 'root_dir' >>> root_dir_instance.is_dir() True >>> >>> [item.name for item in root_dir_instance.glob(\"*\")]  # Wildcard searching for all direct descendants ['dir0', 'dir1', 'dir2', 'dir3', 'file0', 'file1'] >>> >>> [os.path.join(item.parent.name, item.name) for item in root_dir_instance.glob(\"*\") if not item.is_dir()]  # Display paths (including parent) for files only ['root_dir\\\\file0', 'root_dir\\\\file1']    Notes:   This is one way of achieving our goal It's the OOP style of handling paths Offers lots of functionalities       [Python]: dircache.listdir(path) (!!! removed in Python3 !!!)   But, according to ${PYTHON_SRC_DIR}/Lib/dircache.py: ~#20+ (from v2.7.14), it's just a (thin) wrapper over os.listdir     def listdir(path):     \"\"\"List directory contents, using cache.\"\"\"     try:         cached_mtime, list = cache[path]         del cache[path]     except KeyError:         cached_mtime, list = -1, []     mtime = os.stat(path).st_mtime     if mtime != cached_mtime:         list = os.listdir(path)         list.sort()     cache[path] = mtime, list     return list       [man]: OPENDIR(3) / [man]: READDIR(3) / [man]: CLOSEDIR(3) via [Python]: ctypes \u2014 A foreign function library for Python (!!! Ux specific !!!)     ctypes is a foreign function library for Python. It provides C compatible data types, and allows calling functions in DLLs or shared libraries. It can be used to wrap these libraries in pure Python.   code_ctypes.py:  #!/usr/bin/env python3  import sys from ctypes import Structure, \\     c_ulonglong, c_longlong, c_ushort, c_ubyte, c_char, c_int, \\     CDLL, POINTER, \\     create_string_buffer, get_errno, set_errno, cast, sizeof   DT_DIR = 4 DT_REG = 8  char256 = c_char * 256  class LinuxDirent64(Structure):     _fields_ = [         (\"d_ino\", c_ulonglong),         (\"d_off\", c_longlong),         (\"d_reclen\", c_ushort),         (\"d_type\", c_ubyte),         (\"d_name\", char256),     ]  LinuxDirent64Ptr = POINTER(LinuxDirent64)  libc_dll = CDLL(None) opendir = libc_dll.opendir readdir = libc_dll.readdir closedir = libc_dll.closedir libc_dll.__errno_location.restype = POINTER(c_int) errno_loc_func = libc_dll.__errno_location   def _get_errno():     return \"errno: {:d}({:d})\".format(get_errno(), errno_loc_func().contents.value)   def get_dir_content(path):     ret = [path, list(), list()]     dir_stream = opendir(create_string_buffer(path.encode()))     if (dir_stream == 0):         print(\"opendir returned NULL ({:s})\".format(_get_errno()))         return ret     set_errno(0)     dirent_addr = readdir(dir_stream)     while dirent_addr:         dirent_ptr = cast(dirent_addr, LinuxDirent64Ptr)         dirent = dirent_ptr.contents         name = dirent.d_name.decode()         if dirent.d_type & DT_DIR:             if name not in (\".\", \"..\"):                 ret[1].append(name)         elif dirent.d_type & DT_REG:             ret[2].append(name)         dirent_addr = readdir(dir_stream)     if get_errno() or errno_loc_func().contents.value:         print(\"readdir returned NULL ({:s})\".format(_get_errno()))     closedir(dir_stream)     return ret   def main():     print(\"{:s} on {:s}\\n\".format(sys.version, sys.platform))     root_dir = \"root_dir\"     entries = get_dir_content(root_dir)     print(entries)   if __name__ == \"__main__\":     main()   Notes:   It loads the three functions from libc (loaded in the current process) and calls them (for more details check [Stack\u00a0Overflow]: How do I check whether a file exists using Python? (@CristiFati's answer) - last notes from item #4.). That would place this approach very close to the Python / C edge LinuxDirent64 is the ctypes representation of struct dirent64 from dirent.h (so are the DT_* constants) from my machine: Ubtu 16 x64 (4.10.0-40-generic and libc6-dev:amd64). On other flavors/versions, the struct definition might differ, and if so, the ctypes alias should be updated, otherwise it will yield Undefined Behavior errno_loc_func (and everything related to it) is because the funcs set errno in case of error, and I need to check its value. Apparently, get_errno doesn't work (with an invalid name, opendir returns NULL, but get_errno still returns 0), or I didn't figure it out yet It returns data in the os.walk's format. I didn't bother to make it recursive, but starting from the existing code, that would be a fairly trivial task Everything is doable on Win as well, the data (libraries, functions, structs, constants, ...) differ     Output:   cfati@testserver:~/work/stackoverflow/q003207219$ ./code_ctypes.py 3.5.2 (default, Nov 23 2017, 16:37:01) [GCC 5.4.0 20160609] on linux  ['root_dir', ['dir3', 'dir2', 'dir0', 'dir1'], ['file0', 'file1']]        [ActiveState]: win32file.FindFilesW (!!! Win specific !!!)     Retrieves a list of matching filenames, using the Windows Unicode API. An interface to the API FindFirstFileW/FindNextFileW/Find close functions.      >>> import os, win32file, win32con >>> root_dir = \"root_dir\" >>> wildcard = \"*\" >>> root_dir_wildcard = os.path.join(root_dir, wildcard) >>> entry_list = win32file.FindFilesW(root_dir_wildcard) >>> len(entry_list)  # Don't display the whole content as it's too long 8 >>> [entry[-2] for entry in entry_list]  # Only display the entry names ['.', '..', 'dir0', 'dir1', 'dir2', 'dir3', 'file0', 'file1'] >>> >>> [entry[-2] for entry in entry_list if entry[0] & win32con.FILE_ATTRIBUTE_DIRECTORY and entry[-2] not in (\".\", \"..\")]  # Filter entries and only display dir names (except self and parent) ['dir0', 'dir1', 'dir2', 'dir3'] >>> >>> [os.path.join(root_dir, entry[-2]) for entry in entry_list if entry[0] & (win32con.FILE_ATTRIBUTE_NORMAL | win32con.FILE_ATTRIBUTE_ARCHIVE)]  # Only display file \"full\" names ['root_dir\\\\file0', 'root_dir\\\\file1']    Notes:   win32file.FindFilesW is part of [GitHub]: Python for Windows (pywin32) Extensions, which is a Python wrapper over WINAPIs The documentation link is from https://www.activestate.com, as I didn't find any pywin32 official documentation       Install some (other) third-party package that does the trick   Most likely, will rely on one (or more) of the above (maybe with slight customizations)      Notes (about the stuff above):   Code is meant to be portable (except places that target a specific area - which are marked) or cross:   platform (Ux, Win, ) Python version (2, 3, )  Multiple path styles (absolute, relatives) were used across the above variants, to illustrate the fact that the \"tools\" used are flexible in this direction os.listdir and os.scandir use opendir / readdir / closedir ([MSDN]: FindFirstFile function / [MSDN]: FindNextFile function / [MSDN]: FindClose function) (via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\") win32file.FindFilesW uses those (Win specific) functions as well (via \"${PYWIN32_SRC_DIR}/win32/src/win32file.i\") get_dir_content (from point #1.) can be implemented using any of these approaches (some will require more work and some less)   Some advanced filtering (instead of just file vs. dir) could be done: e.g. the include_folders argument could be replaced by another one (e.g. filter_func) which would be a function that takes a path as an argument: filter_func=lambda x: True (this doesn't strip out anything) and inside get_dir_content something like: if not filter_func(entry_with_path): continue (if the function fails for one entry, it will be skipped), but the more complex the code becomes, the longer it will take to execute  Nota bene! Since recursion is used, I must mention that I did some tests on my laptop (Win 10 x64), totally unrelated to this problem, and when the recursion level was reaching values somewhere in the (990 .. 1000) range (recursionlimit - 1000 (default)), I got StackOverflow :). If the directory tree exceeds that limit (I am not an FS expert, so I don't know if that is even possible), that could be a problem.  I must also mention that I didn't try to increase recursionlimit because I have no experience in the area (how much can I increase it before having to also increase the stack at OS level), but in theory there will always be the possibility for failure, if the dir depth is larger than the highest possible recursionlimit (on that machine) The code samples are for demonstrative purposes only. That means that I didn't take into account error handling (I don't think there's any try / except / else / finally block), so the code is not robust (the reason is: to keep it as simple and short as possible). For production, error handling should be added as well   End of Part One 1    1. Due to the fact that SO's post (question / answer) limit is 30000 chars ([SE.Meta]: Knowing Your Limits: What is the maximum length of a question title, post, image and links used?), the answer was split in 2 parts. Please also visit [SO]: How do I list all files of a directory? (@CristiFati's answer - \"Part Two\").     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "3566", "A_Content": "  Look at the subprocess module in the standard library:  from subprocess import call call([\"ls\", \"-l\"])   The advantage of subprocess vs. system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...).  The official documentation recommends the subprocess module over the alternative os.system():     The subprocess module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function [os.system()].   The \"Replacing Older Functions with the subprocess Module\" section in the subprocess documentation may have some helpful recipes.  Official documentation on the subprocess module:   Python 2 - subprocess Python 3 - subprocess      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "22", "A_Content": "  import os lst=os.listdir(path)   os.listdir returns a list containing the names of the entries in the directory given by path.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "21", "A_Content": "  If you are looking for a Python implementation of find, this is a recipe I use rather frequently:  from findtools.find_files import (find_files, Match)  # Recursively find all *.sh files in **/usr/bin** sh_files_pattern = Match(filetype='f', name='*.sh') found_files = find_files(path='/usr/bin', match=sh_files_pattern)  for found_file in found_files:     print found_file   So I made a PyPI package out of it and there is also a GitHub repository. I hope that someone finds it potentially useful for this code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "16", "A_Content": "  Python 3.5 introduced a new, faster method for walking through the directory - os.scandir().  Example:  for file in os.scandir('/usr/bin'):     line = ''     if file.is_file():         line += 'f'     elif file.is_dir():         line += 'd'     elif file.is_symlink():         line += 'l'     line += '\\t'     print(\"{}{}\".format(line, file.name))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "14", "A_Content": "  Returning a list of absolute filepaths, does not recurse into subdirectories  L = [os.path.join(os.getcwd(),f) for f in os.listdir('.') if os.path.isfile(os.path.join(os.getcwd(),f))]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "13", "A_Content": "  List all files in a directory:  import os from os import path  files = [x for x in os.listdir(directory_path) if path.isfile(directory_path+os.sep+x)]   Here, you get list of all files in a directory.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "10", "A_Content": "  import os import os.path   def get_files(target_dir):     item_list = os.listdir(target_dir)      file_list = list()     for item in item_list:         item_dir = os.path.join(target_dir,item)         if os.path.isdir(item_dir):             file_list += get_files(item_dir)         else:             file_list.append(item_dir)     return file_list   Here I use a recursive structure.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "8", "A_Content": "  # -** coding: utf-8 -*- import os import traceback  print '\\n\\n'  def start():     address = \"/home/ubuntu/Desktop\"     try:         Folders = []         Id = 1         for item in os.listdir(address):             endaddress = address + \"/\" + item             Folders.append({'Id': Id, 'TopId': 0, 'Name': item, 'Address': endaddress })             Id += 1                       state = 0             for item2 in os.listdir(endaddress):                 state = 1             if state == 1:                  Id = FolderToList(endaddress, Id, Id - 1, Folders)         return Folders     except:         print \"___________________________ ERROR ___________________________\\n\" + traceback.format_exc()  def FolderToList(address, Id, TopId, Folders):     for item in os.listdir(address):         endaddress = address + \"/\" + item         Folders.append({'Id': Id, 'TopId': TopId, 'Name': item, 'Address': endaddress })         Id += 1          state = 0         for item in os.listdir(endaddress):             state = 1         if state == 1:              Id = FolderToList(endaddress, Id, Id - 1, Folders)     return Id  print start()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "6", "A_Content": "  import dircache list = dircache.listdir(pathname) i = 0 check = len(list[0]) temp = [] count = len(list) while count != 0:   if len(list[i]) != check:      temp.append(list[i-1])      check = len(list[i])   else:     i = i + 1     count = count - 1  print temp      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "6", "A_Content": "  Using generators  import os def get_files(search_path):      for (dirpath, _, filenames) in os.walk(search_path):          for filename in filenames:              yield os.path.join(dirpath, filename) list_files = get_files('.') for filename in list_files:     print(filename)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "6", "A_Content": "  If you care about performance, try scandir. For Python 2.x, you may need to install it manually. Examples:  # python 2.x import scandir import sys  de = scandir.scandir(sys.argv[1]) while 1:     try:         d = de.next()         print d.path     except StopIteration as _:         break   This saves a lot of time when you need to scan a huge directory, and you do not need to buffer a huge list, just fetch one by one. And also you can do it recursively:  def scan_path(path):     de = scandir.scandir(path)     while 1:         try:             e = de.next()             if e.is_dir():                 scan_path(e.path)             else:                 print e.path         except StopIteration as _:                 break      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "6", "A_Content": "  Use this function if you want to use a different file type or get the full directory:  import os  def createList(foldername, fulldir = True, suffix=\".jpg\"):     file_list_tmp = os.listdir(foldername)     #print len(file_list_tmp)     file_list = []     if fulldir:         for item in file_list_tmp:             if item.endswith(suffix):                 file_list.append(os.path.join(foldername, item))     else:         for item in file_list_tmp:             if item.endswith(suffix):                 file_list.append(item)     return file_list      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "5", "A_Content": "  import os  os.listdir(path)   This will return a list of all files and directories in path.  filenames = next(os.walk(path))[2]   This will return only a list of files, not subdirectories.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "4", "A_Content": "  By using os library.  import os for root, dirs,files in os.walk(\"your dir path\", topdown=True):     for name in files:         print(os.path.join(root, name))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "3", "A_Content": "  Execute findfiles() with a directory as a parameter and it will return a list of all files in it.  import os def findfiles(directory):     objects = os.listdir(directory)  # find all objects in a dir      files = []     for i in objects:  # check if very object in the folder ...         if os.path.isfile(os.path.join(directory, i)):  # ... is a file.             files.append(i)  # if yes, append it.     return files      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "2", "A_Content": "  Referring to the answer by @adamk, here is my os detection method in response to the slash inconsistency comment by @Anti Earth  import sys import os from pathlib import Path from glob import glob platformtype = sys.platform if platformtype == 'win32':     slash = \"\\\\\" if platformtype == 'darwin':     slash = \"/\"  # TODO: How can I list all files of a directory in Python and add them to a list?  # Step 1 - List all files of a directory  # Method 1: Find only pre-defined filetypes (.txt) and no subfiles, answer provided by @adamk dir1 = \"%sfoo%sbar%s*.txt\" % (slash) _files = glob(dir1)  # Method 2: Find all files and no subfiles dir2 = \"%sfoo%sbar%s\" % (slash) _files = (x for x in Path(\"dir2\").iterdir() if x.is_file())  # Method 3: Find all files and all subfiles dir3 = \"%sfoo%sbar\" % (slash) _files = (x for x in Path('dir3').glob('**/*') if x.is_file())   # Step 2 - Add them to a list  files_list = [] for eachfiles in _files:     files_basename = os.path.basename(eachfiles)     files_list.append(files_basename)     print(files_list) ['file1.txt', 'file2.txt', .... ]   I'm assuming that you want just the basenames in the list.  Refer to this post for pre-defining multiple file formats for Method 1.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "2", "A_Content": "  I will provide a sample one liner where sourcepath and file type can be provided as input. The code returns a list of filenames with csv extension. Use . in case all files needs to be returned. This will also recursively scans the subdirectories.   [y for x in os.walk(sourcePath) for y in glob(os.path.join(x[0], '*.csv'))]  Modify file extensions and source path as needed.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "2", "A_Content": "  Really simple version:  import os [f for f in os.listdir(os.getcwd) if ...]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "2", "A_Content": "  Another very readable variant for Python 3.4+ is using pathlib.Path.glob:  from pathlib import Path folder = '/foo' [f for f in Path(folder).glob('*') if f.is_file()]   It is simple to make more specific, e.g. only look for Python source files which are not symbolic links, also in all subdirectories:  [f for f in Path(folder).glob('**/*.py') if not f.is_symlink()]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory", "Language": "Python", "Q_Title": "How do I list all files of a directory?", "Q_Votes": "2907", "Q_Content": "    How can I list all files of a directory in Python and add them to a list?     ", "Tags": ["python", "directory"], "A_Votes": "2", "A_Content": "  Part Two 1  Solutions (continued)  Other approaches:   Use Python only as a wrapper   Everything is done using another technology That technology is invoked from Python The most famous flavor that I know is what I call the system administrator approach:   Use Python (or any programming language for that matter) in order to execute shell commands (and parse their outputs - in general this approach is to be avoided, since if some command output format slightly differs between OS versions/flavors, the parsing code should be adapted as well; not to mention non EN locales) Some consider this a neat hack I consider it more like a lame workaround (gainarie), as the action per se is performed from shell (cmd in this case), and thus doesn't have anything to do with Python. Filtering (grep / findstr) or output formatting could be done on both sides, but I'm not going to insist on it. Also, I deliberately used os.system instead of subprocess.Popen.    (py35x64_test) E:\\Work\\Dev\\StackOverflow\\q003207219>\"e:\\Work\\Dev\\VEnvs\\py35x64_test\\Scripts\\python.exe\" -c \"import os;os.system(\\\"dir /b root_dir\\\")\" dir0 dir1 dir2 dir3 file0 file1      End of Part Two 1    1. Due to the fact that SO's post (question / answer) limit is 30000 chars ([SE.Meta]: Knowing Your Limits: What is the maximum length of a question title, post, image and links used?), the answer was split in 2 parts. Please make sure to read [SO]: How do I list all files of a directory? (@CristiFati's answer - \"Part One\") before.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "2498", "A_Content": "  Here's a summary of the ways to call external programs and the advantages and disadvantages of each:   os.system(\"some_command with args\") passes the command and arguments to your system's shell.  This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection.  For example:    os.system(\"some_command < input_file | another_command > output_file\")     However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc.  On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.  See the documentation. stream = os.popen(\"some_command with args\") will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process.  There are 3 other variants of popen that all handle the i/o slightly differently.  If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don't need to worry about escaping anything.  See the documentation. The Popen class of the subprocess module.  This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive.  For example, you'd say:  print subprocess.Popen(\"echo Hello World\", shell=True, stdout=subprocess.PIPE).stdout.read()   instead of:   print os.popen(\"echo Hello World\").read()   but it is nice to have all of the options there in one unified class instead of 4 different popen functions.  See the documentation. The call function from the subprocess module.  This is basically just like the Popen class and takes all of the same arguments, but it simply waits until the command completes and gives you the return code.  For example:  return_code = subprocess.call(\"echo Hello World\", shell=True)     See the documentation. If you're on Python 3.5 or later, you can use the new subprocess.run function, which is a lot like the above but even more flexible and returns a CompletedProcess object when the command finishes executing. The os module also has all of the fork/exec/spawn functions that you'd have in a C program, but I don't recommend using them directly.   The subprocess module should probably be what you use.  Finally please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it. There are serious security implications if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code:  print subprocess.Popen(\"echo %s \" % user_input, stdout=PIPE).stdout.read()   and imagine that the user enters \"my mama didnt love me && rm -rf /\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "264", "A_Content": "  I typically use:  import subprocess  p = subprocess.Popen('ls', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) for line in p.stdout.readlines():     print line, retval = p.wait()   You are free to do what you want with the stdout data in the pipe.  In fact, you can simply omit those parameters (stdout= and stderr=) and it'll behave like os.system().     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "159", "A_Content": "  Some hints on detaching the child process from the calling one (starting the child process in background).  Suppose you want to start a long task from a CGI-script, that is the child process should live longer than the CGI-script execution process.  The classical example from the subprocess module docs is:  import subprocess import sys  # some code here  pid = subprocess.Popen([sys.executable, \"longtask.py\"]) # call subprocess  # some more code here   The idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example.  My target platform was freebsd, but the development was on windows, so I faced the problem on windows first.  On windows (win xp), the parent process will not finish until the longtask.py has finished its work. It is not what you want in CGI-script. The problem is not specific to Python, in PHP community the problems are the same.  The solution is to pass DETACHED_PROCESS Process Creation Flag to the underlying CreateProcess function in win API. If you happen to have installed pywin32 you can import the flag from the win32process module, otherwise you should define it yourself:  DETACHED_PROCESS = 0x00000008  pid = subprocess.Popen([sys.executable, \"longtask.py\"],                        creationflags=DETACHED_PROCESS).pid   /* UPD 2015.10.27 @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */  On freebsd we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in CGI-script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following:  pid = subprocess.Popen([sys.executable, \"longtask.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)   I have not checked the code on other platforms and do not know the reasons of the behaviour on freebsd. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "99", "A_Content": "  I'd recommend using the subprocess module instead of os.system because it does shell escaping for you and is therefore much safer: http://docs.python.org/library/subprocess.html  subprocess.call(['ping', 'localhost'])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "97", "A_Content": "  import os cmd = 'ls -al' os.system(cmd)   If you want to return the results of the command, you can use os.popen. However, this is deprecated since version 2.6 in favor of the subprocess module, which other answers have covered well.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "85", "A_Content": "  import os os.system(\"your command\")   Note that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant documentation on the 'os' and 'sys' modules. There are a bunch of functions (exec* and spawn*) that will do similar things.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "53", "A_Content": "  I always use fabric for this things like:  from fabric.operations import local result = local('ls', capture=True) print \"Content:/n%s\" % (result, )   But this seem to be a good tool: sh (Python subprocess interface).  Look an example:  from sh import vgdisplay print vgdisplay() print vgdisplay('-v') print vgdisplay(v=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "52", "A_Content": "  Check the \"pexpect\" Python library, too.  It allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like:  child = pexpect.spawn('ftp 192.168.0.24')  child.expect('(?i)name .*: ')  child.sendline('anonymous')  child.expect('(?i)password')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "49", "A_Content": "  There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is ls -l (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them.     Sources:    subprocess: https://docs.python.org/3.5/library/subprocess.html shlex: https://docs.python.org/3/library/shlex.html os: https://docs.python.org/3.5/library/os.html sh: https://amoffat.github.io/sh/ plumbum: https://plumbum.readthedocs.io/en/latest/ pexpect: https://pexpect.readthedocs.io/en/stable/ fabric: http://www.fabfile.org/ envoy: https://github.com/kennethreitz/envoy commands: https://docs.python.org/2/library/commands.html                  These are all the libraries:           Hopefully this will help you make a decision on which library to use :)     subprocess   Subprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better.  subprocess.run([\"ls\", \"-l\"]) # Run command subprocess.run([\"ls\", \"-l\"], stdout=subprocess.PIPE) # This will run the command and return any output subprocess.run(shlex.split(\"ls -l\")) # You can also use the shlex library to split the command      os   os is used for \"operating system dependent functionality\". It can also be used to call external commands with os.system and os.popen (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use subprocess.run.  os.system(\"ls -l\") # run command os.popen(\"ls -l\").read() # This will run the command and return any output      sh   sh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times.  sh.ls(\"-l\") # Run command normally ls_cmd = sh.Command(\"ls\") # Save command as a variable ls_cmd() # Run command as if it were a function      plumbum   plumbum is a library for \"script-like\" Python programs. You can call programs like functions as in sh. Plumbum is useful if you want to run a pipeline without the shell.  ls_cmd = plumbum.local(\"ls -l\") # get command ls_cmd() # run command      pexpect   pexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix.  pexpect.run(\"ls -l\") # Run command as normal child = pexpect.spawn('scp foo user@example.com:.') # Spawns child application child.expect('Password:') # When this is the output child.sendline('mypassword')      fabric   fabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH)  fabric.operations.local('ls -l') # Run command as normal fabric.operations.local('ls -l', capture = True) # Run command and receive output      envoy   envoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the subprocess module.  r = envoy.run(\"ls -l\") # Run command r.std_out # get output      commands   commands contains wrapper functions for os.popen, but it has been removed from Python 3 since subprocess is a better alternative.  The edit was based on J.F. Sebastian's comment.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "46", "A_Content": "  If you need the output from the command you are calling, then you can use subprocess.check_output (Python 2.7+).  >>> subprocess.check_output([\"ls\", \"-l\", \"/dev/null\"]) 'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\\n'   Also note the shell parameter.     If shell is True, the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user\u2019s home directory. However, note that Python itself offers implementations of many shell-like features (in particular, glob, fnmatch, os.walk(), os.path.expandvars(), os.path.expanduser(), and shutil).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "41", "A_Content": "  This is how I run my commands. This code has everything you need pretty much  from subprocess import Popen, PIPE cmd = \"ls -l ~/\" p = Popen(cmd , shell=True, stdout=PIPE, stderr=PIPE) out, err = p.communicate() print \"Return code: \", p.returncode print out.rstrip(), err.rstrip()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "36", "A_Content": "  With Standard Library  Use subprocess module:  from subprocess import call call(['ls', '-l'])   It is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write.  Note: shlex.split can help you to parse the command for call and other subprocess functions in case you don't want (or you can't!) provide them in form of lists:  import shlex from subprocess import call call(shlex.split('ls -l'))   With External Dependencies  If you do not mind external dependencies, use plumbum:  from plumbum.cmd import ifconfig print(ifconfig['wlan0']())   It is the best subprocess wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by pip install plumbum.  Another popular library is sh:  from sh import ifconfig print(ifconfig('wlan0'))   However, sh dropped Windows support, so it's not as awesome as it used to be. Install by pip install sh.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "35", "A_Content": "  Update:  subprocess.run is the recommended approach as of Python 3.5 if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See this question for how.)  Here's some examples from the docs.  Run a process:  >>> subprocess.run([\"ls\", \"-l\"])  # doesn't capture output CompletedProcess(args=['ls', '-l'], returncode=0)   Raise on failed run:  >>> subprocess.run(\"exit 1\", shell=True, check=True) Traceback (most recent call last):   ... subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1   Capture output:  >>> subprocess.run([\"ls\", \"-l\", \"/dev/null\"], stdout=subprocess.PIPE) CompletedProcess(args=['ls', '-l', '/dev/null'], returncode=0, stdout=b'crw-rw-rw- 1 root root 1, 3 Jan 23 16:23 /dev/null\\n')   Original answer:  I recommend trying Envoy. It's a wrapper for subprocess, which in turn aims to replace the older modules and functions. Envoy is subprocess for humans.  Example usage from the readme:  >>> r = envoy.run('git config', data='data to pipe in', timeout=2)  >>> r.status_code 129 >>> r.std_out 'usage: git config [options]' >>> r.std_err ''   Pipe stuff around too:  >>> r = envoy.run('uptime | pbcopy')  >>> r.command 'pbcopy' >>> r.status_code 0  >>> r.history [<Response 'uptime'>]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "31", "A_Content": "  Without the output of the result:  import os os.system(\"your command here\")   With output of the result:  import commands commands.getoutput(\"your command here\") or commands.getstatusoutput(\"your command here\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "23", "A_Content": "  https://docs.python.org/2/library/subprocess.html  ...or for a very simple command:  import os os.system('cat testfile')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "22", "A_Content": "  There is also Plumbum  >>> from plumbum import local >>> ls = local[\"ls\"] >>> ls LocalCommand(<LocalPath /bin/ls>) >>> ls() u'build.py\\ndist\\ndocs\\nLICENSE\\nplumbum\\nREADME.rst\\nsetup.py\\ntests\\ntodo.txt\\n' >>> notepad = local[\"c:\\\\windows\\\\notepad.exe\"] >>> notepad()                                   # Notepad window pops up u''                                             # Notepad window is closed by user, command returns      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "22", "A_Content": "  os.system is OK, but kind of dated.  It's also not very secure.  Instead, try subprocess.  subprocess does not call sh directly and is therefore more secure than os.system.  Get more information here.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "21", "A_Content": "  Use:  import os  cmd = 'ls -al'  os.system(cmd)   os - This module provides a portable way of using operating system-dependent functionality.  For the more os functions, here is the documentation.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "17", "A_Content": "     Calling an external command in Python   Simple, use subprocess.run, which returns a CompletedProcess object:  >>> import subprocess >>> completed_process = subprocess.run('python --version') Python 3.6.1 :: Anaconda 4.4.0 (64-bit) >>> completed_process CompletedProcess(args='python --version', returncode=0)   Why?  As of Python 3.5, the documentation recommends subprocess.run:     The recommended approach to invoking subprocesses is to use the run() function for all use cases it can handle. For more advanced use cases, the underlying Popen interface can be used directly.   Here's an example of the simplest possible usage - and it does exactly as asked:  >>> import subprocess >>> completed_process = subprocess.run('python --version') Python 3.6.1 :: Anaconda 4.4.0 (64-bit) >>> completed_process CompletedProcess(args='python --version', returncode=0)   run waits for the command to successfully finish, then returns a CompletedProcess object. It may instead raise TimeoutExpired (if you give it a timeout= argument) or CalledProcessError (if it fails and you pass check=True).  As you might infer from the above example, stdout and stderr both get piped to your own stdout and stderr by default.  We can inspect the returned object and see the command that was given and the returncode:  >>> completed_process.args 'python --version' >>> completed_process.returncode 0   Capturing output  If you want to capture the output, you can pass subprocess.PIPE to the appropriate stderr or stdout:  >>> cp = subprocess.run('python --version',                          stderr=subprocess.PIPE,                          stdout=subprocess.PIPE) >>> cp.stderr b'Python 3.6.1 :: Anaconda 4.4.0 (64-bit)\\r\\n' >>> cp.stdout b''   (I find it interesting and slightly counterintuitive that the version info gets put to stderr instead of stdout.)  Pass a command list  One might easily move from manually providing a command string (like the question suggests) to providing a string built programmatically. Don't build strings programmatically. This is a potential security issue. It's better to assume you don't trust the input.   >>> import textwrap >>> args = ['python', textwrap.__file__] >>> cp = subprocess.run(args, stdout=subprocess.PIPE) >>> cp.stdout b'Hello there.\\r\\n  This is indented.\\r\\n'   Note, only args should be passed positionally.  Full Signature  Here's the actual signature in the source and as shown by help(run):   def run(*popenargs, input=None, timeout=None, check=False, **kwargs):    The popenargs and kwargs are given to the Popen constructor. input can be a string of bytes (or unicode, if specify encoding or universal_newlines=True) that will be piped to the subprocess's stdin.  The documentation describes timeout= and check=True better than I could:     The timeout argument is passed to Popen.communicate(). If the timeout   expires, the child process will be killed and waited for. The   TimeoutExpired exception will be re-raised after the child process has   terminated.      If check is true, and the process exits with a non-zero exit code, a   CalledProcessError exception will be raised. Attributes of that   exception hold the arguments, the exit code, and stdout and stderr if   they were captured.   and this example for check=True is better than one I could come up with:   >>> subprocess.run(\"exit 1\", shell=True, check=True) Traceback (most recent call last):   ... subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1    Expanded Signature  Here's an expanded signature, as given in the documentation:   subprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None,  shell=False, cwd=None, timeout=None, check=False, encoding=None,  errors=None)    Note that this indicates that only the args list should be passed positionally. So pass the remaining arguments as keyword arguments.  Popen  When use Popen instead? I would struggle to find use-case based on the arguments alone. Direct usage of Popen would, however, give you access to its methods, including poll, 'send_signal', 'terminate', and 'wait'.  Here's the Popen signature as given in the source. I think this is the most precise encapsulation of the information (as opposed to help(Popen)):  def __init__(self, args, bufsize=-1, executable=None,              stdin=None, stdout=None, stderr=None,              preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,              shell=False, cwd=None, env=None, universal_newlines=False,              startupinfo=None, creationflags=0,              restore_signals=True, start_new_session=False,              pass_fds=(), *, encoding=None, errors=None):   But more informative is the Popen documentation:   subprocess.Popen(args, bufsize=-1, executable=None, stdin=None,                  stdout=None, stderr=None, preexec_fn=None, close_fds=True,                  shell=False, cwd=None, env=None, universal_newlines=False,                  startupinfo=None, creationflags=0, restore_signals=True,                  start_new_session=False, pass_fds=(), *, encoding=None, errors=None)       Execute a child program in a new process. On POSIX, the class uses   os.execvp()-like behavior to execute the child program. On Windows,   the class uses the Windows CreateProcess() function. The arguments to   Popen are as follows.   Understanding the remaining documentation on Popen will be left as an exercise for the reader.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "17", "A_Content": "  It can be this simple:  import os cmd = \"your command\" os.system(cmd)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "16", "A_Content": "  subprocess.check_call is convenient if you don't want to test return values. It throws an exception on any error.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "16", "A_Content": "  There is another difference here which is not mentioned previously.  subprocess.Popen executes the <command> as a subprocess. In my case, I need to execute file <a> which needs to communicate with another program, <b>.   I tried subprocess, and execution was successful. However <b> could not communicate with <a>. Everything is normal when I run both from the terminal.  One more:  (NOTE: kwrite behaves different from other applications. If you try the below with Firefox, the results will not be the same.)  If you try os.system(\"kwrite\"), program flow freezes until the user closes kwrite. To overcome that I tried instead os.system(konsole -e kwrite). This time program continued to flow, but kwrite became the subprocess of the console.  Anyone runs the kwrite not being a subprocess (i.e. in the system monitor it must appear at the leftmost edge of the tree).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "15", "A_Content": "  os.system does not allow you to store results, so if you want to store results in some list or something subprocess.call works.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "15", "A_Content": "  I tend to use subprocess together with shlex (to handle escaping of quoted strings):  >>> import subprocess, shlex >>> command = 'ls -l \"/your/path/with spaces/\"' >>> call_params = shlex.split(command) >>> print call_params [\"ls\", \"-l\", \"/your/path/with spaces/\"] >>> subprocess.call(call_params)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "13", "A_Content": "  Shameless plug, I wrote a library for this :P https://github.com/houqp/shell.py  It's basically a wrapper for popen and shlex for now. It also supports piping commands so you can chain commands easier in Python. So you can do things like:  ex('echo hello shell.py') | \"awk '{print $2}'\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "13", "A_Content": "  You can use Popen, and then you can check the procedure's status:  from subprocess import Popen  proc = Popen(['ls', '-l']) if proc.poll() is None:     proc.kill()   Check out subprocess.Popen.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "13", "A_Content": "  I quite like shell_command for its simplicity.  It's built on top of the subprocess module.  Here's an example from the docs:  >>> from shell_command import shell_call >>> shell_call(\"ls *.py\") setup.py  shell_command.py  test_shell_command.py 0 >>> shell_call(\"ls -l *.py\") -rw-r--r-- 1 ncoghlan ncoghlan  391 2011-12-11 12:07 setup.py -rw-r--r-- 1 ncoghlan ncoghlan 7855 2011-12-11 16:16 shell_command.py -rwxr-xr-x 1 ncoghlan ncoghlan 8463 2011-12-11 16:17 test_shell_command.py 0      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "12", "A_Content": "  To fetch the network id from the openstack neutron:  #!/usr/bin/python import os netid= \"nova net-list | awk '/ External / { print $2 }'\" temp=os.popen(netid).read()  /* here temp also contains new line (\\n) */ networkId=temp.rstrip() print(networkId)   Output of nova net-list  +--------------------------------------+------------+------+ | ID                                   | Label      | CIDR | +--------------------------------------+------------+------+ | 431c9014-5b5d-4b51-a357-66020ffbb123 | test1      | None | | 27a74fcd-37c0-4789-9414-9531b7e3f126 | External   | None | | 5a2712e9-70dc-4b0e-9281-17e02f4684c9 | management | None | | 7aa697f5-0e60-4c15-b4cc-9cb659698512 | Internal   | None | +--------------------------------------+------------+------+   Output of print(networkId)  27a74fcd-37c0-4789-9414-9531b7e3f126      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python", "Language": "Python", "Q_Title": "Calling an external command in Python", "Q_Votes": "3717", "Q_Content": "    How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?     ", "Tags": ["python", "shell", "command", "subprocess", "external"], "A_Votes": "12", "A_Content": "  Under Linux, in case you would like to call an external command that will execute independently (will keep running after the python script terminates), you can use a simple queue as task spooler or the at command  An example with task spooler:  import os os.system('ts <your-command>')   Notes about task spooler (ts):    You could set the number of concurrent processes to be run (\"slots\") with:  ts -S <number-of-slots> Installing ts doesn't requires admin privileges. You can download and compile it from source with a simple make, add it to your path and you're done.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "4050", "A_Content": "  If the reason you're checking is so you can do something like if file_exists: open_it(), it's safer to use a try around the attempt to open it. Checking and then opening risks the file being deleted or moved or something between when you check and when you try to open it.  If you're not planning to open the file immediately, you can use os.path.isfile     Return True if path is an existing regular file. This follows symbolic links, so both islink() and isfile() can be true for the same path.   import os.path os.path.isfile(fname)    if you need to be sure it's a file.  Starting with Python 3.4, the pathlib module offers an object-oriented approach (backported to pathlib2 in Python 2.7):  from pathlib import Path  my_file = Path(\"/path/to/file\") if my_file.is_file():     # file exists   To check a directory, do:  if my_file.is_dir():     # directory exists   To check whether a Path object exists independently of whether is it a file or directory, use exists():  if my_file.exists():     # path exists   You can also use resolve() in a try block:  try:     my_abs_path = my_file.resolve() except FileNotFoundError:     # doesn't exist else:     # exists      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "1657", "A_Content": "  You have the os.path.exists function:  import os.path os.path.exists(file_path)   This returns True for both files and directories but you can instead use  os.path.isfile(file_name)   to test if it's a file specifically. It follows symlinks.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "841", "A_Content": "  Unlike isfile(), exists() will return True for directories. So depending on if you want only plain files or also directories, you'll use isfile() or exists(). Here is a simple REPL output.  >>> print os.path.isfile(\"/etc/password.txt\") True >>> print os.path.isfile(\"/etc\") False >>> print os.path.isfile(\"/does/not/exist\") False >>> print os.path.exists(\"/etc/password.txt\") True >>> print os.path.exists(\"/etc\") True >>> print os.path.exists(\"/does/not/exist\") False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "480", "A_Content": "  import os.path  if os.path.isfile(filepath):      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "235", "A_Content": "  Use os.path.isfile() with os.access():  import os import os.path  PATH='./file.txt'  if os.path.isfile(PATH) and os.access(PATH, os.R_OK):     print \"File exists and is readable\" else:     print \"Either the file is missing or not readable\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "220", "A_Content": "  import os os.path.exists(path) # Returns whether the path (directory or file) exists or not os.path.isfile(path) # Returns whether the file exists or not      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "146", "A_Content": "  2017 / 12 / 22:  Although almost every possible way has been listed in (at least one of) the existing answers (e.g. Python 3.4 specific stuff was added), I'll try to group everything together.  Note: every piece of Python standard library code that I'm going to post, belongs to version 3.5.3 (doc quotes are version 3 specific).  Problem statement:   Check file (arguable: also folder (\"special\" file) ?) existence Don't use try / except / else / finally blocks   Possible solutions:   [Python]: os.path.exists(path) (also check other function family members like os.path.isfile, os.path.isdir, os.path.lexists for slightly different behaviors)  os.path.exists(path)      Return True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic links. On some platforms, this function may return False if permission is not granted to execute os.stat() on the requested file, even if the path physically exists.   All good, but if following the import tree:   os.path - posixpath.py (ntpath.py)   genericpath.py, line ~#20+  def exists(path):     \"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"     try:         st = os.stat(path)     except os.error:         return False     return True     it's just a try/except block around [Python]: os.stat(path, *, dir_fd=None, follow_symlinks=True). So, your code is try/except free, but lower in the framestack there's (at least) one such block. This also applies to other funcs (including os.path.isfile).  1.1. [Python]: pathlib.Path.is_file()   It's a fancier (and more pythonic) way of handling paths, but Under the hood, it does exactly the same thing (pathlib.py, line ~#1330):  def is_file(self):     \"\"\"     Whether this path is a regular file (also True for symlinks pointing     to regular files).     \"\"\"     try:         return S_ISREG(self.stat().st_mode)     except OSError as e:         if e.errno not in (ENOENT, ENOTDIR):             raise         # Path doesn't exist or is a broken symlink         # (see https://bitbucket.org/pitrou/pathlib/issue/12/)         return False   [Python]: With Statement Context Managers. Either:   Create one:  class Swallow:  # Dummy example     swallowed_exceptions = (FileNotFoundError,)      def __enter__(self):         print(\"Entering...\")      def __exit__(self, exc_type, exc_value, exc_traceback):         print(\"Exiting:\", exc_type, exc_value, exc_traceback)         return exc_type in Swallow.swallowed_exceptions  # only swallow FileNotFoundError (not e.g. TypeError - if the user passes a wrong argument like None or float or ...)    And its usage - I'll replicate the isfile behavior (note that this is just for demonstrating purposes, do not attempt to write such code for production):  import os import stat   def isfile_seaman(path):  # Dummy func     result = False     with Swallow():         result = stat.S_ISREG(os.stat(path).st_mode)     return result   Use [Python]: contextlib.suppress(*exceptions) - which was specifically designed for selectively suppressing exceptions   But, they seem to be wrappers over try/except/else/finally blocks, as [Python]: The with statement states:     This allows common try...except...finally usage patterns to be encapsulated for convenient reuse.  Filesystem traversal functions (and search the results for matching item(s))   [Python]: os.listdir(path='.') (or [Python]: os.scandir(path='.') on Python v3.5+)   Under the hood, both use [man]: OPENDIR(3) / [man]: READDIR(3) / [man]: CLOSEDIR(3) ([MSDN]: FindFirstFile function / [MSDN]: FindNextFile function / [MSDN]: FindClose function) - via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"      Using scandir() instead of listdir() can significantly increase the performance of code that also needs file type or file attribute information, because os.DirEntry objects expose this information if the operating system provides it when scanning a directory. All os.DirEntry methods may perform a system call, but is_dir() and is_file() usually only require a system call for symbolic links; os.DirEntry.stat() always requires a system call on Unix but only requires one for symbolic links on Windows.  [Python]: os.walk(top, topdown=True, onerror=None, followlinks=False)   It uses os.listdir (os.scandir when available)  [Python]: glob.iglob(pathname, recursive=False) ([Python]: glob.glob(pathname, *, recursive=False))   Doesn't seem a traversing function per se (at least in some cases), but it still uses os.listdir    Since these iterate over folders, (in most of the cases) they are inefficient for our problem (there are exceptions, like non wildcarded globbing - as @ShadowRanger pointed out), so I'm not going to insist on them. Not to mention that in some cases, filename processing might be required. [Python]: os.access(path, mode, *, dir_fd=None, effective_ids=False, follow_symlinks=True) whose behavior is close to os.path.exists (actually it's wider, mainly because of the 2nd argument)   user permissions might restrict the file \"visibility\" as the doc states:     ...test if the invoking user has the specified access to path. mode should be F_OK to test the existence of path...      os.access(\"/tmp\", os.F_OK)   Since I also work in C, I use this method as well because under the hood, it calls native APIs (again, via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants. So, as @AaronHall rightly pointed out, don't use it unless you know what you're doing:   Ux: [man]: ACCESS(2) (!!! pay attention to the note about the security hole its usage might introduce !!!) Win: [MSDN]: GetFileAttributes function   Note: calling native APIs is also possible via [Python]: ctypes \u2014 A foreign function library for Python, but in most cases it's more complicated.  (Win specific): Since msvcr*(vcruntime*) exports a [MSDN]: _access, _waccess function family as well, here's an example:   Python 3.5.3 (v3.5.3:1880cb95a742, Jan 16 2017, 16:02:32) [MSC v.1900 64 bit (AMD64)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import os, ctypes >>> ctypes.CDLL(\"msvcrt\")._waccess(u\"C:\\\\Windows\\\\System32\\\\cmd.exe\", os.F_OK) 0 >>> ctypes.CDLL(\"msvcrt\")._waccess(u\"C:\\\\Windows\\\\System32\\\\___cmd.exe\", os.F_OK) -1    Notes:   Although it's not a good practice, I'm using os.F_OK in the call, but that's just for clarity (its value is 0) I'm using _waccess so that the same code works on Python3 and Python2 (in spite of unicode related differences between them) Although this targets a very specific area, it was not mentioned in any of the previous answers   The Lnx (Ubtu (16 x64)) counterpart as well:   Python 3.5.2 (default, Nov 17 2016, 17:05:23) [GCC 5.4.0 20160609] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import os, ctypes >>> ctypes.CDLL(\"/lib/x86_64-linux-gnu/libc.so.6\").access(b\"/tmp\", os.F_OK) 0 >>> ctypes.CDLL(\"/lib/x86_64-linux-gnu/libc.so.6\").access(b\"/tmp1\", os.F_OK) -1    Notes:   Instead hardcoding libc's path (\"/lib/x86_64-linux-gnu/libc.so.6\") which may (and most likely, will) vary across systems, None (or the empty string) can be passed to CDLL constructor (ctypes.CDLL(None).access(b\"/tmp\", os.F_OK)). According to [man]: DLOPEN(3):     If filename is NULL, then the returned handle is for the main   program.  When given to dlsym(), this handle causes a search for a   symbol in the main program, followed by all shared objects loaded at   program startup, and then all shared objects loaded by dlopen() with   the flag RTLD_GLOBAL.    Main (current) program (python) is linked against libc, so its symbols (including access) will be loaded This has to be handled with care, since functions like main, Py_Main and (all the) others are available; calling them could have disastrous effects (on the current program) This doesn't also apply to Win (but that's not such a big deal, since msvcrt.dll is located in \"%SystemRoot%\\System32\" which is in %PATH% by default). I wanted to take things further and replicate this behavior on Win (and submit a patch), but as it turns out, [MSDN]: GetProcAddress function only \"sees\" exported symbols, so unless someone declares the functions in the main executable as __declspec(dllexport) (why on Earth the regular person would do that?), the main program is loadable but pretty much unusable   Install some 3rd Party module with filesystem capabilities  Most likely, will rely on one of the ways above (maybe with slight customizations).One example would be (again, Win specific) [GitHub]: Python for Windows (pywin32) Extensions, which is a Python wrapper over WINAPIs.  But, since this is more like a workaround, I'm stopping here. Another (lame) workaround (gainarie) is (as I like to call it,) the sysadmin approach: use Python as a wrapper to execute shell commands   Win:   (py35x64_test) e:\\Work\\Dev\\StackOverflow\\q000082831>\"e:\\Work\\Dev\\VEnvs\\py35x64_test\\Scripts\\python.exe\" -c \"import os; print(os.system('dir /b \\\"C:\\\\Windows\\\\System32\\\\cmd.exe\\\" > nul 2>&1'))\" 0  (py35x64_test) e:\\Work\\Dev\\StackOverflow\\q000082831>\"e:\\Work\\Dev\\VEnvs\\py35x64_test\\Scripts\\python.exe\" -c \"import os; print(os.system('dir /b \\\"C:\\\\Windows\\\\System32\\\\cmd.exe.notexist\\\" > nul 2>&1'))\" 1   Lnx (Ubtu):   [cfati@cfati-ubtu16x64-0:~]> python3 -c \"import os; print(os.system('ls \\\"/tmp\\\" > /dev/null 2>&1'))\" 0 [cfati@cfati-ubtu16x64-0:~]> python3 -c \"import os; print(os.system('ls \\\"/tmp.notexist\\\" > /dev/null 2>&1'))\" 512      Bottom line:   Do use try / except / else / finally blocks, because they can prevent you running into a series of nasty problems. A counter-example that I can think of, is performance: such blocks are costly, so try not to place them in code that it's supposed to run hundreds of thousands times per second (but since (in most cases) it involves disk access, it won't be the case).   Final note(s):   I will try to keep it up to date, any suggestions are welcome, I will incorporate anything useful that will come up into the answer      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "140", "A_Content": "  This is the simplest way to check if a file exists. Just because the file existed when you checked doesn't guarantee that it will be there when you need to open it.  import os fname = \"foo.txt\" if os.path.isfile(fname):     print(\"file does exist at this time\") else:     print(\"no such file exists at this time\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "124", "A_Content": "  Python 3.4+ has an object-oriented path module: pathlib.  Using this new module, you can check whether a file exists like this:  import pathlib p = pathlib.Path('path/to/file') if p.is_file():  # or p.is_dir() to see if it is a directory     # do stuff   You can (and usually should) still use a try/except block when opening files:  try:     with p.open() as f:         # do awesome stuff except OSError:     print('Well darn.')   The pathlib module has lots of cool stuff in it: convenient globbing, checking file's owner, easier path joining, etc.  It's worth checking out.  If you're on an older Python (version 2.6 or later), you can still install pathlib with pip:  # installs pathlib2 on older Python versions # the original third-party module, pathlib, is no longer maintained. pip install pathlib2   Then import it as follows:  # Older Python versions import pathlib2 as pathlib      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "112", "A_Content": "  Prefer the try statement. It's considered better style and avoids race conditions.  Don't take my word for it. There's plenty of support for this theory. Here's a couple:   Style: Section \"Handling unusual conditions\" of http://allendowney.com/sd/notes/notes11.txt Avoiding Race Conditions      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "103", "A_Content": "     How do I check whether a file exists, using Python, without using a try statement?   Now available since Python 3.4, import and instantiate a Path object with the file name, and check the is_file method (note that this returns True for symlinks pointing to regular files as well):  >>> from pathlib import Path >>> Path('/').is_file() False >>> Path('/initrd.img').is_file() True >>> Path('/doesnotexist').is_file() False   If you're on Python 2, you can backport the pathlib module from pypi, pathlib2, or otherwise check isfile from the os.path module:  >>> import os >>> os.path.isfile('/') False >>> os.path.isfile('/initrd.img') True >>> os.path.isfile('/doesnotexist') False   Now the above is probably the best pragmatic direct answer here, but there's the possibility of a race condition (depending on what you're trying to accomplish), and the fact that the underlying implementation uses a try, but Python uses try everywhere in its implementation.   Because Python uses try everywhere, there's really no reason to avoid an implementation that uses it.  But the rest of this answer attempts to consider these caveats.  Longer, much more pedantic answer  Available since Python 3.4, use the new Path object in pathlib. Note that .exists is not quite right, because directories are not files (except in the unix sense that everything is a file).  >>> from pathlib import Path >>> root = Path('/') >>> root.exists() True   So we need to use is_file:  >>> root.is_file() False   Here's the help on is_file:  is_file(self)     Whether this path is a regular file (also True for symlinks pointing     to regular files).   So let's get a file that we know is a file:  >>> import tempfile >>> file = tempfile.NamedTemporaryFile() >>> filepathobj = Path(file.name) >>> filepathobj.is_file() True >>> filepathobj.exists() True   By default, NamedTemporaryFile deletes the file when closed (and will automatically close when no more references exist to it).  >>> del file >>> filepathobj.exists() False >>> filepathobj.is_file() False   If you dig into the implementation, though, you'll see that is_file uses try:  def is_file(self):     \"\"\"     Whether this path is a regular file (also True for symlinks pointing     to regular files).     \"\"\"     try:         return S_ISREG(self.stat().st_mode)     except OSError as e:         if e.errno not in (ENOENT, ENOTDIR):             raise         # Path doesn't exist or is a broken symlink         # (see https://bitbucket.org/pitrou/pathlib/issue/12/)         return False   Race Conditions: Why we like try  We like try because it avoids race conditions. With try, you simply attempt to read your file, expecting it to be there, and if not, you catch the exception and perform whatever fallback behavior makes sense.  If you want to check that a file exists before you attempt to read it, and you might be deleting it and then you might be using multiple threads or processes, or another program knows about that file and could delete it - you risk the chance of a race condition if you check it exists, because you are then racing to open it before its condition (its existence) changes.   Race conditions are very hard to debug because there's a very small window in which they can cause your program to fail.  But if this is your motivation, you can get the value of a try statement by using the suppress context manager.  Avoiding race conditions without a try statement: suppress  Python 3.4 gives us the suppress context manager (previously the ignore context manager), which does semantically exactly the same thing in fewer lines, while also (at least superficially) meeting the original ask to avoid a try statement:  from contextlib import suppress from pathlib import Path   Usage:  >>> with suppress(OSError), Path('doesnotexist').open() as f: ...     for line in f: ...         print(line) ...  >>> >>> with suppress(OSError): ...     Path('doesnotexist').unlink() ...  >>>    For earlier Pythons, you could roll your own suppress, but without a try will be more verbose than with. I do believe this actually is the only answer that doesn't use try at any level in the Python that can be applied to prior to Python 3.4 because it uses a context manager instead:  class suppress(object):     def __init__(self, *exceptions):         self.exceptions = exceptions     def __enter__(self):         return self     def __exit__(self, exc_type, exc_value, traceback):         if exc_type is not None:             return issubclass(exc_type, self.exceptions)   Perhaps easier with a try:  from contextlib import contextmanager  @contextmanager def suppress(*exceptions):     try:         yield     except exceptions:         pass   Other options that don't meet the ask for \"without try\":  isfile  import os os.path.isfile(path)   from the docs:     os.path.isfile(path)      Return True if path is an existing regular file. This follows symbolic   links, so both islink() and isfile() can be true for the same path.   But if you examine the source of this function, you'll see it actually does use a try statement:   # This follows symbolic links, so both islink() and isdir() can be true # for the same path on systems that support symlinks def isfile(path):     \"\"\"Test whether a path is a regular file\"\"\"     try:         st = os.stat(path)     except os.error:         return False     return stat.S_ISREG(st.st_mode)    >>> OSError is os.error True   All it's doing is using the given path to see if it can get stats on it,  catching OSError and then checking if it's a file if it didn't raise the exception.  If you intend to do something with the file, I would suggest directly attempting it with a try-except to avoid a race condition:  try:     with open(path) as f:         f.read() except OSError:     pass   os.access  Available for Unix and Windows is os.access, but to use you must pass flags, and it does not differentiate between files and directories. This is more used to test if the real invoking user has access in an elevated privilege environment:  import os os.access(path, os.F_OK)   It also suffers from the same race condition problems as isfile. From the docs:     Note:   Using access() to check if a user is authorized to e.g. open a file   before actually doing so using open() creates a security hole, because   the user might exploit the short time interval between checking and   opening the file to manipulate it. It\u2019s preferable to use EAFP   techniques. For example:  if os.access(\"myfile\", os.R_OK):     with open(\"myfile\") as fp:         return fp.read() return \"some default data\"       is better written as:  try:     fp = open(\"myfile\") except IOError as e:     if e.errno == errno.EACCES:         return \"some default data\"     # Not a permission error.     raise else:     with fp:         return fp.read()    Avoid using os.access. It is a low level function that has more opportunities for user error than the higher level objects and functions discussed above.  Criticism of another answer:  Another answer says this about os.access:     Personally, I prefer this one because under the hood, it calls native APIs (via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants:   This answer says it prefers a non-Pythonic, error-prone method, with no justification. It seems to encourage users to use low-level APIs without understanding them.   It also creates a context manager which, by unconditionally returning True, allows all Exceptions (including KeyboardInterrupt and SystemExit!) to pass silently, which is a good way to hide bugs.  This seems to encourage users to adopt poor practices.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "3473", "A_Content": "     How can I merge two Python dictionaries in a single expression?   For dictionaries x and y, z becomes a merged dictionary with values from y replacing those from x.   In Python 3.5 or greater, :  z = {**x, **y} w = {'foo': 'bar', 'baz': 'qux', **y}  # merge a dict with literal values  In Python 2, (or 3.4 or lower) write a function:  def merge_two_dicts(x, y):     z = x.copy()   # start with x's keys and values     z.update(y)    # modifies z with y's keys and values & returns None     return z   and  z = merge_two_dicts(x, y)    Explanation  Say you have two dicts and you want to merge them into a new dict without altering the original dicts:  x = {'a': 1, 'b': 2} y = {'b': 3, 'c': 4}   The desired result is to get a new dictionary (z) with the values merged, and the second dict's values overwriting those from the first.  >>> z {'a': 1, 'b': 3, 'c': 4}   A new syntax for this, proposed in PEP 448 and available as of Python 3.5, is   z = {**x, **y}   And it is indeed a single expression. It is now showing as implemented in the release schedule for 3.5, PEP 478, and it has now made its way into What's New in Python 3.5 document.  However, since many organizations are still on Python 2, you may wish to do this in a backwards compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:  z = x.copy() z.update(y) # which returns None since it mutates z   In both approaches, y will come second and its values will replace x's values, thus 'b' will point to 3 in our final result.  Not yet on Python 3.5, but want a single expression  If you are not yet on Python 3.5, or need to write backward-compatible code, and you want this in a single expression, the most performant while correct approach is to put it in a function:  def merge_two_dicts(x, y):     \"\"\"Given two dicts, merge them into a new dict as a shallow copy.\"\"\"     z = x.copy()     z.update(y)     return z   and then you have a single expression:  z = merge_two_dicts(x, y)   You can also make a function to merge an undefined number of dicts, from zero to a very large number:  def merge_dicts(*dict_args):     \"\"\"     Given any number of dicts, shallow copy and merge into a new dict,     precedence goes to key value pairs in latter dicts.     \"\"\"     result = {}     for dictionary in dict_args:         result.update(dictionary)     return result   This function will work in Python 2 and 3 for all dicts. e.g. given dicts a to g:  z = merge_dicts(a, b, c, d, e, f, g)    and key value pairs in g will take precedence over dicts a to f, and so on.  Critiques of Other Answers  Don't use what you see in the formerly accepted answer:  z = dict(x.items() + y.items())   In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. In Python 3, this will fail because you're adding two dict_items objects together, not two lists -   >>> c = dict(a.items() + b.items()) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'   and you would have to explicitly create them as lists, e.g. z = dict(list(x.items()) + list(y.items())). This is a waste of resources and computation power.   Similarly, taking the union of items() in Python 3 (viewitems() in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:  >>> c = dict(a.items() | b.items())   This example demonstrates what happens when values are unhashable:  >>> x = {'a': []} >>> y = {'b': []} >>> dict(x.items() | y.items()) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: unhashable type: 'list'   Here's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:  >>> x = {'a': 2} >>> y = {'a': 1} >>> dict(x.items() | y.items()) {'a': 2}   Another hack you should not use:  z = dict(x, **y)   This uses the dict constructor, and is very fast and memory efficient (even slightly more-so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.   Here's an example of the usage being remediated in django.  Dicts are intended to take hashable keys (e.g. frozensets or tuples), but this method fails in Python 3 when keys are not strings.  >>> c = dict(a, **b) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: keyword arguments must be strings   From the mailing list, Guido van Rossum, the creator of the language, wrote:     I am fine with   declaring dict({}, **{1:3}) illegal, since after all it is abuse of   the ** mechanism.   and      Apparently dict(x, **y) is going around as \"cool hack\" for \"call   x.update(y) and return x\". Personally I find it more despicable than   cool.   It is my understanding (as well as the understanding of the creator of the language) that the intended usage for dict(**y) is for creating dicts for readability purposes, e.g.:  dict(a=1, b=10, c=11)   instead of   {'a': 1, 'b': 10, 'c': 11}   Response to comments     Despite what Guido says, dict(x, **y) is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-comming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact ** was designed precisely to pass dicts as keywords.    Again, it doesn't work for 3 when keys are non-strings. The implicit calling contract is that namespaces take ordinary dicts, while users must only pass keyword arguments that are strings. All other callables enforced it. dict broke this consistency in Python 2:  >>> foo(**{('a', 'b'): None}) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: foo() keywords must be strings >>> dict(**{('a', 'b'): None}) {('a', 'b'): None}   This inconsistency was bad given other implementations of Python (Pypy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.  I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.  Another comment:     dict(x.items() + y.items()) is still the most readable solution for Python 2. Readability counts.    My response: merge_two_dicts(x, y) actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.  Less Performant But Correct Ad-hocs  These approaches are less performant, but they will provide correct behavior. They will be much less performant than copy and update or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they do respect the order of precedence (latter dicts have precedence)  You can also chain the dicts manually inside a dict comprehension:  {k: v for d in dicts for k, v in d.items()} # iteritems in Python 2.7   or in python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):  dict((k, v) for d in dicts for k, v in d.items())   itertools.chain will chain the iterators over the key-value pairs in the correct order:  import itertools z = dict(itertools.chain(x.iteritems(), y.iteritems()))   Performance Analysis  I'm only going to do the performance analysis of the usages known to behave correctly.   import timeit   The following is done on Ubuntu 14.04  In Python 2.7 (system Python):  >>> min(timeit.repeat(lambda: merge_two_dicts(x, y))) 0.5726828575134277 >>> min(timeit.repeat(lambda: {k: v for d in (x, y) for k, v in d.items()} )) 1.163769006729126 >>> min(timeit.repeat(lambda: dict(itertools.chain(x.iteritems(), y.iteritems())))) 1.1614501476287842 >>> min(timeit.repeat(lambda: dict((k, v) for d in (x, y) for k, v in d.items()))) 2.2345519065856934   In Python 3.5 (deadsnakes PPA):  >>> min(timeit.repeat(lambda: {**x, **y})) 0.4094954460160807 >>> min(timeit.repeat(lambda: merge_two_dicts(x, y))) 0.7881555100320838 >>> min(timeit.repeat(lambda: {k: v for d in (x, y) for k, v in d.items()} )) 1.4525277839857154 >>> min(timeit.repeat(lambda: dict(itertools.chain(x.items(), y.items())))) 2.3143140770262107 >>> min(timeit.repeat(lambda: dict((k, v) for d in (x, y) for k, v in d.items()))) 3.2069112799945287   Resources on Dictionaries   My explanation of Python's dictionary implementation, updated for 3.6. Answer on how to add new keys to a dictionary Mapping two lists into a dictionary The official Python docs on dictionaries  The Dictionary Even Mightier - talk by Brandon Rhodes at Pycon 2017 Modern Python Dictionaries, A Confluence of Great Ideas - talk by Raymond Hettinger at Pycon 2017      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "80", "A_Content": "  import os #Your path here e.g. \"C:\\Program Files\\text.txt\" #For access purposes: \"C:\\\\Program Files\\\\text.txt\" if os.path.exists(\"C:\\...\"):        print \"File found!\" else:     print \"File not found!\"   Importing os makes it easier to navigate and perform standard actions with your operating system.   For reference also see How to check whether a file exists using Python?  If you need high-level operations, use shutil.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "67", "A_Content": "  Testing for files and folders with os.path.isfile(), os.path.isdir() and os.path.exists()  Assuming that the \"path\" is a valid path, this table shows what is returned by each function for files and folders:    You can also test if a file is a certain type of file using os.path.splitext() to get the extension (if you don't already know it)  >>> import os >>> path = \"path to a word document\" >>> os.path.isfile(path) True >>> os.path.splitext(path)[1] == \".docx\" # test if the extension is .docx True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "63", "A_Content": "  In 2016 the best way is still using os.path.isfile:  >>> os.path.isfile('/path/to/some/file.txt')   Or in Python 3 you can use pathlib:  import pathlib path = pathlib.Path('/path/to/some/file.txt') if path.is_file():     ...      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "59", "A_Content": "  It doesn't seem like there's a meaningful functional difference between try/except and isfile(), so you should use which one makes sense.  If you want to read a file, if it exists, do  try:     f = open(filepath) except IOError:     print 'Oh dear.'   But if you just wanted to rename a file if it exists, and therefore don't need to open it, do  if os.path.isfile(filepath):     os.rename(filepath, filepath + '.old')   If you want to write to a file, if it doesn't exist, do  # python 2 if not os.path.isfile(filepath):     f = open(filepath, 'w')  # python 3, x opens for exclusive creation, failing if the file already exists try:     f = open(filepath, 'wx') except IOError:     print 'file already exists'   If you need file locking, that's a different matter.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "51", "A_Content": "  You could try this (safer):  try:     # http://effbot.org/zone/python-with-statement.htm     # 'with' is safer to open a file     with open('whatever.txt') as fh:         # Do something with 'fh' except IOError as e:     print(\"({})\".format(e))   The ouput would be:     ([Errno 2] No such file or directory:   'whatever.txt')   Then, depending on the result, your program can just keep running from there or you can code to stop it if you want.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "45", "A_Content": "  Although I always recommend using try and except statements, here are a few possibilities for you (my personal favourite is using os.access):   Try opening the file:  Opening the file will always verify the existence of the file. You can make a function just like so:  def File_Existence(filepath):     f = open(filepath)     return True   If it's False, it will stop execution with an unhanded IOError or OSError in later versions of Python. To catch the exception, you have to use a try except clause. Of course, you can always use a try except` statement like so (thanks to hsandt for making me think):  def File_Existence(filepath):     try:         f = open(filepath)     except IOError, OSError: # Note OSError is for later versions of Python         return False      return True  Use os.path.exists(path):  This will check the existence of what you specify. However, it checks for files and directories so beware about how you use it.  import os.path >>> os.path.exists(\"this/is/a/directory\") True >>> os.path.exists(\"this/is/a/file.txt\") True >>> os.path.exists(\"not/a/directory\") False  Use os.access(path, mode):  This will check whether you have access to the file. It will check for permissions. Based on the os.py documentation, typing in os.F_OK, it will check the existence of the path. However, using this will create a security hole, as someone can attack your file using the time between checking the permissions and opening the file. You should instead go directly to opening the file instead of checking its permissions. (EAFP vs LBYP). If you're not going to open the file afterwards, and only checking its existence, then you can use this.  Anyway, here:  >>> import os >>> os.access(\"/is/a/file.txt\", os.F_OK) True    I should also mention that there are two ways that you will not be able to verify the existence of a file. Either the issue will be permission denied or no such file or directory. If you catch an IOError, set the IOError as e (like my first option), and then type in print(e.args) so that you can hopefully determine your issue. I hope it helps! :)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "32", "A_Content": "  Additionally, os.access():  if os.access(\"myfile\", os.R_OK):     with open(\"myfile\") as fp:         return fp.read()   Being R_OK, W_OK, and X_OK the flags to test for permissions (doc).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "32", "A_Content": "  In Python 3.4 the language provides a new module to manage files:  import pathlib path = pathlib.Path('path/to/file') if path.is_file(): # If you want to check a directory: path.is_dir()     # If it is true, return true on your code.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "22", "A_Content": "  If the file is for opening you could use one of the following techniques:  >>> with open('somefile', 'xt') as f: #Using the x-flag, Python3.3 and above ...     f.write('Hello\\n')  >>> if not os.path.exists('somefile'):  ...     with open('somefile', 'wt') as f: ...         f.write(\"Hello\\n\") ... else: ...     print('File already exists!')     UPDATE  Just to avoid confusion and based on the answers I got, current answer finds either a file or a directory with the given name.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "20", "A_Content": "  if os.path.isfile(path_to_file):     try:          open(path_to_file)             pass     except IOError as e:         print \"Unable to open file\"      Raising exceptions is considered to be an acceptable, and Pythonic,   approach for flow control in your program. Consider handling missing   files with IOErrors. In this situation, an IOError exception will be   raised if the file exists but the user does not have read permissions.   SRC: http://www.pfinn.net/python-check-if-file-exists.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "17", "A_Content": "  You can write Brian's suggestion without the try:.  from contextlib import suppress  with suppress(IOError), open('filename'):     process()   suppress is part of Python 3.4. In older releases you can quickly write your own suppress:  from contextlib import contextmanager  @contextmanager def suppress(*exceptions):     try:         yield     except exceptions:         pass      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "15", "A_Content": "  Here's a 1 line Python command for the Linux command line environment. I find this VERY HANDY since I'm not such a hot Bash guy.  python -c \"import os.path; print os.path.isfile('/path_to/file.xxx')\"   I hope this is helpful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "15", "A_Content": "  Adding one more slight variation which isn't exactly reflected in the other answers.  This will handle the case of the file_path being None or empty string.    def file_exists(file_path):     if not file_path:         return False     elif not os.path.isfile(file_path):         return False     else:         return True   Adding a variant based on suggestion from Shahbaz   def file_exists(file_path):     if not file_path:         return False     else:         return os.path.isfile(file_path)   Adding a variant based on suggestion from Peter Wood   def file_exists(file_path):     return file_path and os.path.isfile(file_path):      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "14", "A_Content": "  I'm the author of a package that's been around for about 10 years, and it has a function that addresses this question directly. Basically, if you are on a non-Windows system, it uses Popen to access find.  However, if you are on Windows, it replicates find with an efficient filesystem walker.  The code itself does not use a try block\u2026 except in determining the operating system and thus steering you to the \"Unix\"-style find or the hand-buillt find. Timing tests showed that the try was faster in determining the OS, so I did use one there (but nowhere else).  >>> import pox >>> pox.find('*python*', type='file', root=pox.homedir(), recurse=False) ['/Users/mmckerns/.python']   And the doc\u2026  >>> print pox.find.__doc__ find(patterns[,root,recurse,type]); Get path to a file or directory      patterns: name or partial name string of items to search for     root: path string of top-level directory to search     recurse: if True, recurse down from root directory     type: item filter; one of {None, file, dir, link, socket, block, char}     verbose: if True, be a little verbose about the search      On some OS, recursion can be specified by recursion depth (an integer).     patterns can be specified with basic pattern matching. Additionally,     multiple patterns can be specified by splitting patterns with a ';'     For example:         >>> find('pox*', root='..')         ['/Users/foo/pox/pox', '/Users/foo/pox/scripts/pox_launcher.py']          >>> find('*shutils*;*init*')         ['/Users/foo/pox/pox/shutils.py', '/Users/foo/pox/pox/__init__.py']  >>>   The implementation, if you care to look, is here: https://github.com/uqfoundation/pox/blob/89f90fb308f285ca7a62eabe2c38acb87e89dad9/pox/shutils.py#L190     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "14", "A_Content": "  Check file or directory exists  You can follow these three ways:     Note1: The os.path.isfile used only for files   import os.path os.path.isfile(filename) # True if file exists os.path.isfile(dirname) # False if directory exists      Note2: The os.path.exists used for both files and directories   import os.path os.path.exists(filename) # True if file exists os.path.exists(dirname) #True if directory exists      The pathlib.Path method (included in Python 3+, installable with pip for Python 2)   from pathlib import Path Path(filename).exists()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "12", "A_Content": "  Date:2017-12-04  Every possible solution has been listed in other answers.  An intuitive and arguable way to check if a file exists is the following:  import os os.path.isfile('~/file.md')    # Returns True if exists, else False additionaly check a dir os.path.isdir('~/folder') # Returns True if the folder exists, else False check either a dir or a file os.path.exists('~/file')   I made an exhaustive cheatsheet for your reference:  #os.path methods in exhaustive cheatsheet {'definition': ['dirname',                'basename',                'abspath',                'relpath',                'commonpath',                'normpath',                'realpath'], 'operation': ['split', 'splitdrive', 'splitext',                'join', 'normcase'], 'compare': ['samefile', 'sameopenfile', 'samestat'], 'condition': ['isdir',               'isfile',               'exists',               'lexists'               'islink',               'isabs',               'ismount',],  'expand': ['expanduser',             'expandvars'],  'stat': ['getatime', 'getctime', 'getmtime',           'getsize']}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "1452", "A_Content": "  In your case, what you can do is:  z = dict(x.items() + y.items())   This will, as you want it, put the final dict in z, and make the value for key b be properly overridden by the second (y) dict's value:  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = dict(x.items() + y.items()) >>> z {'a': 1, 'c': 11, 'b': 10}   If you use Python 3, it is only a little more complicated.  To create z:  >>> z = dict(list(x.items()) + list(y.items())) >>> z {'a': 1, 'c': 11, 'b': 10}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "554", "A_Content": "  An alternative:  z = x.copy() z.update(y)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "276", "A_Content": "  Another, more concise, option:  z = dict(x, **y)   Note: this has become a popular answer, but it is important to point out that if y has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also, Guido is not a fan. So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "170", "A_Content": "  This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or deepcopy, depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit.  In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item.  In terms of time:  >>> timeit.Timer(\"dict(x, **y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000) 15.52571702003479 >>> timeit.Timer(\"temp = x.copy()\\ntemp.update(y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000) 15.694622993469238 >>> timeit.Timer(\"dict(x.items() + y.items())\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000) 41.484580039978027   IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "117", "A_Content": "  In a follow-up answer, you asked about the relative performance of these two alternatives:  z1 = dict(x.items() + y.items()) z2 = dict(x, **y)   On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative z2 is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the timeit module that comes with Python.  Example 1: identical dictionaries mapping 20 consecutive integers to themselves:  % python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z1=dict(x.items() + y.items())' 100000 loops, best of 3: 5.67 usec per loop % python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z2=dict(x, **y)'  100000 loops, best of 3: 1.53 usec per loop   z2 wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but z2 always seems to come out ahead.  (If you get inconsistent results for the same test, try passing in -r with a number larger than the default 3.)  Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa:  % python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z1=dict(x.items() + y.items())' 1000 loops, best of 3: 260 usec per loop % python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z2=dict(x, **y)'                10000 loops, best of 3: 26.9 usec per loop   z2 wins by about a factor of 10.  That's a pretty big win in my book!  After comparing those two, I wondered if z1's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better:  from itertools import chain z3 = dict(chain(x.iteritems(), y.iteritems()))   A few quick tests, e.g.  % python -m timeit -s 'from itertools import chain; from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z3=dict(chain(x.iteritems(), y.iteritems()))' 10000 loops, best of 3: 66 usec per loop   lead me to conclude that z3 is somewhat faster than z1, but not nearly as fast as z2.  Definitely not worth all the extra typing.  This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the update method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows:  z0 = dict(x) z0.update(y)   A typical result:  % python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z0=dict(x); z0.update(y)' 10000 loops, best of 3: 26.9 usec per loop   In other words, z0 and z2 seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't....  In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses dict in lots of places; optimizing its operations is a big deal.  You could also write this as  z0 = x.copy() z0.update(y)   as Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "86", "A_Content": "  I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call.  def merge(d1, d2, merge_fn=lambda x,y:y):     \"\"\"     Merges two dictionaries, non-destructively, combining      values on duplicate keys as defined by the optional merge     function.  The default behavior replaces the values in d1     with corresponding values in d2.  (There is no other generally     applicable merge strategy, but often you'll have homogeneous      types in your dicts, so specifying a merge technique can be      valuable.)      Examples:      >>> d1     {'a': 1, 'c': 3, 'b': 2}     >>> merge(d1, d1)     {'a': 1, 'c': 3, 'b': 2}     >>> merge(d1, d1, lambda x,y: x+y)     {'a': 2, 'c': 6, 'b': 4}      \"\"\"     result = dict(d1)     for k,v in d2.iteritems():         if k in result:             result[k] = merge_fn(result[k], v)         else:             result[k] = v     return result      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "77", "A_Content": "  In Python 3, you can use collections.ChainMap which groups multiple dicts or other mappings together to create a single, updateable view:  >>> from collections import ChainMap >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = ChainMap({}, y, x) >>> for k, v in z.items():         print(k, '-->', v)  a --> 1 b --> 10 c --> 11      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "61", "A_Content": "  Recursively/deep update a dict  def deepupdate(original, update):     \"\"\"     Recursively update a dict.     Subdict's won't be overwritten but also updated.     \"\"\"     for key, value in original.iteritems():          if key not in update:             update[key] = value         elif isinstance(value, dict):             deepupdate(value, update[key])      return update  Demonstration:  pluto_original = {     'name': 'Pluto',     'details': {         'tail': True,         'color': 'orange'     } }  pluto_update = {     'name': 'Pluutoo',     'details': {         'color': 'blue'     } }  print deepupdate(pluto_original, pluto_update)  Outputs:  {     'name': 'Pluutoo',     'details': {         'color': 'blue',         'tail': True     } }  Thanks rednaw for edits.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "54", "A_Content": "  The best version I could think while not using copy would be:  from itertools import chain x = {'a':1, 'b': 2} y = {'b':10, 'c': 11} dict(chain(x.iteritems(), y.iteritems()))   It's faster than dict(x.items() + y.items()) but not as fast as n = copy(a); n.update(b), at least on CPython. This version also works in Python 3 if you change iteritems() to items(), which is automatically done by the 2to3 tool.  Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "42", "A_Content": "  Python 3.5 (PEP 448) allows a nicer syntax option:  x = {'a': 1, 'b': 1} y = {'a': 2, 'c': 2} final = {**x, **y}  final # {'a': 2, 'b': 1, 'c': 2}   Or even   final = {'a': 1, 'b': 1, **x, **y}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "40", "A_Content": "  x = {'a':1, 'b': 2} y = {'b':10, 'c': 11} z = dict(x.items() + y.items()) print z   For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "35", "A_Content": "  While the question has already been answered several times, this simple solution to the problem has not been listed yet.  x = {'a':1, 'b': 2} y = {'b':10, 'c': 11} z4 = {} z4.update(x) z4.update(y)   It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "33", "A_Content": "  def dict_merge(a, b):   c = a.copy()   c.update(b)   return c  new = dict_merge(old, extras)   Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life Guido van Rossum himself!  Someone else suggested half of this, but did not put it in a function.  print dict_merge(       {'color':'red', 'model':'Mini'},       {'model':'Ferrari', 'owner':'Carl'})   gives:  {'color': 'red', 'owner': 'Carl', 'model': 'Ferrari'}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "25", "A_Content": "  If you think lambdas are evil then read no further. As requested, you can write the fast and memory-efficient solution with one expression:  x = {'a':1, 'b':2} y = {'b':10, 'c':11} z = (lambda a, b: (lambda a_copy: a_copy.update(b) or a_copy)(a.copy()))(x, y) print z {'a': 1, 'c': 11, 'b': 10} print x {'a': 1, 'b': 2}   As suggested above, using two lines or writing a function is probably a better way to go.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "11", "A_Content": "  You can use the \"OS\" library of Python:  >>> import os >>> os.path.exists(\"C:\\\\Users\\\\####\\\\Desktop\\\\test.txt\")  True >>> os.path.exists(\"C:\\\\Users\\\\####\\\\Desktop\\\\test.tx\") False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "11", "A_Content": "     How do I check whether a file exists, without using the try statement?   In 2016, this is still arguably the easiest way to check if both a file exists and if it is a file:  import os os.path.isfile('./file.txt')    # Returns True if exists, else False   isfile is actually just a helper method that internally uses os.stat and stat.S_ISREG(mode) underneath. This os.stat is a lower-level method that will provide you with detailed information about files, directories, sockets, buffers, and more. More about os.stat here  Note: However, this approach will not lock the file in any way and therefore your code can become vulnerable to \"time of check to time of use\" (TOCTTOU) bugs.  So raising exceptions is considered to be an acceptable, and Pythonic, approach for flow control in your program. And one should consider handling missing files with IOErrors, rather than if statements (just an advice).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists", "Language": "Python", "Q_Title": "How do I check whether a file exists?", "Q_Votes": "4453", "Q_Content": "    How do I see if a file exists or not, without using the try statement?     ", "Tags": ["python", "file"], "A_Votes": "10", "A_Content": "  import os path = /path/to/dir  root,dirs,files = os.walk(path).next() if myfile in files:    print \"yes it exists\"   This is helpful when checking for several files. Or you want to do a set intersection/ subtraction with an existing list.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "20", "A_Content": "  Be pythonic. Use a comprehension:  z={i:d[i] for d in [x,y] for i in d}  >>> print z {'a': 1, 'c': 11, 'b': 10}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "19", "A_Content": "  In python3, the items method no longer returns a list, but rather a view, which acts like a set. In this case you'll need to take the set union since concatenating with + won't work:  dict(x.items() | y.items())   For python3-like behavior in version 2.7, the viewitems method should work in place of items:  dict(x.viewitems() | y.viewitems())   I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows).  Edit:  A couple more points for python 3. First, note that the dict(x, **y) trick won't work in python 3 unless the keys in y are strings.  Also, Raymond Hettinger's Chainmap answer is pretty elegant, since it can take an arbitrary number of dicts as arguments, but from the docs it looks like it sequentially looks through a list of all the dicts for each lookup:     Lookups search the underlying mappings successively until a key is found.   This can slow you down if you have a lot of lookups in your application:  In [1]: from collections import ChainMap In [2]: from string import ascii_uppercase as up, ascii_lowercase as lo; x = dict(zip(lo, up)); y = dict(zip(up, lo)) In [3]: chainmap_dict = ChainMap(y, x) In [4]: union_dict = dict(x.items() | y.items()) In [5]: timeit for k in union_dict: union_dict[k] 100000 loops, best of 3: 2.15 \u00b5s per loop In [6]: timeit for k in chainmap_dict: chainmap_dict[k] 10000 loops, best of 3: 27.1 \u00b5s per loop   So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "14", "A_Content": "  Abuse leading to a one-expression solution for Matthew's answer:  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = (lambda f=x.copy(): (f.update(y), f)[1])() >>> z {'a': 1, 'c': 11, 'b': 10}   You said you wanted one expression, so I abused lambda to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe.  You could also do this of course if you don't care about copying it:  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = (x.update(y), x)[1] >>> z {'a': 1, 'b': 10, 'c': 11}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "13", "A_Content": "  Simple solution using itertools that preserves order (latter dicts have precedence)  import itertools as it merge = lambda *args: dict(it.chain.from_iterable(it.imap(dict.iteritems, args)))   And it's usage:  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> merge(x, y) {'a': 1, 'b': 10, 'c': 11}  >>> z = {'c': 3, 'd': 4} >>> merge(x, y, z) {'a': 1, 'b': 10, 'c': 3, 'd': 4}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "11", "A_Content": "  Two dictionaries  def union2(dict1, dict2):     return dict(list(dict1.items()) + list(dict2.items()))   n dictionaries  def union(*dicts):     return dict(itertools.chain.from_iterable(dct.items() for dct in dicts))   sum has bad performance. See https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python/     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "11", "A_Content": "  In python 3:  import collections a = {1: 1, 2: 2} b = {2: 3, 3: 4} c = {3: 5}  r = dict(collections.ChainMap(a, b, c)) print(r)   Out:  {1: 1, 2: 2, 3: 4}   Docs: https://docs.python.org/3/library/collections.html#collections.ChainMap:     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "9", "A_Content": "  Even though the answers were good for this shallow dictionary, none of the methods defined here actually do a deep dictionary merge.  Examples follow:  a = { 'one': { 'depth_2': True }, 'two': True } b = { 'one': { 'extra': False } } print dict(a.items() + b.items())   One would expect a result of something like this:  { 'one': { 'extra': False', 'depth_2': True }, 'two': True }   Instead, we get this:  {'two': True, 'one': {'extra': False}}   The 'one' entry should have had 'depth_2' and 'extra' as items inside its dictionary if it truly was a merge.  Using chain also, does not work:  from itertools import chain print dict(chain(a.iteritems(), b.iteritems()))   Results in:  {'two': True, 'one': {'extra': False}}   The deep merge that rcwesick gave also creates the same result.  Yes, it will work to merge the sample dictionaries, but none of them are a generic mechanism to merge.  I'll update this later once I write a method that does a true merge.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "8", "A_Content": "  For Python 2 :  x = {'a':1, 'b': 2} y = {'b':10, 'c': 11} z = dict(x.items()+y.items()) print(z)   For Python 3:  x = {'a':1, 'b': 2} y = {'b':10, 'c': 11} z = dict(x.items()|y.items()) print(z)   It gives output:{'a': 1, 'c': 11, 'b': 10}     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "7", "A_Content": "  Drawing on ideas here and elsewhere I've comprehended a function:  def merge(*dicts, **kv):        return { k:v for d in list(dicts) + [kv] for k,v in d.items() }   Usage (tested in python 3):  assert (merge({1:11,'a':'aaa'},{1:99, 'b':'bbb'},foo='bar')==\\     {1: 99, 'foo': 'bar', 'b': 'bbb', 'a': 'aaa'})  assert (merge(foo='bar')=={'foo': 'bar'})  assert (merge({1:11},{1:99},foo='bar',baz='quux')==\\     {1: 99, 'foo': 'bar', 'baz':'quux'})  assert (merge({1:11},{1:99})=={1: 99})   You could use a lambda instead.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "5", "A_Content": "  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> x, z = dict(x), x.update(y) or x >>> x {'a': 1, 'b': 2} >>> y {'c': 11, 'b': 10} >>> z {'a': 1, 'c': 11, 'b': 10}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "5", "A_Content": "  The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12. In that light, I present the following:  import timeit  n=100000 su = \"\"\" x = {'a':1, 'b': 2} y = {'b':10, 'c': 11} \"\"\"  def timeMerge(f,su,niter):     print \"{:4f} sec for: {:30s}\".format(timeit.Timer(f,setup=su).timeit(n),f)  timeMerge(\"dict(x, **y)\",su,n) timeMerge(\"x.update(y)\",su,n) timeMerge(\"dict(x.items() + y.items())\",su,n) timeMerge(\"for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k] \",su,n)  #confirm for loop adds b entries together x = {'a':1, 'b': 2} y = {'b':10, 'c': 11} for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k] print \"confirm b elements are added:\",x   Results:  0.049465 sec for: dict(x, **y) 0.033729 sec for: x.update(y)                    0.150380 sec for: dict(x.items() + y.items())    0.083120 sec for: for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k]  confirm b elements are added: {'a': 1, 'c': 11, 'b': 12}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "5", "A_Content": "  This can be done with a single dict comprehension:  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> { key: y[key] if key in y else x[key]       for key in set(x) + set(y)     }   In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "5", "A_Content": "  from collections import Counter dict1 = {'a':1, 'b': 2} dict2 = {'b':10, 'c': 11} result = dict(Counter(dict1) + Counter(dict2))   This should solve your problem.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "5", "A_Content": "  (For Python2.7* only; there are simpler solutions for Python3*.)  If you're not averse to importing a standard library module, you can do  from functools import reduce  def merge_dicts(*dicts):     return reduce(lambda a, d: a.update(d) or a, dicts, {})   (The or a bit in the lambda is necessary because dict.update always returns None on success.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression", "Language": "Python", "Q_Title": "How to merge two dictionaries in a single expression?", "Q_Votes": "3307", "Q_Content": "    I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The update() method would be what I need, if it returned its result instead of modifying a dict in-place.  >>> x = {'a':1, 'b': 2} >>> y = {'b':10, 'c': 11} >>> z = x.update(y) >>> print(z) None >>> x {'a': 1, 'b': 10, 'c': 11}   How can I get that final merged dict in z, not x?  (To be extra-clear, the last-one-wins conflict-handling of dict.update() is what I'm looking for as well.)     ", "Tags": ["python", "dictionary", "merge"], "A_Votes": "5", "A_Content": "  In Python 3.5 you can use unpack ** in order to create new dictionary.  This method has no been showed in past answers. Also, it's better to use {} instead of dict(). Because {} is a python literal and dict() involves a function call.  dict1 = {'a':1} dict2 = {'b':2} new_dict = {**dict1, **dict2} >>>new_dict {'a':1, 'a':2}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "4546", "A_Content": "  When the Python interpreter reads a source file, it executes all of the code found in it.  Before executing the code, it will define a few special variables. For example, if the Python interpreter is running that module (the source file) as the main program, it sets the special __name__ variable to have a value \"__main__\".  If this file is being imported from another module, __name__ will be set to the module's name.  In the case of your script, let's assume that it's executing as the main function, e.g. you said something like  python threading_example.py   on the command line. After setting up the special variables, it will execute the import statement and load those modules. It will then evaluate the def block, creating a function object and creating a variable called myfunction that points to the function object. It will then read the if statement and see that __name__ does equal \"__main__\", so it will execute the block shown there.  One reason for doing this is that sometimes you write a module (a .py file) where it can be executed directly. Alternatively, it can also be imported and used in another module. By doing the main check, you can have that code only execute when you want to run the module as a program and not have it execute when someone just wants to import your module and call your functions themselves.  See this page for some extra details.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "1458", "A_Content": "  When your script is run by passing it as a command to the Python interpreter,  python myscript.py   all of the code that is at indentation level 0 gets executed.  Functions and classes that are defined are, well, defined, but none of their code gets run.  Unlike other languages, there's no main() function that gets run automatically - the main() function is implicitly all the code at the top level.  In this case, the top-level code is an if block.  __name__ is a built-in variable which evaluates to the name of the current module.  However, if a module is being run directly (as in myscript.py above), then __name__ instead is set to the string \"__main__\".  Thus, you can test whether your script is being run directly or being imported by something else by testing  if __name__ == \"__main__\":     ...   If your script is being imported into another module, its various function and class definitions will be imported and its top-level code will be executed, but the code in the then-body of the if clause above won't get run as the condition is not met. As a basic example, consider the following two scripts:  # file one.py def func():     print(\"func() in one.py\")  print(\"top-level in one.py\")  if __name__ == \"__main__\":     print(\"one.py is being run directly\") else:     print(\"one.py is being imported into another module\")     # file two.py import one  print(\"top-level in two.py\") one.func()  if __name__ == \"__main__\":     print(\"two.py is being run directly\") else:     print(\"two.py is being imported into another module\")   Now, if you invoke the interpreter as  python one.py   The output will be  top-level in one.py one.py is being run directly   If you run two.py instead:  python two.py   You get  top-level in one.py one.py is being imported into another module top-level in two.py func() in one.py two.py is being run directly   Thus, when module one gets loaded, its __name__ equals \"one\" instead of \"__main__\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "571", "A_Content": "  The simplest explanation for the __name__ variable (imho) is the following:  Create the following files.  # a.py import b   and  # b.py print \"Hello World from %s!\" % __name__  if __name__ == '__main__':     print \"Hello World again from %s!\" % __name__   Running them will get you this output:  $ python a.py Hello World from b!   As you can see, when a module is imported, Python sets globals()['__name__'] in this module to the module's name.  $ python b.py Hello World from __main__! Hello World again from __main__!   As you can see, when a file is executed, Python sets globals()['__name__'] in this file to \"__main__\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "418", "A_Content": "     What does the if __name__ == \"__main__\": do?   To outline the basics:   The global variable, __name__, in the module that is the entry point to your program, is '__main__'. Otherwise, it's the name you import the module by. So, code under the if block will only run if the module is the entry point to your program. It allows the code in the module to be importable by other modules, without executing the code block beneath on import.     Why do we need this?  Developing and Testing Your Code  Say you're writing a Python script designed to be used as a module:  def do_important():     \"\"\"This function does something very important\"\"\"   You could test the module by adding this call of the function to the bottom:  do_important()   and running it (on a command prompt) with something like:  ~$ python important.py   The Problem  However, if you want to import the module to another script:  import important   On import, the do_important function would be called, so you'd probably comment out your function call, do_important(), at the bottom.   # do_important() # I must remember to uncomment to execute this!   And then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome.  A Better Way  The __name__ variable points to the namespace wherever the Python interpreter happens to be at the moment.   Inside an imported module, it's the name of that module.   But inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its \"__main__\".  So if you check before executing:  if __name__ == \"__main__\":     do_important()   With the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script).   An Even Better Way  There's a Pythonic way to improve on this, though.   What if we want to run this business process from outside the module?  If we put the code we want to exercise as we develop and test in a function like this and then do our check for '__main__' immediately after:  def main():     \"\"\"business logic for when running this module as the primary one!\"\"\"     setup()     foo = do_important()     bar = do_even_more_important(foo)     for baz in bar:         do_super_important(baz)     teardown()  # Here's our payoff idiom! if __name__ == '__main__':     main()   We now have a final function for the end of our module that will run if we run the module as the primary module.   It will allow the module and its functions and classes to be imported into other scripts without running the main function, and will also allow the module (and its functions and classes) to be called when running from a different '__main__' module, i.e.  import important important.main()   This idiom can also be found in the Python documentation in an explanation of the __main__ module. That text states:     This module represents the (otherwise anonymous) scope in which the   interpreter\u2019s main program executes \u2014 commands read either from   standard input, from a script file, or from an interactive prompt. It   is this environment in which the idiomatic \u201cconditional script\u201d stanza   causes a script to run:  if __name__ == '__main__':     main()       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "94", "A_Content": "  if __name__ == \"__main__\" is the part that runs when the script is run from (say) the command line using a command like python myscript.py.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "59", "A_Content": "     What does if __name__ == \"__main__\": do?   __name__ is a global variable (in Python, global actually means on the module level) that exists in all namespaces. It is typically the module's name (as a str type).  As the only special case, however, in whatever Python process you run, as in mycode.py:  python mycode.py   the otherwise anonymous global namespace is assigned the value of '__main__' to its __name__.   Thus, including the final lines  if __name__ == '__main__':     main()    at the end of your mycode.py script, when it is the primary, entry-point module that is run by a Python process,    will cause your script's uniquely defined main function to run.   Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides:  import mycode # ... any amount of other code mycode.main()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "2142", "A_Content": "  A metaclass is the class of a class. Like a class defines how an instance of the class behaves, a metaclass defines how a class behaves. A class is an instance of a metaclass.    While in Python you can use arbitrary callables for metaclasses (like Jerub shows), the more useful approach is actually to make it an actual class itself. type is the usual metaclass in Python. In case you're wondering, yes, type is itself a class, and it is its own type. You won't be able to recreate something like type purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass type.  A metaclass is most commonly used as a class-factory. Like you create an instance of the class by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal __init__ and __new__ methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry, or even replace the class with something else entirely.  When the class statement is executed, Python first executes the body of the class statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the __metaclass__ attribute of the class-to-be (if any) or the __metaclass__ global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.  However, metaclasses actually define the type of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods, in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. type.__subclasses__() is an example of a method on the type metaclass. You can also define the normal 'magic' methods, like __add__, __iter__ and __getattr__, to implement or change how the class behaves.  Here's an aggregated example of the bits and pieces:  def make_hook(f):     \"\"\"Decorator to turn 'foo' method into '__foo__'\"\"\"     f.is_hook = 1     return f  class MyType(type):     def __new__(mcls, name, bases, attrs):          if name.startswith('None'):             return None          # Go over attributes and see if they should be renamed.         newattrs = {}         for attrname, attrvalue in attrs.iteritems():             if getattr(attrvalue, 'is_hook', 0):                 newattrs['__%s__' % attrname] = attrvalue             else:                 newattrs[attrname] = attrvalue          return super(MyType, mcls).__new__(mcls, name, bases, newattrs)      def __init__(self, name, bases, attrs):         super(MyType, self).__init__(name, bases, attrs)          # classregistry.register(self, self.interfaces)         print \"Would register class %s now.\" % self      def __add__(self, other):         class AutoClass(self, other):             pass         return AutoClass         # Alternatively, to autogenerate the classname as well as the class:         # return type(self.__name__ + other.__name__, (self, other), {})      def unregister(self):         # classregistry.unregister(self)         print \"Would unregister class %s now.\" % self  class MyObject:     __metaclass__ = MyType   class NoneSample(MyObject):     pass  # Will print \"NoneType None\" print type(NoneSample), repr(NoneSample)  class Example(MyObject):     def __init__(self, value):         self.value = value     @make_hook     def add(self, other):         return self.__class__(self.value + other.value)  # Will unregister the class Example.unregister()  inst = Example(10) # Will fail with an AttributeError #inst.unregister()  print inst + inst class Sibling(MyObject):     pass  ExampleSibling = Example + Sibling # ExampleSibling is now a subclass of both Example and Sibling (with no # content of its own) although it will believe it's called 'AutoClass' print ExampleSibling print ExampleSibling.__mro__      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "50", "A_Content": "  There are lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers.  Take file \"ab.py\":  def a():     print('A function in ab file'); a()   And a second file \"xy.py\":  import ab def main():     print('main function: this is where the action is') def x():     print ('peripheral task: might be useful in other projects') x() if __name__ == \"__main__\":     main()      What is this code actually doing?   When you execute xy.py, you import ab. The import statement runs the module immediately on import, so ab's operations get executed before the remainder of xy's. Once finished with ab, it continues with xy.  The interpreter keeps track of which scripts are running with __name__. When you run a script - no matter what you've named it - the interpreter calls it \"__main__\", making it the master or 'home' script that gets returned to after running an external script.  Any other script that's called from this \"__main__\" script is assigned its filename as its __name__ (e.g., __name__ == \"ab.py\"). Hence, the line if __name__ == \"__main__\": is the interpreter's test to determine if it's interpreting/parsing the 'home' script that was initially executed, or if it's temporarily peeking into another (external) script. This gives the programmer flexibility to have the script behave differently if it's executed directly vs. called externally.  Let's step through the above code to understand what's happening, focusing first on the unindented lines and the order they appear in the scripts. Remember that function - or def - blocks don't do anything by themselves until they're called. What the interpreter might say if mumbled to itself:   Open xy.py as the 'home' file; call it \"__main__\" in the __name__ variable. Import and open file with the __name__ == \"ab.py\". Oh, a function. I'll remember that. Ok, function a(); I just learned that. Printing 'A function in ab file'. End of file; back to \"__main__\"! Oh, a function. I'll remember that. Another one. Function x(); ok, printing 'peripheral task: might be useful in other projects'. What's this? An if statement. Well, the condition has been met (the variable __name__ has been set to \"__main__\"), so I'll enter the main() function and print 'main function: this is where the action is'.   The bottom two lines mean: \"If this is the \"__main__\" or 'home' script, execute the function called main()\". That's why you'll see a def main(): block up top, which contains the main flow of the script's functionality.     Why implement this?   Remember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the main() function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script.  Again, there will be exceptions, but common practice is that main() doesn't usually get called externally. So you may be wondering one more thing: if we're not calling main(), why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run independent of the rest of the code in the file. They're then later called somewhere else in the body of the script. Which brings me to this:     But the code works without it   Yes, that's right. These separate functions can be called from an in-line script that's not contained inside a main() function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read.  But that's a script that probably can't have its functions called externally, because if it did it would immediately start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there will be conflicting variables.  In splitting out independent functions, you gain the ability to re-use your previous work by calling them into another script. For example, \"example.py\" might import \"xy.py\" and call x(), making use of the 'x' function from \"xy.py\". (Maybe it's capitalizing the third word of a given text string; creating a NumPy array from a list of numbers and squaring them; or detrending a 3D surface. The possibilities are limitless.)  (As an aside, this question contains an answer by @kindall that finally helped me to understand - the why, not the how. Unfortunately it's been marked as a duplicate of this one, which I think is a mistake.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "40", "A_Content": "  When there are certain statements in our module (M.py) we want to be executed when it'll be running as main (not imported), we can place those statements (test-cases, print statements) under this if block.  As by default (when module running as main, not imported) the __name__ variable is set to \"__main__\", and when it'll be imported the __name__ variable will get a different value, most probably the name of the module ('M'). This is helpful in running different variants of a modules together, and separating their specific input & output statements and also if there are any test-cases.  In short, use this 'if __name__ == \"main\" ' block to prevent (certain) code from being run when the module is imported.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "33", "A_Content": "  Let's look at the answer in a more abstract way:  Suppose we have this code in x.py:  ... <Block A> if __name__ == '__main__':     <Block B> ...   Blocks A and B are run when we are running \"x.py\".  But just block A (and not B) is run when we are running another module, \"y.py\" for example, in which x.y is imported and the code is run from there (like when a function in \"x.py\" is called from y.py).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "31", "A_Content": "  When you run Python interactively the local __name__ variable is assigned a value of __main__. Likewise, when you execute a Python module from the command line, rather than importing it into another module, its __name__ attribute is assigned a value of __main__, rather than the actual name of the module. In this way, modules can look at their own __name__ value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules:  if __name__ == '__main__':     # Do something appropriate here, like calling a     # main() function defined elsewhere in this module.     main() else:     # Do nothing. This module has been imported by another     # module that wants to make use of the functions,     # classes and other useful bits it has defined.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "30", "A_Content": "  Put simply, __name__ is a variable defined for each script that defines whether the script is being run as the main module or it is being run as an imported module.  So if we have two scripts;  #script1.py print \"Script 1's name: {}\".format(__name__)   and  #script2.py import script1 print \"Script 2's name: {}\".format(__name__)   The output from executing script1 is  Script 1's name: __main__   And the output from executing script2 is:  Script1's name is script1 Script 2's name: __main__   As you can see, __name__ tells us which code is the 'main' module. This is great, because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library.  Say you write a Python script that does something great and you implement a boatload of functions that are useful for other purposes. If I want to use them I can just import your script and use them without executing your program (given that your code only executes within the  if __name__ == \"__main__\": context). Whereas in C/C++ you would have to portion out those pieces into a separate module that then includes the file. Picture the situation below;    The arrows are import links. For three modules each trying to include the previous modules code there are six files (nine, counting the implementation files) and five links. This makes it difficult to include other code into a C project unless it is compiled specifically as a library. Now picture it for Python:    You write a module, and if someone wants to use your code they just import it and the __name__ variable can help to separate the executable portion of the program from the library part.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "25", "A_Content": "  Consider:  if __name__ == \"__main__\":     main()   It checks if the __name__ attribute of the Python script is \"__main__\". In other words, if the program itself is executed, the attribute will be __main__, so the program will be executed (in this case the main() function).  However, if your Python script is used by a module, any code outside of the if statement will be executed, so if \\__name__ == \"\\__main__\" is used just to check if the program is used as a module or not, and therefore decides whether to run the code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "18", "A_Content": "  There are a number of variables that the system (Python interpreter) provides for source files (modules).  You can get their values anytime you want, so, let us focus on the __name__ variable/attribute:  When Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.)  Before the interpreter executes the source code file though, it defines a few special variables for that file; __name__ is one of those special variables that Python automatically defines for each source code file.  If Python is loading this source code file as the main program (i.e. the file you run), then it sets the special __name__ variable for this file to have a value \"__main__\".  If this is being imported from another module, __name__ will be set to that module's name.  So, in your example in part:  if __name__ == \"__main__\":    lock = thread.allocate_lock()    thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))    thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))   means that the code block:  lock = thread.allocate_lock() thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock)) thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))   will be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of __name__ will not equal to \"main\" in that particular instance.  Hope this helps out.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "17", "A_Content": "  I think it's best to break the answer in depth and in simple words:  __name__: Every module in Python has a special attribute called __name__. It is a built-in variable that returns the name of the module.  __main__: Like other programming languages, Python too has an execution entry point, i.e., main. '__main__' is the name of the scope in which top-level code executes. Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its __name__ is set to __main__.  Thus, the value of the __name__ attribute is set to __main__ when the module is run as the main program. Otherwise the value of __name__  is set to contain the name of the module.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "17", "A_Content": "  Before explaining anything about if __name__ == '__main__' it is important to understand what __name__ is and what it does.     What is __name__?   __name__ is a DunderAlias - can be thought of as a global variable (accessible from modules) and works in a similar way to global.  It is a string (global as mentioned above) as indicated by type(__name__) (yielding <class 'str'>), and is an inbuilt standard for both Python 3 and Python 2 versions.     Where:   It can not only be used in scripts but can also be found in both the interpreter and modules/packages.    Interpreter:  >>> print(__name__) __main__ >>>   Script:  test_file.py:  print(__name__)   Resulting in __main__  Module or package:  somefile.py:  def somefunction():     print(__name__)   test_file.py:  import somefile somefile.somefunction()   Resulting in somefile  Notice that when used in a package or module, __name__ takes the name of the file.  The path of the actual module or package path is not given, but has its own DunderAlias __file__, that allows for this.  You should see that, where __name__, where it is the main file (or program) will always return __main__, and if it is a module/package, or anything that is running off some other Python script, will return the name of the file where it has originated from.     Practice:   Being a variable means that it's value can be overwritten (\"can\" does not mean \"should\"), overwriting the value of __name__ will result in a lack of readability.  So do not do it, for any reason.  If you need a variable define a new variable.  It is always assumed that the value of __name__ to be __main__ or the name of the file.  Once again changing this default value will cause more confusion that it will do good, causing problems further down the line.  example:  >>> __name__ = 'Horrify' # Change default from __main__ >>> if __name__ == 'Horrify': print(__name__) ... >>> else: print('Not Horrify') ... Horrify >>>   It is considered good practice in general to include the if __name__ == '__main__' in scripts.     Now to answer if __name__ == '__main__':   Now we know the behaviour of __name__ things become clearer:  An if is a flow control statement that contains the block of code will execute if the value given is true. We have seen that __name__ can take either  __main__ or the file name it has been imported from.    This means that if __name__ is equal to __main__ then the file must be the main file and must actually be running (or it is the interpreter), not a module or package imported into the script.  If indeed __name__ does take the value of __main__ then whatever is in that block of code will execute.  This tells us that if the file running is the main file (or you are running from the interpreter directly) then that condition must execute.  If it is a package then it should not, and the value will not be __main__.     Modules:   __name__ can also be used in modules to define the name of a module     Variants:     It is also possible to do other, less common but useful things with __name__, some I will show here:  Executing only if the file is a module or package:  if __name__ != '__main__':     # Do some useful things    Running one condition if the file is the main one and another if it is not:  if __name__ == '__main__':     # Execute something else:     # Do some useful things   You can also use it to provide runnable help functions/utilities on packages and modules without the elaborate use of libraries.  It also allows modules to be run from the command line as main scripts, which can be also very useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "17", "A_Content": "  It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance.  It could be written in several ways. Another is:  def some_function_for_instance_main():     dosomething()   __name__ == '__main__' and some_function_for_instance_main()   I am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about if __name__ == '__main__'. It is a good convention for invoking a main function in Python files.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "16", "A_Content": "  if __name__ == \"__main__\": is basically the top-level script environment, and it specifies the interpreter that ('I have the highest priority to be executed first').  '__main__' is the name of the scope in which top-level code executes. A module\u2019s __name__ is set equal to '__main__' when read from standard input, a script, or from an interactive prompt.  if __name__ == \"__main__\":     # Execute only if run as a script     main()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "12", "A_Content": "  The reason for  if __name__ == \"__main__\":     main()   is primarily to avoid the import lock problems that would arise from having code directly imported. You want main() to run if your file was directly invoked (that's the __name__ == \"__main__\" case), but if your code was imported then the importer has to enter your code from the true main module to avoid import lock problems.  A side-effect is that you automatically sign on to a methodology that supports multiple entry points. You can run your program using main() as the entry point, but you don't have to. While setup.py expects main(), other tools use alternate entry points. For example, to run your file as a gunicorn process, you define an app() function instead of a main(). Just as with setup.py, gunicorn imports your code so you don't want it do do anything while it's being imported (because of the import lock issue).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "5826", "A_Content": "  Classes as objects  Before understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.  In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:  >>> class ObjectCreator(object): ...       pass ...  >>> my_object = ObjectCreator() >>> print(my_object) <__main__.ObjectCreator object at 0x8974f2c>   But classes are more than that in Python. Classes are objects too.  Yes, objects.  As soon as you use the keyword class, Python executes it and creates an OBJECT. The instruction  >>> class ObjectCreator(object): ...       pass ...   creates in memory an object with the name \"ObjectCreator\".  This object (the class) is itself capable of creating objects (the instances), and this is why it's a class.  But still, it's an object, and therefore:   you can assign it to a variable you can copy it you can add attributes to it you can pass it as a function parameter   e.g.:  >>> print(ObjectCreator) # you can print a class because it's an object <class '__main__.ObjectCreator'> >>> def echo(o): ...       print(o) ... >>> echo(ObjectCreator) # you can pass a class as a parameter <class '__main__.ObjectCreator'> >>> print(hasattr(ObjectCreator, 'new_attribute')) False >>> ObjectCreator.new_attribute = 'foo' # you can add attributes to a class >>> print(hasattr(ObjectCreator, 'new_attribute')) True >>> print(ObjectCreator.new_attribute) foo >>> ObjectCreatorMirror = ObjectCreator # you can assign a class to a variable >>> print(ObjectCreatorMirror.new_attribute) foo >>> print(ObjectCreatorMirror()) <__main__.ObjectCreator object at 0x8997b4c>   Creating classes dynamically  Since classes are objects, you can create them on the fly, like any object.  First, you can create a class in a function using class:  >>> def choose_class(name): ...     if name == 'foo': ...         class Foo(object): ...             pass ...         return Foo # return the class, not an instance ...     else: ...         class Bar(object): ...             pass ...         return Bar ... >>> MyClass = choose_class('foo') >>> print(MyClass) # the function returns a class, not an instance <class '__main__.Foo'> >>> print(MyClass()) # you can create an object from this class <__main__.Foo object at 0x89c6d4c>   But it's not so dynamic, since you still have to write the whole class yourself.  Since classes are objects, they must be generated by something.  When you use the class keyword, Python creates this object automatically. But as with most things in Python, it gives you a way to do it manually.  Remember the function type? The good old function that lets you know what type an object is:  >>> print(type(1)) <type 'int'> >>> print(type(\"1\")) <type 'str'> >>> print(type(ObjectCreator)) <type 'type'> >>> print(type(ObjectCreator())) <class '__main__.ObjectCreator'>   Well, type has a completely different ability, it can also create classes on the fly. type can take the description of a class as parameters, and return a class.  (I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backwards compatibility in Python)  type works this way:  type(name of the class,      tuple of the parent class (for inheritance, can be empty),      dictionary containing attributes names and values)   e.g.:  >>> class MyShinyClass(object): ...       pass   can be created manually this way:  >>> MyShinyClass = type('MyShinyClass', (), {}) # returns a class object >>> print(MyShinyClass) <class '__main__.MyShinyClass'> >>> print(MyShinyClass()) # create an instance with the class <__main__.MyShinyClass object at 0x8997cec>   You'll notice that we use \"MyShinyClass\" as the name of the class and as the variable to hold the class reference. They can be different, but there is no reason to complicate things.  type accepts a dictionary to define the attributes of the class. So:  >>> class Foo(object): ...       bar = True   Can be translated to:  >>> Foo = type('Foo', (), {'bar':True})   And used as a normal class:  >>> print(Foo) <class '__main__.Foo'> >>> print(Foo.bar) True >>> f = Foo() >>> print(f) <__main__.Foo object at 0x8a9b84c> >>> print(f.bar) True   And of course, you can inherit from it, so:  >>>   class FooChild(Foo): ...         pass   would be:  >>> FooChild = type('FooChild', (Foo,), {}) >>> print(FooChild) <class '__main__.FooChild'> >>> print(FooChild.bar) # bar is inherited from Foo True   Eventually you'll want to add methods to your class. Just define a function with the proper signature and assign it as an attribute.  >>> def echo_bar(self): ...       print(self.bar) ... >>> FooChild = type('FooChild', (Foo,), {'echo_bar': echo_bar}) >>> hasattr(Foo, 'echo_bar') False >>> hasattr(FooChild, 'echo_bar') True >>> my_foo = FooChild() >>> my_foo.echo_bar() True   And you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.  >>> def echo_bar_more(self): ...       print('yet another method') ... >>> FooChild.echo_bar_more = echo_bar_more >>> hasattr(FooChild, 'echo_bar_more') True   You see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.  This is what Python does when you use the keyword class, and it does so by using a metaclass.  What are metaclasses (finally)  Metaclasses are the 'stuff' that creates classes.  You define classes in order to create objects, right?  But we learned that Python classes are objects.  Well, metaclasses are what create these objects. They are the classes' classes, you can picture them this way:  MyClass = MetaClass() my_object = MyClass()   You've seen that type lets you do something like this:  MyClass = type('MyClass', (), {})   It's because the function type is in fact a metaclass. type is the metaclass Python uses to create all classes behind the scenes.  Now you wonder why the heck is it written in lowercase, and not Type?  Well, I guess it's a matter of consistency with str, the class that creates strings objects, and int the class that creates integer objects. type is just the class that creates class objects.  You see that by checking the __class__ attribute.  Everything, and I mean everything, is an object in Python. That includes ints, strings, functions and classes. All of them are objects. And all of them have been created from a class:  >>> age = 35 >>> age.__class__ <type 'int'> >>> name = 'bob' >>> name.__class__ <type 'str'> >>> def foo(): pass >>> foo.__class__ <type 'function'> >>> class Bar(object): pass >>> b = Bar() >>> b.__class__ <class '__main__.Bar'>   Now, what is the __class__ of any __class__ ?  >>> age.__class__.__class__ <type 'type'> >>> name.__class__.__class__ <type 'type'> >>> foo.__class__.__class__ <type 'type'> >>> b.__class__.__class__ <type 'type'>   So, a metaclass is just the stuff that creates class objects.  You can call it a 'class factory' if you wish.  type is the built-in metaclass Python uses, but of course, you can create your own metaclass.  The __metaclass__ attribute  In Python 2, you can add a __metaclass__ attribute when you write a class (see next section for the Python 3 syntax):  class Foo(object):     __metaclass__ = something...     [...]   If you do so, Python will use the metaclass to create the class Foo.  Careful, it's tricky.  You write class Foo(object) first, but the class object Foo is not created in memory yet.  Python will look for __metaclass__ in the class definition. If it finds it, it will use it to create the object class Foo. If it doesn't, it will use type to create the class.  Read that several times.  When you do:  class Foo(Bar):     pass   Python does the following:  Is there a __metaclass__ attribute in Foo?  If yes, create in memory a class object (I said a class object, stay with me here), with the name Foo by using what is in __metaclass__.  If Python can't find __metaclass__, it will look for a __metaclass__ at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes).  Then if it can't find any __metaclass__ at all, it will use the Bar's (the first parent) own metaclass (which might be the default type) to create the class object.  Be careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.  Now the big question is, what can you put in __metaclass__ ?  The answer is: something that can create a class.  And what can create a class? type, or anything that subclasses or uses it.  Metaclasses in Python 3  The syntax to set the metaclass has been changed in Python 3:  class Foo(object, metaclass=something):     [...]   i.e. the __metaclass__ attribute is no longer used, in favor of a keyword argument in the list of base classes.  The behaviour of metaclasses however stays largely the same.  Custom metaclasses  The main purpose of a metaclass is to change the class automatically, when it's created.  You usually do this for APIs, where you want to create classes matching the current context.  Imagine a stupid example, where you decide that all classes in your module should have their attributes written in uppercase. There are several ways to do this, but one way is to set __metaclass__ at the module level.  This way, all classes of this module will be created using this metaclass, and we just have to tell the metaclass to turn all attributes to uppercase.  Luckily, __metaclass__ can actually be any callable, it doesn't need to be a formal class (I know, something with 'class' in its name doesn't need to be a class, go figure... but it's helpful).  So we will start with a simple example, by using a function.  # the metaclass will automatically get passed the same argument # that you usually pass to `type` def upper_attr(future_class_name, future_class_parents, future_class_attr):     \"\"\"       Return a class object, with the list of its attribute turned       into uppercase.     \"\"\"      # pick up any attribute that doesn't start with '__' and uppercase it     uppercase_attr = {}     for name, val in future_class_attr.items():         if not name.startswith('__'):             uppercase_attr[name.upper()] = val         else:             uppercase_attr[name] = val      # let `type` do the class creation     return type(future_class_name, future_class_parents, uppercase_attr)  __metaclass__ = upper_attr # this will affect all classes in the module  class Foo(): # global __metaclass__ won't work with \"object\" though     # but we can define __metaclass__ here instead to affect only this class     # and this will work with \"object\" children     bar = 'bip'  print(hasattr(Foo, 'bar')) # Out: False print(hasattr(Foo, 'BAR')) # Out: True  f = Foo() print(f.BAR) # Out: 'bip'   Now, let's do exactly the same, but using a real class for a metaclass:  # remember that `type` is actually a class like `str` and `int` # so you can inherit from it class UpperAttrMetaclass(type):     # __new__ is the method called before __init__     # it's the method that creates the object and returns it     # while __init__ just initializes the object passed as parameter     # you rarely use __new__, except when you want to control how the object     # is created.     # here the created object is the class, and we want to customize it     # so we override __new__     # you can do some stuff in __init__ too if you wish     # some advanced use involves overriding __call__ as well, but we won't     # see this     def __new__(upperattr_metaclass, future_class_name,                 future_class_parents, future_class_attr):          uppercase_attr = {}         for name, val in future_class_attr.items():             if not name.startswith('__'):                 uppercase_attr[name.upper()] = val             else:                 uppercase_attr[name] = val          return type(future_class_name, future_class_parents, uppercase_attr)   But this is not really OOP. We call type directly and we don't override or call the parent __new__. Let's do it:  class UpperAttrMetaclass(type):      def __new__(upperattr_metaclass, future_class_name,                 future_class_parents, future_class_attr):          uppercase_attr = {}         for name, val in future_class_attr.items():             if not name.startswith('__'):                 uppercase_attr[name.upper()] = val             else:                 uppercase_attr[name] = val          # reuse the type.__new__ method         # this is basic OOP, nothing magic in there         return type.__new__(upperattr_metaclass, future_class_name,                             future_class_parents, uppercase_attr)   You may have noticed the extra argument upperattr_metaclass. There is nothing special about it: __new__ always receives the class it's defined in, as first parameter. Just like you have self for ordinary methods which receive the instance as first parameter, or the defining class for class methods.  Of course, the names I used here are long for the sake of clarity, but like for self, all the arguments have conventional names. So a real production metaclass would look like this:  class UpperAttrMetaclass(type):      def __new__(cls, clsname, bases, dct):          uppercase_attr = {}         for name, val in dct.items():             if not name.startswith('__'):                 uppercase_attr[name.upper()] = val             else:                 uppercase_attr[name] = val          return type.__new__(cls, clsname, bases, uppercase_attr)   We can make it even cleaner by using super, which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):  class UpperAttrMetaclass(type):      def __new__(cls, clsname, bases, dct):          uppercase_attr = {}         for name, val in dct.items():             if not name.startswith('__'):                 uppercase_attr[name.upper()] = val             else:                 uppercase_attr[name] = val          return super(UpperAttrMetaclass, cls).__new__(cls, clsname, bases, uppercase_attr)   That's it. There is really nothing more about metaclasses.  The reason behind the complexity of the code using metaclasses is not because of metaclasses, it's because you usually use metaclasses to do twisted stuff relying on introspection, manipulating inheritance, vars such as __dict__, etc.  Indeed, metaclasses are especially useful to do black magic, and therefore complicated stuff. But by themselves, they are simple:   intercept a class creation modify the class return the modified class   Why would you use metaclasses classes instead of functions?  Since __metaclass__ can accept any callable, why would you use a class since it's obviously more complicated?  There are several reasons to do so:   The intention is clear. When you read UpperAttrMetaclass(type), you know what's going to follow You can use OOP. Metaclass can inherit from metaclass, override parent methods. Metaclasses can even use metaclasses. Subclasses of a class will be instances of its metaclass if you specified a metaclass-class, but not with a metaclass-function. You can structure your code better. You never use metaclasses for something as trivial as the above example. It's usually for something complicated. Having the ability to make several methods and group them in one class is very useful to make the code easier to read. You can hook on __new__, __init__ and __call__. Which will allow you to do different stuff. Even if usually you can do it all in __new__, some people are just more comfortable using __init__. These are called metaclasses, damn it! It must mean something!   Why would you use metaclasses?  Now the big question. Why would you use some obscure error prone feature?  Well, usually you don't:     Metaclasses are deeper magic that   99% of users should never worry about.   If you wonder whether you need them,   you don't (the people who actually   need them know with certainty that   they need them, and don't need an   explanation about why).   Python Guru Tim Peters  The main use case for a metaclass is creating an API. A typical example of this is the Django ORM.  It allows you to define something like this:  class Person(models.Model):     name = models.CharField(max_length=30)     age = models.IntegerField()   But if you do this:  guy = Person(name='bob', age='35') print(guy.age)   It won't return an IntegerField object. It will return an int, and can even take it directly from the database.  This is possible because models.Model defines __metaclass__ and it uses some magic that will turn the Person you just defined with simple statements into a complex hook to a database field.  Django makes something complex look simple by exposing a simple API and using metaclasses, recreating code from this API to do the real job behind the scenes.  The last word  First, you know that classes are objects that can create instances.  Well in fact, classes are themselves instances. Of metaclasses.  >>> class Foo(object): pass >>> id(Foo) 142630324   Everything is an object in Python, and they are all either instances of classes or instances of metaclasses.  Except for type.  type is actually its own metaclass. This is not something you could reproduce in pure Python, and is done by cheating a little bit at the implementation level.  Secondly, metaclasses are complicated. You may not want to use them for very simple class alterations. You can change classes by using two different techniques:   monkey patching class decorators   99% of the time you need class alteration, you are better off using these.  But 98% of the time, you don't need class alteration at all.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "317", "A_Content": "  Note, this answer is for Python 2.x as it was written in 2008, metaclasses are slightly different in 3.x, see the comments.  Metaclasses are the secret sauce that make 'class' work. The default metaclass for a new style object is called 'type'.  class type(object)   |  type(object) -> the object's type   |  type(name, bases, dict) -> a new type   Metaclasses take 3 args. 'name', 'bases' and 'dict'  Here is where the secret starts. Look for where name, bases and the dict come from in this example class definition.  class ThisIsTheName(Bases, Are, Here):     All_the_code_here     def doesIs(create, a):         dict   Lets define a metaclass that will demonstrate how 'class:' calls it.  def test_metaclass(name, bases, dict):     print 'The Class Name is', name     print 'The Class Bases are', bases     print 'The dict has', len(dict), 'elems, the keys are', dict.keys()      return \"yellow\"  class TestName(object, None, int, 1):     __metaclass__ = test_metaclass     foo = 1     def baz(self, arr):         pass  print 'TestName = ', repr(TestName)  # output =>  The Class Name is TestName The Class Bases are (<type 'object'>, None, <type 'int'>, 1) The dict has 4 elems, the keys are ['baz', '__module__', 'foo', '__metaclass__'] TestName =  'yellow'   And now, an example that actually means something, this will automatically make the variables in the list \"attributes\" set on the class, and set to None.  def init_attributes(name, bases, dict):     if 'attributes' in dict:         for attr in dict['attributes']:             dict[attr] = None      return type(name, bases, dict)  class Initialised(object):     __metaclass__ = init_attributes     attributes = ['foo', 'bar', 'baz']  print 'foo =>', Initialised.foo # output=> foo => None   Note that the magic behaviour that 'Initalised' gains by having the metaclass init_attributes is not passed onto a subclass of Initalised.  Here is an even more concrete example, showing how you can subclass 'type' to make a metaclass that performs an action when the class is created. This is quite tricky:  class MetaSingleton(type):     instance = None     def __call__(cls, *args, **kw):         if cls.instance is None:             cls.instance = super(MetaSingleton, cls).__call__(*args, **kw)         return cls.instance   class Foo(object):      __metaclass__ = MetaSingleton   a = Foo()  b = Foo()  assert a is b      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "128", "A_Content": "  One use for metaclasses is adding new properties and methods to an instance automatically.  For example, if you look at Django models, their definition looks a bit confusing. It looks as if you are only defining class properties:  class Person(models.Model):     first_name = models.CharField(max_length=30)     last_name = models.CharField(max_length=30)   However, at runtime the Person objects are filled with all sorts of useful methods. See the source for some amazing metaclassery.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "120", "A_Content": "  Others have explained how metaclasses work and how they fit into the Python type system. Here's an example of what they can be used for. In a testing framework I wrote, I wanted to keep track of the order in which classes were defined, so that I could later instantiate them in this order. I found it easiest to do this using a metaclass.  class MyMeta(type):      counter = 0      def __init__(cls, name, bases, dic):         type.__init__(cls, name, bases, dic)         cls._order = MyMeta.counter         MyMeta.counter += 1  class MyType(object):              # Python 2     __metaclass__ = MyMeta  class MyType(metaclass=MyMeta):    # Python 3     pass   Anything that's a subclass of MyType then gets a class attribute _order that records the order in which the classes were defined.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "89", "A_Content": "  I think the ONLamp introduction to metaclass programming is well written and gives a really good introduction to the topic despite being several years old already.  http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html (archived at https://web.archive.org/web/20080206005253/http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html)  In short: A class is a blueprint for the creation of an instance, a metaclass is a blueprint for the creation of a class. It can be easily seen that in Python classes need to be first-class objects too to enable this behavior.  I've never written one myself, but I think one of the nicest uses of metaclasses can be seen in the Django framework. The model classes use a metaclass approach to enable a declarative style of writing new models or form classes. While the metaclass is creating the class, all members get the possibility to customize the class itself.   Creating a new model The metaclass enabling this   The thing that's left to say is: If you don't know what metaclasses are, the probability that you will not need them is 99%.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "76", "A_Content": "     What are metaclasses? What do you use them for?   TLDR: A metaclass instantiates and defines behavior for a class just like a class instantiates and defines behavior for an instance.   Pseudocode:  >>> Class(...) instance   The above should look familiar. Well, where does Class come from? It's an instance of a metaclass (also pseudocode):  >>> Metaclass(...) Class   In real code, we can pass the default metaclass, type, everything we need to instantiate a class and we get a class:  >>> type('Foo', (object,), {}) # requires a name, bases, and a namespace <class '__main__.Foo'>   Putting it differently   A class is to an instance as a metaclass is to a class.   When we instantiate an object, we get an instance:  >>> object()                          # instantiation of class <object object at 0x7f9069b4e0b0>     # instance   Likewise, when we define a class explicitly with the default metaclass, type, we instantiate it:  >>> type('Object', (object,), {})     # instantiation of metaclass <class '__main__.Object'>             # instance  Put another way, a class is an instance of a metaclass:  >>> isinstance(object, type) True  Put a third way, a metaclass is a class's class.  >>> type(object) == type True >>> object.__class__ <class 'type'>    When you write a class definition and Python executes it, it uses a metaclass to instantiate the class object (which will, in turn, be used to instantiate instances of that class).  Just as we can use class definitions to change how custom object instances behave, we can use a metaclass class definition to change the way a class object behaves.  What can they be used for? From the docs:     The potential uses for metaclasses are boundless. Some ideas that have been explored include logging, interface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource locking/synchronization.   Nevertheless, it is usually encouraged for users to avoid using metaclasses unless absolutely necessary.  You use a metaclass every time you create a class:  When you write a class definition, for example, like this,  class Foo(object):      'demo'   You instantiate a class object.  >>> Foo <class '__main__.Foo'> >>> isinstance(Foo, type), isinstance(Foo, object) (True, True)   It is the same as functionally calling type with the appropriate arguments and assigning the result to a variable of that name:  name = 'Foo' bases = (object,) namespace = {'__doc__': 'demo'} Foo = type(name, bases, namespace)   Note, some things automatically get added to the __dict__, i.e., the namespace:  >>> Foo.__dict__ dict_proxy({'__dict__': <attribute '__dict__' of 'Foo' objects>,  '__module__': '__main__', '__weakref__': <attribute '__weakref__'  of 'Foo' objects>, '__doc__': 'demo'})   The metaclass of the object we created, in both cases, is type.   (A side-note on the contents of the class __dict__: __module__ is there because classes must know where they are defined, and  __dict__ and __weakref__ are there because we don't define __slots__ - if we define __slots__ we'll save a bit of space in the instances, as we can disallow __dict__ and __weakref__ by excluding them. For example:  >>> Baz = type('Bar', (object,), {'__doc__': 'demo', '__slots__': ()}) >>> Baz.__dict__ mappingproxy({'__doc__': 'demo', '__slots__': (), '__module__': '__main__'})   ... but I digress.)  We can extend type just like any other class definition:  Here's the default __repr__ of classes:  >>> Foo <class '__main__.Foo'>   One of the most valuable things we can do by default in writing a Python object is to provide it with a good __repr__. When we call help(repr) we learn that there's a good test for a __repr__ that also requires a test for equality - obj == eval(repr(obj)). The following simple implementation of __repr__ and __eq__ for class instances of our type class provides us with a demonstration that may improve on the default __repr__ of classes:  class Type(type):     def __repr__(cls):         \"\"\"         >>> Baz         Type('Baz', (Foo, Bar,), {'__module__': '__main__', '__doc__': None})         >>> eval(repr(Baz))         Type('Baz', (Foo, Bar,), {'__module__': '__main__', '__doc__': None})         \"\"\"         metaname = type(cls).__name__         name = cls.__name__         parents = ', '.join(b.__name__ for b in cls.__bases__)         if parents:             parents += ','         namespace = ', '.join(': '.join(           (repr(k), repr(v) if not isinstance(v, type) else v.__name__))                for k, v in cls.__dict__.items())         return '{0}(\\'{1}\\', ({2}), {{{3}}})'.format(metaname, name, parents, namespace)     def __eq__(cls, other):         \"\"\"         >>> Baz == eval(repr(Baz))         True                     \"\"\"         return (cls.__name__, cls.__bases__, cls.__dict__) == (                 other.__name__, other.__bases__, other.__dict__)   So now when we create an object with this metaclass, the __repr__ echoed on the command line provides a much less ugly sight than the default:  >>> class Bar(object): pass >>> Baz = Type('Baz', (Foo, Bar,), {'__module__': '__main__', '__doc__': None}) >>> Baz Type('Baz', (Foo, Bar,), {'__module__': '__main__', '__doc__': None})   With a nice __repr__ defined for the class instance, we have a stronger ability to debug our code. However, much further checking with eval(repr(Class)) is unlikely (as functions would be rather impossible to eval from their default __repr__'s).  An expected usage: __prepare__ a namespace  If, for example, we want to know in what order a class's methods are created in, we could provide an ordered dict as the namespace of the class. We would do this with __prepare__ which returns the namespace dict for the class if it is implemented in Python 3:   from collections import OrderedDict  class OrderedType(Type):     @classmethod     def __prepare__(metacls, name, bases, **kwargs):         return OrderedDict()     def __new__(cls, name, bases, namespace, **kwargs):         result = Type.__new__(cls, name, bases, dict(namespace))         result.members = tuple(namespace)         return result   And usage:  class OrderedMethodsObject(object, metaclass=OrderedType):     def method1(self): pass     def method2(self): pass     def method3(self): pass     def method4(self): pass   And now we have a record of the order in which these methods (and other class attributes) were created:  >>> OrderedMethodsObject.members ('__module__', '__qualname__', 'method1', 'method2', 'method3', 'method4')   Note, this example was adapted from the documentation - the new enum in the standard library does this.  So what we did was instantiate a metaclass by creating a class. We can also treat the metaclass as we would any other class. It has a method resolution order:  >>> inspect.getmro(OrderedType) (<class '__main__.OrderedType'>, <class '__main__.Type'>, <class 'type'>, <class 'object'>)   And it has approximately the correct repr (which we can no longer eval unless we can find a way to represent our functions.):  >>> OrderedMethodsObject OrderedType('OrderedMethodsObject', (object,), {'method1': <function OrderedMethodsObject.method1 at 0x0000000002DB01E0>, 'members': ('__module__', '__qualname__', 'method1', 'method2', 'method3', 'method4'), 'method3': <function OrderedMet hodsObject.method3 at 0x0000000002DB02F0>, 'method2': <function OrderedMethodsObject.method2 at 0x0000000002DB0268>, '__module__': '__main__', '__weakref__': <attribute '__weakref__' of 'OrderedMethodsObject' objects>, '__doc__': None, '__d ict__': <attribute '__dict__' of 'OrderedMethodsObject' objects>, 'method4': <function OrderedMethodsObject.method4 at 0x0000000002DB0378>})      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "57", "A_Content": "  Python 3 update  There are (at this point) two key methods in a metaclass:   __prepare__, and __new__   __prepare__ lets you supply a custom mapping (such as an OrderedDict) to be used as the namespace while the class is being created.  You must return an instance of whatever namespace you choose.  If you don't implement __prepare__ a normal dict is used.  __new__ is responsible for the actual creation/modification of the final class.  A bare-bones, do-nothing-extra metaclass would like:  class Meta(type):      def __prepare__(metaclass, cls, bases):         return dict()      def __new__(metacls, cls, bases, clsdict):         return super().__new__(metacls, cls, bases, clsdict)   A simple example:  Say you want some simple validation code to run on your attributes -- like it must always be an int or a str.  Without a metaclass, your class would look something like:  class Person:     weight = ValidateType('weight', int)     age = ValidateType('age', int)     name = ValidateType('name', str)   As you can see, you have to repeat the name of the attribute twice.  This makes typos possible along with irritating bugs.  A simple metaclass can address that problem:  class Person(metaclass=Validator):     weight = ValidateType(int)     age = ValidateType(int)     name = ValidateType(str)   This is what the metaclass would look like (not using __prepare__ since it is not needed):  class Validator(type):     def __new__(metacls, cls, bases, clsdict):         # search clsdict looking for ValidateType descriptors         for name, attr in clsdict.items():             if isinstance(attr, ValidateType):                 attr.name = name                 attr.attr = '_' + name         # create final class and return it         return super().__new__(metacls, cls, bases, clsdict)   A sample run of:  p = Person() p.weight = 9 print(p.weight) p.weight = '9'   produces:  9 Traceback (most recent call last):   File \"simple_meta.py\", line 36, in <module>     p.weight = '9'   File \"simple_meta.py\", line 24, in __set__     (self.name, self.type, value)) TypeError: weight must be of type(s) <class 'int'> (got '9')     Note:  This example is simple enough it could have also been accomplished with a class decorator, but presumably an actual metaclass would be doing much more.  The 'ValidateType' class for reference:  class ValidateType:     def __init__(self, type):         self.name = None  # will be set by metaclass         self.attr = None  # will be set by metaclass         self.type = type     def __get__(self, inst, cls):         if inst is None:             return self         else:             return inst.__dict__[self.attr]     def __set__(self, inst, value):         if not isinstance(value, self.type):             raise TypeError('%s must be of type(s) %s (got %r)' %                     (self.name, self.type, value))         else:             inst.__dict__[self.attr] = value      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "8", "A_Content": "     You can make the file usable as a script as well as an importable module.   fibo.py (a module named fibo)  # Other modules can IMPORT this MODULE to use the function fib def fib(n):    # write Fibonacci series up to n     a, b = 0, 1     while b < n:         print(b, end=' ')         a, b = b, a+b     print()  # This allows the file to be used as a SCRIPT if __name__ == \"__main__\":     import sys     fib(int(sys.argv[1]))   Reference: https://docs.python.org/3.5/tutorial/modules.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "8", "A_Content": "  Consider:  print __name__   The output for the above is __main__.  if __name == \"__main__\":   print \"direct method\"   The above statement is true and prints \"direct method\". Suppose if they imported this class in other class it doesn't print \"direct method\" because, while importing, it will set __name__ equal to \"firstmodel name\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "2", "A_Content": "  Create a file, a.py:  print(__name__) # It will print out __main__   __name__ is always equal to __main__ whenever that file is run directly showing that this is the main file.  Create another file, b.py, in the same directory:  import a  # Prints a   Run it. It will print a, i.e., the name of the file which is imported.  So, to show two different behavior of the same file, this is a commonly used trick:  # Code to be run when imported into another python file  if __name__ == '__main__':     # Code to be run only when run directly      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "2", "A_Content": "  All the answers have pretty much explained the functionality. But I will provide one example of its usage which might help clearing out the concept further.  Assume that you have two Python files, a.py and b.py. Now, a.py imports b.py. We run the a.py file, where the \"import b.py\" code is executed first. Before the rest of the a.py code runs, the code in the file b.py must run completely.  In the b.py code there is some code that is exclusive to that file b.py and we don't want any other file (other than b.py file), that has imported the b.py file, to run it.  So that is what this line of code checks. If it is the main file (i.e., b.py) running the code, which in this case it is not (a.py is the main file running), then only the code gets executed.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "2", "A_Content": "  I've been reading so much throughout the answers on this page. I would say, if you know the thing, for sure you will understand those answers, otherwise, you are still confused.  To be short, you need to know several points:   import a action actually runs all that can be ran in \"a\" Because of point 1, you may not want everything to be run in \"a\" when importing it To solve the problem in point 2, python allows you to put a condition check __name__ is an implicit variable in all .py modules; when a.py is imported, the value of __name__ of a.py module is set to its file name \"a\"; when a.py is run directly using \"python a.py\", which means a.py is the entry point, then the value of __name__ of a.py module is set to a string __main__ Based on the mechanism how python sets the variable __name__ for each module, do you know how to achieve point 3? The answer is fairly easy, right? Put a if condition: if __name__ == \"__main__\": ...; you can even put if __name__ == \"a\" depending on your functional need   The important thing that python is special at is point 4! The rest is just basic logic.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "1", "A_Content": "  if name == 'main':  We see if __name__ == '__main__': quite often.  It checks if a module is being imported or not.  In other words, the code within the if block will be executed only when the code runs directly. Here directly means not imported.  Let's see what it does using a simple code that prints the name of the module:  # test.py def test():    print('test module name=%s' %(__name__))  if __name__ == '__main__':    print('call test()')    test()   If we run the code directly via python test.py, the module name is __main__:  call test() test module name=__main__      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "1", "A_Content": "  If this .py file are imported by other .py files, the code under \"the if statement\" will not be executed.  If this .py are run by python this_py.py under shell, or double clicked in Windows. the code under \"the if statement\" will be executed.  It is usually written for testing.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "-1", "A_Content": "  _ name _ == _ main _ will make sure that the code/statements present inside this block will run only when we execute this file directly, instead if we import this as module in another python file then we can call the function defined in it and also the block whichever is present inside the _ name == main _ will not get executed.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "-1", "A_Content": "  If the python interpreter is running that module (the source file) as the main program, it sets the special name variable to have a value \u201cmain\u201d.  If this file is being imported from another module, name will be set to the module\u2019s name. Module\u2019s name is available as value to name global variable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/419163/what-does-if-name-main-do", "Language": "Python", "Q_Title": "What does if __name__ == \u201c__main__\u201d: do?", "Q_Votes": "4250", "Q_Content": "    What does the if __name__ == \"__main__\": do?  # Threading example import time, thread  def myfunction(string, sleeptime, lock, *args):     while True:         lock.acquire()         time.sleep(sleeptime)         lock.release()         time.sleep(sleeptime)  if __name__ == \"__main__\":     lock = thread.allocate_lock()     thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))     thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))      ", "Tags": ["python", "namespaces", "main", "python-module", "idioms"], "A_Votes": "-1", "A_Content": "     What does the if name == \"main\": do?   Outline:  1, As an executable script, work for oneself as self-employed:  It executes the codes in the module if is run directly as \"python foo.py\" 2, As an imported module to work for others: It's codes could be reused safely if as imported to another module as \"import foo\"     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1549801/what-are-the-differences-between-type-and-isinstance", "Language": "Python", "Q_Title": "What are the differences between type() and isinstance()?", "Q_Votes": "953", "Q_Content": "    What are the differences between these two code fragments? Using type():  import types  if type(a) is types.DictType:     do_something() if type(b) in types.StringTypes:     do_something_else()   Using isinstance():  if isinstance(a, dict):     do_something() if isinstance(b, str) or isinstance(b, unicode):     do_something_else()      ", "Tags": ["python", "oop", "inheritance", "types"], "A_Votes": "1020", "A_Content": "  To summarize the contents of other (already good!) answers, isinstance caters for inheritance (an instance of a derived class is an instance of a base class, too), while checking for equality of type does not (it demands identity of types and rejects instances of subtypes, AKA subclasses).  Normally, in Python, you want your code to support inheritance, of course (since inheritance is so handy, it would be bad to stop code using yours from using it!), so isinstance is less bad than checking identity of types because it seamlessly supports inheritance.  It's not that isinstance is good, mind you\u2014it's just less bad than checking equality of types.  The normal, Pythonic, preferred solution is almost invariably \"duck typing\": try using the argument as if it was of a certain desired type, do it in a try/except statement catching all exceptions that could arise if the argument was not in fact of that type (or any other type nicely duck-mimicking it;-), and in the except clause, try something else (using the argument \"as if\" it was of some other type).  basestring is, however, quite a special case\u2014a builtin type that exists only to let you use isinstance (both str and unicode subclass basestring). Strings are sequences (you could loop over them, index them, slice them, ...), but you generally want to treat them as \"scalar\" types\u2014it's somewhat incovenient (but a reasonably frequent use case) to treat all kinds of strings (and maybe other scalar types, i.e., ones you can't loop on) one way, all containers (lists, sets, dicts, ...) in another way, and basestring plus isinstance helps you do that\u2014the overall structure of this idiom is something like:  if isinstance(x, basestring)   return treatasscalar(x) try:   return treatasiter(iter(x)) except TypeError:   return treatasscalar(x)   You could say that basestring is an Abstract Base Class (\"ABC\")\u2014it offers no concrete functionality to subclasses, but rather exists as a \"marker\", mainly for use with isinstance. The concept is obviously a growing one in Python, since PEP 3119, which introduces a generalization of it, was accepted and has been implemented starting with Python 2.6 and 3.0.  The PEP makes it clear that, while ABCs can often substitute for duck typing, there is generally no big pressure to do that (see here). ABCs as implemented in recent Python versions do however offer extra goodies: isinstance (and issubclass) can now mean more than just \"[an instance of] a derived class\" (in particular, any class can be \"registered\" with an ABC so that it will show as a subclass, and its instances as instances of the ABC); and ABCs can also offer extra convenience to actual subclasses in a very natural way via Template Method design pattern applications (see here and here [[part II]] for more on the TM DP, in general and specifically in Python, independent of ABCs).  For the underlying mechanics of ABC support as offered in Python 2.6, see here; for their 3.1 version, very similar, see here.  In both versions, standard library module collections (that's the 3.1 version\u2014for the very similar 2.6 version, see here) offers several useful ABCs.  For the purpose of this answer, the key thing to retain about ABCs (beyond an arguably more natural placement for TM DP functionality, compared to the classic Python alternative of mixin classes such as UserDict.DictMixin) is that they make isinstance (and issubclass) much more attractive and pervasive (in Python 2.6 and going forward) than they used to be (in 2.5 and before), and therefore, by contrast, make checking type equality an even worse practice in recent Python versions than it already used to be.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "43", "A_Content": "  Role of a metaclass' __call__() method when creating a class instance  If you've done Python programming for more than a few months you'll eventually stumble upon code that looks like this:  # define a class class SomeClass(object):     # ...     # some definition here ...     # ...  # create an instance of it instance = SomeClass()  # then call the object as if it's a function result = instance('foo', 'bar')   The latter is possible when you implement the __call__() magic method on the class.  class SomeClass(object):     # ...     # some definition here ...     # ...      def __call__(self, foo, bar):         return bar + foo   The __call__() method is invoked when an instance of a class is used as a callable. But as we've seen from previous answers a class itself is an instance of a metaclass, so when we use the class as a callable (i.e. when we create an instance of it) we're actually calling its metaclass' __call__() method. At this point most Python programmers are a bit confused because they've been told that when creating an instance like this instance = SomeClass() you're calling its __init__() method. Some who've dug a bit deeper know that before __init__() there's __new__(). Well, today another layer of truth is being revealed, before __new__() there's the metaclass' __call__().  Let's study the method call chain from specifically the perspective of creating an instance of a class.  This is a metaclass that logs exactly the moment before an instance is created and the moment it's about to return it.  class Meta_1(type):     def __call__(cls):         print \"Meta_1.__call__() before creating an instance of \", cls         instance = super(Meta_1, cls).__call__()         print \"Meta_1.__call__() about to return instance.\"         return instance   This is a class that uses that metaclass  class Class_1(object):      __metaclass__ = Meta_1      def __new__(cls):         print \"Class_1.__new__() before creating an instance.\"         instance = super(Class_1, cls).__new__(cls)         print \"Class_1.__new__() about to return instance.\"         return instance      def __init__(self):         print \"entering Class_1.__init__() for instance initialization.\"         super(Class_1,self).__init__()         print \"exiting Class_1.__init__().\"   And now let's create an instance of Class_1  instance = Class_1() # Meta_1.__call__() before creating an instance of <class '__main__.Class_1'>. # Class_1.__new__() before creating an instance. # Class_1.__new__() about to return instance. # entering Class_1.__init__() for instance initialization. # exiting Class_1.__init__(). # Meta_1.__call__() about to return instance.   Observe that the code above doesn't actually do anything more than logging the tasks. Each method delegates the actual work to its parent's implementation, thus keeping the default behavior. Since type is Meta_1's parent class (type being the default parent metaclass) and considering the ordering sequence of the output above, we now have a clue as to what would be the pseudo implementation of type.__call__():  class type:     def __call__(cls, *args, **kwarg):          # ... maybe a few things done to cls here          # then we call __new__() on the class to create an instance         instance = cls.__new__(cls, *args, **kwargs)          # ... maybe a few things done to the instance here          # then we initialize the instance with its __init__() method         instance.__init__(*args, **kwargs)          # ... maybe a few more things done to instance here          # then we return it         return instance   We can see that the metaclass' __call__() method is the one that's called first. It then delegates creation of the instance to the class's __new__() method and initialization to the instance's __init__(). It's also the one that ultimately returns the instance.  From the above it stems that the metaclass' __call__() is also given the opportunity to decide whether or not a call to Class_1.__new__() or Class_1.__init__() will eventually be made. Over the course of its execution it could actually return an object that hasn't been touched by either of these methods. Take for example this approach to the singleton pattern:  class Meta_2(type):     singletons = {}      def __call__(cls, *args, **kwargs):         if cls in Meta_2.singletons:             # we return the only instance and skip a call to __new__()             # and __init__()             print (\"{} singleton returning from Meta_2.__call__(), \"                    \"skipping creation of new instance.\".format(cls))             return Meta_2.singletons[cls]          # else if the singleton isn't present we proceed as usual         print \"Meta_2.__call__() before creating an instance.\"         instance = super(Meta_2, cls).__call__(*args, **kwargs)         Meta_2.singletons[cls] = instance         print \"Meta_2.__call__() returning new instance.\"         return instance  class Class_2(object):      __metaclass__ = Meta_2      def __new__(cls, *args, **kwargs):         print \"Class_2.__new__() before creating instance.\"         instance = super(Class_2, cls).__new__(cls)         print \"Class_2.__new__() returning instance.\"         return instance      def __init__(self, *args, **kwargs):         print \"entering Class_2.__init__() for initialization.\"         super(Class_2, self).__init__()         print \"exiting Class_2.__init__().\"   Let's observe what happens when repeatedly trying to create an object of type Class_2  a = Class_2() # Meta_2.__call__() before creating an instance. # Class_2.__new__() before creating instance. # Class_2.__new__() returning instance. # entering Class_2.__init__() for initialization. # exiting Class_2.__init__(). # Meta_2.__call__() returning new instance.  b = Class_2() # <class '__main__.Class_2'> singleton returning from Meta_2.__call__(), skipping creation of new instance.  c = Class_2() # <class '__main__.Class_2'> singleton returning from Meta_2.__call__(), skipping creation of new instance.  a is b is c # True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "42", "A_Content": "  A metaclass is a class that tells how (some) other class should be created.  This is a case where I saw metaclass as a solution to my problem: I had a really complicated problem, that probably could have been solved differently, but I chose to solve it using a metaclass.  Because of the complexity, it is one of the few modules I have written where the comments in the module surpass the amount of code that has been written.  Here it is...  #!/usr/bin/env python  # Copyright (C) 2013-2014 Craig Phillips.  All rights reserved.  # This requires some explaining.  The point of this metaclass excercise is to # create a static abstract class that is in one way or another, dormant until # queried.  I experimented with creating a singlton on import, but that did # not quite behave how I wanted it to.  See now here, we are creating a class # called GsyncOptions, that on import, will do nothing except state that its # class creator is GsyncOptionsType.  This means, docopt doesn't parse any # of the help document, nor does it start processing command line options. # So importing this module becomes really efficient.  The complicated bit # comes from requiring the GsyncOptions class to be static.  By that, I mean # any property on it, may or may not exist, since they are not statically # defined; so I can't simply just define the class with a whole bunch of # properties that are @property @staticmethods. # # So here's how it works: # # Executing 'from libgsync.options import GsyncOptions' does nothing more # than load up this module, define the Type and the Class and import them # into the callers namespace.  Simple. # # Invoking 'GsyncOptions.debug' for the first time, or any other property # causes the __metaclass__ __getattr__ method to be called, since the class # is not instantiated as a class instance yet.  The __getattr__ method on # the type then initialises the class (GsyncOptions) via the __initialiseClass # method.  This is the first and only time the class will actually have its # dictionary statically populated.  The docopt module is invoked to parse the # usage document and generate command line options from it.  These are then # paired with their defaults and what's in sys.argv.  After all that, we # setup some dynamic properties that could not be defined by their name in # the usage, before everything is then transplanted onto the actual class # object (or static class GsyncOptions). # # Another piece of magic, is to allow command line options to be set in # in their native form and be translated into argparse style properties. # # Finally, the GsyncListOptions class is actually where the options are # stored.  This only acts as a mechanism for storing options as lists, to # allow aggregation of duplicate options or options that can be specified # multiple times.  The __getattr__ call hides this by default, returning the # last item in a property's list.  However, if the entire list is required, # calling the 'list()' method on the GsyncOptions class, returns a reference # to the GsyncListOptions class, which contains all of the same properties # but as lists and without the duplication of having them as both lists and # static singlton values. # # So this actually means that GsyncOptions is actually a static proxy class... # # ...And all this is neatly hidden within a closure for safe keeping. def GetGsyncOptionsType():     class GsyncListOptions(object):         __initialised = False      class GsyncOptionsType(type):         def __initialiseClass(cls):             if GsyncListOptions._GsyncListOptions__initialised: return              from docopt import docopt             from libgsync.options import doc             from libgsync import __version__              options = docopt(                 doc.__doc__ % __version__,                 version = __version__,                 options_first = True             )              paths = options.pop('<path>', None)             setattr(cls, \"destination_path\", paths.pop() if paths else None)             setattr(cls, \"source_paths\", paths)             setattr(cls, \"options\", options)              for k, v in options.iteritems():                 setattr(cls, k, v)              GsyncListOptions._GsyncListOptions__initialised = True          def list(cls):             return GsyncListOptions          def __getattr__(cls, name):             cls.__initialiseClass()             return getattr(GsyncListOptions, name)[-1]          def __setattr__(cls, name, value):             # Substitut option names: --an-option-name for an_option_name             import re             name = re.sub(r'^__', \"\", re.sub(r'-', \"_\", name))             listvalue = []              # Ensure value is converted to a list type for GsyncListOptions             if isinstance(value, list):                 if value:                     listvalue = [] + value                 else:                     listvalue = [ None ]             else:                 listvalue = [ value ]              type.__setattr__(GsyncListOptions, name, listvalue)      # Cleanup this module to prevent tinkering.     import sys     module = sys.modules[__name__]     del module.__dict__['GetGsyncOptionsType']      return GsyncOptionsType  # Our singlton abstract proxy class. class GsyncOptions(object):     __metaclass__ = GetGsyncOptionsType()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "28", "A_Content": "  type is actually a metaclass -- a class that creates another classes. Most metaclass are the subclasses of type. The metaclass receives the new class as its first argument and provide access to class object with details as mentioned below:  >>> class MetaClass(type): ...     def __init__(cls, name, bases, attrs): ...         print ('class name: %s' %name ) ...         print ('Defining class %s' %cls) ...         print('Bases %s: ' %bases) ...         print('Attributes') ...         for (name, value) in attrs.items(): ...             print ('%s :%r' %(name, value)) ...   >>> class NewClass(object, metaclass=MetaClass): ...    get_choch='dairy' ...  class name: NewClass Bases <class 'object'>:  Defining class <class 'NewClass'> get_choch :'dairy' __module__ :'builtins' __qualname__ :'NewClass'   Note:  Notice that the class was not instantiated at any time; the simple act of creating the class triggered execution of the metaclass.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "24", "A_Content": "  The tl;dr version  The type(obj) function gets you the type of an object.   The type() of a class is its metaclass.  To use a metaclass:  class Foo(object):     __metaclass__ = MyMetaClass      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "13", "A_Content": "  Python classes are themselves objects - as in instance - of their meta-class.   The default metaclass, which is applied when when you determine classes as:  class foo:     ...   meta class are used to apply some rule to an entire set of classes. For example, suppose you're building an ORM to access a database, and you want records from each table to be of a class mapped to that table (based on fields, business rules, etc..,), a possible use of metaclass is for instance, connection pool logic, which is share by all classes of record from all tables. Another use is logic to to support foreign keys, which involves multiple classes of records.   when you define metaclass, you subclass type, and can overrided the following magic methods to insert your logic.   class somemeta(type):     __new__(mcs, name, bases, clsdict):       \"\"\"   mcs: is the base metaclass, in this case type.   name: name of the new class, as provided by the user.   bases: tuple of base classes    clsdict: a dictionary containing all methods and attributes defined on class    you must return a class object by invoking the __new__ constructor on the base metaclass.   ie:      return type.__call__(mcs, name, bases, clsdict).    in the following case:    class foo(baseclass):         __metaclass__ = somemeta    an_attr = 12    def bar(self):       ...    @classmethod   def foo(cls):       ...        arguments would be : ( somemeta, \"foo\", (baseclass, baseofbase,..., object), {\"an_attr\":12, \"bar\": <function>, \"foo\": <bound class method>}        you can modify any of these values before passing on to type       \"\"\"       return type.__call__(mcs, name, bases, clsdict)       def __init__(self, name, bases, clsdict):       \"\"\"        called after type has been created. unlike in standard classes, __init__ method cannot modify the instance (cls) - and should be used for class validaton.       \"\"\"       pass       def __prepare__():         \"\"\"         returns a dict or something that can be used as a namespace.         the type will then attach methods and attributes from class definition to it.          call order :          somemeta.__new__ ->  type.__new__ -> type.__init__ -> somemeta.__init__          \"\"\"         return dict()      def mymethod(cls):         \"\"\" works like a classmethod, but for class objects. Also, my method will not be visible to instances of cls.         \"\"\"         pass   anyhow, those two are the most commonly used hooks. metaclassing is powerful, and above is nowhere near and exhaustive list of uses for metaclassing.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "9", "A_Content": "  The type() function can return the type of an object or create a new type,   for example, we can create a Hi class with the type() function and do not  need to use this way with class Hi(object):  def func(self, name='mike'):     print('Hi, %s.' % name)  Hi = type('Hi', (object,), dict(hi=func)) h = Hi() h.hi() Hi, mike.  type(Hi) type  type(h) __main__.Hi   In addition to using type() to create classes dynamically, you can control creation behavior of class and use metaclass.  According to the Python object model, the class is the object, so the class must be an instance of another certain class. By default, a Python class is instance of the type class. That is, type is metaclass of most of the built-in classes and metaclass of user-defined classes.  class ListMetaclass(type):     def __new__(cls, name, bases, attrs):         attrs['add'] = lambda self, value: self.append(value)         return type.__new__(cls, name, bases, attrs)  class CustomList(list, metaclass=ListMetaclass):     pass  lst = CustomList() lst.add('custom_list_1') lst.add('custom_list_2')  lst ['custom_list_1', 'custom_list_2']   Magic will take effect when we passed keyword arguments in metaclass, it indicates the Python interpreter to create the CustomList through ListMetaclass. new (), at this point, we can modify the class definition, for example, and add a new method and then return the revised definition.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/100003/what-are-metaclasses-in-python", "Language": "Python", "Q_Title": "What are metaclasses in Python?", "Q_Votes": "4660", "Q_Content": "    What are metaclasses and what do we use them for?     ", "Tags": ["python", "oop", "metaclass", "python-datamodel"], "A_Votes": "8", "A_Content": "  Two sentences to master Python's most difficult knowledge point: Metaclass  Original source: segmentfault.com/a/1190000011447445  translated and corrected by me.  The orignal author of this article preserve all right, however the translating jobs still can not be ignored  If there are some mistakes or some format against PEP8, please help me to correct it. Thanks!!!  At the begining, there are some examples from chinese traditional culture(I am not Chinese, but I have some knowledge about it. If you like it, it is good. And if you don't, just ignore it. The understanding of metaclass is most important thing)  It is a brief introduction of Metaclass in Python with some practical and useful example. Wish you will like it.  Don't be frightened by such rhetoric as the so-called \"feature that the metaclass is not used by 99% of Python programmers.\" Because every person is a natural user.  To understand metaclasses, you only need to know two sentences:  sentence 1: one came from truth, two came from one, three came from two, all the things came from three  sentence 2: who am I? Where did I come from? Where do I go?  In the python world, there is an eternal truth, that is, \"type\", please remember in mind, type is the truth. The python ecosystem that is so vast is produced by type.  one came from truth, two came from one, three came from two, all the things came from three:  The truth is type  One is the metaclass (metaclass, or class generator)  Second is the class (class, or instance generator)  Three is an instance (example)  Everything is the various attributes and methods of an instance. When we use Python, we call them.   Truth and One are the propositions we discuss today. The second, third, and all things are the classes, instances, attributes, and methods that we often use. We use hello world as an example:  # Create a Hello class that has the attributes say_hello ---- Second Origin  class Hello () :       def say_hello ( self ,name= 'world' ) :           print( 'Hello, %s.' % name )      # Create an instance hello from the Hello class ---- Two students three  Hello = Hello ()    # Use hello to call the method say_hello ---- all three things  Hello.say_hello ()    Output effect:  Hello, world.    This is a standard \"three came from two, all the things came from three\" process. From the class to the methods we can call, these two steps are used.  Then we can't help from the main question, where does the class come from? Go back to the first line of code.  The class Hello is actually a \"semantic abbreviation\" of a function, just to make the code easier to understand. Another way of writing it is:  def  fn(self ,name='world' ) : # If we have a function called fn      print ( 'Hello, %s.' % name )   Hello = type ('Hello',(object,),dict(say_hello = fn)) # Create Hello class by type ---- Mysterious \"Truth\", you can change everything, this time we directly from the \"Truth\" gave birth to \"2\"    This type of writing is exactly the same as the previous Class Hello writing. You can try to create an instance and call it.  # Create an instance of hello from the Hello class.  hello = Hello ()    # Use hello call method say_hello ---- all three things, exactly the same  Hello . say_hello ()    Output effect:  Hello, world. ---- The result of the call is exactly the same.    We looked back at the most exciting place. The road gave birth directly to two:  Hello = type('Hello', (object,), dict(say_hello=fn))    This is the \"Truth\", the origin of the python world. You can marvel at this.  Pay attention to its three parameters! Three eternal propositions that coincide with mankind: Who am I, where do I come from, where do I go?  The first parameter: who I am. Here, I need a name that distinguishes everything else. The above example names me \"Hello.\"  The second parameter: where do I come from. Here, I need to know where I come from, which is my \"parent\". In my example above, my parent is \"object\" - a very primitive class in Python.  The third parameter: Where do I go? Here, we include the methods and properties that we need to call into a dictionary and pass them as parameters. In the above example, we have a say_hello method packed into a dictionary.    It is worth noting that the three major eternal propositions are all classes, all instances, and even all instance properties and methods. As it should be, their \"creators\", Truth and One, namely type and metaclass, also have these three parameters. But usually, the three eternal propositions of the class are not passed as parameters, but are passed in as follows  class Hello(object):{  After class # statement \"Who Am I?\"  # In the parentheses declare \"where do I come from\"  # In curly brackets declare \"Where do I go?\"       def say_hello ():{         }  }    The Creator can create a single person directly, but this is a hard labor. The Creator will first create the species \"human\" and then create a specific individual in batches. And pass on the three eternal propositions.  \"Truth\" can produce \"2\" directly, but it will produce \"1\" and then make \"2\" in batches.  Type can directly generate a class, but it can also be a metaclass and then use a metaclass to customize a class.    Metaclass - One came from Truth, two came from one.  In general, metaclasses are named suffix Metaclass. Imagine that we need a metaclass that can automatically say hello. The class methods in it, sometimes need say_Hello, sometimes say_Hi, sometimes say_Sayolala, and sometimes say_Nihao.  If every built-in say_xxx needs to be declared once in a class, how terribly hard work it will be! It is better to use metaclasses to solve the problem.  The following is a meta class code for creating a special \"greet\":  class SayMetaClass(type):         def __new__ (cls, Name ,Bases ,Attrs) :           attrs[ 'say_' + name ] = lambda   self, value , saying = name : print ( saying + ',' + value + '!' )           Return   Type . __new__ ( cls ,name, bases ,   attrs)    Remember two things:  Metaclasses are derived from \"type\", so the parent class needs to pass in the type. [Taosheng 1, so one must include Tao]  Metaclass operations are done in __new__. The first parameter is the class that will be created. The following parameters are the three eternal propositions: Who am I, where do I come from, and where do I go. The objects it returns are also the three eternal propositions. Next, these three parameters will always be with us.   In new, I only performed one operation.  Attrs['say_'+name] = lambda self,value,saying=name: print(saying+','+value+'!')    It creates a class method with the name of the class. For example, the class we created from metaclass is called \"Hello\". When it was created, it would automatically have a class method called \"say_Hello\". Then it would use the class name \"Hello\" as the default parameter to say, and passed it to the method. Then pass in the hello method call as a value, and finally print it out.  So how does a metaclass go from creation to invocation?  Come! Together with the principles of Daosheng, Yishengyou, Bishengsan, Sanshengwu, enter the life cycle of the Yuan class!  # Tao Shengyi: incoming type  class SayMetaClass(type):         # Incoming three eternal propositions: class name, parent class, attribute       def __new__(cls ,name ,bases ,attrs):           # Create \"talent\"           attrs[ 'say_' + name ] = lambda   self, value , saying = name : print( saying + ',' + value + '!' )           # Three eternal propositions: class name, parent class, attribute           return type . __new__ ( cls ,name ,bases ,attrs )    # Lifetime 2: Create class  class Hello ( object ,metaclass = SayMetaClass):      pass    # two students three: create a real column  Hello = Hello ()    # Three things: call the instance method  hello.say_Hello('world!')    The output is  Hello, world!    Note: The class created by the metaclass, the first parameter is the parent class, the second parameter is the metaclass  Ordinary people will not be able to speak at birth, but some people will say hello, \u201chello\u201d and \u201csayolala\u201d when they are born. This is the power of talent. It will give us object-oriented programming to save countless troubles.  Now, keeping the metaclass unchanged, we can continue to create the Sayolala, Nihao class, as follows:  # Two came from one: Create class  class Sayolala ( object ,metaclass = SayMetaClass ) :     pass    # three came from two: create a real column  s = Sayolala ()    # all things came from two: call the instance method  s.say_Sayolala ( 'japan!' )    Output  Sayolala, japan!    Can also speak Chinese  # Two came from one: Create class  class Nihao(object ,metaclass = SayMetaClass ) :     pass    # two students three: create a real column  n = Nihao()    # Three things: call the instance method  n.say_Nihao ( '\u4e2d \u4e2d\u534e!' )    Output  Nihao, China!    Another small example:  # one came from truth.  class ListMetaclass (type) :       def   __new__ ( cls ,name, bases ,   attrs) :           # Talent: Bind values \u200b\u200bby the add method           attrs[ 'add' ] = lambda   self, value: self.append(value)           return type . __new__ ( cls ,name ,bases ,attrs )    # One lifetime  class MyList ( list ,   Metaclass = ListMetaclass ) :     pass    # Two students three  L = MyList ()    # Three things  L.add( 1 )    Now we print L  print(L)    >>> [ 1 ]    The ordinary list does not have an add() method  L2 = list ()  L2 . add ( 1 )    >>> AttributeError : 'list'   Object   Has no attribute   'add'    awesome! Learned here, have you experienced the joy of the Creator?  Everything in the python world is at your fingertips.    Young Creator, please follow me to create a new world.  We choose two areas, one is the core idea of \u200b\u200bDjango, \"Object Relational Mapping\", object-relational mapping, referred to as ORM.  This is a major Django difficulty, but after learning the metaclass, everything becomes clear. Your understanding of Django will be even better!  Another area is reptiles (hackers), an automatic search of available agents on the network, and then changing IP to break other people's anti-crawler restrictions.  These two skills are very useful and very fun!  Challenge 1: Create ORM by Metaclass  Prepare to create a Field class  class Field ( object ) :      def __init__ ( self, name, column_type ) :           Self.name = name           Self.column_type = column_type         def   __str__ ( self ) :           return   '<%s:%s>' % ( self . __class__ . __name__ ,   self. name )    Its role is  When the Field class is instantiated, it will get two parameters, name and column_type. They will be bound to Field's private property. If you want to convert the Field into a string, it will return \"Field:XXX\". XXX is passed in. Name name.  Preparation: Create StringField and IntergerField  class StringField ( Field ) :        def   __init__ ( self ,   name ) :           super( StringField ,   self). __init__ ( name ,   'varchar(100)' )    class IntegerField ( Field ) :      def   __init__ ( self ,name) :           super( IntegerField ,   self). __init__ ( name ,   'bigint' )    Its role is  When the StringField, IntegerField instance is initialized, the parent's initialization method is automatically called.  one came from the truth  class ModelMetaclass ( type ) :         def __new__ ( cls ,name, bases ,   attrs) :           Ifname== 'Model' :               Return   Type . __new__ ( cls ,name, bases ,   attrs)           print( 'Found model: %s' % name )           Mappings = dict ()           for k ,   v   In   attrs. items () :               If   Isinstance ( v ,   Field ) :                   print( 'Found mapping: %s ==> %s' % ( k ,   v ))                   Mappings [ k ] = v           for k   In   Mappings . keys () :               attrs. pop ( k )           attrs[ '__mappings__' ] = mappings   # Save the mapping between attributes and columns           attrs[ '__table__' ] = name   # Assume that the table name and class name are the same           Return   Type . __new__ ( cls ,name, bases ,   attrs)    It does the following things  Create a new dictionary mapping  Each property of the class is traversed through its .items() key-value pair. If the value is a Field class, the key is printed and the key is bound to the mapping dictionary.  Delete the property that was just passed in as the Field class.  Create a special __mappings__ attribute and save the dictionary mapping.  Create a special __table__ attribute and save the name of the passed in class.    two came from one  class Model ( dict ,   Metaclass = ModelMetaclass ) :         def __init__ ( self , ** kwarg ) :           super(model ,   self). __init__ ( ** kwarg )         def __getattr__ ( self ,   Key ) :           Try :               Return   self[ key ]           except KeyError :               Raise   AttributeError ( \"'Model' object has no attribute '%s'\" % key )         def __setattr__ ( self ,   Key ,   Value ) :           self[ key ] = value         # Simulate table creation operation       def save( self ) :           Fields = []           Args = []           for k ,   v   In   self. __mappings__ . items () :               Fields . append ( v . name )               Args . append ( getattr ( self ,   k ,   None ))           Sql = 'insert into %s (%s) values \u200b\u200b(%s)' % ( self . __table__ ,   ',' . join ( fields ),   ',' . join ([ str ( i )   for i   In   Args ]))           print( 'SQL: %s' % sql )           print( 'ARGS: %s' % str ( args ))    If you create a subclass User from themodel:  class User (model ) :       # Define the mapping of attributes's attributes to columns:       Id = IntegerField ( 'id' )    name= StringField ( 'username' )       Email = StringField ( 'email' )       Password = StringField ( 'password' )    At this time  Id= IntegerField('id') will automatically resolve to:  Model.setattr(self, 'id', IntegerField('id'))  Because IntergerField('id') is an instance of Field's subclass, the metaclass's new is automatically triggered, so the IntergerField('id') is stored in mappings and the key-value pair is deleted.  Two students, three students, all things  When you initialize an instance and call the save() method  u = User ( id = 12345 ,name= 'Batman' ,   Email = 'batman@nasa.org' ,   Password = 'iamback' )  u . save ()    At this time, the process of two students is completed first:  First call Model.__setattr__ to load key values \u200b\u200binto private objects  Then call the \"genius\" of the metaclass, ModelMetaclass.__new__, and private objects in the Model, as long as they are instances of Field, are automatically stored in u.__mappings__.    The next step is to complete the three things:  Simulate data inventory operations through u.save(). Here we just do a little traversal mappings operation, virtual sql and print, in reality, by entering the sql statement and the database to run.  The output is  Found model : User  Found mapping : name ==> < StringField : username >  Found mapping : password ==> < StringField : password >  Found mapping : id ==> < IntegerField : id >  Found mapping : email ==> < StringField : email >  SQL : insert into User   ( username , password , id , email )   Values   ( Batman , iamback , 12345 , batman @ nasa . org )  ARGS : [ 'Batman' ,   'iamback'   12345 ,   'batman@nasa.org' ]        Young Creator, you have experienced with me the great course of evolution of Everything from the Tao, which is also the core principle of the Model section in Django.      Next, join me in a more fun reptile battle (well, you are now a junior hacker): crawling web agents!    Challenge II: Crawling of Network Agents  Prepare to climb a page to play  Please make sure that both packages, requests and pyquery, are installed.  # File: get_page.py  import Requests    Base_headers = {       'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36' ,       'Accept-Encoding' : 'gzip, deflate, sdch' ,       'Accept-Language' : 'zh-CN,zh;q=0.8'  }      def Get_page ( url ) :       Headers = dict ( base_headers )       print( 'Getting' ,   Url )       Try :           r = requests . get ( url ,   Headers = headers )           print( 'Getting result' ,   Url ,   r . status_code )           If   r . status_code == 200 :               Return   r .       exceptConnectionError :           print( 'Crawling Failed' ,   Url )           Return   None    Here, we use the request package to climb out of Baidu's source code.  Try to try Baidu  Stick this paragraph behind get_page.py and try deleting  If ( __name__ == '__main__' ) :       Rs = get_page ( 'https://www.baidu.com' )       print( 'result: ' ,   Rs )    Try to catch agents  Stick this paragraph behind get_page.py and try deleting  If ( __name__ == '__main__' ) :       from Pyquery import   PyQuery as   Pq       Start_url = 'http://www.proxy360.cn/Region/China'       print( 'Crawling' ,   Start_url )       Html = get_page ( start_url )       If   Html :           Doc = pq ( html )           Lines = doc ( 'div[name=\"list_proxy_ip\"]' ). items ()           for Line in   Lines :               Ip = line . find ( '.tbBottomLine:nth-child(1)' ). text ()               Port = line . find ( '.tbBottomLine:nth-child(2)' ). text ()               print( ip + ':' + port )    Next, go to the topic: Use the metaclass batch fetch proxy    Batch processing crawling agent  from Getpage import   Get_page  from Pyquery import   PyQuery as   Pq      # one came from truth: Create metaclass of extraction agent  class ProxyMetaclass ( type ) :       \"\"\"  Metaclass, added in the FreeProxyGetter class  __CrawlFunc__ and __CrawlFuncCount__  Two parameters, which represent the crawler function and the number of crawler functions, respectively.  \"\"\"       def __new__ ( cls ,name, bases ,   attrs) :           Count = 0           attrs[ '__CrawlFunc__' ] = []           attrs[ '__CrawlName__' ] = []           for k ,   v   In   attrs. items () :               If   'crawl_'   In   k :                   attrs[ '__CrawlName__' ]. append ( k )                   attrs[ '__CrawlFunc__' ]. append ( v )                   Count += 1           for k   In   attrs[ '__CrawlName__' ] :               attrs. pop ( k )           attrs[ '__CrawlFuncCount__' ] = count           Return   Type . __new__ ( cls ,name, bases ,   attrs)      # two came from one: Create an agent to get the class    class ProxyGetter ( object ,   Metaclass = ProxyMetaclass ) :       def Get_raw_proxies ( self ,   Site ) :           Proxies = []           print( 'Site' ,   Site )           for Func in   self. __CrawlFunc__ :               If   Func . __name__ == site :                   This_page_proxies = func ( self )                   for Proxy in   This_page_proxies :                       print( 'Getting' ,   Proxy ,   'from' ,   Site )                       Proxies . append ( proxy )           Return   Proxies           def Crawl_daili66 ( self ,   Page_count = 4 ) :           Start_url = 'http://www.66ip.cn/{}.html'           Urls = [ start_url . format ( page )   for Page in   Range ( 1 ,   Page_count + 1 )]           for Url in   Urls :               print( 'Crawling' ,   Url )               Html = get_page ( url )               If   Html :                   Doc = pq ( html )                   Trs = doc ( '.containerbox table tr:gt(0)' ). items ()                   for Tr in   Trs :                       Ip = tr . find ( 'td:nth-child(1)' ). text ()                       Port = tr . find ( 'td:nth-child(2)' ). text ()                       Yield   ':' . join ([ ip ,   Port ])         def Crawl_proxy360 ( self ) :           Start_url = 'http://www.proxy360.cn/Region/China'           print( 'Crawling' ,   Start_url )           Html = get_page ( start_url )           If   Html :               Doc = pq ( html )               Lines = doc ( 'div[name=\"list_proxy_ip\"]' ). items ()               for Line in   Lines :                   Ip = line . find ( '.tbBottomLine:nth-child(1)' ). text ()                   Port = line . find ( '.tbBottomLine:nth-child(2)' ). text ()                   Yield   ':' . join ([ ip ,   Port ])         def Crawl_goubanjia ( self ) :           Start_url = 'http://www.goubanjia.com/free/gngn/index.shtml'           Html = get_page ( start_url )           If   Html :               Doc = pq ( html )               Tds = doc ( 'td.ip' ). items ()               for Td in   Tds :                   Td . find ( 'p' ). remove ()                   Yield   Td . text (). replace ( ' ' ,   '' )      If   __name__ == '__main__' :       # Two students three: Instantiate ProxyGetter       Crawler = ProxyGetter ()       print(crawler . __CrawlName__ )       # Three things       for Site_label in   Range ( crawler . __CrawlFuncCount__ ) :           Site = crawler . __CrawlName__ [ site_label ]           myProxies = crawler . get_raw_proxies ( site )    one came from truth: In the metaclass new, he did four things:  Push the name of the class method that starts with \"crawl_\" into ProxyGetter.__CrawlName__  Push the class method that starts with \"crawl_\" itself into ProxyGetter.__CrawlFunc__  Calculate the number of class methods that match \"crawl_\"  Delete all class methods that match \"crawl_\"    how about it? Is it very similar to the __mappings__ process used to create an ORM?    two came from one: The class defines the method of using pyquery to grab page elements  Each of the agents shown on the page was crawled from three free agent sites.  If you are not familiar with yield usage, check out: Liao Xuefeng's python tutorial: generator  three came from two: create instance object crawler  slightly  Three things: Traversing every CrawlFunc  Above ProxyGetter.__CrawlName__, get the URL name that can be crawled.  Trigger class method ProxyGetter.get_raw_proxies(site)  Traverse ProxyGetter.__CrawlFunc__, if the method name and URL are the same, then execute this method  Integrate the proxy obtained from each URL into an array output.    So. . . How to use bulk agents, impact other people's websites, capture other people's passwords, frantically advertise water stickers, and regularly harass customers? Uh! Think it! These self-realization! If you do not realize it, please listen to the next decomposition!    The young Creator, the tool for creating the world, is already in your hands. Please use its power to the fullest!  Remember the wielding tool's mouth:  One came from truth, two came from one, three came from two, all the thing came from three.  Who am I, where do I come from, where do I go       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1549801/what-are-the-differences-between-type-and-isinstance", "Language": "Python", "Q_Title": "What are the differences between type() and isinstance()?", "Q_Votes": "953", "Q_Content": "    What are the differences between these two code fragments? Using type():  import types  if type(a) is types.DictType:     do_something() if type(b) in types.StringTypes:     do_something_else()   Using isinstance():  if isinstance(a, dict):     do_something() if isinstance(b, str) or isinstance(b, unicode):     do_something_else()      ", "Tags": ["python", "oop", "inheritance", "types"], "A_Votes": "269", "A_Content": "  Here's why isinstance is better than type:  class Vehicle:     pass  class Truck(Vehicle):     pass   in this case, a truck object is a Vehicle, but you'll get this:  isinstance(Vehicle(), Vehicle)  # returns True type(Vehicle()) == Vehicle      # returns True isinstance(Truck(), Vehicle)    # returns True type(Truck()) == Vehicle        # returns False, and this probably won't be what you want.   In other words, isinstance is true for subclasses, too.  Also see: How to compare type of an object in Python?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1549801/what-are-the-differences-between-type-and-isinstance", "Language": "Python", "Q_Title": "What are the differences between type() and isinstance()?", "Q_Votes": "953", "Q_Content": "    What are the differences between these two code fragments? Using type():  import types  if type(a) is types.DictType:     do_something() if type(b) in types.StringTypes:     do_something_else()   Using isinstance():  if isinstance(a, dict):     do_something() if isinstance(b, str) or isinstance(b, unicode):     do_something_else()      ", "Tags": ["python", "oop", "inheritance", "types"], "A_Votes": "62", "A_Content": "     Differences between isinstance() and type() in Python?   Type-checking with   isinstance(obj, Base)   allows for instances of subclasses and multiple possible bases:   isinstance(obj, (Base1, Base2))   whereas type-checking with   type(obj) is Base   only supports the type referenced.     As a sidenote, is is likely more appropriate than  type(obj) == Base   because classes are singletons.  Avoid type-checking - use Polymorphism (duck-typing)  In Python, usually you want to allow any type for your arguments, treat it as expected, and if the object doesn't behave as expected, it will raise an appropriate error. This is known as polymorphism, also known as duck-typing.  def function_of_duck(duck):     duck.quack()     duck.swim()   If the code above works, we can presume our argument is a duck. Thus we can pass in other things are actual sub-types of duck:  function_of_duck(mallard)   or that work like a duck:  function_of_duck(object_that_quacks_and_swims_like_a_duck)   and our code still works.  However, there are some cases where it is desirable to explicitly type-check. Perhaps you have sensible things to do with different object types. For example, the Pandas Dataframe object can be constructed from dicts or records. In such a case, your code needs to know what type of argument it is getting so that it can properly handle it.   So, to answer the question:  Differences between isinstance() and type() in Python?  Allow me to demonstrate the difference:  type  Say you need to ensure a certain behavior if your function gets a certain kind of argument (a common use-case for constructors). If you check for type like this:  def foo(data):     '''accepts a dict to construct something, string support in future'''     if type(data) is not dict:         # we're only going to test for dicts for now         raise ValueError('only dicts are supported for now')   If we try to pass in a dict that is a subclass of dict (as we should be able to, if we're expecting our code to follow the principle of Liskov Substitution, that subtypes can be substituted for types) our code breaks!:  from collections import OrderedDict  foo(OrderedDict([('foo', 'bar'), ('fizz', 'buzz')]))   raises an error!  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 3, in foo ValueError: argument must be a dict   isinstance  But if we use isinstance, we can support Liskov Substitution!:  def foo(a_dict):     if not isinstance(a_dict, dict):         raise ValueError('argument must be a dict')     return a_dict  foo(OrderedDict([('foo', 'bar'), ('fizz', 'buzz')]))   returns OrderedDict([('foo', 'bar'), ('fizz', 'buzz')])  Abstract Base Classes  In fact, we can do even better. collections provides Abstract Base Classes that enforce minimal protocols for various types. In our case, if we only expect the Mapping protocol, we can do the following, and our code becomes even more flexible:  from collections import Mapping  def foo(a_dict):     if not isinstance(a_dict, Mapping):         raise ValueError('argument must be a dict')     return a_dict   Response to comment:     It should be noted that type can be used to check against multiple classes using type(obj) in (A, B, C)   Yes, you can test for equality of types, but instead of the above, use the multiple bases for control flow, unless you are specifically only allowing those types:  isinstance(obj, (A, B, C))   The difference, again, is that isinstance supports subclasses that can be substituted for the parent without otherwise breaking the program, a property known as Liskov substitution.   Even better, though, invert your dependencies and don't check for specific types at all.  Conclusion  So since we want to support substituting subclasses, in most cases, we want to avoid type-checking with type and prefer type-checking with isinstance - unless you really need to know the precise class of an instance.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1549801/what-are-the-differences-between-type-and-isinstance", "Language": "Python", "Q_Title": "What are the differences between type() and isinstance()?", "Q_Votes": "953", "Q_Content": "    What are the differences between these two code fragments? Using type():  import types  if type(a) is types.DictType:     do_something() if type(b) in types.StringTypes:     do_something_else()   Using isinstance():  if isinstance(a, dict):     do_something() if isinstance(b, str) or isinstance(b, unicode):     do_something_else()      ", "Tags": ["python", "oop", "inheritance", "types"], "A_Votes": "56", "A_Content": "  The latter is preferred, because it will handle subclasses properly. In fact, your example can be written even more easily because isinstance()'s second parameter may be a tuple:  if isinstance(b, (str, unicode)):     do_something_else()   or, using the basestring abstract class:  if isinstance(b, basestring):     do_something_else()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1549801/what-are-the-differences-between-type-and-isinstance", "Language": "Python", "Q_Title": "What are the differences between type() and isinstance()?", "Q_Votes": "953", "Q_Content": "    What are the differences between these two code fragments? Using type():  import types  if type(a) is types.DictType:     do_something() if type(b) in types.StringTypes:     do_something_else()   Using isinstance():  if isinstance(a, dict):     do_something() if isinstance(b, str) or isinstance(b, unicode):     do_something_else()      ", "Tags": ["python", "oop", "inheritance", "types"], "A_Votes": "11", "A_Content": "  According to python documentation here is a statement:     8.15. types \u2014 Names for built-in types      Starting in Python 2.2, built-in   factory functions such as int() and   str() are also names for the   corresponding types.   So isinstance() should be preferred over type().      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1549801/what-are-the-differences-between-type-and-isinstance", "Language": "Python", "Q_Title": "What are the differences between type() and isinstance()?", "Q_Votes": "953", "Q_Content": "    What are the differences between these two code fragments? Using type():  import types  if type(a) is types.DictType:     do_something() if type(b) in types.StringTypes:     do_something_else()   Using isinstance():  if isinstance(a, dict):     do_something() if isinstance(b, str) or isinstance(b, unicode):     do_something_else()      ", "Tags": ["python", "oop", "inheritance", "types"], "A_Votes": "0", "A_Content": "  For the real differences, we can find it in code, but I can't find the implement of the default behavior of the isinstance().   However we can get the similar one abc.__instancecheck__ according to __instancecheck__.  From above abc.__instancecheck__, after using test below:  # file tree # /test/__init__.py # /test/aaa/__init__.py # /test/aaa/aa.py class b(): pass  # /test/aaa/a.py import sys sys.path.append('/test')  from aaa.aa import b from aa import b as c  d = b()  print(b, c, d.__class__) for i in [b, c, object]:     print(i, '__subclasses__',  i.__subclasses__())     print(i, '__mro__', i.__mro__)     print(i, '__subclasshook__', i.__subclasshook__(d.__class__))     print(i, '__subclasshook__', i.__subclasshook__(type(d))) print(isinstance(d, b)) print(isinstance(d, c))  <class 'aaa.aa.b'> <class 'aa.b'> <class 'aaa.aa.b'> <class 'aaa.aa.b'> __subclasses__ [] <class 'aaa.aa.b'> __mro__ (<class 'aaa.aa.b'>, <class 'object'>) <class 'aaa.aa.b'> __subclasshook__ NotImplemented <class 'aaa.aa.b'> __subclasshook__ NotImplemented <class 'aa.b'> __subclasses__ [] <class 'aa.b'> __mro__ (<class 'aa.b'>, <class 'object'>) <class 'aa.b'> __subclasshook__ NotImplemented <class 'aa.b'> __subclasshook__ NotImplemented <class 'object'> __subclasses__ [..., <class 'aaa.aa.b'>, <class 'aa.b'>] <class 'object'> __mro__ (<class 'object'>,) <class 'object'> __subclasshook__ NotImplemented <class 'object'> __subclasshook__ NotImplemented True False   I get this conclusion, For type:  # according to `abc.__instancecheck__`, they are maybe different! I have not found negative one  type(INSTANCE) ~= INSTANCE.__class__ type(CLASS) ~= CLASS.__class__   For isinstance:  # guess from `abc.__instancecheck__` return any(c in cls.__mro__ or c in cls.__subclasses__ or cls.__subclasshook__(c) for c in {INSTANCE.__class__, type(INSTANCE)})   BTW: better not to mix use relative and absolutely import, use absolutely import from project_dir( added by sys.path)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "5402", "A_Content": "  Yes, it was added in version 2.5. The syntax is:  a if condition else b   First condition is evaluated, then either a or b is returned based on the Boolean value of condition If condition evaluates to True a is returned, else b is returned.   For example:  >>> 'true' if True else 'false' 'true' >>> 'true' if False else 'false' 'false'   Note that conditionals are an expression, not a statement. This means you can't use assignments or pass or other statements in a conditional:  >>> pass if False else x = 3   File \"<stdin>\", line 1     pass if False else x = 3           ^ SyntaxError: invalid syntax   In such a case, you have to use a normal if statement instead of a conditional.    Keep in mind that it's frowned upon by some Pythonistas for several reasons:   The order of the arguments is different from many other languages (such as C, Ruby, Java, etc.), which may lead to bugs when people unfamiliar with Python's \"surprising\" behaviour use it (they may reverse the order). Some find it \"unwieldy\", since it goes contrary to the normal flow of thought (thinking of the condition first and then the effects). Stylistic reasons.   If you're having trouble remembering the order, then remember that if you read it out loud, you (almost) say what you mean. For example, x = 4 if b > 8 else 9 is read aloud as x will be 4 if b is greater than 8 otherwise 9.  Official documentation:   Conditional expressions Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator?      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "605", "A_Content": "  You can index into a tuple:  (falseValue, trueValue)[test]   test needs to return True or False. It might be safer to always implement it as:  (falseValue, trueValue)[test == True]   or you can use the built-in bool() to assure a Boolean value:  (falseValue, trueValue)[bool(<expression>)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "250", "A_Content": "  For versions prior to 2.5, there's the trick:  [expression] and [on_true] or [on_false]   It can give wrong results when on_true   has a false boolean value.1 Although it does have the benefit of evaluating expressions left to right, which is clearer in my opinion.  1. Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "159", "A_Content": "  expression1 if condition else expression2  >>> a = 1 >>> b = 2 >>> 1 if a > b else -1  -1 >>> 1 if a > b else -1 if a < b else 0 -1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "106", "A_Content": "  From the documentation:     Conditional expressions (sometimes called a \u201cternary operator\u201d) have the lowest priority of all Python operations.      The expression x if C else y first evaluates the condition, C (not x); if C is true, x is evaluated and its value is returned; otherwise, y is evaluated and its value is returned.      See PEP 308 for more details about conditional expressions.   New since version 2.5.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "80", "A_Content": "  An operator for a conditional expression in Python was added in 2006 as part of Python Enhancement Proposal 308. Its form differ from common ?: operator and it's:  <expression1> if <condition> else <expression2>   which is equivalent to:  if <condition>: <expression1> else: <expression2>   Here is an example:  result = x if a > b else y   Another syntax which can be used (compatible with versions before 2.5):  result = (lambda:y, lambda:x)[a > b]()   where operands are lazily evaluated.  Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages):  result = (y, x)[a > b]   or explicitly constructed dictionary:  result = {True: x, False: y}[a > b]   Another (less reliable), but simpler method is to use and and or operators:  result = (a > b) and x or y   however this won't work if x would be False.  A possible workaround is to make x and y lists or tuples as in the following:  result = ((a > b) and [x] or [y])[0]   or:  result = ((a > b) and (x,) or (y,))[0]   If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of get(key, default), for example:  shell = os.environ.get('SHELL', \"/bin/sh\")   Source: ?: in Python at Wikipedia     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "72", "A_Content": "  @up:  Unfortunately, the  (falseValue, trueValue)[test]   solution doesn't have short-circuit behaviour; thus both falseValue and trueValue are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both trueValue and falseValue could be methods and have side-effects).  One solution to this would be  (lambda: falseValue, lambda: trueValue)[test]()   (execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties.  And so the story goes - choosing between 3 mentioned solutions is a trade-off between having the short-circuit feature, using at least python 2.5 (IMHO not a problem anymore) and not being prone to \"trueValue-evaluates-to-false\" errors.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "48", "A_Content": "  For Python 2.5 and newer there is a specific syntax:  [on_true] if [cond] else [on_false]   In older Pythons a ternary operator is not implemented but it's possible to simulate it.  cond and on_true or on_false   Though, there is a potential problem, which if cond evaluates to True and on_true evaluates to False then on_false is returned instead of on_true. If you want this behavior the method is OK, otherwise use this:  {True: on_true, False: on_false}[cond is True] # is True, not == True   which can be wrapped by:  def q(cond, on_true, on_false)     return {True: on_true, False: on_false}[cond is True]   and used this way:  q(cond, on_true, on_false)   It is compatible with all Python versions.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "40", "A_Content": "  Ternary Operator in different programming Languages  Here I just try to show some important difference in ternary operator between a couple of programming languages.     Ternary Operator in Javascript   var a = true ? 1 : 0; # 1 var b = false ? 1 : 0; # 0      Ternary Operator in Ruby   a = true ? 1 : 0 # 1 b = false ? 1 : 0 # 0      Ternary operator in Scala   val a = true ? 1 | 0 # 1 val b = false ? 1 | 0 # 0      Ternary operator in R programming   a <- if (TRUE) 1 else 0 # 1 b <- if (FALSE) 1 else 0 # 0      Ternary operator in Python   a = 1 if True else 0 # 1 b = 1 if False else 0 # 0   Now you can see the beauty of python language. its highly readable and maintainable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "31", "A_Content": "  You might often find  cond and on_true or on_false   but this lead to problem when on_true == 0  >>> x = 0 >>> print x == 0 and 0 or 1  1 >>> x = 1 >>> print x == 0 and 0 or 1  1   where you would expect for a  normal ternary operator this result  >>> x = 0 >>> print 0 if x == 0 else 1  0 >>> x = 1 >>> print 0 if x == 0 else 1  1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "28", "A_Content": "  Absolutely, and it is incredibly easy to understand.   general syntax : first_expression if bool_expression_is_true else second_expression  Example: x= 3 if 3 > 2 else 4  # assigns 3 to x if the boolean expression evaluates to true or 4 if it is false      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "21", "A_Content": "     Does Python have a ternary conditional operator?   Yes. From the grammar file:  test: or_test ['if' or_test 'else' test] | lambdef   The part of interest is:  or_test ['if' or_test 'else' test]   So, a ternary conditional operation is of the form:  expression1 if expression2 else expression3   expression3 will be lazily evaluated (that is, evaluated only if expression2 is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.)  expression1 if expression2 else expression3 if expression4 else expression5 # and so on   A note on usage:  Note that every if must be followed with an else. People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else:  [expression1 if expression2 for element in iterable] #                          ^-- need an else here   which raises a SyntaxError: invalid syntax. So the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use expression2 as a filter - notes that the following is legal Python:  [expression1 for element in iterable if expression2]   expression2 works as a filter for the list comprehension, and is not a ternary conditional operator.  Alternative syntax for a more narrow case:  You may find it somewhat painful to write the following:  expression1 if expression1 else expression2   expression1 will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use or's shortcutting behavior:  expression1 or expression2   which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "14", "A_Content": "  Simulating the python ternary operator.  For example  a, b, x, y = 1, 2, 'a greather than b', 'b greater than a' result = (lambda:y, lambda:x)[a > b]()   output:  'b greater than a'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "9", "A_Content": "  you can do this :-  [condition] and [expression_1] or [expression_2] ;  Example:-  print(number%2 and \"odd\" or \"even\")  This would print \"odd\" if the number is odd or \"even\" if the number is even.    The result :-  If condition is true exp_1 is executed else exp_2 is executed.  Note :- 0 , None , False , emptylist , emptyString evaluates as False. And any data other than 0 evaluates to True.  Here's how it works:  if the condition [condition] becomes \"True\" then , expression_1 will be evaluated but not expression_2 . If we \"and\" something with 0 (zero) , the result will always to be fasle .So in the below statement ,  0 and exp   The expression exp won't be evaluated at all since \"and\" with 0 will always evaluate to zero and there is no need to evaluate the expression . This is how the compiler itself works , in all languages.  In   1 or exp   the expression exp won't be evaluated at all since \"or\" with 1 will always be 1. So it won't bother to evaluate the expression exp since the result will be 1 anyway . (compiler optimization methods).   But in case of   True and exp1 or exp2   The second expression exp2 won't be evaluated since True and exp1 would be True when exp1 isn't false .  Similarly in   False and exp1 or exp2   The expression exp1 won't be evaluated since False is equivalent to writing 0 and doing \"and\" with 0 would be 0 itself but after exp1 since \"or\" is used, it will evaluate the expression exp2 after \"or\" .    Note:- This kind of branching using \"or\" and \"and\" can only be used when the expression_1 doesn't have a Truth value of False (or 0 or None or emptylist [ ] or emptystring ' '.) since if expression_1 becomes False , then the expression_2 will be evaluated because of the presence \"or\" between exp_1 and exp_2.  In case you still want to make it work for all the cases regardless of what exp_1 and exp_2 truth values are, do this :-  [condition] and ([expression_1] or 1) or [expression_2] ;     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "8", "A_Content": "  In [1]: a = 1 if False else 0  In [2]: a Out[2]: 0  In [3]: b = 1 if True else 0  In [4]: b Out[4]: 1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "8", "A_Content": "  Ternary conditional operator simply allows testing a condition in a single line replacing the multiline if-else making the code compact.  Syntax :     [on_true] if [expression] else [on_false]    1- Simple Method to use ternary operator:  # Program to demonstrate conditional operator a, b = 10, 20 # Copy value of a in min if a < b else copy b min = a if a < b else b print(min)  # Output: 10   2- Direct Method of using tuples, Dictionary, and lambda:  # Python program to demonstrate ternary operator a, b = 10, 20 # Use tuple for selecting an item print( (b, a) [a < b] ) # Use Dictionary for selecting an item print({True: a, False: b} [a < b]) # lamda is more efficient than above two methods # because in lambda  we are assure that # only one expression will be evaluated unlike in # tuple and Dictionary print((lambda: b, lambda: a)[a < b]()) # in output you should see three 10   3- Ternary operator can be written as nested if-else:  # Python program to demonstrate nested ternary operator a, b = 10, 20 print (\"Both a and b are equal\" if a == b else \"a is greater than b\"         if a > b else \"b is greater than a\")   Above approach can be written as:  # Python program to demonstrate nested ternary operator a, b = 10, 20 if a != b:     if a > b:         print(\"a is greater than b\")     else:         print(\"b is greater than a\") else:     print(\"Both a and b are equal\")  # Output: b is greater than a      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "12382", "A_Content": "  To understand what yield does, you must understand what generators are. And before generators come iterables.  Iterables  When you create a list, you can read its items one by one. Reading its items one by one is called iteration:  >>> mylist = [1, 2, 3] >>> for i in mylist: ...    print(i) 1 2 3   mylist is an iterable. When you use a list comprehension, you create a list, and so an iterable:  >>> mylist = [x*x for x in range(3)] >>> for i in mylist: ...    print(i) 0 1 4   Everything you can use \"for... in...\" on is an iterable; lists, strings, files...  These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.  Generators  Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly:  >>> mygenerator = (x*x for x in range(3)) >>> for i in mygenerator: ...    print(i) 0 1 4   It is just the same except you used () instead of []. BUT, you cannot perform for i in mygenerator a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one.  Yield  yield is a keyword that is used like return, except the function will return a generator.  >>> def createGenerator(): ...    mylist = range(3) ...    for i in mylist: ...        yield i*i ... >>> mygenerator = createGenerator() # create a generator >>> print(mygenerator) # mygenerator is an object! <generator object createGenerator at 0xb7555c34> >>> for i in mygenerator: ...     print(i) 0 1 4   Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.  To master yield, you must understand that when you call the function, the code you have written in the function body does not run. The function only returns the generator object, this is a bit tricky :-)  Then, your code will be run each time the for uses the generator.  Now the hard part:  The first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it'll return the first value of the loop. Then, each other call will run the loop you have written in the function one more time, and return the next value, until there is no value to return.  The generator is considered empty once the function runs, but does not hit yield anymore. It can be because the loop had come to an end, or because you do not satisfy an \"if/else\" anymore.    Your code explained  Generator:  # Here you create the method of the node object that will return the generator def _get_child_candidates(self, distance, min_dist, max_dist):      # Here is the code that will be called each time you use the generator object:      # If there is still a child of the node object on its left     # AND if distance is ok, return the next child     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild      # If there is still a child of the node object on its right     # AND if distance is ok, return the next child     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild      # If the function arrives here, the generator will be considered empty     # there is no more than two values: the left and the right children   Caller:  # Create an empty list and a list with the current object reference result, candidates = list(), [self]  # Loop on candidates (they contain only one element at the beginning) while candidates:      # Get the last candidate and remove it from the list     node = candidates.pop()      # Get the distance between obj and the candidate     distance = node._get_dist(obj)      # If distance is ok, then you can fill the result     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)      # Add the children of the candidate in the candidates list     # so the loop will keep running until it will have looked     # at all the children of the children of the children, etc. of the candidate     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))  return result   This code contains several smart parts:   The loop iterates on a list, but the list expands while the loop is being iterated :-) It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) exhausts all the values of the generator, but while keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node. The extend() method is a list object method that expects an iterable and adds its values to the list.   Usually we pass a list to it:  >>> a = [1, 2] >>> b = [3, 4] >>> a.extend(b) >>> print(a) [1, 2, 3, 4]   But in your code it gets a generator, which is good because:   You don't need to read the values twice. You may have a lot of children and you don't want them all stored in memory.   And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples and generators! This is called duck typing and is one of the reason why Python is so cool. But this is another story, for another question...  You can stop here, or read a little bit to see an advanced use of a generator:  Controlling a generator exhaustion  >>> class Bank(): # Let's create a bank, building ATMs ...    crisis = False ...    def create_atm(self): ...        while not self.crisis: ...            yield \"$100\" >>> hsbc = Bank() # When everything's ok the ATM gives you as much as you want >>> corner_street_atm = hsbc.create_atm() >>> print(corner_street_atm.next()) $100 >>> print(corner_street_atm.next()) $100 >>> print([corner_street_atm.next() for cash in range(5)]) ['$100', '$100', '$100', '$100', '$100'] >>> hsbc.crisis = True # Crisis is coming, no more money! >>> print(corner_street_atm.next()) <type 'exceptions.StopIteration'> >>> wall_street_atm = hsbc.create_atm() # It's even true for new ATMs >>> print(wall_street_atm.next()) <type 'exceptions.StopIteration'> >>> hsbc.crisis = False # The trouble is, even post-crisis the ATM remains empty >>> print(corner_street_atm.next()) <type 'exceptions.StopIteration'> >>> brand_new_atm = hsbc.create_atm() # Build a new one to get back in business >>> for cash in brand_new_atm: ...    print cash $100 $100 $100 $100 $100 $100 $100 $100 $100 ...   Note: For Python 3, useprint(corner_street_atm.__next__()) or print(next(corner_street_atm))  It can be useful for various things like controlling access to a resource.  Itertools, your best friend  The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator? Chain two generators? Group values in a nested list with a one-liner? Map / Zip without creating another list?  Then just import itertools.  An example? Let's see the possible orders of arrival for a four-horse race:  >>> horses = [1, 2, 3, 4] >>> races = itertools.permutations(horses) >>> print(races) <itertools.permutations object at 0xb754f1dc> >>> print(list(itertools.permutations(horses))) [(1, 2, 3, 4),  (1, 2, 4, 3),  (1, 3, 2, 4),  (1, 3, 4, 2),  (1, 4, 2, 3),  (1, 4, 3, 2),  (2, 1, 3, 4),  (2, 1, 4, 3),  (2, 3, 1, 4),  (2, 3, 4, 1),  (2, 4, 1, 3),  (2, 4, 3, 1),  (3, 1, 2, 4),  (3, 1, 4, 2),  (3, 2, 1, 4),  (3, 2, 4, 1),  (3, 4, 1, 2),  (3, 4, 2, 1),  (4, 1, 2, 3),  (4, 1, 3, 2),  (4, 2, 1, 3),  (4, 2, 3, 1),  (4, 3, 1, 2),  (4, 3, 2, 1)]   Understanding the inner mechanisms of iteration  Iteration is a process implying iterables (implementing the __iter__() method) and iterators (implementing the __next__() method). Iterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.  There is more about it in this article about how for loops work.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "7", "A_Content": "  More a tip than an answer (don't need to repeat the obvious for the hundreth time), but I sometimes use it as a oneliner shortcut in such constructs:  if conditionX:     print('yes') else:     print('nah')   , becomes:  print('yes') if conditionX else print('nah')   Some (many :) may frown upon it as unpythonic (even, ruby-ish :), but I personally find it more natural - i.e. how you'd express it normally, plus a bit more visually appealing in large blocks of code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "7", "A_Content": "  Yes, you can use it that way :   is_fat = True state = \"fat\" if is_fat else \"not fat\"      Read more about ternary conditional operator      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "3", "A_Content": "  Yes.  >>> b = (True if 5 > 4 else False) >>> print b True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "1", "A_Content": "  Yes:  Let\u2019s say you want to give variable x some value if some bool is true and likewise   X = 5 if something else x = 10  X = [some value] if [if this is true first value evaluates] else [other value evaluates]     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "0", "A_Content": "  There is a ternary option as stated in other answers, but you can also simulate it using \"or\" if you are checking against a boolean or None value:  >>> a = False >>> b = 5 >>> a or b 5  >>> a = None >>> a or b 5      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "0", "A_Content": "  if variable is defined and you want to check if it has value you can just a or b  def test(myvar=None):     # shorter than: print myvar if myvar else \"no Input\"     print myvar or \"no Input\"  test() test([]) test(False) test('hello') test(['Hello']) test(True)   will output  no Input no Input no Input hello ['Hello'] True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator", "Language": "Python", "Q_Title": "Does Python have a ternary conditional operator?", "Q_Votes": "4534", "Q_Content": "    If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?       ", "Tags": ["python", "operators", "ternary-operator", "conditional-operator", "python-2.5"], "A_Votes": "0", "A_Content": "  Syntax: The Ternary operator will be given as:  [on_true] if [expression] else [on_false]   e.g  x, y = 25, 50 big = x if x < y else y print(big)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "1661", "A_Content": "  Shortcut to Grokking yield  When you see a function with yield statements, apply this easy trick to understand what will happen:   Insert a line result = [] at the start of the function. Replace each yield expr with result.append(expr). Insert a line return result at the bottom of the function. Yay - no more yield statements! Read and figure out code. Compare function to original definition.   This trick may give you an idea of the logic behind the function, but what actually happens with yield is significantly different that what happens in the list based approach. In many cases the yield approach will be a lot more memory efficient and faster too. In other cases this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more...  Don't confuse your Iterables, Iterators and Generators  First, the iterator protocol - when you write  for x in mylist:     ...loop body...   Python performs the following two steps:   Gets an iterator for mylist:  Call iter(mylist) -> this returns an object with a next() method (or __next__() in Python 3).  [This is the step most people forget to tell you about] Uses the iterator to loop over items:  Keep calling the next() method on the iterator returned from step 1. The return value from next() is assigned to x and the loop body is executed. If an exception StopIteration is raised from within next(), it means there are no more values in the iterator and the loop is exited.   The truth is Python performs the above two steps anytime it wants to loop over the contents of an object - so it could be a for loop, but it could also be code like otherlist.extend(mylist) (where otherlist is a Python list).  Here mylist is an iterable because it implements the iterator protocol. In a user defined class, you can implement the __iter__() method to make instances of your class iterable. This method should return an iterator. An iterator is an object with a next() method. It is possible to implement both __iter__() and next() on the same class, and have __iter__() return self. This will work for simple cases, but not when you want two iterators looping over the same object at the same time.  So that's the iterator protocol, many objects implement this protocol:   Built-in lists, dictionaries, tuples, sets, files. User defined classes that implement __iter__(). Generators.   Note that a for loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls next(). Built-in lists return their items one by one, dictionaries return the keys one by one, files return the lines one by one, etc. And generators return... well that's where yield comes in:  def f123():     yield 1     yield 2     yield 3  for item in f123():     print item   Instead of yield statements, if you had three return statements in f123() only the first would get executed, and the function would exit. But f123() is no ordinary function. When f123() is called, it does not return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the for loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the yield it previously returned from, executes the next line of code, in this case a yield statement, and returns that as the next item. This happens until the function exits, at which point the generator raises StopIteration, and the loop exits.   So the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing __iter__() and next() methods to keep the for loop happy. At the other end however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode.  Why Use Generators?  Usually you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class SomethingIter that keeps state in instance members and performs the next logical step in it's next() (or __next__() in Python 3) method. Depending on the logic, the code inside the next() method may end up looking very complex and be prone to bugs. Here generators provide a clean and easy solution.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "409", "A_Content": "  Think of it this way:  An iterator is just a fancy sounding term for an object that has a next() method.  So a yield-ed function ends up being something like this:  Original version:  def some_function():     for i in xrange(4):         yield i  for i in some_function():     print i   This is basically what the Python interpreter does with the above code:  class it:     def __init__(self):         # Start at -1 so that we get 0 when we add 1 below.         self.count = -1      # The __iter__ method will be called once by the 'for' loop.     # The rest of the magic happens on the object returned by this method.     # In this case it is the object itself.     def __iter__(self):         return self      # The next method will be called repeatedly by the 'for' loop     # until it raises StopIteration.     def next(self):         self.count += 1         if self.count < 4:             return self.count         else:             # A StopIteration exception is raised             # to signal that the iterator is done.             # This is caught implicitly by the 'for' loop.             raise StopIteration  def some_func():     return it()  for i in some_func():     print i   For more insight as to what's happening behind the scenes, the for loop can be rewritten to this:  iterator = some_func() try:     while 1:         print iterator.next() except StopIteration:     pass   Does that make more sense or just confuse you more?  :)  I should note that this is an oversimplification for illustrative purposes. :)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "354", "A_Content": "  The yield keyword is reduced to two simple facts:   If the compiler detects the yield keyword anywhere inside a function, that function no longer returns via the return statement. Instead, it immediately returns a lazy \"pending list\" object called a generator A generator is iterable. What is an iterable? It's anything like a list or set or range or dict-view, with a built-in protocol for visiting each element in a certain order.   In a nutshell: a generator is a lazy, incrementally-pending list, and yield statements allow you to use function notation to program the list values the generator should incrementally spit out.  generator = myYieldingFunction(...) x = list(generator)     generator        v [x[0], ..., ???]           generator              v [x[0], x[1], ..., ???]                 generator                    v [x[0], x[1], x[2], ..., ???]                         StopIteration exception [x[0], x[1], x[2]]     done  list==[x[0], x[1], x[2]]     Example  Let's define a function makeRange that's just like Python's range. Calling makeRange(n) RETURNS A GENERATOR:  def makeRange(n):     # return 0,1,2,...,n-1     i = 0     while i < n:         yield i         i += 1  >>> makeRange(5) <generator object makeRange at 0x19e4aa0>   To force the generator to immediately return its pending values, you can pass it into list() (just like you could any iterable):  >>> list(makeRange(5)) [0, 1, 2, 3, 4]     Comparing example to \"just returning a list\"  The above example can be thought of as merely creating a list which you append to and return:  # list-version                   #  # generator-version def makeRange(n):                #  def makeRange(n):     \"\"\"return [0,1,2,...,n-1]\"\"\" #~     \"\"\"return 0,1,2,...,n-1\"\"\"     TO_RETURN = []               #>     i = 0                        #      i = 0     while i < n:                 #      while i < n:         TO_RETURN += [i]         #~         yield i         i += 1                   #          i += 1  ## indented     return TO_RETURN             #>  >>> makeRange(5) [0, 1, 2, 3, 4]   There is one major difference, though; see the last section.    How you might use generators  An iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so:  #                   _ITERABLE_ >>> [x+10 for x in makeRange(5)] [10, 11, 12, 13, 14]   To get a better feel for generators, you can play around with the itertools module (be sure to use chain.from_iterable rather than chain when warranted). For example, you might even use generators to implement infinitely-long lazy lists like itertools.count(). You could implement your own def enumerate(iterable): zip(count(), iterable), or alternatively do so with the yield keyword in a while-loop.  Please note: generators can actually be used for many more things, such as implementing coroutines or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find.    Behind the scenes  This is how the \"Python iteration protocol\" works. That is, what is going on when you do list(makeRange(5)). This is what I describe earlier as a \"lazy, incremental list\".  >>> x=iter(range(5)) >>> next(x) 0 >>> next(x) 1 >>> next(x) 2 >>> next(x) 3 >>> next(x) 4 >>> next(x) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> StopIteration   The built-in function next() just calls the objects .next() function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the next() function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that...    Minutiae  Normally, most people would not care about the following distinctions and probably want to stop reading here.  In Python-speak, an iterable is any object which \"understands the concept of a for-loop\" like a list [1,2,3], and an iterator is a specific instance of the requested for-loop like [1,2,3].__iter__(). A generator is exactly the same as any iterator, except for the way it was written (with function syntax).  When you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself.  Thus, in the unlikely event that you are failing to do something like this...  > x = myRange(5) > list(x) [0, 1, 2, 3, 4] > list(x) []   ... then remember that a generator is an iterator; that is, it is one-time-use. If you want to reuse it, you should call myRange(...) again. If you need to use the result twice, convert the result to a list and store it in a variable x = list(myRange(5)). Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use itertools.tee if absolutely necessary, since the copyable iterator Python PEP standards proposal has been deferred.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "262", "A_Content": "     What does the yield keyword do in Python?   Answer Outline/Summary   A function with yield, when called, returns a Generator. Generators are iterators because they implement the iterator protocol, so you can iterate over them. A generator can also be sent information, making it conceptually a coroutine. In Python 3, you can delegate from one generator to another in both directions with yield from. (Appendix critiques a couple of answers, including the top one, and discusses the use of return in a generator.)   Generators:  yield is only legal inside of a function definition, and the inclusion of yield in a function definition makes it return a generator.  The idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is frozen at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield.  yield provides an  easy way of implementing the iterator protocol, defined by the following two methods:  __iter__ and next (Python 2) or __next__ (Python 3).  Both of those methods make an object an iterator that you could type-check with the Iterator Abstract Base  Class from the collections module.  >>> def func(): ...     yield 'I am' ...     yield 'a generator!' ...  >>> type(func)                 # A function with yield is still a function <type 'function'> >>> gen = func() >>> type(gen)                  # but it returns a generator <type 'generator'> >>> hasattr(gen, '__iter__')   # that's an iterable True >>> hasattr(gen, 'next')       # and with .next (.__next__ in Python 3) True                           # implements the iterator protocol.   The generator type is a sub-type of iterator:  >>> import collections, types >>> issubclass(types.GeneratorType, collections.Iterator) True   And if necessary, we can type-check like this:  >>> isinstance(gen, types.GeneratorType) True >>> isinstance(gen, collections.Iterator) True   A feature of an Iterator is that once exhausted, you can't reuse or reset it:  >>> list(gen) ['I am', 'a generator!'] >>> list(gen) []   You'll have to make another if you want to use its functionality again (see footnote 2):  >>> list(func()) ['I am', 'a generator!']   One can yield data programmatically, for example:  def func(an_iterable):     for item in an_iterable:         yield item   The above simple generator is also equivalent to the below - as of Python 3.3 (and not available in Python 2), you can use yield from:  def func(an_iterable):     yield from an_iterable   However, yield from also allows for delegation to subgenerators,  which will be explained in the following section on cooperative delegation with sub-coroutines.  Coroutines:  yield forms an expression that allows data to be sent into the generator (see footnote 3)  Here is an example, take note of the received variable, which will point to the data that is sent to the generator:  def bank_account(deposited, interest_rate):     while True:         calculated_interest = interest_rate * deposited          received = yield calculated_interest         if received:             deposited += received   >>> my_account = bank_account(1000, .05)   First, we must queue up the generator with the builtin function, next. It will  call the appropriate next or __next__ method, depending on the version of Python you are using:  >>> first_year_interest = next(my_account) >>> first_year_interest 50.0   And now we can send data into the generator. (Sending None is  the same as calling next.) :  >>> next_year_interest = my_account.send(first_year_interest + 1000) >>> next_year_interest 102.5   Cooperative Delegation to Sub-Coroutine with yield from  Now, recall that yield from is available in Python 3. This allows us to delegate coroutines to a subcoroutine:  def money_manager(expected_rate):     under_management = yield     # must receive deposited value     while True:         try:             additional_investment = yield expected_rate * under_management              if additional_investment:                 under_management += additional_investment         except GeneratorExit:             '''TODO: write function to send unclaimed funds to state'''         finally:             '''TODO: write function to mail tax info to client'''   def investment_account(deposited, manager):     '''very simple model of an investment account that delegates to a manager'''     next(manager) # must queue up manager     manager.send(deposited)     while True:         try:             yield from manager         except GeneratorExit:             return manager.close()   And now we can delegate functionality to a sub-generator and it can be used by a generator just as above:  >>> my_manager = money_manager(.06) >>> my_account = investment_account(1000, my_manager) >>> first_year_return = next(my_account) >>> first_year_return 60.0 >>> next_year_return = my_account.send(first_year_return + 1000) >>> next_year_return 123.6   You can read more about the precise semantics of yield from in PEP 380.  Other Methods: close and throw  The close method raises GeneratorExit at the point the function  execution was frozen. This will also be called by __del__ so you  can put any cleanup code where you handle the GeneratorExit:  >>> my_account.close()   You can also throw an exception which can be handled in the generator or propagated back to the user:  >>> import sys >>> try: ...     raise ValueError ... except: ...     my_manager.throw(*sys.exc_info()) ...  Traceback (most recent call last):   File \"<stdin>\", line 4, in <module>   File \"<stdin>\", line 2, in <module> ValueError   Conclusion  I believe I have covered all aspects of the following question:     What does the yield keyword do in Python?   It turns out that yield does a lot. I'm sure I could add even more  thorough examples to this. If you want more or have some constructive criticism, let me know by commenting below.    Appendix:  Critique of the Top/Accepted Answer**   It is confused on what makes an iterable, just using a list as an example. See my references above, but in summary: an iterable has an __iter__ method returning an iterator. An iterator provides a .next (Python 2 or .__next__ (Python 3) method, which is implicitly called by for loops until it raises StopIteration, and once it does, it will continue to do so. It then uses a generator expression to describe what a generator is. Since a generator is simply a convenient way to create an iterator, it only confuses the matter, and we still have not yet gotten to the yield part. In Controlling a generator exhaustion he calls the .next method, when instead he should use the builtin function, next. It would be an appropriate layer of indirection, because his code does not work in Python 3. Itertools? This was not relevant to what yield does at all. No discussion of the methods that yield provides along with the new functionality yield from in Python 3. The top/accepted answer is a very incomplete answer.   Critique of answer suggesting yield in a generator expression or comprehension.  The grammar currently allows any expression in a list comprehension.   expr_stmt: testlist_star_expr (annassign | augassign (yield_expr|testlist) |                      ('=' (yield_expr|testlist_star_expr))*) ... yield_expr: 'yield' [yield_arg] yield_arg: 'from' test | testlist   Since yield is an expression, it has been touted by some as interesting to use it in comprehensions or generator expression - in spite of citing no particularly good use-case.  The CPython core developers are discussing deprecating its allowance. Here's a relevant post from the mailing list:     On 30 January 2017 at 19:05, Brett Cannon  wrote:           On Sun, 29 Jan 2017 at 16:39 Craig Rodrigues  wrote:                 I'm OK with either approach.  Leaving things the way they are in Python 3       is no good, IMHO.               My vote is it be a SyntaxError since you're not getting what you expect from     the syntax.         I'd agree that's a sensible place for us to end up, as any code   relying on the current behaviour is really too clever to be   maintainable.      In terms of getting there, we'll likely want:         SyntaxWarning or DeprecationWarning in 3.7   Py3k warning in 2.7.x   SyntaxError in 3.8         Cheers, Nick.      --  Nick Coghlan   |   ncoghlan at gmail.com   |   Brisbane, Australia   Further, there is an outstanding issue (10544) which seems to be pointing in the direction of this never being a good idea (PyPy, a Python implementation written in Python, is already raising syntax warnings.)  Bottom line, until the developers of CPython tell us otherwise: Don't put yield in a generator expression or comprehension.  The return statement in a generator  In Python 2:     In a generator function, the return statement is not allowed to include an expression_list. In that context, a bare return indicates that the generator is done and will cause StopIteration to be raised.   An expression_list is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with return, but you can't return a value.  In Python 3:      In a generator function, the return statement indicates that the generator is done and will cause StopIteration to be raised. The returned value (if any) is used as an argument to construct StopIteration and becomes the StopIteration.value attribute.   Footnotes   The languages CLU, Sather, and Icon were referenced in the proposal to introduce the concept of generators to Python. The general idea is that a function can maintain internal state and yield intermediate  data points on demand by the user. This promised to be superior in performance  to other approaches, including Python threading, which isn't even available on some systems.  This means, for example, that xrange objects (range in Python 3) aren't Iterators, even though they are iterable, because they can be reused. Like lists, their __iter__ methods return iterator objects.   yield was originally introduced as a statement, meaning that it  could only appear at the beginning of a line in a code block.  Now yield creates a yield expression.  https://docs.python.org/2/reference/simple_stmts.html#grammar-token-yield_stmt  This change was proposed to allow a user to send data into the generator just as one might receive it. To send data, one must be able to assign it to something, and for that, a statement just won't work.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "235", "A_Content": "  yield is just like return - it returns whatever you tell it to (as a generator). The difference is that the next time you call the generator, execution starts from the last call to the yield statement. Unlike return, the stack frame is not cleaned up when a yield occurs, however control is transferred back to the caller, so its state will resume the next time the function.  In the case of your code, the function get_child_candidates is acting like an iterator so that when you extend your list, it adds one element at a time to the new list.  list.extend calls an iterator until it's exhausted. In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "186", "A_Content": "  There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this:  def fib():     last, cur = 0, 1     while True:          yield cur         last, cur = cur, last + cur   Then I can use it in other code like this:  for f in fib():     if some_condition: break     coolfuncs(f);   It really helps simplify some problems, and makes some things easier to work with.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "156", "A_Content": "  For those who prefer a minimal working example, meditate on this interactive Python session:  >>> def f(): ...   yield 1 ...   yield 2 ...   yield 3 ...  >>> g = f() >>> for i in g: ...   print i ...  1 2 3 >>> for i in g: ...   print i ...  >>> # Note that this time nothing was printed      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "134", "A_Content": "  Yield gives you a generator.   def get_odd_numbers(i):     return range(1, i, 2) def yield_odd_numbers(i):     for x in range(1, i, 2):        yield x foo = get_odd_numbers(10) bar = yield_odd_numbers(10) foo [1, 3, 5, 7, 9] bar <generator object yield_odd_numbers at 0x1029c6f50> bar.next() 1 bar.next() 3 bar.next() 5   As you can see, in the first case foo holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called. In the second case, bar just gives you a generator. A generator is an iterable--which means you can use it in a for loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through. Again, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :)  This is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "126", "A_Content": "  It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as C#'s iterator blocks if you're familiar with those.  There's an IBM article which explains it reasonably well (for Python) as far as I can see.  The key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values - as if the generator method was paused. Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "123", "A_Content": "  There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators. Here is the programming language theory answer:  The yield statement in Python returns a generator. A generator in Python is a function that returns continuations (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on).  Continuations in programming languages theory are a much more fundamental kind of computation, but they are not often used, because they are extremely hard to reason about and also very difficult to implement. But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state, the current values of variables, the operations that have yet to be performed, and so on, are saved. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out.  Continuations, in this more general form, can be implemented in two ways. In the call/cc way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored.  In continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows:  def save_file(filename):   def write_file_continuation():     write_stuff_to_file(filename)    check_if_file_exists_and_user_wants_to_overwrite(write_file_continuation)   In this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger.)  The rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read.    Now let's talk about generators in Python. Generators are a specific subtype of continuation. Whereas continuations are able in general to save the state of a computation (i.e., the program's call stack), generators are only able to save the state of iteration over an iterator. Although, this definition is slightly misleading for certain use cases of generators. For instance:  def f():   while True:     yield 4   This is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e., for x in collection: do_something(x)). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration.  To reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand this page about continuations and call/cc).  But you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style:  Whenever yield is called, it tells the function to return a continuation.  When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode (i.e., not pseudocode, but not code) the generator's next method is basically as follows:  class Generator():   def __init__(self,iterable,generatorfun):     self.next_continuation = lambda:generatorfun(iterable)    def next(self):     value, next_continuation = self.next_continuation()     self.next_continuation = next_continuation     return value   where the yield keyword is actually syntactic sugar for the real generator function, basically something like:  def generatorfun(iterable):   if len(iterable) == 0:     raise StopIteration   else:     return (iterable[0], lambda:generatorfun(iterable[1:]))   Remember that this is just pseudocode and the actual implementation of generators in Python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the yield keyword.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "121", "A_Content": "  TL;DR  Instead of this:  def squares_list(n):     the_list = []                         # Replace     for x in range(n):         y = x * x         the_list.append(y)                # these     return the_list                       # lines   do this:  def squares_the_yield_way(n):     for x in range(n):         y = x * x         yield y                           # with this one.   Whenever you find yourself building a list from scratch, yield each piece instead.   This was my first \"aha\" moment with yield.    yield is a sugary way to say      build a series of stuff   Same behavior:  >>> for square in squares_list(4): ...     print(square) ... 0 1 4 9 >>> for square in squares_the_yield_way(4): ...     print(square) ... 0 1 4 9   Different behavior:  Yield is single-pass: you can only iterate through once. When a function has a yield in it we call it a generator function. And an iterator is what it returns. That's revealing. We lose the convenience of a container, but gain the power of an arbitrarily long series.   Yield is lazy, it puts off computation. A function with a yield in it doesn't actually execute at all when you call it. The iterator object it returns uses magic to maintain the function's internal context. Each time you call next() on the iterator (this happens in a for-loop) execution inches forward to the next yield. (return raises StopIteration and ends the series.)  Yield is versatile. It can do infinite loops:  >>> def squares_all_of_them(): ...     x = 0 ...     while True: ...         yield x * x ...         x += 1 ... >>> squares = squares_all_of_them() >>> for _ in range(4): ...     print(next(squares)) ... 0 1 4 9     If you need multiple passes and the series isn't too long, just call list() on it:  >>> list(squares_the_yield_way(4)) [0, 1, 4, 9]     Brilliant choice of the word yield because both meanings apply:     yield \u2014 produce or provide (as in agriculture)   ...provide the next data in the series.     yield \u2014 give way or relinquish (as in political power)   ...relinquish CPU execution until the iterator advances.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "109", "A_Content": "  Here is an example in plain language. I will provide a correspondence between high-level human concepts to low-level Python concepts.  I want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following:   I call you and tell you that I want a sequence of numbers which is produced in a specific way, and I let you know what the algorithm is.  This step corresponds to defining the generator function, i.e. the function containing a yield. Sometime later, I tell you, \"OK, get ready to tell me the sequence of numbers\".  This step corresponds to calling the generator function which returns a generator object. Note that you don't tell me any numbers yet; you just grab your paper and pencil. I ask you, \"tell me the next number\", and you tell me the first number; after that, you wait for me to ask you for the next number. It's your job to remember where you were, what numbers you have already said, and what is the next number. I don't care about the details.  This step corresponds to calling .next() on the generator object. \u2026 repeat previous step, until\u2026 eventually, you might come to an end. You don't tell me a number; you just shout, \"hold your horses! I'm done! No more numbers!\"  This step corresponds to the generator object ending its job, and raising a StopIteration exception The generator function does not need to raise the exception. It's raised automatically when the function ends or issues a return.   This is what a generator does (a function that contains a yield); it starts executing, pauses whenever it does a yield, and when asked for a .next() value it continues from the point it was last. It fits perfectly by design with the iterator protocol of Python, which describes how to sequentially request values.  The most famous user of the iterator protocol is the for command in Python. So, whenever you do a:  for item in sequence:   it doesn't matter if sequence is a list, a string, a dictionary or a generator object like described above; the result is the same: you read items off a sequence one by one.  Note that defining a function which contains a yield keyword is not the only way to create a generator; it's just the easiest way to create one.  For more accurate information, read about iterator types, the yield statement and generators in the Python documentation.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "97", "A_Content": "  While a lot of answers show why you'd use a yield to create a generator, there are more uses for yield.  It's quite easy to make a coroutine, which enables the passing of information between two blocks of code.  I won't repeat any of the fine examples that have already been given about using yield to create a generator.  To help understand what a yield does in the following code, you can use your finger to trace the cycle through any code that has a yield.  Every time your finger hits the yield, you have to wait for a next or a send to be entered.  When a next is called, you trace through the code until you hit the yield\u2026 the code on the right of the yield is evaluated and returned to the caller\u2026 then you wait.  When next is called again, you perform another loop through the code.  However, you'll note that in a coroutine, yield can also be used with a send\u2026 which will send a value from the caller into the yielding function. If a send is given, then yield receives the value sent, and spits it out the left hand side\u2026 then the trace through the code progresses until you hit the yield again (returning the value at the end, as if next was called).  For example:  >>> def coroutine(): ...     i = -1 ...     while True: ...         i += 1 ...         val = (yield i) ...         print(\"Received %s\" % val) ... >>> sequence = coroutine() >>> sequence.next() 0 >>> sequence.next() Received None 1 >>> sequence.send('hello') Received hello 2 >>> sequence.close()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "86", "A_Content": "  There is another yield use and meaning (since Python 3.3):  yield from <expr>   From PEP 380 -- Syntax for Delegating to a Subgenerator:     A syntax is proposed for a generator to delegate part of its operations to another generator. This allows a section of code containing 'yield' to be factored out and placed in another generator. Additionally, the subgenerator is allowed to return with a value, and the value is made available to the delegating generator.      The new syntax also opens up some opportunities for optimisation when one generator re-yields values produced by another.   Moreover this will introduce (since Python 3.5):  async def new_coroutine(data):    ...    await blocking_action()   to avoid coroutines being confused with a regular generator (today yield is used in both).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "77", "A_Content": "  I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already.  Also, note that yield can be used in coroutines as the dual of their use in generator functions.  Although it isn't the same use as your code snippet, (yield) can be used as an expression in a function.  When a caller sends a value to the method using the send() method, then the coroutine will execute until the next (yield) statement is encountered.  Generators and coroutines are a cool way to set up data-flow type applications.  I thought it would be worthwhile knowing about the other use of the yield statement in functions.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "76", "A_Content": "  Here are some Python examples of how to actually implement generators as if Python did not provide syntactic sugar for them:  As a Python generator:  from itertools import islice  def fib_gen():     a, b = 1, 1     while True:         yield a         a, b = b, a + b  assert [1, 1, 2, 3, 5] == list(islice(fib_gen(), 5))   Using lexical closures instead of generators  def ftake(fnext, last):     return [fnext() for _ in xrange(last)]  def fib_gen2():     #funky scope due to python2.x workaround     #for python 3.x use nonlocal     def _():         _.a, _.b = _.b, _.a + _.b         return _.a     _.a, _.b = 0, 1     return _  assert [1,1,2,3,5] == ftake(fib_gen2(), 5)   Using object closures instead of generators (because ClosuresAndObjectsAreEquivalent)  class fib_gen3:     def __init__(self):         self.a, self.b = 1, 1      def __call__(self):         r = self.a         self.a, self.b = self.b, self.a + self.b         return r  assert [1,1,2,3,5] == ftake(fib_gen3(), 5)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "70", "A_Content": "  From a programming viewpoint, the iterators are implemented as thunks.  To implement iterators, generators, and thread pools for concurrent execution, etc. as thunks (also called anonymous functions), one uses messages sent to a closure object, which has a dispatcher, and the dispatcher answers to \"messages\".  http://en.wikipedia.org/wiki/Message_passing  \"next\" is a message sent to a closure, created by the \"iter\" call.  There are lots of ways to implement this computation. I used mutation, but it is easy to do it without mutation, by returning the current value and the next yielder.  Here is a demonstration which uses the structure of R6RS, but the semantics is absolutely identical to Python's. It's the same model of computation, and only a change in syntax is required to rewrite it in Python.   Welcome to Racket v6.5.0.3.  -> (define gen      (lambda (l)        (define yield          (lambda ()            (if (null? l)                'END                (let ((v (car l)))                  (set! l (cdr l))                  v))))        (lambda(m)          (case m            ('yield (yield))            ('init  (lambda (data)                      (set! l data)                      'OK)))))) -> (define stream (gen '(1 2 3))) -> (stream 'yield) 1 -> (stream 'yield) 2 -> (stream 'yield) 3 -> (stream 'yield) 'END -> ((stream 'init) '(a b)) 'OK -> (stream 'yield) 'a -> (stream 'yield) 'b -> (stream 'yield) 'END -> (stream 'yield) 'END ->       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "63", "A_Content": "  Here is a simple example:  def isPrimeNumber(n):     print \"isPrimeNumber({}) call\".format(n)     if n==1:         return False     for x in range(2,n):         if n % x == 0:             return False     return True  def primes (n=1):     while(True):         print \"loop step ---------------- {}\".format(n)         if isPrimeNumber(n): yield n         n += 1  for n in primes():     if n> 10:break     print \"wiriting result {}\".format(n)   Output:  loop step ---------------- 1 isPrimeNumber(1) call loop step ---------------- 2 isPrimeNumber(2) call loop step ---------------- 3 isPrimeNumber(3) call wiriting result 3 loop step ---------------- 4 isPrimeNumber(4) call loop step ---------------- 5 isPrimeNumber(5) call wiriting result 5 loop step ---------------- 6 isPrimeNumber(6) call loop step ---------------- 7 isPrimeNumber(7) call wiriting result 7 loop step ---------------- 8 isPrimeNumber(8) call loop step ---------------- 9 isPrimeNumber(9) call loop step ---------------- 10 isPrimeNumber(10) call loop step ---------------- 11 isPrimeNumber(11) call   I am not a Python developer, but it looks to me yield holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work.  It seems to be an interesting and nice ability :D     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "63", "A_Content": "  All great answers, however a bit difficult for newbies.  I assume you have learned the return statement.  As an analogy, return and yield are twins. return means 'return and stop' whereas 'yield` means 'return, but continue'        Try to get a num_list with return.      def num_list(n):     for i in range(n):         return i   Run it:  In [5]: num_list(3) Out[5]: 0   See, you get only a single number rather than a list of them. return never allows you prevail happily, just implements once and quit.        There comes yield      Replace return with yield:  In [10]: def num_list(n):     ...:     for i in range(n):     ...:         yield i     ...:  In [11]: num_list(3) Out[11]: <generator object num_list at 0x10327c990>  In [12]: list(num_list(3)) Out[12]: [0, 1, 2]   Now, you win to get all the numbers.  Comparing to return which runs once and stops, yield runs times you planed. You can interpret return as return one of them, and yield as return all of them. This is called iterable.        One more step we can rewrite yield statement with return      In [15]: def num_list(n):     ...:     result = []     ...:     for i in range(n):     ...:         result.append(i)     ...:     return result  In [16]: num_list(3) Out[16]: [0, 1, 2]   It's the core about yield.  The difference between a list return outputs and the object yield output is:  You will always get [0, 1, 2] from a list object but only could retrieve them from 'the object yield output' once. So, it has a new name generator object as displayed in Out[11]: <generator object num_list at 0x10327c990>.  In conclusion, as a metaphor to grok it:   return and yield are twins list and generator are twins      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "54", "A_Content": "  Here is a mental image of what yield does.  I like to think of a thread as having a stack (even when it's not implemented that way).  When a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again.  With a yield function, when its code begins to run (i.e. after the function is called, returning a generator object, whose next() method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the yield statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular yield statement).  So it's a kind of a frozen function that the generator is hanging onto.  When next() is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage.  Compare the following examples:  def normalFunction():     return     if False:         pass  def yielderFunction():     return     if False:         yield 12   When we call the second function, it behaves very differently to the first. The yield statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with.  >>> yielderFunction() <generator object yielderFunction at 0x07742D28>   Calling yielderFunction() doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the yielder prefix for readability.)  >>> gen = yielderFunction() >>> dir(gen) ['__class__',  ...  '__iter__',    #Returns gen itself, to make it work uniformly with containers  ...            #when given to a for loop. (Containers return an iterator instead.)  'close',  'gi_code',  'gi_frame',  'gi_running',  'next',        #The method that runs the function's body.  'send',  'throw']   The gi_code and gi_frame fields are where the frozen state is stored. Exploring them with dir(..), we can confirm that our mental model above is credible.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "42", "A_Content": "  Like every answer suggests, yield is used for creating a sequence generator. It's used for generating some sequence dynamically. For example, while reading a file line by line on a network, you can use the yield function as follows:  def getNextLines():    while con.isOpen():        yield con.read()   You can use it in your code as follows:  for line in getNextLines():     doSomeThing(line)   Execution Control Transfer gotcha  The execution control will be transferred from getNextLines() to the for loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time.  Thus in short, a function with the following code  def simpleYield():     yield \"first time\"     yield \"second time\"     yield \"third time\"     yield \"Now some useful value {}\".format(12)  for i in simpleYield():     print i   will print  \"first time\" \"second time\" \"third time\" \"Now some useful value 12\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "37", "A_Content": "  Yield is an object  A return in a function will return a single value.  If you want a function to return a huge set of values, use yield.  More importantly, yield is a barrier.     like barrier in the CUDA language, it will not transfer control until it gets   completed.   That is, it will run the code in your function from the beginning until it hits yield. Then, it\u2019ll return the first value of the loop.  Then, every other call will run the loop you have written in the function one more time, returning the next value until there isn't any value to return.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "36", "A_Content": "  In summary, the yield statement transforms your function into a factory that produces a special object called a generator which wraps around the body of your original function. When the generator is iterated, it executes your function  until it reaches the next yield then suspends execution and evaluates to the value passed to yield. It repeats this process on each iteration until the path of execution exits the function. For instance,  def simple_generator():     yield 'one'     yield 'two'     yield 'three'  for i in simple_generator():     print i   simply outputs  one two three   The power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculations  Say you wanted to create a your own range function that produces an iterable range of numbers, you could do it like so,  def myRangeNaive(i):     n = 0     range = []     while n < i:         range.append(n)         n = n + 1     return range   and use it like this;  for i in myRangeNaive(10):     print i   But this is inefficient because   You create an array that you only use once (this wastes memory) This code actually loops over that array twice! :(   Luckily Guido and his team were generous enough to develop generators so we could just do this;  def myRangeSmart(i):     n = 0     while n < i:        yield n        n = n + 1     return  for i in myRangeSmart(10):     print i   Now upon each iteration a function on the generator called next() executes the function until it either reaches a 'yield' statement in which it stops and  'yields' the value or reaches the end of the function. In this case on the first call, next() executes up to the yield statement and yield 'n', on the next call it will execute the  increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "34", "A_Content": "  yield is like a return element for a function. The difference is, that the yield element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling list(generator()).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "34", "A_Content": "  (My below answer only speaks from the perspective of using Python generator, not the underlying implementation of generator mechanism, which involves some tricks of stack and heap manipulation.)  When yield is used instead of a return in a python function, that function is turned into something special called generator function. That function will return an object of generator type. The yield keyword is a flag to notify the python compiler to treat such function specially. Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function can be thought of as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a StopIteration exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about generator but this one from the functional programming perspective is the most digestable.  (Now I want to talk about the rationale behind generator, and the iterator based on my own understanding. I hope this can help you grasp the essential motivation of iterator and generator. Such concept shows up in other languages as well such as C#.)  As I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this intuitive approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand. So instead of storing the data itself directly, why not store some kind of metadata indirectly, i.e. the logic how the data is computed.   There are 2 approaches to wrap such metadata.   The OO approach, we wrap the metadata as a class. This is the so-called iterator who implements the iterator protocol (i.e. the __next__(), and __iter__() methods). This is also the commonly seen iterator design pattern. The functional approach, we wrap the metadata as a function. This is the so-called generator function. But under the hood, the returned generator object still IS-A iterator because it also implements the iterator protocol.   Either way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "33", "A_Content": "  The yield keyword simply collects returning results. Think of yield like return +=     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "33", "A_Content": "  Many people use return rather than yield, but in some cases yield can be more efficient and easier to work with.  Here is an example which yield is definitely best for:     return (in function)   import random  def return_dates():     dates = [] # With 'return' you need to create a list then return it     for i in range(5):         date = random.choice([\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"])         dates.append(date)     return dates      yield (in function)   def yield_dates():     for i in range(5):         date = random.choice([\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"])         yield date # 'yield' makes a generator automatically which works                    # in a similar way. This is much more efficient.      Calling functions   dates_list = return_dates() print(dates_list) for i in dates_list:     print(i)  dates_generator = yield_dates() print(dates_generator) for i in dates_generator:     print(i)   Both functions do the same thing, but yield uses three lines instead of five and has one less variable to worry about.          This is the result from the code:        As you can see both functions do the same thing. The only difference is return_dates() gives a list and yield_dates() gives a generator.  A real life example would be something like reading a file line by line or if you just want to make a generator.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "29", "A_Content": "  Here's a simple yield based approach, to compute the fibonacci series, explained:  def fib(limit=50):     a, b = 0, 1     for i in range(limit):        yield b        a, b = b, a+b   When you enter this into your REPL and then try and call it, you'll get a mystifying result:  >>> fib() <generator object fib at 0x7fa38394e3b8>   This is because the presence of yield signaled to Python that you want to create a generator, that is, an object that generates values on demand.  So, how do you generate these values? This can either be done directly by using the built-in function next, or, indirectly by feeding it to a construct that consumes values.   Using the built-in next() function, you directly invoke .next/__next__, forcing the generator to produce a value:  >>> g = fib() >>> next(g) 1 >>> next(g) 1 >>> next(g) 2 >>> next(g) 3 >>> next(g) 5   Indirectly, if you provide fib to a for loop, a list initializer, a tuple initializer, or anything else that expects an object that generates/produces values, you'll \"consume\" the generator until no more values can be produced by it (and it returns):  results = [] for i in fib(30):       # consumes fib     results.append(i)  # can also be accomplished with results = list(fib(30)) # consumes fib   Similarly, with a tuple initializer:   >>> tuple(fib(5))       # consumes fib (1, 1, 2, 3, 5)   A generator differs from a function in the sense that it is lazy. It accomplishes this by maintaining it's local state and allowing you to resume whenever you need to.   When you first invoke fib by calling it:  f = fib()   Python compiles the function, encounters the yield keyword and simply returns a generator object back at you. Not very helpful it seems.   When you then request it generates the first value, directly or indirectly, it executes all statements that it finds, until it encounters a yield, it then yields back the value you supplied to yield and pauses. For an example that better demonstrates this, let's use some print calls (replace with print \"text\" if on Python 2):  def yielder(value):     \"\"\" This is an infinite generator. Only use next on it \"\"\"      while 1:         print(\"I'm going to generate the value for you\")         print(\"Then I'll pause for a while\")         yield value         print(\"Let's go through it again.\")   Now, enter in the REPL:  >>> gen = yielder(\"Hello, yield!\")   you have a generator object now waiting for a command for it to generate a value. Use next and see what get's printed:  >>> next(gen) # runs until it finds a yield I'm going to generate the value for you Then I'll pause for a while 'Hello, yield!'   The unquoted results are what's printed. The quoted result is what is returned from yield. Call next again now:  >>> next(gen) # continues from yield and runs again Let's go through it again. I'm going to generate the value for you Then I'll pause for a while 'Hello, yield!'   The generator remembers it was paused at yield value and resumes from there. The next message is printed and the search for the yield statement to pause at it performed again (due to the while loop).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do", "Language": "Python", "Q_Title": "What does the \u201cyield\u201d keyword do?", "Q_Votes": "8456", "Q_Content": "    What is the use of the yield keyword in Python? What does it do?  For example, I'm trying to understand this code1:  def _get_child_candidates(self, distance, min_dist, max_dist):     if self._leftchild and distance - max_dist < self._median:         yield self._leftchild     if self._rightchild and distance + max_dist >= self._median:         yield self._rightchild     And this is the caller:  result, candidates = [], [self] while candidates:     node = candidates.pop()     distance = node._get_dist(obj)     if distance <= max_dist and distance >= min_dist:         result.extend(node._values)     candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) return result   What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?     1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.     ", "Tags": ["python", "iterator", "generator", "yield", "coroutine"], "A_Votes": "20", "A_Content": "  yield is similar to return. The difference is:   yield makes a function iterable (in the following example primes(n = 1) function becomes iterable). What it essentially means is the next time the function is called, it will continue from where it left (which is after the line of yield expression).  def isprime(n):     if n == 1:         return False     for x in range(2, n):         if n % x == 0:             return False     else:         return True  def primes(n = 1):    while(True):        if isprime(n): yield n        n += 1   for n in primes():     if n > 100: break     print(n)   In the above example if isprime(n) is true it will return the prime number. In the next iteration it will continue from the next line   n += 1        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-python-string-and-also-use-fo", "Language": "Python", "Q_Title": "How can I print literal curly-brace characters in python string and also use .format on it?", "Q_Votes": "948", "Q_Content": "    x = \" \\{ Hello \\} {0} \" print x.format(42)   gives me : Key Error: Hello\\\\  I want to print the output: {Hello} 42     ", "Tags": ["python", "string", "format", "string-formatting", "curly-braces"], "A_Votes": "1305", "A_Content": "  You need to double the {{ and }}:  >>> x = \" {{ Hello }} {0} \" >>> print x.format(42) ' { Hello } 42 '   Here's the relevant part of the Python documentation for format string syntax:     Format strings contain \u201creplacement fields\u201d surrounded by curly braces {}. Anything that is not contained in braces is considered literal text, which is copied unchanged to the output. If you need to include a brace character in the literal text, it can be escaped by doubling: {{ and }}.      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-python-string-and-also-use-fo", "Language": "Python", "Q_Title": "How can I print literal curly-brace characters in python string and also use .format on it?", "Q_Votes": "948", "Q_Content": "    x = \" \\{ Hello \\} {0} \" print x.format(42)   gives me : Key Error: Hello\\\\  I want to print the output: {Hello} 42     ", "Tags": ["python", "string", "format", "string-formatting", "curly-braces"], "A_Votes": "53", "A_Content": "  You escape it by doubling the braces.  Eg:  x = \"{{ Hello }} {0}\" print x.format(42)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-python-string-and-also-use-fo", "Language": "Python", "Q_Title": "How can I print literal curly-brace characters in python string and also use .format on it?", "Q_Votes": "948", "Q_Content": "    x = \" \\{ Hello \\} {0} \" print x.format(42)   gives me : Key Error: Hello\\\\  I want to print the output: {Hello} 42     ", "Tags": ["python", "string", "format", "string-formatting", "curly-braces"], "A_Votes": "24", "A_Content": "  Try doing this:  x = \" {{ Hello }} {0} \" print x.format(42)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-python-string-and-also-use-fo", "Language": "Python", "Q_Title": "How can I print literal curly-brace characters in python string and also use .format on it?", "Q_Votes": "948", "Q_Content": "    x = \" \\{ Hello \\} {0} \" print x.format(42)   gives me : Key Error: Hello\\\\  I want to print the output: {Hello} 42     ", "Tags": ["python", "string", "format", "string-formatting", "curly-braces"], "A_Votes": "20", "A_Content": "  Try this:  x = \"{{ Hello }} {0}\"     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-python-string-and-also-use-fo", "Language": "Python", "Q_Title": "How can I print literal curly-brace characters in python string and also use .format on it?", "Q_Votes": "948", "Q_Content": "    x = \" \\{ Hello \\} {0} \" print x.format(42)   gives me : Key Error: Hello\\\\  I want to print the output: {Hello} 42     ", "Tags": ["python", "string", "format", "string-formatting", "curly-braces"], "A_Votes": "20", "A_Content": "  The OP wrote this comment:  I was trying to format a small JSON for some purposes, like this: '{\"all\": false, \"selected\": \"{}\"}'.format(data) to get something like {\"all\": false, \"selected\": \"1,2\"}   It's pretty common that the \"escaping braces\" issue comes up when dealing with JSON.  I suggest doing this:  import json data = \"1,2\" mydict = {\"all\": \"false\", \"selected\": data} json.dumps(mydict)   It's cleaner than the alternative, which is:  '{{\"all\": false, \"selected\": \"{}\"}}'.format(data)   Using the json library is definitely preferable when the JSON string gets more complicated than the example.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-python-string-and-also-use-fo", "Language": "Python", "Q_Title": "How can I print literal curly-brace characters in python string and also use .format on it?", "Q_Votes": "948", "Q_Content": "    x = \" \\{ Hello \\} {0} \" print x.format(42)   gives me : Key Error: Hello\\\\  I want to print the output: {Hello} 42     ", "Tags": ["python", "string", "format", "string-formatting", "curly-braces"], "A_Votes": "10", "A_Content": "  Although not any better, just for the reference, you can also do this:  >>> x = '{}Hello{} {}' >>> print x.format('{','}',42) {Hello} 42   It can be useful for example when someone wants to print {argument}. It is maybe more readable than '{{{}}}'.format('argument')  Note that you omit argument positions (e.g. {} instead of {0}) after Python 2.7     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-python-string-and-also-use-fo", "Language": "Python", "Q_Title": "How can I print literal curly-brace characters in python string and also use .format on it?", "Q_Votes": "948", "Q_Content": "    x = \" \\{ Hello \\} {0} \" print x.format(42)   gives me : Key Error: Hello\\\\  I want to print the output: {Hello} 42     ", "Tags": ["python", "string", "format", "string-formatting", "curly-braces"], "A_Votes": "10", "A_Content": "  Python 3.6+ (2017)  In the recent versions of Python one would use f-strings (see also PEP498).  With f-strings one should use double {{ or }}  n = 42   print(f\" {{Hello}} {n} \")   produces the desired   {Hello} 42   If you need to resolve an expression in the brackets instead of using literal text you'll need three sets of brackets:  hello = \"HELLO\" print(f\"{{{hello.lower()}}}\")   produces  {hello}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-python-string-and-also-use-fo", "Language": "Python", "Q_Title": "How can I print literal curly-brace characters in python string and also use .format on it?", "Q_Votes": "948", "Q_Content": "    x = \" \\{ Hello \\} {0} \" print x.format(42)   gives me : Key Error: Hello\\\\  I want to print the output: {Hello} 42     ", "Tags": ["python", "string", "format", "string-formatting", "curly-braces"], "A_Votes": "5", "A_Content": "  If you are going to be doing this a lot, it might be good to define a utility function that will let you use arbitrary brace substitutes instead, like  def custom_format(string, brackets, *args, **kwargs):     if len(brackets) != 2:         raise ValueError('Expected two brackets. Got {}.'.format(len(brackets)))     padded = string.replace('{', '{{').replace('}', '}}')     substituted = padded.replace(brackets[0], '{').replace(brackets[1], '}')     formatted = substituted.format(*args, **kwargs)     return formatted  >>> custom_format('{{[cmd]} process 1}', brackets='[]', cmd='firefox.exe') '{{firefox.exe} process 1}'   Note that this will work either with brackets being a string of length 2 or an iterable of two strings (for multi-character delimiters).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-python-string-and-also-use-fo", "Language": "Python", "Q_Title": "How can I print literal curly-brace characters in python string and also use .format on it?", "Q_Votes": "948", "Q_Content": "    x = \" \\{ Hello \\} {0} \" print x.format(42)   gives me : Key Error: Hello\\\\  I want to print the output: {Hello} 42     ", "Tags": ["python", "string", "format", "string-formatting", "curly-braces"], "A_Votes": "1", "A_Content": "  Reason is , {} is the syntax of .format() so in your case .format() doesn't recognize {Hello} so it threw an error.  you can override it by using double curly braces {{}},    x = \" {{ Hello }} {0} \"   or   try %s for text formatting,  x = \" { Hello } %s\" print x%(42)        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "1403", "A_Content": "  Empty strings are \"falsy\" which means they are considered false in a Boolean context, so you can just do this:  if not myString:   This is the preferred way if you know that your variable is a string.  If your variable could also be some other type then you should use myString == \"\".  See the documentation on Truth Value Testing for other values that are false in Boolean contexts.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "295", "A_Content": "  From PEP 8, in the \u201cProgramming Recommendations\u201d section:     For sequences, (strings, lists, tuples), use the fact that empty sequences are false.   So you should use:  if not some_string:   or:  if some_string:   Just to clarify, sequences are evaluated to False or True in a Boolean context if they are empty or not. They are not equal to False or True.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "161", "A_Content": "  The most elegant way would probably be to simply check if its true or falsy, e.g.:  if not my_string:   However, you may want to strip white space because:   >>> bool(\"\")  False  >>> bool(\"   \")  True  >>> bool(\"   \".strip())  False   You should probably be a bit more explicit in this however, unless you know for sure that this string has passed some kind of validation and is a string that can be tested this way.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "58", "A_Content": "  I would test noneness before stripping. Also, I would use the fact that empty strings are False (or Falsy). This approach is similar to Apache's StringUtils.isBlank or Guava's Strings.isNullOrEmpty  This is what I would use to test if a string is either None OR Empty OR Blank:  def isBlank (myString):     if myString and myString.strip():         #myString is not None AND myString is not empty or blank         return False     #myString is None OR myString is empty or blank     return True   And, the exact opposite to test if a string is not None NOR Empty NOR Blank:  def isNotBlank (myString):     if myString and myString.strip():         #myString is not None AND myString is not empty or blank         return True     #myString is None OR myString is empty or blank     return False   More concise forms of the above code:  def isBlank (myString):     return not (myString and myString.strip())  def isNotBlank (myString):     return bool(myString and myString.strip())      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "27", "A_Content": "  I once wrote something similar to Bartek's answer and javascript inspired:  def isNotEmpty(s):     return bool(s and s.strip())   Test:  print isNotEmpty(\"\")    # False print isNotEmpty(\"   \") # False print isNotEmpty(\"ok\")  # True print isNotEmpty(None)  # False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "12", "A_Content": "  Test empty or blank string (shorter way):  if myString.strip():     print(\"it's not an empty or blank string\") else:     print(\"it's an empty or blank string\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "9", "A_Content": "  If you want to differentiate between empty and null strings, I would suggest using if len(string), otherwise, I'd suggest using simply if string as others have said.  The caveat about strings full of whitespace still applies though, so don't forget to strip.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "7", "A_Content": "  a = '' b = '   ' a.isspace() -> False b.isspace() -> True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "7", "A_Content": "  if my_string is '':   I haven't noticed THAT particular combination in any of the answers.  I searched for   is ''   in the answers prior to posting.    if my_string is '': print ('My string is EMPTY') # **footnote   I think this is what the original poster was trying to get to... something that reads as close to English as possible and follows solid programming practices.    if my_string is '':     print('My string is EMPTY') else:     print(f'My string is {my_string}')   Character for character I think this solution is a good one.  I noted None has entered into the discussion, so adding that and compacting further we get:  if my_string is '': print('My string is Empty') elif my_string is None : print('My string.... isn\\'t') else: print(f'My string is {my_string}')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "5", "A_Content": "     I find hardcoding(sic) \"\" every time for checking an empty string not as good.   Clean code approach  Doing this: foo == \"\" is very bad practice. \"\" is a magical value. You should never check against magical values (more commonly known as magical numbers)  What you should do is compare to a descriptive variable name.  Descriptive variable names  One may think that \"empty_string\" is a descriptive variable name. It isn't.  Before you go and do empty_string = \"\" and think you have a great variable name to compare to. This is not what \"descriptive variable name\" means.  A good descriptive variable name is based on its context. You have to think about what the empty string is.   Where does it come from.  Why is it there.  Why do you need to check for it.   Simple form field example  You are building a form where a user can enter values. You want to check if the user wrote something or not.  A good variable name may be not_filled_in  This makes the code very readable  if formfields.name == not_filled_in:     raise ValueError(\"We need your name\")   Thorough CSV parsing example  You are parsing CSV files and want the empty string to be parsed as None  (Since CSV is entirely text based, it cannot represent None without using predefined keywords)  A good variable name may be CSV_NONE  This makes the code easy to change and adapt if you have a new CSV file that represents None with another string than \"\"  if csvfield == CSV_NONE:     csvfield = None   There are no questions about if this piece of code is correct. It is pretty clear that it does what it should do.  Compare this to  if csvfield == EMPTY_STRING:     csvfield = None   The first question here is, Why does the empty string deserve special treatment?  This would tell future coders that an empty string should always be considered as None.  This is because it mixes business logic (What CSV value should be None) with code implementation (What are we actually comparing to)  There needs to be a separation of concern between the two.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "4", "A_Content": "  if stringname: gives a false when the string is empty. I guess it can't be simpler than this.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "2", "A_Content": "  Responding to @1290. Sorry, no way to format blocks in comments. The None value is not an empty string in Python, and neither is (spaces). The answer from Andrew Clark is the correct one: if not myString. The answer from @rouble is application-specific and does not answer the OP's question. You will get in trouble if you adopt a peculiar definition of what is a \"blank\" string. In particular, the standard behavior is that str(None) produces 'None', a non-blank string.  However if you must treat None and (spaces) as \"blank\" strings, here is a better way:  class weirdstr(str):     def __new__(cls, content):         return str.__new__(cls, content if content is not None else '')     def __nonzero__(self):         return bool(self.strip())   Examples:  >>> normal = weirdstr('word') >>> print normal, bool(normal) word True  >>> spaces = weirdstr('   ') >>> print spaces, bool(spaces)     False  >>> blank = weirdstr('') >>> print blank, bool(blank)  False  >>> none = weirdstr(None) >>> print none, bool(none)  False  >>> if not spaces: ...     print 'This is a so-called blank string' ...  This is a so-called blank string   Meets the @rouble requirements while not breaking the expected bool behavior of strings.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "0", "A_Content": "  You may have a look at this Assigning empty value or string in Python  This is about comparing strings that are empty. So instead of testing for emptiness with not, you may test is your string is equal to empty string with \"\" the empty string...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "0", "A_Content": "  for those who expect a behaviour like the apache StringUtils.isBlank or Guava Strings.isNullOrEmpty :  if mystring and mystring.strip():     print \"not blank string\" else:     print \"blank string\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "0", "A_Content": "  not str(myString)   This expression is True for strings that are empty. Non-empty strings, None and non-string objects will all produce False, with the caveat that objects may override __str__ to thwart this logic by returning a falsy value.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "0", "A_Content": "  str = \"\" if not str:    print \"Empty String\" if(len(str)==0):    print \"Empty String\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "0", "A_Content": "  If you just use   not var1    it is not possible to difference a variable which is boolean False from an empty string '':  var1 = '' not var1 > True  var1 = False not var1 > True   However, if you add a simple condition to your script, the difference is made:  var1  = False not var1 and var1 != '' > True  var1 = '' not var1 and var1 != '' > False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "-1", "A_Content": "  When you are reading file by lines and want to determine, which line is empty, make sure you will use .strip(), because there is new line character in \"empty\" line:  lines = open(\"my_file.log\", \"r\").readlines()  for line in lines:     if not line.strip():         continue      # your code for non-empty lines      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "-1", "A_Content": "  How about this?  Perhaps it's not \"the most elegant\", but it seems pretty complete and clear:  if (s is None) or (str(s).strip()==\"\"): // STRING s IS \"EMPTY\"...      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9573244/most-elegant-way-to-check-if-the-string-is-empty-in-python", "Language": "Python", "Q_Title": "Most elegant way to check if the string is empty in Python?", "Q_Votes": "956", "Q_Content": "    Does Python have something like an empty string variable where you can do?:  if myString == string.empty:   Regardless what's the most elegant way to check for empty string values? I find hard coding \"\" every time for checking an empty string not as good.     ", "Tags": ["python", "string", "comparison-operators"], "A_Votes": "-2", "A_Content": "  As prmatta posted above, but with mistake.  def isNoneOrEmptyOrBlankString (myString):     if myString:         if not myString.strip():             return True         else:             return False     return False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "1045", "A_Content": "  Since this question was asked in 2010, there has been real simplification in how to do simple multithreading with python with map and pool.  The code below comes from an article/blog post that you should definitely check out (no affiliation) - Parallelism in one line: A Better Model for Day to Day Threading Tasks.  I'll summarize below - it ends up being just a few lines of code:  from multiprocessing.dummy import Pool as ThreadPool  pool = ThreadPool(4)  results = pool.map(my_function, my_array)   Which is the multithreaded version of:  results = [] for item in my_array:     results.append(my_function(item))     Description     Map is a cool little function, and the key to easily injecting parallelism into your Python code. For those unfamiliar, map is something lifted from functional languages like Lisp. It is a function which maps another function over a sequence.      Map handles the iteration over the sequence for us, applies the function, and stores all of the results in a handy list at the end.       Implementation     Parallel versions of the map function are provided by two libraries:multiprocessing, and also its little known, but equally fantastic step child:multiprocessing.dummy.   multiprocessing.dummy is exactly the same as multiprocessing module, but uses threads instead (an important distinction - use multiple processes for CPU-intensive tasks; threads for (and during) IO):     multiprocessing.dummy replicates the API of multiprocessing but is no more than a wrapper around the threading module.   import urllib2  from multiprocessing.dummy import Pool as ThreadPool   urls = [   'http://www.python.org',    'http://www.python.org/about/',   'http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html',   'http://www.python.org/doc/',   'http://www.python.org/download/',   'http://www.python.org/getit/',   'http://www.python.org/community/',   'https://wiki.python.org/moin/', ]  # make the Pool of workers pool = ThreadPool(4)   # open the urls in their own threads # and return the results results = pool.map(urllib2.urlopen, urls)  # close the pool and wait for the work to finish  pool.close()  pool.join()    And the timing results:  Single thread:   14.4 seconds        4 Pool:   3.1 seconds        8 Pool:   1.4 seconds       13 Pool:   1.3 seconds     Passing multiple arguments (works like this only in Python 3.3 and later):  To pass multiple arrays:  results = pool.starmap(function, zip(list_a, list_b))   or to pass a constant and an array:  results = pool.starmap(function, zip(itertools.repeat(constant), list_a))   If you are using an earlier version of Python, you can pass multiple arguments via this workaround.  (Thanks to user136036 for the helpful comment)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "674", "A_Content": "  Here's a simple example: you need to try a few alternative URLs and return the contents of the first one to respond.  import Queue import threading import urllib2  # called by each thread def get_url(q, url):     q.put(urllib2.urlopen(url).read())  theurls = [\"http://google.com\", \"http://yahoo.com\"]  q = Queue.Queue()  for u in theurls:     t = threading.Thread(target=get_url, args = (q,u))     t.daemon = True     t.start()  s = q.get() print s   This is a case where threading is used as a simple optimization: each subthread is waiting for a URL to resolve and respond, in order to put its contents on the queue; each thread is a daemon (won't keep the process up if main thread ends -- that's more common than not); the main thread starts all subthreads, does a get on the queue to wait until one of them has done a put, then emits the results and terminates (which takes down any subthreads that might still be running, since they're daemon threads).  Proper use of threads in Python is invariably connected to I/O operations (since CPython doesn't use multiple cores to run CPU-bound tasks anyway, the only reason for threading is not blocking the process while there's a wait for some I/O).  Queues are almost invariably the best way to farm out work to threads and/or collect the work's results, by the way, and they're intrinsically threadsafe so they save you from worrying about locks, conditions, events, semaphores, and other inter-thread coordination/communication concepts.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "230", "A_Content": "  NOTE: For actual parallelization in Python, you should use the multiprocessing module to fork multiple processes that execute in parallel (due to the global interpreter lock, Python threads provide interleaving but are in fact executed serially, not in parallel, and are only useful when interleaving I/O operations).  However, if you are merely looking for interleaving (or are doing I/O operations that can be parallelized despite the global interpreter lock), then the threading module is the place to start. As a really simple example, let's consider the problem of summing a large range by summing subranges in parallel:  import threading  class SummingThread(threading.Thread):      def __init__(self,low,high):          super(SummingThread, self).__init__()          self.low=low          self.high=high          self.total=0       def run(self):          for i in range(self.low,self.high):              self.total+=i   thread1 = SummingThread(0,500000) thread2 = SummingThread(500000,1000000) thread1.start() # This actually causes the thread to run thread2.start() thread1.join()  # This waits until the thread has completed thread2.join()   # At this point, both threads have completed result = thread1.total + thread2.total print result   Note that the above is a very stupid example, as it does absolutely no I/O and will be executed serially albeit interleaved (with the added overhead of context switching) in CPython due to the global interpreter lock.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "87", "A_Content": "  Like others mentioned, CPython can use threads only for I\\O waits due to GIL. If you want to benefit from multiple cores for CPU-bound tasks, use multiprocessing:  from multiprocessing import Process  def f(name):     print 'hello', name  if __name__ == '__main__':     p = Process(target=f, args=('bob',))     p.start()     p.join()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "87", "A_Content": "  Just a note, Queue is not required for threading.  This is the simplest example I could imagine that shows 10 processes running concurrently.  import threading from random import randint from time import sleep   def print_number(number):     # Sleeps a random 1 to 10 seconds     rand_int_var = randint(1, 10)     sleep(rand_int_var)     print \"Thread \" + str(number) + \" slept for \" + str(rand_int_var) + \" seconds\"  thread_list = []  for i in range(1, 10):     # Instantiates the thread     # (i) does not make a sequence, so (i,)     t = threading.Thread(target=print_number, args=(i,))     # Sticks the thread in a list so that it remains accessible     thread_list.append(t)  # Starts threads for thread in thread_list:     thread.start()  # This blocks the calling thread until the thread whose join() method is called is terminated. # From http://docs.python.org/2/library/threading.html#thread-objects for thread in thread_list:     thread.join()  # Demonstrates that the main process waited for threads to complete print \"Done\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "39", "A_Content": "  The answer from Alex Martelli helped me, however here is modified version that I thought was more useful (at least to me).  import Queue import threading import urllib2  worker_data = ['http://google.com', 'http://yahoo.com', 'http://bing.com']  #load up a queue with your data, this will handle locking q = Queue.Queue() for url in worker_data:     q.put(url)  #define a worker function def worker(queue):     queue_full = True     while queue_full:         try:             #get your data off the queue, and do some work             url= queue.get(False)             data = urllib2.urlopen(url).read()             print len(data)          except Queue.Empty:             queue_full = False  #create as many threads as you want thread_count = 5 for i in range(thread_count):     t = threading.Thread(target=worker, args = (q,))     t.start()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "19", "A_Content": "  I found this very useful: create as many threads as cores and let them execute a (large) number of tasks (in this case, calling a shell program):  import Queue import threading import multiprocessing import subprocess  q = Queue.Queue() for i in range(30): #put 30 tasks in the queue     q.put(i)  def worker():     while True:         item = q.get()         #execute a task: call a shell program and wait until it completes         subprocess.call(\"echo \"+str(item), shell=True)          q.task_done()  cpus=multiprocessing.cpu_count() #detect number of cores print(\"Creating %d threads\" % cpus) for i in range(cpus):      t = threading.Thread(target=worker)      t.daemon = True      t.start()  q.join() #block until all tasks are done      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "15", "A_Content": "  For me, the perfect example for Threading is monitoring Asynchronous events.  Look at this code.  # thread_test.py import threading import time   class Monitor(threading.Thread):     def __init__(self, mon):         threading.Thread.__init__(self)         self.mon = mon      def run(self):         while True:             if self.mon[0] == 2:                 print \"Mon = 2\"                 self.mon[0] = 3;   You can play with this code by opening an IPython session and doing something like:  >>>from thread_test import Monitor >>>a = [0] >>>mon = Monitor(a) >>>mon.start() >>>a[0] = 2 Mon = 2 >>>a[0] = 2 Mon = 2   Wait a few minutes  >>>a[0] = 2 Mon = 2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "15", "A_Content": "  Given a function, f, thread it like this:  import threading threading.Thread(target=f).start()   To pass arguments to f  threading.Thread(target=f, args=(a,b,c)).start()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "15", "A_Content": "  Python 3 has the facility of Launching parallel tasks. This makes our work easier.   It has for thread pooling and Process pooling.   The following gives an insight:  ThreadPoolExecutor Example  import concurrent.futures import urllib.request  URLS = ['http://www.foxnews.com/',         'http://www.cnn.com/',         'http://europe.wsj.com/',         'http://www.bbc.co.uk/',         'http://some-made-up-domain.com/']  # Retrieve a single page and report the URL and contents def load_url(url, timeout):     with urllib.request.urlopen(url, timeout=timeout) as conn:         return conn.read()  # We can use a with statement to ensure threads are cleaned up promptly with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:     # Start the load operations and mark each future with its URL     future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}     for future in concurrent.futures.as_completed(future_to_url):         url = future_to_url[future]         try:             data = future.result()         except Exception as exc:             print('%r generated an exception: %s' % (url, exc))         else:             print('%r page is %d bytes' % (url, len(data)))   ProcessPoolExecutor  import concurrent.futures import math  PRIMES = [     112272535095293,     112582705942171,     112272535095293,     115280095190773,     115797848077099,     1099726899285419]  def is_prime(n):     if n % 2 == 0:         return False      sqrt_n = int(math.floor(math.sqrt(n)))     for i in range(3, sqrt_n + 1, 2):         if n % i == 0:             return False     return True  def main():     with concurrent.futures.ProcessPoolExecutor() as executor:         for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):             print('%d is prime: %s' % (number, prime))  if __name__ == '__main__':     main()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "13", "A_Content": "  Using the blazing new concurrent.futures module  def sqr(val):     import time     time.sleep(0.1)     return val * val  def process_result(result):     print(result)  def process_these_asap(tasks):     import concurrent.futures      with concurrent.futures.ProcessPoolExecutor() as executor:         futures = []         for task in tasks:             futures.append(executor.submit(sqr, task))          for future in concurrent.futures.as_completed(futures):             process_result(future.result())         # Or instead of all this just do:         # results = executor.map(sqr, tasks)         # list(map(process_result, results))  def main():     tasks = list(range(10))     print('Processing {} tasks'.format(len(tasks)))     process_these_asap(tasks)     print('Done')     return 0  if __name__ == '__main__':     import sys     sys.exit(main())   The executor approach might seem familiar to all those who have gotten their hands dirty with Java before.  Also on a side note: To keep the universe sane, don't forget to close your pools/executors if you don't use with context (which is so awesome that it does it for you)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "9", "A_Content": "  Most documentations and tutorials use Python's Threading and Queue module they could seem overwhelming for beginners.  Perhaps consider the concurrent.futures.ThreadPoolExecutor module of python 3. Combined with with clause and list comprehension it could be a real charm.  from concurrent.futures import ThreadPoolExecutor, as_completed  def get_url(url):     # Your actual program here. Using threading.Lock() if necessary     return \"\"  # List of urls to fetch urls = [\"url1\", \"url2\"]  with ThreadPoolExecutor(max_workers = 5) as executor:      # Create threads      futures = {executor.submit(get_url, url) for url in urls}      # as_completed() gives you the threads once finished     for f in as_completed(futures):         # Get the results          rs = f.result()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "8", "A_Content": "  Here is the very simple example of CSV import using threading. [Library inclusion may differ for different purpose ]  Helper Functions:  from threading import Thread from project import app  import csv   def import_handler(csv_file_name):     thr = Thread(target=dump_async_csv_data, args=[csv_file_name])     thr.start()  def dump_async_csv_data(csv_file_name):     with app.app_context():         with open(csv_file_name) as File:             reader = csv.DictReader(File)             for row in reader:                 #DB operation/query   Driver Function:  import_handler(csv_file_name)       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "6", "A_Content": "  Multi threading with simple example which will be helpful. You can run it and understand easily how is multi thread working in python. I used lock for prevent to access other thread until previous threads finished their work. By the use of      tLock = threading.BoundedSemaphore(value=4)   this line of code you can allow numbers of process at a time and keep hold to rest of thread which will run later or after finished previous processes.  import threading import time  #tLock = threading.Lock() tLock = threading.BoundedSemaphore(value=4) def timer(name, delay, repeat):     print  \"\\r\\nTimer: \", name, \" Started\"     tLock.acquire()     print \"\\r\\n\", name, \" has the acquired the lock\"     while repeat > 0:         time.sleep(delay)         print \"\\r\\n\", name, \": \", str(time.ctime(time.time()))         repeat -= 1      print \"\\r\\n\", name, \" is releaseing the lock\"     tLock.release()     print \"\\r\\nTimer: \", name, \" Completed\"  def Main():     t1 = threading.Thread(target=timer, args=(\"Timer1\", 2, 5))     t2 = threading.Thread(target=timer, args=(\"Timer2\", 3, 5))     t3 = threading.Thread(target=timer, args=(\"Timer3\", 4, 5))     t4 = threading.Thread(target=timer, args=(\"Timer4\", 5, 5))     t5 = threading.Thread(target=timer, args=(\"Timer5\", 0.1, 5))      t1.start()     t2.start()     t3.start()     t4.start()     t5.start()      print \"\\r\\nMain Complete\"  if __name__ == \"__main__\":     Main()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "3", "A_Content": "  None of the above solutions actually used multiple cores on my GNU/Linux server (where I don't have admin rights). They just ran on a single core. I used the lower level os.fork interface to spawn multiple processes. This is the code that worked for me:  from os import fork  values = ['different', 'values', 'for', 'threads']  for i in range(len(values)):     p = fork()     if p == 0:         my_function(values[i])         break      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "3", "A_Content": "  I saw a lot of examples here where no real work was being performed + they were mostly CPU bound. Here is an example of a CPU bound task that computes all prime numbers between 10 million and 10.05 million. I have used all 4 methods here  import math import timeit import threading import multiprocessing from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor   def time_stuff(fn):     \"\"\"     Measure time of execution of a function     \"\"\"     def wrapper(*args, **kwargs):         t0 = timeit.default_timer()         fn(*args, **kwargs)         t1 = timeit.default_timer()         print(\"{} seconds\".format(t1 - t0))     return wrapper  def find_primes_in(nmin, nmax):     \"\"\"     Compute a list of prime numbers between the given minimum and maximum arguments     \"\"\"     primes = []      #Loop from minimum to maximum     for current in range(nmin, nmax + 1):          #Take the square root of the current number         sqrt_n = int(math.sqrt(current))         found = False          #Check if the any number from 2 to the square root + 1 divides the current numnber under consideration         for number in range(2, sqrt_n + 1):              #If divisible we have found a factor, hence this is not a prime number, lets move to the next one             if current % number == 0:                 found = True                 break          #If not divisible, add this number to the list of primes that we have found so far         if not found:             primes.append(current)      #I am merely printing the length of the array containing all the primes but feel free to do what you want     print(len(primes))  @time_stuff def sequential_prime_finder(nmin, nmax):     \"\"\"     Use the main process and main thread to compute everything in this case     \"\"\"     find_primes_in(nmin, nmax)  @time_stuff def threading_prime_finder(nmin, nmax):     \"\"\"     If the minimum is 1000 and the maximum is 2000 and we have 4 workers     1000 - 1250 to worker 1     1250 - 1500 to worker 2     1500 - 1750 to worker 3     1750 - 2000 to worker 4     so lets split the min and max values according to the number of workers     \"\"\"     nrange = nmax - nmin     threads = []     for i in range(8):         start = int(nmin + i * nrange/8)         end = int(nmin + (i + 1) * nrange/8)          #Start the thrread with the min and max split up to compute         #Parallel computation will not work here due to GIL since this is a CPU bound task         t = threading.Thread(target = find_primes_in, args = (start, end))         threads.append(t)         t.start()      #Dont forget to wait for the threads to finish     for t in threads:         t.join()  @time_stuff def processing_prime_finder(nmin, nmax):     \"\"\"     Split the min, max interval similar to the threading method above but use processes this time     \"\"\"     nrange = nmax - nmin     processes = []     for i in range(8):         start = int(nmin + i * nrange/8)         end = int(nmin + (i + 1) * nrange/8)         p = multiprocessing.Process(target = find_primes_in, args = (start, end))         processes.append(p)         p.start()      for p in processes:         p.join()  @time_stuff def thread_executor_prime_finder(nmin, nmax):     \"\"\"     Split the min max interval similar to the threading method but use thread pool executor this time     This method is slightly faster than using pure threading as the pools manage threads more efficiently     This method is still slow due to the GIL limitations since we are doing a CPU bound task     \"\"\"     nrange = nmax - nmin     with ThreadPoolExecutor(max_workers = 8) as e:         for i in range(8):             start = int(nmin + i * nrange/8)             end = int(nmin + (i + 1) * nrange/8)             e.submit(find_primes_in, start, end)  @time_stuff def process_executor_prime_finder(nmin, nmax):     \"\"\"     Split the min max interval similar to the threading method but use the process pool executor     This is the fastest method recorded so far as it manages process efficiently + overcomes GIL limitations     RECOMMENDED METHOD FOR CPU BOUND TASKS     \"\"\"     nrange = nmax - nmin     with ProcessPoolExecutor(max_workers = 8) as e:         for i in range(8):             start = int(nmin + i * nrange/8)             end = int(nmin + (i + 1) * nrange/8)             e.submit(find_primes_in, start, end)  def main():     nmin = int(1e7)     nmax = int(1.05e7)     print(\"Sequential Prime Finder Starting\")     sequential_prime_finder(nmin, nmax)     print(\"Threading Prime Finder Starting\")     threading_prime_finder(nmin, nmax)     print(\"Processing Prime Finder Starting\")     processing_prime_finder(nmin, nmax)     print(\"Thread Executor Prime Finder Starting\")     thread_executor_prime_finder(nmin, nmax)     print(\"Process Executor Finder Starting\")     process_executor_prime_finder(nmin, nmax)  main()   Here are the results on my Mac OSX 4 core machine  Sequential Prime Finder Starting 9.708213827005238 seconds Threading Prime Finder Starting 9.81836523200036 seconds Processing Prime Finder Starting 3.2467174359990167 seconds Thread Executor Prime Finder Starting 10.228896902000997 seconds Process Executor Finder Starting 2.656402041000547 seconds      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "1", "A_Content": "  import threading import requests  def send():    r = requests.get('https://www.stackoverlow.com')  thread = [] t = threading.Thread(target=send()) thread.append(t) t.start()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python", "Language": "Python", "Q_Title": "How to use threading in Python?", "Q_Votes": "954", "Q_Content": "    I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.  How do you clearly show tasks being divided for multi-threading?     ", "Tags": ["python", "multithreading"], "A_Votes": "-2", "A_Content": "  Here, args is a tuple of arguments; use an empty tuple to call function without passing any arguments. kwargs is an optional dictionary of keyword arguments.  Example  #!/usr/bin/python  import thread import time  # Define a function for the thread def print_time( threadName, delay):    count = 0    while count < 5:       time.sleep(delay)       count += 1       print \"%s: %s\" % ( threadName, time.ctime(time.time()) )  # Create two threads as follows try:    thread.start_new_thread( print_time, (\"Thread-1\", 2, ) )    thread.start_new_thread( print_time, (\"Thread-2\", 4, ) ) except:    print \"Error: unable to start thread\"  while 1:    pass   When the above code is executed, it produces the following result \u2212  Thread-1: Thu Jan 22 15:42:17 2009 Thread-1: Thu Jan 22 15:42:19 2009 Thread-2: Thu Jan 22 15:42:19 2009 Thread-1: Thu Jan 22 15:42:21 2009 Thread-2: Thu Jan 22 15:42:23 2009 Thread-1: Thu Jan 22 15:42:23 2009 Thread-1: Thu Jan 22 15:42:25 2009 Thread-2: Thu Jan 22 15:42:27 2009 Thread-2: Thu Jan 22 15:42:31 2009 Thread-2: Thu Jan 22 15:42:35 2009      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "1076", "A_Content": "  You need to read the Python Unicode HOWTO. This error is the very first example.  Basically, stop using str to convert from unicode to encoded text / bytes.  Instead, properly use .encode() to encode the string:  p.agent_info = u' '.join((agent_contact, agent_telno)).encode('utf-8').strip()   or work entirely in unicode.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "376", "A_Content": "  This is a classic python unicode pain point! Consider the following:  a = u'bats\\u00E0' print a  => bats\u00e0   All good so far, but if we call str(a), let's see what happens:  str(a) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode character u'\\xe0' in position 4: ordinal not in range(128)   Oh dip, that's not gonna do anyone any good! To fix the error, encode the bytes explicitly with .encode and tell python what codec to use:  a.encode('utf-8')  => 'bats\\xc3\\xa0' print a.encode('utf-8')  => bats\u00e0   Voil\\u00E0!  The issue is that when you call str(), python uses the default character encoding to try and encode the bytes you gave it, which in your case are sometimes representations of unicode characters. To fix the problem, you have to tell python how to deal with the string you give it by using .encode('whatever_unicode'). Most of the time, you should be fine using utf-8.  For an excellent exposition on this topic, see Ned Batchelder's PyCon talk here: http://nedbatchelder.com/text/unipain.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "172", "A_Content": "  I found elegant work around for me to remove symbols and continue to keep string as string in follows:  yourstring = yourstring.encode('ascii', 'ignore').decode('ascii')   It's important to notice that using the ignore option is dangerous because it silently drops any unicode(and internationalization) support from the code that uses it, as seen here (convert unicode):  >>> u'City: Malm\u00f6'.encode('ascii', 'ignore').decode('ascii') 'City: Malm'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "115", "A_Content": "  well i tried everything but it did not help, after googling around i figured the following and it helped. python 2.7 is in use.  # encoding=utf8 import sys reload(sys) sys.setdefaultencoding('utf8')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "74", "A_Content": "  A subtle problem causing even print to fail is having your environment variables set wrong, eg. here LC_ALL set to \"C\".  In Debian they discourage setting it: Debian wiki on Locale  $ echo $LANG en_US.utf8 $ echo $LC_ALL  C $ python -c \"print (u'voil\\u00e0')\" Traceback (most recent call last):   File \"<string>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode character u'\\xe0' in position 4: ordinal not in range(128) $ export LC_ALL='en_US.utf8' $ python -c \"print (u'voil\\u00e0')\" voil\u00e0 $ unset LC_ALL $ python -c \"print (u'voil\\u00e0')\" voil\u00e0      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "27", "A_Content": "  I've actually found that in most of my cases, just stripping out those characters is much simpler:  s = mystring.decode('ascii', 'ignore')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "24", "A_Content": "  For me, what worked was:  BeautifulSoup(html_text,from_encoding=\"utf-8\")   Hope this helps someone.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "16", "A_Content": "  Add line below at the beginning of your script ( or as second line):  # -*- coding: utf-8 -*-   That's definition of python source code encoding. More info in PEP 263.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "14", "A_Content": "  The problem is that you're trying to print a unicode character, but your terminal doesn't support it.  You can try installing language-pack-en package to fix that:  sudo apt-get install language-pack-en   which provides English translation data updates for all supported packages (including Python). Install different language package if necessary (depending which characters you're trying to print).  On some Linux distributions it's required in order to make sure that the default English locales are set-up properly (so unicode characters can be handled by shell/terminal). Sometimes it's easier to install it, than configuring it manually.  Then when writing the code, make sure you use the right encoding in your code.  For example:  open(foo, encoding='utf-8')   If you've still a problem, double check your system configuration, such as:   Your locale file (/etc/default/locale), which should have e.g.  LANG=\"en_US.UTF-8\" LC_ALL=\"en_US.UTF-8\"  Value of LANG/LC_CTYPE in shell. Check which locale your shell supports by:  locale -a | grep \"UTF-8\"      Demonstrating the problem and solution in fresh VM.   Initialize and provision the VM (e.g. using vagrant):  vagrant init ubuntu/trusty64; vagrant up; vagrant ssh   See: available Ubuntu boxes.. Printing unicode characters (such as trade mark sign like \u2122):   $ python -c 'print(u\"\\u2122\");' Traceback (most recent call last):   File \"<string>\", line 1, in <module> UnicodeEncodeError: 'ascii' codec can't encode character u'\\u2122' in position 0: ordinal not in range(128)  Now installing language-pack-en:  $ sudo apt-get -y install language-pack-en The following extra packages will be installed:   language-pack-en-base Generating locales...   en_GB.UTF-8... /usr/sbin/locale-gen: done Generation complete.  Now problem is solved:  $ python -c 'print(u\"\\u2122\");' \u2122       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "10", "A_Content": "  Here's a rehashing of some other so-called \"cop out\" answers.  There are situations in which simply throwing away the troublesome characters/strings is a good solution, despite the protests voiced here.    def safeStr(obj):     try: return str(obj)     except UnicodeEncodeError:         return obj.encode('ascii', 'ignore').decode('ascii')     except: return \"\"   Testing it:  if __name__ == '__main__':      print safeStr( 1 )      print safeStr( \"test\" )      print u'98\\xb0'     print safeStr( u'98\\xb0' )   Results:  1 test 98\u00b0 98   Suggestion: you might want to name this function to toAscii instead?  That's a matter of preference.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "6", "A_Content": "  Simple helper functions found here.  def safe_unicode(obj, *args):     \"\"\" return the unicode representation of obj \"\"\"     try:         return unicode(obj, *args)     except UnicodeDecodeError:         # obj is byte string         ascii_text = str(obj).encode('string_escape')         return unicode(ascii_text)  def safe_str(obj):     \"\"\" return the byte string representation of obj \"\"\"     try:         return str(obj)     except UnicodeEncodeError:         # obj is unicode         return unicode(obj).encode('unicode_escape')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "6", "A_Content": "  Try this might solve,  # encoding=utf8 import sys reload(sys) sys.setdefaultencoding('utf8')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "3", "A_Content": "  I just used the following:  import unicodedata message = unicodedata.normalize(\"NFKD\", message)   Check what documentation says about it:     unicodedata.normalize(form, unistr) Return the normal form form for   the Unicode string unistr. Valid values for form are \u2018NFC\u2019, \u2018NFKC\u2019,   \u2018NFD\u2019, and \u2018NFKD\u2019.      The Unicode standard defines various normalization forms of a Unicode   string, based on the definition of canonical equivalence and   compatibility equivalence. In Unicode, several characters can be   expressed in various way. For example, the character U+00C7 (LATIN   CAPITAL LETTER C WITH CEDILLA) can also be expressed as the sequence   U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING CEDILLA).      For each character, there are two normal forms: normal form C and   normal form D. Normal form D (NFD) is also known as canonical   decomposition, and translates each character into its decomposed form.   Normal form C (NFC) first applies a canonical decomposition, then   composes pre-combined characters again.      In addition to these two forms, there are two additional normal forms   based on compatibility equivalence. In Unicode, certain characters are   supported which normally would be unified with other characters. For   example, U+2160 (ROMAN NUMERAL ONE) is really the same thing as U+0049   (LATIN CAPITAL LETTER I). However, it is supported in Unicode for   compatibility with existing character sets (e.g. gb2312).      The normal form KD (NFKD) will apply the compatibility decomposition,   i.e. replace all compatibility characters with their equivalents. The   normal form KC (NFKC) first applies the compatibility decomposition,   followed by the canonical composition.      Even if two unicode strings are normalized and look the same to a   human reader, if one has combining characters and the other doesn\u2019t,   they may not compare equal.   Solves it for me. Simple and easy.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "3", "A_Content": "  I always put the code below in the first two lines of the python files:  # -*- coding: utf-8 -*- from __future__ import unicode_literals      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "2", "A_Content": "  Just add to a variable encode('utf-8')  agent_contact.encode('utf-8')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "2", "A_Content": "  We struck this error when running manage.py migrate in Django with localized fixtures.  Our source contained the # -*- coding: utf-8 -*- declaration, MySQL was correctly configured for utf8 and Ubuntu had the appropriate language pack and values in /etc/default/locale.  The issue was simply that the Django container (we use docker) was missing the LANG env var.  Setting LANG to en_US.UTF-8 and restarting the container before re-running migrations fixed the problem.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "1140", "A_Content": "    Connecting to MYSQL with Python in 3 steps  1 - Setting  You must install a MySQL driver before doing anything. Unlike PHP, Only the SQLite driver is installed by default with Python. The most used package to do so is MySQLdb but it's hard to install it using easy_install.  For Windows user, you can get an exe of MySQLdb.   For Linux, this is a casual package (python-mysqldb). (You can use sudo apt-get install python-mysqldb (for debian based distros), yum install MySQL-python (for rpm-based), or dnf install python-mysql (for modern fedora distro) in command line to download.)  For Mac, you can install MySQLdb using Macport.  2 - Usage  After installing, Reboot. This is not mandatory, But it will prevent me from answering 3 or 4 other questions in this post if something goes wrong. So please reboot.  Then it is just like using any other package :  #!/usr/bin/python import MySQLdb  db = MySQLdb.connect(host=\"localhost\",    # your host, usually localhost                      user=\"john\",         # your username                      passwd=\"megajonhy\",  # your password                      db=\"jonhydb\")        # name of the data base  # you must create a Cursor object. It will let #  you execute all the queries you need cur = db.cursor()  # Use all the SQL you like cur.execute(\"SELECT * FROM YOUR_TABLE_NAME\")  # print all the first cell of all the rows for row in cur.fetchall():     print row[0]  db.close()   Of course, there are thousand of possibilities and options; this is a very basic example. You will have to look at the documentation. A good starting point.  3 - More advanced usage  Once you know how it works, You may want to use an ORM to avoid writing SQL manually and manipulate your tables as they were Python objects. The most famous ORM in the Python community is SQLAlchemy.   I strongly advise you to use it: your life is going to be much easier.  I recently discovered another jewel in the Python world: peewee. It's a very lite ORM, really easy and fast to setup then use. It makes my day for small projects or stand alone apps, Where using big tools like SQLAlchemy or Django is overkill :  import peewee from peewee import *  db = MySQLDatabase('jonhydb', user='john', passwd='megajonhy')  class Book(peewee.Model):     author = peewee.CharField()     title = peewee.TextField()      class Meta:         database = db  Book.create_table() book = Book(author=\"me\", title='Peewee is cool') book.save() for book in Book.filter(author=\"me\"):     print book.title   This example works out of the box. Nothing other than having peewee (pip install peewee) is required.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "2", "A_Content": "  Below solution worked for me, Just added      u \"String\"   (representing the string as unicode) before my string.  result_html = result.to_html(col_space=1, index=False, justify={'right'})  text = u\"\"\" <html> <body> <p> Hello all, <br> <br> Here's weekly summary report.  Let me know if you have any questions. <br> <br> Data Summary <br> <br> <br> {0} </p> <p>Thanks,</p> <p>Data Team</p> </body></html> \"\"\".format(result_html)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "1", "A_Content": "  I just had this problem, and Google led me here, so just to add to the general solutions here, this is what worked for me:  # 'value' contains the problematic data unic = u'' unic += value value = unic   I had this idea after reading Ned's presentation.  I don't claim to fully understand why this works, though. So if anyone can edit this answer or put in a comment to explain, I'll appreciate it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20", "Language": "Python", "Q_Title": "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)", "Q_Votes": "967", "Q_Content": "    I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.   The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.  One of the sections of code that is causing problems is shown below:  agent_telno = agent.find('div', 'agent_contact_number') agent_telno = '' if agent_telno is None else agent_telno.contents[0] p.agent_info = str(agent_contact + ' ' + agent_telno).strip()   Here is a stack trace produced on SOME strings when the snippet above is run:  Traceback (most recent call last):   File \"foobar.py\", line 792, in <module>     p.agent_info = str(agent_contact + ' ' + agent_telno).strip() UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)   I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.  Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?     ", "Tags": ["python", "unicode", "beautifulsoup", "python-2.x", "python-unicode"], "A_Votes": "0", "A_Content": "  If you have something like packet_data = \"This is data\" then do this on the next line, right after initializing packet_data:  unic = u'' packet_data = unic      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "161", "A_Content": "  Here's one way to do it:  #!/usr/bin/python import MySQLdb  # Connect db = MySQLdb.connect(host=\"localhost\",                      user=\"appuser\",                      passwd=\"\",                      db=\"onco\")  cursor = db.cursor()  # Execute SQL select statement cursor.execute(\"SELECT * FROM location\")  # Commit your changes if writing # In this case, we are only reading data # db.commit()  # Get the number of rows in the resultset numrows = cursor.rowcount  # Get and display one row at a time for x in range(0, numrows):     row = cursor.fetchone()     print row[0], \"-->\", row[1]  # Close the connection db.close()   Reference here     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "107", "A_Content": "  Oracle (MySQL) now supports a pure Python connector.  That means no binaries to install: it's just a Python library.  It's called \"Connector/Python\".    http://dev.mysql.com/downloads/connector/python/     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "96", "A_Content": "  If you do not need MySQLdb, but would accept any library, I would very, very much recommend MySQL Connector/Python from MySQL: http://dev.mysql.com/downloads/connector/python/.  It is one package (around 110k), pure Python, so it is system independent, and dead simple to install. You just download, double-click, confirm license agreement and go. There is no need for Xcode, MacPorts, compiling, restarting \u2026  Then you connect like:  import mysql.connector     cnx = mysql.connector.connect(user='scott', password='tiger',                               host='127.0.0.1',                               database='employees')  try:    cursor = cnx.cursor()    cursor.execute(\"\"\"       select 3 from your_table    \"\"\")    result = cursor.fetchall()    print result finally:     cnx.close()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "85", "A_Content": "     Stop Using MySQLDb if you want to avoid installing mysql headers just to access mysql from python.   Use pymysql. It does all of what MySQLDb does, but it was implemented purely in Python with NO External Dependencies.  This makes the installation process on all operating systems consistent and easy.  pymysql is a drop in replacement for MySQLDb and IMHO there is no reason to ever use MySQLDb for anything... EVER! - PTSD from installing MySQLDb on Mac OSX and *Nix systems, but that's just me.  Installation  pip install pymysql     That's it... you are ready to play.   Example usage from pymysql Github repo  import pymysql.cursors import pymysql  # Connect to the database connection = pymysql.connect(host='localhost',                              user='user',                              password='passwd',                              db='db',                              charset='utf8mb4',                              cursorclass=pymysql.cursors.DictCursor)  try:     with connection.cursor() as cursor:         # Create a new record         sql = \"INSERT INTO `users` (`email`, `password`) VALUES (%s, %s)\"         cursor.execute(sql, ('webmaster@python.org', 'very-secret'))      # connection is not autocommit by default. So you must commit to save     # your changes.     connection.commit()      with connection.cursor() as cursor:         # Read a single record         sql = \"SELECT `id`, `password` FROM `users` WHERE `email`=%s\"         cursor.execute(sql, ('webmaster@python.org',))         result = cursor.fetchone()         print(result) finally:     connection.close()      ALSO - Replace MySQLdb in existing code quickly and transparently   If you have existing code that uses MySQLdb, you can easily replace it with pymysql using this simple process:  # import MySQLdb << Remove this line and replace with: import pymysql pymysql.install_as_MySQLdb()   All subsequent references to MySQLdb will use pymysql transparently.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "18", "A_Content": "  As a db driver, there is also oursql. Some of the reasons listed on that link, which say why oursql is better:        oursql has real parameterization, sending the SQL and data to MySQL completely separately.   oursql allows text or binary data to be streamed into the database and streamed out of the database, instead of requiring everything to be buffered in the client.   oursql can both insert rows lazily and fetch rows lazily.   oursql has unicode support on by default.   oursql supports python 2.4 through 2.7 without any deprecation warnings on 2.6+ (see PEP 218) and without completely failing on 2.7 (see PEP 328).   oursql runs natively on python 3.x.      So how to connect to mysql with oursql?  Very similar to mysqldb:  import oursql  db_connection = oursql.connect(host='127.0.0.1',user='foo',passwd='foobar',db='db_name') cur=db_connection.cursor() cur.execute(\"SELECT * FROM `tbl_name`\") for row in cur.fetchall():     print row[0]   The tutorial in the documentation is pretty decent.  And of course for ORM SQLAlchemy is a good choice, as already mentioned in the other answers.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "17", "A_Content": "  Try using MySQLdb  There is a how to page here: http://www.kitebird.com/articles/pydbapi.html    From the page:  # server_version.py - retrieve and display database server version  import MySQLdb  conn = MySQLdb.connect (host = \"localhost\",                         user = \"testuser\",                         passwd = \"testpass\",                         db = \"test\") cursor = conn.cursor () cursor.execute (\"SELECT VERSION()\") row = cursor.fetchone () print \"server version:\", row[0] cursor.close () conn.close ()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "11", "A_Content": "  Despite all answers above, in case you do not want to connect to a specific database upfront, for example, if you want to create the database still (!), you can use connection.select_db(database), as demonstrated in the following.  import pymysql.cursors connection = pymysql.connect(host='localhost',                          user='mahdi',                          password='mahdi',                          charset='utf8mb4',                          cursorclass=pymysql.cursors.DictCursor) cursor = connection.cursor() cursor.execute(\"CREATE DATABASE IF NOT EXISTS \"+database) connection.select_db(database) sql_create = \"CREATE TABLE IF NOT EXISTS \"+tablename+(timestamp DATETIME NOT NULL PRIMARY KEY)\" cursor.execute(sql_create) connection.commit() cursor.close()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "8", "A_Content": "  MySQLdb is the straightforward way. You get to execute SQL queries over a connection. Period.  My preferred way, which is also pythonic, is to use the mighty SQLAlchemy instead. Here is a query related tutorial, and here is a tutorial on ORM capabilities of SQLALchemy.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "7", "A_Content": "  SqlAlchemy       SQLAlchemy is the Python SQL toolkit and Object Relational Mapper that   gives application developers the full power and flexibility of SQL.   SQLAlchemy provides a full suite of well known enterprise-level   persistence patterns, designed for efficient and high-performing   database access, adapted into a simple and Pythonic domain language.   Installation  pip install sqlalchemy   RAW query  from sqlalchemy import create_engine from sqlalchemy.orm import sessionmaker, scoped_session  engine = create_engine(\"mysql://<user_name>:<password>@<host_name>/smsmagic\") session_obj = sessionmaker(bind=engine) session = scoped_session(session_obj)  # insert into database session.execute(\"insert into person values(2, 'random_name')\") session.flush() session.commit()   ORM way  from sqlalchemy import Column, Integer, String from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import create_engine from sqlalchemy.orm import sessionmaker, scoped_session  Base = declarative_base() engine = create_engine(\"mysql://<user_name>:<password>@<host_name>/smsmagic\") session_obj = sessionmaker(bind=engine) session = scoped_session(session_obj)  # Bind the engine to the metadata of the Base class so that the # declaratives can be accessed through a DBSession instance Base.metadata.bind = engine  class Person(Base):     __tablename__ = 'person'     # Here we define columns for the table person     # Notice that each column is also a normal Python instance attribute.     id = Column(Integer, primary_key=True)     name = Column(String(250), nullable=False)  # insert into database person_obj = Person(id=12, name=\"name\") session.add(person_obj) session.flush() session.commit()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "6", "A_Content": "  Just a modification in above answer.  Simply run this command to install mysql for python  sudo yum install MySQL-python sudo apt-get install MySQL-python   remember! It is case sensitive.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "3", "A_Content": "  Also take a look at Storm. It is a simple SQL mapping tool which allows you to easily edit and create SQL entries without writing the queries.  Here is a simple example:  from storm.locals import *  # User will be the mapped object; you have to create the table before mapping it class User(object):         __storm_table__ = \"user\" # table name         ID = Int(primary=True) #field ID         name= Unicode() # field name  database = create_database(\"mysql://root:password@localhost:3306/databaseName\") store = Store(database)  user = User() user.name = u\"Mark\"  print str(user.ID) # None  store.add(user)   store.flush() # ID is AUTO_INCREMENT  print str(user.ID) # 1 (ID)  store.commit() # commit all changes to the database   To find and object use:  michael = store.find(User, User.name == u\"Michael\").one() print str(user.ID) # 10   Find with primary key:  print store.get(User, 1).name #Mark   For further information see the tutorial.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "1", "A_Content": "  first install the driver  pip install MySQL-python      Then a basic code goes like this:   #!/usr/bin/python import MySQLdb  try:     db = MySQLdb.connect(host=\"localhost\",      # db server, can be a remote one                       db=\"mydb\"                  # database                      user=\"mydb\",               # username                      passwd=\"mydb123\",          # password for this username                      )              # Create a Cursor object     cur = db.cursor()      # Create a query string. It can contain variables     query_string = \"SELECT * FROM MY_TABLE\"      # Execute the query     cur.execute(query_string)      # Get all the rows present the database     for each_row in cur.fetchall():         print each_row      # Close the connection     db.close() except Exception, e:     print 'Error ', e       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "1", "A_Content": "  mysqlclient is the best as others only provide support to specific versions of python    pip install mysqlclient   example code      import mysql.connector     import _mysql     db=_mysql.connect(\"127.0.0.1\",\"root\",\"umer\",\"sys\")     #db=_mysql.connect(host,user,password,db)     # Example of how to insert new values:     db.query(\"\"\"INSERT INTO table1 VALUES ('01', 'myname')\"\"\")     db.store_result()     db.query(\"SELECT * FROM new1.table1 ;\")      #new1 is scheme table1 is table mysql      res= db.store_result()     for i in range(res.num_rows()):         print(result.fetch_row())   see https://github.com/PyMySQL/mysqlclient-python     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "1", "A_Content": "  you can connect your python code to mysql in this way.   import MySQLdb db = MySQLdb.connect(host=\"localhost\",                  user=\"appuser\",                  passwd=\"\",                  db=\"onco\")  cursor = db.cursor()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "1", "A_Content": "  for Python3.6 I found two driver: pymysql and mysqlclient. I tested the performance between them and got the result: the mysqlclient is faster.  below is my test process(need install python lib profilehooks to analyze time elapse\uff1a  raw sql: select * from FOO;  immediatly execute in mysql terminal: 46410 rows in set (0.10 sec)  pymysql (2.4s):  from profilehooks import profile import pymysql.cursors import pymysql connection = pymysql.connect(host='localhost', user='root', db='foo') c = connection.cursor()  @profile(immediate=True) def read_by_pymysql():     c.execute(\"select * from FOO;\")     res = c.fetchall()  read_by_pymysql()   here's the pymysql profile:    mysqlclient (0.4s)  from profilehooks import profile import MySQLdb  connection = MySQLdb.connect(host='localhost', user='root', db='foo') c = connection.cursor()  @profile(immediate=True) def read_by_mysqlclient():     c.execute(\"select * from FOO;\")     res = c.fetchall()  read_by_mysqlclient()   here's the mysqlclient profile:   So, it seems that mysqlclient is much faster than pymysql     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "0", "A_Content": "  For python 3.3  CyMySQL https://github.com/nakagami/CyMySQL  I have pip installed on my windows 7, just  pip install cymysql  (you don't need cython) quick and painless     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "0", "A_Content": "  To write database applications in Python, there are five steps to follow:  Import the SQL interface with the following command:  >>> import MySQLdb   Establish a connection with the database with the following command:                 conn=MySQLdb.connect(host='localhost',user='root',passwd='')       \u2026where host is the name of your host machine, followed by the user name and password. In case of the root, there is no need to provide a password.           Create a cursor for the connection with the following command:  >>>cursor = conn.cursor()   Execute any SQL query using this cursor as shown below\u2014here the outputs in terms of show a number of rows affected by this query:                 cursor.execute('Create database Library') // Indicates how many rows affected           >>> cursor.execute('use Library')  >>>table='create table books(book_accno char(30) primary key, book_name char(50),no_of_copies int(5),price int(5))' >>> cursor.execute(table)   Finally, fetch the result set and iterate over this result set. In this step, the user can fetch the result sets as shown below:  >>> cursor.execute('select * from books') >>> cursor.fetchall()   (('Py9098', 'Programming With Python', 100L, 50L), ('Py9099', 'Programming With Python', 100L, 50L))     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "0", "A_Content": "  Best way to connect to MySQL from python is to Use MySQL Connector/Python because it is official Oracle driver for MySQL for working with Python and it works with both Python 3 and Python 2.  follow the steps mentioned below to connect MySQL   install connector using pip   pip install mysql-connector-python   or you can download the installer from https://dev.mysql.com/downloads/connector/python/   Use connect() method of mysql connector python to connect to MySQL.pass the required argument to connect() method. i.e. Host, username, password, and database name. Create cursor object from connection object returned by connect()method to execute SQL queries. close the connection after your work completes.   Example:  import mysql.connector  from mysql.connector import Error  try:      conn = mysql.connector.connect(host='hostname',                          database='db',                          user='root',                          password='passcode')      if conn.is_connected():        cursor = conn.cursor()        cursor.execute(\"select database();\")        record = cursor.fetchall()        print (\"Your connected to - \", record)  except Error as e :     print (\"Print your error msg\", e)  finally:     #closing database connection.     if(conn.is_connected()):        cursor.close()        conn.close()   Reference  - https://pynative.com/python-mysql-database-connection/  Important API of MySQL Connector Python   For DML operations - Use cursor.execute() and cursor.executemany() to run query. and after this use connection.commit() to persist your changes to DB To fetch data      - Use cursor.execute() to run query and cursor.fetchall(), cursor.fetchone(), cursor.fetchmany(SIZE) to fetch data      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "0", "A_Content": "  First install the driver (Ubuntu)   sudo apt-get install python-pip sudo pip install -U pip sudo apt-get install python-dev libmysqlclient-dev sudo apt-get install MySQL-python   MySQL database connection codes  import MySQLdb conn = MySQLdb.connect (host = \"localhost\",user = \"root\",passwd = \"pass\",db = \"dbname\") cursor = conn.cursor () cursor.execute (\"SELECT VERSION()\") row = cursor.fetchone () print \"server version:\", row[0] cursor.close () conn.close ()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python", "Language": "Python", "Q_Title": "How do I connect to a MySQL Database in Python?", "Q_Votes": "983", "Q_Content": "    How do I connect to a MySQL database using a python program?     ", "Tags": ["python", "mysql"], "A_Votes": "-1", "A_Content": "  First, install python-mysql connector from https://dev.mysql.com/downloads/connector/python/  on Python console enter:    pip install mysql-connector-python-rf import mysql.connector      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "869", "A_Content": "  I found this to be the only one short + flexible + portable + readable:  from __future__ import print_function import sys  def eprint(*args, **kwargs):     print(*args, file=sys.stderr, **kwargs)   The function eprint can be used in the same way as the standard print function:  >>> print(\"Test\") Test >>> eprint(\"Test\") Test >>> eprint(\"foo\", \"bar\", \"baz\", sep=\"---\") foo---bar---baz      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "412", "A_Content": "  sys.stderr.write() is my choice, just more readable and saying exactly what you intend to do and portable across versions.    Edit: being 'pythonic' is a third thought to me over readability and performance... with these two things in mind, with python 80% of your code will be pythonic. list comprehension being the 'big thing' that isn't used as often (readability).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "122", "A_Content": "  For Python 2 my choice is: print >> sys.stderr, 'spam' Because you can simply print lists/dicts etc. without convert it to string.  print >> sys.stderr, {'spam': 'spam'} instead of: sys.stderr.write(str({'spam': 'spam'}))     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "100", "A_Content": "  print >> sys.stderr is gone in Python3. http://docs.python.org/3.0/whatsnew/3.0.html says:  Old: print >>sys.stderr, \"fatal error\" New: print(\"fatal error\", file=sys.stderr)   Unfortunately, this is quite ugly. Alternatively, use  sys.stderr.write(\"fatal error\\n\")   but note that write is not a 1:1 replacement for print.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "57", "A_Content": "  Nobody's mentioned logging yet, but logging was created specifically to communicate error messages. By default it is set up to write to stderr. This script:  # foo.py import logging logging.basicConfig(format='%(message)s')  logging.warn('I print to stderr by default') logging.info('For this you must change the level and add a handler.') print('hello world')   has the following result when run on the command line:  $ python3 foo.py > bar.txt I print to stderr by default   (and bar.txt contains the 'hello world')     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "32", "A_Content": "  I would say that your first approach:  print >> sys.stderr, 'spam'    is the \"One . . . obvious way to do it\"  The others don't satisfy rule #1 (\"Beautiful is better than ugly.\")     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "28", "A_Content": "  I did the following using Python 3:  from sys import stderr  def print_err(*args, **kwargs):     print(*args, file=stderr, **kwargs)   So now I'm able to add keyword arguments, for example, to avoid carriage return:  print_err(\"Error: end of the file reached. The word \", end='') print_err(word, \"was not found\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "18", "A_Content": "  This will mimic the standard print function but output on stderr  def print_err(*args):     sys.stderr.write(' '.join(map(str,args)) + '\\n')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "16", "A_Content": "  EDIT In hind-sight, I think the potential confusion with changing sys.stderr and not seeing the behaviour updated makes this answer not as good as just using a simple function as others have pointed out.  Using partial only saves you 1 line of code. The potential confusion is not worth saving 1 line of code.  original  To make it even easier, here's a version that uses 'partial', which is a big help in wrapping functions.  from __future__ import print_function import sys from functools import partial  error = partial(print, file=sys.stderr)   You then use it like so  error('An error occured!')   You can check that it's printing to stderr and not stdout by doing the following (over-riding code from http://coreygoldberg.blogspot.com.au/2009/05/python-redirect-or-turn-off-stdout-and.html):  # over-ride stderr to prove that this function works. class NullDevice():     def write(self, s):         pass sys.stderr = NullDevice()  # we must import print error AFTER we've removed the null device because # it has been assigned and will not be re-evaluated. # assume error function is in print_error.py from print_error import error  # no message should be printed error(\"You won't see this error!\")   The downside to this is partial assigns the value of sys.stderr to the wrapped function at the time of creation. Which means, if you redirect stderr later it won't affect this function. If you plan to redirect stderr, then use the **kwargs method mentioned by aaguirre on this page.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "6", "A_Content": "  The same applies to stdout:  print 'spam' sys.stdout.write('spam\\n')   As stated in the other answers, print offers a pretty interface that is often more convenient (e.g. for printing debug information), while write is faster and can also be more convenient when you have to format the output exactly in certain way. I would consider maintainability as well:   You may later decide to switch between stdout/stderr and a regular file. print() syntax has changed in Python 3, so if you need to support both versions, write() might be better.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "4", "A_Content": "  I am working in python 3.4.3.  I am cutting out a little typing that shows how I got here:  [18:19 jsilverman@JSILVERMAN-LT7 pexpect]$ python3 >>> import sys >>> print(\"testing\", file=sys.stderr) testing >>> [18:19 jsilverman@JSILVERMAN-LT7 pexpect]$    Did it work?  Try redirecting stderr to a file and see what happens:  [18:22 jsilverman@JSILVERMAN-LT7 pexpect]$ python3 2> /tmp/test.txt >>> import sys >>> print(\"testing\", file=sys.stderr) >>> [18:22 jsilverman@JSILVERMAN-LT7 pexpect]$ [18:22 jsilverman@JSILVERMAN-LT7 pexpect]$ cat /tmp/test.txt Python 3.4.3 (default, May  5 2015, 17:58:45) [GCC 4.9.2] on cygwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. testing  [18:22 jsilverman@JSILVERMAN-LT7 pexpect]$   Well, aside from the fact that the little introduction that python gives you has been slurped into stderr (where else would it go?), it works.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "3", "A_Content": "  If you do a simple test:  import time import sys  def run1(runs):     x = 0     cur = time.time()     while x < runs:         x += 1         print >> sys.stderr, 'X'     elapsed = (time.time()-cur)     return elapsed  def run2(runs):     x = 0     cur = time.time()     while x < runs:         x += 1         sys.stderr.write('X\\n')         sys.stderr.flush()     elapsed = (time.time()-cur)     return elapsed  def compare(runs):     sum1, sum2 = 0, 0     x = 0     while x < runs:         x += 1         sum1 += run1(runs)         sum2 += run2(runs)     return sum1, sum2  if __name__ == '__main__':     s1, s2 = compare(1000)     print \"Using (print >> sys.stderr, 'X'): %s\" %(s1)     print \"Using (sys.stderr.write('X'),sys.stderr.flush()):%s\" %(s2)     print \"Ratio: %f\" %(float(s1) / float(s2))   You will find that sys.stderr.write() is consistently 1.81 times faster!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "0", "A_Content": "  Try:   from sys import stderr   print >> sys.stderr, 'spam'       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "0", "A_Content": "     Answer to the question is : There are different way to print stderr in python but that depends on   1.) which python version we are using   2.) what exact output we want.   The differnce between print and stderr's write function: stderr : stderr (standard error) is pipe that is built into every UNIX/Linux system, when your program crashes and prints out debugging information (like a traceback in Python), it goes to the stderr pipe.  print: print is a wrapper that formats the inputs (the input is the space between argument and the newline at the end) and it then calls the write function of a given object, the given object by default is sys.stdout, but we can pass a file i.e we can print the input in a file also.  Python2: If we are using python2 then  >>> import sys >>> print \"hi\" hi >>> print(\"hi\") hi >>> print >> sys.stderr.write(\"hi\") hi      Python2 trailing comma has in Python3 become a parameter, so if we use   trailing commas to avoid the newline after a print, this will in   Python3 look like print('Text to print', end=' ') which is a syntax   error under Python2.   http://python3porting.com/noconv.html     If we check same above sceario in python3:   >>> import sys >>> print(\"hi\") hi      Under Python 2.6 there is a future import to make print into a   function. So to avoid any syntax errors and other differences we   should start any file where we use print() with from future import   print_function. The future import only works under Python 2.6 and   later, so for Python 2.5 and earlier you have two options. You can   either convert the more complex print to something simpler, or you can   use a separate print function that works under both Python2 and   Python3.   >>> from __future__ import print_function >>>  >>> def printex(*args, **kwargs): ...     print(*args, file=sys.stderr, **kwargs) ...  >>> printex(\"hii\") hii >>>      Case: Point to be noted that sys.stderr.write() or sys.stdout.write()   ( stdout (standard output) is a pipe that is built into every   UNIX/Linux system) is not a replacement for print, but yes we can use   it as a alternative in some case. Print is a wrapper which wraps the   input with space and newline at the end and uses the write function to   write. This is the reason  sys.stderr.write() is faster.      Note: we can also trace and debugg using Logging   #test.py import logging logging.info('This is the existing protocol.') FORMAT = \"%(asctime)-15s %(clientip)s %(user)-8s %(message)s\" logging.basicConfig(format=FORMAT) d = {'clientip': '192.168.0.1', 'user': 'fbloggs'} logging.warning(\"Protocol problem: %s\", \"connection reset\", extra=d)   https://docs.python.org/2/library/logging.html#logger-objects     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5574702/how-to-print-to-stderr-in-python", "Language": "Python", "Q_Title": "How to print to stderr in Python?", "Q_Votes": "1010", "Q_Content": "    I've come across several ways to write to stderr:   # Note: this first one does not work in Python 3  print >> sys.stderr, \"spam\"   sys.stderr.write(\"spam\\n\")   os.write(2, b\"spam\\n\")   from __future__ import print_function  print(\"spam\", file=sys.stderr)   It seems to contradict zen of Python #13 \u2020, so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?  \u2020 There should be one \u2014 and preferably only one \u2014 obvious way to do it.     ", "Tags": ["python", "python-2.7", "printing", "stderr", "zen"], "A_Votes": "0", "A_Content": "  import logging logging.basicConfig(format='[%(levelname)s] %(message)s')  logging.error('is error, alarm!') logging.warning('is simple waring')  print('hello')   pydoc logging     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "1097", "A_Content": "  Python includes a profiler called cProfile. It not only gives the total running time, but also times each function separately, and tells you how many times each function was called, making it easy to determine where you should make optimizations.  You can call it from within your code, or from the interpreter, like this:  import cProfile cProfile.run('foo()')   Even more usefully, you can invoke the cProfile when running a script:  python -m cProfile myscript.py   To make it even easier, I made a little batch file called 'profile.bat':  python -m cProfile %1   So all I have to do is run:  profile euler048.py   And I get this:  1007 function calls in 0.061 CPU seconds  Ordered by: standard name ncalls  tottime  percall  cumtime  percall filename:lineno(function)     1    0.000    0.000    0.061    0.061 <string>:1(<module>)  1000    0.051    0.000    0.051    0.000 euler048.py:2(<lambda>)     1    0.005    0.005    0.061    0.061 euler048.py:2(<module>)     1    0.000    0.000    0.061    0.061 {execfile}     1    0.002    0.002    0.053    0.053 {map}     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler objects}     1    0.000    0.000    0.000    0.000 {range}     1    0.003    0.003    0.003    0.003 {sum}   EDIT: Updated link to a good video resource from PyCon 2013 titled  Python Profiling Also via YouTube.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "352", "A_Content": "  A while ago I made pycallgraph which generates a visualisation from your Python code. Edit: I've updated the example to work with the latest release.  After a pip install pycallgraph and installing GraphViz you can run it from the command line:  pycallgraph graphviz -- ./mypythonscript.py   Or, you can profile particular parts of your code:  from pycallgraph import PyCallGraph from pycallgraph.output import GraphvizOutput  with PyCallGraph(output=GraphvizOutput()):     code_to_profile()   Either of these will generate a pycallgraph.png file similar to the image below:       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "171", "A_Content": "  It's worth pointing out that using the profiler only works (by default) on the main thread, and you won't get any information from other threads if you use them.  This can be a bit of a gotcha as it is completely unmentioned in the profiler documentation.  If you also want to profile threads, you'll want to look at the threading.setprofile() function in the docs.  You could also create your own threading.Thread subclass to do it:  class ProfiledThread(threading.Thread):     # Overrides threading.Thread.run()     def run(self):         profiler = cProfile.Profile()         try:             return profiler.runcall(threading.Thread.run, self)         finally:             profiler.dump_stats('myprofile-%d.profile' % (self.ident,))   and use that ProfiledThread class instead of the standard one.  It might give you more flexibility, but I'm not sure it's worth it, especially if you are using third-party code which wouldn't use your class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "127", "A_Content": "  The python wiki is a great page for profiling resources: http://wiki.python.org/moin/PythonSpeed/PerformanceTips#Profiling_Code  as is the python docs: http://docs.python.org/library/profile.html  as shown by Chris Lawlor cProfile is a great tool and can easily be used to print to the screen:  python -m cProfile -s time mine.py <args>   or to file:  python -m cProfile -o output.file mine.py <args>   PS> If you are using Ubuntu, make sure to install python-profile  sudo apt-get install python-profiler    If you output to file you can get nice visualizations using the following tools  PyCallGraph : a tool to create call graph images    install:   sudo pip install pycallgraph   run:   pycallgraph mine.py args   view:   gimp pycallgraph.png   You can use whatever you like to view the png file, I used gimp Unfortunately I often get   dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.257079 to fit  which makes my images unusably small.  So I generally create svg files:  pycallgraph -f svg -o pycallgraph.svg mine.py <args>   PS> make sure to install graphviz (which provides the dot program):  sudo pip install graphviz   Alternative Graphing using gprof2dot via @maxy / @quodlibetor :  sudo pip install gprof2dot python -m cProfile -o profile.pstats mine.py gprof2dot -f pstats profile.pstats | dot -Tsvg -o mine.svg      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "115", "A_Content": "  @Maxy's comment on this answer helped me out enough that I think it deserves its own answer: I already had cProfile-generated .pstats files and I didn't want to re-run things with pycallgraph, so I used gprof2dot, and got pretty svgs:  $ sudo apt-get install graphviz $ git clone https://github.com/jrfonseca/gprof2dot $ ln -s \"$PWD\"/gprof2dot/gprof2dot.py ~/bin $ cd $PROJECT_DIR $ gprof2dot.py -f pstats profile.pstats | dot -Tsvg -o callgraph.svg   and BLAM!  It uses dot (the same thing that pycallgraph uses) so output looks similar. I get the impression that gprof2dot loses less information though:       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "42", "A_Content": "  I ran into a handy tool called SnakeViz when researching this topic. SnakeViz is a web-based profiling visualization tool. It is very easy to install and use. The usual way I use it is to generate a stat file with %prun and then do analysis in SnakeViz.  The main viz technique used is Sunburst chart as shown below, in which the hierarchy of function calls is arranged as layers of arcs and time info encoded in their angular widths.  The best thing is you can interact with the chart. For example, to zoom in one can click on an arc, and the arc and its descendants will be enlarged as a new sunburst to display more details.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "33", "A_Content": "  Also worth mentioning is the GUI cProfile dump viewer RunSnakeRun.  It allows you to sort and select, thereby zooming in on the relevant parts of the program.  The sizes of the rectangles in the picture is proportional to the time taken.  If you mouse over a rectangle it highlights that call in the table and everywhere on the map.  When you double-click on a rectangle it zooms in on that portion.  It will show you who calls that portion and what that portion calls.  The descriptive information is very helpful.  It shows you the code for that bit which can be helpful when you are dealing with built-in library calls.  It tells you what file and what line to find the code.  Also want to point at that the OP said 'profiling' but it appears he meant 'timing'.  Keep in mind programs will run slower when profiled.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "32", "A_Content": "  I think that cProfile is great for profiling, while kcachegrind is great for visualizing the results. The pyprof2calltree in between handles the file conversion.  python -m cProfile -o script.profile script.py pyprof2calltree -i script.profile -o script.calltree kcachegrind script.calltree   To install the required tools (on Ubuntu, at least):  apt-get install kcachegrind pip install pyprof2calltree   The result:       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "28", "A_Content": "  pprofile  line_profiler (already presented here) also inspired  pprofile, which is described as:     Line-granularity, thread-aware deterministic and statistic pure-python   profiler   It provides line-granularity as line_profiler, is pure Python, can be used as a standalone command or a module, and can even generate callgrind-format files that can be easily analyzed with [k|q]cachegrind.  vprof  There is also vprof, a Python package described as:     [...] providing rich and interactive visualizations for various Python program characteristics such as running time and memory usage.        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "27", "A_Content": "  A nice profiling module is the line_profiler (called using the script kernprof.py).  It can be downloaded here.  My understanding is that cProfile only gives information about total time spent in each function.  So individual lines of code are not timed.  This is an issue in scientific computing since often one single line can take a lot of time.  Also, as I remember, cProfile didn't catch the time I was spending in say numpy.dot.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "16", "A_Content": "  Simplest and quickest way to find where all the time is going.  1. pip install snakeviz  2. python -m cProfile -o temp.dat <PROGRAM>.py  3. snakeviz temp.dat   Draws a pie chart in a browser. Biggest piece is the problem function. Simple.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "11", "A_Content": "  Following Joe Shaw's answer about multi-threaded code not to work as expected, I figured that the runcall method in cProfile is merely doing self.enable() and self.disable() calls around the profiled function call, so you can simply do that yourself and have whatever code you want in-between with minimal interference with existing code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "10", "A_Content": "  There's a lot of great answers but they either use command line or some external program for profiling and/or sorting the results.  I really missed some way I could use in my IDE (eclipse-PyDev) without touching the command line or installing anything. So here it is.  Profiling without command line  def count():     from math import sqrt     for x in range(10**5):         sqrt(x)  if __name__ == '__main__':     import cProfile, pstats     cProfile.run(\"count()\", \"{}.profile\".format(__file__))     s = pstats.Stats(\"{}.profile\".format(__file__))     s.strip_dirs()     s.sort_stats(\"time\").print_stats(10)   See docs or other answers for more info.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "10", "A_Content": "  In Virtaal's source there's a very useful class and decorator that can make profiling (even for specific methods/functions) very easy. The output can then be viewed very comfortably in KCacheGrind.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "9", "A_Content": "  cProfile is great for quick profiling but most of the time it was ending for me with the errors. Function runctx solves this problem by initializing correctly the environment and variables, hope it can be useful for someone:  import cProfile cProfile.runctx('foo()', None, locals())      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "6", "A_Content": "  My way is to use yappi (https://code.google.com/p/yappi/). It's especially useful combined with an RPC server where (even just for debugging) you register method to start, stop and print profiling information, e.g. in this way:   @staticmethod def startProfiler():     yappi.start()  @staticmethod def stopProfiler():     yappi.stop()  @staticmethod def printProfiler():     stats = yappi.get_stats(yappi.SORTTYPE_TTOT, yappi.SORTORDER_DESC, 20)     statPrint = '\\n'     namesArr = [len(str(stat[0])) for stat in stats.func_stats]     log.debug(\"namesArr %s\", str(namesArr))     maxNameLen = max(namesArr)     log.debug(\"maxNameLen: %s\", maxNameLen)      for stat in stats.func_stats:         nameAppendSpaces = [' ' for i in range(maxNameLen - len(stat[0]))]         log.debug('nameAppendSpaces: %s', nameAppendSpaces)         blankSpace = ''         for space in nameAppendSpaces:             blankSpace += space          log.debug(\"adding spaces: %s\", len(nameAppendSpaces))         statPrint = statPrint + str(stat[0]) + blankSpace + \" \" + str(stat[1]).ljust(8) + \"\\t\" + str(             round(stat[2], 2)).ljust(8 - len(str(stat[2]))) + \"\\t\" + str(round(stat[3], 2)) + \"\\n\"      log.log(1000, \"\\nname\" + ''.ljust(maxNameLen - 4) + \" ncall \\tttot \\ttsub\")     log.log(1000, statPrint)   Then when your program work you can start profiler at any time by calling the startProfiler RPC method and dump profiling information to a log file by calling printProfiler (or modify the rpc method to return it to the caller) and get such output:  2014-02-19 16:32:24,128-|SVR-MAIN  |-(Thread-3   )-Level 1000:  name                                                                                                                                      ncall     ttot    tsub 2014-02-19 16:32:24,128-|SVR-MAIN  |-(Thread-3   )-Level 1000:  C:\\Python27\\lib\\sched.py.run:80                                                                                                           22        0.11    0.05 M:\\02_documents\\_repos\\09_aheadRepos\\apps\\ahdModbusSrv\\pyAheadRpcSrv\\xmlRpc.py.iterFnc:293                                                22        0.11    0.0 M:\\02_documents\\_repos\\09_aheadRepos\\apps\\ahdModbusSrv\\serverMain.py.makeIteration:515                                                    22        0.11    0.0 M:\\02_documents\\_repos\\09_aheadRepos\\apps\\ahdModbusSrv\\pyAheadRpcSrv\\PicklingXMLRPC.py._dispatch:66                                       1         0.0     0.0 C:\\Python27\\lib\\BaseHTTPServer.py.date_time_string:464                                                                                    1         0.0     0.0 c:\\users\\zasiec~1\\appdata\\local\\temp\\easy_install-hwcsr1\\psutil-1.1.2-py2.7-win32.egg.tmp\\psutil\\_psmswindows.py._get_raw_meminfo:243     4         0.0     0.0 C:\\Python27\\lib\\SimpleXMLRPCServer.py.decode_request_content:537                                                                          1         0.0     0.0 c:\\users\\zasiec~1\\appdata\\local\\temp\\easy_install-hwcsr1\\psutil-1.1.2-py2.7-win32.egg.tmp\\psutil\\_psmswindows.py.get_system_cpu_times:148 4         0.0     0.0 <string>.__new__:8                                                                                                                        220       0.0     0.0 C:\\Python27\\lib\\socket.py.close:276                                                                                                       4         0.0     0.0 C:\\Python27\\lib\\threading.py.__init__:558                                                                                                 1         0.0     0.0 <string>.__new__:8                                                                                                                        4         0.0     0.0 C:\\Python27\\lib\\threading.py.notify:372                                                                                                   1         0.0     0.0 C:\\Python27\\lib\\rfc822.py.getheader:285                                                                                                   4         0.0     0.0 C:\\Python27\\lib\\BaseHTTPServer.py.handle_one_request:301                                                                                  1         0.0     0.0 C:\\Python27\\lib\\xmlrpclib.py.end:816                                                                                                      3         0.0     0.0 C:\\Python27\\lib\\SimpleXMLRPCServer.py.do_POST:467                                                                                         1         0.0     0.0 C:\\Python27\\lib\\SimpleXMLRPCServer.py.is_rpc_path_valid:460                                                                               1         0.0     0.0 C:\\Python27\\lib\\SocketServer.py.close_request:475                                                                                         1         0.0     0.0 c:\\users\\zasiec~1\\appdata\\local\\temp\\easy_install-hwcsr1\\psutil-1.1.2-py2.7-win32.egg.tmp\\psutil\\__init__.py.cpu_times:1066               4         0.0     0.0    It may not be very useful for short scripts but helps to optimize server-type processes especially given the printProfiler method can be called multiple times over time to profile and compare e.g. different program usage scenarios.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "933", "A_Content": "  Single Underscore  Names, in a class, with a leading underscore are simply to indicate to other programmers that the attribute or method is intended to be private.  However, nothing special is done with the name itself.  To quote PEP-8:     _single_leading_underscore: weak \"internal use\" indicator. E.g. from M import * does not import objects whose name starts with an underscore.   Double Underscore (Name Mangling)  From the Python docs:     Any identifier of the form __spam (at least two leading underscores, at most one trailing underscore) is textually replaced with _classname__spam, where classname is the current class name with leading underscore(s) stripped. This mangling is done without regard to the syntactic position of the identifier, so it can be used to define class-private instance and class variables, methods, variables stored in globals, and even variables stored in instances. private to this class on instances of other classes.    And a warning from the same page:     Name mangling is intended to give classes an easy way to define \u201cprivate\u201d instance variables and methods, without having to worry about instance variables defined by derived classes, or mucking with instance variables by code outside the class. Note that the mangling rules are designed mostly to avoid accidents; it still is possible for a determined soul to access or modify a variable that is considered private.   Example  >>> class MyClass(): ...     def __init__(self): ...             self.__superprivate = \"Hello\" ...             self._semiprivate = \", world!\" ... >>> mc = MyClass() >>> print mc.__superprivate Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: myClass instance has no attribute '__superprivate' >>> print mc._semiprivate , world! >>> print mc.__dict__ {'_MyClass__superprivate': 'Hello', '_semiprivate': ', world!'}      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "3", "A_Content": "     Ever want to know what the hell that python script is doing? Enter the   Inspect Shell. Inspect Shell lets you print/alter globals and run   functions without interrupting the running script. Now with   auto-complete and command history (only on linux).      Inspect Shell is not a pdb-style debugger.   https://github.com/amoffat/Inspect-Shell  You could use that (and your wristwatch).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "3", "A_Content": "  To add on to https://stackoverflow.com/a/582337/1070617,  I wrote this module that allows you to use cProfile and view its output easily. More here: https://github.com/ymichael/cprofilev  $ python -m cprofilev /your/python/program # Go to http://localhost:4000 to view collected statistics.   Also see: http://ymichael.com/2014/03/08/profiling-python-with-cprofile.html on how to make sense of the collected statistics.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "3", "A_Content": "  A new tool to handle profiling in Python is PyVmMonitor: http://www.pyvmmonitor.com/  It has some unique features such as   Attach profiler to a running (CPython) program On demand profiling with Yappi integration Profile on a different machine Multiple processes support (multiprocessing, django...) Live sampling/CPU view (with time range selection) Deterministic profiling through cProfile/profile integration Analyze existing PStats results Open DOT files Programatic API access Group samples by method or line PyDev integration PyCharm integration   Note: it's commercial, but free for open source.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "3", "A_Content": "  I recently created tuna for visualizing Python runtime and import profiles; this may be helpful here.    Install with  pip3 install tuna   Create a runtime profile  python -mcProfile -o program.prof yourfile.py   or an import profile (Python 3.7+ required)  python -X importprofile yourfile.py 2> import.log   Then just run tuna on the file  tuna program.prof      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "1", "A_Content": "  There's also a statistical profiler called statprof. It's a sampling profiler, so it adds minimal overhead to your code and gives line-based (not just function-based) timings. It's more suited to soft real-time applications like games, but may be have less precision than cProfile.  The version in pypi is a bit old, so can install it with pip by specifying the git repository:  pip install git+git://github.com/bos/statprof.py@1a33eba91899afe17a8b752c6dfdec6f05dd0c01   You can run it like this:  import statprof  with statprof.profile():     my_questionable_function()   See also https://stackoverflow.com/a/10333592/320036     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "1", "A_Content": "  It would depend on what you want to see out of profiling. Simple time  metrics can be given by (bash).   time python python_prog.py   Even '/usr/bin/time' can output detailed metrics by using '--verbose' flag.  To check time metrics given by each function and to better understand how much time is spent on functions, you can use the inbuilt cProfile in python.   Going into more detailed metrics like performance, time is not the only metric. You can worry about memory, threads etc. Profiling options: 1. line_profiler is another profiler used commonly to find out timing metrics line-by-line. 2. memory_profiler is a tool to profile memory usage. 3. heapy (from project Guppy) Profile how objects in the heap are used.   These are some of the common ones I tend to use. But if you want to find out more, try reading this book It is a pretty good book on starting out with performance in mind. You can move onto advanced topics on using Cython and JIT(Just-in-time) compiled python.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/582336/how-can-you-profile-a-script", "Language": "Python", "Q_Title": "How can you profile a script?", "Q_Votes": "993", "Q_Content": "    Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.  What is a good way to profile how long a python program takes to run?     ", "Tags": ["python", "performance", "profiling", "time-complexity"], "A_Votes": "0", "A_Content": "  When i'm not root on the server, I use  lsprofcalltree.py and run my program like this:  python lsprofcalltree.py -o callgrind.1 test.py   Then I can open the report with any callgrind-compatible software, like qcachegrind     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "273", "A_Content": "  Excellent answers so far but some tidbits are missing. A single leading underscore isn't exactly just a convention: if you use from foobar import *, and module foobar does not define an __all__ list, the names imported from the module do not include those with a leading underscore. Let's say it's mostly a convention, since this case is a pretty obscure corner;-).  The leading-underscore convention is widely used not just for private names, but also for what C++ would call protected ones -- for example, names of methods that are fully intended to be overridden by subclasses (even ones that have to be overridden since in the base class they raise NotImplementedError!-) are often single-leading-underscore names to indicate to code using instances of that class (or subclasses) that said methods are not meant to be called directly.  For example, to make a thread-safe queue with a different queueing discipline than FIFO, one imports Queue, subclasses Queue.Queue, and overrides such methods as _get and _put; \"client code\" never calls those (\"hook\") methods, but rather the (\"organizing\") public methods such as put and get (this is known as the Template Method design pattern -- see e.g. here for an interesting presentation based on a video of a talk of mine on the subject, with the addition of synopses of the transcript).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "249", "A_Content": "  __foo__: this is just a convention, a way for the Python system to use names that won't conflict with user names.  _foo: this is just a convention, a way for the programmer to indicate that the variable is private (whatever that means in Python).  __foo: this has real meaning: the interpreter replaces this name with _classname__foo as a way to ensure that the name will not overlap with a similar name in another class.  No other form of underscores have meaning in the Python world.  There's no difference between class, variable, global, etc in these conventions.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "180", "A_Content": "  ._variable is semiprivate and meant just for convention  .__variable is often incorrectly considered superprivate, while it's actual meaning is just to namemangle to prevent accidental access[1]  .__variable__ is typically reserved for builtin methods or variables  You can still access .__mangled variables if you desperately want to. The double underscores just namemangles, or renames, the variable to something like instance._className__mangled  Example:  class Test(object):     def __init__(self):         self.__a = 'a'         self._b = 'b'  >>> t = Test() >>> t._b 'b'   t._b is accessible because it is only hidden by convention  >>> t.__a Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: 'Test' object has no attribute '__a'   t.__a isn't found because it no longer exists due to namemangling  >>> t._Test__a 'a'   By accessing instance._className__variable instead of just the double underscore name, you can access the hidden value     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "89", "A_Content": "  Single underscore at the beginning:  Python doesn't have real private methods. Instead, one underscore at the start of a method or attribute name means you shouldn't access this method, because it's not part of the API.  class BaseForm(StrAndUnicode):      def _get_errors(self):         \"Returns an ErrorDict for the data provided for the form\"         if self._errors is None:             self.full_clean()         return self._errors      errors = property(_get_errors)   (This code snippet was taken from django source code: django/forms/forms.py). In this code, errors is a public property, but the method this property calls, _get_errors, is \"private\", so you shouldn't access it.  Two underscores at the beginning:  This causes a lot of confusion. It should not be used to create a private method. It should be used to avoid your method being overridden by a subclass or accessed accidentally. Let's see an example:  class A(object):     def __test(self):         print \"I'm a test method in class A\"      def test(self):         self.__test()  a = A() a.test() # a.__test() # This fails with an AttributeError a._A__test() # Works! We can access the mangled name directly!   Output:   $ python test.py I'm test method in class A I'm test method in class A   Now create a subclass B and do customization for __test method  class B(A):     def __test(self):         print \"I'm test method in class B\"  b = B() b.test()   Output will be....  $ python test.py I'm test method in class A   As we have seen, A.test() didn't call B.__test() methods, as we might expect. But in fact, this is the correct behavior for __. The two methods called __test() are automatically renamed (mangled) to _A__test() and _B__test(), so they do not accidentally override.  When you create a method starting with __ it means that you don't want to anyone to be able to override it, and you only intend to access it from inside its own class.  Two underscores at the beginning and at the end:  When we see a method like __this__, don't call it. This is a method which python is meant to call, not you. Let's take a look:  >>> name = \"test string\" >>> name.__len__() 11 >>> len(name) 11  >>> number = 10 >>> number.__add__(40) 50 >>> number + 50 60   There is always an operator or native function which calls these magic methods. Sometimes it's just a hook python calls in specific situations. For example __init__() is called when the object is created after __new__() is called to build the instance...  Let's take an example...  class FalseCalculator(object):      def __init__(self, number):         self.number = number      def __add__(self, number):         return self.number - number      def __sub__(self, number):         return self.number + number  number = FalseCalculator(20) print number + 10      # 10 print number - 20      # 40   For more details, see the PEP-8 guide. For more magic methods, see this PDF.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "15", "A_Content": "  Sometimes you have what appears to be a tuple with a leading underscore as in   def foo(bar):     return _('my_' + bar)   In this case, what's going on is that _() is an alias for a localization function that operates on text to put it into the proper language, etc. based on the locale. For example, Sphinx does this, and you'll find among the imports  from sphinx.locale import l_, _   and in sphinx.locale, _() is assigned as an alias of some localization function.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "10", "A_Content": "  Underscore (_) in Python  Following are different places where _ is used in Python:  Single Underscore:   In Interpreter After a name Before a name   Double Underscore:   __leading_double_underscore before_after Single Underscore   In Interpreter:  _ returns the value of last executed expression value in Python REPL  >>> a = 10 >>> b = 10 >>> _ Traceback (most recent call last): File \"<stdin>\", line 1, in <module> NameError: name '_' is not defined >>> a+b 20 >>> _ 20 >>> _ * 2 40 >>> _ 40 >>> _ / 2 20   For ignoring values:  Multiple time we do not want return values at that time assign those values to wnderscore. It used as throwaway variable.  # Ignore a value of specific location/index for _ in rang(10)     print \"Test\"  # Ignore a value when unpacking a,b,_,_ = my_method(var1)   After a name  Python has their by default keywords which we can not use as the variable name. To avoid such conflict between python keyword and variable we use underscore after name  Example:  >>> class MyClass(): ...     def __init__(self): ...             print \"OWK\"  >>> def my_defination(var1 = 1, class_ = MyClass): ...     print var1 ...     print class_  >>> my_defination() 1 __main__.MyClass >>>   Before a name  Leading Underscore before variable/function/method name indicates to programmer that It is for internal use only, that can be modified whenever class want.  Here name prefix by underscore is treated as non-public. If specify from Import * all the name starts with _ will not import.  Python does not specify truly private so this ones can be call directly from other modules if it is specified in all, We also call it weak Private  class Prefix: ...     def __init__(self): ...             self.public = 10 ...             self._private = 12 >>> test = Prefix() >>> test.public 10 >>> test._private 12 Python class_file.py  def public_api():     print \"public api\"  def _private_api():     print \"private api\"   Calling file from REPL  >>> from class_file import * >>> public_api() public api  >>> _private_api() Traceback (most recent call last): File \"<stdin>\", line 1, in <module> NameError: name '_private_api' is not defined  >>> import class_file >>> class_file.public_api() public api >>> class_file._private_api() private api Double Underscore(__)   __leading_double_underscore  Leading double underscore tell python interpreter to rewrite name in order to avoid conflict in subclass.Interpreter changes variable name with class extension and that feature known as the Mangling. testFile.py  class Myclass():     def __init__(self):         self.__variable = 10   Calling from REPL  >>> import testFile >>> obj = testFile.Myclass() >>> obj.__variable Traceback (most recent call last): File \"\", line 1, in AttributeError: Myclass instance has no attribute '__variable' nce has no attribute 'Myclass' >>> obj._Myclass__variable 10   In Mangling python interpreter modify variable name with ___. So Multiple time It use as the Private member because another class can not access that variable directly. Main purpose for __ is to use variable/method in class only If you want to use it outside of the class you can make public api  class Myclass():     def __init__(self):         self.__variable = 10     def func(self)         print self.__variable   Calling from REPL  >>> import testFile >>> obj = testFile.Myclass() >>> obj.func() 10   __BEFORE_AFTER__  Name with start with __ and ends with same considers special methods in Python. Python provide this methods to use it as the operator overloading depending on the user.  Python provides this convention to differentiate between the user defined function with the module\u2019s function  class Myclass():     def __add__(self,a,b):         print a*b   Calling from REPL  >>> import testFile >>> obj = testFile.Myclass() >>> obj.__add__(1,2) 2 >>> obj.__add__(5,2) 10   Reference     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "7", "A_Content": "  If one really wants to make a variable read-only, IMHO the best way would be to use property() with only getter passed to it. With property() we can have complete control over the data.  class PrivateVarC(object):      def get_x(self):         pass      def set_x(self, val):         pass      rwvar = property(get_p, set_p)        ronly = property(get_p)    I understand that OP asked a little different question but since I found another question asking for 'how to set private variables' marked duplicate with this one, I thought of adding this additional info here.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "5", "A_Content": "  Single leading underscores is a convention. there is no difference from the interpreter's point of view if whether names starts with a single underscore or not.   Double leading and trailing underscores are used for built-in methods, such as __init__, __bool__, etc.  Double leading underscores w/o trailing counterparts are a convention too, however, the class methods will be mangled by the interpreter. For variables or basic function names no difference exists.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "3", "A_Content": "  Your question is good, it is not only about methods. Functions and objects in modules are commonly prefixed with one underscore as well, and can be prefixed by two.  But __double_underscore names are not name-mangled in modules, for example. What happens is that names beginning with one (or more) underscores are not imported if you import all from a module (from module import *), nor are the names shown in help(module).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "3", "A_Content": "  Here is a simple illustrative example on how double underscore properties can affect an inherited class. So with the following setup:  class parent(object):     __default = \"parent\"     def __init__(self, name=None):         self.default = name or self.__default      @property     def default(self):         return self.__default      @default.setter     def default(self, value):         self.__default = value   class child(parent):     __default = \"child\"   if you then create a child instance in the python REPL, you will see the below  child_a = child() child_a.default            # 'parent' child_a._child__default    # 'child' child_a._parent__default   # 'parent'  child_b = child(\"orphan\") ## this will show  child_b.default            # 'orphan' child_a._child__default    # 'child' child_a._parent__default   # 'orphan'   This may be obvious to some, but it caught me off guard in a much more complex environment     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "3", "A_Content": "  \u201cPrivate\u201d instance variables that cannot be accessed except from inside an object don\u2019t exist in Python. However, there is a convention that is followed by most Python code: a name prefixed with an underscore (e.g. _spam) should be treated as a non-public part of the API (whether it is a function, a method or a data member). It should be considered an implementation detail and subject to change without notice.  reference https://docs.python.org/2/tutorial/classes.html#private-variables-and-class-local-references     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-a-single-and-a-double-underscore-before-an-object-name", "Language": "Python", "Q_Title": "What is the meaning of a single- and a double-underscore before an object name?", "Q_Votes": "1003", "Q_Content": "    I want to clear this up once and for all. Can someone please explain the exact meaning of having leading underscores before an object's name in Python? Also explain the difference between a single and a double leading underscore. Also, does that meaning stay the same whether the object in question is a variable, a function, a method, etc?     ", "Tags": ["python", "naming-conventions", "private", "underscores", "double-underscore"], "A_Votes": "0", "A_Content": "  Getting the facts of _ and __ is pretty easy; the other answers express them pretty well. The usage is much harder to determine.   This is how I see it:  _   Should be used to indicate that a function is not for public use as for example an API. This and the import restriction make it behave much like internal in c#.  __   Should be used to avoid name collision in the inheritace hirarchy and to avoid latebinding. Much like private in c#.  ==>   If you want to indicate that something is not for public use, but it should act like protected use _. If you want to indicate that something is not for public use, but it should act like private use __.  This is also a quote that I like very much:     The problem is that the author of a class may legitimately think \"this   attribute/method name should be private, only accessible from within   this class definition\" and use the __private convention. But later on,   a user of that class may make a subclass that legitimately needs   access to that name. So either the superclass has to be modified   (which may be difficult or impossible), or the subclass code has to   use manually mangled names (which is ugly and fragile at best).   But the problem with that is in my opinion that if there's no IDE that warns you when you override methods, finding the error might take you a while if you have accidentially overriden a method from a base-class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/81584/what-ide-to-use-for-python", "Language": "Python", "Q_Title": "What IDE to use for Python? [closed]", "Q_Votes": "1028", "Q_Content": "    What IDEs (\"GUIs/editors\") do others use for Python coding?     ", "Tags": ["python", "ide", "editor"], "A_Votes": "1240", "A_Content": "    Results  Spreadsheet version    Alternatively, in plain text: (also available as a a screenshot)                         Bracket Matching -.  .- Line Numbering                         Smart Indent -.  |  |  .- UML Editing / Viewing        Source Control Integration -.  |  |  |  |  .- Code Folding                   Error Markup -.  |  |  |  |  |  |  .- Code Templates Integrated Python Debugging -.  |  |  |  |  |  |  |  |  .- Unit Testing   Multi-Language Support -.  |  |  |  |  |  |  |  |  |  |  .- GUI Designer (Qt, Eric, etc)  Auto Code Completion -.  |  |  |  |  |  |  |  |  |  |  |  |  .- Integrated DB Support    Commercial/Free -.  |  |  |  |  |  |  |  |  |  |  |  |  |  |  .- Rapid Application  Cross Platform -.  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |     Development                 +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+  Atom           |Y |F |Y |Y*|Y |Y |Y |Y |Y |Y |  |Y |Y |  |  |  |  |*many plugins  Editra         |Y |F |Y |Y |  |  |Y |Y |Y |Y |  |Y |  |  |  |  |  |  Emacs          |Y |F |Y |Y |Y |Y |Y |Y |Y |Y |Y |Y |Y |Y |  |  |  |  Eric Ide       |Y |F |Y |  |Y |Y |  |Y |  |Y |  |Y |  |Y |  |  |  |  Geany          |Y |F |Y*|Y |  |  |  |Y |Y |Y |  |Y |  |  |  |  |  |*very limited  Gedit          |Y |F |Y\u00b9|Y |  |  |  |Y |Y |Y |  |  |Y\u00b2|  |  |  |  |\u00b9with plugin; \u00b2sort of  Idle           |Y |F |Y |  |Y |  |  |Y |Y |  |  |  |  |  |  |  |  |  JEdit          |Y |F |  |Y |  |  |  |  |Y |Y |  |Y |  |  |  |  |  |  KDevelop       |Y |F |  |Y |  |  |Y |Y |Y |Y |  |Y |  |  |  |  |  |  Komodo         |Y |CF|Y |Y |Y |Y |Y |Y |Y |Y |  |Y |Y |Y |  |Y |  |  NetBeans*      |Y |F |Y |Y |Y |  |Y |Y |Y |Y |Y |Y |Y |Y |  |  |Y |*pre-v7.0  Notepad++      |W |F |Y |Y |  |Y*|Y*|Y*|Y |Y |  |Y |Y*|  |  |  |  |*with plugin  Pfaide         |W |C |Y |Y |  |  |  |Y |Y |Y |  |Y |Y |  |  |  |  |  PIDA           |LW|F |Y |Y |  |  |  |Y |Y |Y |  |Y |  |  |  |  |  |VIM based  PTVS           |W |F |Y |Y |Y |Y |Y |Y |Y |Y |  |Y |  |  |Y*|  |Y |*WPF bsed  PyCharm        |Y |CF|Y |Y*|Y |Y |Y |Y |Y |Y |Y |Y |Y |Y |Y |Y |  |*JavaScript  PyDev(Eclipse) |Y |F |Y |Y |Y |Y |Y |Y |Y |Y |Y |Y |Y |Y |  |  |  |  Pyscripter     |W |F |Y |  |Y |Y |  |Y |  |Y |  |  |Y |Y |  |  |  |  PythonWin      |W |F |Y |  |Y |  |  |Y |Y |  |  |Y |  |  |  |  |  |  SciTE          |Y |F\u00b9|  |Y |  |Y |  |Y |Y |Y |  |Y |Y |  |  |  |  |\u00b9Mac version is  ScriptDev      |W |C |Y |Y |Y |Y |  |Y |Y |Y |  |Y |Y |  |  |  |  |    commercial  Spyder         |Y |F |Y |  |Y |Y |  |Y |Y |Y |  |  |  |  |  |  |  |  Sublime Text   |Y |CF|Y |Y |  |Y |Y |Y |Y |Y |  |Y |Y |Y*|  |  |  |extensible w/Python,  TextMate       |M |F |  |Y |  |  |Y |Y |Y |Y |  |Y |Y |  |  |  |  |    *PythonTestRunner  UliPad         |Y |F |Y |Y |Y |  |  |Y |Y |  |  |  |Y |Y |  |  |  |  Vim            |Y |F |Y |Y |Y |Y |Y |Y |Y |Y |  |Y |Y |Y |  |  |  |  Visual Studio  |W |CF|Y |Y |Y |? |Y |Y |Y |Y |? |Y |? |? |? |? |? |  WingIde        |Y |C |Y |Y*|Y |Y |Y |Y |Y |Y |  |Y |Y |Y |  |  |  |*support for C  Zeus           |W |C |  |  |  |  |Y |Y |Y |Y |  |Y |Y |  |  |  |  |                 +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+  Cross Platform -'  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |     Development    Commercial/Free -'  |  |  |  |  |  |  |  |  |  |  |  |  |  |  '- Rapid Application  Auto Code Completion -'  |  |  |  |  |  |  |  |  |  |  |  |  '- Integrated DB Support   Multi-Language Support -'  |  |  |  |  |  |  |  |  |  |  '- GUI Designer (Qt, Eric, etc) Integrated Python Debugging -'  |  |  |  |  |  |  |  |  '- Unit Testing                   Error Markup -'  |  |  |  |  |  |  '- Code Templates        Source Control Integration -'  |  |  |  |  '- Code Folding                         Smart Indent -'  |  |  '- UML Editing / Viewing                        Bracket Matching -'  '- Line Numbering     Acronyms used:   L  - Linux  W  - Windows  M  - Mac  C  - Commercial  F  - Free  CF - Commercial with Free limited edition  ?  - To be confirmed   I don't mention basics like syntax highlighting as I expect these by default.    This is a just dry list reflecting your feedback and comments, I am not advocating any of these tools. I will keep updating this list as you keep posting your answers.  PS. Can you help me to add features of the above editors to the list (like auto-complete, debugging, etc.)?  We have a comprehensive wiki page for this question https://wiki.python.org/moin/IntegratedDevelopmentEnvironments  Submit edits to the spreadsheet     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "1610", "A_Content": "  >>> str(10) '10' >>> int('10') 10   Links to the documentation:   int()   str()   The problem seems to come from this line: d.str().   Conversion to a string is done with the builtin str() function, which basically calls the __str__() method of its parameter.  Also, it shouldn't be necessary to call pow(). Try using the ** operator.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "83", "A_Content": "  Try this:  str(i)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "43", "A_Content": "  There is not typecast and no type coercion in Python. You have to convert your variable in an explicit way.  To convert an object in string you use the str() function. It works with any object that has a method  called __str__() defined. In fact  str(a)   is equivalent to  a.__str__()   The same if you want to convert something to int, float, etc.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "20", "A_Content": "  a = 2   You can use str(a) which gives you a string object of int(2).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "15", "A_Content": "  To manage non-integer inputs:  number = raw_input() try:     value = int(number) except ValueError:     value = 0     Ok, if I take your latest code and rewrite a bit to get it working with Python:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d2=str(d)     c.append(d2[0]) for j in c:     print j   It gives me something like:  >>> 2 >>> 8 2 >>> 2 3 6 8   Which is the first characters of the string result pow(a,b). What are we trying to do here?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "12", "A_Content": "  >>> i = 5 >>> print \"Hello, world the number is \" + i TypeError: must be str, not int >>> s = str(i) >>> print \"Hello, world the number is \" + s Hello, world the number is 5      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "6", "A_Content": "  The most decent way in my opinion is ``.  i = 32   -->    `i` == '32'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "3", "A_Content": "  Can use %s or .format  >>> \"%s\" % 10 '10' >>>   (OR)  >>> '{}'.format(10) '10' >>>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "1", "A_Content": "  For someone who wants to convert int to string in specific digits, the below method is recommended.  month = \"{0:04d}\".format(localtime[1])   For more details, you can refer to Stack Overflow question Display number with leading zeros.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/961632/converting-integer-to-string-in-python", "Language": "Python", "Q_Title": "Converting integer to string in Python?", "Q_Votes": "1017", "Q_Content": "    I want to convert an integer to a string in Python. I am typecasting it in vain:  t=raw_input() c=[] for j in range(0,int(t)):     n=raw_input()     a=[]     a,b= (int(i) for i in n.split(' '))     d=pow(a,b)     d.str()     c.append(d[0]) for j in c:     print j   When I try to convert it to string, it's showing an error like int doesn't have any attribute called str.     ", "Tags": ["python"], "A_Votes": "1", "A_Content": "  In Python => 3.6 you can use f formatting:  >>> int_value = 10 >>> f'{int_value}' '10' >>>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "1633", "A_Content": "  Strings:  >>> n = '4' >>> print n.zfill(3) 004   And for numbers:  >>> n = 4 >>> print '%03d' % n 004 >>> print format(n, '03') # python >= 2.6 004 >>> print '{0:03d}'.format(n)  # python >= 2.6 004 >>> print '{foo:03d}'.format(foo=n)  # python >= 2.6 004 >>> print('{:03d}'.format(n))  # python >= 2.7 + python3 004 >>> print('{0:03d}'.format(n))  # python 3 004 >>> print(f'{n:03}') # python >= 3.6 004   String formatting documentation.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "278", "A_Content": "  Just use the rjust method of the string object.  This example will make a string of 10 characters long, padding as necessary.  >>> t = 'test' >>> t.rjust(10, '0') >>> '000000test'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "86", "A_Content": "  For numbers:  print \"%05d\" % number   See also: Python: String formatting.  EDIT: It's worth noting that as of yesterday December 3rd, 2008, this method of formatting is deprecated in favour of the format string method:  print(\"{0:05d}\".format(number)) # or print(format(number, \"05d\"))   See PEP 3101 for details.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "44", "A_Content": "  >>> '99'.zfill(5) '00099' >>> '99'.rjust(5,'0') '00099'   if you want the opposite:  >>> '99'.ljust(5,'0') '99000'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "41", "A_Content": "  Works in both Python 2 and Python 3:  >>> \"{:0>2}\".format(\"1\")  # Works for both numbers and strings. '01' >>> \"{:02}\".format(1)  # Only works for numbers. '01'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "32", "A_Content": "  str(n).zfill(width) will work with strings, ints, floats... and is Python 2.x and 3.x compatible:  >>> n = 3 >>> str(n).zfill(5) '00003' >>> n = '3' >>> str(n).zfill(5) '00003' >>> n = '3.0' >>> str(n).zfill(5) '003.0'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "16", "A_Content": "  For the ones who came here to understand and not just a quick answer. I do these especially for time strings:  hour = 4 minute = 3 \"{:0>2}:{:0>2}\".format(hour,minute) # prints 04:03  \"{:0>3}:{:0>5}\".format(hour,minute) # prints '004:00003'  \"{:0<3}:{:0<5}\".format(hour,minute) # prints '400:30000'  \"{:$<3}:{:#<5}\".format(hour,minute) # prints '4$$:3####'      \"0\" symbols what to replace with the \"2\" padding characters, the default is an empty space      \">\" symbols allign all the 2 \"0\" character to the left of the string      \":\" symbols the format_spec      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "14", "A_Content": "  width = 10 x = 5 print \"%0*d\" % (width, x) > 0000000005   See the print documentation for all the exciting details!  Update for Python 3.x (7.5 years later)  That last line should now be:  print(\"%0*d\" % (width, x))   I.e. print() is now a function, not a statement. Note that I still prefer the Old School printf() style because, IMNSHO, it reads better, and because, um, I've been using that notation since January, 1980. Something ... old dogs .. something something ... new tricks.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "4", "A_Content": "  >>> width = 4 >>> x = 5 >>> print(\"%0*d\" %(width,x)) >>> 00005   this will work in python 3.x     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "4", "A_Content": "  For zip codes saved as integers:  >>> a = 6340 >>> b = 90210 >>> print '%05d' % a 06340 >>> print '%05d' % b 90210      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "4", "A_Content": "     What is the most pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?   str.zfill is specifically intended to do this:  >>> '1'.zfill(4) '0001'   Note that it is specifically intended to handle numeric strings as requested, and moves a + or - to the beginning of the string:  >>> '+1'.zfill(4) '+001' >>> '-1'.zfill(4) '-001'   Here's the help on str.zfill:  >>> help(str.zfill) Help on method_descriptor:  zfill(...)     S.zfill(width) -> str      Pad a numeric string S with zeros on the left, to fill a field     of the specified width. The string S is never truncated.   Performance  This is also the most performant of alternative methods:  >>> min(timeit.repeat(lambda: '1'.zfill(4))) 0.18824880896136165 >>> min(timeit.repeat(lambda: '1'.rjust(4, '0'))) 0.2104538488201797 >>> min(timeit.repeat(lambda: f'{1:04}')) 0.32585487607866526 >>> min(timeit.repeat(lambda: '{:04}'.format(1))) 0.34988890308886766   To best compare apples to apples for the % method (note it is actually slower), which will otherwise pre-calculate:  >>> min(timeit.repeat(lambda: '1'.zfill(0 or 4))) 0.19728074967861176 >>> min(timeit.repeat(lambda: '%04d' % (0 or 1))) 0.2347015216946602   Implementation  With a little digging, I found the implementation of the zfill method in Objects/stringlib/transmogrify.h:  static PyObject * stringlib_zfill(PyObject *self, PyObject *args) {     Py_ssize_t fill;     PyObject *s;     char *p;     Py_ssize_t width;      if (!PyArg_ParseTuple(args, \"n:zfill\", &width))         return NULL;      if (STRINGLIB_LEN(self) >= width) {         return return_self(self);     }      fill = width - STRINGLIB_LEN(self);      s = pad(self, fill, 0, '0');      if (s == NULL)         return NULL;      p = STRINGLIB_STR(s);     if (p[fill] == '+' || p[fill] == '-') {         /* move sign to beginning of string */         p[0] = p[fill];         p[fill] = '0';     }      return s; }   Let's walk through this C code.  It first parses the argument positionally, meaning it doesn't allow keyword arguments:   >>> '1'.zfill(width=4) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: zfill() takes no keyword arguments   It then checks if it's the same length or longer, in which case it returns the string.  >>> '1'.zfill(0) '1'   zfill calls pad (this pad function is also called by ljust, rjust, and center as well). This basically copies the contents into a new string and fills in the padding.  static inline PyObject * pad(PyObject *self, Py_ssize_t left, Py_ssize_t right, char fill) {     PyObject *u;      if (left < 0)         left = 0;     if (right < 0)         right = 0;      if (left == 0 && right == 0) {         return return_self(self);     }      u = STRINGLIB_NEW(NULL, left + STRINGLIB_LEN(self) + right);     if (u) {         if (left)             memset(STRINGLIB_STR(u), fill, left);         memcpy(STRINGLIB_STR(u) + left,                STRINGLIB_STR(self),                STRINGLIB_LEN(self));         if (right)             memset(STRINGLIB_STR(u) + left + STRINGLIB_LEN(self),                    fill, right);     }      return u; }   After calling pad, zfill moves any originally preceding + or - to the beginning of the string.   Note that for the original string to actually be numeric is not required:  >>> '+foo'.zfill(10) '+000000foo' >>> '-foo'.zfill(10) '-000000foo'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "3", "A_Content": "  Quick timing comparison:  setup = ''' from random import randint def test_1():     num = randint(0,1000000)     return str(num).zfill(7) def test_2():     num = randint(0,1000000)     return format(num, '07') def test_3():     num = randint(0,1000000)     return '{0:07d}'.format(num) def test_4():     num = randint(0,1000000)     return format(num, '07d') def test_5():     num = randint(0,1000000)     return '{:07d}'.format(num) def test_6():     num = randint(0,1000000)     return '{x:07d}'.format(x=num) def test_7():     num = randint(0,1000000)     return str(num).rjust(7, '0') ''' import timeit print timeit.Timer(\"test_1()\", setup=setup).repeat(3, 900000) print timeit.Timer(\"test_2()\", setup=setup).repeat(3, 900000) print timeit.Timer(\"test_3()\", setup=setup).repeat(3, 900000) print timeit.Timer(\"test_4()\", setup=setup).repeat(3, 900000) print timeit.Timer(\"test_5()\", setup=setup).repeat(3, 900000) print timeit.Timer(\"test_6()\", setup=setup).repeat(3, 900000) print timeit.Timer(\"test_7()\", setup=setup).repeat(3, 900000)   > [2.281613943830961, 2.2719342631547077, 2.261691106209631] > [2.311480238815406, 2.318420542148333, 2.3552384305184493] > [2.3824197456864304, 2.3457239951596485, 2.3353268829498646] > [2.312442972404032, 2.318053102249902, 2.3054072168069872] > [2.3482314132374853, 2.3403386400002475, 2.330108825844775] > [2.424549090688892, 2.4346475296851438, 2.429691196530058] > [2.3259756401716487, 2.333549212826732, 2.32049893822186]   I've made different tests of different repetitions. The differences are not huge, but in all tests, the zfill solution was fastest.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/339007/nicest-way-to-pad-zeroes-to-a-string", "Language": "Python", "Q_Title": "Nicest way to pad zeroes to a string", "Q_Votes": "1030", "Q_Content": "    What is the most Pythonic way to pad a numeric string with zeroes to the left, i.e., so the numeric string has a specific length?     ", "Tags": ["python", "string"], "A_Votes": "-2", "A_Content": "  You could also repeat \"0\", prepend it to str(n) and get the rightmost width slice. Quick and dirty little expression.  def pad_left(n, width, pad=\"0\"):     return ((pad * width) + str(n))[-width:]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510972/getting-the-class-name-of-an-instance", "Language": "Python", "Q_Title": "Getting the class name of an instance?", "Q_Votes": "1036", "Q_Content": "    How do I find out a name of class that created an instance of an object in Python if the function I am doing this from is the base class of which the class of the instance has been derived?  Was thinking maybe the inspect module might have helped me out here, but it doesn't seem to give me what I want. And short of parsing the __class__ member, I'm not sure how to get at this information.     ", "Tags": ["python", "introspection", "instanceof", "python-datamodel"], "A_Votes": "1383", "A_Content": "  Have you tried the __name__ attribute of the class? ie type(x).__name__ will give you the name of the class, which I think is what you want.  >>> import itertools >>> x = itertools.count(0) >>> type(x).__name__ 'count'   This method works with new-style classes only. Your code might use some old-style classes. The following works for both:  x.__class__.__name__      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/510972/getting-the-class-name-of-an-instance", "Language": "Python", "Q_Title": "Getting the class name of an instance?", "Q_Votes": "1036", "Q_Content": "    How do I find out a name of class that created an instance of an object in Python if the function I am doing this from is the base class of which the class of the instance has been derived?  Was thinking maybe the inspect module might have helped me out here, but it doesn't seem to give me what I want. And short of parsing the __class__ member, I'm not sure how to get at this information.     ", "Tags": ["python", "introspection", "instanceof", "python-datamodel"], "A_Votes": "284", "A_Content": "  Do you want the name of the class as a string?  instance.__class__.__name__      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510972/getting-the-class-name-of-an-instance", "Language": "Python", "Q_Title": "Getting the class name of an instance?", "Q_Votes": "1036", "Q_Content": "    How do I find out a name of class that created an instance of an object in Python if the function I am doing this from is the base class of which the class of the instance has been derived?  Was thinking maybe the inspect module might have helped me out here, but it doesn't seem to give me what I want. And short of parsing the __class__ member, I'm not sure how to get at this information.     ", "Tags": ["python", "introspection", "instanceof", "python-datamodel"], "A_Votes": "72", "A_Content": "  type() ?  >>> class A(object): ...    def whoami(self): ...       print type(self).__name__ ... >>> >>> class B(A): ...    pass ... >>> >>> >>> o = B() >>> o.whoami() 'B' >>>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510972/getting-the-class-name-of-an-instance", "Language": "Python", "Q_Title": "Getting the class name of an instance?", "Q_Votes": "1036", "Q_Content": "    How do I find out a name of class that created an instance of an object in Python if the function I am doing this from is the base class of which the class of the instance has been derived?  Was thinking maybe the inspect module might have helped me out here, but it doesn't seem to give me what I want. And short of parsing the __class__ member, I'm not sure how to get at this information.     ", "Tags": ["python", "introspection", "instanceof", "python-datamodel"], "A_Votes": "26", "A_Content": "  class A:   pass  a = A() str(a.__class__)   The sample code above (when input in the interactive interpreter) will produce '__main__.A' as opposed to 'A' which is produced if the __name__ attribute is invoked. By simply passing the result of A.__class__ to the str constructor the parsing is handled for you. However, you could also use the following code if you want something more explicit.  \"{0}.{1}\".format(a.__class__.__module__,a.__class__.__name__)   This behavior can be preferable if you have classes with the same name defined in separate modules.  The sample code provided above was tested in Python 2.7.5.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510972/getting-the-class-name-of-an-instance", "Language": "Python", "Q_Title": "Getting the class name of an instance?", "Q_Votes": "1036", "Q_Content": "    How do I find out a name of class that created an instance of an object in Python if the function I am doing this from is the base class of which the class of the instance has been derived?  Was thinking maybe the inspect module might have helped me out here, but it doesn't seem to give me what I want. And short of parsing the __class__ member, I'm not sure how to get at this information.     ", "Tags": ["python", "introspection", "instanceof", "python-datamodel"], "A_Votes": "24", "A_Content": "  type(instance).__name__ != instance.__class__.__name  #if class A is defined like class A():    ...  type(instance) == instance.__class__                  #if class A is defined like class A(object):   ...   Example:  >>> class aclass(object): ...   pass ... >>> a = aclass() >>> type(a) <class '__main__.aclass'> >>> a.__class__ <class '__main__.aclass'> >>> >>> type(a).__name__ 'aclass' >>> >>> a.__class__.__name__ 'aclass' >>>   >>> class bclass(): ...   pass ... >>> b = bclass() >>> >>> type(b) <type 'instance'> >>> b.__class__ <class __main__.bclass at 0xb765047c> >>> type(b).__name__ 'instance' >>> >>> b.__class__.__name__ 'bclass' >>>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510972/getting-the-class-name-of-an-instance", "Language": "Python", "Q_Title": "Getting the class name of an instance?", "Q_Votes": "1036", "Q_Content": "    How do I find out a name of class that created an instance of an object in Python if the function I am doing this from is the base class of which the class of the instance has been derived?  Was thinking maybe the inspect module might have helped me out here, but it doesn't seem to give me what I want. And short of parsing the __class__ member, I'm not sure how to get at this information.     ", "Tags": ["python", "introspection", "instanceof", "python-datamodel"], "A_Votes": "13", "A_Content": "  Good question.  Here's a simple example based on GHZ's which might help someone:  >>> class person(object):         def init(self,name):             self.name=name         def info(self)             print \"My name is {0}, I am a {1}\".format(self.name,self.__class__.__name__) >>> bob = person(name='Robert') >>> bob.info() My name is Robert, I am a person      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510972/getting-the-class-name-of-an-instance", "Language": "Python", "Q_Title": "Getting the class name of an instance?", "Q_Votes": "1036", "Q_Content": "    How do I find out a name of class that created an instance of an object in Python if the function I am doing this from is the base class of which the class of the instance has been derived?  Was thinking maybe the inspect module might have helped me out here, but it doesn't seem to give me what I want. And short of parsing the __class__ member, I'm not sure how to get at this information.     ", "Tags": ["python", "introspection", "instanceof", "python-datamodel"], "A_Votes": "4", "A_Content": "  Apart from grabbing the special __name__ attribute, you might find yourself in need of the qualified name for a given class/function. This is done by grabbing the types __qualname__.  In most cases, these will be exactly the same, but, when dealing with nested classes/methods these differ in the output you get. For example:  class Spam:     def meth(self):         pass     class Bar:         pass  >>> s = Spam() >>> type(s).__name__  'Spam' >>> type(s).__qualname__ 'Spam' >>> type(s).Bar.__name__       # type not needed here 'Bar' >>> type(s).Bar.__qualname__   # type not needed here  'Spam.Bar' >>> type(s).meth.__name__ 'meth' >>> type(s).meth.__qualname__ 'Spam.meth'   Since introspection is what you're after, this is always you might want to consider.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/510972/getting-the-class-name-of-an-instance", "Language": "Python", "Q_Title": "Getting the class name of an instance?", "Q_Votes": "1036", "Q_Content": "    How do I find out a name of class that created an instance of an object in Python if the function I am doing this from is the base class of which the class of the instance has been derived?  Was thinking maybe the inspect module might have helped me out here, but it doesn't seem to give me what I want. And short of parsing the __class__ member, I'm not sure how to get at this information.     ", "Tags": ["python", "introspection", "instanceof", "python-datamodel"], "A_Votes": "4", "A_Content": "  Alternatively you can use the classmethod decorator:  class A:     @classmethod     def get_classname(cls):         return cls.__name__      def use_classname(self):         return self.get_classname()   Usage:  >>> A.get_classname() 'A' >>> a = A() >>> a.get_classname() 'A' >>> a.use_classname() 'A'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "2091", "A_Content": "  Answer in one line:  ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(N))   or even shorter starting with Python 3.6 using random.choices():  ''.join(random.choices(string.ascii_uppercase + string.digits, k=N))   A cryptographically more secure version; see https://stackoverflow.com/a/23728630/2213647:  ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(N))   In details, with a clean function for further reuse:  >>> import string >>> import random >>> def id_generator(size=6, chars=string.ascii_uppercase + string.digits): ...    return ''.join(random.choice(chars) for _ in range(size)) ... >>> id_generator() 'G5G74W' >>> id_generator(3, \"6793YUIO\") 'Y3U'   How does it work ?  We import string, a module that contains sequences of common ASCII characters, and random, a module that deals with random generation.  string.ascii_uppercase + string.digits just concatenates the list of characters representing uppercase ASCII chars and digits:  >>> string.ascii_uppercase 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' >>> string.digits '0123456789' >>> string.ascii_uppercase + string.digits 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'   Then we use a list comprehension to create a list of 'n' elements:  >>> range(4) # range create a list of 'n' numbers [0, 1, 2, 3] >>> ['elem' for _ in range(4)] # we use range to create 4 times 'elem' ['elem', 'elem', 'elem', 'elem']   In the example above, we use [ to create the list, but we don't in the id_generator function so Python doesn't create the list in memory, but generates the elements on the fly, one by one (more about this here).  Instead of asking to create 'n' times the string elem, we will ask Python to create 'n' times a random character, picked from a sequence of characters:  >>> random.choice(\"abcde\") 'a' >>> random.choice(\"abcde\") 'd' >>> random.choice(\"abcde\") 'b'   Therefore random.choice(chars) for _ in range(size) really is creating a sequence of size characters. Characters that are randomly picked from chars:  >>> [random.choice('abcde') for _ in range(3)] ['a', 'b', 'b'] >>> [random.choice('abcde') for _ in range(3)] ['e', 'b', 'e'] >>> [random.choice('abcde') for _ in range(3)] ['d', 'a', 'c']   Then we just join them with an empty string so the sequence becomes a string:  >>> ''.join(['a', 'b', 'b']) 'abb' >>> [random.choice('abcde') for _ in range(3)] ['d', 'c', 'b'] >>> ''.join(random.choice('abcde') for _ in range(3)) 'dac'      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "463", "A_Content": "  This Stack Overflow quesion is the current top Google result for \"random string Python\". The current top answer is:  ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(N))   This is an excellent method, but the PRNG in random is not cryptographically secure. I assume many people researching this question will want to generate random strings for encryption or passwords. You can do this securely by making a small change in the above code:  ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(N))   Using random.SystemRandom() instead of just random uses /dev/urandom on *nix machines and CryptGenRandom() in Windows.  These are cryptographically secure PRNGs. Using random.choice instead of random.SystemRandom().choice in an application that requires a secure PRNG could be potentially devastating, and given the popularity of this question, I bet that mistake has been made many times already.  If you're using python3.6 or above, you can use the new secrets module.  ''.join(secrets.choice(string.ascii_uppercase + string.digits) for _ in range(N))   The module docs also discuss convenient ways to generate secure tokens and best practices.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "135", "A_Content": "  Simply use Python's builtin uuid:  If UUIDs are okay for your purposes, use the built-in uuid package.  One Line Solution:  import uuid; uuid.uuid4().hex.upper()[0:6]  In Depth Version:  Example:  import uuid uuid.uuid4() #uuid4 => full random uuid # Outputs something like: UUID('0172fc9a-1dac-4414-b88d-6b9a6feb91ea')   If you need exactly your format (for example, \"6U1S75\"), you can do it like this:  import uuid  def my_random_string(string_length=10):     \"\"\"Returns a random string of length string_length.\"\"\"     random = str(uuid.uuid4()) # Convert UUID format to a Python string.     random = random.upper() # Make all characters uppercase.     random = random.replace(\"-\",\"\") # Remove the UUID '-'.     return random[0:string_length] # Return the random string.  print(my_random_string(6)) # For example, D9E50C      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "41", "A_Content": "  A simpler, faster but slightly less random way is to use random.sample instead of choosing each letter separately, If n-repetitions are allowed, enlarge your random basis by n times e.g.  import random import string  char_set = string.ascii_uppercase + string.digits print ''.join(random.sample(char_set*6, 6))   Note: random.sample prevents character reuse, multiplying the size of the character set makes multiple repetitions possible, but they are still less likely then they are in a pure random choice. If we go for a string of length 6, and we pick 'X' as the first character, in the choice example, the odds of getting 'X' for the second character are the same as the odds of getting 'X' as the first character. In the random.sample implementation, the odds of getting 'X' as any subsequent character are only 6/7 the chance of getting it as the first character     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "24", "A_Content": "  import uuid lowercase_str = uuid.uuid4().hex     lowercase_str is a random value like 'cea8b32e00934aaea8c005a35d85a5c0'  uppercase_str = lowercase_str.upper()   uppercase_str is 'CEA8B32E00934AAEA8C005A35D85A5C0'     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "18", "A_Content": "  Taking the answer from Ignacio, this works with Python 2.6:  import random import string  N=6 print ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(N))   Example output:     JQUBT2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "16", "A_Content": "  A faster, easier and more flexible way to do this is to use the strgen module (pip install StringGenerator).  Generate a 6-character random string with upper case letters and digits:  >>> from strgen import StringGenerator as SG >>> SG(\"[\\u\\d]{6}\").render() u'YZI2CI'   Get a unique list:  >>> SG(\"[\\l\\d]{10}\").render_list(5,unique=True) [u'xqqtmi1pOk', u'zmkWdUr63O', u'PGaGcPHrX2', u'6RZiUbkk2i', u'j9eIeeWgEF']   Guarantee one \"special\" character in the string:  >>> SG(\"[\\l\\d]{10}&[\\p]\").render() u'jaYI0bcPG*0'   A random HTML color:  >>> SG(\"#[\\h]{6}\").render() u'#CEdFCa'   etc.   We need to be aware that this:  ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(N))   might not have a digit (or uppercase character) in it.  strgen is faster in developer-time than any of the above solutions. The solution from Ignacio is the fastest run-time performing and is the right answer using the Python Standard Library. But you will hardly ever use it in that form. You will want to use SystemRandom (or fallback if not available), make sure required character sets are represented, use unicode (or not), make sure successive invocations produce a unique string, use a subset of one of the string module character classes, etc. This all requires lots more code than in the answers provided. The various attempts to generalize a solution all have limitations that strgen solves with greater brevity and expressive power using a simple template language.  It's on PyPI:  pip install StringGenerator   Disclosure: I'm the author of the strgen module.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "8", "A_Content": "  If you need a random string rather than a pseudo random one, you should use os.urandom as the source  from os import urandom from itertools import islice, imap, repeat import string  def rand_string(length=5):     chars = set(string.ascii_uppercase + string.digits)     char_gen = (c for c in imap(urandom, repeat(1)) if c in chars)     return ''.join(islice(char_gen, None, length))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "8", "A_Content": "  I thought no one had answered this yet lol! But hey, here's my own go at it:  import random  def random_alphanumeric(limit):     #ascii alphabet of all alphanumerals     r = (range(48, 58) + range(65, 91) + range(97, 123))     random.shuffle(r)     return reduce(lambda i, s: i + chr(s), r[:random.randint(0, len(r))], \"\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "8", "A_Content": "  Based on another Stack\u00a0Overflow answer, Most lightweight way to create a random string and a random hexadecimal number, a better version than the accepted answer would be:  ('%06x' % random.randrange(16**6)).upper()   much faster.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "6", "A_Content": "  This method is slightly faster, and slightly more annoying, than the random.choice() method Ignacio posted.  It takes advantage of the nature of pseudo-random algorithms, and banks on bitwise and and shift being faster than generating a new random number for each character.  # must be length 32 -- 5 bits -- the question didn't specify using the full set # of uppercase letters ;) _ALPHABET = 'ABCDEFGHJKLMNPQRSTUVWXYZ23456789'  def generate_with_randbits(size=32):     def chop(x):         while x:             yield x & 31             x = x >> 5     return  ''.join(_ALPHABET[x] for x in chop(random.getrandbits(size * 5))).ljust(size, 'A')   ...create a generator that takes out 5 bit numbers at a time 0..31 until none left  ...join() the results of the generator on a random number with the right bits  With Timeit, for 32-character strings, the timing was:  [('generate_with_random_choice', 28.92901611328125),  ('generate_with_randbits', 20.0293550491333)]   ...but for 64 character strings, randbits loses out ;)  I would probably never use this approach in production code unless I really disliked my co-workers.  edit: updated to suit the question (uppercase and digits only), and use bitwise operators & and >> instead of % and //     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "6", "A_Content": "  From Python 3.6 on you should use the secrets module if you need it to be cryptographically secure instead of the random module (otherwise this answer is identical to the one of @Ignacio Vazquez-Abrams):  from secrets import choice import string  ''.join([choice(string.ascii_uppercase + string.digits) for _ in range(N)])   One additional note: a list-comprehension is faster in the case of str.join than using a generator expression!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "4", "A_Content": "  I'd do it this way:  import random from string import digits, ascii_uppercase  legals = digits + ascii_uppercase  def rand_string(length, char_set=legals):      output = ''     for _ in range(length): output += random.choice(char_set)     return output   Or just:  def rand_string(length, char_set=legals):      return ''.join( random.choice(char_set) for _ in range(length) )      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "3", "A_Content": "  Use Numpy's random.choice() function  import numpy as np import string          if __name__ == '__main__':     length = 16     a = np.random.choice(list(string.ascii_uppercase + string.digits), length)                     print(''.join(a))   Documentation is here http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.random.choice.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "2", "A_Content": "  For those of you who enjoy functional python:  from itertools import imap, starmap, islice, repeat from functools import partial from string import letters, digits, join from random import choice  join_chars = partial(join, sep='') identity = lambda o: o  def irand_seqs(symbols=join_chars((letters, digits)), length=6, join=join_chars, select=choice, breakup=islice):     \"\"\" Generates an indefinite sequence of joined random symbols each of a specific length     :param symbols: symbols to select,         [defaults to string.letters + string.digits, digits 0 - 9, lower and upper case English letters.]     :param length: the length of each sequence,         [defaults to 6]     :param join: method used to join selected symbol,          [defaults to ''.join generating a string.]     :param select: method used to select a random element from the giving population.          [defaults to random.choice, which selects a single element randomly]     :return: indefinite iterator generating random sequences of giving [:param length]     >>> from tools import irand_seqs     >>> strings = irand_seqs()     >>> a = next(strings)     >>> assert isinstance(a, (str, unicode))     >>> assert len(a) == 6     >>> assert next(strings) != next(strings)     \"\"\"     return imap(join, starmap(breakup, repeat((imap(select, repeat(symbols)), None, length))))   It generates an indefinite [infinite] iterator, of joined random sequences, by first generating an indefinite sequence of randomly selected symbol from the giving pool, then breaking this sequence into length parts which is then joined, it should work with any sequence that supports getitem, by default it simply generates a random sequence of alpha numeric letters, though you can easily modify to generate other things:  for example to generate random tuples of digits:  >>> irand_tuples = irand_seqs(xrange(10), join=tuple) >>> next(irand_tuples) (0, 5, 5, 7, 2, 8) >>> next(irand_tuples) (3, 2, 2, 0, 3, 1)   if you don't want to use next for generation you can simply make it callable:  >>> irand_tuples = irand_seqs(xrange(10), join=tuple) >>> make_rand_tuples = partial(next, irand_tuples)  >>> make_rand_tuples() (1, 6, 2, 8, 1, 9)   if you want to generate the sequence on the fly simply set join to identity.  >>> irand_tuples = irand_seqs(xrange(10), join=identity) >>> selections = next(irand_tuples) >>> next(selections) 8 >>> list(selections) [6, 3, 8, 2, 2]   As others have mentioned if you need more security then set the appropriate select function:  >>> from random import SystemRandom >>> rand_strs = irand_seqs(select=SystemRandom().choice) 'QsaDxQ'   the default selector is choice which may select the same symbol multiple times for each chunk, if instead you'd want the same member selected at most once for each chunk then, one possible usage:  >>> from random import sample >>> irand_samples = irand_seqs(xrange(10), length=1, join=next, select=lambda pool: sample(pool, 6)) >>> next(irand_samples) [0, 9, 2, 3, 1, 6]   we use sample as our selector, to do the complete selection, so the chunks are actually length 1, and to join we simply call next which fetches the next completely generated chunk, granted this example seems a bit cumbersome and it is ...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "2", "A_Content": "  (1) This will give you all caps and numbers:  import string, random passkey='' for x in range(8):     if random.choice([1,2]) == 1:         passkey += passkey.join(random.choice(string.ascii_uppercase))     else:         passkey += passkey.join(random.choice(string.digits)) print passkey    (2) If you later want to include lowercase letters in your key, then this will also work:  import string, random passkey='' for x in range(8):     if random.choice([1,2]) == 1:         passkey += passkey.join(random.choice(string.ascii_letters))     else:         passkey += passkey.join(random.choice(string.digits)) print passkey        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "2", "A_Content": "  this is a take on Anurag Uniyal 's response and something that i was working on myself.  import random import string  oneFile = open('\u202aNumbers.txt', 'w') userInput = 0 key_count = 0 value_count = 0 chars = string.ascii_uppercase + string.digits + string.punctuation  for userInput in range(int(input('How many 12 digit keys do you want?'))):     while key_count <= userInput:         key_count += 1         number = random.randint(1, 999)         key = number          text = str(key) + \": \" + str(''.join(random.sample(chars*6, 12)))         oneFile.write(text + \"\\n\") oneFile.close()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "1600", "A_Content": "  In Python 2.6 and earlier, the dict constructor can receive an iterable of key/value pairs:  d = dict((key, value) for (key, value) in iterable)   From Python 2.7 and 3 onwards, you can just use the dict comprehension syntax directly:  d = {key: value for (key, value) in iterable}   Of course, you can use the iterable in any way you want (tuples and lists literals, generator comprehensions, list comprehensions, generator functions, functional composition... feel creative) as long as each element is an iterable itself of two elements:  d = {value: foo(value) for value in sequence if bar(value)}  def key_value_gen(k):    yield chr(k+65)    yield chr((k+13)%26+65) d = dict(map(key_value_gen, range(26)))      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "2", "A_Content": "  >>> import string  >>> import random   the following logic still generates 6 character random sample   >>> print ''.join(random.sample((string.ascii_uppercase+string.digits),6)) JT7K3Q   No need to multiply by 6  >>> print ''.join(random.sample((string.ascii_uppercase+string.digits)*6,6))  TK82HK      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "1", "A_Content": "  >>> import random >>> str = [] >>> chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890' >>> num = int(raw_input('How long do you want the string to be?  ')) How long do you want the string to be?  10 >>> for k in range(1, num+1): ...    str.append(random.choice(chars)) ... >>> str = \"\".join(str) >>> str 'tm2JUQ04CK'   The random.choice function picks a random entry in a list. You also create a list so that you can append the character in the for statement. At the end str is ['t', 'm', '2', 'J', 'U', 'Q', '0', '4', 'C', 'K'], but the str = \"\".join(str) takes care of that, leaving you with 'tm2JUQ04CK'.  Hope this helps!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "1", "A_Content": "  A simple one:  import string import random character = string.lowercase + string.uppercase + string.digits + string.punctuation char_len = len(character) # you can specify your password length here pass_len = random.randint(10,20) password = '' for x in range(pass_len):     password = password + character[random.randint(0,char_len-1)] print password      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "1", "A_Content": "  import string from random import * characters = string.ascii_letters + string.punctuation  + string.digits password =  \"\".join(choice(characters) for x in range(randint(8, 16))) print password      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "0", "A_Content": "  I would like to suggest you next option:  import crypt n = 10 crypt.crypt(\"any sring\").replace('/', '').replace('.', '').upper()[-n:-1]   Paranoic mode:  import uuid import crypt n = 10 crypt.crypt(str(uuid.uuid4())).replace('/', '').replace('.', '').upper()[-n:-1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "0", "A_Content": "  Two methods :  import random, math     def randStr_1(chars:str, length:int) -> str:     chars *= math.ceil(length / len(chars))     chars = letters[0:length]     chars = list(chars)     random.shuffle(characters)      return ''.join(chars)     def randStr_2(chars:str, length:int) -> str:     return ''.join(random.choice(chars) for i in range(chars))        Benchmark :   from timeit import timeit  setup = \"\"\" import os, subprocess, time, string, random, math  def randStr_1(letters:str, length:int) -> str:     letters *= math.ceil(length / len(letters))     letters = letters[0:length]     letters = list(letters)     random.shuffle(letters)     return ''.join(letters)  def randStr_2(letters:str, length:int) -> str:     return ''.join(random.choice(letters) for i in range(length)) \"\"\"  print('Method 1 vs Method 2', ', run 10 times each.')  for length in [100,1000,10000,50000,100000,500000,1000000]:     print(length, 'characters:')      eff1 = timeit(\"randStr_1(string.ascii_letters, {})\".format(length), setup=setup, number=10)     eff2 = timeit(\"randStr_2(string.ascii_letters, {})\".format(length), setup=setup, number=10)     print('\\t{}s : {}s'.format(round(eff1, 6), round(eff2, 6)))     print('\\tratio = {} : {}\\n'.format(eff1/eff1, round(eff2/eff1, 2)))   Output :  Method 1 vs Method 2 , run 10 times each.  100 characters:     0.001411s : 0.00179s     ratio = 1.0 : 1.27  1000 characters:     0.013857s : 0.017603s     ratio = 1.0 : 1.27  10000 characters:     0.13426s : 0.151169s     ratio = 1.0 : 1.13  50000 characters:     0.709403s : 0.855136s     ratio = 1.0 : 1.21  100000 characters:     1.360735s : 1.674584s     ratio = 1.0 : 1.23  500000 characters:     6.754923s : 7.160508s     ratio = 1.0 : 1.06  1000000 characters:     11.232965s : 14.223914s     ratio = 1.0 : 1.27   The performance of first method is better.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "0", "A_Content": "  for python 3 import string, random  ''.join(random.choice(string.ascii_lowercase + string.ascii_uppercase + string.digits) for _ in range(15))     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "0", "A_Content": "  import random q=2 o=1 list  =[r'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','s','0','1','2','3','4','5','6','7','8','9','0'] while(q>o):     print(\"\")      for i in range(1,128):         x=random.choice(list)         print(x,end=\"\")   Here length of string can be changed in for loop i.e for i in range(1,length)  It is simple algorithm which is easy to understand. it uses list so you can discard characters that you do not need.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python", "Language": "Python", "Q_Title": "Random string generation with upper case letters and digits in Python", "Q_Votes": "1030", "Q_Content": "    I want to generate a string of size N.  It should be made up of numbers and uppercase English letters such as:   6U1S75 4Z4UKK U911K4   How can I achieve this in a pythonic way?     ", "Tags": ["python", "string", "random"], "A_Votes": "-1", "A_Content": "  I found this to be simpler and cleaner.  str_Key           = \"\" str_FullKey       = \"\"  str_CharacterPool = \"01234ABCDEFfghij~>()\" for int_I in range(64):      str_Key = random.choice(str_CharacterPool)      str_FullKey = str_FullKey + str_Key    Just change the 64 to vary the length, vary the CharacterPool to do alpha only alpha numeric or numeric only or strange characters or whatever you want.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "194", "A_Content": "  In Python 3 and Python 2.7+, dictionary comprehensions look like the below:  d = {k:v for k, v in iterable}   For Python 2.6 or earlier, see fortran's answer.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "40", "A_Content": "  In fact, you don't even need to iterate over the iterable if it already comprehends some kind of mapping, the dict constructor doing it graciously for you:  >>> ts = [(1, 2), (3, 4), (5, 6)] >>> dict(ts) {1: 2, 3: 4, 5: 6} >>> gen = ((i, i+1) for i in range(1, 6, 2)) >>> gen <generator object <genexpr> at 0xb7201c5c> >>> dict(gen) {1: 2, 3: 4, 5: 6}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "31", "A_Content": "  In Python 2.7, it goes like:  >>> list1, list2 = ['a', 'b', 'c'], [1,2,3] >>> dict( zip( list1, list2)) {'a': 1, 'c': 3, 'b': 2}   Zip them!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "13", "A_Content": "  To add onto @fortran's answer, if you want to iterate over a list of keys key_list as well as a list of values value_list:  d = dict((key, value) for (key, value) in zip(key_list, value_list))   or  d = {(key, value) for (key, value) in zip(key_list, value_list)}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "12", "A_Content": "     Create a dictionary with list comprehension in Python      I like the Python list comprehension syntax.      Can it be used to create dictionaries too? For example, by iterating   over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}    Assuming blah blah blah is an iterable of two-tuples - you're so close. Let's create some \"blahs\" like that:  blahs = [('blah0', 'blah'), ('blah1', 'blah'), ('blah2', 'blah'), ('blah3', 'blah')]   Dict comprehension syntax:  Now the syntax here is the mapping part. What makes this a dict comprehension instead of a set comprehension (which is what your pseudo-code approximates) is the colon, : like below:  mydict = {k: v for k, v in blahs}   And now when you do:  >>> mydict {'blah0': 'blah', 'blah1': 'blah', 'blah3': 'blah', 'blah2': 'blah'}   Adding a Filter:  Just like list comprehensions, you can add a filter part to the end:  >>> mydict = {k: v for k, v in blahs if not int(k[-1]) % 2} >>> mydict {'blah0': 'blah', 'blah2': 'blah'}   Here we test for if the last character is divisible by 2.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "11", "A_Content": "  For python version < 2.7, do the below:  d = dict((i,True) for i in [1,2,3])   For python version >= 2.7, do the below:  d = {i: True for i in [1,2,3]}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "6", "A_Content": "  Here is another example of dictionary creation using dict comprehension:  What i am tring to do here is to create a alphabet dictionary where each pair; is the english letter and its corresponding position in english alphabet  >>> import string >>> dict1 = {value: (int(key) + 1) for key, value in  enumerate(list(string.ascii_lowercase))} >>> dict1 {'a': 1, 'c': 3, 'b': 2, 'e': 5, 'd': 4, 'g': 7, 'f': 6, 'i': 9, 'h': 8,  'k': 11, 'j': 10, 'm': 13, 'l': 12, 'o': 15, 'n': 14, 'q': 17, 'p': 16, 's':  19, 'r': 18, 'u': 21, 't': 20, 'w': 23, 'v': 22, 'y': 25, 'x': 24, 'z': 26} >>>    Notice the use of enumerate here to get a list of alphabets and their indexes in the list and swapping the alphabets and indices to generate the key value pair for dictionary  Hope it gives a good idea of dictionary comp to you and encourages you to use it more often to make your code compact     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "3", "A_Content": "  Try this,  def get_dic_from_two_lists(keys, values):     return { keys[i] : values[i] for i in range(len(keys)) }   Assume we have two lists country and capital  country = ['India', 'Pakistan', 'China'] capital = ['New Delhi', 'Islamabad', 'Beijing']   Then create dictionary from the two lists:  print get_dic_from_two_lists(country, capital)   The output is like this,  {'Pakistan': 'Islamabad', 'China': 'Beijing', 'India': 'New Delhi'}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1747817/create-a-dictionary-with-list-comprehension-in-python", "Language": "Python", "Q_Title": "Create a dictionary with list comprehension in Python", "Q_Votes": "1048", "Q_Content": "    I like the Python list comprehension syntax.  Can it be used to create dictionaries too? For example, by iterating over pairs of keys and values:  mydict = {(k,v) for (k,v) in blah blah blah}  # doesn't work      ", "Tags": ["python", "dictionary", "list-comprehension", "language-features", "dict-comprehension"], "A_Votes": "0", "A_Content": "  Just to throw in another example. Imagine you have the following list:  nums = [4,2,2,1,3]   and you want to turn it into a dict where the key is the index and value is the element in the list. You can do so with the following line of code:  {index:nums[index] for index in range(0,len(nums))}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "1685", "A_Content": "  You can use glob:  import glob, os os.chdir(\"/mydir\") for file in glob.glob(\"*.txt\"):     print(file)   or simply os.listdir:  import os for file in os.listdir(\"/mydir\"):     if file.endswith(\".txt\"):         print(os.path.join(\"/mydir\", file))   or if you want to traverse directory, use os.walk:  import os for root, dirs, files in os.walk(\"/mydir\"):     for file in files:         if file.endswith(\".txt\"):              print(os.path.join(root, file))      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "181", "A_Content": "  Use glob.  >>> import glob >>> glob.glob('./*.txt') ['./outline.txt', './pip-log.txt', './test.txt', './testingvim.txt']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "115", "A_Content": "  Something like that should do the job  for root, dirs, files in os.walk(directory):     for file in files:         if file.endswith('.txt'):             print file      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "88", "A_Content": "  Something like this will work:   >>> import os >>> path = '/usr/share/cups/charmaps' >>> text_files = [f for f in os.listdir(path) if f.endswith('.txt')] >>> text_files ['euc-cn.txt', 'euc-jp.txt', 'euc-kr.txt', 'euc-tw.txt', ... 'windows-950.txt']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "26", "A_Content": "  import os  path = 'mypath/path'  files = os.listdir(path)  files_txt = [i for i in files if i.endswith('.txt')]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "25", "A_Content": "  I like os.walk():  import os, os.path  for root, dirs, files in os.walk(dir):     for f in files:         fullpath = os.path.join(root, f)         if os.path.splitext(fullpath)[1] == '.txt':             print fullpath   Or with generators:  import os, os.path  fileiter = (os.path.join(root, f)     for root, _, files in os.walk(dir)     for f in files) txtfileiter = (f for f in fileiter if os.path.splitext(f)[1] == '.txt') for txt in txtfileiter:     print txt      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "21", "A_Content": "  Here's more versions of the same that produce slightly different results:  glob.iglob()  import glob for f in glob.iglob(\"/mydir/*/*.txt\"): # generator, search immediate subdirectories      print f   glob.glob1()  print glob.glob1(\"/mydir\", \"*.tx?\")  # literal_directory, basename_pattern   fnmatch.filter()  import fnmatch, os print fnmatch.filter(os.listdir(\"/mydir\"), \"*.tx?\") # include dot-files      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "17", "A_Content": "  path.py is another alternative: https://github.com/jaraco/path.py  from path import path p = path('/path/to/the/directory') for f in p.files(pattern='*.txt'):     print f      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "10", "A_Content": "  Python has all tools to do this:   import os  the_dir = 'the_dir_that_want_to_search_in' all_txt_files = filter(lambda x: x.endswith('.txt'), os.listdir(the_dir))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "8", "A_Content": "  import os import sys   if len(sys.argv)==2:     print('no params')     sys.exit(1)  dir = sys.argv[1] mask= sys.argv[2]  files = os.listdir(dir);   res = filter(lambda x: x.endswith(mask), files);   print res      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "8", "A_Content": "  You can simply use pathlibs glob 1:  import pathlib  list(pathlib.Path('your_directory').glob('*.txt'))   or in a loop:  for txt_file in pathlib.Path('your_directory').glob('*.txt'):     # do something with \"txt_file\"   If you want it recursive you can use .glob('**/*.txt)    1The pathlib module was included in the standard library in python 3.4. But you can install back-ports of that module even on older Python versions (i.e. using conda or pip): pathlib and pathlib2.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "6", "A_Content": "  This code makes my life simpler.  import os fnames = ([file for root, dirs, files in os.walk(dir)     for file in files     if file.endswith('.txt') #or file.endswith('.png') or file.endswith('.pdf')     ]) for fname in fnames: print(fname)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "5", "A_Content": "  You can try this code  import glob import os filenames_without_extension = [os.path.basename(c).split('.')[0:1][0] for c in glob.glob('your/files/dir/*.txt')] filenames_with_extension = [os.path.basename(c) for c in glob.glob('your/files/dir/*.txt')]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "5", "A_Content": "  Use fnmatch: https://docs.python.org/2/library/fnmatch.html  import fnmatch import os  for file in os.listdir('.'):     if fnmatch.fnmatch(file, '*.txt'):         print file      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "5", "A_Content": "  I did a test (Python 3.6.4, W7x64) to see which solution is the fastest for one folder, no subdirectories, to get a list of complete file paths for files with a specific extension.  To make it short, for this task os.listdir() is the fastest and is 1.7x as fast as the next best: os.walk() (with a break!), 2.7x as fast as pathlib, 3.2x faster than os.scandir() and 3.3x faster than glob. Please keep in mind, that those results will change when you need recursive results. If you copy/paste one method below, please add a .lower() otherwise .EXT would not be found when searching for .ext.  import os import pathlib import timeit import glob  def a():     path = pathlib.Path().cwd()     list_sqlite_files = [str(f) for f in path.glob(\"*.sqlite\")]  def b():      path = os.getcwd()     list_sqlite_files = [f.path for f in os.scandir(path) if os.path.splitext(f)[1] == \".sqlite\"]  def c():     path = os.getcwd()     list_sqlite_files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".sqlite\")]  def d():     path = os.getcwd()     os.chdir(path)     list_sqlite_files = [os.path.join(path, f) for f in glob.glob(\"*.sqlite\")]  def e():     path = os.getcwd()     list_sqlite_files = [os.path.join(path, f) for f in glob.glob1(str(path), \"*.sqlite\")]  def f():     path = os.getcwd()     list_sqlite_files = []     for root, dirs, files in os.walk(path):         for file in files:             if file.endswith(\".sqlite\"):                 list_sqlite_files.append( os.path.join(root, file) )         break    print(timeit.timeit(a, number=1000)) print(timeit.timeit(b, number=1000)) print(timeit.timeit(c, number=1000)) print(timeit.timeit(d, number=1000)) print(timeit.timeit(e, number=1000)) print(timeit.timeit(f, number=1000))   Results:  # Python 3.6.4 0.431 0.515 0.161 0.548 0.537 0.274      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "5", "A_Content": "  To get all '.txt' file names inside 'dataPath' folder as a list in a Pythonic way  from os import listdir from os.path import isfile, join path = \"/dataPath/\" onlyTxtFiles = [f for f in listdir(path) if isfile(join(path, f)) and  f.endswith(\".txt\")] print onlyTxtFiles      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "3", "A_Content": "  import glob,os  data_dir = 'data_folder/' file_dir_extension = os.path.join(data_dir, '*.txt')  for file_name in glob.glob(file_dir_extension):     if file_name.endswith('.txt'):         print file_name   For me. It's classic.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "3", "A_Content": "  I suggest you to use fnmatch and the upper method. In this way you can find any of the following:   Name.txt; Name.TXT; Name.Txt   .  import fnmatch import os      for file in os.listdir(\"/Users/Johnny/Desktop/MyTXTfolder\"):         if fnmatch.fnmatch(file.upper(), '*.TXT'):             print(file)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "2", "A_Content": "  Functional solution with sub-directories:  from fnmatch import filter from functools import partial from itertools import chain from os import path, walk  print(*chain(*(map(partial(path.join, root), filter(filenames, \"*.txt\")) for root, _, filenames in walk(\"mydir\"))))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "2", "A_Content": "  In case the folder contains a lot of files or memory is an constraint, consider using generators:  def yield_files_with_extensions(folder_path, file_extension):    for _, _, files in os.walk(folder_path):        for file in files:            if file.endswith(file_extension):                yield file   Option A: Iterate  for f in yield_files_with_extensions('.', '.txt'):      print(f)   Option B: Get all  files = [f for f in yield_files_with_extensions('.', '.txt')]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "970", "A_Content": "  Python doesn't have the same types as C/C++, which appears to be your question.  Try this:  >>> i = 123 >>> type(i) <type 'int'> >>> type(i) is int True >>> i = 123456789L >>> type(i) <type 'long'> >>> type(i) is long True >>> i = 123.456 >>> type(i) <type 'float'> >>> type(i) is float True   The distinction between int and long goes away in Python 3.0, though.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "2", "A_Content": "  import glob import os  path=os.getcwd()  extensions=('*.py','*.cpp')  for i in extensions:   for files in glob.glob(i):      print files      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "2", "A_Content": "  Try this this will find all your file inside folder or folder      import glob, os os.chdir(\"H:\\\\wallpaper\")# use whatever you directory   #double\\\\ no single \\  for file in glob.glob(\"**/*.psd\", recursive = True):#your format     print(file)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "2", "A_Content": "  To get an array of \".txt\" file names from a folder called \"data\" in the same directory I usually use this simple line of code:  import os fileNames = [fileName for fileName in os.listdir(\"data\") if fileName.endswith(\".txt\")]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "2", "A_Content": "  A copy-pastable solution similar to the one of ghostdog:  def get_all_filepaths(root_path, ext):     \"\"\"     Search all files which have a given extension within root_path.      This ignores the case of the extension and searches subdirectories, too.      Parameters     ----------     root_path : str     ext : str      Returns     -------     list of str      Examples     --------     >>> get_all_filepaths('/run', '.lock')     ['/run/unattended-upgrades.lock',      '/run/mlocate.daily.lock',      '/run/xtables.lock',      '/run/mysqld/mysqld.sock.lock',      '/run/postgresql/.s.PGSQL.5432.lock',      '/run/network/.ifstate.lock',      '/run/lock/asound.state.lock']     \"\"\"     import os     all_files = []     for root, dirs, files in os.walk(root_path):         for filename in files:             if filename.lower().endswith(ext):                 all_files.append(os.path.join(root, filename))     return all_files      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "2", "A_Content": "  Python v3.5+  Fast method using os.scandir in a recursive function.  Searches for all files with a specified extension in folder and sub-folders.  import os  def findFilesInFolder(path, pathList, extension, subFolders = True):     \"\"\"  Recursive function to find all files of an extension type in a folder (and optionally in all subfolders too)      path:        Base directory to find files     pathList:    A list that stores all paths     extension:   File extension to find     subFolders:  Bool.  If True, find files in all subfolders under path. If False, only searches files in the specified folder     \"\"\"      try:   # Trapping a OSError:  File permissions problem I believe         for entry in os.scandir(path):             if entry.is_file() and entry.path.endswith(extension):                 pathList.append(entry.path)             elif entry.is_dir() and subFolders:   # if its a directory, then repeat process as a nested function                 pathList = findFilesInFolder(entry.path, pathList, extension, subFolders)     except OSError:         print('Cannot access ' + path +'. Probably a permissions error')      return pathList  dir_name = r'J:\\myDirectory' extension = \".txt\"  pathList = [] pathList = findFilesInFolder(dir_name, pathList, extension, True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "1", "A_Content": "  You can try this code:  import glob import os  os.chdir(\"D:\\...\\DirName\") filename_arr={} i=0 for files in glob.glob(\"*.txt\"):     filename_arr[i] = files     i= i+1  for key,value in filename_arr.items():     print key , value      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "1", "A_Content": "  use Python OS module to find files with specific extension.  the simple example is here :  import os  # This is the path where you want to search path = r'd:'    # this is extension you want to detect extension = '.txt'   # this can be : .jpg  .png  .xls  .log .....  for root, dirs_list, files_list in os.walk(path):     for file_name in files_list:         if os.path.splitext(file_name)[-1] == extension:             file_name_path = os.path.join(root, file_name)             print file_name             print file_name_path   # This is the full path of the filter file      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "1", "A_Content": "  Many users have replied with os.walk answers, which includes all files but also all directories and subdirectories and their files.  import os   def files_in_dir(path, extension=''):     \"\"\"        Generator: yields all of the files in <path> ending with        <extension>         \\param   path       Absolute or relative path to inspect,        \\param   extension  [optional] Only yield files matching this,         \\yield              [filenames]     \"\"\"       for _, dirs, files in os.walk(path):         dirs[:] = []  # do not recurse directories.         yield from [f for f in files if f.endswith(extension)]  # Example: print all the .py files in './python' for filename in files_in_dir('./python', '*.py'):     print(\"-\", filename)   Or for a one off where you don't need a generator:  path, ext = \"./python\", ext = \".py\" for _, _, dirfiles in os.walk(path):     matches = (f for f in dirfiles if f.endswith(ext))     break  for filename in matches:     print(\"-\", filename)   If you are going to use matches for something else, you may want to make it a list rather than a generator expression:      matches = [f for f in dirfiles if f.endswith(ext)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "1", "A_Content": "  Here's one with extend()  types = ('*.jpg', '*.png') images_list = [] for files in types:     images_list.extend(glob.glob(os.path.join(path, files)))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python", "Language": "Python", "Q_Title": "Find all files in a directory with extension .txt in Python", "Q_Votes": "1044", "Q_Content": "    How can I find all the files in a directory having the extension .txt in python?     ", "Tags": ["python", "file-io"], "A_Votes": "0", "A_Content": "  A simple method by using for loop  :   import os  dir = [\"e\",\"x\",\"e\"]  p = os.listdir('E:')  #path  for n in range(len(p)):    name = p[n]    myfile = [name[-3],name[-2],name[-1]]  #for .txt    if myfile == dir :       print(name)    else:       print(\"nops\")   Though this can be made more generalised .     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "315", "A_Content": "  You may be looking for the type() function.  See the examples below, but there's no \"unsigned\" type in Python just like Java.  Positive integer:  >>> v = 10 >>> type(v) <type 'int'>   Large positive integer:  >>> v = 100000000000000 >>> type(v) <type 'long'>   Negative integer:  >>> v = -10 >>> type(v) <type 'int'>   Literal sequence of characters:  >>> v = 'hi' >>> type(v) <type 'str'>   Floating point integer:  >>> v = 3.14159 >>> type(v) <type 'float'>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "140", "A_Content": "  It is so simple. You do it like this.  print(type(variable_name))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "79", "A_Content": "     How to determine the variable type in Python?   So if you have a variable, for example:  one = 1   You want to know its type?  There are right ways and wrong ways to do just about everything in Python. Here's the right way:   Use type  >>> type(one) <type 'int'>   You can use the __name__ attribute to get the name of the object. (This is one of the few special attributes that you need to use the __dunder__ name to get to - there's not even a method for it in the inspect module.)  >>> type(one).__name__ 'int'   Don't use __class__  In Python, names that start with underscores are semantically not a part of the public API, and it's a best practice for users to avoid using them. (Except when absolutely necessary.)  Since type gives us the class of the object, we should avoid getting this directly. :  >>> one.__class__   This is usually the first idea people have when accessing the type of an object in a method - they're already looking for attributes, so type seems weird. For example:  class Foo(object):     def foo(self):         self.__class__   Don't. Instead, do type(self):  class Foo(object):     def foo(self):         type(self)   Implementation details of ints and floats     How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?   In Python, these specifics are implementation details. So, in general, we don't usually worry about this in Python. However, to sate your curiosity...  In Python 2, int is usually a signed integer equal to the implementation's word width (limited by the system). It's usually implemented as a long in C. When integers get bigger than this, we usually convert them to Python longs (with unlimited precision, not to be confused with C longs).  For example, in a 32 bit Python 2, we can deduce that int is a signed 32 bit integer:  >>> import sys  >>> format(sys.maxint, '032b') '01111111111111111111111111111111' >>> format(-sys.maxint - 1, '032b') # minimum value, see docs. '-10000000000000000000000000000000'   In Python 3, the old int goes away, and we just use (Python's) long as int, which has unlimited precision.  We can also get some information about Python's floats, which are usually implemented as a double in C:  >>> sys.float_info sys.floatinfo(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308,  min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15,  mant_dig=53, epsilon=2.2204460492503131e-16, radix=2, rounds=1)   Conclusion  Don't use __class__, a semantically nonpublic API, to get the type of a variable. Use type instead.   And don't worry too much about the implementation details of Python. I've not had to deal with issues around this myself. You probably won't either, and if you really do, you should know enough not to be looking to this answer for what to do.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "36", "A_Content": "  One more way using __class__:  >>> a = [1, 2, 3, 4] >>> a.__class__ <type 'list'> >>> b = {'key1': 'val1'} >>> b.__class__ <type 'dict'> >>> c = 12 >>> c.__class__ <type 'int'>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "26", "A_Content": "  print type(variable_name)   I also highly recommend the IPython interactive interpreter when dealing with questions like this. It lets you type variable_name? and will return a whole list of information about the object including the type and the doc string for the type.  e.g.  In [9]: var = 123  In [10]: var? Type:       int Base Class: <type 'int'> String Form:    123 Namespace:  Interactive Docstring:     int(x[, base]) -> integer   Convert a string or number to an integer, if possible.  A floating point argument will be truncated towards zero (this does not include a string representation of a floating point number!)  When converting a string, use the optional base.  It is an error to supply a base when converting a         non-string. If the argument is outside the integer range a long object         will be returned instead.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "25", "A_Content": "  The question is somewhat ambiguous -- I'm not sure what you mean by \"view\". If you are trying to query the type of a native Python object, @atzz's answer will steer you in the right direction.  However, if you are trying to generate Python objects that have the semantics of primitive C-types, (such as uint32_t, int16_t), use the struct module. You can determine the number of bits in a given C-type primitive thusly:  >>> struct.calcsize('c') # char 1 >>> struct.calcsize('h') # short 2 >>> struct.calcsize('i') # int 4 >>> struct.calcsize('l') # long 4   This is also reflected in the array module, which can make arrays of these lower-level types:  >>> array.array('c').itemsize # char 1   The maximum integer supported (Python 2's int) is given by sys.maxint.  >>> import sys, math >>> math.ceil(math.log(sys.maxint, 2)) + 1 # Signedness 32.0   There is also sys.getsizeof, which returns the actual size of the Python object in residual memory:  >>> a = 5 >>> sys.getsizeof(a) # Residual memory. 12   For float data and precision data, use sys.float_info:  >>> sys.float_info sys.floatinfo(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.2204460492503131e-16, radix=2, rounds=1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "20", "A_Content": "  Examples of simple type checking in Python:  assert type(variable_name) == int  assert type(variable_name) == bool  assert type(variable_name) == list      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "19", "A_Content": "  It may be little irrelevant. but you can check types of an object with isinstance(object, type) as mentioned here.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "18", "A_Content": "  Do you mean in Python or using ctypes?  In the first case, you simply cannot - because Python does not have signed/unsigned, 16/32 bit integers.  In the second case, you can use type():  >>> import ctypes >>> a = ctypes.c_uint() # unsigned int >>> type(a) <class 'ctypes.c_ulong'>   For more reference on ctypes, an its type, see the official documentation.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "15", "A_Content": "  Python doesn't have such types as you describe. There are two types used to represent integral values: int, which corresponds to platform's int type in C, and long, which is an arbitrary precision integer (i.e. it grows as needed and doesn't have an upper limit). ints are silently converted to long if an expression produces result which cannot be stored in int.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "11", "A_Content": "  Simple, for python 3.4 and above  print (type(variable_name))   Python 2.7 and above  print type(variable_name)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "10", "A_Content": "  It really depends on what level you mean. In Python 2.x, there are two integer types, int (constrained to sys.maxint) and long (unlimited precision), for historical reasons. In Python code, this shouldn't make a bit of difference because the interpreter automatically converts to long when a number is too large. If you want to know about the actual data types used in the underlying interpreter, that's implementation dependent. (CPython's are located in Objects/intobject.c and Objects/longobject.c.) To find out about the systems types look at cdleary answer for using the struct module.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "5", "A_Content": "  For python2.x, use   print type(variable_name)   For python3.x, use   print(type(variable_name))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/402504/how-to-determine-a-python-variables-type", "Language": "Python", "Q_Title": "How to determine a Python variable's type?", "Q_Votes": "1062", "Q_Content": "    How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?  How do I view it?     ", "Tags": ["python", "types", "unsigned", "signed", "16-bit"], "A_Votes": "0", "A_Content": "  If you want to check and compare the variable type, you can use isinstance() function. I got this few years ago from this site  >>> a = [] >>> b = () >>> c = {} >>> isinstance(a, int) False >>> isinstance(a, list) True >>> isinstance(b, list) False >>> isinstance(b, tuple) True >>> isinstance(c, dict) True   And different way for checking a None type:  >>> a is None False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "1237", "A_Content": "  Use del and specify the index of the element you want to delete:  >>> a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> del a[-1] >>> a [0, 1, 2, 3, 4, 5, 6, 7, 8]   Also supports slices:  >>> del a[2:4] >>> a [0, 1, 4, 5, 6, 7, 8, 9]   Here is the section from the tutorial.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "503", "A_Content": "  You probably want pop:  a = ['a', 'b', 'c', 'd'] a.pop(1)  # now a is ['a', 'c', 'd']   By default, pop without any arguments removes the last item:  a = ['a', 'b', 'c', 'd'] a.pop()  # now a is ['a', 'b', 'c']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "102", "A_Content": "  Like others mentioned pop and del are the efficient ways to remove an item of given index. Yet just for the sake of completion (since the same thing can be done via many ways in Python):  Using slices (this does not do in place removal of item from original list):  (Also this will be the least efficient method when working with Python list, but this could be useful (but not efficient, I reiterate) when working with user defined objects that do not support pop, yet do define a __getitem__ ):  >>> a = [1, 2, 3, 4, 5, 6] >>> index = 3 # Only positive index  >>> a = a[:index] + a[index+1 :] # a is now [1, 2, 3, 5, 6]   Note: Please note that this method does not modify the list in place like pop and del. It instead makes two copies of lists (one from the start until the index but without it (a[:index]) and one after the index till the last element (a[index+1:])) and creates a new list object by adding both. This is then reassigned to the list variable (a). The old list object is hence dereferenced and hence garbage collected (provided the original list object is not referenced by any variable other than a).  This makes this method very inefficient and it can also produce undesirable side effects (especially when other variables point to the original list object which remains un-modified).  Thanks to @MarkDickinson for pointing this out ...  This Stack Overflow answer explains the concept of slicing.  Also note that this works only with positive indices.  While using with objects, the __getitem__ method must have been defined and more importantly the __add__ method must have been defined to return an object containing items from both the operands.  In essence, this works with any object whose class definition is like:  class foo(object):     def __init__(self, items):         self.items = items      def __getitem__(self, index):         return foo(self.items[index])      def __add__(self, right):         return foo( self.items + right.items )   This works with list which defines __getitem__ and __add__ methods.  Comparison of the three ways in terms of efficiency:  Assume the following is predefined:  a = range(10) index = 3   The del object[index] method:  By far the most efficient method. It works will all objects that define a __del__ method.  The disassembly is as follows:  Code:  def del_method():     global a     global index     del a[index]   Disassembly:   10    0 LOAD_GLOBAL     0 (a)        3 LOAD_GLOBAL     1 (index)        6 DELETE_SUBSCR   # This is the line that deletes the item        7 LOAD_CONST      0 (None)       10 RETURN_VALUE None   pop method:  It is less efficient than the del method and is used when you need to get the deleted item.  Code:  def pop_method():     global a     global index     a.pop(index)   Disassembly:   17     0 LOAD_GLOBAL     0 (a)         3 LOAD_ATTR       1 (pop)         6 LOAD_GLOBAL     2 (index)         9 CALL_FUNCTION   1        12 POP_TOP        13 LOAD_CONST      0 (None)        16 RETURN_VALUE   The slice and add method.  The least efficient.  Code:  def slice_method():     global a     global index     a = a[:index] + a[index+1:]   Disassembly:   24     0 LOAD_GLOBAL    0 (a)         3 LOAD_GLOBAL    1 (index)         6 SLICE+2         7 LOAD_GLOBAL    0 (a)        10 LOAD_GLOBAL    1 (index)        13 LOAD_CONST     1 (1)        16 BINARY_ADD        17 SLICE+1        18 BINARY_ADD        19 STORE_GLOBAL   0 (a)        22 LOAD_CONST     0 (None)        25 RETURN_VALUE None   Note: In all three disassembles ignore the last two lines which basically are return None. Also the first two lines are loading the global values a and index.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "44", "A_Content": "  pop is also useful to remove and keep an item from a list.  Where del actually trashes the item.  >>> x = [1, 2, 3, 4]  >>> p = x.pop(1) >>> p     2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "13", "A_Content": "  Generally, I am using the following method:  >>> myList = [10,20,30,40,50] >>> rmovIndxNo = 3 >>> del myList[rmovIndxNo] >>> myList [10, 20, 30, 50]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "11", "A_Content": "  This depends on what you want to do.  If you want to return the element you removed, use pop():  >>> l = [1, 2, 3, 4, 5] >>> l.pop(2) 3 >>> l [1, 2, 4, 5]   However, if you just want to delete an element, use del:  >>> l = [1, 2, 3, 4, 5] >>> del l[2] >>> l [1, 2, 4, 5]   Additionally, del allows you to use slices (e.g. del[2:]).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "9", "A_Content": "  Yet another way to remove an element(s) from a list by index.  a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # remove the element at index 3 a[3:4] = [] # a is now [0, 1, 2, 4, 5, 6, 7, 8, 9]  # remove the elements from index 3 to index 6 a[3:7] = [] # a is now [0, 1, 2, 7, 8, 9]   a[x:y] points to the elements from index x to y-1. When we declare that portion of the list as an empty list ([]), those elements are removed.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "7", "A_Content": "  You could just search for the item you want to delete. It is really simple. Example:      letters = [\"a\", \"b\", \"c\", \"d\", \"e\"]     letters.remove(letters[1])     print(*letters) # Used with a * to make it unpack you don't have to (Python 3.x or newer)   Output: a c d e     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "6", "A_Content": "  Use the following code to remove element from the list:   list = [1, 2, 3, 4] list.remove(1) print(list)  output = [2, 3, 4]   If you want to remove index element data from the list use:  list = [1, 2, 3, 4] list.remove(list[2]) print(list) output : [1, 2, 4]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "4", "A_Content": "  As previously mentioned, best practice is del(); or pop() if you need to know the value.  An alternate solution is to re-stack only those elements you want:      a = ['a', 'b', 'c', 'd']       def remove_element(list_,index_):         clipboard = []         for i in range(len(list_)):             if i is not index_:                 clipboard.append(list_[i])         return clipboard      print(remove_element(a,2))      >> ['a', 'b', 'd']   eta: hmm... will not work on negative index values, will ponder and update  I suppose   if index_<0:index_=len(list_)+index_   would patch it... but suddenly this idea seems very brittle. Interesting thought experiment though.  Seems there should be a 'proper' way to do this with append() / list comprehension.    pondering     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "4", "A_Content": "  It doesn't sound like you're working with a list of lists, so I'll keep this short.  You want to use pop since it will remove elements not elements that are lists, you should use del for that.  To call the last element in python it's \"-1\"  >>> test = ['item1', 'item2'] >>> test.pop(-1) 'item2' >>> test ['item1']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "4", "A_Content": "  Use the \"del\" function:      del listName[-N]   For example, if you want to remove the last 3 items, your code should be:  del listName[-3:]   For example, if you want to remove the last 8 items, your code should be:  del listName[-8:]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "3", "A_Content": "  l - list of values; we have to remove indexes from inds2rem list.  l = range(20) inds2rem = [2,5,1,7] map(lambda x: l.pop(x), sorted(inds2rem, key = lambda x:-x))  >>> l [0, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  One can either use del or pop, but I prefer del, since you can specify index and slices, giving the user more control over the data.  For example, starting with the list shown, one can remove its last element with del as a slice, and then one can remove the last element from the result using pop.  >>> l = [1,2,3,4,5] >>> del l[-1:] >>> l [1, 2, 3, 4] >>> l.pop(-1) 4 >>> l [1, 2, 3]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  If you want to remove the specific position element in a list, like the 2th, 3th and 7th. you can't use  del my_list[2] del my_list[3] del my_list[7]   Since after you delete the second element, the third element you delete actually is the fourth element in the original list. You can filter the 2th, 3th and 7th element in the original list and get a new list, like below:  new list = [j for i, j in enumerate(my_list) if i not in [2, 3, 7]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "0", "A_Content": "  You can use either del or pop to remove element from list based on index.  Pop will print member it is removing from list, while list delete that member without printing it.  >>> a=[1,2,3,4,5] >>> del a[1] >>> a [1, 3, 4, 5] >>> a.pop(1)  3 >>> a [1, 4, 5] >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/627435/how-do-i-remove-an-element-from-a-list-by-index-in-python", "Language": "Python", "Q_Title": "How do I remove an element from a list by index in Python?", "Q_Votes": "1068", "Q_Content": "    How do I remove an element from a list by index in Python?  I found the list.remove method, but say I want to remove the last element, how do I do this? It seems like the default remove searches the list, but I don't want any search to be performed.     ", "Tags": ["python", "list"], "A_Votes": "0", "A_Content": "  You can simply use the remove function of Python. Like this:  v = [1, 2, 3, 4, 5, 6] v.remove(v[4]) # I'm removing the number with index 4 of my array print(v) # If you want verify the process  # It gave me this: #[1,2,3,4,6]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary", "Language": "Python", "Q_Title": "How to remove a key from a Python dictionary?", "Q_Votes": "1083", "Q_Content": "    When trying to delete a key from a dictionary, I write:  if 'key' in myDict:     del myDict['key']   Is there a one line way of doing this?     ", "Tags": ["python", "dictionary", "unset"], "A_Votes": "1805", "A_Content": "  Use dict.pop():  my_dict.pop('key', None)   This will return my_dict[key] if key exists in the dictionary, and None otherwise. If the second parameter is not specified (ie. my_dict.pop('key')) and key does not exist, a KeyError is raised.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary", "Language": "Python", "Q_Title": "How to remove a key from a Python dictionary?", "Q_Votes": "1083", "Q_Content": "    When trying to delete a key from a dictionary, I write:  if 'key' in myDict:     del myDict['key']   Is there a one line way of doing this?     ", "Tags": ["python", "dictionary", "unset"], "A_Votes": "268", "A_Content": "  Specifically to answer \"is there a one line way of doing this?\"  if 'key' in myDict: del myDict['key']   ...well, you asked ;-)  You should consider, though, that this way of deleting an object from a dict is not atomic\u2014it is possible that 'key' may be in myDict during the if statement, but may be deleted before del is executed, in which case del will fail with a KeyError.  Given this, it would be safest to either use dict.pop or something along the lines of  try:     del myDict['key'] except KeyError:     pass   which, of course, is definitely not a one-liner.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary", "Language": "Python", "Q_Title": "How to remove a key from a Python dictionary?", "Q_Votes": "1083", "Q_Content": "    When trying to delete a key from a dictionary, I write:  if 'key' in myDict:     del myDict['key']   Is there a one line way of doing this?     ", "Tags": ["python", "dictionary", "unset"], "A_Votes": "116", "A_Content": "  It took me some time to figure out what exactly my_dict.pop(\"key\", None) is doing. So I'll add this as an answer to save others googling time:     pop(key[, default])      If key is in the dictionary, remove it and return its value, else   return default. If default is not given and key is not in the    dictionary, a KeyError is raised   Documentation     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary", "Language": "Python", "Q_Title": "How to remove a key from a Python dictionary?", "Q_Votes": "1083", "Q_Content": "    When trying to delete a key from a dictionary, I write:  if 'key' in myDict:     del myDict['key']   Is there a one line way of doing this?     ", "Tags": ["python", "dictionary", "unset"], "A_Votes": "27", "A_Content": "  Timing of the three solutions described above.  Small dictionary:  >>> import timeit >>> timeit.timeit(\"d={'a':1}; d.pop('a')\") 0.23399464370632472 >>> timeit.timeit(\"d={'a':1}; del d['a']\") 0.15225347193388927 >>> timeit.timeit(\"d={'a':1}; d2 = {key: val for key, val in d.items() if key != 'a'}\") 0.5365207354998063   Larger dictionary:  >>> timeit.timeit(\"d={nr: nr for nr in range(100)}; d.pop(3)\") 5.478138627299643 >>> timeit.timeit(\"d={nr: nr for nr in range(100)}; del d[3]\") 5.362219126590048 >>> timeit.timeit(\"d={nr: nr for nr in range(100)}; d2 = {key: val for key, val in d.items() if key != 3}\") 13.93129749387532      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary", "Language": "Python", "Q_Title": "How to remove a key from a Python dictionary?", "Q_Votes": "1083", "Q_Content": "    When trying to delete a key from a dictionary, I write:  if 'key' in myDict:     del myDict['key']   Is there a one line way of doing this?     ", "Tags": ["python", "dictionary", "unset"], "A_Votes": "20", "A_Content": "  If you need to remove a lot of keys from a dictionary in one line of code, I think using map() is quite succinct and Pythonic readable:  myDict = {'a':1,'b':2,'c':3,'d':4} map(myDict.pop, ['a','c']) # The list of keys to remove >>> myDict {'b': 2, 'd': 4}   And if you need to catch errors where you pop a value that isn't in the dictionary, use lambda inside map() like this:  map(lambda x: myDict.pop(x,None), ['a','c','e']) [1, 3, None] # pop returns >>> myDict {'b': 2, 'd': 4}   It works. And 'e' did not cause an error, even though myDict did not have an 'e' key.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary", "Language": "Python", "Q_Title": "How to remove a key from a Python dictionary?", "Q_Votes": "1083", "Q_Content": "    When trying to delete a key from a dictionary, I write:  if 'key' in myDict:     del myDict['key']   Is there a one line way of doing this?     ", "Tags": ["python", "dictionary", "unset"], "A_Votes": "15", "A_Content": "  Use:  >>> if myDict.get(key): myDict.pop(key)   Another way:  >>> {k:v for k, v in myDict.items() if k != 'key'}   You can delete by conditions. No error if key doesn't exist.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary", "Language": "Python", "Q_Title": "How to remove a key from a Python dictionary?", "Q_Votes": "1083", "Q_Content": "    When trying to delete a key from a dictionary, I write:  if 'key' in myDict:     del myDict['key']   Is there a one line way of doing this?     ", "Tags": ["python", "dictionary", "unset"], "A_Votes": "6", "A_Content": "  Using the \"del\" keyword:  del dict[key]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary", "Language": "Python", "Q_Title": "How to remove a key from a Python dictionary?", "Q_Votes": "1083", "Q_Content": "    When trying to delete a key from a dictionary, I write:  if 'key' in myDict:     del myDict['key']   Is there a one line way of doing this?     ", "Tags": ["python", "dictionary", "unset"], "A_Votes": "5", "A_Content": "  We can delete a key from a Python dictionary by the some following approaches.  Using the del keyword; it's almost the same approach like you did though -   myDict = {'one': 100, 'two': 200, 'three': 300 }  print(myDict)  # {'one': 100, 'two': 200, 'three': 300}  if myDict.get('one') : del myDict['one']  print(myDict)  # {'two': 200, 'three': 300}   Or  We can do like following:  But one should keep in mind that, in this process actually it won't delete any key from the dictionary rather than making specific key excluded from that dictionary. In addition, I observed that it returned a dictionary which was not ordered the same as myDict.  myDict = {'one': 100, 'two': 200, 'three': 300, 'four': 400, 'five': 500} {key:value for key, value in myDict.items() if key != 'one'}   If we run it in the shell, it'll execute something like {'five': 500, 'four': 400, 'three': 300, 'two': 200} - notice that it's not the same ordered as myDict. Again if we try to print myDict, then we can see all keys including which we excluded from the dictionary by this approach. However, we can make a new dictionary by assigning the following statement into a variable:  var = {key:value for key, value in myDict.items() if key != 'one'}   Now if we try to print it, then it'll follow the parent order:  print(var) # {'two': 200, 'three': 300, 'four': 400, 'five': 500}   Or  Using the pop() method.  myDict = {'one': 100, 'two': 200, 'three': 300} print(myDict)  if myDict.get('one') : myDict.pop('one') print(myDict)  # {'two': 200, 'three': 300}   The difference between del and pop is that, using pop() method, we can actually store the key's value if needed, like the following:  myDict = {'one': 100, 'two': 200, 'three': 300} if myDict.get('one') : var = myDict.pop('one') print(myDict) # {'two': 200, 'three': 300} print(var)    # 100      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "1452", "A_Content": "  If you only want one item's count, use the count method:  >>> [1, 2, 3, 4, 1, 4, 1].count(1) 3   Don't use this if you want to count multiple items. Calling count in a loop requires a separate pass over the list for every count call, which can be catastrophic for performance. If you want to count all items, or even just multiple items, use Counter, as explained in the other answers.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "1377", "A_Content": "  If you are using Python 2.7 or 3 and you want number of occurrences for each element:  >>> from collections import Counter >>> z = ['blue', 'red', 'blue', 'yellow', 'blue', 'red'] >>> Counter(z) Counter({'blue': 3, 'red': 2, 'yellow': 1})      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "193", "A_Content": "  Counting the occurrences of one item in a list  For counting the occurrences of just one list item you can use count()  >>> l = [\"a\",\"b\",\"b\"] >>> l.count(\"a\") 1 >>> l.count(\"b\") 2   Counting the occurrences of all items in a list is also known as \"tallying\" a list, or creating a tally counter.  Counting all items with count()  To count the occurrences of items in l one can simply use a list comprehension and the count() method  [[x,l.count(x)] for x in set(l)]   (or similarly with a dictionary dict((x,l.count(x)) for x in set(l)))  Example:   >>> l = [\"a\",\"b\",\"b\"] >>> [[x,l.count(x)] for x in set(l)] [['a', 1], ['b', 2]] >>> dict((x,l.count(x)) for x in set(l)) {'a': 1, 'b': 2}   Counting all items with Counter()  Alternatively, there's the faster Counter class from the collections library  Counter(l)   Example:  >>> l = [\"a\",\"b\",\"b\"] >>> from collections import Counter >>> Counter(l) Counter({'b': 2, 'a': 1})   How much faster is Counter?  I checked how much faster Counter is for tallying lists. I tried both methods out with a few values of n and it appears that Counter is faster by a constant factor of approximately 2.  Here is the script I used:  from __future__ import print_function import timeit  t1=timeit.Timer('Counter(l)', \\                 'import random;import string;from collections import Counter;n=1000;l=[random.choice(string.ascii_letters) for x in range(n)]'                 )  t2=timeit.Timer('[[x,l.count(x)] for x in set(l)]',                 'import random;import string;n=1000;l=[random.choice(string.ascii_letters) for x in range(n)]'                 )  print(\"Counter(): \", t1.repeat(repeat=3,number=10000)) print(\"count():   \", t2.repeat(repeat=3,number=10000)   And the output:  Counter():  [0.46062711701961234, 0.4022796869976446, 0.3974247490405105] count():    [7.779430688009597, 7.962715800967999, 8.420845870045014]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "57", "A_Content": "  Another way to get the number of occurrences of each item, in a dictionary:  dict((i, a.count(i)) for i in a)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "41", "A_Content": "  list.count(x) returns the number of times x appears in a list  see: http://docs.python.org/tutorial/datastructures.html#more-on-lists     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "27", "A_Content": "  If you want to count all values at once you can do it very fast using numpy arrays and bincount as follows  import numpy as np a = np.array([1, 2, 3, 4, 1, 4, 1]) np.bincount(a)   which gives  >>> array([0, 3, 1, 1, 2])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "25", "A_Content": "     Given an item, how can I count its occurrences in a list in Python?   Here's an example list:  >>> l = list('aaaaabbbbcccdde') >>> l ['a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'c', 'c', 'c', 'd', 'd', 'e']   list.count  There's the list.count method  >>> l.count('b') 4   This works fine for any list. Tuples have this method as well:  >>> t = tuple('aabbbffffff') >>> t ('a', 'a', 'b', 'b', 'b', 'f', 'f', 'f', 'f', 'f', 'f') >>> t.count('f') 6   collections.Counter  And then there's collections.Counter. You can dump any iterable into a Counter, not just a list, and the Counter will retain a data structure of the counts of the elements.  Usage:  >>> from collections import Counter >>> c = Counter(l) >>> c['b'] 4   Counters are based on Python dictionaries, their keys are the elements, so the keys need to be hashable. They are basically like sets that allow redundant elements into them.  Further usage of collections.Counter  You can add or subtract with iterables from your counter:  >>> c.update(list('bbb')) >>> c['b'] 7 >>> c.subtract(list('bbb')) >>> c['b'] 4   And you can do multi-set operations with the counter as well:  >>> c2 = Counter(list('aabbxyz')) >>> c - c2                   # set difference Counter({'a': 3, 'c': 3, 'b': 2, 'd': 2, 'e': 1}) >>> c + c2                   # addition of all elements Counter({'a': 7, 'b': 6, 'c': 3, 'd': 2, 'e': 1, 'y': 1, 'x': 1, 'z': 1}) >>> c | c2                   # set union Counter({'a': 5, 'b': 4, 'c': 3, 'd': 2, 'e': 1, 'y': 1, 'x': 1, 'z': 1}) >>> c & c2                   # set intersection Counter({'a': 2, 'b': 2})   Why not pandas?  Another answer suggests:     Why not use pandas?    Pandas is a common library, but it's not in the standard library. Adding it as a requirement is non-trivial.  There are builtin solutions for this use-case in the list object itself as well as in the standard library.  If your project does not already require pandas, it would be foolish to make it a requirement just for this functionality.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "23", "A_Content": "  I've compared all suggested solutions (and a few new ones) with perfplot (a small project of mine).  Counting one item  For large enough arrays, it turns out that    numpy.sum(numpy.array(a) == 1)    is slightly faster than the other solutions.    Counting all items  As established before,    numpy.bincount(a)   is what you want.      Code to reproduce the plots:    from collections import Counter from collections import defaultdict import numpy import operator import pandas import perfplot   def counter(a):     return Counter(a)   def count(a):     return dict((i, a.count(i)) for i in set(a))   def bincount(a):     return numpy.bincount(a)   def pandas_value_counts(a):     return pandas.Series(a).value_counts()   def occur_dict(a):     d = {}     for i in a:         if i in d:             d[i] = d[i]+1         else:             d[i] = 1     return d   def count_unsorted_list_items(items):     counts = defaultdict(int)     for item in items:         counts[item] += 1     return dict(counts)   def operator_countof(a):     return dict((i, operator.countOf(a, i)) for i in set(a))   perfplot.show(     setup=lambda n: list(numpy.random.randint(0, 100, n)),     n_range=[2**k for k in range(20)],     kernels=[         counter, count, bincount, pandas_value_counts, occur_dict,         count_unsorted_list_items, operator_countof         ],     equality_check=None,     logx=True,     logy=True,     )   2.    from collections import Counter from collections import defaultdict import numpy import operator import pandas import perfplot   def counter(a):     return Counter(a)   def count(a):     return dict((i, a.count(i)) for i in set(a))   def bincount(a):     return numpy.bincount(a)   def pandas_value_counts(a):     return pandas.Series(a).value_counts()   def occur_dict(a):     d = {}     for i in a:         if i in d:             d[i] = d[i]+1         else:             d[i] = 1     return d   def count_unsorted_list_items(items):     counts = defaultdict(int)     for item in items:         counts[item] += 1     return dict(counts)   def operator_countof(a):     return dict((i, operator.countOf(a, i)) for i in set(a))   perfplot.show(     setup=lambda n: list(numpy.random.randint(0, 100, n)),     n_range=[2**k for k in range(20)],     kernels=[         counter, count, bincount, pandas_value_counts, occur_dict,         count_unsorted_list_items, operator_countof         ],     equality_check=None,     logx=True,     logy=True,     )      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "16", "A_Content": "  If you can use pandas, then value_counts is there for rescue.   >>> import pandas as pd >>> a = [1, 2, 3, 4, 1, 4, 1] >>> pd.Series(a).value_counts() 1    3 4    2 3    1 2    1 dtype: int64   It automatically sorts the result based on frequency as well.   If you want the result to be in a list of list, do as below  >>> pd.Series(a).value_counts().reset_index().values.tolist() [[1, 3], [4, 2], [3, 1], [2, 1]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "14", "A_Content": "  Why not using Pandas?  import pandas as pd  l = ['a', 'b', 'c', 'd', 'a', 'd', 'a']  # converting the list to a Series and counting the values my_count = pd.Series(l).value_counts() my_count   Output:  a    3 d    2 b    1 c    1 dtype: int64   If you are looking for a count of a particular element, say a, try:  my_count['a']   Output:  3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "11", "A_Content": "  I had this problem today and rolled my own solution before I thought to check SO.  This:  dict((i,a.count(i)) for i in a)   is really, really slow for large lists.  My solution  def occurDict(items):     d = {}     for i in items:         if i in d:             d[i] = d[i]+1         else:             d[i] = 1 return d   is actually a bit faster than the Counter solution, at least for Python 2.7.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "11", "A_Content": "  # Python >= 2.6 (defaultdict) && < 2.7 (Counter, OrderedDict) from collections import defaultdict def count_unsorted_list_items(items):     \"\"\"     :param items: iterable of hashable items to count     :type items: iterable      :returns: dict of counts like Py2.7 Counter     :rtype: dict     \"\"\"     counts = defaultdict(int)     for item in items:         counts[item] += 1     return dict(counts)   # Python >= 2.2 (generators) def count_sorted_list_items(items):     \"\"\"     :param items: sorted iterable of items to count     :type items: sorted iterable      :returns: generator of (item, count) tuples     :rtype: generator     \"\"\"     if not items:         return     elif len(items) == 1:         yield (items[0], 1)         return     prev_item = items[0]     count = 1     for item in items[1:]:         if prev_item == item:             count += 1         else:             yield (prev_item, count)             count = 1             prev_item = item     yield (item, count)     return   import unittest class TestListCounters(unittest.TestCase):     def test_count_unsorted_list_items(self):         D = (             ([], []),             ([2], [(2,1)]),             ([2,2], [(2,2)]),             ([2,2,2,2,3,3,5,5], [(2,4), (3,2), (5,2)]),             )         for inp, exp_outp in D:             counts = count_unsorted_list_items(inp)              print inp, exp_outp, counts             self.assertEqual(counts, dict( exp_outp ))          inp, exp_outp = UNSORTED_WIN = ([2,2,4,2], [(2,3), (4,1)])         self.assertEqual(dict( exp_outp ), count_unsorted_list_items(inp) )       def test_count_sorted_list_items(self):         D = (             ([], []),             ([2], [(2,1)]),             ([2,2], [(2,2)]),             ([2,2,2,2,3,3,5,5], [(2,4), (3,2), (5,2)]),             )         for inp, exp_outp in D:             counts = list( count_sorted_list_items(inp) )             print inp, exp_outp, counts             self.assertEqual(counts, exp_outp)          inp, exp_outp = UNSORTED_FAIL = ([2,2,4,2], [(2,3), (4,1)])         self.assertEqual(exp_outp, list( count_sorted_list_items(inp) ))         # ... [(2,2), (4,1), (2,1)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "6", "A_Content": "  To count the number of diverse elements having a common type:  li = ['A0','c5','A8','A2','A5','c2','A3','A9']  print sum(1 for el in li if el[0]=='A' and el[1] in '01234')   gives  3  , not 6     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "4", "A_Content": "  from collections import Counter country=['Uruguay', 'Mexico', 'Uruguay', 'France', 'Mexico'] count_country = Counter(country) output_list= []   for i in count_country:     output_list.append([i,count_country[i]]) print output_list   Output list:  [['Mexico', 2], ['France', 1], ['Uruguay', 2]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "3", "A_Content": "  You can also use countOf method of a built-in module operator.  >>> import operator >>> operator.countOf([1, 2, 3, 4, 1, 4, 1], 1) 3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "1", "A_Content": "  sum([1 for elem in <yourlist> if elem==<your_value>])   This will return the amount of occurences of your_value     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "0", "A_Content": "  May not be the most efficient, requires an extra pass to remove duplicates.   Functional implementation :   arr = np.array(['a','a','b','b','b','c']) print(set(map(lambda x  : (x , list(arr).count(x)) , arr)))   returns :   {('c', 1), ('b', 3), ('a', 2)}   or return as dict :  print(dict(map(lambda x  : (x , list(arr).count(x)) , arr)))   returns :   {'b': 3, 'c': 1, 'a': 2}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "0", "A_Content": "  if you want a number of occurrences for the particular element:  >>> from collections import Counter >>> z = ['blue', 'red', 'blue', 'yellow', 'blue', 'red'] >>> single_occurrences = Counter(z) >>> print(single_occurrences.get(\"blue\")) 3 >>> print(single_occurrences.values()) dict_values([3, 2, 1])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2600191/how-to-count-the-occurrences-of-a-list-item", "Language": "Python", "Q_Title": "How to count the occurrences of a list item?", "Q_Votes": "1111", "Q_Content": "    Given an item, how can I count its occurrences in a list in Python?     ", "Tags": ["python", "list", "count"], "A_Votes": "0", "A_Content": "  def countfrequncyinarray(arr1):     r=len(arr1)     return {i:arr1.count(i) for i in range(1,r+1)} arr1=[4,4,4,4] a=countfrequncyinarray(arr1) print(a)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/990754/how-to-leave-exit-deactivate-a-python-virtualenv", "Language": "Python", "Q_Title": "How to leave/exit/deactivate a python virtualenv?", "Q_Votes": "1094", "Q_Content": "    I'm using virtualenv and the virtualenvwrapper. I can switch between virtualenv's just fine using the workon command.   me@mymachine:~$ workon env1 (env1)me@mymachine:~$ workon env2 (env2)me@mymachine:~$ workon env1 (env1)me@mymachine:~$    However, how do I exit all virtual machines and workon my real machine again? Right now, the only way I have of getting back to  me@mymachine:~$    is to exit the shell and start a new one. That's kind of annoying. Is there a command to workon \"nothing\", and if so, what is it? If such a command does not exist, how would I go about creating it?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "1807", "A_Content": "  Usually, activating a virtualenv gives you a shell function named:  $ deactivate   which puts things back to normal.  Edit 1  I have just looked specifically again at the code for virtualenvwrapper, and, yes, it too supports deactivate as the way to escape from all virtualenvs.  Edit 2  If you are trying to leave an Anaconda environment, the procedure is a bit different: run the two-word command source deactivate since they implement deactivation using a stand-alone script.  bash-4.3$ deactivate pyenv-virtualenv: deactivate must be sourced. Run 'source deactivate' instead of 'deactivate' bash-4.3$ source deactivate pyenv-virtualenv: no virtualenv has been activated.      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/990754/how-to-leave-exit-deactivate-a-python-virtualenv", "Language": "Python", "Q_Title": "How to leave/exit/deactivate a python virtualenv?", "Q_Votes": "1094", "Q_Content": "    I'm using virtualenv and the virtualenvwrapper. I can switch between virtualenv's just fine using the workon command.   me@mymachine:~$ workon env1 (env1)me@mymachine:~$ workon env2 (env2)me@mymachine:~$ workon env1 (env1)me@mymachine:~$    However, how do I exit all virtual machines and workon my real machine again? Right now, the only way I have of getting back to  me@mymachine:~$    is to exit the shell and start a new one. That's kind of annoying. Is there a command to workon \"nothing\", and if so, what is it? If such a command does not exist, how would I go about creating it?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "33", "A_Content": "  I defined an alias workoff as the opposite of workon:  alias workoff='deactivate'   Easy to remember:  [bobstein@host ~]$ workon django_project (django_project)[bobstein@host ~]$ workoff [bobstein@host ~]$      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/990754/how-to-leave-exit-deactivate-a-python-virtualenv", "Language": "Python", "Q_Title": "How to leave/exit/deactivate a python virtualenv?", "Q_Votes": "1094", "Q_Content": "    I'm using virtualenv and the virtualenvwrapper. I can switch between virtualenv's just fine using the workon command.   me@mymachine:~$ workon env1 (env1)me@mymachine:~$ workon env2 (env2)me@mymachine:~$ workon env1 (env1)me@mymachine:~$    However, how do I exit all virtual machines and workon my real machine again? Right now, the only way I have of getting back to  me@mymachine:~$    is to exit the shell and start a new one. That's kind of annoying. Is there a command to workon \"nothing\", and if so, what is it? If such a command does not exist, how would I go about creating it?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "25", "A_Content": "  $ deactivate    If this doesn't work , try   $ source deactivate   Anyone who knows how bash source works will think that's odd, but some wrappers/workflows around virtualenv implement as a compliment/counterpart to source activate. YMMV     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/990754/how-to-leave-exit-deactivate-a-python-virtualenv", "Language": "Python", "Q_Title": "How to leave/exit/deactivate a python virtualenv?", "Q_Votes": "1094", "Q_Content": "    I'm using virtualenv and the virtualenvwrapper. I can switch between virtualenv's just fine using the workon command.   me@mymachine:~$ workon env1 (env1)me@mymachine:~$ workon env2 (env2)me@mymachine:~$ workon env1 (env1)me@mymachine:~$    However, how do I exit all virtual machines and workon my real machine again? Right now, the only way I have of getting back to  me@mymachine:~$    is to exit the shell and start a new one. That's kind of annoying. Is there a command to workon \"nothing\", and if so, what is it? If such a command does not exist, how would I go about creating it?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "10", "A_Content": "  to activate python virtual environment:  $cd ~/python-venv/ $./bin/activate   to deactivate:  $deactivate      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/990754/how-to-leave-exit-deactivate-a-python-virtualenv", "Language": "Python", "Q_Title": "How to leave/exit/deactivate a python virtualenv?", "Q_Votes": "1094", "Q_Content": "    I'm using virtualenv and the virtualenvwrapper. I can switch between virtualenv's just fine using the workon command.   me@mymachine:~$ workon env1 (env1)me@mymachine:~$ workon env2 (env2)me@mymachine:~$ workon env1 (env1)me@mymachine:~$    However, how do I exit all virtual machines and workon my real machine again? Right now, the only way I have of getting back to  me@mymachine:~$    is to exit the shell and start a new one. That's kind of annoying. Is there a command to workon \"nothing\", and if so, what is it? If such a command does not exist, how would I go about creating it?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "1", "A_Content": "  You can use virtualenvwrapper in order to ease the way you work with virtualenv  Installing virtualenvwrapper  pip install virtualenvwrapper   If you are using standard shell, open your ~/.bashrc or ~/.zshrc if you use oh-my-zsh. Add this two lines:  export WORKON_HOME=$HOME/.virtualenvs   source /usr/local/bin/virtualenvwrapper.sh   To activate an existing virtualenv, use command workon:  $ workon myenv (myenv)$   In order to deactivate your virtualenv:  (myenv)$ deactivate   Here is my tutorial, step by step in how to install virtualenv and virtualenvwrapper     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/990754/how-to-leave-exit-deactivate-a-python-virtualenv", "Language": "Python", "Q_Title": "How to leave/exit/deactivate a python virtualenv?", "Q_Votes": "1094", "Q_Content": "    I'm using virtualenv and the virtualenvwrapper. I can switch between virtualenv's just fine using the workon command.   me@mymachine:~$ workon env1 (env1)me@mymachine:~$ workon env2 (env2)me@mymachine:~$ workon env1 (env1)me@mymachine:~$    However, how do I exit all virtual machines and workon my real machine again? Right now, the only way I have of getting back to  me@mymachine:~$    is to exit the shell and start a new one. That's kind of annoying. Is there a command to workon \"nothing\", and if so, what is it? If such a command does not exist, how would I go about creating it?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "0", "A_Content": "  I use zsh-autoenv which is based off autoenv.      zsh-autoenv automatically   sources (known/whitelisted) .autoenv.zsh files, typically used in   project root directories. It handles \"enter\" and leave\" events,   nesting, and stashing of variables (overwriting and restoring).   Here is an example:  ; cd dtree  Switching to virtual environment: Development tree utiles ;dtree(feature/task24|\u2713); cat .autoenv.zsh        # Autoenv. echo -n \"Switching to virtual environment: \" printf \"\\e[38;5;93m%s\\e[0m\\n\" \"Development tree utiles\" workon dtree # eof dtree(feature/task24|\u2713); cat .autoenv_leave.zsh  deactivate   So when I leave the dtree directory, the virtual environment is automatically exited.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/990754/how-to-leave-exit-deactivate-a-python-virtualenv", "Language": "Python", "Q_Title": "How to leave/exit/deactivate a python virtualenv?", "Q_Votes": "1094", "Q_Content": "    I'm using virtualenv and the virtualenvwrapper. I can switch between virtualenv's just fine using the workon command.   me@mymachine:~$ workon env1 (env1)me@mymachine:~$ workon env2 (env2)me@mymachine:~$ workon env1 (env1)me@mymachine:~$    However, how do I exit all virtual machines and workon my real machine again? Right now, the only way I have of getting back to  me@mymachine:~$    is to exit the shell and start a new one. That's kind of annoying. Is there a command to workon \"nothing\", and if so, what is it? If such a command does not exist, how would I go about creating it?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "0", "A_Content": "  (my_env) basant@basant:~/EonTraining/my_env$ deactivate  use 'deactivate'  basant@basant-Lenovo-E40-80:~/EonTraining/my_env$   Gone (my_env);     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/990754/how-to-leave-exit-deactivate-a-python-virtualenv", "Language": "Python", "Q_Title": "How to leave/exit/deactivate a python virtualenv?", "Q_Votes": "1094", "Q_Content": "    I'm using virtualenv and the virtualenvwrapper. I can switch between virtualenv's just fine using the workon command.   me@mymachine:~$ workon env1 (env1)me@mymachine:~$ workon env2 (env2)me@mymachine:~$ workon env1 (env1)me@mymachine:~$    However, how do I exit all virtual machines and workon my real machine again? Right now, the only way I have of getting back to  me@mymachine:~$    is to exit the shell and start a new one. That's kind of annoying. Is there a command to workon \"nothing\", and if so, what is it? If such a command does not exist, how would I go about creating it?     ", "Tags": ["python", "virtualenv", "virtualenvwrapper"], "A_Votes": "-2", "A_Content": "  Had the same problem myself while working on an installer script, I took a look at what the bin/activate_this.py did and reversed it.   Example:  #! /usr/bin/python # -*- coding: utf-8 -*- import os import sys  # path to virtualenv venv_path = os.path.join('/home', 'sixdays', '.virtualenvs', 'test32')  # Save old values old_os_path = os.environ['PATH'] old_sys_path = list(sys.path) old_sys_prefix = sys.prefix   def deactivate():     # Change back by setting values to starting values     os.environ['PATH'] = old_os_path     sys.prefix = old_sys_prefix     sys.path[:0] = old_sys_path   # Activate the virtualenvironment activate_this = os.path.join(venv_path, 'bin/activate_this.py') execfile(activate_this, dict(__file__=activate_this))   # Print list of pip packages for virtualenv for example purpose import pip print str(pip.get_installed_distributions()) # Unload pip module del pip  # deactive/switch back to initial interpreter deactivate()  # print list of initial environment pip packages for example purpose import pip print str(pip.get_installed_distributions())   Not 100% sure if it works as intended, I may have missed something completely.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "2256", "A_Content": "  How about:  >>> 'hello world'[::-1] 'dlrow olleh'   This is extended slice syntax. It works by doing [begin:end:step] - by leaving begin and end off and specifying a step of -1, it reverses a string.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "221", "A_Content": "  @Paolo's s[::-1] is fastest; a slower approach (maybe more readable, but that's debatable) is ''.join(reversed(s)).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "170", "A_Content": "     What is the best way of implementing a reverse function for strings?   My own experience with this question is academic. However, if you're a pro looking for the quick answer, use a slice that steps by -1:  >>> 'a string'[::-1] 'gnirts a'   or more readably (but slower due to the method name lookups and the fact that join forms a list when given an iterator), str.join:  >>> ''.join(reversed('a string')) 'gnirts a'   or for readability and reusability, put the slice in a function  def reversed_string(a_string):     return a_string[::-1]   and then:  >>> reversed_string('a_string') 'gnirts_a'   Longer explanation  If you're interested in the academic exposition, please keep reading.     There is no built-in reverse function in Python's str object.    Here is a couple of things about Python's strings you should know:   In Python, strings are immutable. Changing a string does not modify the string. It creates a new one. Strings are sliceable. Slicing a string gives you a new string from one point in the string, backwards or forwards, to another point, by given increments. They take slice notation or a slice object in a subscript:  string[subscript]    The subscript creates a slice by including a colon within the braces:      string[start:stop:step]   To create a slice outside of the braces, you'll need to create a slice object:      slice_obj = slice(start, stop, step)     string[slice_obj]   A readable approach:  While ''.join(reversed('foo')) is readable, it requires calling a string method, str.join, on another called function, which can be rather relatively slow. Let's put this in a function - we'll come back to it:  def reverse_string_readable_answer(string):     return ''.join(reversed(string))   Most performant approach:  Much faster is using a reverse slice:  'foo'[::-1]   But how can we make this more readable and understandable to someone less familiar with slices or the intent of the original author? Let's create a slice object outside of the subscript notation, give it a descriptive name, and pass it to the subscript notation.  start = stop = None step = -1 reverse_slice = slice(start, stop, step) 'foo'[reverse_slice]   Implement as Function  To actually implement this as a function, I think it is semantically clear enough to simply use a descriptive name:  def reversed_string(a_string):     return a_string[::-1]   And usage is simply:  reversed_string('foo')   What your teacher probably wants:  If you have an instructor, they probably want you to start with an empty string, and build up a new string from the old one. You can do this with pure syntax and literals using a while loop:  def reverse_a_string_slowly(a_string):     new_string = ''     index = len(a_string)     while index:         index -= 1                    # index = index - 1         new_string += a_string[index] # new_string = new_string + character     return new_string   This is theoretically bad because, remember, strings are immutable - so every time where it looks like you're appending a character onto your new_string, it's theoretically creating a new string every time! However, CPython knows how to optimize this in certain cases, of which this trivial case is one.  Best Practice  Theoretically better is to collect your substrings in a list, and join them later:  def reverse_a_string_more_slowly(a_string):     new_strings = []     index = len(a_string)     while index:         index -= 1                                new_strings.append(a_string[index])     return ''.join(new_strings)   However, as we will see in the timings below for CPython, this actually takes longer, because CPython can optimize the string concatenation.  Timings  Here are the timings:  >>> a_string = 'amanaplanacanalpanama' * 10 >>> min(timeit.repeat(lambda: reverse_string_readable_answer(a_string))) 10.38789987564087 >>> min(timeit.repeat(lambda: reversed_string(a_string))) 0.6622700691223145 >>> min(timeit.repeat(lambda: reverse_a_string_slowly(a_string))) 25.756799936294556 >>> min(timeit.repeat(lambda: reverse_a_string_more_slowly(a_string))) 38.73570013046265   CPython optimizes string concatenation, whereas other implementations may not:     ... do not rely on CPython's efficient implementation of in-place string concatenation for statements in the form  a += b  or  a = a + b  . This optimization is fragile even in CPython (it only works for some types) and isn't present at all in implementations that don't use refcounting. In performance sensitive parts of the library, the  ''.join()   form should be used instead. This will ensure that concatenation occurs in linear time across various implementations.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "33", "A_Content": "  Quick Answer (TL;DR)  Example  ### example01 ------------------- mystring  =   'coup_ate_grouping' backwards =   mystring[::-1] print backwards  ### ... or even ... mystring  =   'coup_ate_grouping'[::-1] print mystring  ### result01 ------------------- ''' gnipuorg_eta_puoc '''   Detailed Answer  Background  This answer is provided to address the following concern from @odigity:     Wow. I was horrified at first by the solution Paolo proposed, but that    took a back seat to the horror I felt upon reading the first   comment: \"That's very pythonic. Good job!\" I'm so disturbed that such   a bright community thinks using such cryptic methods for something so   basic is a good idea. Why isn't it just s.reverse()?   Problem   Context   Python 2.x Python 3.x  Scenario:   Developer wants to transform a string Transformation is to reverse order of all the characters    Solution   example01 produces the desired result, using extended slice notation.           Pitfalls   Developer might expect something like string.reverse() The native idiomatic (aka \"pythonic\") solution may not be readable to newer developers Developer may be tempted to implement his or her own version of string.reverse() to avoid slice notation. The output of slice notation may be counter-intuitive in some cases:   see e.g., example02   print 'coup_ate_grouping'[-4:]    ## => 'ping' compared to print 'coup_ate_grouping'[-4:-1]  ## => 'pin' compared to print 'coup_ate_grouping'[-1]  ## => 'g'  the different outcomes of indexing on [-1] may throw some developers off    Rationale  Python has a special circumstance to be aware of: a string is an iterable type.  One rationale for excluding a string.reverse() method is to give python developers incentive to leverage the power of this special circumstance.  In simplified terms, this simply means each individual character in a string can be easily operated on as a part of a sequential arrangement of elements, just like arrays in other programming languages.  To understand how this works, reviewing example02 can provide a good overview.  Example02  ### example02 ------------------- ## start (with positive integers) print 'coup_ate_grouping'[0]  ## => 'c' print 'coup_ate_grouping'[1]  ## => 'o'  print 'coup_ate_grouping'[2]  ## => 'u'   ## start (with negative integers) print 'coup_ate_grouping'[-1]  ## => 'g' print 'coup_ate_grouping'[-2]  ## => 'n'  print 'coup_ate_grouping'[-3]  ## => 'i'   ## start:end  print 'coup_ate_grouping'[0:4]    ## => 'coup'     print 'coup_ate_grouping'[4:8]    ## => '_ate'     print 'coup_ate_grouping'[8:12]   ## => '_gro'      ## start:end  print 'coup_ate_grouping'[-4:]    ## => 'ping' (counter-intuitive) print 'coup_ate_grouping'[-4:-1]  ## => 'pin' print 'coup_ate_grouping'[-4:-2]  ## => 'pi' print 'coup_ate_grouping'[-4:-3]  ## => 'p' print 'coup_ate_grouping'[-4:-4]  ## => '' print 'coup_ate_grouping'[0:-1]   ## => 'coup_ate_groupin' print 'coup_ate_grouping'[0:]     ## => 'coup_ate_grouping' (counter-intuitive)  ## start:end:step (or start:end:stride) print 'coup_ate_grouping'[-1::1]  ## => 'g'    print 'coup_ate_grouping'[-1::-1] ## => 'gnipuorg_eta_puoc'  ## combinations print 'coup_ate_grouping'[-1::-1][-4:] ## => 'puoc'   Conclusion  The cognitive load associated with understanding how slice notation works in python may indeed be too much for some adopters and developers who do not wish to invest much time in learning the language.  Nevertheless, once the basic principles are understood, the power of this approach over fixed string manipulation methods can be quite favorable.  For those who think otherwise, there are alternate approaches, such as lambda functions, iterators, or simple one-off function declarations.  If desired, a developer can implement her own string.reverse() method, however it is good to understand the rationale behind this aspect of python.  See also   alternate simple approach alternate simple approach alternate explanation of slice notation              ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "11", "A_Content": "  A lesser perplexing way to look at it would be:  string = 'happy' print(string)      'happy'   string_reversed = string[-1::-1] print(string_reversed)      'yppah'   In English [-1::-1] reads as:     \"Starting at -1,  go all the way,  taking steps of -1\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "4", "A_Content": "  Reverse a string in python without using reversed() or [::-1]  def reverse(test):     n = len(test)     x=\"\"     for i in range(n-1,-1,-1):         x += test[i]     return x      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "3", "A_Content": "  def reverse(input):     return reduce(lambda x,y : y+x, input)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "3", "A_Content": "  using slice notation  def rev_string(s):      return s[::-1]   using reversed() function  def rev_string(s):      return ''.join(reversed(s))   using recursion  def rev_string(s):      if len(s) == 1:         return s      return s[-1] + rev_string(s[:-1])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "2", "A_Content": "  Here is a no fancy one:  def reverse(text):     r_text = ''     index = len(text) - 1      while index >= 0:         r_text += text[index] #string canbe concatenated         index -= 1      return r_text  print reverse(\"hello, world!\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "2", "A_Content": "  Another alternative, (not efficient! just to show the diversity of Python with so many possible solutions!): convert the string to a list using the list() function. A list value is a mutable data type. Therefore we can use the method reverse() which reverses the objects of a list in place. And then we convert the list back to a string using the list join method with an empty separator:   >>> s = 'hello world' >>> s 'hello world' >>> t = list(s) # convert to list >>> t ['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd'] >>> t.reverse() # reverse method of list >>> t ['d', 'l', 'r', 'o', 'w', ' ', 'o', 'l', 'l', 'e', 'h'] >>> s = ''.join(t) # convert to string >>> s 'dlrow olleh'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "1", "A_Content": "  Here is one without [::-1] or reversed (for learning purposes):  def reverse(text):     new_string = []     n = len(text)     while (n > 0):         new_string.append(text[n-1])         n -= 1     return ''.join(new_string) print reverse(\"abcd\")   you can use += to concatenate strings but join() is faster.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "1", "A_Content": "  Recursive method:  def reverse(s): return s[0] if len(s)==1 else s[len(s)-1] + reverse(s[0:len(s)-1])   example:  print(reverse(\"Hello!\"))    #!olleH      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "1", "A_Content": "  All of the above solutions are perfect but if we are trying to reverse a string using for loop in python will became a little bit tricky so here is how we can reverse a string using for loop  string =\"hello,world\" for i in range(-1,-len(string)-1,-1):     print (string[i],end=(\" \"))    I hope this one will be helpful for someone.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "0", "A_Content": "  Here is simply:  print \"loremipsum\"[-1::-1]  and some logically:  def str_reverse_fun():     empty_list = []     new_str = 'loremipsum'     index = len(new_str)     while index:         index = index - 1         empty_list.append(new_str[index])     return ''.join(empty_list) print str_reverse_fun()   output:  muspimerol     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "0", "A_Content": "  def rev(str1):       print( str1[::-1])  str1=\"123\" r=rev(str1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "0", "A_Content": "  This is simple and meaningful reverse function, easy to understand and code  def reverse_sentence(text):     words = text.split(\" \")     reverse =\"\"     for word in reversed(words):         reverse += word+ \" \"     return reverse      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/931092/reverse-a-string-in-python", "Language": "Python", "Q_Title": "Reverse a string in Python", "Q_Votes": "1092", "Q_Content": "    There is no built in reverse function for Python's str object. What is the best way of implementing this method?  If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc.      ", "Tags": ["python", "string"], "A_Votes": "-1", "A_Content": "  s = 'Hello world'  s[::-1]  in the above example label s or variable s is holding string which contain Hello world string and on second step i m printing reverse of Hello world string by taking starting from everything to everything in reverse step order with -1.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "690", "A_Content": "  figure tells you the call signature:  from matplotlib.pyplot import figure figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')   figure(figsize=(1,1)) would create an inch-by-inch image, which would be 80-by-80 pixels unless you also give a different dpi argument.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "541", "A_Content": "  If you've already got the figure created you can quickly do this:  fig = matplotlib.pyplot.gcf() fig.set_size_inches(18.5, 10.5) fig.savefig('test2png.png', dpi=100)   To propagate the size change to an existing gui window add forward=True  fig.set_size_inches(18.5, 10.5, forward=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "260", "A_Content": "     Deprecation note:   As per the official Matplotlib guide, usage of the pylab module is no longer recommended. Please consider using the matplotlib.pyplot module instead, as described by this other answer.   The following seems to work:  from pylab import rcParams rcParams['figure.figsize'] = 5, 10   This makes the figure's width 5 inches, and its height 10 inches.   The Figure class then uses this as the default value for one of its arguments.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "159", "A_Content": "  Please try a simple code as following:  from matplotlib import pyplot as plt plt.figure(figsize=(1,1)) x = [1,2,3] plt.plot(x, x) plt.show()   You need to set the figure size before you plot.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "132", "A_Content": "  USING  plt.rcParams  There is also this workaround in case you want to change the size without using the figure environment. So in case you are using plt.plot() for example.  import matplotlib.pyplot as plt plt.rcParams[\"figure.figsize\"] = (20,3)   This is very useful when you plot inline (e.g. with IPython Notebook).  Conversion to cm  The figsize tuple accepts inches so if you want to set it in centimetres you have to divide them by 2.54 have a look to this question.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "69", "A_Content": "  The first link in Google for 'matplotlib figure size' is AdjustingImageSize (Google cache of the page).  Here's a test script from the above page. It creates test[1-3].png files of different sizes of the same image:  #!/usr/bin/env python \"\"\" This is a small demo file that helps teach how to adjust figure sizes for matplotlib  \"\"\"  import matplotlib print \"using MPL version:\", matplotlib.__version__ matplotlib.use(\"WXAgg\") # do this before pylab so you don'tget the default back end.  import pylab import numpy as np  # Generate and plot some simple data: x = np.arange(0, 2*np.pi, 0.1) y = np.sin(x)  pylab.plot(x,y) F = pylab.gcf()  # Now check everything with the defaults: DPI = F.get_dpi() print \"DPI:\", DPI DefaultSize = F.get_size_inches() print \"Default size in Inches\", DefaultSize print \"Which should result in a %i x %i Image\"%(DPI*DefaultSize[0], DPI*DefaultSize[1]) # the default is 100dpi for savefig: F.savefig(\"test1.png\") # this gives me a 797 x 566 pixel image, which is about 100 DPI  # Now make the image twice as big, while keeping the fonts and all the # same size F.set_size_inches( (DefaultSize[0]*2, DefaultSize[1]*2) ) Size = F.get_size_inches() print \"Size in Inches\", Size F.savefig(\"test2.png\") # this results in a 1595x1132 image  # Now make the image twice as big, making all the fonts and lines # bigger too.  F.set_size_inches( DefaultSize )# resetthe size Size = F.get_size_inches() print \"Size in Inches\", Size F.savefig(\"test3.png\", dpi = (200)) # change the dpi # this also results in a 1595x1132 image, but the fonts are larger.   Output:  using MPL version: 0.98.1 DPI: 80 Default size in Inches [ 8.  6.] Which should result in a 640 x 480 Image Size in Inches [ 16.  12.] Size in Inches [ 16.  12.]   Two notes:   The module comments and the actual output differ. This answer allows easily to combine all three images in one image file to see the difference in sizes.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "42", "A_Content": "  In case you're looking for a way to change the figure size in Pandas, you could do e.g.:  df['some_column'].plot(figsize=(10, 5))   where df is a Pandas dataframe. If you want to change the default settings, you could do the following:  import matplotlib  matplotlib.rc('figure', figsize=(10, 5))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "21", "A_Content": "  You can simply use (from matplotlib.figure.Figure):  fig.set_size_inches(width,height)   As of Matplotlib 2.0.0, changes to your canvas will be visible immediately, as the forward keyword defaults to True.  If you want to just change the width or height instead of both, you can use   fig.set_figwidth(val) or fig.set_figheight(val)  These will also immediately update your canvas, but only in Matplotlib 2.2.0 and newer.  For Older Versions  You need to specify forward=True explicitly in order to live-update your canvas in versions older than what is specified above. Note that the set_figwidth and set_figheight functions don\u2019t support the forward parameter in versions older than Matplotlib 1.5.0.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "20", "A_Content": "  Try commenting out the fig = ... line  %matplotlib inline import numpy as np import matplotlib.pyplot as plt  N = 50 x = np.random.rand(N) y = np.random.rand(N) area = np.pi * (15 * np.random.rand(N))**2  fig = plt.figure(figsize=(18, 18)) plt.scatter(x, y, s=area, alpha=0.5) plt.show()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "13", "A_Content": "  To increase size of your figure N times you need to insert this just before your pl.show():  N = 2 params = pl.gcf() plSize = params.get_size_inches() params.set_size_inches( (plSize[0]*N, plSize[1]*N) )   It also works well with ipython notebook.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "9", "A_Content": "  This works well for me:  from matplotlib import pyplot as plt F = gcf() Size = F.get_size_inches() F.set_size_inches(Size[0]*2, Size[1]*2, forward=True)#Set forward to True to resize window along with plot in figure. plt.show() #or plt.imshow(z_array) if using an animation, where z_array is a matrix or numpy array   This might also help: http://matplotlib.1069221.n5.nabble.com/Resizing-figure-windows-td11424.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "8", "A_Content": "  Since Matplotlib isn't able to use the metric system natively, if you want to specify the size of your figure in a reasonable unit of length such as centimeters, you can do the following (code from gns-ank):  def cm2inch(*tupl):     inch = 2.54     if isinstance(tupl[0], tuple):         return tuple(i/inch for i in tupl[0])     else:         return tuple(i/inch for i in tupl)   Then you can use:  plt.figure(figsize=cm2inch(21, 29.7))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib", "Language": "Python", "Q_Title": "How do you change the size of figures drawn with matplotlib?", "Q_Votes": "1141", "Q_Content": "    How do you change the size of figure drawn with matplotlib?     ", "Tags": ["python", "graph", "matplotlib", "plot", "visualization"], "A_Votes": "7", "A_Content": "  This resizes the figure immediately even after the figure has been drawn (at least using Qt4Agg/TkAgg - but not MacOSX - with matplotlib 1.4.0):  matplotlib.pyplot.get_current_fig_manager().resize(width_px, height_px)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "1165", "A_Content": "  Just assign it to the .columns attribute:  >>> df = pd.DataFrame({'$a':[1,2], '$b': [10,20]}) >>> df.columns = ['a', 'b'] >>> df    a   b 0  1  10 1  2  20      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "1912", "A_Content": "  Use the df.rename() function and refer the columns to be renamed. Not all the columns have to be renamed:  df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}) # Or rename the existing DataFrame (rather than creating a copy)  df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "300", "A_Content": "  The rename method can take a function, for example:  In [11]: df.columns Out[11]: Index([u'$a', u'$b', u'$c', u'$d', u'$e'], dtype=object)  In [12]: df.rename(columns=lambda x: x[1:], inplace=True)  In [13]: df.columns Out[13]: Index([u'a', u'b', u'c', u'd', u'e'], dtype=object)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "127", "A_Content": "  As documented in http://pandas.pydata.org/pandas-docs/stable/text.html:  df.columns = df.columns.str.replace('$','')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "116", "A_Content": "  Since you only want to remove the $ sign in all column names, you could just do:  df = df.rename(columns=lambda x: x.replace('$', ''))   OR  df.rename(columns=lambda x: x.replace('$', ''), inplace=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "97", "A_Content": "  Pandas 0.21+ Answer  There have been some significant updates to column renaming in version 0.21.    The rename method has added the axis parameter which may be set to columns or 1. This update makes this method match the rest of the pandas API. It still has the index and columns parameters but you are no longer forced to use them.  The set_axis method with the inplace set to False enables you to rename all the index or column labels with a list.   Examples for Pandas 0.21+  Construct sample DataFrame:  df = pd.DataFrame({'$a':[1,2], '$b': [3,4],                     '$c':[5,6], '$d':[7,8],                     '$e':[9,10]})     $a  $b  $c  $d  $e 0   1   3   5   7   9 1   2   4   6   8  10   Using rename with axis='columns' or axis=1  df.rename({'$a':'a', '$b':'b', '$c':'c', '$d':'d', '$e':'e'}, axis='columns')   or   df.rename({'$a':'a', '$b':'b', '$c':'c', '$d':'d', '$e':'e'}, axis=1)   Both result in the following:     a  b  c  d   e 0  1  3  5  7   9 1  2  4  6  8  10   It is still possible to use the old method signature:  df.rename(columns={'$a':'a', '$b':'b', '$c':'c', '$d':'d', '$e':'e'})   The rename function also accepts functions that will be applied to each column name.  df.rename(lambda x: x[1:], axis='columns')   or  df.rename(lambda x: x[1:], axis=1)     Using set_axis with a list and inplace=False  You can supply a list to the set_axis method that is equal in length to the number of columns (or index). Currently, inplace defaults to True, but inplace will be defaulted to False in future releases.  df.set_axis(['a', 'b', 'c', 'd', 'e'], axis='columns', inplace=False)   or  df.set_axis(['a', 'b', 'c', 'd', 'e'], axis=1, inplace=False)     Why not use df.columns = ['a', 'b', 'c', 'd', 'e']?  There is nothing wrong with assigning columns directly like this. It is a perfectly good solution.   The advantage of using set_axis is that it can be used as part of a method chain and that it returns a new copy of the DataFrame. Without it, you would have to store your intermediate steps of the chain to another variable before reassigning the columns.  # new for pandas 0.21+ df.some_method1()   .some_method2()   .set_axis()   .some_method3()  # old way df1 = df.some_method1()         .some_method2() df1.columns = columns df1.some_method3()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "68", "A_Content": "  df.columns = ['a', 'b', 'c', 'd', 'e']   It will replace the existing names with the names you provide, in the order you provide.  You can also assign them by index like this:  df.columns.values[2] = 'c'    #renames the 2nd column to 'c' (in position #3)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "54", "A_Content": "  old_names = ['$a', '$b', '$c', '$d', '$e']  new_names = ['a', 'b', 'c', 'd', 'e'] df.rename(columns=dict(zip(old_names, new_names)), inplace=True)   This way you can manually edit the new_names as you wish. Works great when you need to rename only a few columns to correct mispellings, accents, remove special characters etc.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "34", "A_Content": "  I think this method is useful:  df.rename(columns={\"old_column_name1\":\"new_column_name1\", \"old_column_name2\":\"new_column_name2\"})   This method allows you to change column names individually.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "31", "A_Content": "  Column names vs Names of Series  I would like to explain a bit what happens behind the scenes.  Dataframes are a set of Series.  Series in turn are an extension of a numpy.array  numpy.arrays have a property .name  This is the name of the series. It is seldom that pandas respects this attribute, but it lingers in places and can be used to hack some pandas behaviors.  Naming the list of columns  A lot of answers here talks about the df.columns attribute being a list when in fact it is a Series. This means it has a .name attribute.  This is what happens if you decide to fill in the name of the columns Series:  df.columns = ['column_one', 'column_two'] df.columns.names = ['name of the list of columns'] df.index.names = ['name of the index']  name of the list of columns     column_one  column_two name of the index        0                                    4           1 1                                    5           2 2                                    6           3   Note that the name of the index always comes one column lower.  Artifacts that linger  The .name attribute lingers on sometimes. If you set df.columns = ['one', 'two'] then the df.one.name will be 'one'.  If you set df.one.name = 'three' then df.columns will still give you ['one', 'two'], and df.one.name will give you 'three'  BUT  pd.DataFrame(df.one) will return      three 0       1 1       2 2       3   Because pandas reuses the .name of the already defined Series.  Multi level column names  Pandas has ways of doing multi layered column names. There is not so much magic involved but I wanted to cover this in my answer too since I don't see anyone picking up on this here.      |one            |     |one      |two  | 0   |  4      |  1  | 1   |  5      |  2  | 2   |  6      |  3  |   This is easily achievable by setting columns to lists, like this:  df.columns = [['one', 'one'], ['one', 'two']]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "28", "A_Content": "  One line or Pipeline solutions  I'll focus on two things:   OP clearly states     I have the edited column names stored it in a list, but I don't know how to replace the column names.     I do not want to solve the problem of how to replace '$' or strip the first character off of each column header.  OP has already done this step.  Instead I want to focus on replacing the existing columns object with a new one given a list of replacement column names. df.columns = new where new is the list of new columns names is as simple as it gets.  The drawback of this approach is that it requires editing the existing dataframe's columns attribute and it isn't done inline.  I'll show a few ways to perform this via pipelining without editing the existing dataframe.     Setup 1 To focus on the need to rename of replace column names with a pre-existing list, I'll create a new sample dataframe df with initial column names and unrelated new column names.  df = pd.DataFrame({'Jack': [1, 2], 'Mahesh': [3, 4], 'Xin': [5, 6]}) new = ['x098', 'y765', 'z432']  df     Jack  Mahesh  Xin 0     1       3    5 1     2       4    6     Solution 1 pd.DataFrame.rename    It has been said already that if you had a dictionary mapping the old column names to new column names, you could use pd.DataFrame.rename.  d = {'Jack': 'x098', 'Mahesh': 'y765', 'Xin': 'z432'} df.rename(columns=d)     x098  y765  z432 0     1     3     5 1     2     4     6   However, you can easily create that dictionary and include it in the call to rename.  The following takes advantage of the fact that when iterating over df, we iterate over each column name.  # given just a list of new column names df.rename(columns=dict(zip(df, new)))     x098  y765  z432 0     1     3     5 1     2     4     6   This works great if your original column names are unique.  But if they are not, then this breaks down.    Setup 2 non-unique columns    df = pd.DataFrame(     [[1, 3, 5], [2, 4, 6]],     columns=['Mahesh', 'Mahesh', 'Xin'] ) new = ['x098', 'y765', 'z432']  df     Mahesh  Mahesh  Xin 0       1       3    5 1       2       4    6     Solution 2 pd.concat using the keys argument    First, notice what happens when we attempt to use solution 1:  df.rename(columns=dict(zip(df, new)))     y765  y765  z432 0     1     3     5 1     2     4     6   We didn't map the new list as the column names.  We ended up repeating y765.  Instead, we can use the keys argument of the pd.concat function while iterating through the columns of df.  pd.concat([c for _, c in df.items()], axis=1, keys=new)      x098  y765  z432 0     1     3     5 1     2     4     6     Solution 3 Reconstruct.  This should only be used if you have a single dtype for all columns.  Otherwise, you'll end up with dtype object for all columns and converting them back requires more dictionary work.  Single dtype    pd.DataFrame(df.values, df.index, new)     x098  y765  z432 0     1     3     5 1     2     4     6   Mixed dtype    pd.DataFrame(df.values, df.index, new).astype(dict(zip(new, df.dtypes)))     x098  y765  z432 0     1     3     5 1     2     4     6     Solution 4 This is a gimmicky trick with transpose and set_index.  pd.DataFrame.set_index allows us to set an index inline but there is no corresponding set_columns.  So we can transpose, then set_index, and transpose back.  However, the same single dtype versus mixed dtype caveat from solution 3 applies here.  Single dtype    df.T.set_index(np.asarray(new)).T     x098  y765  z432 0     1     3     5 1     2     4     6   Mixed dtype    df.T.set_index(np.asarray(new)).T.astype(dict(zip(new, df.dtypes)))     x098  y765  z432 0     1     3     5 1     2     4     6     Solution 5 Use a lambda in pd.DataFrame.rename that cycles through each element of new In this solution, we pass a lambda that takes x but then ignores it.  It also takes a y but doesn't expect it.  Instead, an iterator is given as a default value and I can then use that to cycle through one at a time without regard to what the value of x is.  df.rename(columns=lambda x, y=iter(new): next(y))     x098  y765  z432 0     1     3     5 1     2     4     6   And as pointed out to me by the folks in sopython chat, if I add a * in between x and y, I can protect my y variable.  Though, in this context I don't believe it needs protecting.  It is still worth mentioning.  df.rename(columns=lambda x, *, y=iter(new): next(y))     x098  y765  z432 0     1     3     5 1     2     4     6      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "19", "A_Content": "  DataFrame -- df.rename() will work.  df.rename(columns = {'Old Name':'New Name'})      df is the DataFrame you have, and the Old Name is the column name you   want to change, then the New Name is the new name you change to. This DataFrame built-in method makes things very easier.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "16", "A_Content": "  df = pd.DataFrame({'$a': [1], '$b': [1], '$c': [1], '$d': [1], '$e': [1]})   If your new list of columns is in the same order as the existing columns, the assignment is simple:  new_cols = ['a', 'b', 'c', 'd', 'e'] df.columns = new_cols >>> df    a  b  c  d  e 0  1  1  1  1  1   If you had a dictionary keyed on old column names to new column names, you could do the following:  d = {'$a': 'a', '$b': 'b', '$c': 'c', '$d': 'd', '$e': 'e'} df.columns = df.columns.map(lambda col: d[col])  # Or `.map(d.get)` as pointed out by @PiRSquared. >>> df    a  b  c  d  e 0  1  1  1  1  1   If you don't have a list or dictionary mapping, you could strip the leading $ symbol via a list comprehension:  df.columns = [col[1:] if col[0] == '$' else col for col in df]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "15", "A_Content": "  If you've got the dataframe, df.columns dumps everything into a list you can manipulate and then reassign into your dataframe as the names of columns...  columns = df.columns columns = [row.replace(\"$\",\"\") for row in columns] df.rename(columns=dict(zip(columns, things)), inplace=True) df.head() #to validate the output   Best way? IDK. A way - yes.  A better way of evaluating all the main techniques put forward in the answers to the question is below using cProfile to gage memory & execution time. @kadee, @kaitlyn, & @eumiro had the functions with the fastest execution times - though these functions are so fast we're comparing the rounding of .000 and .001 seconds for all the answers. Moral: my answer above likely isn't the 'Best' way.  import pandas as pd import cProfile, pstats, re  old_names = ['$a', '$b', '$c', '$d', '$e'] new_names = ['a', 'b', 'c', 'd', 'e'] col_dict = {'$a': 'a', '$b': 'b','$c':'c','$d':'d','$e':'e'}  df = pd.DataFrame({'$a':[1,2], '$b': [10,20],'$c':['bleep','blorp'],'$d':[1,2],'$e':['texa$','']})  df.head()  def eumiro(df,nn):     df.columns = nn     #This direct renaming approach is duplicated in methodology in several other answers:      return df  def lexual1(df):     return df.rename(columns=col_dict)  def lexual2(df,col_dict):     return df.rename(columns=col_dict, inplace=True)  def Panda_Master_Hayden(df):     return df.rename(columns=lambda x: x[1:], inplace=True)  def paulo1(df):     return df.rename(columns=lambda x: x.replace('$', ''))  def paulo2(df):     return df.rename(columns=lambda x: x.replace('$', ''), inplace=True)  def migloo(df,on,nn):     return df.rename(columns=dict(zip(on, nn)), inplace=True)  def kadee(df):     return df.columns.str.replace('$','')  def awo(df):     columns = df.columns     columns = [row.replace(\"$\",\"\") for row in columns]     return df.rename(columns=dict(zip(columns, '')), inplace=True)  def kaitlyn(df):     df.columns = [col.strip('$') for col in df.columns]     return df  print 'eumiro' cProfile.run('eumiro(df,new_names)') print 'lexual1' cProfile.run('lexual1(df)') print 'lexual2' cProfile.run('lexual2(df,col_dict)') print 'andy hayden' cProfile.run('Panda_Master_Hayden(df)') print 'paulo1' cProfile.run('paulo1(df)') print 'paulo2' cProfile.run('paulo2(df)') print 'migloo' cProfile.run('migloo(df,old_names,new_names)') print 'kadee' cProfile.run('kadee(df)') print 'awo' cProfile.run('awo(df)') print 'kaitlyn' cProfile.run('kaitlyn(df)')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "11", "A_Content": "  Another way we could replace the original column labels is by stripping the unwanted characters (here '$') from the original column labels.  This could have been done by running a for loop over df.columns and appending the stripped columns to df.columns.  Instead , we can do this neatly in a single statement by using list comprehension like below:  df.columns = [col.strip('$') for col in df.columns]   (strip method in Python strips the given character from beginning and end of the string.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "11", "A_Content": "  df = df.rename(columns=lambda n: n.replace('$', ''))   is a functional way of solving this     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "10", "A_Content": "  I know this question and answer has been chewed to death. But I referred to it for inspiration for one of the problem I was having . I was able to solve it using bits and pieces from different answers hence providing my response in case anyone needs it.  My method is generic wherein you can add additional delimiters by comma separating delimiters= variable and future-proof it.  Working Code:  import pandas as pd import re   df = pd.DataFrame({'$a':[1,2], '$b': [3,4],'$c':[5,6], '$d': [7,8], '$e': [9,10]})  delimiters = '$' matchPattern = '|'.join(map(re.escape, delimiters)) df.columns = [re.split(matchPattern, i)[1] for i in df.columns ]   Output:  >>> df    $a  $b  $c  $d  $e 0   1   3   5   7   9 1   2   4   6   8  10  >>> df    a  b  c  d   e 0  1  3  5  7   9 1  2  4  6  8  10      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "9", "A_Content": "  Real simple just use   df.columns = ['Name1', 'Name2', 'Name3'...]   and it will assign the column names by the order you put them     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "9", "A_Content": "  You could use str.slice for that:  df.columns = df.columns.str.slice(1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "7", "A_Content": "  Note that these approach do not work for a MultiIndex. For a MultiIndex, you need to do something like the following:  >>> df = pd.DataFrame({('$a','$x'):[1,2], ('$b','$y'): [3,4], ('e','f'):[5,6]}) >>> df    $a $b  e    $x $y  f 0  1  3  5 1  2  4  6 >>> rename = {('$a','$x'):('a','x'), ('$b','$y'):('b','y')} >>> df.columns = pandas.MultiIndex.from_tuples([         rename.get(item, item) for item in df.columns.tolist()]) >>> df    a  b  e    x  y  f 0  1  3  5 1  2  4  6      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "7", "A_Content": "  The rename dataframe columns and replace format  import pandas as pd  data = {'year':[2015,2011,2007,2003,1999,1996,1992,1987,1983,1979,1975],         'team':['Australia','India','Australia','Australia','Australia','Sri Lanka','Pakistan','Australia','India','West Indies','West Indies'],         } df = pd.DataFrame(data)  #Rename Columns df.rename(columns={'year':'Years of Win','team':'Winning Team'}, inplace=True)  #Replace format df = df.columns.str.replace(' ', '_')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "6", "A_Content": "  df.rename(index=str,columns={'A':'a','B':'b'})   https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "4", "A_Content": "  If you have to deal with loads of columns named by the providing system out of your control, I came up with the following approach that is a combination of a general approach and specific replacments in one go.  I first create a dictionary from the dataframe column names using regex expressions in order to throw away certain appendixes of column names  and then I add specific replacements to the dictionary to name core columns as expected later in the receiving database.  This is then applied to the dataframe in one go.  dict=dict(zip(df.columns,df.columns.str.replace('(:S$|:C1$|:L$|:D$|\\.Serial:L$)',''))) dict['brand_timeseries:C1']='BTS' dict['respid:L']='RespID' dict['country:C1']='CountryID dict['pim1:D']='pim_actual' df.rename(columns=dict, inplace=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "3", "A_Content": "  Try this. It works for me  df.rename(index=str, columns={\"$a\": \"a\", \"$b\": \"b\", \"$c\" : \"c\", \"$d\" : \"d\", \"$e\" : \"e\"})      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "3", "A_Content": "  Another option is to rename using a regular expression:  import pandas as pd import re  df = pd.DataFrame({'$a':[1,2], '$b':[3,4], '$c':[5,6]})  df = df.rename(columns=lambda x: re.sub('\\$','',x)) >>> df    a  b  c 0  1  3  5 1  2  4  6      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "2", "A_Content": "  In case you don't want the row names df.columns = ['a', 'b',index=False]     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas", "Language": "Python", "Q_Title": "Renaming columns in pandas", "Q_Votes": "1123", "Q_Content": "    I have a DataFrame using pandas and column labels that I need to edit to replace the original column labels.   I'd like to change the column names in a DataFrame A where the original column names are:  ['$a', '$b', '$c', '$d', '$e']    to   ['a', 'b', 'c', 'd', 'e'].   I have the edited column names stored it in a list, but I don't know how to replace the column names.     ", "Tags": ["python", "pandas", "replace", "dataframe", "rename"], "A_Votes": "2", "A_Content": "  Here's a nifty little function I like to use to cut down on typing:  def rename(data, oldnames, newname):      if type(oldnames) == str: #input can be a string or list of strings          oldnames = [oldnames] #when renaming multiple columns          newname = [newname] #make sure you pass the corresponding list of new names     i = 0      for name in oldnames:         oldvar = [c for c in data.columns if name in c]         if len(oldvar) == 0:              raise ValueError(\"Sorry, couldn't find that column in the dataset\")         if len(oldvar) > 1: #doesn't have to be an exact match              print(\"Found multiple columns that matched \" + str(name) + \" :\")             for c in oldvar:                 print(str(oldvar.index(c)) + \": \" + str(c))             ind = input('please enter the index of the column you would like to rename: ')             oldvar = oldvar[int(ind)]         if len(oldvar) == 1:             oldvar = oldvar[0]         data = data.rename(columns = {oldvar : newname[i]})         i += 1      return data      Here is an example of how it works:   In [2]: df = pd.DataFrame(np.random.randint(0,10,size=(10, 4)), columns=['col1','col2','omg','idk']) #first list = existing variables #second list = new names for those variables In [3]: df = rename(df, ['col','omg'],['first','ohmy'])  Found multiple columns that matched col : 0: col1 1: col2  please enter the index of the column you would like to rename: 0  In [4]: df.columns Out[5]: Index(['first', 'col2', 'ohmy', 'idk'], dtype='object')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/610883/how-to-know-if-an-object-has-an-attribute-in-python", "Language": "Python", "Q_Title": "How to know if an object has an attribute in Python", "Q_Votes": "1167", "Q_Content": "    Is there a way in Python to determine if an object has some attribute?  For example:  >>> a = SomeClass() >>> a.someProperty = value >>> a.property Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: SomeClass instance has no attribute 'property'   How can you tell if a has the attribute property before using it?     ", "Tags": ["python", "attributes"], "A_Votes": "1633", "A_Content": "  Try hasattr():  if hasattr(a, 'property'):     a.property   EDIT: See zweiterlinde's answer below, who offers good advice about asking forgiveness! A very pythonic approach!   The general practice in python is that, if the property is likely to be there most of the time, simply call it and either let the exception propagate, or trap it with a try/except block. This will likely be faster than hasattr. If the property is likely to not be there most of the time, or you're not sure, using hasattr will probably be faster than repeatedly falling into an exception block.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/610883/how-to-know-if-an-object-has-an-attribute-in-python", "Language": "Python", "Q_Title": "How to know if an object has an attribute in Python", "Q_Votes": "1167", "Q_Content": "    Is there a way in Python to determine if an object has some attribute?  For example:  >>> a = SomeClass() >>> a.someProperty = value >>> a.property Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: SomeClass instance has no attribute 'property'   How can you tell if a has the attribute property before using it?     ", "Tags": ["python", "attributes"], "A_Votes": "472", "A_Content": "  As Jarret Hardie answered, hasattr will do the trick.  I would like to add, though, that many in the Python community recommend a strategy of \"easier to ask for forgiveness than permission\" (EAFP) rather than \"look before you leap\" (LBYL).  See these references:  EAFP vs LBYL (was Re: A little disappointed so far) EAFP vs. LBYL @Code Like a Pythonista: Idiomatic Python  ie:  try:     doStuff(a.property) except AttributeError:     otherStuff()   ... is preferred to:  if hasattr(a, 'property'):     doStuff(a.property) else:     otherStuff()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/610883/how-to-know-if-an-object-has-an-attribute-in-python", "Language": "Python", "Q_Title": "How to know if an object has an attribute in Python", "Q_Votes": "1167", "Q_Content": "    Is there a way in Python to determine if an object has some attribute?  For example:  >>> a = SomeClass() >>> a.someProperty = value >>> a.property Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: SomeClass instance has no attribute 'property'   How can you tell if a has the attribute property before using it?     ", "Tags": ["python", "attributes"], "A_Votes": "378", "A_Content": "  You can use hasattr() or catch AttributeError, but if you really just want the value of the attribute with a default if it isn't there, the best option is just to use getattr():  getattr(a, 'property', 'default value')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/610883/how-to-know-if-an-object-has-an-attribute-in-python", "Language": "Python", "Q_Title": "How to know if an object has an attribute in Python", "Q_Votes": "1167", "Q_Content": "    Is there a way in Python to determine if an object has some attribute?  For example:  >>> a = SomeClass() >>> a.someProperty = value >>> a.property Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: SomeClass instance has no attribute 'property'   How can you tell if a has the attribute property before using it?     ", "Tags": ["python", "attributes"], "A_Votes": "33", "A_Content": "  I think what you are looking for is hasattr. However, I'd recommend something like this if you want to detect python properties-  try:     getattr(someObject, 'someProperty')          except AttributeError:     print \"Doesn't exist\" else     print \"Exists\"   The disadvantage here is that attribute errors in the properties __get__ code are also caught.  Otherwise, do-  if hasattr(someObject, 'someProp'):     #Access someProp/ set someProp     pass   Docs:http://docs.python.org/library/functions.html Warning: The reason for my recommendation is that hasattr doesn't detect properties. Link:http://mail.python.org/pipermail/python-dev/2005-December/058498.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/610883/how-to-know-if-an-object-has-an-attribute-in-python", "Language": "Python", "Q_Title": "How to know if an object has an attribute in Python", "Q_Votes": "1167", "Q_Content": "    Is there a way in Python to determine if an object has some attribute?  For example:  >>> a = SomeClass() >>> a.someProperty = value >>> a.property Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: SomeClass instance has no attribute 'property'   How can you tell if a has the attribute property before using it?     ", "Tags": ["python", "attributes"], "A_Votes": "25", "A_Content": "  According to pydoc, hasattr(obj, prop) simply calls getattr(obj, prop) and catches exceptions. So, it is just as valid to wrap the attribute access with a try statement and catch AttributeError as it is to use hasattr() beforehand.  a = SomeClass() try:     return a.fake_prop except AttributeError:     return default_value      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/610883/how-to-know-if-an-object-has-an-attribute-in-python", "Language": "Python", "Q_Title": "How to know if an object has an attribute in Python", "Q_Votes": "1167", "Q_Content": "    Is there a way in Python to determine if an object has some attribute?  For example:  >>> a = SomeClass() >>> a.someProperty = value >>> a.property Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: SomeClass instance has no attribute 'property'   How can you tell if a has the attribute property before using it?     ", "Tags": ["python", "attributes"], "A_Votes": "13", "A_Content": "  I would like to suggest avoid this:  try:     doStuff(a.property) except AttributeError:     otherStuff()   The user @jpalecek mentioned it: If an AttributeError occurs inside doStuff(), you are lost.  Maybe this approach is better:  try:     val = a.property except AttributeError:     otherStuff() else:     doStuff(val)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/610883/how-to-know-if-an-object-has-an-attribute-in-python", "Language": "Python", "Q_Title": "How to know if an object has an attribute in Python", "Q_Votes": "1167", "Q_Content": "    Is there a way in Python to determine if an object has some attribute?  For example:  >>> a = SomeClass() >>> a.someProperty = value >>> a.property Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: SomeClass instance has no attribute 'property'   How can you tell if a has the attribute property before using it?     ", "Tags": ["python", "attributes"], "A_Votes": "11", "A_Content": "  Depending on the situation you can check with isinstance what kind of object you have, and then use the corresponding attributes. With the introduction of abstract base classes in Python 2.6/3.0 this approach has also become much more powerful (basically ABCs allow for a more sophisticated way of duck typing).  One situation were this is useful would be if two different objects have an attribute with the same name, but with different meaning. Using only hasattr might then lead to strange errors.  One nice example is the distinction between iterators and iterables (see this question). The __iter__ methods in an iterator and an iterable have the same name but are semantically quite different! So hasattr is useless, but isinstance together with ABC's provides a clean solution.  However, I agree that in most situations the hasattr approach (described in other answers) is the most appropriate solution.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/610883/how-to-know-if-an-object-has-an-attribute-in-python", "Language": "Python", "Q_Title": "How to know if an object has an attribute in Python", "Q_Votes": "1167", "Q_Content": "    Is there a way in Python to determine if an object has some attribute?  For example:  >>> a = SomeClass() >>> a.someProperty = value >>> a.property Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: SomeClass instance has no attribute 'property'   How can you tell if a has the attribute property before using it?     ", "Tags": ["python", "attributes"], "A_Votes": "8", "A_Content": "  EDIT:This approach has serious limitation. It should work if the object is an iterable one. Please check the comments below.  If you are using Python 3.6 or higher like me there is a convenient alternative to check whether an object has a particular attribute:  if 'attr1' in obj1:     print(\"attr1 = {}\".format(obj1[\"attr1\"]))   However, I'm not sure which is the best approach right now. using hasattr(), using getattr() or using in. Comments are welcome.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/610883/how-to-know-if-an-object-has-an-attribute-in-python", "Language": "Python", "Q_Title": "How to know if an object has an attribute in Python", "Q_Votes": "1167", "Q_Content": "    Is there a way in Python to determine if an object has some attribute?  For example:  >>> a = SomeClass() >>> a.someProperty = value >>> a.property Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> AttributeError: SomeClass instance has no attribute 'property'   How can you tell if a has the attribute property before using it?     ", "Tags": ["python", "attributes"], "A_Votes": "7", "A_Content": "  Hope you expecting hasattr(), but try to avoid hasattr() and please prefer getattr(). getattr() is faster than hasattr()  using hasattr():   if hasattr(a, 'property'):      print a.property   same here i am using getattr to get property if there is no property it return none     property = getattr(a,\"property\",None)     if property:         print property      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2835559/parsing-values-from-a-json-file", "Language": "Python", "Q_Title": "Parsing values from a JSON file?", "Q_Votes": "1141", "Q_Content": "    I have this JSON in a file:  {     \"maps\": [         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         },         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         }     ],     \"masks\": [         \"id\": \"valore\"     ],     \"om_points\": \"value\",     \"parameters\": [         \"id\": \"valore\"     ] }   I wrote this script which prints all of the json text:  json_data=open(file_directory).read()  data = json.loads(json_data) pprint(data)   How can I parse the file and extract single values?     ", "Tags": ["python", "json", "parsing"], "A_Votes": "1713", "A_Content": "  I think what Ignacio is saying is that your JSON file is incorrect. You have [] when you should have {}. [] are for lists, {} are for dictionaries.  Here's how your JSON file should look, your JSON file wouldn't even load for me:  {     \"maps\": [         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         },         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         }     ],     \"masks\": {         \"id\": \"valore\"     },     \"om_points\": \"value\",     \"parameters\": {         \"id\": \"valore\"     } }   Then you can use your code:  import json from pprint import pprint  with open('data.json') as f:     data = json.load(f)  pprint(data)   With data, you can now also find values like so:  data[\"maps\"][0][\"id\"] data[\"masks\"][\"id\"] data[\"om_points\"]   Try those out and see if it starts to make sense.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2835559/parsing-values-from-a-json-file", "Language": "Python", "Q_Title": "Parsing values from a JSON file?", "Q_Votes": "1141", "Q_Content": "    I have this JSON in a file:  {     \"maps\": [         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         },         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         }     ],     \"masks\": [         \"id\": \"valore\"     ],     \"om_points\": \"value\",     \"parameters\": [         \"id\": \"valore\"     ] }   I wrote this script which prints all of the json text:  json_data=open(file_directory).read()  data = json.loads(json_data) pprint(data)   How can I parse the file and extract single values?     ", "Tags": ["python", "json", "parsing"], "A_Votes": "277", "A_Content": "  Your data.json should look like this:  {  \"maps\":[          {\"id\":\"blabla\",\"iscategorical\":\"0\"},          {\"id\":\"blabla\",\"iscategorical\":\"0\"}         ], \"masks\":          {\"id\":\"valore\"}, \"om_points\":\"value\", \"parameters\":          {\"id\":\"valore\"} }   Your code should be:  import json from pprint import pprint  with open('data.json') as data_file:         data = json.load(data_file) pprint(data)   Note that this only works in Python 2.6 and up, as it depends upon the with-statement. In Python 2.5 use from __future__ import with_statement, in Python <= 2.4, see Justin Peel's answer, which this answer is based upon.  You can now also access single values like this:  data[\"maps\"][0][\"id\"]  # will return 'blabla' data[\"masks\"][\"id\"]    # will return 'valore' data[\"om_points\"]      # will return 'value'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2835559/parsing-values-from-a-json-file", "Language": "Python", "Q_Title": "Parsing values from a JSON file?", "Q_Votes": "1141", "Q_Content": "    I have this JSON in a file:  {     \"maps\": [         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         },         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         }     ],     \"masks\": [         \"id\": \"valore\"     ],     \"om_points\": \"value\",     \"parameters\": [         \"id\": \"valore\"     ] }   I wrote this script which prints all of the json text:  json_data=open(file_directory).read()  data = json.loads(json_data) pprint(data)   How can I parse the file and extract single values?     ", "Tags": ["python", "json", "parsing"], "A_Votes": "61", "A_Content": "  @Justin Peel's answer is really helpful, but if you are using Python 3 reading JSON should be done like this:  with open('data.json', encoding='utf-8') as data_file:     data = json.loads(data_file.read())   Note: use json.loads instead of json.load. In Python 3, json.loads takes a string parameter. json.load takes a file-like object parameter. data_file.read() returns a string object.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2835559/parsing-values-from-a-json-file", "Language": "Python", "Q_Title": "Parsing values from a JSON file?", "Q_Votes": "1141", "Q_Content": "    I have this JSON in a file:  {     \"maps\": [         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         },         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         }     ],     \"masks\": [         \"id\": \"valore\"     ],     \"om_points\": \"value\",     \"parameters\": [         \"id\": \"valore\"     ] }   I wrote this script which prints all of the json text:  json_data=open(file_directory).read()  data = json.loads(json_data) pprint(data)   How can I parse the file and extract single values?     ", "Tags": ["python", "json", "parsing"], "A_Votes": "49", "A_Content": "  data = [] with codecs.open('d:\\output.txt','rU','utf-8') as f:     for line in f:        data.append(json.loads(line))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2835559/parsing-values-from-a-json-file", "Language": "Python", "Q_Title": "Parsing values from a JSON file?", "Q_Votes": "1141", "Q_Content": "    I have this JSON in a file:  {     \"maps\": [         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         },         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         }     ],     \"masks\": [         \"id\": \"valore\"     ],     \"om_points\": \"value\",     \"parameters\": [         \"id\": \"valore\"     ] }   I wrote this script which prints all of the json text:  json_data=open(file_directory).read()  data = json.loads(json_data) pprint(data)   How can I parse the file and extract single values?     ", "Tags": ["python", "json", "parsing"], "A_Votes": "11", "A_Content": "  \"Ultra JSON\" or simply \"ujson\" can handle having [] in your JSON file input. If you're reading a JSON input file into your program as a list of JSON elements; such as, [{[{}]}, {}, [], etc...] ujson can handle any arbitrary order of lists of dictionaries, dictionaries of lists.   You can find ujson in the Python package index and the API is almost identical to Python's built-in json library.   ujson is also much faster if you're loading larger JSON files. You can see the performance details in comparison to other Python JSON libraries in the same link provided.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2835559/parsing-values-from-a-json-file", "Language": "Python", "Q_Title": "Parsing values from a JSON file?", "Q_Votes": "1141", "Q_Content": "    I have this JSON in a file:  {     \"maps\": [         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         },         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         }     ],     \"masks\": [         \"id\": \"valore\"     ],     \"om_points\": \"value\",     \"parameters\": [         \"id\": \"valore\"     ] }   I wrote this script which prints all of the json text:  json_data=open(file_directory).read()  data = json.loads(json_data) pprint(data)   How can I parse the file and extract single values?     ", "Tags": ["python", "json", "parsing"], "A_Votes": "6", "A_Content": "  if you are in python 3 here is how you can do it  {   \"connection1\": {     \"DSN\": \"con1\",     \"UID\": \"abc\",     \"PWD\": \"1234\",     \"connection_string_python\":\"test1\"   }   ,   \"connection2\": {     \"DSN\": \"con2\",     \"UID\": \"def\",     \"PWD\": \"1234\"   } }   The code should look like assuming connection.json file looks like above  connection_file = open('connection.json', 'r') conn_string = json.load(connection_file) conn_string['connection1']['connection_string_python']) connection_file.close() >>>test1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2835559/parsing-values-from-a-json-file", "Language": "Python", "Q_Title": "Parsing values from a JSON file?", "Q_Votes": "1141", "Q_Content": "    I have this JSON in a file:  {     \"maps\": [         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         },         {             \"id\": \"blabla\",             \"iscategorical\": \"0\"         }     ],     \"masks\": [         \"id\": \"valore\"     ],     \"om_points\": \"value\",     \"parameters\": [         \"id\": \"valore\"     ] }   I wrote this script which prints all of the json text:  json_data=open(file_directory).read()  data = json.loads(json_data) pprint(data)   How can I parse the file and extract single values?     ", "Tags": ["python", "json", "parsing"], "A_Votes": "4", "A_Content": "     # Here you go with modified json file:    # data.json file :      {         \"maps\": [             {                 \"id\": \"blabla\",                 \"iscategorical\": \"0\"             },             {                 \"id\": \"blabla\",                 \"iscategorical\": \"0\"             }         ],         \"masks\": [{             \"id\": \"valore\"         }],         \"om_points\": \"value\",         \"parameters\": [{             \"id\": \"valore\"         }]     }      # You can call or print data on console by using below lines      import json     from pprint import pprint     with open('data.json') as data_file:         data_item = json.load(data_file)     pprint(data_item)      print(data_item['parameters'][0]['id'])      #Output :      #pprint(data_item) output as :      {'maps': [{'id': 'blabla', 'iscategorical': '0'},               {'id': 'blabla', 'iscategorical': '0'}],      'masks': [{'id': 'valore'}],      'om_points': 'value',      'parameters': [{'id': 'valore'}]}     #print(data_item['parameters'][0]['id']) output as :     valore      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "2342", "A_Content": "  Enums have been added to Python 3.4 as described in PEP 435.  It has also been backported to 3.3, 3.2, 3.1, 2.7, 2.6, 2.5, and 2.4 on pypi.    For more advanced Enum techniques try the aenum library (2.7, 3.3+, same author as enum34. Code is not perfectly compatible between py2 and py3, e.g. you'll need __order__ in python 2).   To use enum34, do $ pip install enum34 To use aenum, do $ pip install aenum   Installing enum (no numbers) will install a completely different and incompatible version.    from enum import Enum     # for enum34, or the stdlib version # from aenum import Enum  # for the aenum version Animal = Enum('Animal', 'ant bee cat dog')  Animal.ant  # returns <Animal.ant: 1> Animal['ant']  # returns <Animal.ant: 1> (string lookup) Animal.ant.name  # returns 'ant' (inverse lookup)   or equivalently:  class Animal(Enum):     ant = 1     bee = 2     cat = 3     dog = 4     In earlier versions, one way of accomplishing enums is:  def enum(**enums):     return type('Enum', (), enums)   which is used like so:  >>> Numbers = enum(ONE=1, TWO=2, THREE='three') >>> Numbers.ONE 1 >>> Numbers.TWO 2 >>> Numbers.THREE 'three'   You can also easily support automatic enumeration with something like this:  def enum(*sequential, **named):     enums = dict(zip(sequential, range(len(sequential))), **named)     return type('Enum', (), enums)   and used like so:  >>> Numbers = enum('ZERO', 'ONE', 'TWO') >>> Numbers.ZERO 0 >>> Numbers.ONE 1   Support for converting the values back to names can be added this way:  def enum(*sequential, **named):     enums = dict(zip(sequential, range(len(sequential))), **named)     reverse = dict((value, key) for key, value in enums.iteritems())     enums['reverse_mapping'] = reverse     return type('Enum', (), enums)   This overwrites anything with that name, but it is useful for rendering your enums in output.  It will throw KeyError if the reverse mapping doesn't exist.  With the first example:  >>> Numbers.reverse_mapping['three'] 'THREE'      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "725", "A_Content": "  Before PEP 435, Python didn't have an equivalent but you could implement your own.  Myself, I like keeping it simple (I've seen some horribly complex examples on the net), something like this ...  class Animal:     DOG = 1     CAT = 2  x = Animal.DOG     In Python 3.4 (PEP 435), you can make Enum the base class.  This gets you a little bit of extra functionality, described in the PEP.  For example, enum members are distinct from integers, and they are composed of a name and a value.   class Animal(Enum):     DOG = 1     CAT = 2  print(Animal.DOG) # <Animal.DOG: 1>  print(Animal.DOG.value) # 1  print(Animal.DOG.name) # \"DOG\"     If you don't want to type the values, use the following shortcut:  class Animal(Enum):     DOG, CAT = range(2)     Enum implementations can be converted to lists and are iterable. The order of its members is the declaration order and has nothing to do with their values. For example:   class Animal(Enum):     DOG = 1     CAT = 2     COW = 0  list(Animal) # [<Animal.DOG: 1>, <Animal.CAT: 2>, <Animal.COW: 0>]  [animal.value for animal in Animal] # [1, 2, 0]  Animal.CAT in Animal # True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "299", "A_Content": "  Here is one implementation:  class Enum(set):     def __getattr__(self, name):         if name in self:             return name         raise AttributeError   Here is its usage:  Animals = Enum([\"DOG\", \"CAT\", \"HORSE\"])  print(Animals.DOG)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "187", "A_Content": "  If you need the numeric values, here's the quickest way:  dog, cat, rabbit = range(3)   In Python 3.x you can also add a starred placeholder at the end, which will soak up all the remaining values of the range in case you don't mind wasting memory and cannot count:  dog, cat, rabbit, horse, *_ = range(100)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "120", "A_Content": "  The best solution for you would depend on what you require from your fake enum.  Simple enum:  If you need the enum as only a list of names identifying different items, the solution by Mark Harrison (above) is great:  Pen, Pencil, Eraser = range(0, 3)   Using a range also allows you to set any starting value:  Pen, Pencil, Eraser = range(9, 12)   In addition to the above, if you also require that the items belong to a container of some sort, then embed them in a class:  class Stationery:     Pen, Pencil, Eraser = range(0, 3)   To use the enum item, you would now need to use the container name and the item name:  stype = Stationery.Pen   Complex enum:  For long lists of enum or more complicated uses of enum, these solutions will not suffice. You could look to the recipe by Will Ware for Simulating Enumerations in Python published in the Python Cookbook. An online version of that is available here.  More info:  PEP 354: Enumerations in Python has the interesting details of a proposal for enum in Python and why it was rejected.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "76", "A_Content": "  The typesafe enum pattern which was used in Java pre-JDK 5 has a number of advantages. Much like in Alexandru's answer, you create a class and class level fields are the enum values; however, the enum values are instances of the class rather than small integers. This has the advantage that your enum values don't inadvertently compare equal to small integers, you can control how they're printed, add arbitrary methods if that's useful and make assertions using isinstance:  class Animal:    def __init__(self, name):        self.name = name     def __str__(self):        return self.name     def __repr__(self):        return \"<Animal: %s>\" % self  Animal.DOG = Animal(\"dog\") Animal.CAT = Animal(\"cat\")  >>> x = Animal.DOG >>> x <Animal: dog> >>> x == 1 False     A recent thread on python-dev pointed out there are a couple of enum libraries in the wild, including:   flufl.enum lazr.enum ... and the imaginatively named enum      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "56", "A_Content": "  An Enum class can be a one-liner.  class Enum(tuple): __getattr__ = tuple.index   How to use it (forward and reverse lookup, keys, values, items, etc.)  >>> State = Enum(['Unclaimed', 'Claimed']) >>> State.Claimed 1 >>> State[1] 'Claimed' >>> State ('Unclaimed', 'Claimed') >>> range(len(State)) [0, 1] >>> [(k, State[k]) for k in range(len(State))] [(0, 'Unclaimed'), (1, 'Claimed')] >>> [(k, getattr(State, k)) for k in State] [('Unclaimed', 0), ('Claimed', 1)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "45", "A_Content": "  Python doesn't have a built-in equivalent to enum, and other answers have ideas for implementing your own (you may also be interested in the over the top version in the Python cookbook).  However, in situations where an enum would be called for in C, I usually end up just using simple strings: because of the way objects/attributes are implemented, (C)Python is optimized to work very fast with short strings anyway, so there wouldn't really be any performance benefit to using integers. To guard against typos / invalid values you can insert checks in selected places.  ANIMALS = ['cat', 'dog', 'python']  def take_for_a_walk(animal):     assert animal in ANIMALS     ...   (One disadvantage compared to using a class is that you lose the benefit of autocomplete)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "45", "A_Content": "  So, I agree. Let's not enforce type safety in Python, but I would like to protect myself from silly mistakes. So what do we think about this?  class Animal(object):     values = ['Horse','Dog','Cat']      class __metaclass__(type):         def __getattr__(self, name):             return self.values.index(name)   It keeps me from value-collision in defining my enums.  >>> Animal.Cat 2   There's another handy advantage: really fast reverse lookups:  def name_of(self, i):     return self.values[i]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "31", "A_Content": "  On 2013-05-10, Guido agreed to accept PEP 435 into the Python 3.4 standard library. This means that Python finally has builtin support for enumerations!  There is a backport available for Python 3.3, 3.2, 3.1, 2.7, 2.6, 2.5, and 2.4.  It's on Pypi as enum34.  Declaration:  >>> from enum import Enum >>> class Color(Enum): ...     red = 1 ...     green = 2 ...     blue = 3   Representation:  >>> print(Color.red) Color.red >>> print(repr(Color.red)) <Color.red: 1>   Iteration:  >>> for color in Color: ...   print(color) ... Color.red Color.green Color.blue   Programmatic access:  >>> Color(1) Color.red >>> Color['blue'] Color.blue   For more information, refer to the proposal. Official documentation will probably follow soon.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "29", "A_Content": "  I prefer to define enums in Python like so:  class Animal:   class Dog: pass   class Cat: pass  x = Animal.Dog   It's more bug-proof than using integers since you don't have to worry about ensuring that the integers are unique (e.g. if you said Dog = 1 and Cat = 1 you'd be screwed).  It's more bug-proof than using strings since you don't have to worry about typos (e.g. x == \"catt\" fails silently, but x == Animal.Catt is a runtime exception).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "29", "A_Content": "  def M_add_class_attribs(attribs):     def foo(name, bases, dict_):         for v, k in attribs:             dict_[k] = v         return type(name, bases, dict_)     return foo  def enum(*names):     class Foo(object):         __metaclass__ = M_add_class_attribs(enumerate(names))         def __setattr__(self, name, value):  # this makes it read-only             raise NotImplementedError     return Foo()   Use it like this:    Animal = enum('DOG', 'CAT') Animal.DOG # returns 0 Animal.CAT # returns 1 Animal.DOG = 2 # raises NotImplementedError   if you just want unique symbols and don't care about the values, replace this line:    __metaclass__ = M_add_class_attribs(enumerate(names))   with this:  __metaclass__ = M_add_class_attribs((object(), name) for name in names)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "21", "A_Content": "  Another, very simple, implementation of an enum in Python, using namedtuple:  from collections import namedtuple  def enum(*keys):     return namedtuple('Enum', keys)(*keys)  MyEnum = enum('FOO', 'BAR', 'BAZ')   or, alternatively,  # With sequential number values def enum(*keys):     return namedtuple('Enum', keys)(*range(len(keys)))  # From a dict / keyword args def enum(**kwargs):     return namedtuple('Enum', kwargs.keys())(*kwargs.values())   Like the method above that subclasses set, this allows:  'FOO' in MyEnum other = MyEnum.FOO assert other == MyEnum.FOO   But has more flexibility as it can have different keys and values. This allows  MyEnum.FOO < MyEnum.BAR   to act as is expected if you use the version that fills in sequential number values.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "19", "A_Content": "  Hmmm... I suppose the closest thing to an enum would be a dictionary, defined either like this:  months = {     'January': 1,     'February': 2,     ... }   or  months = dict(     January=1,     February=2,     ... )   Then, you can use the symbolic name for the constants like this:  mymonth = months['January']   There are other options, like a list of tuples, or a tuple of tuples, but the dictionary is the only one that provides you with a \"symbolic\" (constant string) way to access the  value.  Edit: I like Alexandru's answer too!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "17", "A_Content": "  What I use:  class Enum(object):     def __init__(self, names, separator=None):         self.names = names.split(separator)         for value, name in enumerate(self.names):             setattr(self, name.upper(), value)     def tuples(self):         return tuple(enumerate(self.names))   How to use:  >>> state = Enum('draft published retracted') >>> state.DRAFT 0 >>> state.RETRACTED 2 >>> state.FOO Traceback (most recent call last):    File \"<stdin>\", line 1, in <module> AttributeError: 'Enum' object has no attribute 'FOO' >>> state.tuples() ((0, 'draft'), (1, 'published'), (2, 'retracted'))   So this gives you integer constants like state.PUBLISHED and the two-tuples to use as choices in Django models.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "15", "A_Content": "  davidg recommends using dicts.  I'd go one step further and use sets:  months = set('January', 'February', ..., 'December')   Now you can test whether a value matches one of the values in the set like this:  if m in months:   like dF, though, I usually just use string constants in place of enums.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "15", "A_Content": "  From Python 3.4 there will be official support for enums. You can find documentation and examples here on Python 3.4 documentation page.     Enumerations are created using the class syntax, which makes them easy   to read and write. An alternative creation method is described in   Functional API. To define an enumeration, subclass Enum as follows:   from enum import Enum class Color(Enum):      red = 1      green = 2      blue = 3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "14", "A_Content": "  This is the best one I have seen: \"First Class Enums in Python\"  http://code.activestate.com/recipes/413486/  It gives you a class, and the class contains all the enums. The enums can be compared to each other, but don't have any particular value; you can't use them as an integer value. (I resisted this at first because I am used to C enums, which are integer values. But if you can't use it as an integer, you can't use it as an integer by mistake so overall I think it is a win.) Each enum is a unique value. You can print enums, you can iterate over them, you can test that an enum value is \"in\" the enum. It's pretty complete and slick.  Edit (cfi): The above link is not Python 3 compatible. Here's my port of enum.py to Python 3:  def cmp(a,b):    if a < b: return -1    if b < a: return 1    return 0   def Enum(*names):    ##assert names, \"Empty enums are not supported\" # <- Don't like empty enums? Uncomment!     class EnumClass(object):       __slots__ = names       def __iter__(self):        return iter(constants)       def __len__(self):         return len(constants)       def __getitem__(self, i):  return constants[i]       def __repr__(self):        return 'Enum' + str(names)       def __str__(self):         return 'enum ' + str(constants)     class EnumValue(object):       __slots__ = ('__value')       def __init__(self, value): self.__value = value       Value = property(lambda self: self.__value)       EnumType = property(lambda self: EnumType)       def __hash__(self):        return hash(self.__value)       def __cmp__(self, other):          # C fans might want to remove the following assertion          # to make all enums comparable by ordinal value {;))          assert self.EnumType is other.EnumType, \"Only values from the same enum are comparable\"          return cmp(self.__value, other.__value)       def __lt__(self, other):   return self.__cmp__(other) < 0       def __eq__(self, other):   return self.__cmp__(other) == 0       def __invert__(self):      return constants[maximum - self.__value]       def __nonzero__(self):     return bool(self.__value)       def __repr__(self):        return str(names[self.__value])     maximum = len(names) - 1    constants = [None] * len(names)    for i, each in enumerate(names):       val = EnumValue(i)       setattr(EnumClass, each, val)       constants[i] = val    constants = tuple(constants)    EnumType = EnumClass()    return EnumType   if __name__ == '__main__':    print( '\\n*** Enum Demo ***')    print( '--- Days of week ---')    Days = Enum('Mo', 'Tu', 'We', 'Th', 'Fr', 'Sa', 'Su')    print( Days)    print( Days.Mo)    print( Days.Fr)    print( Days.Mo < Days.Fr)    print( list(Days))    for each in Days:       print( 'Day:', each)    print( '--- Yes/No ---')    Confirmation = Enum('No', 'Yes')    answer = Confirmation.No    print( 'Your answer is not', ~answer)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "11", "A_Content": "  I have had occasion to need of an Enum class, for the purpose of decoding a binary file format. The features I happened to want is concise enum definition, the ability to freely create instances of the enum by either integer value or string, and a useful representation.  Here's what I ended up with:  >>> class Enum(int): ...     def __new__(cls, value): ...         if isinstance(value, str): ...             return getattr(cls, value) ...         elif isinstance(value, int): ...             return cls.__index[value] ...     def __str__(self): return self.__name ...     def __repr__(self): return \"%s.%s\" % (type(self).__name__, self.__name) ...     class __metaclass__(type): ...         def __new__(mcls, name, bases, attrs): ...             attrs['__slots__'] = ['_Enum__name'] ...             cls = type.__new__(mcls, name, bases, attrs) ...             cls._Enum__index = _index = {} ...             for base in reversed(bases): ...                 if hasattr(base, '_Enum__index'): ...                     _index.update(base._Enum__index) ...             # create all of the instances of the new class ...             for attr in attrs.keys(): ...                 value = attrs[attr] ...                 if isinstance(value, int): ...                     evalue = int.__new__(cls, value) ...                     evalue._Enum__name = attr ...                     _index[value] = evalue ...                     setattr(cls, attr, evalue) ...             return cls ...    A whimsical example of using it:  >>> class Citrus(Enum): ...     Lemon = 1 ...     Lime = 2 ...  >>> Citrus.Lemon Citrus.Lemon >>>  >>> Citrus(1) Citrus.Lemon >>> Citrus(5) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"<stdin>\", line 6, in __new__ KeyError: 5 >>> class Fruit(Citrus): ...     Apple = 3 ...     Banana = 4 ...  >>> Fruit.Apple Fruit.Apple >>> Fruit.Lemon Citrus.Lemon >>> Fruit(1) Citrus.Lemon >>> Fruit(3) Fruit.Apple >>> \"%d %s %r\" % ((Fruit.Apple,)*3) '3 Apple Fruit.Apple' >>> Fruit(1) is Citrus.Lemon True   Key features:   str(), int() and repr() all produce the most useful output possible, respectively the name of the enumartion, its integer value, and a Python expression that evaluates back to the enumeration. Enumerated values returned by the constructor are limited strictly to the predefined values, no accidental enum values. Enumerated values are singletons; they can be strictly compared with is      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "11", "A_Content": "  Keep it simple:  class Enum(object):      def __init__(self, tupleList):             self.tupleList = tupleList      def __getattr__(self, name):             return self.tupleList.index(name)   Then:  DIRECTION = Enum(('UP', 'DOWN', 'LEFT', 'RIGHT')) DIRECTION.DOWN 1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "9", "A_Content": "  I really like Alec Thomas' solution (http://stackoverflow.com/a/1695250):  def enum(**enums):     '''simple constant \"enums\"'''     return type('Enum', (object,), enums)   It's elegant and clean looking, but it's just a function that creates a class with the specified attributes.  With a little modification to the function, we can get it to act a little more 'enumy':     NOTE: I created the following examples by trying to reproduce the   behavior of pygtk's new style 'enums' (like Gtk.MessageType.WARNING)   def enum_base(t, **enums):     '''enums with a base class'''     T = type('Enum', (t,), {})     for key,val in enums.items():         setattr(T, key, T(val))      return T   This creates an enum based off a specified type. In addition to giving attribute access like the previous function, it behaves as you would expect an Enum to with respect to types.  It also inherits the base class.  For example, integer enums:  >>> Numbers = enum_base(int, ONE=1, TWO=2, THREE=3) >>> Numbers.ONE 1 >>> x = Numbers.TWO >>> 10 + x 12 >>> type(Numbers) <type 'type'> >>> type(Numbers.ONE) <class 'Enum'> >>> isinstance(x, Numbers) True   Another interesting thing that can be done with this method is customize specific behavior by overriding built-in methods:  def enum_repr(t, **enums):     '''enums with a base class and repr() output'''     class Enum(t):         def __repr__(self):             return '<enum {0} of type Enum({1})>'.format(self._name, t.__name__)      for key,val in enums.items():         i = Enum(val)         i._name = key         setattr(Enum, key, i)      return Enum    >>> Numbers = enum_repr(int, ONE=1, TWO=2, THREE=3) >>> repr(Numbers.ONE) '<enum ONE of type Enum(int)>' >>> str(Numbers.ONE) '1'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "8", "A_Content": "  The new standard in Python is PEP 435, so an Enum class will be available in future versions of Python:  >>> from enum import Enum   However to begin using it now you can install the original library that motivated the PEP:  #sudo pip install flufl.enum   //or #sudo easy_install flufl.enum   Then you can use it as per its online guide:  >>> from flufl.enum import Enum >>> class Colors(Enum): ...     red = 1 ...     green = 2 ...     blue = 3 >>> for color in Colors: print color Colors.red Colors.green Colors.blue      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "8", "A_Content": "  def enum(*sequential, **named):     enums = dict(zip(sequential, [object() for _ in range(len(sequential))]), **named)     return type('Enum', (), enums)   If you name it, is your problem, but if not creating objects instead of values allows you to do this:  >>> DOG = enum('BARK', 'WALK', 'SIT') >>> CAT = enum('MEOW', 'WALK', 'SIT') >>> DOG.WALK == CAT.WALK False   When using other implementations sited here (also when using named instances in my example) you must be sure you never try to compare objects from different enums. For here's a possible pitfall:  >>> DOG = enum('BARK'=1, 'WALK'=2, 'SIT'=3) >>> CAT = enum('WALK'=1, 'SIT'=2) >>> pet1_state = DOG.BARK >>> pet2_state = CAT.WALK >>> pet1_state == pet2_state True   Yikes!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "7", "A_Content": "  The enum package from PyPI provides a robust implementation of enums. An earlier answer mentioned PEP 354; this was rejected but the proposal was implemented  http://pypi.python.org/pypi/enum.  Usage is easy and elegant:  >>> from enum import Enum >>> Colors = Enum('red', 'blue', 'green') >>> shirt_color = Colors.green >>> shirt_color = Colors[2] >>> shirt_color > Colors.red True >>> shirt_color.index 2 >>> str(shirt_color) 'green'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "6", "A_Content": "  Alexandru's suggestion of using class constants for enums works quite well.   I also like to add a dictionary for each set of constants to lookup a human-readable string representation.   This serves two purposes: a) it provides a simple way to pretty-print your enum and b) the dictionary logically groups the constants so that you can test for membership.  class Animal:       TYPE_DOG = 1   TYPE_CAT = 2    type2str = {     TYPE_DOG: \"dog\",     TYPE_CAT: \"cat\"   }    def __init__(self, type_):     assert type_ in self.type2str.keys()     self._type = type_    def __repr__(self):     return \"<%s type=%s>\" % (         self.__class__.__name__, self.type2str[self._type].upper())      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "4", "A_Content": "  Here is a variant on Alec Thomas's solution:  def enum(*args, **kwargs):     return type('Enum', (), dict((y, x) for x, y in enumerate(args), **kwargs))   x = enum('POOH', 'TIGGER', 'EEYORE', 'ROO', 'PIGLET', 'RABBIT', 'OWL') assert x.POOH == 0 assert x.TIGGER == 1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "4", "A_Content": "  This solution is a simple way of getting a class for the enumeration defined as a list (no more annoying integer assignments):  enumeration.py:  import new  def create(class_name, names):     return new.classobj(         class_name, (object,), dict((y, x) for x, y in enumerate(names))     )   example.py:  import enumeration  Colors = enumeration.create('Colors', (     'red',     'orange',     'yellow',     'green',     'blue',     'violet', ))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "4", "A_Content": "  While the original enum proposal, PEP 354, was rejected years ago, it keeps coming back up. Some kind of enum was intended to be added to 3.2, but it got pushed back to 3.3 and then forgotten. And now there's a PEP 435 intended for inclusion in Python 3.4. The reference implementation of PEP 435 is flufl.enum.  As of April 2013, there seems to be a general consensus that something should be added to the standard library in 3.4\u2014as long as people can agree on what that \"something\" should be. That's the hard part. See the threads starting here and here, and a half dozen other threads in the early months of 2013.  Meanwhile, every time this comes up, a slew of new designs and implementations appear on PyPI, ActiveState, etc., so if you don't like the FLUFL design, try a PyPI search.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "4", "A_Content": "  Here's an approach with some different characteristics I find valuable:   allows > and < comparison based on order in enum, not lexical order can address item by name, property or index: x.a, x['a'] or x[0] supports slicing operations like [:] or [-1]   and most importantly prevents comparisons between enums of different types!  Based closely on http://code.activestate.com/recipes/413486-first-class-enums-in-python.  Many doctests included here to illustrate what's different about this approach.  def enum(*names):     \"\"\" SYNOPSIS     Well-behaved enumerated type, easier than creating custom classes  DESCRIPTION     Create a custom type that implements an enumeration.  Similar in concept     to a C enum but with some additional capabilities and protections.  See     http://code.activestate.com/recipes/413486-first-class-enums-in-python/.  PARAMETERS     names       Ordered list of names.  The order in which names are given                 will be the sort order in the enum type.  Duplicate names                 are not allowed.  Unicode names are mapped to ASCII.  RETURNS     Object of type enum, with the input names and the enumerated values.  EXAMPLES     >>> letters = enum('a','e','i','o','u','b','c','y','z')     >>> letters.a < letters.e     True      ## index by property     >>> letters.a     a      ## index by position     >>> letters[0]     a      ## index by name, helpful for bridging string inputs to enum     >>> letters['a']     a      ## sorting by order in the enum() create, not character value     >>> letters.u < letters.b     True      ## normal slicing operations available     >>> letters[-1]     z      ## error since there are not 100 items in enum     >>> letters[99]     Traceback (most recent call last):         ...     IndexError: tuple index out of range      ## error since name does not exist in enum     >>> letters['ggg']     Traceback (most recent call last):         ...     ValueError: tuple.index(x): x not in tuple      ## enums must be named using valid Python identifiers     >>> numbers = enum(1,2,3,4)     Traceback (most recent call last):         ...     AssertionError: Enum values must be string or unicode      >>> a = enum('-a','-b')     Traceback (most recent call last):         ...     TypeError: Error when calling the metaclass bases         __slots__ must be identifiers      ## create another enum     >>> tags = enum('a','b','c')     >>> tags.a     a     >>> letters.a     a      ## can't compare values from different enums     >>> letters.a == tags.a     Traceback (most recent call last):         ...     AssertionError: Only values from the same enum are comparable      >>> letters.a < tags.a     Traceback (most recent call last):         ...     AssertionError: Only values from the same enum are comparable      ## can't update enum after create     >>> letters.a = 'x'     Traceback (most recent call last):         ...     AttributeError: 'EnumClass' object attribute 'a' is read-only      ## can't update enum after create     >>> del letters.u     Traceback (most recent call last):         ...     AttributeError: 'EnumClass' object attribute 'u' is read-only      ## can't have non-unique enum values     >>> x = enum('a','b','c','a')     Traceback (most recent call last):         ...     AssertionError: Enums must not repeat values      ## can't have zero enum values     >>> x = enum()     Traceback (most recent call last):         ...     AssertionError: Empty enums are not supported      ## can't have enum values that look like special function names     ## since these could collide and lead to non-obvious errors     >>> x = enum('a','b','c','__cmp__')     Traceback (most recent call last):         ...     AssertionError: Enum values beginning with __ are not supported  LIMITATIONS     Enum values of unicode type are not preserved, mapped to ASCII instead.      \"\"\"     ## must have at least one enum value     assert names, 'Empty enums are not supported'     ## enum values must be strings     assert len([i for i in names if not isinstance(i, types.StringTypes) and not \\         isinstance(i, unicode)]) == 0, 'Enum values must be string or unicode'     ## enum values must not collide with special function names     assert len([i for i in names if i.startswith(\"__\")]) == 0,\\         'Enum values beginning with __ are not supported'     ## each enum value must be unique from all others     assert names == uniquify(names), 'Enums must not repeat values'      class EnumClass(object):         \"\"\" See parent function for explanation \"\"\"          __slots__ = names          def __iter__(self):             return iter(constants)          def __len__(self):             return len(constants)          def __getitem__(self, i):             ## this makes xx['name'] possible             if isinstance(i, types.StringTypes):                 i = names.index(i)             ## handles the more normal xx[0]             return constants[i]          def __repr__(self):             return 'enum' + str(names)          def __str__(self):             return 'enum ' + str(constants)          def index(self, i):             return names.index(i)      class EnumValue(object):         \"\"\" See parent function for explanation \"\"\"          __slots__ = ('__value')          def __init__(self, value):             self.__value = value          value = property(lambda self: self.__value)          enumtype = property(lambda self: enumtype)          def __hash__(self):             return hash(self.__value)          def __cmp__(self, other):             assert self.enumtype is other.enumtype, 'Only values from the same enum are comparable'             return cmp(self.value, other.value)          def __invert__(self):             return constants[maximum - self.value]          def __nonzero__(self):             ## return bool(self.value)             ## Original code led to bool(x[0])==False, not correct             return True          def __repr__(self):             return str(names[self.value])      maximum = len(names) - 1     constants = [None] * len(names)     for i, each in enumerate(names):         val = EnumValue(i)         setattr(EnumClass, each, val)         constants[i] = val     constants = tuple(constants)     enumtype = EnumClass()     return enumtype      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/36932/how-can-i-represent-an-enum-in-python", "Language": "Python", "Q_Title": "How can I represent an 'Enum' in Python?", "Q_Votes": "1146", "Q_Content": "    I'm mainly a C# developer, but I'm currently working on a project in Python.  How can I represent the equivalent of an Enum in Python?       ", "Tags": ["python", "python-3.x", "enums"], "A_Votes": "2", "A_Content": "  I had need of some symbolic constants in pyparsing to represent left and right associativity of binary operators.  I used class constants like this:  # an internal class, not intended to be seen by client code class _Constants(object):     pass   # an enumeration of constants for operator associativity opAssoc = _Constants() opAssoc.LEFT = object() opAssoc.RIGHT = object()   Now when client code wants to use these constants, they can import the entire enum using:  import opAssoc from pyparsing   The enumerations are unique, they can be tested with 'is' instead of '==', they don't take up a big footprint in my code for a minor concept, and they are easily imported into the client code.  They don't support any fancy str() behavior, but so far that is in the YAGNI category.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "1490", "A_Content": "  The syntax is the * and **.  The names *args and **kwargs are only by convention but there's no hard requirement to use them.  You would use *args when you're not sure how many arguments might be passed to your function, i.e. it allows you pass an arbitrary number of arguments to your function.  For example:  >>> def print_everything(*args):         for count, thing in enumerate(args): ...         print( '{0}. {1}'.format(count, thing)) ... >>> print_everything('apple', 'banana', 'cabbage') 0. apple 1. banana 2. cabbage   Similarly, **kwargs allows you to handle named arguments that you have not defined in advance:  >>> def table_things(**kwargs): ...     for name, value in kwargs.items(): ...         print( '{0} = {1}'.format(name, value)) ... >>> table_things(apple = 'fruit', cabbage = 'vegetable') cabbage = vegetable apple = fruit   You can use these along with named arguments too.  The explicit arguments get values first and then everything else is passed to *args and **kwargs.  The named arguments come first in the list.  For example:  def table_things(titlestring, **kwargs)   You can also use both in the same function definition but *args must occur before **kwargs.  You can also use the * and ** syntax when calling a function.  For example:  >>> def print_three_things(a, b, c): ...     print( 'a = {0}, b = {1}, c = {2}'.format(a,b,c)) ... >>> mylist = ['aardvark', 'baboon', 'cat'] >>> print_three_things(*mylist) a = aardvark, b = baboon, c = cat   As you can see in this case it takes the list (or tuple) of items and unpacks it. By this it matches them to the arguments in the function.  Of course, you could have a * both in the function definition and in the function call.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "446", "A_Content": "  One place where the use of *args and **kwargs is quite useful is for subclassing.  class Foo(object):     def __init__(self, value1, value2):         # do something with the values         print value1, value2  class MyFoo(Foo):     def __init__(self, *args, **kwargs):         # do something else, don't care about the args         print 'myfoo'         super(MyFoo, self).__init__(*args, **kwargs)   This way you can extend the behaviour of the Foo class, without having to know too much about Foo. This can be quite convenient if you are programming to an API which might change. MyFoo just passes all arguments to the Foo class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "284", "A_Content": "  Here's an example that uses 3 different types of parameters.  def func(required_arg, *args, **kwargs):     # required_arg is a positional-only parameter.     print required_arg      # args is a tuple of positional arguments,     # because the parameter name has * prepended.     if args: # If args is not empty.         print args      # kwargs is a dictionary of keyword arguments,     # because the parameter name has ** prepended.     if kwargs: # If kwargs is not empty.         print kwargs  >>> func() Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: func() takes at least 1 argument (0 given)  >>> func(\"required argument\") required argument  >>> func(\"required argument\", 1, 2, '3') required argument (1, 2, '3')  >>> func(\"required argument\", 1, 2, '3', keyword1=4, keyword2=\"foo\") required argument (1, 2, '3') {'keyword2': 'foo', 'keyword1': 4}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "65", "A_Content": "  Here's one of my favorite places to use the ** syntax as in Dave Webb's final example:  mynum = 1000 mystr = 'Hello World!' print \"{mystr} New-style formatting is {mynum}x more fun!\".format(**locals())   I'm not sure if it's terribly fast when compared to just using the names themselves, but it's a lot easier to type!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "39", "A_Content": "  One case where *args and **kwargs are useful is when writing wrapper functions (such as decorators) that need to be able accept arbitrary arguments to pass through to the function being wrapped.  For example, a simple decorator that prints the arguments and return value of the function being wrapped:  def mydecorator( f ):    @functools.wraps( f )    def wrapper( *args, **kwargs ):       print \"Calling f\", args, kwargs       v = f( *args, **kwargs )       print \"f returned\", v       return v    return wrapper      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "35", "A_Content": "  *args and **kwargs are special-magic features of Python. Think of a function that could have an unknown number of arguments. For example, for whatever reasons, you want to have function that sums an unknown number of numbers (and you don't want to use the built-in sum function). So you write this function:  def sumFunction(*args):   result = 0   for x in args:     result += x   return result   and use it like: sumFunction(3,4,6,3,6,8,9).  **kwargs has a diffrent function. With **kwargs you can give arbitrary keyword arguments to a function and you can access them as a dictonary.  def someFunction(**kwargs):   if 'text' in kwargs:     print kwargs['text']   Calling someFunction(text=\"foo\") will print foo.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "17", "A_Content": "  Just imagine you have a function but you don't want to restrict the number of parameter it takes. Example:  >>> import operator >>> def multiply(*args): ...  return reduce(operator.mul, args)   Then you use this function like:  >>> multiply(1,2,3) 6  or  >>> numbers = [1,2,3] >>> multiply(*numbers) 6      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "15", "A_Content": "  The names *args and **kwargs or **kw are purely by convention. It makes it easier for us to read each other's code  One place it is handy is when using the struct module  struct.unpack() returns a tuple whereas struct.pack() uses a variable number of arguments. When manipulating data it is convenient to be able to pass a tuple to struck.pack() eg.  tuple_of_data = struct.unpack(format_str, data) ... manipulate the data new_data = struct.pack(format_str, *tuple_of_data)   without this ability you would be forced to write  new_data = struct.pack(format_str, tuple_of_data[0], tuple_of_data[1], tuple_of_data[2],...)   which also means the if the format_str changes and the size of the tuple changes, I'll have to go back and edit that really long line     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "9", "A_Content": "  Note that *args/**kwargs is part of function-calling syntax, and not really an operator. This has a particular side effect that I ran into, which is that you can't use *args expansion with the print statement, since print is not a function.  This seems reasonable:  def myprint(*args):     print *args   Unfortunately it doesn't compile (syntax error).  This compiles:  def myprint(*args):     print args   But prints the arguments as a tuple, which isn't what we want.  This is the solution I settled on:  def myprint(*args):     for arg in args:         print arg,     print      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "7", "A_Content": "  These parameters are typically used for proxy functions, so the proxy can pass any input parameter to the target function.  def foo(bar=2, baz=5):     print bar, baz  def proxy(x, *args, **kwargs): # reqire parameter x and accept any number of additional arguments     print x     foo(*args, **kwargs) # applies the \"non-x\" parameter to foo  proxy(23, 5, baz='foo') # calls foo with bar=5 and baz=foo proxy(6)# calls foo with its default arguments proxy(7, bar='asdas') # calls foo with bar='asdas' and leave baz default argument   But since these parameters hide the actual parameter names, it is better to avoid them.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3394835/args-and-kwargs", "Language": "Python", "Q_Title": "*args and **kwargs? [duplicate]", "Q_Votes": "1211", "Q_Content": "          This question already has an answer here:                              What does ** (double star/asterisk) and * (star/asterisk) do for parameters?                                        18 answers                                          So I have difficulty with the concept of *args and **kwargs.  So far I have learned that:   *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.   I don't understand what programming task this would be helpful for.   Maybe:  I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?  Is there a simple example to explain how *args and **kwargs are used?  Also the tutorial I found used just the \"*\" and a variable name.   Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?     ", "Tags": ["python", "args", "kwargs"], "A_Votes": "3", "A_Content": "  You can have a look at python docs (docs.python.org in the FAQ), but more specifically for a good explanation the mysterious miss args and mister kwargs (courtesy of archive.org) (the original, dead link is here).  In a nutshell, both are used when optional parameters to a function or method are used.  As Dave says, *args is used when you don't know how many arguments may be passed, and **kwargs when you want to handle parameters specified by name and value as in:  myfunction(myarg=1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "814", "A_Content": "  You could use the fileinput module:  import fileinput  for line in fileinput.input():     pass   fileinput will loop through all the lines in the input specified as file names given in command-line arguments, or the standard input if no arguments are provided.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "592", "A_Content": "  There's a few ways to do it.   sys.stdin is a file-like object on which you can call functions read or readlines if you want to read everything or you want to read everything and split it by newline automatically. (You need to import sys for this to work.) If you want to prompt the user for input, you can use raw_input in Python 2.X, and just input in Python 3.   If you actually just want to read command-line options, you can access them via the sys.argv list.   You will probably find this Wikibook article on I/O in Python to be a useful reference as well.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "338", "A_Content": "  import sys  for line in sys.stdin:     print line      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "186", "A_Content": "  Python also has built-in functions input() and raw_input(). See the Python documentation under Built-in Functions.  For example,  name = raw_input(\"Enter your name: \")   # Python 2.x   or  name = input(\"Enter your name: \")   # Python 3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "162", "A_Content": "  Here's from Learning Python:  import sys data = sys.stdin.readlines() print \"Counted\", len(data), \"lines.\"     On Unix, you could test it by doing something like:  % cat countlines.py | python countlines.py  Counted 3 lines.   On Windows or DOS, you'd do:  C:\\> type countlines.py | python countlines.py  Counted 3 lines.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "87", "A_Content": "  The answer proposed by others:  for line in sys.stdin:   print line   is very simple and pythonic, but it must be noted that the script will wait until EOF before starting to iterate on the lines of input.  This means that tail -f error_log | myscript.py will not process lines as expected.  The correct script for such a use case would be:  while 1:     try:         line = sys.stdin.readline()     except KeyboardInterrupt:         break      if not line:         break      print line   UPDATE From the comments it has been cleared that on python 2 only there might be buffering involved, so that you end up waiting for the buffer to fill or EOF before the print call is issued.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "52", "A_Content": "     How do you read from stdin in Python?      I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?   You can use:   sys.stdin - A file-like object - call sys.stdin.read() to read everything. input(prompt) - pass it an optional prompt to output, it reads from stdin up to the first newline, which it strips. You'd have to do this repeatedly to get more lines, at the end of the input it raises EOFError. (Probably not great for golfing.) In Python 2, this is rawinput(prompt). open(0).read() - In Python 3 open accepts file descriptors (integers representing operating system IO resources), and 0 is the descriptor of stdin. It returns a file-like object like sys.stdin - probably your best bet for golfing. open('/dev/stdin').read() - similar to open(0), works on Python 2 and 3, but not on Windows (or even Cygwin). fileinput.input() - returns an iterator over lines in all files listed in sys.argv[1:], or stdin if not given. Use like ''.join(fileinput.input()).   Both sys and fileinput must be imported, respectively, of course.  Quick sys.stdin examples compatible with Python 2 and 3, Windows, Unix  You just need to read from sys.stdin, for example, if you pipe data to stdin:  $ echo foo | python -c \"import sys; print(sys.stdin.read())\" foo   file example  Say you have a file, inputs.txt, we can accept that file and write it back out:   python -c \"import sys; sys.stdout.write(sys.stdin.read())\" < inputs.txt   Longer answer  Here's a complete, easily replicable demo, using two methods, the builtin function, input (use raw_input in Python 2), and sys.stdin. The data is unmodified, so the processing is a non-operation.  To begin with, let's create a file for inputs:  $ python -c \"print('foo\\nbar\\nbaz')\" > inputs.txt   And using the code we've already seen, we can check that we've created the file:  $ python -c \"import sys; sys.stdout.write(sys.stdin.read())\" < inputs.txt  foo bar baz   Here's the help on sys.stdin.read from Python 3:  read(size=-1, /) method of _io.TextIOWrapper instance     Read at most n characters from stream.      Read from underlying buffer until we have n characters or we hit EOF.     If n is negative or omitted, read until EOF.   Builtin function, input (raw_input in Python 2)  The builtin function input reads from standard input up to a newline, which is stripped (complementing print, which adds a newline by default.) This occurs until it gets EOF (End Of File), at which point it raises EOFError.  Thus, here's how you can use input in Python 3 (or raw_input in Python 2) to read from stdin - so we create a Python module we call stdindemo.py:  $ python -c \"print('try:\\n    while True:\\n        print(input())\\nexcept EOFError:\\n    pass')\" > stdindemo.py    And let's print it back out to ensure it's as we expect:  $ python -c \"import sys; sys.stdout.write(sys.stdin.read())\" < stdindemo.py  try:     while True:         print(input()) except EOFError:     pass   Again, input reads up until the newline and essentially strips it from the line. print adds a newline. So while they both modify the input, their modifications cancel. (So they are essentially each other's complement.)  And when input gets the end-of-file character, it raises EOFError, which we ignore and then exit from the program.  And on Linux/Unix, we can pipe from cat:  $ cat inputs.txt | python -m stdindemo foo bar baz   Or we can just redirect the file from stdin:  $ python -m stdindemo < inputs.txt  foo bar baz   We can also execute the module as a script:  $ python stdindemo.py < inputs.txt  foo bar baz   Here's the help on the builtin input from Python 3:  input(prompt=None, /)     Read a string from standard input.  The trailing newline is stripped.      The prompt string, if given, is printed to standard output without a     trailing newline before reading input.      If the user hits EOF (*nix: Ctrl-D, Windows: Ctrl-Z+Return), raise EOFError.     On *nix systems, readline is used if available.   sys.stdin  Here we make a demo script using sys.stdin. The efficient way to iterate over a file-like object is to use the file-like object as an iterator. The complementary method to write to stdout from this input is to simply use sys.stdout.write:  $ python -c \"print('import sys\\nfor line in sys.stdin:\\n    sys.stdout.write(line)')\" > stdindemo2.py   Print it back out to make sure it looks right:  $ python -c \"import sys; sys.stdout.write(sys.stdin.read())\" < stdindemo2.py  import sys for line in sys.stdin:     sys.stdout.write(line)   And redirecting the inputs into the file:  $ python -m stdindemo2 < inputs.txt foo bar baz   Golfed into a command:  $ python -c \"import sys; sys.stdout.write(sys.stdin.read())\" < inputs.txt foo bar baz   File Descriptors for Golfing  Since the file descriptors for stdin and stdout are 0 and 1 respectively, we can also pass those to open in Python 3 (not 2, and note that we still need the 'w' for writing to stdout).  If this works on your system, it will shave off more characters.   $ python -c \"open(1,'w').write(open(0).read())\" < inputs.txt baz bar foo   Python 2's io.open does this as well, but the import takes a lot more space:  $ python -c \"from io import open; open(1,'w').write(open(0).read())\" < inputs.txt  foo bar baz   Addressing other comments and answers  One comment suggests ''.join(sys.stdin) but that's actually longer than sys.stdin.read() - plus Python must create an extra list in memory (that's how str.join works when not given a list) - for contrast:  ''.join(sys.stdin) sys.stdin.read()   The top answer suggests:  import fileinput  for line in fileinput.input():     pass   But, since sys.stdin implements the file API, including the iterator protocol, that's just the same as this:  import sys  for line in sys.stdin:     pass   Another answer does suggest this. Just remember that if you do it in an interpreter, you'll need to do Ctrl-d if you're on Linux or Mac, or Ctrl-z on Windows (after Enter) to send the end-of-file character to the process. Also, that answer suggests print(line) - which adds a '\\n' to the end - use print(line, end='') instead (if in Python 2, you'll need from __future__ import print_function).   The real use-case for fileinput is for reading in a series of files.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "36", "A_Content": "  This will echo standard input to standard output:  import sys line = sys.stdin.readline() while line:     print line,     line = sys.stdin.readline()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "28", "A_Content": "  Building on all the anwers using sys.stdin, you can also do something like the following to read from an argument file if at least one argument exists, and fall back to stdin otherwise:  import sys f = open(sys.argv[1]) if len(sys.argv) > 1 else sys.stdin     for line in f: #     Do your stuff   and use it as either  $ python do-my-stuff.py infile.txt   or  $ cat infile.txt | python do-my-stuff.py   or even  $ python do-my-stuff.py < infile.txt   That would make your Python script behave like many GNU/Unix programs such as cat, grep and sed.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "13", "A_Content": "  The following chip of code will help you (it will read all of stdin blocking unto EOF, into one string):  import sys input_str = sys.stdin.read() print input_str.split()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "7", "A_Content": "  Try this:  import sys  print sys.stdin.read().upper()   and check it with:  $ echo \"Hello World\" | python myFile.py      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "7", "A_Content": "  You can read from stdin and then store inputs into \"data\" as follows:  data = \"\" for line in sys.stdin:     data += line      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "5", "A_Content": "  I am pretty amazed no one had mentioned this hack so far:  python -c \"import sys;print (''.join([l for l in sys.stdin.readlines()]))\"   compatible with both python2 and python3     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "4", "A_Content": "  Read from sys.stdin, but to read binary data on Windows, you need to be extra careful, because sys.stdin there is opened in text mode and it will corrupt \\r\\n replacing them with \\n.  The solution is to set mode to binary if Windows + Python 2 is detected, and on Python 3 use sys.stdin.buffer.  import sys  PY3K = sys.version_info >= (3, 0)  if PY3K:     source = sys.stdin.buffer else:     # Python 2 on Windows opens sys.stdin in text mode, and     # binary data that read from it becomes corrupted on \\r\\n     if sys.platform == \"win32\":         # set sys.stdin to binary mode         import os, msvcrt         msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)     source = sys.stdin  b = source.read()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "3", "A_Content": "  The problem I have with solution  import sys  for line in sys.stdin:     print(line)   is that if you don't pass any data to stdin, it will block forever. That's why I love this answer: check if there is some data on stdin first, and then read it. This is what I ended up doing:  import sys import select  # select(files to read from, files to write to, magic, timeout) # timeout=0.0 is essential b/c we want to know the asnwer right away if select.select([sys.stdin], [], [], 0.0)[0]:     help_file_fragment = sys.stdin.read() else:     print(\"No data passed to stdin\", file=sys.stderr)     sys.exit(2)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "2", "A_Content": "  I had some issues when getting this to work for reading over sockets piped to it. When the socket got closed it started returning empty string in an active loop. So this is my solution to it (which I only tested in linux, but hope it works in all other systems)  import sys, os sep=os.linesep  while sep == os.linesep:     data = sys.stdin.readline()                    sep = data[-len(os.linesep):]     print '> \"%s\"' % data.strip()   So if you start listening on a socket it will work properly (e.g. in bash):  while :; do nc -l 12345 | python test.py ; done   And you can call it with telnet or just point a browser to localhost:12345     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file", "Language": "Python", "Q_Title": "How do you append to a file?", "Q_Votes": "1213", "Q_Content": "    How do you append to the file instead of overwriting it? Is there a special function that appends to the file?     ", "Tags": ["python", "file", "append"], "A_Votes": "1921", "A_Content": "  with open(\"test.txt\", \"a\") as myfile:     myfile.write(\"appended text\")      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "1186", "A_Content": "  You are running into the old problem with floating point numbers that all numbers cannot be represented. The command line is just showing you the full floating point form from memory.  In floating point your rounded version is the same number. Since computers are binary, they store floating point numbers as an integer and then divide it by a power of two so 13.95 will be represented in a similar fashion to 125650429603636838/(2**53).  Double precision numbers have 53 bits (16 digits) of precision and regular floats have 24 bits (8 digits) of precision. The floating point in Python uses double precision to store the values.  For example,    >>> 125650429603636838/(2**53)   13.949999999999999    >>> 234042163/(2**24)   13.949999988079071    >>> a=13.946   >>> print(a)   13.946   >>> print(\"%.2f\" % a)   13.95   >>> round(a,2)   13.949999999999999   >>> print(\"%.2f\" % round(a,2))   13.95   >>> print(\"{0:.2f}\".format(a))   13.95   >>> print(\"{0:.2f}\".format(round(a,2)))   13.95   >>> print(\"{0:.15f}\".format(round(a,2)))   13.949999999999999   If you are after only two decimal places as in currency then you have a couple of better choices: 1) Use integers and store values in cents, not dollars and then divide by 100 to convert to dollars. 2) Or use a fixed point number like decimal.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "1", "A_Content": "  Regarding this:  for line in sys.stdin:  I just tried it on python 2.7 (following someone else's suggestion) for a very large file, and I don't recommend it, precisely for the reasons mentioned above (nothing happens for a long time).   I ended up with a slightly more pythonic solution (and it works on bigger files):  with open(sys.argv[1], 'r') as f:     for line in f:   Then I can run the script locally as:  python myscript.py \"0 1 2 3 4...\" # can be a multi-line string or filename - any std.in input will work      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1450393/how-do-you-read-from-stdin-in-python", "Language": "Python", "Q_Title": "How do you read from stdin in Python?", "Q_Votes": "1194", "Q_Content": "    I'm trying to do some of the code golf challenges, but they all require the input to be taken from stdin. How do I get that in Python?     ", "Tags": ["python", "stdin"], "A_Votes": "0", "A_Content": "  n = int(raw_input()) for i in xrange(n):     name, number = raw_input().split()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file", "Language": "Python", "Q_Title": "How do you append to a file?", "Q_Votes": "1213", "Q_Content": "    How do you append to the file instead of overwriting it? Is there a special function that appends to the file?     ", "Tags": ["python", "file", "append"], "A_Votes": "163", "A_Content": "  You need to open the file in append mode, by setting \"a\" or \"ab\" as the mode. See open().  When you open with \"a\" mode, the write position will always be at the end of the file (an append). You can open with \"a+\" to allow reading, seek backwards and read (but all writes will still be at the end of the file!).  Example:  >>> with open('test1','wb') as f:         f.write('test') >>> with open('test1','ab') as f:         f.write('koko') >>> with open('test1','rb') as f:         f.read() 'testkoko'   Note: Using 'a' is not the same as opening with 'w' and seeking to the end of the file - consider what might happen if another program opened the file and started writing between the seek and the write. On some operating systems, opening the file with 'a' guarantees that all your following writes will be appended atomically to the end of the file (even as the file grows by other writes).    A few more details about how the \"a\" mode operates (tested on Linux only). Even if you seek back, every write will append to the end of the file:  >>> f = open('test','a+') # Not using 'with' just to simplify the example REPL session >>> f.write('hi') >>> f.seek(0) >>> f.read() 'hi' >>> f.seek(0) >>> f.write('bye') # Will still append despite the seek(0)! >>> f.seek(0) >>> f.read() 'hibye'   In fact, the fopen manpage states:     Opening a file in append mode (a as the first character of mode)   causes all subsequent write operations to this stream to occur at   end-of-file, as if preceded the call:  fseek(stream, 0, SEEK_END);      Old simplified answer (not using with):  Example: (in a real program use with to close the file - see the documentation)  >>> open(\"test\",\"wb\").write(\"test\") >>> open(\"test\",\"a+b\").write(\"koko\") >>> open(\"test\",\"rb\").read() 'testkoko'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file", "Language": "Python", "Q_Title": "How do you append to a file?", "Q_Votes": "1213", "Q_Content": "    How do you append to the file instead of overwriting it? Is there a special function that appends to the file?     ", "Tags": ["python", "file", "append"], "A_Votes": "35", "A_Content": "  I always do this,  f = open('filename.txt', 'a') f.write(\"stuff\") f.close()   It's simple, but very useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file", "Language": "Python", "Q_Title": "How do you append to a file?", "Q_Votes": "1213", "Q_Content": "    How do you append to the file instead of overwriting it? Is there a special function that appends to the file?     ", "Tags": ["python", "file", "append"], "A_Votes": "33", "A_Content": "  You probably want to pass \"a\" as the mode argument.  See the docs for open().  with open(\"foo\", \"a\") as f:     f.write(\"cool beans...\")   There are other permutations of the mode argument for updating (+), truncating (w) and binary (b) mode but starting with just \"a\" is your best bet.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file", "Language": "Python", "Q_Title": "How do you append to a file?", "Q_Votes": "1213", "Q_Content": "    How do you append to the file instead of overwriting it? Is there a special function that appends to the file?     ", "Tags": ["python", "file", "append"], "A_Votes": "11", "A_Content": "  Python has many variations off of the main three modes, these three modes are:  'w'   write text 'r'   read text 'a'   append text   So to append to a file it's as easy as:  f = open('filename.txt', 'a')  f.write('whatever you want to write here (in append mode) here.')   Then there are the modes that just make your code fewer lines:  'r+'  read + write text 'w+'  read + write text 'a+'  append + read text   Finally, there are the modes of reading/writing in binary format:   'rb'  read binary 'wb'  write binary 'ab'  append binary 'rb+' read + write binary 'wb+' read + write binary 'ab+' append + read binary      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file", "Language": "Python", "Q_Title": "How do you append to a file?", "Q_Votes": "1213", "Q_Content": "    How do you append to the file instead of overwriting it? Is there a special function that appends to the file?     ", "Tags": ["python", "file", "append"], "A_Votes": "10", "A_Content": "  when we using this line open(filename, \"a\"), that a indicates the appending the file, that means allow to insert extra data to the existing file.  You can just use this following lines to append the text in your file  def FileSave(filename,content):     with open(filename, \"a\") as myfile:         myfile.write(content)  FileSave(\"test.txt\",\"test1 \\n\") FileSave(\"test.txt\",\"test2 \\n\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "435", "A_Content": "  There are new format specifications, String Format Specification Mini-Language:  You can do the same as:  \"{0:.2f}\".format(13.949999999999999)   Note that the above returns a string. In order to get as float, simply wrap with float(...):  float(\"{0:.2f}\".format(13.949999999999999))   Note that wrapping with float() doesn't change anything:  >>> x = 13.949999999999999999 >>> x 13.95 >>> g = float(\"{0:.2f}\".format(x)) >>> g 13.95 >>> x == g True >>> h = round(x, 2) >>> h 13.95 >>> x == h True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "154", "A_Content": "  The built-in round() works just fine in Python 2.7 or later.  Example:  >>> round(14.22222223, 2) 14.22   Check out the documentation.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "123", "A_Content": "  I feel that the simplest approach is to use the format() function.  For example:  a = 13.949999999999999 format(a, '.2f')  13.95   This produces a float number as a string rounded to two decimal points.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "86", "A_Content": "  Most numbers cannot be exactly represented in floats. If you want to round the number because that's what your mathematical formula or algorithm requires, then you want to use round. If you just want to restrict the display to a certain precision, then don't even use round and just format it as that string. (If you want to display it with some alternate rounding method, and there are tons, then you need to mix the two approaches.)  >>> \"%.2f\" % 3.14159 '3.14' >>> \"%.2f\" % 13.9499999 '13.95'   And lastly, though perhaps most importantly, if you want exact math then you don't want floats at all. The usual example is dealing with money and to store 'cents' as an integer.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "66", "A_Content": "  Try the code below:  >>> a = 0.99334 >>> a = int((a * 100) + 0.5) / 100.0 # Adding 0.5 rounds it up >>> print a 0.99      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "49", "A_Content": "  With Python < 3 (e.g. 2.6 or 2.7), there are two ways to do so.  # Option one  older_method_string = \"%.9f\" % numvar  # Option two (note ':' before the '.9f') newer_method_string = \"{:.9f}\".format(numvar)   But note that for Python versions above 3 (e.g. 3.2 or 3.3), option two is preferred.  For more information on option two, I suggest this link on string formatting from the Python documentation.  And for more information on option one, this link will suffice and has information on the various flags.  Reference: Convert floating point number to a certain precision, and then copy to string     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "39", "A_Content": "  You can modify the output format:  >>> a = 13.95 >>> a 13.949999999999999 >>> print \"%.2f\" % a 13.95      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "39", "A_Content": "  Use  print\"{:.2f}\".format(a)   instead of  print\"{0:.2f}\".format(a)   Because the latter may lead to output errors when trying to output multiple variables (see comments).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "27", "A_Content": "  TLDR ;)  The rounding problem at input / output has been solved by Python 2.7.0 and 3.1 definitively.  Infinite test:  import random for x in iter(random.random, None):           # Verify FOREVER that rounding is fixed :-)     assert float(repr(x)) == x                # Reversible repr() conversion.     assert len(repr(round(x, 10))) <= 12      # Smart decimal places in repr() after round.     if x >= 0.1:                              # Implicit rounding to 12 significant digits         assert str(x) == repr(round(x, 12))   # by str() is good enough for small errors.         y = 1000 * x                             # Decimal type is excessive for shopping         assert str(y) == repr(round(y, 12 - 3))  # in the supermaket with Python 2.7+ :-)   Documentation  See the Release notes Python 2.7 - Other Language Changes the fourth paragraph:     Conversions between floating-point numbers and strings are now correctly rounded on most platforms. These conversions occur in many different places: str() on floats and complex numbers; the float and complex constructors; numeric formatting; serializing and de-serializing floats and complex numbers using the marshal, pickle and json modules; parsing of float and imaginary literals in Python code; and Decimal-to-float conversion.      Related to this, the repr() of a floating-point number x now returns a result based on the shortest decimal string that\u2019s guaranteed to round back to x under correct rounding (with round-half-to-even rounding mode). Previously it gave a string based on rounding x to 17 decimal digits.   The related issue    More information:: The formatting of float before Python 2.7 was similar to the current numpy.float64. Both types use the same 64 bit IEEE 754 double precision with 52 bit mantissa. A big difference is that np.float64.__repr__ is formatted frequently with an excessive decimal number so that no bit can be lost, but no valid IEEE 754 number exists between 13.949999999999999 and 13.950000000000001. The result is not nice and the conversion repr(float(number_as_string)) is not reversible. On the other hand: float.__repr__ is formatted so that every digit is important; the sequence is without gaps and the conversion is reversible. Simply: If you perhaps have a numpy.float64 number, convert it to normal float in order to be formatted for humans, not for numeric processors, otherwise nothing more is necessary with Python 2.7+.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "19", "A_Content": "  The Python tutorial has an appendix called Floating Point Arithmetic: Issues and Limitations. Read it. It explains what is happening and why Python is doing its best. It has even an example that matches yours. Let me quote a bit:   >>> 0.1 0.10000000000000001       you may be tempted to use the round()   function to chop it back to the single   digit you expect. But that makes no   difference:  >>> round(0.1, 1) 0.10000000000000001       The problem is that the binary   floating-point value stored for \u201c0.1\u201d   was already the best possible binary   approximation to 1/10, so trying to   round it again can\u2019t make it better:   it was already as good as it gets.      Another consequence is that since 0.1   is not exactly 1/10, summing ten   values of 0.1 may not yield exactly   1.0, either:  >>> sum = 0.0 >>> for i in range(10): ...     sum += 0.1 ... >>> sum 0.99999999999999989    One alternative and solution to your problems would be using the decimal module.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "14", "A_Content": "  In Python 2.7:  a = 13.949999999999999 output = float((\"%0.2f\"%a)) print output      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "11", "A_Content": "  Nobody here seems to have mentioned it yet, so let me give an example in Python 3.6's f-string/template-string format, which I think is beautifully neat:  >>> f'{a:.2f}'   It works well with longer examples too, with operators and not needing parens:  >>> print(f'Completed in {time.time() - start:.2f}s')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "11", "A_Content": "  It's doing exactly what you told it to do and is working correctly. Read more about floating point confusion and maybe try decimal objects instead.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "7", "A_Content": "  As @Matt pointed out, Python 3.6 provides f-strings, and they can also use nested parameters:  value = 2.34558 precision = 2 width = 4  print(f'result: {value:{width}.{precision}f}')   which will display result: 2.35     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "6", "A_Content": "  For fixing the floating point in type-dynamic languages such as Python and JavaScript, I use this technique  # For example: a = 70000 b = 0.14 c = a * b  print c # Prints 980.0000000002 # Try to fix c = int(c * 10000)/100000 print c # Prints 980   You can also use Decimal as following:  from decimal import * getcontext().prec = 6 Decimal(1) / Decimal(7) # Results in 6 precision -> Decimal('0.142857')  getcontext().prec = 28 Decimal(1) / Decimal(7) # Results in 28 precision -> Decimal('0.1428571428571428571428571429')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "4", "A_Content": "  orig_float = 232569 / 16000.0      14.5355625   short_float = float(\"{:.2f}\".format(orig_float))       14.54      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points", "Language": "Python", "Q_Title": "Limiting floats to two decimal points", "Q_Votes": "1155", "Q_Content": "    I want a to be rounded to 13.95.  >>> a 13.949999999999999 >>> round(a, 2) 13.949999999999999   The round function does not work the way I expected.     ", "Tags": ["python", "floating-point", "rounding", "precision"], "A_Votes": "1", "A_Content": "  To round a number to a resolution, the best way is the following one, which can work with any resolution (0.01 for two decimals or even other steps):  >>> import numpy as np >>> value = 13.949999999999999 >>> resolution = 0.01 >>> newValue = int(np.round(value/resolution))*resolution >>> print newValue 13.95  >>> resolution = 0.5 >>> newValue = int(np.round(value/resolution))*resolution >>> print newValue 14.0      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "855", "A_Content": "  To answer your first question... .format just seems more sophisticated in many ways. An annoying thing about % is also how it can either take a variable or a tuple. You'd think the following would always work:  \"hi there %s\" % name   yet, if name happens to be (1, 2, 3), it will throw a TypeError. To guarantee that it always prints, you'd need to do  \"hi there %s\" % (name,)   # supply the single argument as a single-item tuple   which is just ugly. .format doesn't have those issues. Also in the second example you gave, the .format example is much cleaner looking.  Why would you not use it?    not knowing about it (me before reading this) having to be compatible with Python 2.5     To answer your second question, string formatting happens at the same time as any other operation - when the string formatting expression is evaluated. And Python, not being a lazy language, evaluates expressions before calling functions, so in your log.debug example, the expression \"some debug info: %s\"%some_infowill first evaluate to, e.g. \"some debug info: roflcopters are active\", then that string will be passed to log.debug().      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "282", "A_Content": "  Something that the modulo operator ( % ) can't do, afaik:  tu = (12,45,22222,103,6) print '{0} {2} {1} {2} {3} {2} {4} {2}'.format(*tu)   result  12 22222 45 22222 103 22222 6 22222   Very useful.  Another point: format(), being a function, can be used as an argument in other functions:   li = [12,45,78,784,2,69,1254,4785,984] print map('the number is {}'.format,li)     print  from datetime import datetime,timedelta  once_upon_a_time = datetime(2010, 7, 1, 12, 0, 0) delta = timedelta(days=13, hours=8,  minutes=20)  gen =(once_upon_a_time +x*delta for x in xrange(20))  print '\\n'.join(map('{:%Y-%m-%d %H:%M:%S}'.format, gen))   Results in:  ['the number is 12', 'the number is 45', 'the number is 78', 'the number is 784', 'the number is 2', 'the number is 69', 'the number is 1254', 'the number is 4785', 'the number is 984']  2010-07-01 12:00:00 2010-07-14 20:20:00 2010-07-28 04:40:00 2010-08-10 13:00:00 2010-08-23 21:20:00 2010-09-06 05:40:00 2010-09-19 14:00:00 2010-10-02 22:20:00 2010-10-16 06:40:00 2010-10-29 15:00:00 2010-11-11 23:20:00 2010-11-25 07:40:00 2010-12-08 16:00:00 2010-12-22 00:20:00 2011-01-04 08:40:00 2011-01-17 17:00:00 2011-01-31 01:20:00 2011-02-13 09:40:00 2011-02-26 18:00:00 2011-03-12 02:20:00      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "126", "A_Content": "  Assuming you're using Python's logging module, you can pass the string formatting arguments as arguments to the .debug() method rather than doing the formatting yourself:  log.debug(\"some debug info: %s\", some_info)   which avoids doing the formatting unless the logger actually logs something.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "89", "A_Content": "  As of Python 3.6 (2016) you can use f-strings to substitute variables:  >>> origin = \"London\" >>> destination = \"Paris\" >>> f\"from {origin} to {destination}\" 'from London to Paris'   Note the f\" prefix. If you try this in Python 3.5 or earlier, you'll get a SyntaxError.  See https://docs.python.org/3.6/reference/lexical_analysis.html#f-strings     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "54", "A_Content": "  PEP 3101 proposes the replacement of the % operator with the new, advanced string formatting in Python 3, where it would be the default.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "51", "A_Content": "  But please be careful, just now I've discovered one issue when trying to replace all % with .format in existing code: '{}'.format(unicode_string) will try to encode unicode_string and will probably fail.  Just look at this Python interactive session log:  Python 2.7.2 (default, Aug 27 2012, 19:52:55)  [GCC 4.1.2 20080704 (Red Hat 4.1.2-48)] on linux2 ; s='\u0439' ; u=u'\u0439' ; s '\\xd0\\xb9' ; u u'\\u0439'   s is just a string (called 'byte array' in Python3) and u is a Unicode string (called 'string' in Python3):  ; '%s' % s '\\xd0\\xb9' ; '%s' % u u'\\u0439'   When you give a Unicode object as a parameter to % operator it will produce a Unicode string even if the original string wasn't Unicode:  ; '{}'.format(s) '\\xd0\\xb9' ; '{}'.format(u) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u0439' in position 0: ordinal not in range(256)   but the .format function will raise \"UnicodeEncodeError\":  ; u'{}'.format(s) u'\\xd0\\xb9' ; u'{}'.format(u) u'\\u0439'   and it will work with a Unicode argument fine only if the original string was Unicode.  ; '{}'.format(u'i') 'i'   or if argument string can be converted to a string (so called 'byte array')     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "33", "A_Content": "  Yet another advantage of .format (which I don't see in the answers): it can take object properties.  In [12]: class A(object):    ....:     def __init__(self, x, y):    ....:         self.x = x    ....:         self.y = y    ....:           In [13]: a = A(2,3)  In [14]: 'x is {0.x}, y is {0.y}'.format(a) Out[14]: 'x is 2, y is 3'   Or, as a keyword argument:  In [15]: 'x is {a.x}, y is {a.y}'.format(a=a) Out[15]: 'x is 2, y is 3'   This is not possible with % as far as I can tell.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "27", "A_Content": "  As I discovered today, the old way of formatting strings via % doesn't support Decimal, Python's module for decimal fixed point and floating point arithmetic, out of the box.  Example (using Python 3.3.5):  #!/usr/bin/env python3  from decimal import *  getcontext().prec = 50 d = Decimal('3.12375239e-24') # no magic number, I rather produced it by banging my head on my keyboard  print('%.50f' % d) print('{0:.50f}'.format(d))   Output:     0.00000000000000000000000312375239000000009907464850   0.00000000000000000000000312375239000000000000000000   There surely might be work-arounds but you still might consider using the format() method right away.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "22", "A_Content": "  % gives better performance than format from my test.  Test code:  Python 2.7.2:  import timeit print 'format:', timeit.timeit(\"'{}{}{}'.format(1, 1.23, 'hello')\") print '%:', timeit.timeit(\"'%s%s%s' % (1, 1.23, 'hello')\")   Result:  > format: 0.470329046249 > %: 0.357107877731   Python 3.5.2  import timeit print('format:', timeit.timeit(\"'{}{}{}'.format(1, 1.23, 'hello')\")) print('%:', timeit.timeit(\"'%s%s%s' % (1, 1.23, 'hello')\"))   Result  > format: 0.5864730989560485 > %: 0.013593495357781649   It looks in Python2, the difference is small whereas in Python3, % is much faster than format.  Thanks @Chris Cogdon for the sample code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "14", "A_Content": "  As a side note, you don't have to take a performance hit to use new style formatting with logging.  You can pass any object to logging.debug, logging.info, etc. that implements the __str__ magic method.  When the logging module has decided that it must emit your message object (whatever it is), it calls str(message_object) before doing so.  So you could do something like this:  import logging   class NewStyleLogMessage(object):     def __init__(self, message, *args, **kwargs):         self.message = message         self.args = args         self.kwargs = kwargs      def __str__(self):         args = (i() if callable(i) else i for i in self.args)         kwargs = dict((k, v() if callable(v) else v) for k, v in self.kwargs.items())          return self.message.format(*args, **kwargs)  N = NewStyleLogMessage  # Neither one of these messages are formatted (or calculated) until they're # needed  # Emits \"Lazily formatted log entry: 123 foo\" in log logging.debug(N('Lazily formatted log entry: {0} {keyword}', 123, keyword='foo'))   def expensive_func():     # Do something that takes a long time...     return 'foo'  # Emits \"Expensive log entry: foo\" in log logging.debug(N('Expensive log entry: {keyword}', keyword=expensive_func))   This is all described in the Python 3 documentation (https://docs.python.org/3/howto/logging-cookbook.html#formatting-styles).  However, it will work with Python 2.6 as well (https://docs.python.org/2.6/library/logging.html#using-arbitrary-objects-as-messages).  One of the advantages of using this technique, other than the fact that it's formatting-style agnostic, is that it allows for lazy values e.g. the function expensive_func above.  This provides a more elegant alternative to the advice being given in the Python docs here: https://docs.python.org/2.6/library/logging.html#optimization.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "8", "A_Content": "  One situation where % may help is when you are formatting regex expressions. For example,   '{type_names} [a-z]{2}'.format(type_names='triangle|square')   raises IndexError. In this situation, you can use:  '%(type_names)s [a-z]{2}' % {'type_names': 'triangle|square'}   This avoids writing the regex as '{type_names} [a-z]{{2}}'. This can be useful when you have two regexes, where one is used alone without format, but the concatenation of both is formatted.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "2", "A_Content": "  If your python >= 3.6, F-string formatted literal is your new friend.  It's more simple, clean, and better performance.  In [1]: params=['Hello', 'adam', 42]  In [2]: %timeit \"%s %s, the answer to everything is %d.\"%(params[0],params[1],params[2]) 448 ns \u00b1 1.48 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)  In [3]: %timeit \"{} {}, the answer to everything is {}.\".format(*params) 449 ns \u00b1 1.42 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)  In [4]: %timeit f\"{params[0]} {params[1]}, the answer to everything is {params[2]}.\" 12.7 ns \u00b1 0.0129 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000000 loops each)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "1", "A_Content": "  For python version >= 3.6 (see PEP 498)  s1='albha' s2='beta'  f'{s1}{s2:>10}'  #output 'albha      beta'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "0", "A_Content": "  I would add that since version 3.6, we can use fstrings like the following  foo = \"john\" bar = \"smith\" print(f\"My name is {foo} {bar}\")   Which give     My name is john smith   Everything is converted to strings  mylist = [\"foo\", \"bar\"] print(f\"mylist = {mylist}\")   Result:     mylist = ['foo', 'bar']   you can pass function, like in others formats method  print(f'Hello, here is the date : {time.strftime(\"%d/%m/%Y\")}')   Giving for example     Hello, here is the date : 16/04/2018      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5082452/python-string-formatting-vs-format", "Language": "Python", "Q_Title": "Python string formatting: % vs. .format", "Q_Votes": "1190", "Q_Content": "    Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?   The following uses each method and has the same outcome, so what is the difference?  #!/usr/bin/python sub1 = \"python string!\" sub2 = \"an arg\"  a = \"i am a %s\" % sub1 b = \"i am a {0}\".format(sub1)  c = \"with %(kwarg)s!\" % {'kwarg':sub2} d = \"with {kwarg}!\".format(kwarg=sub2)  print a    # \"i am a python string!\" print b    # \"i am a python string!\" print c    # \"with an arg!\" print d    # \"with an arg!\"  Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?  log.debug(\"some debug info: %s\" % some_info)       ", "Tags": ["python", "performance", "logging", "string-formatting"], "A_Votes": "0", "A_Content": "  But one thing is that also if you have nested curly-braces, won't work for format but % will work.  Example:  >>> '{{0}, {1}}'.format(1,2) Traceback (most recent call last):   File \"<pyshell#3>\", line 1, in <module>     '{{0}, {1}}'.format(1,2) ValueError: Single '}' encountered in format string >>> '{%s, %s}'%(1,2) '{1, 2}' >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "2202", "A_Content": "  Though classmethod and staticmethod are quite similar, there's a slight difference in usage for both entities: classmethod must have a reference to a class object as the first parameter, whereas staticmethod can have no parameters at all.  Example  class Date(object):      def __init__(self, day=0, month=0, year=0):         self.day = day         self.month = month         self.year = year      @classmethod     def from_string(cls, date_as_string):         day, month, year = map(int, date_as_string.split('-'))         date1 = cls(day, month, year)         return date1      @staticmethod     def is_date_valid(date_as_string):         day, month, year = map(int, date_as_string.split('-'))         return day <= 31 and month <= 12 and year <= 3999  date2 = Date.from_string('11-09-2012') is_date = Date.is_date_valid('11-09-2012')   Explanation  Let's assume an example of a class, dealing with date information (this will be our boilerplate):  class Date(object):      def __init__(self, day=0, month=0, year=0):         self.day = day         self.month = month         self.year = year   This class obviously could be used to store information about certain dates (without timezone information; let's assume all dates are presented in UTC).  Here we have __init__, a typical initializer of Python class instances, which receives arguments as a typical instancemethod, having the first non-optional argument (self) that holds a reference to a newly created instance.  Class Method  We have some tasks that can be nicely done using classmethods.  Let's assume that we want to create a lot of Date class instances having date information coming from an outer source encoded as a string with format 'dd-mm-yyyy'. Suppose we have to do this in different places in the source code of our project.  So what we must do here is:   Parse a string to receive day, month and year as three integer variables or a 3-item tuple consisting of that variable. Instantiate Date by passing those values to the initialization call.   This will look like:  day, month, year = map(int, string_date.split('-')) date1 = Date(day, month, year)   For this purpose, C++ can implement such a feature with overloading, but Python lacks this overloading. Instead, we can use classmethod. Let's create another \"constructor\".      @classmethod     def from_string(cls, date_as_string):         day, month, year = map(int, date_as_string.split('-'))         date1 = cls(day, month, year)         return date1  date2 = Date.from_string('11-09-2012')   Let's look more carefully at the above implementation, and review what advantages we have here:   We've implemented date string parsing in one place and it's reusable now. Encapsulation works fine here (if you think that you could implement string parsing as a single function elsewhere, this solution fits the OOP paradigm far better). cls is an object that holds the class itself, not an instance of the class. It's pretty cool because if we inherit our Date class, all children will have from_string defined also.   Static method  What about staticmethod? It's pretty similar to classmethod but doesn't take any obligatory parameters (like a class method or instance method does).  Let's look at the next use case.  We have a date string that we want to validate somehow. This task is also logically bound to the Date class we've used so far, but doesn't require instantiation of it.  Here is where staticmethod can be useful. Let's look at the next piece of code:      @staticmethod     def is_date_valid(date_as_string):         day, month, year = map(int, date_as_string.split('-'))         return day <= 31 and month <= 12 and year <= 3999      # usage:     is_date = Date.is_date_valid('11-09-2012')   So, as we can see from usage of staticmethod, we don't have any access to what the class is---it's basically just a function,  called syntactically like a method, but without access to the object and its internals (fields and another methods), while classmethod does.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "730", "A_Content": "  Rostyslav Dzinko's answer is very appropriate. I thought I could highlight one other reason you should choose @classmethod over @staticmethod when you are creating additional constructor.  In the example above, Rostyslav used the @classmethod from_string as a Factory to create Date objects from otherwise unacceptable parameters. The same can be done with @staticmethod as is shown in the code below:    class Date:   def __init__(self, month, day, year):     self.month = month     self.day   = day     self.year  = year     def display(self):     return \"{0}-{1}-{2}\".format(self.month, self.day, self.year)     @staticmethod   def millenium(month, day):     return Date(month, day, 2000)  new_year = Date(1, 1, 2013)               # Creates a new Date object millenium_new_year = Date.millenium(1, 1) # also creates a Date object.   # Proof: new_year.display()           # \"1-1-2013\" millenium_new_year.display() # \"1-1-2000\"  isinstance(new_year, Date) # True isinstance(millenium_new_year, Date) # True   Thus both new_year and millenium_new_year are instances of Date class.  But, if you observe closely, the Factory process is hard-coded to create Date objects no matter what. What this means is that even if the Date class is subclassed, the subclasses will still create plain Date object (without any property of the subclass). See that in the example below:  class DateTime(Date):   def display(self):       return \"{0}-{1}-{2} - 00:00:00PM\".format(self.month, self.day, self.year)   datetime1 = DateTime(10, 10, 1990) datetime2 = DateTime.millenium(10, 10)  isinstance(datetime1, DateTime) # True isinstance(datetime2, DateTime) # False  datetime1.display() # returns \"10-10-1990 - 00:00:00PM\" datetime2.display() # returns \"10-10-2000\" because it's not a DateTime object but a Date object. Check the implementation of the millenium method on the Date class   datetime2 is not an instance of DateTime? WTF? Well that's because of the @staticmethod decorator used.  In most cases, this is undesired. If what you want is a Factory method that is aware of the class that called it, then @classmethod is what you need.  Rewriting the Date.millenium as (that's the only part of the above code that changes)  @classmethod def millenium(cls, month, day):     return cls(month, day, 2000)   ensures that the class is not hard-coded but rather learnt. cls can be any subclass. The resulting object will rightly be an instance of cls. Let's test that out.  datetime1 = DateTime(10, 10, 1990) datetime2 = DateTime.millenium(10, 10)  isinstance(datetime1, DateTime) # True isinstance(datetime2, DateTime) # True   datetime1.display() # \"10-10-1990 - 00:00:00PM\" datetime2.display() # \"10-10-2000 - 00:00:00PM\"   The reason is, as you know by now, @classmethod was used instead of @staticmethod     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "207", "A_Content": "  @classmethod means: when this method is called, we pass the class as the first argument instead of the instance of that class (as we normally do with methods). This means you can use the class and its properties inside that method rather than a particular instance.  @staticmethod means:  when this method is called, we don't pass an instance of the class to it (as we normally do with methods). This means you can put a function inside a class but you can't access the instance of that class (this is useful when your method does not use the instance).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "55", "A_Content": "  When to use each  @staticmethod function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It\u2019s definition is immutable via inheritance.   Python does not have to instantiate a bound-method for object. It eases the readability of the code: seeing @staticmethod, we know that the method does not depend on the state of object itself;   @classmethod function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance, can be overridden by subclass. That\u2019s because the first argument for @classmethod function must always be cls (class).   Factory methods, that are used to create an instance for a class using for example some sort of pre-processing.  Static methods calling static methods: if you split a static methods in several static methods, you shouldn't hard-code the class name but use class methods   here is good link to this topic.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "31", "A_Content": "  One would use @classmethod when he/she would want to change the behaviour of the method based on which subclass is calling the method. remember we have a reference to the calling class in a class method.  While using static you would want the behaviour to remain unchanged across subclasses   Example:  class Hero:    @staticmethod   def say_hello():      print(\"Helllo...\")    @classmethod   def say_class_hello(cls):      if(cls.__name__==\"HeroSon\"):         print(\"Hi Kido\")      elif(cls.__name__==\"HeroDaughter\"):         print(\"Hi Princess\")  class HeroSon(Hero):   def say_son_hello(self):      print(\"test  hello\")    class HeroDaughter(Hero):   def say_daughter_hello(self):      print(\"test  hello daughter\")   testson = HeroSon()  testson.say_class_hello() #Output: \"Hi Kido\"  testson.say_hello() #Outputs: \"Helllo...\"  testdaughter = HeroDaughter()  testdaughter.say_class_hello() #Outputs: \"Hi Princess\"  testdaughter.say_hello() #Outputs: \"Helllo...\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "28", "A_Content": "  A little compilation  @staticmethod A way to write a method inside a class without reference to the object it is being called on. So no need to pass implicit argument like self or cls. It is written exactly the same how written outside the class, but it is not of no use in python because if you need to encapsulate a method inside a class since this method needs to be the part of that class @staticmethod is comes handy in that case.  @classmethod It is important when you want to write a factory method and by this custom attribute(s) can be attached in a class. This attribute(s) can be overridden in the inherited class.  A comparison between these two methods can be as below       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "22", "A_Content": "     Meaning of @classmethod and @staticmethod?    A method is a function in an object's namespace, accessible as an attribute. A regular (i.e. instance) method gets the instance (we usually call it self) as the implicit first argument. A class method gets the class (we usually call it cls) as the implicit first argument. A static method gets no implicit first argument (like a regular function).      when should I use them, why should I use them, and how should I use them?   You don't need either decorator. But on the principle that you should minimize the number of arguments to functions (see Clean Coder), they are useful for doing just that.  class Example(object):      def regular_instance_method(self):         \"\"\"A function of an instance has access to every attribute of that          instance, including its class (and its attributes.)         Not accepting at least one argument is a TypeError.         Not understanding the semantics of that argument is a user error.         \"\"\"         return some_function_f(self)      @classmethod     def a_class_method(cls):         \"\"\"A function of a class has access to every attribute of the class.         Not accepting at least one argument is a TypeError.         Not understanding the semantics of that argument is a user error.         \"\"\"         return some_function_g(cls)      @staticmethod     def a_static_method():         \"\"\"A static method has no information about instances or classes         unless explicitly given. It just lives in the class (and thus its          instances') namespace.         \"\"\"         return some_function_h()   For both instance methods and class methods, not accepting at least one argument is a TypeError, but not understanding the semantics of that argument is a user error.  (Define some_function's, e.g.:  some_function_h = some_function_g = some_function_f = lambda x=None: x   and this will work.)  dotted lookups on instances and classes:  A dotted lookup on an instance is performed in this order - we look for:   a data descriptor in the class namespace (like a property) data in the instance __dict__ a non-data descriptor in the class namespace (methods).   Note, a dotted lookup on an instance is invoked like this:  instance = Example() instance.regular_instance_method    and methods are callable attributes:  instance.regular_instance_method()   instance methods  The argument, self, is implicitly given via the dotted lookup.  You must access instance methods from instances of the class.  >>> instance = Example() >>> instance.regular_instance_method() <__main__.Example object at 0x00000000399524E0>   class methods  The argument, cls, is implicitly given via dotted lookup.  You can access this method via an instance or the class (or subclasses).  >>> instance.a_class_method() <class '__main__.Example'> >>> Example.a_class_method() <class '__main__.Example'>   static methods  No arguments are implicitly given. This method works like any function defined (for example) on a modules' namespace, except it can be looked up  >>> print(instance.a_static_method()) None      Again, when should I use them, why should I use them?   Each of these are progressively more restrictive in the information they pass the method versus instance methods.  Use them when you don't need the information.  This makes your functions and methods easier to reason about and to unittest.  Which is easier to reason about?  def function(x, y, z): ...   or  def function(y, z): ...   or   def function(z): ...   The functions with fewer arguments are easier to reason about. They are also easier to unittest.  These are akin to instance, class, and static methods. Keeping in mind that when we have an instance, we also have its class, again, ask yourself, which is easier to reason about?:  def an_instance_method(self, arg, kwarg=None):     cls = type(self)             # Also has the class of instance!     ...  @classmethod def a_class_method(cls, arg, kwarg=None):     ...  @staticmethod def a_static_method(arg, kwarg=None):     ...   Builtin examples  Here are a couple of my favorite builtin examples:  The str.maketrans static method was a function in the string module, but it is much more convenient for it to be accessible from the str namespace.  >>> 'abc'.translate(str.maketrans({'a': 'b'})) 'bbc'   The dict.fromkeys class method returns a new dictionary instantiated from an iterable of keys:  >>> dict.fromkeys('abc') {'a': None, 'c': None, 'b': None}   When subclassed, we see that it gets the class information as a class method, which is very useful:  >>> class MyDict(dict): pass >>> type(MyDict.fromkeys('abc')) <class '__main__.MyDict'>    My advice - Conclusion  Use static methods when you don't need the class or instance arguments, but the function is related to the use of the object, and it is convenient for the function to be in the object's namespace.  Use class methods when you don't need instance information, but need the class information perhaps for its other class or static methods, or perhaps itself as a constructor. (You wouldn't hardcode the class so that subclasses could be used here.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "1", "A_Content": "  I'm a beginner on this site, I have read all above answers, and got the information what I want. However, I don't have the right to upvote.  So I want to get my start on StackOverflow with the answer as I understand it.   @staticmethod doesn't need self or cls as the first parameter of the method @staticmethod and @classmethod wrapped function could be called by instance or class variable @staticmethod decorated function impact some kind 'immutable property' that subclass inheritance can't overwrite its base class function which is wrapped by a @staticmethod decorator.  @classmethod need cls (Class name, you could change the variable name if you want, but it's not advised) as the first parameter of function @classmethod always used by subclass manner, subclass inheritance may change the effect of base class function, i.e. @classmethod wrapped base class function could be overwritten by different subclasses.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "0", "A_Content": "  A slightly different way to think about it that might be useful for someone... A class method is used in a superclass to define how that method should behave when it's called by different child classes. A static method is used when we want to return the same thing regardless of the child class that we are calling.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "0", "A_Content": "  In short, @classmehtod turns a normal method to a factory method.  Let's explore it with an example:  class PythonBook:     def __init__(self, name, author):         self.name = name         self.author = author     def __repr__(self):         return f'Book: {self.name}, Author: {self.author}'   Without a @classmethod,you should labor to creat instances one by one and they are scartted.  book1 = PythonBook('Learning Python', 'Mark Lutz') In [20]: book1 Out[20]: Book: Learning Python, Author: Mark Lutz book2 = PythonBook('Python Think', 'Allen B Dowey') In [22]: book2 Out[22]: Book: Python Think, Author: Allen B Dowey   As for example with @classmethod  class PythonBook:     def __init__(self, name, author):         self.name = name         self.author = author     def __repr__(self):         return f'Book: {self.name}, Author: {self.author}'     @classmethod     def book1(cls):         return cls('Learning Python', 'Mark Lutz')     @classmethod     def book2(cls):         return cls('Python Think', 'Allen B Dowey')   Test it:  In [31]: PythonBook.book1() Out[31]: Book: Learning Python, Author: Mark Lutz In [32]: PythonBook.book2() Out[32]: Book: Python Think, Author: Allen B Dowey   See? Instances are successfully created inside a class definition and they are collected together.  In conclusion, @classmethod decorator convert a conventional method to a factory method,Using classmethods makes it possible to add as many alternative constructors as necessary.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/12179271/meaning-of-classmethod-and-staticmethod-for-beginner", "Language": "Python", "Q_Title": "Meaning of @classmethod and @staticmethod for beginner?", "Q_Votes": "1289", "Q_Content": "    Could someone explain to me the meaning of @classmethod and @staticmethod in python? I need to know the difference and the meaning.   As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?  tl;dr: when should I use them, why should I use them, and how should I use them?  I'm pretty advanced with C++, so using more advanced programming concepts shouldn't be a problem. Feel free giving me a corresponding C++ example if possible.     ", "Tags": ["python", "oop", "static-methods", "class-method"], "A_Votes": "-2", "A_Content": "  Class method can modify the class state,it bound to the class and it contain cls as parameter.  Static method can not modify the class state,it bound to the class and it does't know class or instance  class empDetails:     def __init__(self,name,sal):         self.name=name         self.sal=sal     @classmethod     def increment(cls,name,none):         return cls('yarramsetti',6000 + 500)     @staticmethod     def salChecking(sal):         return sal > 6000  emp1=empDetails('durga prasad',6000) emp2=empDetails.increment('yarramsetti',100) # output is 'durga prasad' print emp1.name # output put is 6000 print emp1.sal # output is 6500,because it change the sal variable print emp2.sal # output is 'yarramsetti' it change the state of name variable print emp2.name # output is True, because ,it change the state of sal variable print empDetails.salChecking(6500)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "1479", "A_Content": "  Assuming module foo with method bar:  import foo method_to_call = getattr(foo, 'bar') result = method_to_call()   As far as that goes, lines 2 and 3 can be compressed to:  result = getattr(foo, 'bar')()   if that makes more sense for your use case.  You can use getattr in this fashion on class instance bound methods, module-level methods, class methods... the list goes on.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "409", "A_Content": "  locals()[\"myfunction\"]()   or  globals()[\"myfunction\"]()   locals returns a dictionary with a current local symbol table. globals returns a dictionary with global symbol table.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "249", "A_Content": "  Patrick's solution is probably the cleanest. If you need to dynamically pick up the module as well, you can import it like:  module = __import__('foo') func = getattr(module, 'bar') func()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "82", "A_Content": "  Just a simple contribution. If the class that we need to instance is in the same file, we can use something like this:  # Get class from globals and create an instance m = globals()['our_class']()  # Get the function (from the instance) that we need to call func = getattr(m, 'function_name')  # Call it func()   For example:  class A:     def __init__(self):         pass      def sampleFunc(self, arg):         print('you called sampleFunc({})'.format(arg))  m = globals()['A']() func = getattr(m, 'sampleFunc') func('sample arg')  # Sample, all on one line getattr(globals()['A'](), 'sampleFunc')('sample arg')   And, if not a class:  def sampleFunc(arg):     print('you called sampleFunc({})'.format(arg))  globals()['sampleFunc']('sample arg')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "66", "A_Content": "  Given a string, with a complete python path to a function, this is how I went about getting the result of said function:  import importlib function_string = 'mypackage.mymodule.myfunc' mod_name, func_name = function_string.rsplit('.',1) mod = importlib.import_module(mod_name) func = getattr(mod, func_name) result = func()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "32", "A_Content": "  The answer (I hope) no one ever wanted  Eval like behavior  getattr(locals().get(\"foo\") or globals().get(\"foo\"), \"bar\")()   Why not add auto-importing  getattr(     locals().get(\"foo\") or      globals().get(\"foo\") or     __import__(\"foo\"),  \"bar\")()   In case we have extra dictionaries we want to check  getattr(next((x for x in (f(\"foo\") for f in                            [locals().get, globals().get,                             self.__dict__.get, __import__])                if x)), \"bar\")()   We need to go deeper  getattr(next((x for x in (f(\"foo\") for f in                ([locals().get, globals().get, self.__dict__.get] +                [d.get for d in (list(dd.values()) for dd in                                  [locals(),globals(),self.__dict__]                                 if isinstance(dd,dict))                 if isinstance(d,dict)] +                 [__import__]))          if x)), \"bar\")()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "28", "A_Content": "  The best answer according to the Python programming FAQ would be:  functions = {'myfoo': foo.bar}  mystring = 'myfoo' if mystring in functions:     functions[mystring]()      The primary advantage of this technique is that the strings do not need to match the names of the functions. This is also the primary technique used to emulate a case construct      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "18", "A_Content": "  For what it's worth, if you needed to pass the function (or class) name and app name as a string, then you could do this:  myFnName  = \"MyFn\" myAppName = \"MyApp\" app = sys.modules[myAppName] fn  = getattr(app,myFnName)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "16", "A_Content": "  none of what was suggested helped me. I did discover this though.  <object>.__getattribute__(<string name>)(<params>)   I am using python 2.66   Hope this helps     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3061/calling-a-function-of-a-module-by-using-its-name-a-string", "Language": "Python", "Q_Title": "Calling a function of a module by using its name (a string)", "Q_Votes": "1220", "Q_Content": "    What is the best way to go about calling a function given a string with the function's name in a Python program.  For example, let's say that I have a module foo, and I have a string whose contents are \"bar\". What is the best way to go about calling foo.bar()?  I need to get the return value of the function, which is why I don't just use eval. I figured out how to do it by using eval to define a temp function that returns the result of that function call, but I'm hoping that there is a more elegant way to do this.     ", "Tags": ["python"], "A_Votes": "15", "A_Content": "  Try this. While this still uses eval, it only uses it to summon the function from the current context. Then, you have the real function to use as you wish.  The main benefit for me from this is that you will get any eval-related errors at the point of summoning the function. Then you will get only the function-related errors when you call.  def say_hello(name):     print 'Hello {}!'.format(name)  # get the function by name method_name = 'say_hello' method = eval(method_name)  # call it like a regular function later args = ['friend'] kwargs = {} method(*args, **kwargs)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "2011", "A_Content": "  Environment variables are accessed through os.environ  import os print(os.environ['HOME'])   Or you can see a list of all the environment variables using:  os.environ   As sometimes you might need to see a complete list!  # using get will return `None` if a key is not present rather than raise a `KeyError` print(os.environ.get('KEY_THAT_MIGHT_EXIST'))  # os.getenv is equivalent, and can also give a default value instead of `None` print(os.getenv('KEY_THAT_MIGHT_EXIST', default_value))   Python default installation on Windows is C:\\Python. If you want to find out while running python you can do:  import sys print(sys.prefix)      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "2139", "A_Content": "  You need to decode the bytes object to produce a string:  >>> b\"abcde\" b'abcde'  # utf-8 is used here because it is a very common encoding, but you # need to use the encoding your data is actually in. >>> b\"abcde\".decode(\"utf-8\")  'abcde'      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "135", "A_Content": "  To check if the key exists (returns True/False)  \"HOME\" in os.environ   or (removed from python 3.x)  os.environ.has_key(\"HOME\")   You can also use get() when printing the key; useful if you want to use a default.     ( for python 2.7.3 )  print os.environ.get('HOME','/home/username/')   where /home/username/ is the default     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "33", "A_Content": "  The original question (first part) was \"how to check environment variables in Python.\"   Here's how to check if $FOO is set:   try:      os.environ[\"FOO\"] except KeyError:     print \"Please set the environment variable FOO\"    sys.exit(1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "21", "A_Content": "  You can access to the environment variables using  import os print os.environ   Try to see the content of PYTHONPATH or PYTHONHOME environment variables, maybe this will be helpful for your second question. However you should clarify it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "13", "A_Content": "  As for the environment variables:  import os print os.environ[\"HOME\"]   I'm afraid you'd have to flesh out your second point a little bit more before a decent answer is possible.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "9", "A_Content": "  import os for a in os.environ:     print('Var: ', a, 'Value: ', os.getenv(a)) print(\"all done\")   That will print all of the environment variables along with their values.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "7", "A_Content": "  If you are planning to use the code in a production web application code, using any web framework like Django/Flask, use projects like envparse,  using it you can read the value as your defined type.  from envparse import env # will read WHITE_LIST=hello,world,hi to white_list = [\"hello\", \"world\", \"hi\"] white_list = env.list(\"WHITE_LIST\", default=[])  # Perfect for reading boolean DEBUG = env.bool(\"DEBUG\", default=False)   NOTE: kennethreitz's autoenv is a recommended tool for making project specific environment variables, please note that those who are using autoenv please keep the .env file private (inaccessible to public)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "5", "A_Content": "  In Python 3:  #!/usr/bin/python3 import os for param in os.environ.keys():     print(\"%s: %s \" % (param, os.environ[param]))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "3", "A_Content": "  Here is a one-line option assuming import os has been done:  for key in os.environ: print(key,':',os.environ[key])   or with formatting:  for key in os.environ: print('{:>30} {:<4} {:}'.format(key,':',os.environ[key]))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "0", "A_Content": "  for os.environ.get:  try:      env_value = os.environ.get(\"key_maybe_not_exist\") except KeyError:     print(\"Not exist environment value for %s\" % \"key_maybe_not_exist\")   or:  if \"key_maybe_not_exist\" in os.environ:     existed_env_value = os.environ[\"key_maybe_not_exist\"]     for os.getenv:  existed_env_value = os.getenv(\"key_maybe_not_exist\")   equivalent to:  existed_env_value = os.getenv(\"key_maybe_not_exist\", default=None)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/4906977/how-do-i-access-environment-variables-from-python", "Language": "Python", "Q_Title": "How do I access environment variables from Python?", "Q_Votes": "1323", "Q_Content": "    I set an environment variable that I want to access in my Python application.  How do I get this value?     ", "Tags": ["python", "environment-variables"], "A_Votes": "-1", "A_Content": "  Actualy may be this away:  import os  for item, value in os.environ.items():     print('{}: {}'.format(item, value))   Or simplely:  for i, j in os.environ.items():     print(i, j)   for view the value in the parameter:  print(os.environ['HOME'])   or  print(os.environ.get('HOME')   to set the value:  os.environ['HOME'] = '/new/value'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "122", "A_Content": "  I think this way is easy:  bytes = [112, 52, 52] \"\".join(map(chr, bytes)) >> p44      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "102", "A_Content": "  You need to decode the byte string and turn it in to a character (unicode) string.   b'hello'.decode(encoding)   or   str(b'hello', encoding)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "58", "A_Content": "  If you don't know the encoding, then to read binary input into string in Python 3 and Python 2 compatible way, use ancient MS-DOS cp437 encoding:  PY3K = sys.version_info >= (3, 0)  lines = [] for line in stream:     if not PY3K:         lines.append(line)     else:         lines.append(line.decode('cp437'))   Because encoding is unknown, expect non-English symbols to translate to characters of cp437 (English chars are not translated, because they match in most single byte encodings and UTF-8).  Decoding arbitrary binary input to UTF-8 is unsafe, because you may get this:  >>> b'\\x00\\x01\\xffsd'.decode('utf-8') Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 2: invalid start byte   The same applies to latin-1, which was popular (default?) for Python 2. See the missing points in Codepage Layout - it is where Python chokes with infamous ordinal not in range.  UPDATE 20150604: There are rumors that Python 3 has surrogateescape error strategy for encoding stuff into binary data without data loss and crashes, but it needs conversion tests [binary] -> [str] -> [binary] to validate both performance and reliability.  UPDATE 20170116: Thanks to comment by Nearoo - there is also a possibility to slash escape all unknown bytes with backslashreplace error handler. That works only for Python 3, so even with this workaround you will still get inconsistent output from different Python versions:  PY3K = sys.version_info >= (3, 0)  lines = [] for line in stream:     if not PY3K:         lines.append(line)     else:         lines.append(line.decode('utf-8', 'backslashreplace'))   See https://docs.python.org/3/howto/unicode.html#python-s-unicode-support for details.  UPDATE 20170119: I decided to implement slash escaping decode that works for both Python 2 and Python 3. It should be slower that cp437 solution, but it should produce identical results on every Python version.  # --- preparation  import codecs  def slashescape(err):     \"\"\" codecs error handler. err is UnicodeDecode instance. return     a tuple with a replacement for the unencodable part of the input     and a position where encoding should continue\"\"\"     #print err, dir(err), err.start, err.end, err.object[:err.start]     thebyte = err.object[err.start:err.end]     repl = u'\\\\x'+hex(ord(thebyte))[2:]     return (repl, err.end)  codecs.register_error('slashescape', slashescape)  # --- processing  stream = [b'\\x80abc']  lines = [] for line in stream:     lines.append(line.decode('utf-8', 'slashescape'))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "35", "A_Content": "  In Python 3, the default encoding is \"utf-8\", so you can use directly:  b'hello'.decode()   which is equivalent to  b'hello'.decode(encoding=\"utf-8\")   On the other hand, in Python 2, encoding defaults to the default string encoding. Thus, you should use:  b'hello'.decode(encoding)   where encoding is the encoding you want.  Note: support for keyword arguments was added in Python 2.7.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "33", "A_Content": "  I think what you actually want is this:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0] >>> command_text = command_stdout.decode(encoding='windows-1252')   Aaron's answer was correct, except that you need to know WHICH encoding to use. And I believe that Windows uses 'windows-1252'. It will only matter if you have some unusual (non-ascii) characters in your content, but then it will make a difference.  By the way, the fact that it DOES matter is the reason that Python moved to using two different types for binary and text data: it can't convert magically between them because it doesn't know the encoding unless you tell it! The only way YOU would know is to read the Windows documentation (or read it here).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "26", "A_Content": "  Set universal_newlines to True, i.e.  command_stdout = Popen(['ls', '-l'], stdout=PIPE, universal_newlines=True).communicate()[0]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "15", "A_Content": "  While @Aaron Maenpaa's answer just works, a user recently asked     Is there any more simply way? 'fhand.read().decode(\"ASCII\")' [...] It's so long!   You can use  command_stdout.decode()   decode() has a standard argument     codecs.decode(obj, encoding='utf-8', errors='strict')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "10", "A_Content": "  To interpret a byte sequence as a text, you have to know the corresponding character encoding:  unicode_text = bytestring.decode(character_encoding)   Example:  >>> b'\\xc2\\xb5'.decode('utf-8') '\u00b5'   ls command may produce output that can't be interpreted as text. File names on Unix may be any sequence of bytes except slash b'/' and zero b'\\0':  >>> open(bytes(range(0x100)).translate(None, b'\\0/'), 'w').close()   Trying to decode such byte soup using utf-8 encoding raises UnicodeDecodeError.  It can be worse. The decoding may fail silently and produce mojibake if you use a wrong incompatible encoding:  >>> '\u2014'.encode('utf-8').decode('cp1252') '\u00e2\u20ac\u201d'   The data is corrupted but your program remains unaware that a failure has occurred.  In general, what character encoding to use is not embedded in the byte sequence itself. You have to communicate this info out-of-band. Some outcomes are more likely than others and therefore chardet module exists that can guess the character encoding. A single Python script may use multiple character encodings in different places.    ls output can be converted to a Python string using os.fsdecode() function that succeeds even for undecodable filenames (it uses sys.getfilesystemencoding() and surrogateescape error handler on Unix):  import os import subprocess  output = os.fsdecode(subprocess.check_output('ls'))   To get the original bytes, you could use os.fsencode().  If you pass universal_newlines=True parameter then subprocess uses locale.getpreferredencoding(False) to decode bytes e.g., it can be cp1252 on Windows.  To decode the byte stream on-the-fly, io.TextIOWrapper() could be used: example.  Different commands may use different character encodings for their output e.g., dir internal command (cmd) may use cp437. To decode its output, you could pass the encoding explicitly (Python 3.6+):  output = subprocess.check_output('dir', shell=True, encoding='cp437')   The filenames may differ from os.listdir() (which uses Windows Unicode API) e.g., '\\xb6' can be substituted with '\\x14'\u2014Python's cp437 codec maps b'\\x14' to control character U+0014 instead of U+00B6 (\u00b6). To support filenames with arbitrary Unicode characters, see  Decode poweshell output possibly containing non-ascii unicode characters into a python string     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "6", "A_Content": "  Since this question is actually asking about subprocess output, you have a more direct approach available since Popen accepts an encoding keyword (in Python 3.6+):  >>> from subprocess import Popen, PIPE >>> text = Popen(['ls', '-l'], stdout=PIPE, encoding='utf-8').communicate()[0] >>> type(text) str >>> print(text) total 0 -rw-r--r-- 1 wim badger 0 May 31 12:45 some_file.txt   The general answer for other users is to decode bytes to text:  >>> b'abcde'.decode() 'abcde'   With no argument, sys.getdefaultencoding() will be used.  If your data is not sys.getdefaultencoding(), then you must specify the encoding explicitly in the decode call:  >>> b'caf\\xe9'.decode('cp1250') 'caf\u00e9'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "572", "A_Content": "     Which, not only is ugly and slow   I'd dispute both.  A regex or other string parsing would be uglier and slower.    I'm not sure that anything much could be faster than the above.  It calls the function and returns.  Try/Catch doesn't introduce much overhead because the most common exception is caught without an extensive search of stack frames.  The issue is that any numeric conversion function has two kinds of results   A number, if the number is valid A status code (e.g., via errno) or exception to show that no valid number could be parsed.   C (as an example) hacks around this a number of ways.  Python lays it out clearly and explicitly.  I think your code for doing this is perfect.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "2176", "A_Content": "  Use random.choice:  import random  foo = ['a', 'b', 'c', 'd', 'e'] print(random.choice(foo))   For cryptographically secure random choices (e.g. for generating a passphrase from a wordlist), use random.SystemRandom class:  import random  foo = ['battery', 'correct', 'horse', 'staple'] secure_random = random.SystemRandom() print(secure_random.choice(foo))      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "1857", "A_Content": "  It may look cleaner using a key instead a cmp:  newlist = sorted(list_to_be_sorted, key=lambda k: k['name'])    or as J.F.Sebastian and others suggested,  from operator import itemgetter newlist = sorted(list_to_be_sorted, key=itemgetter('name'))    For completeness (as pointed out in comments by fitzgeraldsteele), add reverse=True to sort descending  newlist = sorted(l, key=itemgetter('name'), reverse=True)      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "1418", "A_Content": "  Try the method rstrip() (see doc Python 2 and Python 3)  >>> 'test string\\n'.rstrip() 'test string'   Python's rstrip() method strips all kinds of trailing whitespace by default, not just one newline as Perl does with chomp.  >>> 'test string \\n \\r\\n\\n\\r \\n\\n'.rstrip() 'test string'   To strip only newlines:  >>> 'test string \\n \\r\\n\\n\\r \\n\\n'.rstrip('\\n') 'test string \\n \\r\\n\\n\\r '   There are also the methods lstrip() and strip():  >>> s = \"   \\n\\r\\n  \\n  abc   def \\n\\r\\n  \\n  \" >>> s.strip() 'abc   def' >>> s.lstrip() 'abc   def \\n\\r\\n  \\n  ' >>> s.rstrip() '   \\n\\r\\n  \\n  abc   def'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "5", "A_Content": "  If you should get the following by trying decode():  AttributeError: 'str' object has no attribute 'decode'  You can also specify the encoding type straight in a cast:  >>> my_byte_str b'Hello World'  >>> str(my_byte_str, 'utf-8') 'Hello World'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "4", "A_Content": "  I made a function to clean a list  def cleanLists(self, lista):     lista = [x.strip() for x in lista]     lista = [x.replace('\\n', '') for x in lista]     lista = [x.replace('\\b', '') for x in lista]     lista = [x.encode('utf8') for x in lista]     lista = [x.decode('utf8') for x in lista]      return lista      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "2", "A_Content": "  When working with data from Windows systems (with \\r\\n line endings), my answer is  String = Bytes.decode(\"utf-8\").replace(\"\\r\\n\", \"\\n\")   Why? Try this with a multiline Input.txt:  Bytes = open(\"Input.txt\", \"rb\").read() String = Bytes.decode(\"utf-8\") open(\"Output.txt\", \"w\").write(String)   All your line endings will be doubled (to \\r\\r\\n), leading to extra empty lines. Python's text-read functions usually normalize line endings so that strings use only \\n. If you receive binary data from a Windows system, Python does not have a chance to do that. Thus,  Bytes = open(\"Input.txt\", \"rb\").read() String = Bytes.decode(\"utf-8\").replace(\"\\r\\n\", \"\\n\") open(\"Output.txt\", \"w\").write(String)   will replicate your original file.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "1", "A_Content": "  For Python 3,this is a much safer and Pythonic approach to convert from byte to string:  def byte_to_str(bytes_or_str):     if isinstance(bytes_or_str, bytes): #check if its in bytes         print(bytes_or_str.decode('utf-8'))     else:         print(\"Object not of byte type\")  byte_to_str(b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n')   Output:  total 0 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "0", "A_Content": "  def toString(string):         try:         return v.decode(\"utf-8\")     except ValueError:         return string  b = b'97.080.500' s = '97.080.500' print(toString(b)) print(toString(s))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/606191/convert-bytes-to-a-string", "Language": "Python", "Q_Title": "Convert bytes to a string?", "Q_Votes": "1301", "Q_Content": "    I'm using this code to get standard output from an external program:  >>> from subprocess import * >>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]   The communicate() method returns an array of bytes:  >>> command_stdout b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   However, I'd like to work with the output as a normal Python string. So that I could print it like this:  >>> print(command_stdout) -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1 -rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2   I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:  >>> binascii.b2a_qp(command_stdout) b'total 0\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\\n'   Does anybody know how to convert the bytes value back to string? I mean, using the \"batteries\" instead of doing it manually. And I'd like it to be ok with Python 3.     ", "Tags": ["python", "string", "python-3.x"], "A_Votes": "-1", "A_Content": "  From http://docs.python.org/3/library/sys.html,  To write or read binary data from/to the standard streams, use the underlying binary buffer. For example, to write bytes to stdout, use sys.stdout.buffer.write(b'abc').     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "1355", "A_Content": "  In case you are looking for parsing (positive, unsigned) integers instead of floats, you can use the isdigit() function for string objects.  >>> a = \"03523\" >>> a.isdigit() True >>> b = \"963spam\" >>> b.isdigit() False   String Methods - isdigit()  There's also something on Unicode strings, which I'm not too familiar with Unicode - Is decimal/decimal     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "67", "A_Content": "  TL;DR The best solution is s.replace('.','',1).isdigit()  I did some benchmarks comparing the different approaches  def is_number_tryexcept(s):     \"\"\" Returns True is string is a number. \"\"\"     try:         float(s)         return True     except ValueError:         return False  import re     def is_number_regex(s):     \"\"\" Returns True is string is a number. \"\"\"     if re.match(\"^\\d+?\\.\\d+?$\", s) is None:         return s.isdigit()     return True   def is_number_repl_isdigit(s):     \"\"\" Returns True is string is a number. \"\"\"     return s.replace('.','',1).isdigit()   If the string is not a number, the except-block is quite slow. But more importantly, the try-except method is the only approach that handles scientific notations correctly.  funcs = [           is_number_tryexcept,            is_number_regex,           is_number_repl_isdigit           ]  a_float = '.1234'  print('Float notation \".1234\" is not supported by:') for f in funcs:     if not f(a_float):         print('\\t -', f.__name__)   Float notation \".1234\" is not supported by: - is_number_regex    scientific1 = '1.000000e+50' scientific2 = '1e50'   print('Scientific notation \"1.000000e+50\" is not supported by:') for f in funcs:     if not f(scientific1):         print('\\t -', f.__name__)     print('Scientific notation \"1e50\" is not supported by:') for f in funcs:     if not f(scientific2):         print('\\t -', f.__name__)   Scientific notation \"1.000000e+50\" is not supported by: - is_number_regex - is_number_repl_isdigit Scientific notation \"1e50\" is not supported by: - is_number_regex - is_number_repl_isdigit    EDIT: The benchmark results  import timeit  test_cases = ['1.12345', '1.12.345', 'abc12345', '12345'] times_n = {f.__name__:[] for f in funcs}  for t in test_cases:     for f in funcs:         f = f.__name__         times_n[f].append(min(timeit.Timer('%s(t)' %f,                        'from __main__ import %s, t' %f)                               .repeat(repeat=3, number=1000000)))   where the following functions were tested  from re import match as re_match from re import compile as re_compile  def is_number_tryexcept(s):     \"\"\" Returns True is string is a number. \"\"\"     try:         float(s)         return True     except ValueError:         return False  def is_number_regex(s):     \"\"\" Returns True is string is a number. \"\"\"     if re_match(\"^\\d+?\\.\\d+?$\", s) is None:         return s.isdigit()     return True   comp = re_compile(\"^\\d+?\\.\\d+?$\")      def compiled_regex(s):     \"\"\" Returns True is string is a number. \"\"\"     if comp.match(s) is None:         return s.isdigit()     return True   def is_number_repl_isdigit(s):     \"\"\" Returns True is string is a number. \"\"\"     return s.replace('.','',1).isdigit()        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "64", "A_Content": "  There is one exception that you may want to take into account: the string 'NaN'  If you want is_number to return FALSE for 'NaN' this code will not work as Python converts it to its representation of a number that is not a number (talk about identity issues):  >>> float('NaN') nan   Otherwise, I should actually thank you for the piece of code I now use extensively. :)  G.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "52", "A_Content": "  how about this:  '3.14'.replace('.','',1).isdigit()   which will return true only if there is one or no '.' in the string of digits.  '3.14.5'.replace('.','',1).isdigit()   will return false  edit: just saw another comment ... adding a .replace(badstuff,'',maxnum_badstuff) for other cases can be done. if you are passing salt and not arbitrary condiments (ref:xkcd#974) this will do fine :P     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "38", "A_Content": "  Updated after Alfe pointed out you don't need to check for float separately as complex handles both:  def is_number(s):     try:         complex(s) # for int, long, float and complex     except ValueError:         return False      return True     Previously said: Is some rare cases you might also need to check for complex numbers (e.g. 1+2i), which can not be represented by a float:  def is_number(s):     try:         float(s) # for int, long and float     except ValueError:         try:             complex(s) # for complex         except ValueError:             return False      return True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "37", "A_Content": "     Which, not only is ugly and slow, seems clunky.   It may take some getting used to, but this is the pythonic way of doing it.  As has been already pointed out, the alternatives are worse.  But there is one other advantage of doing things this way:  polymorphism.  The central idea behind duck typing is that \"if it walks and talks like a duck, then it's a duck.\"  What if you decide that you need to subclass string so that you can change how you determine if something can be converted into a float?  Or what if you decide to test some other object entirely?  You can do these things without having to change the above code.  Other languages solve these problems by using interfaces.  I'll save the analysis of which solution is better for another thread.  The point, though, is that python is decidedly on the duck typing side of the equation, and you're probably going to have to get used to syntax like this if you plan on doing much programming in Python (but that doesn't mean you have to like it of course).  One other thing you might want to take into consideration: Python is pretty fast in throwing and catching exceptions compared to a lot of other languages (30x faster than .Net for instance).  Heck, the language itself even throws exceptions to communicate non-exceptional, normal program conditions (every time you use a for loop).  Thus, I wouldn't worry too much about the performance aspects of this code until you notice a significant problem.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "19", "A_Content": "  For int use this:  >>> \"1221323\".isdigit() True   But for float we need some tricks ;-). Every float number has one point...  >>> \"12.34\".isdigit() False >>> \"12.34\".replace('.','',1).isdigit() True >>> \"12.3.4\".replace('.','',1).isdigit() False   Also for negative numbers just add lstrip():  >>> '-12'.lstrip('-') '12'   And now we get a universal way:  >>> '-12.34'.lstrip('-').replace('.','',1).isdigit() True >>> '.-234'.lstrip('-').replace('.','',1).isdigit() False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "15", "A_Content": "  For strings of non-numbers, try: except: is actually slower than regular expressions.  For strings of valid numbers, regex is slower.  So, the appropriate method depends on your input.   If you find that you are in a performance bind, you can use a new third-party module called fastnumbers that provides a function called isfloat.  Full disclosure, I am the author.  I have included its results in the timings below.    from __future__ import print_function import timeit  prep_base = '''\\ x = 'invalid' y = '5402' z = '4.754e3' '''  prep_try_method = '''\\ def is_number_try(val):     try:         float(val)         return True     except ValueError:         return False  '''  prep_re_method = '''\\ import re float_match = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?$').match def is_number_re(val):     return bool(float_match(val))  '''  fn_method = '''\\ from fastnumbers import isfloat  '''  print('Try with non-number strings', timeit.timeit('is_number_try(x)',     prep_base + prep_try_method), 'seconds') print('Try with integer strings', timeit.timeit('is_number_try(y)',     prep_base + prep_try_method), 'seconds') print('Try with float strings', timeit.timeit('is_number_try(z)',     prep_base + prep_try_method), 'seconds') print() print('Regex with non-number strings', timeit.timeit('is_number_re(x)',     prep_base + prep_re_method), 'seconds') print('Regex with integer strings', timeit.timeit('is_number_re(y)',     prep_base + prep_re_method), 'seconds') print('Regex with float strings', timeit.timeit('is_number_re(z)',     prep_base + prep_re_method), 'seconds') print() print('fastnumbers with non-number strings', timeit.timeit('isfloat(x)',     prep_base + 'from fastnumbers import isfloat'), 'seconds') print('fastnumbers with integer strings', timeit.timeit('isfloat(y)',     prep_base + 'from fastnumbers import isfloat'), 'seconds') print('fastnumbers with float strings', timeit.timeit('isfloat(z)',     prep_base + 'from fastnumbers import isfloat'), 'seconds') print()     Try with non-number strings 2.39108395576 seconds Try with integer strings 0.375686168671 seconds Try with float strings 0.369210958481 seconds  Regex with non-number strings 0.748660802841 seconds Regex with integer strings 1.02021503448 seconds Regex with float strings 1.08564686775 seconds  fastnumbers with non-number strings 0.174362897873 seconds fastnumbers with integer strings 0.179651021957 seconds fastnumbers with float strings 0.20222902298 seconds   As you can see   try: except: was fast for numeric input but very slow for an invalid input regex is very efficient when the input is invalid fastnumbers wins in both cases      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "14", "A_Content": "  Just Mimic C#  In C# there are two different functions that handle parsing of scalar values:   Float.Parse() Float.TryParse()   float.parse():  def parse(string):     try:         return float(string)     except Exception:         throw TypeError   Note: If you're wondering why I changed the exception to a TypeError, here's the documentation.  float.try_parse():  def try_parse(string, fail=None):     try:         return float(string)     except Exception:         return fail;   Note: You don't want to return the boolean 'False' because that's still a value type. None is better because it indicates failure. Of course, if you want something different you can change the fail parameter to whatever you want.  To extend float to include the 'parse()' and 'try_parse()' you'll need to monkeypatch the 'float' class to add these methods.  If you want respect pre-existing functions the code should be something like:  def monkey_patch():     if(!hasattr(float, 'parse')):         float.parse = parse     if(!hasattr(float, 'try_parse')):         float.try_parse = try_parse   SideNote: I personally prefer to call it Monkey Punching because it feels like I'm abusing the language when I do this but YMMV.  Usage:  float.parse('giggity') // throws TypeException float.parse('54.3') // returns the scalar value 54.3 float.tryParse('twank') // returns None float.tryParse('32.2') // returns the scalar value 32.2   And the great Sage Pythonas said to the Holy See Sharpisus, \"Anything you can do I can do better; I can do anything better than you.\"     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "13", "A_Content": "  I know this is particularly old but I would add an answer I believe covers the information missing from the highest voted answer that could be very valuable to any who find this:  For each of the following methods connect them with a count if you need any input to be accepted. (Assuming we are using vocal definitions of integers rather than 0-255, etc.)  x.isdigit() works well for checking if x is an integer.  x.replace('-','').isdigit() works well for checking if x is a negative.(Check - in first position)  x.replace('.','').isdigit() works well for checking if x is a decimal.  x.replace(':','').isdigit() works well for checking if x is a ratio.  x.replace('/','',1).isdigit() works well for checking if x is a fraction.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "10", "A_Content": "  Casting to float and catching ValueError is probably the fastest way, since float() is specifically meant for just that. Anything else that requires string parsing (regex, etc) will likely be slower due to the fact that it's not tuned for this operation. My $0.02.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "10", "A_Content": "  You can use Unicode strings, they have a method to do just what you want:  >>> s = u\"345\" >>> s.isnumeric() True   Or:  >>> s = \"345\" >>> u = unicode(s) >>> u.isnumeric() True   http://www.tutorialspoint.com/python/string_isnumeric.htm  http://docs.python.org/2/howto/unicode.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "8", "A_Content": "  Lets say you have digits in string. str = \"100949\" and you would like to check if it has only numbers  if str.isdigit(): returns TRUE or FALSE    isdigit docs  otherwise your method works great to find the occurrence of a digit in a string.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "8", "A_Content": "  This answer provides step by step guide having function with examples to find the string is:   Positive integer Positive/negative - integer/float How to discard \"NaN\" (not a number) strings while checking for number?   Check if string is positive integer  You may use str.isdigit() to check whether given string is positive integer.   Sample Results:  # For digit >>> '1'.isdigit() True >>> '1'.isalpha() False   Check for string as positive/negative - integer/float  str.isdigit() returns False if the string is a negative number or a float number. For example:  # returns `False` for float >>> '123.3'.isdigit() False # returns `False` for negative number >>> '-123'.isdigit() False   If you want to also check for the negative integers and float, then you may write a custom function to check for it as:  def is_number(n):     try:         float(n)   # Type-casting the string to `float`.                    # If string is not a valid `float`,                     # it'll raise `ValueError` exception     except ValueError:         return False     return True   Sample Run:  >>> is_number('123')    # positive integer number True  >>> is_number('123.4')  # positive float number True  >>> is_number('-123')   # negative integer number True  >>> is_number('-123.4') # negative `float` number True  >>> is_number('abc')    # `False` for \"some random\" string False   Discard \"NaN\" (not a number) strings while checking for number  The above functions will return True for the \"NAN\" (Not a number) string because for Python it is valid float representing it is not a number. For example:  >>> is_number('NaN') True   In order to check whether the number is \"NaN\", you may use math.isnan() as:  >>> import math >>> nan_num = float('nan')  >>> math.isnan(nan_num) True   Or if you don't want to import additional library to check this, then you may simply check it via comparing it with itself using ==. Python returns False when nan float is compared with itself. For example:  # `nan_num` variable is taken from above example >>> nan_num == nan_num False   Hence, above function is_number can be updated to return False for \"NaN\" as:  def is_number(n):     is_number = True     try:         num = float(n)         # check for \"nan\" floats         is_number = num == num   # or use `math.isnan(num)`     except ValueError:         is_number = False     return is_number   Sample Run:  >>> is_number('Nan')   # not a number \"Nan\" string False  >>> is_number('nan')   # not a number string \"nan\" with all lower cased False  >>> is_number('123')   # positive integer True  >>> is_number('-123')  # negative integer True  >>> is_number('-1.12') # negative `float` True  >>> is_number('abc')   # \"some random\" string False   PS: Each operation for each check depending on the type of number comes with additional overhead. Choose the version of is_number function which fits your requirement.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "130", "A_Content": "  If you also need the index, use random.randrange  from random import randrange random_index = randrange(len(foo)) print(foo[random_index])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "115", "A_Content": "  If you want to randomly select more than one item from a list, or select an item from a set, I'd recommend using random.sample instead.  import random group_of_items = {1, 2, 3, 4}               # a sequence or set will work here. num_to_select = 2                           # set the number to select here. list_of_random_items = random.sample(group_of_items, num_to_select) first_random_item = list_of_random_items[0] second_random_item = list_of_random_items[1]    If you're only pulling a single item from a list though, choice is less clunky, as using sample would have the syntax random.sample(some_list, 1)[0] instead of random.choice(some_list).  Unfortunately though, choice only works for a single output from sequences (such as lists or tuples).  Though random.choice(tuple(some_set)) may be an option for getting a single item from a set.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "28", "A_Content": "  As of Python 3.6 you can use the secrets module, which is preferable to the random module for cryptography or security uses.  To print a random element from a list:  import secrets foo = ['a', 'b', 'c', 'd', 'e'] print(secrets.choice(foo))   To print a random index:  print(secrets.randbelow(len(foo)))   For details, see PEP 506.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "27", "A_Content": "  I propose a script for removing randomly picked up items off a list until it is empty:  Maintain a set and remove randomly picked up element (with choice) until list is empty.  s=set(range(1,6)) import random  while len(s)>0:   s.remove(random.choice(list(s)))   print(s)   Three runs give three different answers:  >>>  set([1, 3, 4, 5]) set([3, 4, 5]) set([3, 4]) set([4]) set([]) >>>  set([1, 2, 3, 5]) set([2, 3, 5]) set([2, 3]) set([2]) set([])  >>>  set([1, 2, 3, 5]) set([1, 2, 3]) set([1, 2]) set([1]) set([])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "7", "A_Content": "  This is the code with a variable that defines the random index:  import random  foo = ['a', 'b', 'c', 'd', 'e'] randomindex = random.randint(0,len(foo)-1)  print (foo[randomindex]) ## print (randomindex)   This is the code without the variable:  import random  foo = ['a', 'b', 'c', 'd', 'e'] print (foo[random.randint(0,len(foo)-1)])   And this is the code in the shortest and smartest way to do it:  import random  foo = ['a', 'b', 'c', 'd', 'e'] print(random.choice(foo))   (python 2.7)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "7", "A_Content": "  foo = ['a', 'b', 'c', 'd', 'e'] number_of_samples = 1   In python 2:   random_items = random.sample(population=foo, k=number_of_samples)   In python 3:  random_items = random.choices(population=foo, k=number_of_samples)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "6", "A_Content": "  if you need the index just use:  import random foo = ['a', 'b', 'c', 'd', 'e'] print int(random.random() * len(foo)) print foo[int(random.random() * len(foo))]   random.choice does the same:)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "5", "A_Content": "     How to randomly select an item from a list?      Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']         What is the simplest way to retrieve an item at random from this list?   If you want close to truly random, then I suggest using a SystemRandom object from the random module with the choice method:  >>> import random >>> sr = random.SystemRandom() >>> foo = list('abcde') >>> foo ['a', 'b', 'c', 'd', 'e']   And now:  >>> sr.choice(foo) 'd' >>> sr.choice(foo) 'e' >>> sr.choice(foo) 'a' >>> sr.choice(foo) 'b' >>> sr.choice(foo) 'a' >>> sr.choice(foo) 'c' >>> sr.choice(foo) 'c'   If you want a deterministic pseudorandom selection, use the choice function (which is actually a bound method on a Random object):  >>> random.choice <bound method Random.choice of <random.Random object at 0x800c1034>>   It seems random, but it's actually not, which we can see if we reseed it repeatedly:  >>> random.seed(42); random.choice(foo), random.choice(foo), random.choice(foo) ('d', 'a', 'b') >>> random.seed(42); random.choice(foo), random.choice(foo), random.choice(foo) ('d', 'a', 'b') >>> random.seed(42); random.choice(foo), random.choice(foo), random.choice(foo) ('d', 'a', 'b') >>> random.seed(42); random.choice(foo), random.choice(foo), random.choice(foo) ('d', 'a', 'b') >>> random.seed(42); random.choice(foo), random.choice(foo), random.choice(foo) ('d', 'a', 'b')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "3", "A_Content": "  We can also do this using randint.  from random import randint l= ['a','b','c']  def get_rand_element(l):     if l:         return l[randint(0,len(l)-1)]     else:         return None  get_rand_element(l)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "2", "A_Content": "  numpy solution: numpy.random.choice  For this question, it works the same as the accepted answer (import random; random.choice()), but I added it because the programmer may have imported numpy already (like me) & also there are some differences between the two methods that may concern your actual use case.  import numpy as np     np.random.choice(foo) # randomly selects a single item   For reproducibility, you can do:  np.random.seed(123) np.random.choice(foo) # first call will always return 'c'   For samples of one or more items, returned as an array, pass the size argument:  np.random.choice(foo, 5)          # sample with replacement (default) np.random.choice(foo, 5, False)   # sample without replacement      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/306400/how-to-randomly-select-an-item-from-a-list", "Language": "Python", "Q_Title": "How to randomly select an item from a list?", "Q_Votes": "1339", "Q_Content": "    Assume I have the following list:  foo = ['a', 'b', 'c', 'd', 'e']   What is the simplest way to retrieve an item at random from this list?     ", "Tags": ["python", "list", "random"], "A_Votes": "0", "A_Content": "  The easiest way to do it is like this:  import random     foo = ['a', 'b', 'c', 'd', 'e'] print(random.choice(foo))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "112", "A_Content": "  import operator   To sort the list of dictionaries by key='name':  list_of_dicts.sort(key=operator.itemgetter('name'))   To sort the list of dictionaries by key='age':  list_of_dicts.sort(key=operator.itemgetter('age'))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "40", "A_Content": "  If you want to sort the list by multiple keys you can do the following:  my_list = [{'name':'Homer', 'age':39}, {'name':'Milhouse', 'age':10}, {'name':'Bart', 'age':10} ] sortedlist = sorted(my_list , key=lambda elem: \"%02d %s\" % (elem['age'], elem['name']))   It is rather hackish, since it relies on converting the values into a single string representation for comparison, but it works as expected for numbers including negative ones (although you will need to format your string appropriately with zero paddings if you are using numbers)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "28", "A_Content": "  my_list = [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]  my_list.sort(lambda x,y : cmp(x['name'], y['name']))   my_list will now be what you want.  (3 years later) Edited to add:  The new key argument is more efficient and neater.  A better answer now looks like:  my_list = sorted(my_list, key=lambda k: k['name'])   ...the lambda is, IMO, easier to understand than operator.itemgetter, but YMMV.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "20", "A_Content": "  import operator a_list_of_dicts.sort(key=operator.itemgetter('name'))   'key' is used to sort by an arbitrary value and 'itemgetter' sets that value to each item's 'name' attribute.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "14", "A_Content": "  I guess you've meant:  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   This would be sorted like this:  sorted(l,cmp=lambda x,y: cmp(x['name'],y['name']))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "13", "A_Content": "  Using Schwartzian transform from Perl,  py = [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   do  sort_on = \"name\" decorated = [(dict_[sort_on], dict_) for dict_ in py] decorated.sort() result = [dict_ for (key, dict_) in decorated]   gives  >>> result [{'age': 10, 'name': 'Bart'}, {'age': 39, 'name': 'Homer'}]   More on Perl Schwartzian transform     In computer science, the Schwartzian transform is a Perl programming   idiom used to improve the efficiency of sorting a list of items. This   idiom is appropriate for comparison-based sorting when the ordering is   actually based on the ordering of a certain property (the key) of the   elements, where computing that property is an intensive operation that   should be performed a minimal number of times. The Schwartzian   Transform is notable in that it does not use named temporary arrays.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "12", "A_Content": "  You could use a custom comparison function, or you could pass in a function that calculates a custom sort key. That's usually more efficient as the key is only calculated once per item, while the comparison function would be called many more times.  You could do it this way:  def mykey(adict): return adict['name'] x = [{'name': 'Homer', 'age': 39}, {'name': 'Bart', 'age':10}] sorted(x, key=mykey)   But the standard library contains a generic routine for getting items of arbitrary objects: itemgetter. So try this instead:  from operator import itemgetter x = [{'name': 'Homer', 'age': 39}, {'name': 'Bart', 'age':10}] sorted(x, key=itemgetter('name'))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "11", "A_Content": "  You have to implement your own comparison function that will compare the dictionaries by values of name keys. See Sorting Mini-HOW TO from PythonInfo Wiki     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "10", "A_Content": "  a = [{'name':'Homer', 'age':39}, ...]  # This changes the list a a.sort(key=lambda k : k['name'])  # This returns a new list (a is not modified) sorted(a, key=lambda k : k['name'])       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "6", "A_Content": "  I tried something like this:  my_list.sort(key=lambda x: x['name'])   It worked for integers as well.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "5", "A_Content": "  Here is the alternative general solution - it sorts elements of dict by keys and values. The advantage of it - no need to specify keys, and it would still work if some keys are missing in some of dictionaries.  def sort_key_func(item):     \"\"\" helper function used to sort list of dicts      :param item: dict     :return: sorted list of tuples (k, v)     \"\"\"     pairs = []     for k, v in item.items():         pairs.append((k, v))     return sorted(pairs) sorted(A, key=sort_key_func)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "4", "A_Content": "  Using the pandas package is another method, though it's runtime at large scale is much slower than the more traditional methods proposed by others:  import pandas as pd  listOfDicts = [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}] df = pd.DataFrame(listOfDicts) df = df.sort_values('name') sorted_listOfDicts = df.T.to_dict().values()   Here are some benchmark values for a tiny list and a large (100k+) list of dicts:  setup_large = \"listOfDicts = [];\\ [listOfDicts.extend(({'name':'Homer', 'age':39}, {'name':'Bart', 'age':10})) for _ in range(50000)];\\ from operator import itemgetter;import pandas as pd;\\ df = pd.DataFrame(listOfDicts);\"  setup_small = \"listOfDicts = [];\\ listOfDicts.extend(({'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}));\\ from operator import itemgetter;import pandas as pd;\\ df = pd.DataFrame(listOfDicts);\"  method1 = \"newlist = sorted(listOfDicts, key=lambda k: k['name'])\" method2 = \"newlist = sorted(listOfDicts, key=itemgetter('name')) \" method3 = \"df = df.sort_values('name');\\ sorted_listOfDicts = df.T.to_dict().values()\"  import timeit t = timeit.Timer(method1, setup_small) print('Small Method LC: ' + str(t.timeit(100))) t = timeit.Timer(method2, setup_small) print('Small Method LC2: ' + str(t.timeit(100))) t = timeit.Timer(method3, setup_small) print('Small Method Pandas: ' + str(t.timeit(100)))  t = timeit.Timer(method1, setup_large) print('Large Method LC: ' + str(t.timeit(100))) t = timeit.Timer(method2, setup_large) print('Large Method LC2: ' + str(t.timeit(100))) t = timeit.Timer(method3, setup_large) print('Large Method Pandas: ' + str(t.timeit(1)))  #Small Method LC: 0.000163078308105 #Small Method LC2: 0.000134944915771 #Small Method Pandas: 0.0712950229645 #Large Method LC: 0.0321750640869 #Large Method LC2: 0.0206089019775 #Large Method Pandas: 5.81405615807      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "4", "A_Content": "  sometime we need to use lower() for example  lists = [{'name':'Homer', 'age':39},   {'name':'Bart', 'age':10},   {'name':'abby', 'age':9}]  lists = sorted(lists, key=lambda k: k['name']) print(lists) # [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}, {'name':'abby', 'age':9}]  lists = sorted(lists, key=lambda k: k['name'].lower()) print(lists) # [ {'name':'abby', 'age':9}, {'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "3", "A_Content": "  Lets Say I h'v a Dictionary D with elements below. To sort just use key argument in sorted to pass custom function as below  D = {'eggs': 3, 'ham': 1, 'spam': 2}  def get_count(tuple):     return tuple[1]  sorted(D.items(), key = get_count, reverse=True) or sorted(D.items(), key = lambda x: x[1], reverse=True)  avoiding get_count function call   https://wiki.python.org/moin/HowTo/Sorting/#Key_Functions     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "2", "A_Content": "  Here is my answer to a related question on sorting by multiple columns. It also works for the degenerate case where the number of columns is only one.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary-in-python", "Language": "Python", "Q_Title": "How do I sort a list of dictionaries by a value of the dictionary in Python?", "Q_Votes": "1378", "Q_Content": "    I got a list of dictionaries and want that to be sorted by a value of that dictionary.  This  [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]   sorted by name, should become  [{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]      ", "Tags": ["python", "list", "sorting", "dictionary", "data-structures"], "A_Votes": "0", "A_Content": "  If you do not need the original list of dictionaries, you could modify it in-place with sort() method using a custom key function.  Key function:  def get_name(d):     \"\"\" Return the value of a key in a dictionary. \"\"\"      return d[\"name\"]   The list to be sorted:  data_one = [{'name': 'Homer', 'age': 39}, {'name': 'Bart', 'age': 10}]   Sorting it in-place:  data_one.sort(key=get_name)   If you need the original list, call the sorted() function passing it the list and the key function, then assign the returned sorted list to a new variable:  data_two = [{'name': 'Homer', 'age': 39}, {'name': 'Bart', 'age': 10}] new_data = sorted(data_two, key=get_name)   Printing data_one and new_data.  >>> print(data_one) [{'name': 'Bart', 'age': 10}, {'name': 'Homer', 'age': 39}] >>> print(new_data) [{'name': 'Bart', 'age': 10}, {'name': 'Homer', 'age': 39}]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "139", "A_Content": "  And I would say the \"pythonic\" way to get lines without trailing newline characters is splitlines().  >>> text = \"line 1\\nline 2\\r\\nline 3\\nline 4\" >>> text.splitlines() ['line 1', 'line 2', 'line 3', 'line 4']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "128", "A_Content": "  The canonical way to strip end-of-line (EOL) characters is to use the string rstrip() method removing any trailing \\r or \\n.  Here are examples for Mac, Windows, and Unix EOL characters.  >>> 'Mac EOL\\r'.rstrip('\\r\\n') 'Mac EOL' >>> 'Windows EOL\\r\\n'.rstrip('\\r\\n') 'Windows EOL' >>> 'Unix EOL\\n'.rstrip('\\r\\n') 'Unix EOL'   Using '\\r\\n' as the parameter to rstrip means that it will strip out any trailing combination of '\\r' or '\\n'.  That's why it works in all three cases above.  This nuance matters in rare cases.  For example, I once had to process a text file which contained an HL7 message.  The HL7 standard requires a trailing '\\r' as its EOL character.  The Windows machine on which I was using this message had appended its own '\\r\\n' EOL character.  Therefore, the end of each line looked like '\\r\\r\\n'.  Using rstrip('\\r\\n') would have taken off the entire '\\r\\r\\n' which is not what I wanted.  In that case, I simply sliced off the last two characters instead.  Note that unlike Perl's chomp function, this will strip all specified characters at the end of the string, not just one:  >>> \"Hello\\n\\n\\n\".rstrip(\"\\n\") \"Hello\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "96", "A_Content": "  Note that rstrip doesn't act exactly like Perl's chomp() because it doesn't modify the string. That is, in Perl:  $x=\"a\\n\";  chomp $x   results in $x being \"a\".  but in Python:  x=\"a\\n\"  x.rstrip()   will mean that the value of x is still \"a\\n\". Even x=x.rstrip() doesn't always give the same result, as it strips all whitespace from the end of the string, not just one newline at most.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "46", "A_Content": "  I might use something like this:  import os s = s.rstrip(os.linesep)   I think the problem with rstrip(\"\\n\") is that you'll probably want to make sure the line separator is portable. (some antiquated systems are rumored to use \"\\r\\n\"). The other gotcha is that rstrip will strip out repeated whitespace. Hopefully os.linesep will contain the right characters. the above works for me.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "37", "A_Content": "  You may use line = line.rstrip('\\n'). This will strip all newlines from the end of the string, not just one.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "28", "A_Content": "  s = s.rstrip()   will remove all newlines at the end of the string s. The assignment is needed because rstrip returns a new string instead of modifying the original string.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "23", "A_Content": "  \"line 1\\nline 2\\r\\n...\".replace('\\n', '').replace('\\r', '') >>> 'line 1line 2...'   or you could always get geekier with regexps :)  have fun!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "19", "A_Content": "  you can use strip:  line = line.strip()   demo:  >>> \"\\n\\n hello world \\n\\n\".strip() 'hello world'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "18", "A_Content": "  Careful with \"foo\".rstrip(os.linesep): That will only chomp the newline characters for the platform where your Python is being executed. Imagine you're chimping the lines of a Windows file under Linux, for instance:  $ python Python 2.7.1 (r271:86832, Mar 18 2011, 09:09:48)  [GCC 4.5.0 20100604 [gcc-4_5-branch revision 160292]] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import os, sys >>> sys.platform 'linux2' >>> \"foo\\r\\n\".rstrip(os.linesep) 'foo\\r' >>>   Use \"foo\".rstrip(\"\\r\\n\") instead, as Mike says above.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "18", "A_Content": "  An example in Python's documentation simply uses line.strip().  Perl's chomp function removes one linebreak sequence from the end of a string only if it's actually there.  Here is how I plan to do that in Python, if process is conceptually the function that I need in order to do something useful to each line from this file:  import os sep_pos = -len(os.linesep) with open(\"file.txt\") as f:     for line in f:         if line[sep_pos:] == os.linesep:             line = line[:sep_pos]         process(line)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "16", "A_Content": "  This would replicate exactly perl's chomp (minus behavior on arrays) for \"\\n\" line terminator:  def chomp(x):     if x.endswith(\"\\r\\n\"): return x[:-2]     if x.endswith(\"\\n\") or x.endswith(\"\\r\"): return x[:-1]     return x   (Note: it does not modify string 'in place'; it does not strip extra trailing whitespace; takes \\r\\n in account)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "15", "A_Content": "  rstrip doesn't do the same thing as chomp, on so many levels. Read http://perldoc.perl.org/functions/chomp.html and see that chomp is very complex indeed.  However, my main point is that chomp removes at most 1 line ending, whereas rstrip will remove as many as it can.  Here you can see rstrip removing all the newlines:  >>> 'foo\\n\\n'.rstrip(os.linesep) 'foo'   A much closer approximation of typical Perl chomp usage can be accomplished with re.sub, like this:  >>> re.sub(os.linesep + r'\\Z','','foo\\n\\n') 'foo\\n'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "13", "A_Content": "  I don't program in Python, but I came across an FAQ at python.org advocating S.rstrip(\"\\r\\n\") for python 2.2 or later.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "9", "A_Content": "  import re  r_unwanted = re.compile(\"[\\n\\t\\r]\") r_unwanted.sub(\"\", your_text)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "7", "A_Content": "  workaround solution for special case:  if the newline character is the last character (as is the case with most file inputs), then for any element in the collection you can index as follows:   foobar= foobar[:-1]   to slice out your newline character.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "7", "A_Content": "  If your question is to clean up all the line breaks in a multiple line str object (oldstr), you can split it into a list according to the delimiter '\\n' and then join this list into a new str(newstr).  newstr = \"\".join(oldstr.split('\\n'))         ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "5", "A_Content": "  I find it convenient to have be able to get the chomped lines via in iterator, parallel to the way you can get the un-chomped lines from a file object. You can do so with the following code:  def chomped_lines(it):     return map(operator.methodcaller('rstrip', '\\r\\n'), it)   Sample usage:  with open(\"file.txt\") as infile:     for line in chomped_lines(infile):         process(line)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "3", "A_Content": "  Just use :   line = line.rstrip(\"\\n\")   or  line = line.strip(\"\\n\")   You don't need any of this complicated stuff     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "7", "A_Content": "  I wanted to see which method is fastest. Overall the best and most consistent results were given by the check_replace function. The fastest results were given by the check_exception function, but only if there was no exception fired - meaning its code is the most efficient, but the overhead of throwing an exception is quite large.  Please note that checking for a successful cast is the only method which is accurate, for example, this works with check_exception but the other two test functions will return False for a valid float:  huge_number = float('1e+100')   Here is the benchmark code:  import time, re, random, string  ITERATIONS = 10000000  class Timer:         def __enter__(self):         self.start = time.clock()         return self     def __exit__(self, *args):         self.end = time.clock()         self.interval = self.end - self.start  def check_regexp(x):     return re.compile(\"^\\d*\\.?\\d*$\").match(x) is not None  def check_replace(x):     return x.replace('.','',1).isdigit()  def check_exception(s):     try:         float(s)         return True     except ValueError:         return False  to_check = [check_regexp, check_replace, check_exception]  print('preparing data...') good_numbers = [     str(random.random() / random.random())      for x in range(ITERATIONS)]  bad_numbers = ['.' + x for x in good_numbers]  strings = [     ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(random.randint(1,10)))     for x in range(ITERATIONS)]  print('running test...') for func in to_check:     with Timer() as t:         for x in good_numbers:             res = func(x)     print('%s with good floats: %s' % (func.__name__, t.interval))     with Timer() as t:         for x in bad_numbers:             res = func(x)     print('%s with bad floats: %s' % (func.__name__, t.interval))     with Timer() as t:         for x in strings:             res = func(x)     print('%s with strings: %s' % (func.__name__, t.interval))   Here are the results with Python 2.7.10 on a 2017 MacBook Pro 13:  check_regexp with good floats: 12.688639 check_regexp with bad floats: 11.624862 check_regexp with strings: 11.349414 check_replace with good floats: 4.419841 check_replace with bad floats: 4.294909 check_replace with strings: 4.086358 check_exception with good floats: 3.276668 check_exception with bad floats: 13.843092 check_exception with strings: 15.786169   Here are the results with Python 3.6.5 on a 2017 MacBook Pro 13:  check_regexp with good floats: 13.472906000000009 check_regexp with bad floats: 12.977665000000016 check_regexp with strings: 12.417542999999995 check_replace with good floats: 6.011045999999993 check_replace with bad floats: 4.849356 check_replace with strings: 4.282754000000011 check_exception with good floats: 6.039081999999979 check_exception with bad floats: 9.322753000000006 check_exception with strings: 9.952595000000002   Here are the results with PyPy 2.7.13 on a 2017 MacBook Pro 13:  check_regexp with good floats: 2.693217 check_regexp with bad floats: 2.744819 check_regexp with strings: 2.532414 check_replace with good floats: 0.604367 check_replace with bad floats: 0.538169 check_replace with strings: 0.598664 check_exception with good floats: 1.944103 check_exception with bad floats: 2.449182 check_exception with strings: 2.200056      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "6", "A_Content": "  So to put it all together, checking for Nan, infinity and complex numbers (it would seem they are specified with j, not i, i.e. 1+2j) it results in:  def is_number(s):     try:         n=str(float(s))         if n == \"nan\" or n==\"inf\" or n==\"-inf\" : return False     except ValueError:         try:             complex(s) # for complex         except ValueError:             return False     return True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "5", "A_Content": "  Your code looks fine to me.  Perhaps you think the code is \"clunky\" because of using exceptions?  Note that Python programmers tend to use exceptions liberally when it improves code readability, thanks to its low performance penalty.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "4", "A_Content": "  I did some speed test. Lets say that if the string is likely to be a number the try/except strategy is the fastest possible.If the string is not likely to be a number and you are interested in Integer check, it worths to do some test (isdigit plus heading '-').  If you are interested to check float number, you have to use the try/except code whitout escape.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "4", "A_Content": "  I needed to determine if a string cast into basic types (float,int,str,bool). After not finding anything on the internet I created this:  def str_to_type (s):     \"\"\" Get possible cast type for a string      Parameters     ----------     s : string      Returns     -------     float,int,str,bool : type         Depending on what it can be cast to      \"\"\"         try:                         f = float(s)                 if \".\" not in s:             return int         return float     except ValueError:         value = s.upper()         if value == \"TRUE\" or value == \"FALSE\":             return bool         return type(s)   Example  str_to_type(\"true\") # bool str_to_type(\"6.0\") # float str_to_type(\"6\") # int str_to_type(\"6abc\") # str str_to_type(u\"6abc\") # unicode          You can capture the type and use it   s = \"6.0\" type_ = str_to_type(s) # float f = type_(s)       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "3", "A_Content": "  RyanN suggests     If you want to return False for a NaN and Inf, change line to x = float(s); return (x == x) and (x - 1 != x). This should return True for all floats except Inf and NaN   But this doesn't quite work, because for sufficiently large floats, x-1 == x returns true. For example, 2.0**54 - 1 == 2.0**54     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "1", "A_Content": "  If you want to know if the entire string can be represented as a number you'll want to use a regexp (or maybe convert the float back to a string and compare it to the source string, but I'm guessing that's not very fast).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "1", "A_Content": "  Here's my simple way of doing it. Let's say that I'm looping through some strings and I want to add them to an array if they turn out to be numbers.  try:     myvar.append( float(string_to_check) ) except:     continue   Replace the myvar.apppend with whatever operation you want to do with the string if it turns out to be a number. The idea is to try to use a float() operation and use the returned error to determine whether or not the string is a number.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "1", "A_Content": "  I was working on a problem that led me to this thread, namely how to convert a collection of data to strings and numbers in the most intuitive way.  I realized after reading the original code that what I needed was different in two ways:  1 - I wanted an integer result if the string represented an integer  2 - I wanted a number or a string result to stick into a data structure  so I adapted the original code to produce this derivative:  def string_or_number(s):     try:         z = int(s)         return z     except ValueError:         try:             z = float(s)             return z         except ValueError:             return s      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "1", "A_Content": "  Try this.   def is_number(var):     try:        if var == int(var):             return True     except Exception:         return False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "1", "A_Content": "  You may use regex.  number = raw_input(\"Enter a number: \") if re.match(r'^\\d+$', number):     print \"It's integer\"     print int(number) elif re.match(r'^\\d+\\.\\d+$', number):     print \"It's float\"     print float(number) else:     print(\"Please enter a number\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "1", "A_Content": "  I also used the function you mentioned, but soon I notice that strings as \"Nan\", \"Inf\" and it's variation are considered as number. So I propose you improved version of your function, that will return false on those type of input and will not fail \"1e3\" variants:  def is_float(text):     try:         float(text)         # check for nan/infinity etc.         if text.isalpha():             return False         return True     except ValueError:         return False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "0", "A_Content": "  You can generalize the exception technique in a useful way by returning more useful values than True and False.  For example this function puts quotes round strings but leaves numbers alone.  Which is just what I needed for a quick and dirty filter to make some variable definitions for R.   import sys  def fix_quotes(s):     try:         float(s)         return s     except ValueError:         return '\"{0}\"'.format(s)  for line in sys.stdin:     input = line.split()     print input[0], '<- c(', ','.join(fix_quotes(c) for c in input[1:]), ')'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "0", "A_Content": "  To check if the input value is a float, you can compare the type of the input to a float  def isFloat(s):     realFloat = 0.1      if type(s) == type(realFloat):         return True     else:         return False   Returns:  False     # s = 5 True      # s = 1.2345   The original post would actually return True for s = 5 since it is a number (integer) and you can cast an int to a float without a ValueError. If you are trying to verify that it is an actual float instead of just a number, you would need to account for that case.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float", "Language": "Python", "Q_Title": "How do I check if a string is a number (float)?", "Q_Votes": "1269", "Q_Content": "    What is the best possible way to check if a string can be represented as a number in Python?   The function I currently have right now is:  def is_number(s):     try:         float(s)         return True     except ValueError:         return False   Which, not only is ugly and slow, seems clunky. However I haven't found a better method because calling float in the main function is even worse.      ", "Tags": ["python", "casting", "floating-point", "type-conversion"], "A_Votes": "0", "A_Content": "  use following it handles all cases:-  import re a=re.match('((\\d+[\\.]\\d*$)|(\\.)\\d+$)' ,  '2.3')  a=re.match('((\\d+[\\.]\\d*$)|(\\.)\\d+$)' ,  '2.') a=re.match('((\\d+[\\.]\\d*$)|(\\.)\\d+$)' ,  '.3') a=re.match('((\\d+[\\.]\\d*$)|(\\.)\\d+$)' ,  '2.3sd') a=re.match('((\\d+[\\.]\\d*$)|(\\.)\\d+$)' ,  '2.3')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/30081275/why-is-1000000000000000-in-range1000000000000001-so-fast-in-python-3", "Language": "Python", "Q_Title": "Why is \u201c1000000000000000 in range(1000000000000001)\u201d so fast in Python 3?", "Q_Votes": "1408", "Q_Content": "    It is my understanding that the range() function, which is actually an object type in Python 3, generates its contents on the fly, similar to a generator.   This being the case, I would have expected the following line to take an inordinate amount of time, because in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated:   1000000000000000 in range(1000000000000001)   Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous).   I have also tried things like this, but the calculation is still almost instant:   1000000000000000000000 in range(0,1000000000000000000001,10) # count by tens   If I try to implement my own range function, the result is not so nice!!   def my_crappy_range(N):     i = 0     while i < N:         yield i         i += 1     return   What is the range() object doing under the hood that makes it so fast?     Martijn Pieters' answer was chosen for its completeness, but also see abarnert's first answer for a good discussion of what it means for range to be a full-fledged sequence in Python 3, and some information/warning regarding potential inconsistency for __contains__ function optimization across Python implementations. abarnert's other answer goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of xrange in Python 2). Answers by poke and by wim provide the relevant C source code and explanations for those who are interested.      ", "Tags": ["python", "performance", "python-3.x", "range", "python-internals"], "A_Votes": "1389", "A_Content": "  The Python 3 range() object doesn't produce numbers immediately; it is a smart sequence object that produces numbers on demand. All it contains is your start, stop and step values, then as you iterate over the object the next integer is calculated each iteration.  The object also implements the object.__contains__ hook, and calculates if your number is part of its range. Calculating is a O(1) constant time operation. There is never a need to scan through all possible integers in the range.  From the range() object documentation:     The advantage of the range type over a regular list or tuple is that a range object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the start, stop and step values, calculating individual items and subranges as needed).   So at a minimum, your range() object would do:  class my_range(object):     def __init__(self, start, stop=None, step=1):         if stop is None:             start, stop = 0, start         self.start, self.stop, self.step = start, stop, step         if step < 0:             lo, hi = stop, start         else:             lo, hi = start, stop         self.length = ((hi - lo - 1) // abs(step)) + 1      def __iter__(self):         current = self.start         if self.step < 0:             while current > self.stop:                 yield current                 current += self.step         else:             while current < self.stop:                 yield current                 current += self.step      def __len__(self):         return self.length      def __getitem__(self, i):         if i < 0:             i += self.length         if 0 <= i < self.length:             return self.start + i * self.step         raise IndexError('Index out of range: {}'.format(i))      def __contains__(self, num):         if self.step < 0:             if not (self.stop < num <= self.start):                 return False         else:             if not (self.start <= num < self.stop):                 return False         return (num - self.start) % self.step == 0   This is still missing several things that a real range() supports (such as the .index() or .count() methods, hashing, equality testing, or slicing), but should give you an idea.  I also simplified the __contains__ implementation to only focus on integer tests; if you give a real range() object a non-integer value (including subclasses of int), a slow scan is initiated to see if there is a match, just as if you use a containment test against a list of all the contained values. This was done to continue to support other numeric types that just happen to support equality testing with integers but are not expected to support integer arithmetic as well. See the original Python issue that implemented the containment test.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "3", "A_Content": "  >>> '   spacious   '.rstrip() '   spacious' >>> \"AABAA\".rstrip(\"A\")   'AAB' >>> \"ABBA\".rstrip(\"AB\") # both AB and BA are stripped    '' >>> \"ABCABBA\".rstrip(\"AB\")    'ABC'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "3", "A_Content": "  It looks like there is not a perfect analog for perl's chomp.  In particular, rstrip cannot handle multi-character newline delimiters like \\r\\n. However, splitlines does as pointed out here. Following my answer on a different question, you can combine join and splitlines to remove/replace all newlines from a string s:  ''.join(s.splitlines())   The following removes exactly one trailing newline (as chomp would, I believe). Passing True as the keepends argument to splitlines retain the delimiters.  Then, splitlines is called again to remove the delimiters on just the last \"line\":   def chomp(s):     if len(s):         lines = s.splitlines(True)         last = lines.pop()         return ''.join(lines + last.splitlines())     else:         return ''      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "3", "A_Content": "  I'm bubbling up my regular expression based answer from one I posted earlier in the comments of another answer.  I think using re is a clearer more explicit solution to this problem than str.rstrip.  >>> import re   If you want to remove one or more trailing newline chars:  >>> re.sub(r'[\\n\\r]+$', '', '\\nx\\r\\n') '\\nx'   If you want to remove newline chars everywhere (not just trailing):  >>> re.sub(r'[\\n\\r]+', '', '\\nx\\r\\n') 'x'   If you want to remove only 1-2 trailing newline chars (i.e., \\r, \\n, \\r\\n, \\n\\r, \\r\\r, \\n\\n)  >>> re.sub(r'[\\n\\r]{1,2}$', '', '\\nx\\r\\n\\r\\n') '\\nx\\r' >>> re.sub(r'[\\n\\r]{1,2}$', '', '\\nx\\r\\n\\r') '\\nx\\r' >>> re.sub(r'[\\n\\r]{1,2}$', '', '\\nx\\r\\n') '\\nx'   I have a feeling what most people really want here, is to remove just one occurrence of a trailing newline character, either \\r\\n or \\n and nothing more.  >>> re.sub(r'(?:\\r\\n|\\n)$', '', '\\nx\\n\\n', count=1) '\\nx\\n' >>> re.sub(r'(?:\\r\\n|\\n)$', '', '\\nx\\r\\n\\r\\n', count=1) '\\nx\\r\\n' >>> re.sub(r'(?:\\r\\n|\\n)$', '', '\\nx\\r\\n', count=1) '\\nx' >>> re.sub(r'(?:\\r\\n|\\n)$', '', '\\nx\\n', count=1) '\\nx'   (The ?: is to create a non-capturing group.)  (By the way this is not what '...'.rstrip('\\n', '').rstrip('\\r', '') does which may not be clear to others stumbling upon this thread.  str.rstrip strips as many of the trailing characters as possible, so a string like foo\\n\\n\\n would result in a false positive of foo whereas you may have wanted to preserve the other newlines after stripping a single trailing one.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "2", "A_Content": "  There are three types of line endings that we normally encounter: \\n, \\r and \\r\\n. A rather simple regular expression in re.sub, namely r\"\\r?\\n?$\", is able to catch them all.  (And we gotta catch 'em all, am I right?)  import re  re.sub(r\"\\r?\\n?$\", \"\", the_text, 1)   With the last argument, we limit the number of occurences replaced to one, mimicking chomp to some extent. Example:  import re  text_1 = \"hellothere\\n\\n\\n\" text_2 = \"hellothere\\n\\n\\r\" text_3 = \"hellothere\\n\\n\\r\\n\"  a = re.sub(r\"\\r?\\n?$\", \"\", text_1, 1) b = re.sub(r\"\\r?\\n?$\", \"\", text_2, 1) c = re.sub(r\"\\r?\\n?$\", \"\", text_3, 1)   ... where a == b == c is True.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "1", "A_Content": "  If you are concerned about speed (say you have a looong list of strings) and you know the nature of the newline char, string slicing is actually faster than rstrip. A little test to illustrate this:  import time  loops = 50000000  def method1(loops=loops):     test_string = 'num\\n'     t0 = time.time()     for num in xrange(loops):         out_sting = test_string[:-1]     t1 = time.time()     print('Method 1: ' + str(t1 - t0))  def method2(loops=loops):     test_string = 'num\\n'     t0 = time.time()     for num in xrange(loops):         out_sting = test_string.rstrip()     t1 = time.time()     print('Method 2: ' + str(t1 - t0))  method1() method2()   Output:  Method 1: 3.92700004578 Method 2: 6.73000001907      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "0", "A_Content": "  A catch all:  line = line.rstrip('\\r|\\n')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/275018/how-can-i-remove-chomp-a-trailing-newline-in-python", "Language": "Python", "Q_Title": "How can I remove (chomp) a trailing newline in Python?", "Q_Votes": "1345", "Q_Content": "    What is the Python equivalent of Perl's chomp function, which removes the last character of a string if it is a newline?     ", "Tags": ["python", "newline", "trailing"], "A_Votes": "0", "A_Content": "    This will work both for windows and linux (bit expensive with re sub if you are looking for only re solution)  import re  if re.search(\"(\\\\r|)\\\\n$\", line):     line = re.sub(\"(\\\\r|)\\\\n$\", \"\", line)        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/30081275/why-is-1000000000000000-in-range1000000000000001-so-fast-in-python-3", "Language": "Python", "Q_Title": "Why is \u201c1000000000000000 in range(1000000000000001)\u201d so fast in Python 3?", "Q_Votes": "1408", "Q_Content": "    It is my understanding that the range() function, which is actually an object type in Python 3, generates its contents on the fly, similar to a generator.   This being the case, I would have expected the following line to take an inordinate amount of time, because in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated:   1000000000000000 in range(1000000000000001)   Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous).   I have also tried things like this, but the calculation is still almost instant:   1000000000000000000000 in range(0,1000000000000000000001,10) # count by tens   If I try to implement my own range function, the result is not so nice!!   def my_crappy_range(N):     i = 0     while i < N:         yield i         i += 1     return   What is the range() object doing under the hood that makes it so fast?     Martijn Pieters' answer was chosen for its completeness, but also see abarnert's first answer for a good discussion of what it means for range to be a full-fledged sequence in Python 3, and some information/warning regarding potential inconsistency for __contains__ function optimization across Python implementations. abarnert's other answer goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of xrange in Python 2). Answers by poke and by wim provide the relevant C source code and explanations for those who are interested.      ", "Tags": ["python", "performance", "python-3.x", "range", "python-internals"], "A_Votes": "586", "A_Content": "  The fundamental misunderstanding here is in thinking that range is a generator. It's not. In fact, it's not any kind of iterator.  You can tell this pretty easily:  >>> a = range(5) >>> print(list(a)) [0, 1, 2, 3, 4] >>> print(list(a)) [0, 1, 2, 3, 4]   If it were a generator, iterating it once would exhaust it:  >>> b = my_crappy_range(5) >>> print(list(b)) [0, 1, 2, 3, 4] >>> print(list(b)) []   What range actually is, is a sequence, just like a list. You can even test this:  >>> import collections.abc >>> isinstance(a, collections.abc.Sequence) True   This means it has to follow all the rules of being a sequence:  >>> a[3]         # indexable 3 >>> len(a)       # sized 5 >>> 3 in a       # membership True >>> reversed(a)  # reversible <range_iterator at 0x101cd2360> >>> a.index(3)   # implements 'index' 3 >>> a.count(3)   # implements 'count' 1     The difference between a range and a list is that a range is a lazy or dynamic sequence; it doesn't remember all of its values, it just remembers its start, stop, and step, and creates the values on demand on __getitem__.  (As a side note, if you print(iter(a)), you'll notice that range uses the same listiterator type as list. How does that work? A listiterator doesn't use anything special about list except for the fact that it provides a C implementation of __getitem__, so it works fine for range too.)    Now, there's nothing that says that Sequence.__contains__ has to be constant time\u2014in fact, for obvious examples of sequences like list, it isn't. But there's nothing that says it can't be. And it's easier to implement range.__contains__ to just check it mathematically ((val - start) % step, but with some extra complexity to deal with negative steps) than to actually generate and test all the values, so why shouldn't it do it the better way?  But there doesn't seem to be anything in the language that guarantees this will happen. As Ashwini Chaudhari points out, if you give it a non-integral value, instead of converting to integer and doing the mathematical test, it will fall back to iterating all the values and comparing them one by one. And just because CPython 3.2+ and PyPy 3.x versions happen to contain this optimization, and it's an obvious good idea and easy to do, there's no reason that IronPython or NewKickAssPython 3.x couldn't leave it out. (And in fact CPython 3.0-3.1 didn't include it.)    If range actually were a generator, like my_crappy_range, then it wouldn't make sense to test __contains__ this way, or at least the way it makes sense wouldn't be obvious. If you'd already iterated the first 3 values, is 1 still in the generator? Should testing for 1 cause it to iterate and consume all the values up to 1 (or up to the first value >= 1)?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/30081275/why-is-1000000000000000-in-range1000000000000001-so-fast-in-python-3", "Language": "Python", "Q_Title": "Why is \u201c1000000000000000 in range(1000000000000001)\u201d so fast in Python 3?", "Q_Votes": "1408", "Q_Content": "    It is my understanding that the range() function, which is actually an object type in Python 3, generates its contents on the fly, similar to a generator.   This being the case, I would have expected the following line to take an inordinate amount of time, because in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated:   1000000000000000 in range(1000000000000001)   Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous).   I have also tried things like this, but the calculation is still almost instant:   1000000000000000000000 in range(0,1000000000000000000001,10) # count by tens   If I try to implement my own range function, the result is not so nice!!   def my_crappy_range(N):     i = 0     while i < N:         yield i         i += 1     return   What is the range() object doing under the hood that makes it so fast?     Martijn Pieters' answer was chosen for its completeness, but also see abarnert's first answer for a good discussion of what it means for range to be a full-fledged sequence in Python 3, and some information/warning regarding potential inconsistency for __contains__ function optimization across Python implementations. abarnert's other answer goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of xrange in Python 2). Answers by poke and by wim provide the relevant C source code and explanations for those who are interested.      ", "Tags": ["python", "performance", "python-3.x", "range", "python-internals"], "A_Votes": "289", "A_Content": "  Use the source, Luke!  In CPython, range(...).__contains__ (a method wrapper) will eventually delegate to a simple calculation which checks if the value can possibly be in the range.  The reason for the speed here is we're using mathematical reasoning about the bounds, rather than a direct iteration of the range object.  To explain the logic used:    Check that the number is between start and stop, and Check that the stride value doesn't \"step over\" our number.     For example, 994 is in range(4, 1000, 2) because:   4 <= 994 < 1000, and (994 - 4) % 2 == 0.   The full C code is included below, which is a bit more verbose because of memory management and reference counting details, but the basic idea is there:  static int range_contains_long(rangeobject *r, PyObject *ob) {     int cmp1, cmp2, cmp3;     PyObject *tmp1 = NULL;     PyObject *tmp2 = NULL;     PyObject *zero = NULL;     int result = -1;      zero = PyLong_FromLong(0);     if (zero == NULL) /* MemoryError in int(0) */         goto end;      /* Check if the value can possibly be in the range. */      cmp1 = PyObject_RichCompareBool(r->step, zero, Py_GT);     if (cmp1 == -1)         goto end;     if (cmp1 == 1) { /* positive steps: start <= ob < stop */         cmp2 = PyObject_RichCompareBool(r->start, ob, Py_LE);         cmp3 = PyObject_RichCompareBool(ob, r->stop, Py_LT);     }     else { /* negative steps: stop < ob <= start */         cmp2 = PyObject_RichCompareBool(ob, r->start, Py_LE);         cmp3 = PyObject_RichCompareBool(r->stop, ob, Py_LT);     }      if (cmp2 == -1 || cmp3 == -1) /* TypeError */         goto end;     if (cmp2 == 0 || cmp3 == 0) { /* ob outside of range */         result = 0;         goto end;     }      /* Check that the stride does not invalidate ob's membership. */     tmp1 = PyNumber_Subtract(ob, r->start);     if (tmp1 == NULL)         goto end;     tmp2 = PyNumber_Remainder(tmp1, r->step);     if (tmp2 == NULL)         goto end;     /* result = ((int(ob) - start) % step) == 0 */     result = PyObject_RichCompareBool(tmp2, zero, Py_EQ);   end:     Py_XDECREF(tmp1);     Py_XDECREF(tmp2);     Py_XDECREF(zero);     return result; }  static int range_contains(rangeobject *r, PyObject *ob) {     if (PyLong_CheckExact(ob) || PyBool_Check(ob))         return range_contains_long(r, ob);      return (int)_PySequence_IterSearch((PyObject*)r, ob,                                        PY_ITERSEARCH_CONTAINS); }   The \"meat\" of the idea is mentioned in the line:  /* result = ((int(ob) - start) % step) == 0 */    As a final note - look at the range_contains function at the bottom of the code snippet.  If the exact type check fails then we don't use the clever algorithm described, instead falling back to a dumb iteration search of the range using _PySequence_IterSearch!  You can check this behaviour in the interpreter (I'm using v3.5.0 here):  >>> x, r = 1000000000000000, range(1000000000000001) >>> class MyInt(int): ...     pass ...  >>> x_ = MyInt(x) >>> x in r  # calculates immediately :)  True >>> x_ in r  # iterates for ages.. :(  ^\\Quit (core dumped)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/30081275/why-is-1000000000000000-in-range1000000000000001-so-fast-in-python-3", "Language": "Python", "Q_Title": "Why is \u201c1000000000000000 in range(1000000000000001)\u201d so fast in Python 3?", "Q_Votes": "1408", "Q_Content": "    It is my understanding that the range() function, which is actually an object type in Python 3, generates its contents on the fly, similar to a generator.   This being the case, I would have expected the following line to take an inordinate amount of time, because in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated:   1000000000000000 in range(1000000000000001)   Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous).   I have also tried things like this, but the calculation is still almost instant:   1000000000000000000000 in range(0,1000000000000000000001,10) # count by tens   If I try to implement my own range function, the result is not so nice!!   def my_crappy_range(N):     i = 0     while i < N:         yield i         i += 1     return   What is the range() object doing under the hood that makes it so fast?     Martijn Pieters' answer was chosen for its completeness, but also see abarnert's first answer for a good discussion of what it means for range to be a full-fledged sequence in Python 3, and some information/warning regarding potential inconsistency for __contains__ function optimization across Python implementations. abarnert's other answer goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of xrange in Python 2). Answers by poke and by wim provide the relevant C source code and explanations for those who are interested.      ", "Tags": ["python", "performance", "python-3.x", "range", "python-internals"], "A_Votes": "107", "A_Content": "  To add to Martijn\u2019s answer, this is the relevant part of the source (in C, as the range object is written in native code):  static int range_contains(rangeobject *r, PyObject *ob) {     if (PyLong_CheckExact(ob) || PyBool_Check(ob))         return range_contains_long(r, ob);      return (int)_PySequence_IterSearch((PyObject*)r, ob,                                        PY_ITERSEARCH_CONTAINS); }   So for PyLong objects (which is int in Python 3), it will use the range_contains_long function to determine the result. And that function essentially checks if ob is in the specified range (although it looks a bit more complex in C).  If it\u2019s not an int object, it falls back to iterating until it finds the value (or not).  The whole logic could be translated to pseudo-Python like this:  def range_contains (rangeObj, obj):     if isinstance(obj, int):         return range_contains_long(rangeObj, obj)      # default logic by iterating     return any(obj == x for x in rangeObj)  def range_contains_long (r, num):     if r.step > 0:         # positive step: r.start <= num < r.stop         cmp2 = r.start <= num         cmp3 = num < r.stop     else:         # negative step: r.start >= num > r.stop         cmp2 = num <= r.start         cmp3 = r.stop < num      # outside of the range boundaries     if not cmp2 or not cmp3:         return False      # num must be on a valid step inside the boundaries     return (num - r.start) % r.step == 0      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/30081275/why-is-1000000000000000-in-range1000000000000001-so-fast-in-python-3", "Language": "Python", "Q_Title": "Why is \u201c1000000000000000 in range(1000000000000001)\u201d so fast in Python 3?", "Q_Votes": "1408", "Q_Content": "    It is my understanding that the range() function, which is actually an object type in Python 3, generates its contents on the fly, similar to a generator.   This being the case, I would have expected the following line to take an inordinate amount of time, because in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated:   1000000000000000 in range(1000000000000001)   Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous).   I have also tried things like this, but the calculation is still almost instant:   1000000000000000000000 in range(0,1000000000000000000001,10) # count by tens   If I try to implement my own range function, the result is not so nice!!   def my_crappy_range(N):     i = 0     while i < N:         yield i         i += 1     return   What is the range() object doing under the hood that makes it so fast?     Martijn Pieters' answer was chosen for its completeness, but also see abarnert's first answer for a good discussion of what it means for range to be a full-fledged sequence in Python 3, and some information/warning regarding potential inconsistency for __contains__ function optimization across Python implementations. abarnert's other answer goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of xrange in Python 2). Answers by poke and by wim provide the relevant C source code and explanations for those who are interested.      ", "Tags": ["python", "performance", "python-3.x", "range", "python-internals"], "A_Votes": "81", "A_Content": "  If you're wondering why this optimization was added to range.__contains__, and why it wasn't added to xrange.__contains__ in 2.7:  First, as Ashwini Chaudhary discovered, issue 1766304 was opened explicitly to optimize [x]range.__contains__. A patch for this was accepted and checked in for 3.2, but not backported to 2.7 because \"xrange has behaved like this for such a long time that I don't see what it buys us to commit the patch this late.\" (2.7 was nearly out at that point.)  Meanwhile:  Originally, xrange was a not-quite-sequence object. As the 3.1 docs say:     Range objects have very little behavior: they only support indexing, iteration, and the len function.   This wasn't quite true; an xrange object actually supported a few other things that come automatically with indexing and len,* including __contains__ (via linear search). But nobody thought it was worth making them full sequences at the time.  Then, as part of implementing the Abstract Base Classes PEP, it was important to figure out which builtin types should be marked as implementing which ABCs, and xrange/range claimed to implement collections.Sequence, even though it still only handled the same \"very little behavior\". Nobody noticed that problem until issue 9213. The patch for that issue not only added index and count to 3.2's range, it also re-worked the optimized __contains__ (which shares the same math with index, and is directly used by count).** This change went in for 3.2 as well, and was not backported to 2.x, because \"it's a bugfix that adds new methods\". (At this point, 2.7 was already past rc status.)  So, there were two chances to get this optimization backported to 2.7, but they were both rejected.    * In fact, you even get iteration for free with len and indexing, but in 2.3 xrange objects got a custom iterator. Which they then lost in 3.x, which uses the same listiterator type as list.  ** The first version actually reimplemented it, and got the details wrong\u2014e.g., it would give you MyIntSubclass(2) in range(5) == False. But Daniel Stutzbach's updated version of the patch restored most of the previous code, including the fallback to the generic, slow _PySequence_IterSearch that pre-3.2 range.__contains__ was implicitly using when the optimization doesn't apply.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/30081275/why-is-1000000000000000-in-range1000000000000001-so-fast-in-python-3", "Language": "Python", "Q_Title": "Why is \u201c1000000000000000 in range(1000000000000001)\u201d so fast in Python 3?", "Q_Votes": "1408", "Q_Content": "    It is my understanding that the range() function, which is actually an object type in Python 3, generates its contents on the fly, similar to a generator.   This being the case, I would have expected the following line to take an inordinate amount of time, because in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated:   1000000000000000 in range(1000000000000001)   Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous).   I have also tried things like this, but the calculation is still almost instant:   1000000000000000000000 in range(0,1000000000000000000001,10) # count by tens   If I try to implement my own range function, the result is not so nice!!   def my_crappy_range(N):     i = 0     while i < N:         yield i         i += 1     return   What is the range() object doing under the hood that makes it so fast?     Martijn Pieters' answer was chosen for its completeness, but also see abarnert's first answer for a good discussion of what it means for range to be a full-fledged sequence in Python 3, and some information/warning regarding potential inconsistency for __contains__ function optimization across Python implementations. abarnert's other answer goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of xrange in Python 2). Answers by poke and by wim provide the relevant C source code and explanations for those who are interested.      ", "Tags": ["python", "performance", "python-3.x", "range", "python-internals"], "A_Votes": "36", "A_Content": "  The other answers explained it well already, but I'd like to offer another experiment illustrating the nature of range objects:  >>> r = range(5) >>> for i in r:         print(i, 2 in r, list(r))  0 True [0, 1, 2, 3, 4] 1 True [0, 1, 2, 3, 4] 2 True [0, 1, 2, 3, 4] 3 True [0, 1, 2, 3, 4] 4 True [0, 1, 2, 3, 4]   As you can see,  a range object is an object that remembers its range and can be used many times (even while iterating over it), not just a one-time generator.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/30081275/why-is-1000000000000000-in-range1000000000000001-so-fast-in-python-3", "Language": "Python", "Q_Title": "Why is \u201c1000000000000000 in range(1000000000000001)\u201d so fast in Python 3?", "Q_Votes": "1408", "Q_Content": "    It is my understanding that the range() function, which is actually an object type in Python 3, generates its contents on the fly, similar to a generator.   This being the case, I would have expected the following line to take an inordinate amount of time, because in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated:   1000000000000000 in range(1000000000000001)   Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous).   I have also tried things like this, but the calculation is still almost instant:   1000000000000000000000 in range(0,1000000000000000000001,10) # count by tens   If I try to implement my own range function, the result is not so nice!!   def my_crappy_range(N):     i = 0     while i < N:         yield i         i += 1     return   What is the range() object doing under the hood that makes it so fast?     Martijn Pieters' answer was chosen for its completeness, but also see abarnert's first answer for a good discussion of what it means for range to be a full-fledged sequence in Python 3, and some information/warning regarding potential inconsistency for __contains__ function optimization across Python implementations. abarnert's other answer goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of xrange in Python 2). Answers by poke and by wim provide the relevant C source code and explanations for those who are interested.      ", "Tags": ["python", "performance", "python-3.x", "range", "python-internals"], "A_Votes": "4", "A_Content": "  It's all about lazy approach to the evaluation, and some extra optimalization of range. Values in ranges don't need to be computed until real use, or even futher due to extra optimalization.  By the way your integer is not such big, consider sys.maxsize  sys.maxsize in range(sys.maxsize) is pretty fast  due to optimization - it's easy to compare given integer just with min and max of range.  but:  float(sys.maxsize) in range(sys.maxsize) is pretty slow.  (in this case there is no optimization in range, so since receive unexpected float, python will compare all numbers)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "Language": "Python", "Q_Title": "Python join: why is it string.join(list) instead of list.join(string)?", "Q_Votes": "1409", "Q_Content": "    This has always confused me. It seems like this would be nicer:  my_list = [\"Hello\", \"world\"] print my_list.join(\"-\") # Produce: \"Hello-world\"   Than this:  my_list = [\"Hello\", \"world\"] print \"-\".join(my_list) # Produce: \"Hello-world\"   Is there a specific reason it is like this?     ", "Tags": ["python", "string", "list", "join"], "A_Votes": "1022", "A_Content": "  It's because any iterable can be joined, not just lists, but the result and the \"joiner\" are always strings.  E.G:  import urllib2 print '\\n############\\n'.join(     urllib2.urlopen('http://data.stackexchange.com/users/7095'))      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "Language": "Python", "Q_Title": "Python join: why is it string.join(list) instead of list.join(string)?", "Q_Votes": "1409", "Q_Content": "    This has always confused me. It seems like this would be nicer:  my_list = [\"Hello\", \"world\"] print my_list.join(\"-\") # Produce: \"Hello-world\"   Than this:  my_list = [\"Hello\", \"world\"] print \"-\".join(my_list) # Produce: \"Hello-world\"   Is there a specific reason it is like this?     ", "Tags": ["python", "string", "list", "join"], "A_Votes": "229", "A_Content": "  Because the join() method is in the string class, instead of the list class?  I agree it looks funny.  See http://www.faqs.org/docs/diveintopython/odbchelper_join.html:     Historical note. When I first learned   Python, I expected join to be a method   of a list, which would take the   delimiter as an argument. Lots of   people feel the same way, and there\u2019s   a story behind the join method. Prior   to Python 1.6, strings didn\u2019t have all   these useful methods. There was a   separate string module which contained   all the string functions; each   function took a string as its first   argument. The functions were deemed   important enough to put onto the   strings themselves, which made sense   for functions like lower, upper, and   split. But many hard-core Python   programmers objected to the new join   method, arguing that it should be a   method of the list instead, or that it   shouldn\u2019t move at all but simply stay   a part of the old string module (which   still has lots of useful stuff in it).   I use the new join method exclusively,   but you will see code written either   way, and if it really bothers you, you   can use the old string.join function   instead.      --- Mark Pilgrim, Dive into Python      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "Language": "Python", "Q_Title": "Python join: why is it string.join(list) instead of list.join(string)?", "Q_Votes": "1409", "Q_Content": "    This has always confused me. It seems like this would be nicer:  my_list = [\"Hello\", \"world\"] print my_list.join(\"-\") # Produce: \"Hello-world\"   Than this:  my_list = [\"Hello\", \"world\"] print \"-\".join(my_list) # Produce: \"Hello-world\"   Is there a specific reason it is like this?     ", "Tags": ["python", "string", "list", "join"], "A_Votes": "217", "A_Content": "  This was discussed in the String methods... finally thread in the Python-Dev achive, and was accepted by Guido. This thread began in Jun 1999, and str.join was included in Python 1.6 which was released in Sep 2000 (and supported Unicode). Python 2.0 (supported str methods including join) was released in Oct 2000.   There were four options proposed in this thread:   str.join(seq) seq.join(str) seq.reduce(str) join as a built-in function  Guido wanted to support not only lists, tuples, but all sequences/iterables. seq.reduce(str) is difficult for new-comers. seq.join(str) introduces unexpected dependency from sequences to str/unicode. join() as a built-in function would support only specific data types. So using a built in namespace is not good. If join() supports many datatypes, creating optimized implementation would be difficult, if implemented using the __add__ method then it's O(n\u00b2). The separater string (sep) should not be omitted. Explicit is better than implicit.   There are no other reasons offered in this thread.  Here are some additional thoughts (my own, and my friend's):   Unicode support was coming, but it was not final. At that time UTF-8 was the most likely about to replace UCS2/4. To calculate total buffer length of UTF-8 strings it needs to know character coding rule. At that time, Python had already decided on a common sequence interface rule where a user could create a sequence-like (iterable) class. But Python didn't support extending built-in types until 2.2. At that time it was difficult to provide basic iterable class (which is mentioned in another comment).    Guido's decision is recorded in a historical mail, deciding on str.join(seq):     Funny, but it does seem right!  Barry, go for it...   --Guido van Rossum      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "Language": "Python", "Q_Title": "Python join: why is it string.join(list) instead of list.join(string)?", "Q_Votes": "1409", "Q_Content": "    This has always confused me. It seems like this would be nicer:  my_list = [\"Hello\", \"world\"] print my_list.join(\"-\") # Produce: \"Hello-world\"   Than this:  my_list = [\"Hello\", \"world\"] print \"-\".join(my_list) # Produce: \"Hello-world\"   Is there a specific reason it is like this?     ", "Tags": ["python", "string", "list", "join"], "A_Votes": "58", "A_Content": "  I agree that it's counterintuitive at first, but there's a good reason. Join can't be a method of a list because:   it must work for different iterables too (tuples, generators, etc.)  it must have different behavior between different types of strings.   There are actually two join methods (Python 3.0):  >>> b\"\".join <built-in method join of bytes object at 0x00A46800> >>> \"\".join <built-in method join of str object at 0x00A28D40>   If join was a method of a list, then it would have to inspect its arguments to decide which one of them to call. And you can't join byte and str together, so the way they have it now makes sense.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "Language": "Python", "Q_Title": "Python join: why is it string.join(list) instead of list.join(string)?", "Q_Votes": "1409", "Q_Content": "    This has always confused me. It seems like this would be nicer:  my_list = [\"Hello\", \"world\"] print my_list.join(\"-\") # Produce: \"Hello-world\"   Than this:  my_list = [\"Hello\", \"world\"] print \"-\".join(my_list) # Produce: \"Hello-world\"   Is there a specific reason it is like this?     ", "Tags": ["python", "string", "list", "join"], "A_Votes": "36", "A_Content": "     Why is it string.join(list) instead of list.join(string)?   This is because join is a \"string\" method! It creates a string from any iterable. If we stuck the method on lists, what about when we have iterables that aren't lists?   What if you have a tuple of strings? If this were a list method, you would have to cast every such iterator of strings as a list before you could join the elements into a single string! For example:  some_strings = ('foo', 'bar', 'baz')   Let's roll our own list join method:  class OurList(list):      def join(self, s):         return s.join(self)   And to use it, note that we have to first create a list from each iterable to join the strings in that iterable, wasting both memory and processing power:  >>> l = OurList(some_strings) # step 1, create our list >>> l.join(', ') # step 2, use our list join method! 'foo, bar, baz'   So we see we have to add an extra step to use our list method, instead of just using the builtin string method:  >>> ' | '.join(some_strings) # a single step! 'foo | bar | baz'   Performance Caveat for Generators  The algorithm Python uses to create the final string with str.join actually has to pass over the iterable twice, so if you provide it a generator expression, it has to materialize it into a list first before it can create the final string.   Thus, while passing around generators is usually better than list comprehensions, str.join is an exception:  >>> import timeit >>> min(timeit.repeat(lambda: ''.join(str(i) for i in range(10) if i))) 3.839168446022086 >>> min(timeit.repeat(lambda: ''.join([str(i) for i in range(10) if i]))) 3.339879313018173   Nevertheless, the str.join operation is still semantically a \"string\" operation, so it still makes sense to have it on the str object than on miscellaneous iterables.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "Language": "Python", "Q_Title": "Python join: why is it string.join(list) instead of list.join(string)?", "Q_Votes": "1409", "Q_Content": "    This has always confused me. It seems like this would be nicer:  my_list = [\"Hello\", \"world\"] print my_list.join(\"-\") # Produce: \"Hello-world\"   Than this:  my_list = [\"Hello\", \"world\"] print \"-\".join(my_list) # Produce: \"Hello-world\"   Is there a specific reason it is like this?     ", "Tags": ["python", "string", "list", "join"], "A_Votes": "23", "A_Content": "  Think of it as the natural orthogonal operation to split.  I understand why it is applicable to anything iterable and so can't easily be implemented just on list.  For readability, I'd like to see it in the language but I don't think that is actually feasible - if iterability were an interface then it could be added to the interface but it is just a convention and so there's no central way to add it to the set of things which are iterable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "Language": "Python", "Q_Title": "Python join: why is it string.join(list) instead of list.join(string)?", "Q_Votes": "1409", "Q_Content": "    This has always confused me. It seems like this would be nicer:  my_list = [\"Hello\", \"world\"] print my_list.join(\"-\") # Produce: \"Hello-world\"   Than this:  my_list = [\"Hello\", \"world\"] print \"-\".join(my_list) # Produce: \"Hello-world\"   Is there a specific reason it is like this?     ", "Tags": ["python", "string", "list", "join"], "A_Votes": "11", "A_Content": "  Primarily because the result of a someString.join() is a string.  The sequence (list or tuple or whatever) doesn't appear in the result, just a string.  Because the result is a string, it makes sense as a method of a string.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "Language": "Python", "Q_Title": "Python join: why is it string.join(list) instead of list.join(string)?", "Q_Votes": "1409", "Q_Content": "    This has always confused me. It seems like this would be nicer:  my_list = [\"Hello\", \"world\"] print my_list.join(\"-\") # Produce: \"Hello-world\"   Than this:  my_list = [\"Hello\", \"world\"] print \"-\".join(my_list) # Produce: \"Hello-world\"   Is there a specific reason it is like this?     ", "Tags": ["python", "string", "list", "join"], "A_Votes": "3", "A_Content": "  - in \"-\".join(my_list) declares that you are converting to a string from joining elements a list.It's result-oriented.(just for easy memory and understanding)  I make a exhaustive cheatsheet of methods_of_string for your reference.  string_methonds_44 = {     'convert': ['join','split', 'rsplit','splitlines', 'partition', 'rpartition'],     'edit': ['replace', 'lstrip', 'rstrip', 'strip'],     'search': ['endswith', 'startswith', 'count', 'index', 'find','rindex', 'rfind',],     'condition': ['isalnum', 'isalpha', 'isdecimal', 'isdigit', 'isnumeric','isidentifier',                   'islower','istitle', 'isupper','isprintable', 'isspace', ],     'text': ['lower', 'upper', 'capitalize', 'title', 'swapcase',              'center', 'ljust', 'rjust', 'zfill', 'expandtabs','casefold'],     'encode': ['translate', 'maketrans', 'encode'],     'format': ['format', 'format_map']}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "Language": "Python", "Q_Title": "Python join: why is it string.join(list) instead of list.join(string)?", "Q_Votes": "1409", "Q_Content": "    This has always confused me. It seems like this would be nicer:  my_list = [\"Hello\", \"world\"] print my_list.join(\"-\") # Produce: \"Hello-world\"   Than this:  my_list = [\"Hello\", \"world\"] print \"-\".join(my_list) # Produce: \"Hello-world\"   Is there a specific reason it is like this?     ", "Tags": ["python", "string", "list", "join"], "A_Votes": "2", "A_Content": "  Both are not nice.  string.join(xs, delimit) means that the string module is aware of the existence of a list, which it has no business knowing about, since the string module only works with strings.  list.join(delimit) is a bit nicer because we're so used to strings being a fundamental type(and lingually speaking, they are). However this means that join needs to be dispatched dynamically because in the arbitrary context of a.split(\"\\n\") the python compiler might not know what a is, and will need to look it up(analogously to vtable lookup), which is expensive if you do it a lot of times.  if the python runtime compiler knows that list is a built in module, it can skip the dynamic lookup and encode the intent into the bytecode directly, whereas otherwise it needs to dynamically resolve \"join\" of \"a\", which may be up several layers of inheritence per call(since between calls, the meaning of join may have changed, because python is a dynamic language).  sadly, this is the ultimate flaw of abstraction; no matter what abstraction you choose, your abstraction will only make sense in the context of the problem you're trying to solve, and as such you can never have a consistent abstraction that doesn't become inconsistent with underlying ideologies as you start gluing them together without wrapping them in a view that is consistent with your ideology. Knowing this, python's approach is more flexible since it's cheaper, it's up to you to pay more to make it look \"nicer\", either by making your own wrapper, or your own preprocessor.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object", "Language": "Python", "Q_Title": "Determine the type of an object?", "Q_Votes": "1417", "Q_Content": "    Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.     ", "Tags": ["python"], "A_Votes": "1640", "A_Content": "  To get the type of an object, you can use the built-in type() function. Passing an object as the only parameter will return the type object of that object:  >>> type([]) is list True >>> type({}) is dict True >>> type('') is str True >>> type(0) is int True >>> type({}) <type 'dict'> >>> type([]) <type 'list'>   This of course also works for custom types:  >>> class Test1 (object):         pass >>> class Test2 (Test1):         pass >>> a = Test1() >>> b = Test2() >>> type(a) is Test1 True >>> type(b) is Test2 True   Note that type() will only return the immediate type of the object, but won\u2019t be able to tell you about type inheritance.  >>> type(b) is Test1 False   To cover that, you should use the isinstance function. This of course also works for built-in types:  >>> isinstance(b, Test1) True >>> isinstance(b, Test2) True >>> isinstance(a, Test1) True >>> isinstance(a, Test2) False >>> isinstance([], list) True >>> isinstance({}, dict) True   isinstance() is usually the preferred way to ensure the type of an object because it will also accept derived types. So unless you actually need the type object (for whatever reason), using isinstance() is preferred over type().  The second parameter of isinstance() also accepts a tuple of types, so it\u2019s possible to check for multiple types at once. isinstance will then return true, if the object is of any of those types:  >>> isinstance([], (tuple, list, set)) True      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/735975/static-methods-in-python", "Language": "Python", "Q_Title": "Static methods in Python?", "Q_Votes": "1414", "Q_Content": "    Is it possible to have static methods in Python so I can call them without initializing a class, like:  ClassName.StaticMethod ( )      ", "Tags": ["python", "static-methods"], "A_Votes": "1715", "A_Content": "  Yep, using the staticmethod decorator  class MyClass(object):     @staticmethod     def the_static_method(x):         print x  MyClass.the_static_method(2) # outputs 2   Note that some code might use the old method of defining a static method, using staticmethod as a function rather than a decorator. This should only be used if you have to support ancient versions of Python (2.2 and 2.3)  class MyClass(object):     def the_static_method(x):         print x     the_static_method = staticmethod(the_static_method)  MyClass.the_static_method(2) # outputs 2   This is entirely identical to the first example (using @staticmethod), just not using the nice decorator syntax  Finally, use staticmethod() sparingly! There are very few situations where static-methods are necessary in Python, and I've seen them used many times where a separate \"top-level\" function would have been clearer.    The following is verbatim from the documentation::     A static method does not receive an implicit first argument. To declare a static method, use this idiom:  class C:     @staticmethod     def f(arg1, arg2, ...): ...       The @staticmethod form is a function decorator \u2013 see the description of function definitions in Function definitions for details.      It can be called either on the class (such as C.f()) or on an instance (such as C().f()). The instance is ignored except for its class.      Static methods in Python are similar to those found in Java or C++. For a more advanced concept, see classmethod().      For more information on static methods, consult the documentation on the standard type hierarchy in The standard type hierarchy.      New in version 2.2.      Changed in version 2.4: Function decorator syntax added.      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object", "Language": "Python", "Q_Title": "Determine the type of an object?", "Q_Votes": "1417", "Q_Content": "    Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.     ", "Tags": ["python"], "A_Votes": "145", "A_Content": "  You can do that using type():  >>> a = [] >>> type(a) <type 'list'> >>> f = () >>> type(f) <type 'tuple'>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object", "Language": "Python", "Q_Title": "Determine the type of an object?", "Q_Votes": "1417", "Q_Content": "    Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.     ", "Tags": ["python"], "A_Votes": "38", "A_Content": "  It might be more Pythonic to use a try...except block. That way, if you have a class which quacks like a list, or quacks like a dict, it will behave properly regardless of what its type really is.  To clarify, the preferred method of \"telling the difference\" between variable types is with something called duck typing: as long as the methods (and return types) that a variable responds to are what your subroutine expects, treat it like what you expect it to be. For example, if you have a class that overloads the bracket operators with getattr and setattr, but uses some funny internal scheme, it would be appropriate for it to behave as a dictionary if that's what it's trying to emulate.  The other problem with the type(A) is type(B) checking is that if A is a subclass of B, it evaluates to false when, programmatically, you would hope it would be true. If an object is a subclass of a list, it should work like a list: checking the type as presented in the other answer will prevent this. (isinstance will work, however).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object", "Language": "Python", "Q_Title": "Determine the type of an object?", "Q_Votes": "1417", "Q_Content": "    Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.     ", "Tags": ["python"], "A_Votes": "32", "A_Content": "  On instances of object you also have the:  __class__   attribute. Here is a sample taken from Python 3.3 console  >>> str = \"str\" >>> str.__class__ <class 'str'> >>> i = 2 >>> i.__class__ <class 'int'> >>> class Test(): ...     pass ... >>> a = Test() >>> a.__class__ <class '__main__.Test'>   Beware that in python 3.x and in New-Style classes (aviable optionally from Python 2.6) class and type have been merged and this can sometime lead to unexpected results. Mainly for this reason my favorite way of testing types/classes is to the isinstance built in function.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object", "Language": "Python", "Q_Title": "Determine the type of an object?", "Q_Votes": "1417", "Q_Content": "    Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.     ", "Tags": ["python"], "A_Votes": "15", "A_Content": "  Determine the type of a Python object  Determine the type of an object with type  >>> obj = object() >>> type(obj) <class 'object'>   Although it works, avoid double underscore attributes like __class__ - they're not semantically public, and, while perhaps not in this case, the builtin functions usually have better behavior.  >>> obj.__class__ # avoid this! <class 'object'>   type checking     Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.   Well that's a different question, don't use type - use isinstance:  def foo(obj):     \"\"\"given a string with items separated by spaces,      or a list or tuple,      do something sensible     \"\"\"     if isinstance(obj, str):         obj = str.split()     return _foo_handles_only_lists_or_tuples(obj)   This covers the case where your user might be doing something clever or sensible by subclassing str - according to the principle of Liskov Substitution, you want to be able to use subclass instances without breaking your code - and isinstance supports this.   Use Abstractions  Even better, you might look for a specific Abstract Base Class from collections or numbers:  from collections import Iterable from numbers import Number  def bar(obj):     \"\"\"does something sensible with an iterable of numbers,      or just one number     \"\"\"     if isinstance(obj, Number): # make it a 1-tuple         obj = (obj,)     if not isinstance(obj, Iterable):         raise TypeError('obj must be either a number or iterable of numbers')     return _bar_sensible_with_iterable(obj)   Or Just Don't explicitly Type-check  Or, perhaps best of all, use duck-typing, and don't explicitly type-check your code. Duck-typing supports Liskov Substitution with more elegance and less verbosity.   def baz(obj):     \"\"\"given an obj, a dict (or anything with an .items method)      do something sensible with each key-value pair     \"\"\"     for key, value in obj.items():         _baz_something_sensible(key, value)   Conclusion   Use type to actually get an instance's class.  Use isinstance to explicitly check for actual subclasses or registered abstractions.  And just avoid type-checking where it makes sense.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object", "Language": "Python", "Q_Title": "Determine the type of an object?", "Q_Votes": "1417", "Q_Content": "    Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.     ", "Tags": ["python"], "A_Votes": "11", "A_Content": "  You can use type() or isinstance().  >>> type([]) is list True   Be warned that you can clobber list or any other type by assigning a variable in the current scope of the same name.  >>> the_d = {} >>> t = lambda x: \"aight\" if type(x) is dict else \"NOPE\" >>> t(the_d) 'aight' >>> dict = \"dude.\" >>> t(the_d) 'NOPE'   Above we see that dict gets reassigned to a string, therefore the test:  type({}) is dict   ...fails.  To get around this and use type() more cautiously:  >>> import __builtin__ >>> the_d = {} >>> type({}) is dict True >>> dict =\"\" >>> type({}) is dict False >>> type({}) is __builtin__.dict True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object", "Language": "Python", "Q_Title": "Determine the type of an object?", "Q_Votes": "1417", "Q_Content": "    Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.     ", "Tags": ["python"], "A_Votes": "4", "A_Content": "  While the questions is pretty old, I stumbled across this while finding out a proper way myself, and I think it still needs clarifying, at least for Python 2.x (did not check on Python 3, but since the issue arises with classic classes which are gone on such version, it probably doesn't matter).  Here I'm trying to answer the title's question: how can I determine the type of an arbitrary object? Other suggestions about using or not using isinstance are fine in many comments and answers, but I'm not addressing those concerns.  The main issue with the type() approach is that it doesn't work properly with old-style instances:  class One:     pass  class Two:     pass   o = One() t = Two()  o_type = type(o) t_type = type(t)  print \"Are o and t instances of the same class?\", o_type is t_type   Executing this snippet would yield:  Are o and t instances of the same class? True   Which, I argue, is not what most people would expect.  The __class__ approach is the most close to correctness, but it won't work in one crucial case: when the passed-in object is an old-style class (not an instance!), since those objects lack such attribute.  This is the smallest snippet of code I could think of that satisfies such legitimate question in a consistent fashion:  #!/usr/bin/env python from types import ClassType #we adopt the null object pattern in the (unlikely) case #that __class__ is None for some strange reason _NO_CLASS=object() def get_object_type(obj):     obj_type = getattr(obj, \"__class__\", _NO_CLASS)     if obj_type is not _NO_CLASS:         return obj_type     # AFAIK the only situation where this happens is an old-style class     obj_type = type(obj)     if obj_type is not ClassType:         raise ValueError(\"Could not determine object '{}' type.\".format(obj_type))     return obj_type      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object", "Language": "Python", "Q_Title": "Determine the type of an object?", "Q_Votes": "1417", "Q_Content": "    Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.     ", "Tags": ["python"], "A_Votes": "3", "A_Content": "  As an aside to the previous answers, it's worth mentioning the existence of collections.abc which contains several abstract base classes (ABCs) that complement duck-typing.  For example, instead of explicitly checking if something is a list with:   isinstance(my_obj, list)   you could, if you're only interested in seeing if the object you have allows getting items, use collections.abc.Sequence:  from collections.abc import Sequence isinstance(my_obj, Sequence)    if you're strictly interested in objects that allow getting, setting and deleting items (i.e mutable sequences), you'd opt for collections.abc.MutableSequence.  Many other ABCs are defined there, Mapping for objects that can be used as maps, Iterable, Callable, et cetera. A full list of all these can be seen in the documentation for collections.abc.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object", "Language": "Python", "Q_Title": "Determine the type of an object?", "Q_Votes": "1417", "Q_Content": "    Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.     ", "Tags": ["python"], "A_Votes": "3", "A_Content": "  be careful using isinstance   isinstance(True, bool) True >>> isinstance(True, int) True   but type  type(True) == bool True >>> type(True) == int False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/735975/static-methods-in-python", "Language": "Python", "Q_Title": "Static methods in Python?", "Q_Votes": "1414", "Q_Content": "    Is it possible to have static methods in Python so I can call them without initializing a class, like:  ClassName.StaticMethod ( )      ", "Tags": ["python", "static-methods"], "A_Votes": "178", "A_Content": "  I think that Steven is actually right. To answer the original question, then, in order to set up a class method, simply assume that the first argument is not going to be a calling instance, and then make sure that you only call the method from the class.  (Note that this answer refers to Python 3.x. In Python 2.x you'll get a TypeError for calling the method on the class itself.)  For example:  class Dog:     count = 0 # this is a class variable     dogs = [] # this is a class variable      def __init__(self, name):         self.name = name #self.name is an instance variable         Dog.count += 1         Dog.dogs.append(name)      def bark(self, n): # this is an instance method         print(\"{} says: {}\".format(self.name, \"woof! \" * n))      def rollCall(n): #this is implicitly a class method (see comments below)         print(\"There are {} dogs.\".format(Dog.count))         if n >= len(Dog.dogs) or n < 0:             print(\"They are:\")             for dog in Dog.dogs:                 print(\"  {}\".format(dog))         else:             print(\"The dog indexed at {} is {}.\".format(n, Dog.dogs[n]))  fido = Dog(\"Fido\") fido.bark(3) Dog.rollCall(-1) rex = Dog(\"Rex\") Dog.rollCall(0)   In this code, the \"rollCall\" method assumes that the first argument is not an instance (as it would be if it were called by an instance instead of a class). As long as \"rollCall\" is called from the class rather than an instance, the code will work fine. If we try to call \"rollCall\" from an instance, e.g.:  rex.rollCall(-1)   however, it would cause an exception to be raised because it would send two arguments: itself and -1, and \"rollCall\" is only defined to accept one argument.  Incidentally, rex.rollCall() would send the correct number of arguments, but would also cause an exception to be raised because now n would be representing a Dog instance (i.e., rex) when the function expects n to be numerical.  This is where the decoration comes in: If we precede the \"rollCall\" method with  @staticmethod   then, by explicitly stating that the method is static, we can even call it from an instance. Now,   rex.rollCall(-1)   would work. The insertion of @staticmethod before a method definition, then, stops an instance from sending itself as an argument.  You can verify this by trying the following code with and without the @staticmethod line commented out.  class Dog:     count = 0 # this is a class variable     dogs = [] # this is a class variable      def __init__(self, name):         self.name = name #self.name is an instance variable         Dog.count += 1         Dog.dogs.append(name)      def bark(self, n): # this is an instance method         print(\"{} says: {}\".format(self.name, \"woof! \" * n))      @staticmethod     def rollCall(n):         print(\"There are {} dogs.\".format(Dog.count))         if n >= len(Dog.dogs) or n < 0:             print(\"They are:\")             for dog in Dog.dogs:                 print(\"  {}\".format(dog))         else:             print(\"The dog indexed at {} is {}.\".format(n, Dog.dogs[n]))   fido = Dog(\"Fido\") fido.bark(3) Dog.rollCall(-1) rex = Dog(\"Rex\") Dog.rollCall(0) rex.rollCall(-1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/735975/static-methods-in-python", "Language": "Python", "Q_Title": "Static methods in Python?", "Q_Votes": "1414", "Q_Content": "    Is it possible to have static methods in Python so I can call them without initializing a class, like:  ClassName.StaticMethod ( )      ", "Tags": ["python", "static-methods"], "A_Votes": "74", "A_Content": "  Yes, check out the staticmethod decorator:  >>> class C: ...     @staticmethod ...     def hello(): ...             print \"Hello World\" ... >>> C.hello() Hello World      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/735975/static-methods-in-python", "Language": "Python", "Q_Title": "Static methods in Python?", "Q_Votes": "1414", "Q_Content": "    Is it possible to have static methods in Python so I can call them without initializing a class, like:  ClassName.StaticMethod ( )      ", "Tags": ["python", "static-methods"], "A_Votes": "43", "A_Content": "  You don't really need to use the @staticmethod decorator. Just declaring a method (that doesn't expect the self parameter) and call it from the class. The decorator is only there in case you want to be able to call it from an instance as well (which was not what you wanted to do)  Mostly, you just use functions though...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/735975/static-methods-in-python", "Language": "Python", "Q_Title": "Static methods in Python?", "Q_Votes": "1414", "Q_Content": "    Is it possible to have static methods in Python so I can call them without initializing a class, like:  ClassName.StaticMethod ( )      ", "Tags": ["python", "static-methods"], "A_Votes": "28", "A_Content": "     Static methods in Python?      Is it possible to have static methods in Python so I can call them   without initializing a class, like:  ClassName.StaticMethod()    Yes, static methods can be created like this (although it's a bit more Pythonic to use underscores instead of CamelCase for methods):  class ClassName(object):      @staticmethod     def static_method(kwarg1=None):         '''return a value that is a function of kwarg1'''   The above uses the decorator syntax. This syntax is equivalent to   class ClassName(object):      def static_method(kwarg1=None):         '''return a value that is a function of kwarg1'''      static_method = staticmethod(static_method)   This can be used just as you described:  ClassName.static_method()   A builtin example of a static method is str.maketrans() in Python 3, which was a function in the string module in Python 2.    Another option that can be used as you describe is the classmethod, the difference is that the classmethod gets the class as an implicit first argument, and if subclassed, then it gets the subclass as the implicit first argument.  class ClassName(object):      @classmethod     def class_method(cls, kwarg1=None):         '''return a value that is a function of the class and kwarg1'''   Note that cls is not a required name for the first argument, but most experienced Python coders will consider it badly done if you use anything else.  These are typically used as alternative constructors.   new_instance = ClassName.class_method()   A builtin example is dict.fromkeys():  new_dict = dict.fromkeys(['key1', 'key2'])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/735975/static-methods-in-python", "Language": "Python", "Q_Title": "Static methods in Python?", "Q_Votes": "1414", "Q_Content": "    Is it possible to have static methods in Python so I can call them without initializing a class, like:  ClassName.StaticMethod ( )      ", "Tags": ["python", "static-methods"], "A_Votes": "9", "A_Content": "  Aside from the particularities of how static method objects behave, there is a certain kind of beauty you can strike with them when it comes to organizing your module-level code.  # garden.py def trim(a):     pass  def strip(a):     pass  def bunch(a, b):     pass  def _foo(foo):     pass  class powertools(object):     \"\"\"     Provides much regarded gardening power tools.     \"\"\"     @staticmethod     def answer_to_the_ultimate_question_of_life_the_universe_and_everything():         return 42      @staticmethod     def random():         return 13      @staticmethod     def promise():         return True  def _bar(baz, quux):     pass  class _Dice(object):     pass  class _6d(_Dice):     pass  class _12d(_Dice):     pass  class _Smarter:     pass  class _MagicalPonies:     pass  class _Samurai:     pass  class Foo(_6d, _Samurai):     pass  class Bar(_12d, _Smarter, _MagicalPonies):     pass   ...  # tests.py import unittest import garden  class GardenTests(unittest.TestCase):     pass  class PowertoolsTests(unittest.TestCase):     pass  class FooTests(unittest.TestCase):     pass  class BarTests(unittest.TestCase):     pass   ...  # interactive.py from garden import trim, bunch, Foo  f = trim(Foo()) bunch(f, Foo())   ...  # my_garden.py import garden from garden import powertools  class _Cowboy(garden._Samurai):     def hit():         return powertools.promise() and powertools.random() or 0  class Foo(_Cowboy, garden.Foo):     pass   It now becomes a bit more intuitive and self-documenting in which context certain components are meant to be used and it pans out ideally for naming distinct test cases as well as having a straightforward approach to how test modules map to actual modules under tests for purists.  I frequently find it viable to apply this approach to organizing a project's utility code. Quite often, people immediately rush and create a utils package and end up with 9 modules of which one has 120 LOC and the rest are two dozen LOC at best. I prefer to start with this and convert it to a package and create modules only for the beasts that truly deserve them:  # utils.py class socket(object):     @staticmethod     def check_if_port_available(port):         pass      @staticmethod     def get_free_port(port)         pass  class image(object):     @staticmethod     def to_rgb(image):         pass      @staticmethod     def to_cmyk(image):         pass      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/735975/static-methods-in-python", "Language": "Python", "Q_Title": "Static methods in Python?", "Q_Votes": "1414", "Q_Content": "    Is it possible to have static methods in Python so I can call them without initializing a class, like:  ClassName.StaticMethod ( )      ", "Tags": ["python", "static-methods"], "A_Votes": "9", "A_Content": "  Perhaps the simplest option is just to put those functions outside of the class:  class Dog(object):     def __init__(self, name):         self.name = name      def bark(self):         if self.name == \"Doggy\":             return barking_sound()         else:             return \"yip yip\"  def barking_sound():     return \"woof woof\"   Using this method, functions which modify or use internal object state (have side effects) can be kept in the class, and the reusable utility functions can be moved outside.  Let's say this file is called dogs.py. To use these, you'd call dogs.barking_sound() instead of dogs.Dog.barking_sound.  If you really need a static method to be part of the class, you can use the staticmethod decorator.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/735975/static-methods-in-python", "Language": "Python", "Q_Title": "Static methods in Python?", "Q_Votes": "1414", "Q_Content": "    Is it possible to have static methods in Python so I can call them without initializing a class, like:  ClassName.StaticMethod ( )      ", "Tags": ["python", "static-methods"], "A_Votes": "-1", "A_Content": "  I encounter this question from time to time.  The use case and example that I am fond of is:  jeffs@jeffs-desktop:/home/jeffs  $ python36 Python 3.6.1 (default, Sep  7 2017, 16:36:03)  [GCC 6.3.0 20170406] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import cmath >>> print(cmath.sqrt(-4)) 2j >>> >>> dir(cmath) ['__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'acos', 'acosh', 'asin', 'asinh', 'atan', 'atanh', 'cos', 'cosh', 'e', 'exp', 'inf', 'infj', 'isclose', 'isfinite', 'isinf', 'isnan', 'log', 'log10', 'nan', 'nanj', 'phase', 'pi', 'polar', 'rect', 'sin', 'sinh', 'sqrt', 'tan', 'tanh', 'tau'] >>>    It does not make sense to create an object of class cmath, because there is no state in a cmath object. However, cmath is a collection of methods that are all related in some way.  In my example above, all of the functions in cmath act on complex numbers in some way.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "2263", "A_Content": "  some_list[-1] is the shortest and most Pythonic.  In fact, you can do much more with this syntax. The some_list[-n] syntax gets the nth-to-last element. So some_list[-1] gets the last element, some_list[-2] gets the second to last, etc, all the way down to some_list[-len(some_list)], which gives you the first element.  You can also set list elements in this way. For instance:  >>> some_list = [1, 2, 3] >>> some_list[-1] = 5 # Set the last element >>> some_list[-2] = 3 # Set the second to last element >>> some_list [1, 3, 5]      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "185", "A_Content": "  If your str() or list() objects might end up being empty as so: astr = '' or alist = [], then you might want to use alist[-1:] instead of alist[-1] for object \"sameness\".  The significance of this is:  alist = [] alist[-1]   # will generate an IndexError exception whereas  alist[-1:]  # will return an empty list astr = '' astr[-1]    # will generate an IndexError exception whereas astr[-1:]   # will return an empty str   Where the distinction being made is that returning an empty list object or empty str object is more \"last element\"-like then an exception object.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "69", "A_Content": "  You can also do:  alist.pop()   It depends on what you want to do with your list because the pop() method will delete the last element.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "53", "A_Content": "  The simplest way to display last element in python is  >>> list[-1:] # returns indexed value     [3] >>> list[-1]  # returns value     3   there are many other method to achieve such a goal but these are short and sweet to use.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "22", "A_Content": "     In Python, how do you get the last element of a list?   To just get the last element,    without modifying the list, and  assuming you know the list has a last element (i.e. it is nonempty)    pass -1 to the subscript notation:  >>> a_list = ['zero', 'one', 'two', 'three'] >>> a_list[-1] 'three'   Explanation  Indexes and slices can take negative integers as arguments.  I have modified an example from the documentation to indicate which item in a sequence each index references, in this case, in the string \"Python\", -1 references the last element, the character, 'n':   +---+---+---+---+---+---+  | P | y | t | h | o | n |  +---+---+---+---+---+---+    0   1   2   3   4   5    -6  -5  -4  -3  -2  -1  >>> p = 'Python' >>> p[-1] 'n'   Assignment via iterable unpacking  This method may unnecessarily materialize a second list for the purposes of just getting the last element, but for the sake of completeness (and since it supports any iterable - not just lists):  >>> *head, last = a_list >>> last 'three'   The variable name, head is bound to the unnecessary newly created list:  >>> head ['zero', 'one', 'two']   If you intend to do nothing with that list, this would be more apropos:  *_, last = a_list   Or, really, if you know it's a list (or at least accepts subscript notation):  last = a_list[-1]   In a function  A commenter said:     I wish Python had a function for first() and last() like Lisp does... it would get rid of a lot of unnecessary lambda functions.   These would be quite simple to define:  def last(a_list):     return a_list[-1]  def first(a_list):     return a_list[0]   Or use operator.itemgetter:  >>> import operator >>> last = operator.itemgetter(-1) >>> first = operator.itemgetter(0)   In either case:  >>> last(a_list) 'three' >>> first(a_list) 'zero'   Special cases  If you're doing something more complicated, you may find it more performant to get the last element in slightly different ways.  If you're new to programming, you should avoid this section, because it couples otherwise semantically different parts of algorithms together. If you change your algorithm in one place, it may have an unintended impact on another line of code.   I try to provide caveats and conditions as completely as I can, but I may have missed something. Please comment if you think I'm leaving a caveat out.  Slicing  A slice of a list returns a new list - so we can slice from -1 to the end if we are going to want the element in a new list:  >>> a_slice = a_list[-1:] >>> a_slice ['three']   This has the upside of not failing if the list is empty:  >>> empty_list = [] >>> tail = empty_list[-1:] >>> if tail: ...     do_something(tail)   Whereas attempting to access by index raises an IndexError which would need to be handled:  >>> empty_list[-1] Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> IndexError: list index out of range   But again, slicing for this purpose should only be done if you need:   a new list created and the new list to be empty if the prior list was empty.   for loops  As a feature of Python, there is no inner scoping in a for loop.  If you're performing a complete iteration over the list already, the last element will still be referenced by the variable name assigned in the loop:  >>> def do_something(arg): pass >>> for item in a_list: ...     do_something(item) ...      >>> item 'three'   This is not semantically the last thing in the list. This is semantically the last thing that the name, item, was bound to.  >>> def do_something(arg): raise Exception >>> for item in a_list: ...     do_something(item) ... Traceback (most recent call last):   File \"<stdin>\", line 2, in <module>   File \"<stdin>\", line 1, in do_something Exception >>> item 'zero'   Thus this should only be used to get the last element if you    are already looping, and  you know the loop will finish (not break or exit due to errors), otherwise it will point to the last element referenced by the loop.   Getting and removing it  We can also mutate our original list by removing and returning the last element:  >>> a_list.pop(-1) 'three' >>> a_list ['zero', 'one', 'two']   But now the original list is modified.   (-1 is actually the default argument, so list.pop can be used without an index argument):  >>> a_list.pop() 'two'   Only do this if   you know the list has elements in it, or are prepared to handle the exception if it is empty, and you do intend to remove the last element from the list, treating it like a stack.    These are valid use-cases, but not very common.  Saving the rest of the reverse for later:  I don't know why you'd do it, but for completeness, since reversed returns an iterator (which supports the iterator protocol) you can pass its result to next:  >>> next(reversed([1,2,3])) 3   So it's like doing the reverse of this:  >>> next(iter([1,2,3])) 1   But I can't think of a good reason to do this, unless you'll need the rest of the reverse iterator later, which would probably look more like this:  reverse_iterator = reversed([1,2,3]) last_element = next(reverse_iterator)  use_later = list(reverse_iterator)   and now:  >>> use_later [2, 1] >>> last_element 3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "6", "A_Content": "  mylist = [ 1 , 2 , 3 , 4 , 5]  #------------------------------------ # Method-1 : Last index #------------------------------------  print(mylist[-1])   #------------------------------------ # Method-2 : Using len  #------------------------------------  print(mylist[len(mylist) - 1])   #------------------------------------ # Method-3 : Using pop, pop will remove the last  #            element from the list. #------------------------------------  print(mylist.pop())      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "5", "A_Content": "  if you want to just get the last value of list, you should use :  your_list[-1]   BUT if you want to get value and also remove it from list, you can use :  your_list.pop()   OR: you can pop with index too...  your_list.pop(-1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "4", "A_Content": "  Ok, but what about common in almost every language way items[len(items) - 1]? This is IMO the easiest way to get last element, because it does not require anything pythonic knowledge.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "4", "A_Content": "     some_list = [1, 2, 3]   Method 1:  some_list[-1]   Method 2:  **some_list.reverse()**   **some_list[0]**   Method 3:  some_list.pop()       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "3", "A_Content": "  Date: 2017-12-06  alist.pop()  I make an exhaustive cheatsheet of all list's 11 methods for your reference.  {'list_methods': {'Add': {'extend', 'append', 'insert'},                   'Entire': {'clear', 'copy'},                   'Search': {'count', 'index'},                   'Sort': {'reverse', 'sort'},                   'Subtract': {'remove', 'pop'}}}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "2", "A_Content": "  list[-1] will retrieve the last element of the list without changing the list. list.pop() will retrieve the last element of the list, but it will mutate/change the original list. Usually, mutating the original list is not recommended.  Alternatively, if, for some reason, you're looking for something less pythonic, you could use list[len(list)-1], assuming the list is not empty.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "0", "A_Content": "  You can also use the code below, if you do not want to get IndexError when the list is empty.  next(reversed(some_list), None)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "0", "A_Content": "  lst[-1] is the best approach, but with general iterables, consider more_itertools.last:  Code  import more_itertools as mit   mit.last([0, 1, 2, 3]) # 3  mit.last(iter([1, 2, 3])) # 3  mit.last([], \"some default\") # 'some default'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python", "Language": "Python", "Q_Title": "Getting the last element of a list in Python", "Q_Votes": "1430", "Q_Content": "    In Python, how do you get the last element of a list?     ", "Tags": ["python", "list", "indexing"], "A_Votes": "0", "A_Content": "  Python list supports negative indexes.  a = [1, 2, 3]  a[-1]   # gives the last elements with negative indexes  OR  a[len(a) - 1]   # gives the last elements len function     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "1944", "A_Content": "  General way  import sys sys.stdout.write('.')   You may also need to call  sys.stdout.flush()   to ensure stdout is flushed immediately.  Python 2.6+  From Python 2.6 you can import the print function from Python 3:  from __future__ import print_function   This allows you to use the Python 3 solution below.  Python 3  In Python 3, the print statement has been changed into a function. In Python 3, you can instead do:  print('.', end='')   This also works in Python 2, provided that you've used from __future__ import print_function.  If you are having trouble with buffering, you can flush the output by adding flush=True keyword argument:  print('.', end='', flush=True)   However, note that the flush keyword is not available in the version of the print function imported from __future__ in Python 2; it only works in Python 3, more specifically 3.3 and later. In earlier versions you'll still need to flush manually with a call to sys.stdout.flush().     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "274", "A_Content": "  It should be as simple as described at this link by Guido Van Rossum:  Re: How does one print without a c/r ?  http://legacy.python.org/search/hypermail/python-1992/0115.html     Is it possible to print something but not automatically have a   carriage return appended to it ?   Yes, append a comma after the last argument to print. For instance, this loop prints the numbers 0..9 on a line separated by spaces. Note the parameterless \"print\" that adds the final newline:  >>> for i in range(10): ...     print i, ... else: ...     print ... 0 1 2 3 4 5 6 7 8 9 >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "157", "A_Content": "  Note: The title of this question used to be something like \"How to printf in python?\"  Since people may come here looking for it based on the title, Python also supports printf-style substitution:  >>> strings = [ \"one\", \"two\", \"three\" ] >>> >>> for i in xrange(3): ...     print \"Item %d: %s\" % (i, strings[i]) ... Item 0: one Item 1: two Item 2: three   And, you can handily multiply string values:  >>> print \".\" * 10 ..........      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "86", "A_Content": "  Use the python3-style print function for python2.6+   (will also break any existing keyworded print statements in the same file.)  # for python2 to use the print() function, removing the print keyword from __future__ import print_function for x in xrange(10):     print('.', end='')   To not ruin all your python2 print keywords, create a separate printf.py file  # printf.py  from __future__ import print_function  def printf(str, *args):     print(str % args, end='')   Then, use it in your file  from printf import printf for x in xrange(10):     printf('.') print 'done' #..........done   More examples showing printf style  printf('hello %s', 'world') printf('%i %f', 10, 3.14) #hello world10 3.140000      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "38", "A_Content": "  This is not the answer to the question in the title, but it's the answer on how to print on the same line:  import sys for i in xrange(0,10):    sys.stdout.write(\".\")    sys.stdout.flush()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "22", "A_Content": "  The new (as of Python 3.0) print function has an optional end parameter that lets you modify the ending character. There's also sep for separator.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "16", "A_Content": "  You can just add , in the end of print function so it won't print on new line.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "14", "A_Content": "  Using functools.partial to create a new function called printf  >>> import functools  >>> printf = functools.partial(print, end=\"\")  >>> printf(\"Hello world\\n\") Hello world   Easy way to wrap a function with default parameters.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "13", "A_Content": "  print function in python automatically generates a new line. You could try:  print(\"Hello World\", end=\"\")     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "9", "A_Content": "  You can do it with end argument of print. In Python3, range() returns iterator and xrange() doesn't exist.  for i in range(10): print('.', end='')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "8", "A_Content": "  Code for Python 3.6.1  for i in range(0,10): print('.' , end=\"\")   Output  .......... >>>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "7", "A_Content": "  You can try:  import sys import time # Keeps the initial message in buffer. sys.stdout.write(\"\\rfoobar bar black sheep\") sys.stdout.flush() # Wait 2 seconds time.sleep(2) # Replace the message with a new one. sys.stdout.write(\"\\r\"+'hahahahaaa             ') sys.stdout.flush() # Finalize the new message by printing a return carriage. sys.stdout.write('\\n')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "6", "A_Content": "  you want to print something in for loop right;but you don't want it print in new line every time.. for example:   for i in range (0,5):    print \"hi\"   OUTPUT:     hi     hi     hi     hi     hi     but you want it to print like this: hi hi hi hi hi hi right???? just add a comma after print \"hi\"  Example:  for i in range (0,5):    print \"hi\", OUTPUT: hi hi hi hi hi      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "6", "A_Content": "  In Python 3, printing is a function. When you call  print ('hello world')   Python translates it to  print ('hello world', end = '\\n')   You can change end to whatever you want.  print ('hello world', end = '') print ('hello world', end = ' ')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "5", "A_Content": "  for i in xrange(0,10): print '.',   This will work for you. here comma (,) is important after print. Got help from : http://freecodeszone.blogspot.in/2016/11/how-to-print-in-python-without-newline.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "4", "A_Content": "  You can do the same in python3 as follows :  #!usr/bin/python  i = 0 while i<10 :     print('.',end='')     i = i+1   and execute it with python filename.py or python3 filename.py     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "4", "A_Content": "  @lenooh satisfied my query. I discovered this article while searching for 'python suppress newline'. I'm using IDLE3 on Raspberry Pi to develop Python 3.2 for PuTTY. I wanted to create a progress bar on the PuTTY command line. I didn't want the page scrolling away. I wanted a horizontal line to re-assure the user from freaking out that the program hasn't cruncxed to a halt nor been sent to lunch on a merry infinite loop - as a plea to 'leave me be, I'm doing fine, but this may take some time.' interactive message - like a progress bar in text.  The print('Skimming for', search_string, '\\b! .001', end='') initializes the message by preparing for the next screen-write, which will print three backspaces as \u232b\u232b\u232b rubout and then a period, wiping off '001' and extending the line of periods. After search_string parrots user input, the \\b! trims the exclamation point of my search_string text to back over the space which print() otherwise forces, properly placing the punctuation. That's followed by a space and the first 'dot' of the 'progress bar' which I'm simulating. Unnecessarily, the message is also then primed with the page number (formatted to a length of three with leading zeros) to take notice from the user that progress is being processed and which will also reflect the count of periods we will later build out to the right.  import sys  page=1 search_string=input('Search for?',) print('Skimming for', search_string, '\\b! .001', end='') sys.stdout.flush() # the print function with an end='' won't print unless forced while page:     # some stuff\u2026     # search, scrub, and build bulk output list[], count items,     # set done flag True     page=page+1 #done flag set in 'some_stuff'     sys.stdout.write('\\b\\b\\b.'+format(page, '03')) #<-- here's the progress bar meat     sys.stdout.flush()     if done: #( flag alternative to break, exit or quit)         print('\\nSorting', item_count, 'items')         page=0 # exits the 'while page' loop list.sort() for item_count in range(0, items)     print(list[item_count]) #print footers here  if not (len(list)==items):     print('#error_handler')   The progress bar meat is in the sys.stdout.write('\\b\\b\\b.'+format(page, '03')) line. First, to erase to the left, it backs up the cursor over the three numeric characters with the '\\b\\b\\b' as \u232b\u232b\u232b rubout and drops a new period to add to the progress bar length. Then it writes three digits of the page it has progressed to so far. Because sys.stdout.write() waits for a full buffer or the output channel to close, the sys.stdout.flush() forces the immediate write. sys.stdout.flush() is built into the end of print() which is bypassed with print(txt, end='' ). Then the code loops through its mundane time intensive operations while it prints nothing more until it returns here to wipe three digits back, add a period and write three digits again, incremented.  The three digits wiped and rewritten is by no means necessary - it's just a flourish which exemplifies sys.stdout.write() versus print(). You could just as easily prime with a period and forget the three fancy backslash-b \u232b backspaces (of course not writing formatted page counts as well) by just printing the period bar longer by one each time through - without spaces or newlines using just the sys.stdout.write('.'); sys.stdout.flush() pair.  Please note that the Raspberry Pi IDLE3 Python shell does not honor the backspace as \u232b rubout but instead prints a space, creating an apparent list of fractions instead.  \u2014(o=8> wiz     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "4", "A_Content": "  python 2.6+:  from __future__ import print_function # needs to be first statement in file print('.', end='')   python 3:  print('.', end='')   python <= 2.5:  import sys sys.stdout.write('.')   if extra space is OK after each print, in python 2  print '.',   misleading in python 2 - avoid:  print('.'), # avoid this if you want to remain sane # this makes it look like print is a function but it is not # this is the `,` creating a tuple and the parentheses enclose an expression # to see the problem, try: print('.', 'x'), # this will print `('.', 'x') `      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "4", "A_Content": "  i recently had the same problem..  i solved it by doing:  import sys, os  # reopen stdout with \"newline=None\". # in this mode, # input:  accepts any newline character, outputs as '\\n' # output: '\\n' converts to os.linesep  sys.stdout = os.fdopen(sys.stdout.fileno(), \"w\", newline=None)  for i in range(1,10):         print(i)   this works on both unix and windows ... have not tested it on macosx ...  hth     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "4", "A_Content": "  You will notice that all the above answers are correct. But I wanted to make a shortcut to always writing the \" end='' \" parameter in the end.  You could define a function like  def Print(*args,sep='',end='',file=None,flush=False):     print(*args,sep=sep,end=end,file=file,flush=flush)   It would accept all the number of parameters. Even it will accept all the other parameters like file, flush ,etc and with the same name.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "3", "A_Content": "  Many of these answers seem a little complicated. In Python 3.X you simply do this,  print(<expr>, <expr>, ..., <expr>, end=\" \")   The default value of end is \"\\n\". We are simply changing it to a space or you can also use end=\"\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "3", "A_Content": "  for i in xrange(0,10): print '\\b.',   This worked in both 2.7.8 & 2.5.2 (Canopy and OSX terminal, respectively) -- no module imports or time travel required.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "1", "A_Content": "  Here's a general way of printing without inserting a newline.  Python 3  for i in range(10):   print('.',end = '')   In Python 3 it is very simple to implement     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "0", "A_Content": "  ...you do not need to import any library. Just use the delete character:  BS=u'\\0008' # the unicode for \"delete\" character for i in range(10):print(BS+\".\"),   this removes the newline and the space (^_^)*     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/493386/how-to-print-without-newline-or-space", "Language": "Python", "Q_Title": "How to print without newline or space?", "Q_Votes": "1410", "Q_Content": "    The question is in the title.  I'd like to do it in  python. What I'd like to do in this example in c:  #include <stdio.h>  int main() {     int i;     for (i=0; i<10; i++) printf(\".\");     return 0; }   Output:  ..........   In Python:  >>> for i in xrange(0,10): print '.' . . . . . . . . . . >>> for i in xrange(0,10): print '.', . . . . . . . . . .   In Python print will add a \\n or a space, how can I avoid that? Now, it's just an example. Don't tell me I can first build a string then print it. I'd like to know how to \"append\" strings to stdout.     ", "Tags": ["python", "newline"], "A_Votes": "0", "A_Content": "  There are general two ways to do this:  Print without newline in Python 3.x  Append nothing after the print statement and remove '\\n' by using end=''  as:  >>> print('hello') hello  # appending '\\n' automatically >>> print('world') world # with previous '\\n' world comes down  # solution is: >>> print('hello', end='');print(' world'); # end with anything like end='-' but not '\\n' hello world # it seem correct output   Another Example in Loop:  for i in range(1,10):     print(i, end='.')   Print without newline in Python 2.x  Adding a trailing comma after print ignore '\\n'.  >>> print \"hello\",; print\" world\" hello world   Another Example in Loop:  for i in range(1,10):     print \"{} .\".format(i),   Hope this will help you. You can visit this link .     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "1694", "A_Content": "  There isn't a built-in flag yet, but you can use  pip list --outdated --format=freeze | grep -v '^\\-e' | cut -d = -f 1  | xargs -n1 pip install -U   Note: there are infinite potential variations for this. I'm trying to keep this answer short and simple, but please do suggest variations in the comments!  In older version of pip, you can use this instead:  pip freeze --local | grep -v '^\\-e' | cut -d = -f 1  | xargs -n1 pip install -U   The grep is to skip editable (\"-e\") package definitions, as suggested by @jawache. (Yes, you could replace grep+cut with sed or awk or perl or...).  The -n1 flag for xargs prevents stopping everything if updating one package fails (thanks @andsens).     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "519", "A_Content": "  You can use the following Python code. Unlike pip freeze, this will not print warnings and FIXME errors.  import pip from subprocess import call  packages = [dist.project_name for dist in pip.get_installed_distributions()] call(\"pip install --upgrade \" + ' '.join(packages), shell=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "513", "A_Content": "  To upgrade all local packages; you could use pip-review:  $ pip install pip-review $ pip-review --local --interactive     pip-review is a fork of pip-tools. See pip-tools issue mentioned by @knedlsepp. pip-review package works but pip-tools package no longer works.  pip-review works on Windows since version 0.5.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "192", "A_Content": "  Works on Windows. Should be good for others too. ($ is whatever directory you're in, in command prompt. eg. C:/Users/Username>)  do  $ pip freeze > requirements.txt   open the text file, replace the == with >=  then do  $ pip install -r requirements.txt --upgrade   If you have a problem with a certain package stalling the upgrade (numpy sometimes), just go to the directory ($), comment out the name (add a # before it) and run the upgrade again. You can later uncomment that section back. This is also great for copying python global environments.  I also like the pip-review method:  py2 $ pip install pip-review  $ pip-review --local --interactive  py3 $ pip3 install pip-review  $ py -3 -m pip_review --local --interactive   You can select 'a' to upgrade all packages; if one upgrade fails, run it again and it continues at the next one.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "91", "A_Content": "  Windows version after consulting excellent documentation for FOR by Rob van der Woude  for /F \"delims===\" %i in ('pip freeze -l') do pip install -U %i      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "70", "A_Content": "  You can just print the packages that are outdated  pip freeze | cut -d = -f 1 | xargs -n 1 pip search | grep -B2 'LATEST:'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "57", "A_Content": "  The following one-liner might prove of help:  pip list --format legacy --outdated | sed 's/(.*//g' | xargs -n1 pip install -U  xargs -n1 keeps going if an error occurs.   If you need more \"fine grained\" control over what is omitted and what raises an error you should not add the -n1 flag and explicitly define the errors to ignore, by \"piping\" the following line for each separate error:  | sed 's/^<First characters of the error>.*//'  Here is a working example:  pip list --format legacy --outdated | sed 's/(.*//g' | sed 's/^<First characters of the first error>.*//' | sed 's/^<First characters of the second error>.*//' | xargs pip install -U      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "42", "A_Content": "  This option seems to me more straightforward and readable:  pip install -U `pip list --outdated | awk '{ print $1}'`   (awk '{ print $1}' selects the first word of the line (separated by a space))  And this version allows for the suppression of warning message from pip list --outdated:  pip install -U `pip list --outdated | awk '!/Could not|ignored/ { print $1}'`   (awk '!/<pattern>/' removes line containing a given pattern. In my case the warning messages include \"Could not\" and \"ignored\" respectively)  This could also be used to tackle the coming default columns format:  pip install -U `pip list --format=columns --outdated | awk '!/Package|---/{ print $1}'`      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "33", "A_Content": "  This seems more concise.  pip list --outdated | cut -d ' ' -f1 | xargs -n1 pip install -U   Explanation:  pip list --outdated gets lines like these  urllib3 (1.7.1) - Latest: 1.15.1 [wheel] wheel (0.24.0) - Latest: 0.29.0 [wheel]   In cut -d ' ' -f1, -d ' ' sets \"space\" as the delimiter, -f1 means to get the first column.   So the above lines becomes:  urllib3 wheel   then pass them to xargs to run the command, pip install -U, with each line as appending arguments  -n1 limits the number of arguments passed to each command pip install -U to be 1     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "26", "A_Content": "  From https://github.com/cakebread/yolk :  $ pip install -U `yolk -U | awk '{print $1}' | uniq`   however you need to get yolk first:  $ sudo pip install -U yolk      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "25", "A_Content": "  More Robust Solution  For pip3 use this:  pip3 freeze --local |sed -rn 's/^([^=# \\t\\\\][^ \\t=]*)=.*/echo; echo Processing \\1 ...; pip3 install -U \\1/p' |sh   For pip, just remove the 3s as such:  pip freeze --local |sed -rn 's/^([^=# \\t\\\\][^ \\t=]*)=.*/echo; echo Processing \\1 ...; pip install -U \\1/p' |sh   OSX Oddity  OSX, as of July 2017, ships with a very old version of sed (a dozen years old).  To get extended regular expressions, use -E instead of -r in the solution above.  Solving Issues with Popular Solutions  This solution is well designed and tested1, whereas there are problems with even the most popular solutions.   Portability issues due to changing pip command line features Crashing of xargs because common pip or pip3 child process failures Crowded logging from the raw xargs output Relying on a Python-to-OS bridge while potentially upgrading it3   The above command uses the simplest and most portable pip syntax in combination with sed and sh to overcome these issues completely.  Details of sed operation can be scrutinized with the commented version2.    Details  [1] Tested and regularly used in a Linux 4.8.16-200.fc24.x86_64 cluster and tested on five other Linux/Unix flavors.  It also runs on Cygwin64 installed on Windows 10.  Testing on iOS is needed.  [2] To see the anatomy of the command more clearly, this is the exact equivalent of the above pip3 command with comments:   # match lines from pip's local package list output # that meet the following three criteria and pass the # package name to the replacement string in group 1. # (a) Do not start with invalid characters # (b) Follow the rule of no white space in the package names # (c) Immediately follow the package name with an equal sign sed=\"s/^([^=# \\t\\\\][^ \\t=]*)=.*\"  # separate the output of package upgrades with a blank line sed=\"$sed/echo\"  # indicate what package is being processed sed=\"$sed; echo Processing \\1 ...\"  # perform the upgrade using just the valid package name sed=\"$sed; pip3 install -U \\1\"  # output the commands sed=\"$sed/p\"  # stream edit the list as above # and pass the commands to a shell pip3 freeze --local |sed -rn \"$sed\" |sh   [3] Upgrading a Python or PIP component that is also used in the upgrading of a Python or PIP component can be a potential cause of a deadlock or package database corruption.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "23", "A_Content": "  One-liner version of @Ramana's answer.  python -c 'import pip, subprocess; [subprocess.call(\"pip install -U \" + d.project_name, shell=1) for d in pip.get_installed_distributions()]'   `     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "21", "A_Content": "  I had the same problem with upgrading. Thing is, i never upgrade all packages. I upgrade only what i need, because project may break.  Because there was no easy way for upgrading package by package, and updating the requirements.txt file, i wrote this pip-upgrader which also updates the versions in your requirements.txt file for the packages chosen (or all packages).  Installation  pip install pip-upgrader   Usage  Activate your virtualenv (important, because it will also install the new versions of upgraded packages in current virtualenv).  cd into your project directory, then run:  pip-upgrade   Advanced usage  If the requirements are placed in a non-standard location, send them as arguments:  pip-upgrade path/to/requirements.txt   If you already know what package you want to upgrade, simply send them as arguments:  pip-upgrade -p django -p celery -p dateutil   If you need to upgrade to  pre-release / post-release version, add --prerelease argument to your command.  Full disclosure: I wrote this package.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "15", "A_Content": "  when using a virtualenv and if you just want to upgrade packages added to your virtualenv, you may want to do:  pip install `pip freeze -l | cut --fields=1 -d = -` --upgrade      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "12", "A_Content": "  You can try this :  for i in ` pip list|awk -F ' ' '{print $1}'`;do pip install --upgrade $i;done      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "12", "A_Content": "  Windows Powershell solution  pip freeze | %{$_.split('==')[0]} | %{pip install --upgrade $_}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "12", "A_Content": "  The simplest and fastest solution that I found in the pip issue discussion is:  sudo -H pip install pipdate sudo -H pipdate   Source: https://github.com/pypa/pip/issues/3819     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "10", "A_Content": "  The rather amazing yolk makes this easy.  pip install yolk3k # don't install `yolk`, see https://github.com/cakebread/yolk/issues/35 yolk --upgrade   For more info on yolk: https://pypi.python.org/pypi/yolk/0.4.3  It can do lots of things you'll probably find useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "9", "A_Content": "  Sent through a pull-request to the pip folk; in the meantime use this pip library solution I wrote:  from pip import get_installed_distributions from pip.commands import install  install_cmd = install.InstallCommand()  options, args = install_cmd.parse_args([package.project_name                                         for package in                                         get_installed_distributions()])  options.upgrade = True install_cmd.run(options, args)  # Chuck this in a try/except and print as wanted      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "9", "A_Content": "  This seemed to work for me...  pip install -U $(pip list --outdated|awk '{printf $1\" \"}')   I used printf with a space afterwards to properly separate the package names.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "9", "A_Content": "  @Ramana's answer worked the best for me, of those here, but I had to add a few catches:  import pip for dist in pip.get_installed_distributions():     if 'site-packages' in dist.location:         try:             pip.call_subprocess(['pip', 'install', '-U', dist.key])         except Exception, exc:             print exc   The site-packages check excludes my development packages, because they are not located in the system site-packages directory. The try-except simply skips packages that have been removed from PyPI.  @endolith: I was hoping for an easy pip.install(dist.key, upgrade=True), too, but it doesn't look like pip was meant to be used by anything but the command line (the docs don't mention the internal API, and the pip developers didn't use docstrings).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "6", "A_Content": "  My script:  pip list --outdated --format=legacy | cut -d ' ' -f1 | xargs -n1 pip install --upgrade      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "6", "A_Content": "  Isn't this more effective?  pip3 list -o | grep -v -i warning | cut -f1 -d' ' | tr \" \" \"\\n\" | awk '{if(NR>=3)print}' | cut -d' ' -f1 | xargs -n1 pip3 install -U     pip list -o lists outdated packages; grep -v -i warning inverted match on warning to avoid errors when updating cut -f1 -d1' ' returns the first word - the name of the outdated package; tr \"\\n|\\r\" \" \" converts the multiline result from cut into a single-line, space-separated list; awk '{if(NR>=3)print}' skips header lines  cut -d' ' -f1 fetches the first column xargs -n1 pip install -U takes 1 argument from the pipe left of it, and passes it to the command to upgrade the list of packages.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "5", "A_Content": "  How about:  pip install -r <(pip freeze) --upgrade      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "5", "A_Content": "  use awk update packges:  pip install -U $(pip freeze | awk -F'[=]' '{print $1}')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "4", "A_Content": "  Here is my variation on rbp's answer, which bypasses \"editable\" and development distributions. It shares two flaws of the original: it re-downloads and reinstalls unnecessarily; and an error on one package will prevent the upgrade of every package after that.  pip freeze |sed -ne 's/==.*//p' |xargs pip install -U --   Related bug reports, a bit disjointed after the migration from bitbucket:   https://github.com/pypa/pip/issues/49 https://github.com/pypa/pip/issues/59      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "4", "A_Content": "  I have tried the code of Ramana and I found out on Ubuntu you have to write sudo for each command. Here is my script which works fine on ubuntu 13.10:  #!/usr/bin/env python import pip from subprocess import call  for dist in pip.get_installed_distributions():     call(\"sudo pip install --upgrade \" + dist.project_name, shell=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "4", "A_Content": "  here is another way of doing with a script in python  import pip, tempfile, contextlib  with tempfile.TemporaryFile('w+') as temp:     with contextlib.redirect_stdout(temp):         pip.main(['list','-o'])     temp.seek(0)     for line in temp:         pk = line.split()[0]         print('--> updating',pk,'<--')         pip.main(['install','-U',pk])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "4", "A_Content": "  Here is a scripts that only updates the outdated packages.      import os, sys from subprocess import check_output, call  file = check_output([\"pip.exe\",  \"list\", \"--outdated\", \"--format=legacy\"]) line = str(file).split()  for distro in line[::6]:     call(\"pip install --upgrade \" + distro, shell=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2720014/upgrading-all-packages-with-pip", "Language": "Python", "Q_Title": "Upgrading all packages with pip", "Q_Votes": "1457", "Q_Content": "    Is it possible to upgrade all Python packages at one time with pip?  Note that there is a feature request for this on the official issue tracker.     ", "Tags": ["python", "pip"], "A_Votes": "4", "A_Content": "  I've been using pur lately. It's simple and to the point. It updates your requirements.txt file to reflect the upgrades and you can then upgrade with your requirements.txt file as usual.  $ pip install pur ... Successfully installed pur-4.0.1  $ pur Updated boto3: 1.4.2 -> 1.4.4 Updated Django: 1.10.4 -> 1.10.5 Updated django-bootstrap3: 7.1.0 -> 8.1.0 All requirements up-to-date.  $ pip install --upgrade -r requirements.txt Successfully installed Django-1.10.5 ...      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "1008", "A_Content": "  It's a part of a package. Here's the documentation.     The __init__.py files are required to make Python treat the directories as containing packages; this is done to prevent directories with a common name, such as string, from unintentionally hiding valid modules that occur later (deeper) on the module search path. In the simplest case, __init__.py can just be an empty file, but it can also execute initialization code for the package or set the __all__ variable, described later.      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "608", "A_Content": "  Files named __init__.py are used to mark directories on disk as Python package directories. If you have the files  mydir/spam/__init__.py mydir/spam/module.py   and mydir is on your path, you can import the code in module.py as  import spam.module   or   from spam import module   If you remove the __init__.py file, Python will no longer look for submodules inside that directory, so attempts to import the module will fail.  The __init__.py file is usually empty, but can be used to export selected portions of the package under more convenient name, hold convenience functions, etc. Given the example above, the contents of the init module can be accessed as   import spam   based on this     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "369", "A_Content": "  In addition to labeling a directory as a Python package and defining __all__, __init__.py allows you to define any variable at the package level. Doing so is often convenient if a package defines something that will be imported frequently, in an API-like fashion. This pattern promotes adherence to the Pythonic \"flat is better than nested\" philosophy.  An example  Here is an example from one of my projects, in which I frequently import a sessionmaker called Session to interact with my database. I wrote a \"database\" package with a few modules:  database/     __init__.py     schema.py     insertions.py     queries.py   My __init__.py contains the following code:  import os  from sqlalchemy.orm import sessionmaker from sqlalchemy import create_engine  engine = create_engine(os.environ['DATABASE_URL']) Session = sessionmaker(bind=engine)   Since I define Session here, I can start a new session using the syntax below. This code would be the same executed from inside or outside of the \"database\" package directory.  from database import Session session = Session()   Of course, this is a small convenience -- the alternative would be to define Session in a new file like \"create_session.py\" in my database package, and start new sessions using:  from database.create_session import Session session = Session()   Further reading  There is a pretty interesting reddit thread covering appropriate uses of __init__.py here:  http://www.reddit.com/r/Python/comments/1bbbwk/whats_your_opinion_on_what_to_include_in_init_py/  The majority opinion seems to be that __init__.py files should be very thin to avoid violating the \"explicit is better than implicit\" philosophy.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "107", "A_Content": "  There are 2 main reasons for __init__.py   For convenience: the other users will not need to know your functions' exact location in your package hierarchy.  your_package/   __init__.py   file1.py/   file2.py/     ...   fileN.py  # in __init__.py from file1 import * from file2 import * ... from fileN import *  # in file1.py def add():     pass   then others can call add() by   from your_package import add   without knowing file1, like  from your_package.file1 import add  If you want something to be initialized; for example, logging (which should be put in the top level):  import logging.config logging.config.dictConfig(Your_logging_config)       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "87", "A_Content": "  The __init__.py file makes Python treat directories containing it as modules.   Furthermore, this is the first file to be loaded in a module, so you can use it to execute code that you want to run each time a module is loaded, or specify the submodules to be exported.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "48", "A_Content": "  Since Python 3.3, __init__.py is no longer required to define directories as importable Python packages.  Check PEP 420: Implicit Namespace Packages:     Native support for package directories that don\u2019t require __init__.py marker files and can automatically span multiple path segments (inspired by various third party approaches to namespace packages, as described in PEP 420)   Here's the test:    $ mkdir -p /tmp/test_init $ touch /tmp/test_init/module.py /tmp/test_init/__init__.py $ tree -at /tmp/test_init /tmp/test_init \u251c\u2500\u2500 module.py \u2514\u2500\u2500 __init__.py $ python3  >>> import sys >>> sys.path.insert(0, '/tmp') >>> from test_init import module >>> import test_init.module  $ rm -f /tmp/test_init/__init__.py $ tree -at /tmp/test_init /tmp/test_init \u2514\u2500\u2500 module.py $ python3  >>> import sys >>> sys.path.insert(0, '/tmp') >>> from test_init import module >>> import test_init.module   references: https://docs.python.org/3/whatsnew/3.3.html#pep-420-implicit-namespace-packages https://www.python.org/dev/peps/pep-0420/ Is __init__.py not required for packages in Python 3?       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "45", "A_Content": "  In Python the definition of package is very simple. Like Java the hierarchical structure and the directory structure are the same. But you have to have __init__.py in a package. I will explain the __init__.py file with the example below:  package_x/ |--  __init__.py |--    subPackage_a/ |------  __init__.py |------  module_m1.py |--    subPackage_b/ |------  __init__.py |------  module_n1.py |------  module_n2.py |------  module_n3.py   __init__.py can be empty, as long as it exists. It indicates that the directory should be regarded as a package. Of course, __init__.py can also set the appropriate content.  If we add a function in module_n1:  def function_X():     print \"function_X in module_n1\"     return   After running:  >>>from package_x.subPackage_b.module_n1 import function_X >>>function_X()  function_X in module_n1    Then we followed the hierarchy package and called module_n1 the function. We can use __init__.py in subPackage_b like this:  __all__ = ['module_n2', 'module_n3']   After running:   >>>from package_x.subPackage_b import *  >>>module_n1.function_X()  Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ImportError: No module named module_n1   Hence using * importing, module package is subject to __init__.py content.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "35", "A_Content": "  __init__.py will treat the directory it is in as a loadable module.  For people who prefer reading code, I put Two-Bit Alchemist's comment here.  $ find /tmp/mydir/ /tmp/mydir/ /tmp/mydir//spam /tmp/mydir//spam/__init__.py /tmp/mydir//spam/module.py $ cd ~ $ python >>> import sys >>> sys.path.insert(0, '/tmp/mydir') >>> from spam import module >>> module.myfun(3) 9 >>> exit() $  $ rm /tmp/mydir/spam/__init__.py* $  $ python >>> import sys >>> sys.path.insert(0, '/tmp/mydir') >>> from spam import module Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> ImportError: No module named spam >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "30", "A_Content": "  What is __init__.py used for?  The primary use of __init__.py is to initialize Python packages. The easiest way to demonstrate this is to take a look at the structure of a standard Python module.  package/     __init__.py     file.py     file2.py     file3.py     subpackage/         __init__.py         submodule1.py         submodule2.py   As you can see in the structure above the inclusion of the __init__.py file in a directory indicates to the Python interpreter that the directory should be treated like a Python package  What goes in __init__.py?  __init__.py can be an empty file but it is often used to perform setup needed for the package(import things, load things into path, etc).  One common thing to do in your __init__.py is to import selected Classes, functions, etc into the package level so they can be convieniently imported from the package.  In example above we can say that file.py has the Class File. So without anything in our __init__.py you would import with this syntax:  from package.file import File   However you can import File into your __init__.py to make it available at the package level:  # in your __init__.py from file import File  # now import File from package from package import File   Another thing to do is at the package level make subpackages/modules available with the __all__ variable. When the interpeter sees an __all__ variable defined in an __init__.py it imports the modules listed in the __all__ variable when you do:  from package import *   __all__ is a list containing the names of modules that you want to be imported with import * so looking at our above example again if we wanted to import the submodules in subpackage the __all__ variable in subpackage/__init__.py would be:  __all__ = ['submodule1', 'submodule2']   With the __all__ variable populated like that, when you perform  from subpackage import *   it would import submodule1 and submodule2.  As you can see __init__.py can be very useful besides its primary function of indicating that a directory is a module.  Reference     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "25", "A_Content": "  It facilitates importing other python files. When you placed this file in a directory (say stuff)containing other py files, then you can do something like import stuff.other.  root\\     stuff\\          other.py      morestuff\\          another.py   Without this __init__.py inside the directory stuff, you couldn't import other.py, because Python doesn't know where the source code for stuff is and unable to recognize it as a package.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/448271/what-is-init-py-for", "Language": "Python", "Q_Title": "What is __init__.py for?", "Q_Votes": "1462", "Q_Content": "    What is __init__.py for in a Python source directory?     ", "Tags": ["python", "module"], "A_Votes": "8", "A_Content": "  Although Python works without an __init__.py file you should still include one.  It specifies a package should be treated as a module, so therefore include it (even if it is empty).  There is also a case where you may actually use an __init__.py file:    Imagine you had the following file structure:  main_methods      |- methods.py   And methods.py contained this:  def foo():     return 'foo'   To use foo() you would need one of the following:  from main_methods.methods import foo # Call with foo() from main_methods import methods # Call with methods.foo() import main_methods.methods # Call with main_methods.methods.foo()   Maybe there you need (or want) to keep methods.py inside main_methods (runtimes/dependencies for example) but you only want to import main_methods.    If you changed the name of methods.py to __init__.py then you could use foo() by just importing main_methods:  import main_methods print(main_methods.foo()) # Prints 'foo'   This works because __init__.py is treated as part of the package.    Some Python packages actually do this.  An example is with JSON, where running import json is actually importing __init__.py from the json package (see the package file structure here):     Source code: Lib/json/__init__.py      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "1048", "A_Content": "     str.count(sub[, start[, end]])      Return the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional arguments start and end are interpreted as in slice notation.   >>> sentence = 'Mary had a little lamb' >>> sentence.count('a') 4      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "118", "A_Content": "  You can use count() :  >>> 'Mary had a little lamb'.count('a') 4      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "80", "A_Content": "  As other answers said, using the string method count() is probably the simplest, but if you're doing this frequently, check out collections.Counter:  from collections import Counter str = \"Mary had a little lamb\" counter = Counter(str) print counter['a']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "46", "A_Content": "  Regular expressions maybe?  import re my_string = \"Mary had a little lamb\" len(re.findall(\"a\", my_string))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "23", "A_Content": "  myString.count('a');   more info here     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "14", "A_Content": "  \"aabc\".count(\"a\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "8", "A_Content": "  Regular expressions are very useful if you want case-insensitivity (and of course all the power of regex).  my_string = \"Mary had a little lamb\" # simplest solution, using count, is case-sensitive my_string.count(\"m\")   # yields 1 import re # case-sensitive with regex len(re.findall(\"m\", my_string)) # three ways to get case insensitivity - all yield 2 len(re.findall(\"(?i)m\", my_string)) len(re.findall(\"m|M\", my_string)) len(re.findall(re.compile(\"m\",re.IGNORECASE), my_string))   Be aware that the regex version takes on the order of ten times as long to run, which will likely be an issue only if my_string is tremendously long, or the code is inside a deep loop.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "5", "A_Content": "  a = 'have a nice day' symbol = 'abcdefghijklmnopqrstuvwxyz' for key in symbol:     print key, a.count(key)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "5", "A_Content": "  str.count(a) is the best solution to count a single character in a string. But if you need to count more characters you would have to read the whole string as many times as characters you want to count.  A better approach for this job would be:  from collections import defaultdict  text = 'Mary had a little lamb' chars = defaultdict(int)  for char in text:     chars[char] += 1   So you'll have a dict that returns the number of occurrences of every letter in the string and 0 if it isn't present.  >>>chars['a'] 4 >>>chars['x'] 0     For a case insensitive counter you could override the mutator and accessor methods by subclassing defaultdict (base class' ones are read-only):  class CICounter(defaultdict):     def __getitem__(self, k):         return super().__getitem__(k.lower())      def __setitem__(self, k, v):         super().__setitem__(k.lower(), v)   chars = CICounter(int)  for char in text:     chars[char] += 1  >>>chars['a'] 4 >>>chars['M'] 2 >>>chars['x'] 0      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "2", "A_Content": "  str = \"count a character occurance\"  List = list(str) print (List) Uniq = set(List) print (Uniq)  for key in Uniq:     print (key, str.count(key))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "2", "A_Content": "  count is definitely the most concise and efficient way of counting the occurrence of a character in a string but I tried to come up with a solution using lambda, something like this :  sentence = 'Mary had a little lamb' sum(map(lambda x : 1 if 'a' in x else 0, sentence))   This will result in :  4   Also, there is one more advantage to this is if the sentence is a list of sub-strings containing same characters as above, then also this gives the correct result because of the use of in. Have a look :  sentence = ['M', 'ar', 'y', 'had', 'a', 'little', 'l', 'am', 'b'] sum(map(lambda x : 1 if 'a' in x else 0, sentence))   This also results in :  4   But Of-course this will work only when checking occurrence of single character such as 'a' in this particular case.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "2", "A_Content": "  This easy and straight forward function might help:  def check_freq(str):     freq = {}     for c in str:        freq[c] = str.count(c)     return freq  check_freq(\"abbabcbdbabdbdbabababcbcbab\") {'a': 7, 'b': 14, 'c': 3, 'd': 3}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "1", "A_Content": "  \"Without using count to find you want character in string\" method.  import re  def count(s, ch):     pass  def main():     s = raw_input (\"Enter strings what you like, for example, 'welcome': \")       ch = raw_input (\"Enter you want count characters, but best result to find one character: \" )     print ( len (re.findall ( ch, s ) ) )  main()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "0", "A_Content": "  spam = 'have a nice day' var = 'd'   def count(spam, var):     found = 0     for key in spam:         if key == var:             found += 1     return found count(spam, var) print 'count %s is: %s ' %(var, count(spam, var))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "0", "A_Content": "  No more than this IMHO - you can add the upper or lower methods  def count_letter_in_str(string,letter):     return string.count(letter)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "0", "A_Content": "  Using Count:   string = \"count the number of counts in string to count from.\" x = string.count(\"count\")   x = 2.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1155617/count-the-number-occurrences-of-a-character-in-a-string", "Language": "Python", "Q_Title": "Count the number occurrences of a character in a string", "Q_Votes": "742", "Q_Content": "    What's the simplest way to count the number of occurrences of a character in a string?  e.g. count the number of times 'a' appears in 'Mary had a little lamb'     ", "Tags": ["python", "string", "count"], "A_Votes": "-2", "A_Content": "  This will give you the occurrence of each characters in a string. O/P is also in string format:  def count_char(string1): string2=\"\" lst=[] lst1=[] for i in string1:     count=0     if i not in lst:         for j in string1:             if i==j:                 count+=1         lst1.append(i)         lst1.append(count)     lst.append(i)  string2=''.join(str(x) for x in lst1) return string2   print count_char(\"aabbacddaabbdsrchhdsdg\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "476", "A_Content": "  I routinely use tens of gigabytes of data in just this fashion e.g. I have tables on disk that I read via queries, create data and append back.  It's worth reading the docs and late in this thread for several suggestions for how to store your data.  Details which will affect how you store your data, like: Give as much detail as you can; and I can help you develop a structure.   Size of data, # of rows, columns, types of columns; are you appending rows, or just columns?  What will typical operations look like. E.g. do a query on columns to select a bunch of rows and specific columns, then do an operation (in-memory), create new columns, save these. (Giving a toy example could enable us to offer more specific recommendations.) After that processing, then what do you do? Is step 2 ad hoc, or repeatable? Input flat files: how many, rough total size in Gb. How are these organized e.g. by records? Does each one contains different fields, or do they have some records per file with all of the fields in each file? Do you ever select subsets of rows (records) based on criteria (e.g. select the rows with field A > 5)? and then do something, or do you just select fields A, B, C with all of the records (and then do something)? Do you 'work on' all of your columns (in groups), or are there a good proportion that you may only use for reports (e.g. you want to keep the data around, but don't need to pull in that column explicity until final results time)?   Solution  Ensure you have pandas at least 0.10.1 installed.  Read iterating files chunk-by-chunk and multiple table queries.  Since pytables is optimized to operate on row-wise (which is what you query on), we will create a table for each group of fields. This way it's easy to select a small group of fields (which will work with a big table, but it's more efficient to do it this way... I think I may be able to fix this limitation in the future... this is more intuitive anyhow): (The following is pseudocode.)  import numpy as np import pandas as pd  # create a store store = pd.HDFStore('mystore.h5')  # this is the key to your storage: #    this maps your fields to a specific group, and defines  #    what you want to have as data_columns. #    you might want to create a nice class wrapping this #    (as you will want to have this map and its inversion)   group_map = dict(     A = dict(fields = ['field_1','field_2',.....], dc = ['field_1',....,'field_5']),     B = dict(fields = ['field_10',......        ], dc = ['field_10']),     .....     REPORTING_ONLY = dict(fields = ['field_1000','field_1001',...], dc = []),  )  group_map_inverted = dict() for g, v in group_map.items():     group_map_inverted.update(dict([ (f,g) for f in v['fields'] ]))   Reading in the files and creating the storage (essentially doing what append_to_multiple does):  for f in files:    # read in the file, additional options hmay be necessary here    # the chunksize is not strictly necessary, you may be able to slurp each     # file into memory in which case just eliminate this part of the loop     # (you can also change chunksize if necessary)    for chunk in pd.read_table(f, chunksize=50000):        # we are going to append to each table by group        # we are not going to create indexes at this time        # but we *ARE* going to create (some) data_columns         # figure out the field groupings        for g, v in group_map.items():              # create the frame for this group              frame = chunk.reindex(columns = v['fields'], copy = False)                   # append it              store.append(g, frame, index=False, data_columns = v['dc'])   Now you have all of the tables in the file (actually you could store them in separate files if you wish, you would prob have to add the filename to the group_map, but probably this isn't necessary).  This is how you get columns and create new ones:  frame = store.select(group_that_I_want) # you can optionally specify: # columns = a list of the columns IN THAT GROUP (if you wanted to #     select only say 3 out of the 20 columns in this sub-table) # and a where clause if you want a subset of the rows  # do calculations on this frame new_frame = cool_function_on_frame(frame)  # to 'add columns', create a new group (you probably want to # limit the columns in this new_group to be only NEW ones # (e.g. so you don't overlap from the other tables) # add this info to the group_map store.append(new_group, new_frame.reindex(columns = new_columns_created, copy = False), data_columns = new_columns_created)   When you are ready for post_processing:  # This may be a bit tricky; and depends what you are actually doing. # I may need to modify this function to be a bit more general: report_data = store.select_as_multiple([groups_1,groups_2,.....], where =['field_1>0', 'field_1000=foo'], selector = group_1)   About data_columns, you don't actually need to define ANY data_columns; they allow you to sub-select rows based on the column. E.g. something like:  store.select(group, where = ['field_1000=foo', 'field_1001>0'])   They may be most interesting to you in the final report generation stage (essentially a data column is segregated from other columns, which might impact efficiency somewhat if you define a lot).  You also might want to:   create a function which takes a list of fields, looks up the groups in the groups_map, then selects these and concatenates the results so you get the resulting frame (this is essentially what select_as_multiple does). This way the structure would be pretty transparent to you. indexes on certain data columns (makes row-subsetting much faster). enable compression.   Let me know when you have questions!     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "102", "A_Content": "  I think the answers above are missing a simple approach that I've found very useful.   When I have a file that is too large to load in memory, I break up the file into multiple smaller files (either by row or cols)  Example: In case of 30 days worth of trading data of ~30GB size, I break it into a file per day of ~1GB size. I subsequently process each file separately and aggregate results at the end  One of the biggest advantages is that it allows parallel processing of the files (either multiple threads or processes)  The other advantage is that file manipulation (like adding/removing dates in the example) can be accomplished by regular shell commands, which is not be possible in more advanced/complicated file formats  This approach doesn't cover all scenarios, but is very useful in a lot of them     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "54", "A_Content": "  If your datasets are between 1 and 20GB, you should get a workstation with 48GB of RAM. Then Pandas can hold the entire dataset in RAM. I know its not the answer you're looking for here, but doing scientific computing on a notebook with 4GB of RAM isn't reasonable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "50", "A_Content": "  There is now, two years after the question, an 'out-of-core' pandas equivalent: dask. It is excellent! Though it does not support all of pandas functionality, you can get really far with it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "47", "A_Content": "  I know this is an old thread but I think the Blaze library is worth checking out.  It's built for these types of situations.  From the docs:  Blaze extends the usability of NumPy and Pandas to distributed and out-of-core computing. Blaze provides an interface similar to that of the NumPy ND-Array or Pandas DataFrame but maps these familiar interfaces onto a variety of other computational engines like Postgres or Spark.  Edit: By the way, it's supported by ContinuumIO and Travis Oliphant, author of NumPy.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "43", "A_Content": "  This is the case for pymongo.  I have also prototyped using sql server, sqlite, HDF, ORM (SQLAlchemy) in python.  First and foremost pymongo is a document based DB, so each person would be a document (dict of attributes).  Many people form a collection and you can have many collections (people, stock market, income).  pd.dateframe -> pymongo Note: I use the chunksize in read_csv to keep it to 5 to 10k records(pymongo drops the socket if larger)  aCollection.insert((a[1].to_dict() for a in df.iterrows()))   querying: gt = greater than...  pd.DataFrame(list(mongoCollection.find({'anAttribute':{'$gt':2887000, '$lt':2889000}})))   .find() returns an iterator so I commonly use ichunked to chop into smaller iterators.    How about a join since I normally get 10 data sources to paste together:  aJoinDF = pandas.DataFrame(list(mongoCollection.find({'anAttribute':{'$in':Att_Keys}})))   then (in my case sometimes I have to agg on aJoinDF first before its \"mergeable\".)  df = pandas.merge(df, aJoinDF, on=aKey, how='left')   And you can then write the new info to your main collection via the update method below. (logical collection vs physical datasources).  collection.update({primarykey:foo},{key:change})   On smaller lookups, just denormalize.  For example, you have code in the document and you just add the field code text and do a dict lookup as you create documents.  Now you have a nice dataset based around a person, you can unleash your logic on each case and make more attributes. Finally you can read into pandas your 3 to memory max key indicators and do pivots/agg/data exploration.  This works for me for 3 million records with numbers/big text/categories/codes/floats/...  You can also use the two methods built into MongoDB (MapReduce and aggregate framework). See here for more info about the aggregate framework, as it seems to be easier than MapReduce and looks handy for quick aggregate work.  Notice I didn't need to define my fields or relations, and I can add items to a document.  At the current state of the rapidly changing numpy, pandas, python toolset, MongoDB helps me just get to work :)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "36", "A_Content": "  I spotted this a little late, but I work with a similar problem (mortgage prepayment models). My solution has been to skip the pandas HDFStore layer and use straight pytables. I save each column as an individual HDF5 array in my final file.  My basic workflow is to first get a CSV file from the database. I gzip it, so it's not as huge. Then I convert that to a row-oriented HDF5 file, by iterating over it in python, converting each row to a real data type, and writing it to a HDF5 file. That takes some tens of minutes, but it doesn't use any memory, since it's only operating row-by-row. Then I \"transpose\" the row-oriented HDF5 file into a column-oriented HDF5 file.  The table transpose looks like:  def transpose_table(h_in, table_path, h_out, group_name=\"data\", group_path=\"/\"):     # Get a reference to the input data.     tb = h_in.getNode(table_path)     # Create the output group to hold the columns.     grp = h_out.createGroup(group_path, group_name, filters=tables.Filters(complevel=1))     for col_name in tb.colnames:         logger.debug(\"Processing %s\", col_name)         # Get the data.         col_data = tb.col(col_name)         # Create the output array.         arr = h_out.createCArray(grp,                                  col_name,                                  tables.Atom.from_dtype(col_data.dtype),                                  col_data.shape)         # Store the data.         arr[:] = col_data     h_out.flush()   Reading it back in then looks like:  def read_hdf5(hdf5_path, group_path=\"/data\", columns=None):     \"\"\"Read a transposed data set from a HDF5 file.\"\"\"     if isinstance(hdf5_path, tables.file.File):         hf = hdf5_path     else:         hf = tables.openFile(hdf5_path)      grp = hf.getNode(group_path)     if columns is None:         data = [(child.name, child[:]) for child in grp]     else:         data = [(child.name, child[:]) for child in grp if child.name in columns]      # Convert any float32 columns to float64 for processing.     for i in range(len(data)):         name, vec = data[i]         if vec.dtype == np.float32:             data[i] = (name, vec.astype(np.float64))      if not isinstance(hdf5_path, tables.file.File):         hf.close()     return pd.DataFrame.from_items(data)   Now, I generally run this on a machine with a ton of memory, so I may not be careful enough with my memory usage. For example, by default the load operation reads the whole data set.  This generally works for me, but it's a bit clunky, and I can't use the fancy pytables magic.  Edit: The real advantage of this approach, over the array-of-records pytables default, is that I can then load the data into R using h5r, which can't handle tables. Or, at least, I've been unable to get it to load heterogeneous tables.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "12", "A_Content": "  One more variation  Many of the operations done in pandas can also be done as a db query (sql, mongo)  Using a RDBMS or mongodb allows you to perform some of the aggregations in the DB Query (which is optimized for large data, and uses cache and indexes efficiently)  Later, you can perform post processing using pandas.  The advantage of this method is that you gain the DB optimizations for working with large data, while still defining the logic in a high level declarative syntax - and not having to deal with the details of deciding what to do in memory and what to do out of core.  And although the query language and pandas are different, it's usually not complicated to translate part of the logic from one to another.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "11", "A_Content": "  One trick I found helpful for \"large data\" use cases is to reduce the volume of the data by reducing float precision to 32-bit. It's not applicable in all cases, but in many applications 64-bit precision is overkill and the 2x memory savings are worth it. To make an obvious point even more obvious:  >>> df = pd.DataFrame(np.random.randn(int(1e8), 5)) >>> df.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 100000000 entries, 0 to 99999999 Data columns (total 5 columns): ... dtypes: float64(5) memory usage: 3.7 GB  >>> df.astype(np.float32).info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 100000000 entries, 0 to 99999999 Data columns (total 5 columns): ... dtypes: float32(5) memory usage: 1.9 GB      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "8", "A_Content": "  As noted by others, after some years an 'out-of-core' pandas equivalent has emerged: dask. Though dask is not a drop-in replacement of pandas and all of its functionality it stands out for several reasons:  Dask is a flexible parallel computing library for analytic computing that is optimized for dynamic task scheduling for interactive computational workloads of \u201cBig Data\u201d collections like parallel arrays, dataframes, and lists that extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments and scales from laptops to clusters.     Dask emphasizes the following virtues:           Familiar: Provides parallelized NumPy array and Pandas DataFrame    objects   Flexible: Provides a task scheduling interface for more    custom workloads and integration with other projects.   Native: Enables distributed computing in Pure Python with access to the    PyData stack.   Fast: Operates with low overhead, low latency, and    minimal serialization necessary for fast numerical algorithms     Scales up: Runs resiliently on clusters with 1000s of cores   Scales    down: Trivial to set up and run on a laptop in a single process     Responsive: Designed with interactive computing in mind it provides    rapid feedback and diagnostics to aid humans      and to add a simple code sample:  import dask.dataframe as dd df = dd.read_csv('2015-*-*.csv') df.groupby(df.user_id).value.mean().compute()   replaces some pandas code like this:  import pandas as pd df = pd.read_csv('2015-01-01.csv') df.groupby(df.user_id).value.mean()   and, especially noteworthy, provides through the concurrent.futures interface a general for the submission of custom tasks:  from dask.distributed import Client client = Client('scheduler:port')  futures = [] for fn in filenames:     future = client.submit(load, fn)     futures.append(future)  summary = client.submit(summarize, futures) summary.result()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "7", "A_Content": "  Consider Ruffus if you go the simple path of creating a data pipeline which is broken down into multiple smaller files.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "5", "A_Content": "  It is worth mentioning here Ray as well, it's a distributed computation framework, that has it's own implementation for pandas in a distributed way.    Just replace the pandas import, and the code should work as is:  # import pandas as pd import ray.dataframe as pd  #use pd as usual   can read more details here:  https://rise.cs.berkeley.edu/blog/pandas-on-ray/     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas", "Language": "Python", "Q_Title": "\u201cLarge data\u201d work flows using pandas", "Q_Votes": "745", "Q_Content": "    I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.  One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.  My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:  What are some best-practice workflows for accomplishing the following:   Loading flat files into a permanent, on-disk database structure Querying that database to retrieve data to feed into a pandas data structure Updating the database after manipulating pieces in pandas   Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\".  Edit -- an example of how I would like this to work:   Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. I would create new columns by performing various operations on the selected columns. I would then have to append these new columns into the database structure.   I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.  Edit -- Responding to Jeff's questions specifically:   I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset. Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.   It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).     ", "Tags": ["python", "mongodb", "pandas", "hdf5", "large-data"], "A_Votes": "3", "A_Content": "  I recently came across a similar issue. I found simply reading the data in chunks and appending it as I write it in chunks to the same csv works well. My problem was adding a date column based on information in another table, using the value of certain columns as follows. This may help those confused by dask and hdf5 but more familiar with pandas like myself.   def addDateColumn(): \"\"\"Adds time to the daily rainfall data. Reads the csv as chunks of 100k     rows at a time and outputs them, appending as needed, to a single csv.     Uses the column of the raster names to get the date. \"\"\"     df = pd.read_csv(pathlist[1]+\"CHIRPS_tanz.csv\", iterator=True,                       chunksize=100000) #read csv file as 100k chunks      '''Do some stuff'''      count = 1 #for indexing item in time list      for chunk in df: #for each 100k rows         newtime = [] #empty list to append repeating times for different rows         toiterate = chunk[chunk.columns[2]] #ID of raster nums to base time         while count <= toiterate.max():             for i in toiterate:                  if i ==count:                     newtime.append(newyears[count])             count+=1         print \"Finished\", str(chunknum), \"chunks\"         chunk[\"time\"] = newtime #create new column in dataframe based on time         outname = \"CHIRPS_tanz_time2.csv\"         #append each output to same csv, using no header         chunk.to_csv(pathlist[2]+outname, mode='a', header=None, index=None)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "550", "A_Content": "  A mixin is a special kind of multiple inheritance.  There are two main situations where mixins are used:   You want to provide a lot of optional features for a class. You want to use one particular feature in a lot of different classes.   For an example of number one, consider werkzeug's request and response system.  I can make a plain old request object by saying:  from werkzeug import BaseRequest  class Request(BaseRequest):     pass   If I want to add accept header support, I would make that  from werkzeug import BaseRequest, AcceptMixin  class Request(AcceptMixin, BaseRequest):     pass   If I wanted to make a request object that supports accept headers, etags, authentication, and user agent support, I could do this:  from werkzeug import BaseRequest, AcceptMixin, ETagRequestMixin, UserAgentMixin, AuthenticationMixin  class Request(AcceptMixin, ETagRequestMixin, UserAgentMixin, AuthenticationMixin, BaseRequest):     pass   The difference is subtle, but in the above examples, the mixin classes weren't made to stand on their own.  In more traditional multiple inheritance, the AuthenticationMixin (for example) would probably be something more like Authenticator.  That is, the class would probably be designed to stand on its own.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "200", "A_Content": "  First, you should note that mixins only exist in multiple-inheritance languages. You can't do a mixin in Java or C#.   Basically, a mixin is a stand-alone base type that provides limited functionality and polymorphic resonance for a child class. If you're thinking in C#, think of an interface that you don't have to actually implement because it's already implemented; you just inherit from it and benefit from its functionality.   Mixins are typically narrow in scope and not meant to be extended.   [edit -- as to why:]  I suppose I should address why, since you asked. The big benefit is that you don't have to do it yourself over and over again. In C#, the biggest place where a mixin could benefit might be from the Disposal pattern. Whenever you implement IDisposable, you almost always want to follow the same pattern, but you end up writing and re-writing the same basic code with minor variations. If there were an extendable Disposal mixin, you could save yourself a lot of extra typing.   [edit 2 -- to answer your other questions]     What separates a mixin from multiple inheritance? Is it just a matter of semantics?   Yes. The difference between a mixin and standard multiple inheritance is just a matter of semantics; a class that has multiple inheritance might utilize a mixin as part of that multiple inheritance.   The point of a mixin is to create a type that can be \"mixed in\" to any other type via inheritance without affecting the inheriting type while still offering some beneficial functionality for that type.   Again, think of an interface that is already implemented.   I personally don't use mixins since I develop primarily in a language that doesn't support them, so I'm having a really difficult time coming up with a decent example that will just supply that \"ahah!\" moment for you. But I'll try again. I'm going to use an example that's contrived -- most languages already provide the feature in some way or another -- but that will, hopefully, explain how mixins are supposed to be created and used. Here goes:  Suppose you have a type that you want to be able to serialize to and from XML. You want the type to provide a \"ToXML\" method that returns a string containing an XML fragment with the data values of the type, and a \"FromXML\" that allows the type to reconstruct its data values from an XML fragment in a string. Again, this is a contrived example, so perhaps you use a file stream, or an XML Writer class from your language's runtime library... whatever. The point is that you want to serialize your object to XML and get a new object back from XML.   The other important point in this example is that you want to do this in a generic way. You don't want to have to implement a \"ToXML\" and \"FromXML\" method for every type that you want to serialize, you want some generic means of ensuring that your type will do this and it just works. You want code reuse.   If your language supported it, you could create the XmlSerializable mixin to do your work for you. This type would implement the ToXML and the FromXML methods. It would, using some mechanism that's not important to the example, be capable of gathering all the necessary data from any type that it's mixed in with to build the XML fragment returned by ToXML and it would be equally capable of restoring that data when FromXML is called.   And.. that's it. To use it, you would have any type that needs to be serialized to XML inherit from XmlSerializable. Whenever you needed to serialize or deserialize that type, you would simply call ToXML or FromXML. In fact, since XmlSerializable is a fully-fledged type and polymorphic, you could conceivably build a document serializer that doesn't know anything about your original type, accepting only, say, an array of XmlSerializable types.   Now imagine using this scenario for other things, like creating a mixin that ensures that every class that mixes it in logs every method call, or a mixin that provides transactionality to the type that mixes it in. The list can go on and on.   If you just think of a mixin as a small base type designed to add a small amount of functionality to a type without otherwise affecting that type, then you're golden.   Hopefully. :)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "123", "A_Content": "  This answer aims to explain mixins with examples that are:   self-contained: short, with no need to know any libraries to understand the example. in Python, not in other languages.  It is understandable that there were examples from other languages such as Ruby since the term is much more common in those languages, but this is a Python thread.   It shall also consider the controversial question:     Is multiple inheritance necessary or not to characterize a mixin?   Definitions  I have yet to see a citation from an \"authoritative\" source clearly saying what is a mixin in Python.  I have seen 2 possible definitions of a mixin (if they are to be considered as different from other similar concepts such as abstract base classes), and people don't entirely agree on which one is correct.  The consensus may vary between different languages.  Definition 1: no multiple inheritance  A mixin is a class such that some method of the class uses a method which is not defined in the class.  Therefore the class is not meant to be instantiated, but rather serve as a base class. Otherwise the instance would have methods that cannot be called without raising an exception.  A constraint which some sources add is that the class may not contain data, only methods, but I don't see why this is necessary. In practice however, many useful mixins don't have any data, and base classes without data are simpler to use.  A classic example  is the implementation of all comparison operators from only <= and ==:  class ComparableMixin(object):     \"\"\"This class has methods which use `<=` and `==`,     but this class does NOT implement those methods.\"\"\"     def __ne__(self, other):         return not (self == other)     def __lt__(self, other):         return self <= other and (self != other)     def __gt__(self, other):         return not self <= other     def __ge__(self, other):         return self == other or self > other  class Integer(ComparableMixin):     def __init__(self, i):         self.i = i     def __le__(self, other):         return self.i <= other.i     def __eq__(self, other):         return self.i == other.i  assert Integer(0) <  Integer(1) assert Integer(0) != Integer(1) assert Integer(1) >  Integer(0) assert Integer(1) >= Integer(1)  # It is possible to instantiate a mixin: o = ComparableMixin() # but one of its methods raise an exception: #o != o    This particular example could have been achieved via the functools.total_ordering() decorator, but the game here was to reinvent the wheel:  import functools  @functools.total_ordering class Integer(object):     def __init__(self, i):         self.i = i     def __le__(self, other):         return self.i <= other.i     def __eq__(self, other):         return self.i == other.i  assert Integer(0) < Integer(1) assert Integer(0) != Integer(1) assert Integer(1) > Integer(0) assert Integer(1) >= Integer(1)   Definition 2: multiple inheritance  A mixin is a design pattern in which some method of a base class uses a method it does not define, and that method is meant to be implemented by another base class, not by the derived like in Definition 1.  The term mixin class refers to base classes which are intended to be used in that design pattern (TODO those that use the method, or those that implement it?)  It is not easy to decide if a given class is a mixin or not: the method could be just implemented on the derived class, in which case we're back to Definition 1. You have to consider the author's intentions.  This pattern is interesting because it is possible to recombine functionalities with different choices of base classes:  class HasMethod1(object):     def method(self):         return 1  class HasMethod2(object):     def method(self):         return 2  class UsesMethod10(object):     def usesMethod(self):         return self.method() + 10  class UsesMethod20(object):     def usesMethod(self):         return self.method() + 20  class C1_10(HasMethod1, UsesMethod10): pass class C1_20(HasMethod1, UsesMethod20): pass class C2_10(HasMethod2, UsesMethod10): pass class C2_20(HasMethod2, UsesMethod20): pass  assert C1_10().usesMethod() == 11 assert C1_20().usesMethod() == 21 assert C2_10().usesMethod() == 12 assert C2_20().usesMethod() == 22  # Nothing prevents implementing the method # on the base class like in Definition 1:  class C3_10(UsesMethod10):     def method(self):         return 3  assert C3_10().usesMethod() == 13   Authoritative Python occurrences  At the official documentatiton for collections.abc the documentation explicitly uses the term Mixin Methods.  It states that if a class:   implements __next__ inherits from a single class Iterator   then the class gets an __iter__ mixin method for free.  Therefore at least on this point of the documentation, mixin does not not require multiple inheritance, and is coherent with Definition 1.  The documentation could of course be contradictory at different points, and other important Python libraries might be using the other definition in their documentation.  This page also uses the term Set mixin, which clearly suggests that classes like Set and Iterator can be called Mixin classes.  In other languages   Ruby: Clearly does not require multiple inheritance for mixin, as mentioned in major reference books such as Programming Ruby and The Ruby programming Language C++: A method that is not implemented is a pure virtual method.  Definition 1 coincides with the definition of an abstract class (a class that has a pure virtual method). That class cannot be instantiated.  Definition 2 is possible with virtual inheritance: Multiple Inheritance from two derived classes      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "26", "A_Content": "  I think of them as a disciplined way of using multiple inheritance - because ultimately a mixin is just another python class that (might) follow the conventions about classes that are called mixins.  My understanding of the conventions that govern something you would call a Mixin are that a Mixin:   adds methods but not instance variables (class constants are OK) only inherits from object (in Python)   That way it limits the potential complexity of multiple inheritance, and makes it reasonably easy to track the flow of your program by limiting where you have to look (compared to full multiple inheritance).  They are similar to ruby modules.  If I want to add instance variables (with more flexibility than allowed for by single inheritance) then I tend to go for composition.  Having said that, I have seen classes called XYZMixin that do have instance variables.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "20", "A_Content": "  Mixins is a concept in Programming in which the class provides functionalities but it is not meant to be used for instantiation. Main purpose of Mixins is to provide functionalities which are standalone and it would be best if the mixins itself do not have inheritance with other mixins and also avoid state. In languages such as Ruby, there is some direct language support but for Python, there isn't. However, you could used multi-class inheritance to execute the functionality provided in Python.  I watched this video http://www.youtube.com/watch?v=v_uKI2NOLEM to understand the basics of mixins. It is quite useful for a beginner to understand the basics of mixins and how they work and the problems you might face in implementing them.  Wikipedia is still the best: http://en.wikipedia.org/wiki/Mixin     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "11", "A_Content": "  I'd advise against mix-ins in new Python code, if you can find any other way around it (such as composition-instead-of-inheritance, or just monkey-patching methods into your own classes) that isn't much more effort.  In old-style classes you could use mix-ins as a way of grabbing a few methods from another class. But in the new-style world everything, even the mix-in, inherits from object. That means that any use of multiple inheritance naturally introduces MRO issues.  There are ways to make multiple-inheritance MRO work in Python, most notably the super() function, but it means you have to do your whole class hierarchy using super(), and it's considerably more difficult to understand the flow of control.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "11", "A_Content": "     What separates a mixin from multiple inheritance? Is it just a matter of semantics?   A mixin is a limited form of multiple inheritance. In some languages the mechanism for adding a mixin to a class is slightly different (in terms of syntax) from that of inheritance.  In the context of Python especially, a mixin is a parent class that provides functionality to subclasses but is not intended to be instantiated itself.   What might cause you to say, \"that's just multiple inheritance, not really a mixin\" is if the class that might be confused for a mixin can actually be instantiated and used - so indeed it is a semantic, and very real, difference.  Example of Multiple Inheritance  This example, from the documentation, is an OrderedCounter:   class OrderedCounter(Counter, OrderedDict):      'Counter that remembers the order elements are first encountered'       def __repr__(self):          return '%s(%r)' % (self.__class__.__name__, OrderedDict(self))       def __reduce__(self):          return self.__class__, (OrderedDict(self),)    It subclasses both the Counter and the OrderedDict from the collections module.  Both Counter and OrderedDict are intended to be instantiated and used on their own. However, by subclassing them both, we can have a counter that is ordered and reuses the code in each object.   This is a powerful way to reuse code, but it can also be problematic. If it turns out there's a bug in one of the objects, fixing it without care could create a bug in the subclass.   Example of a Mixin  Mixins are usually promoted as the way to get code reuse without potential coupling issues that cooperative multiple inheritance, like the OrderedCounter, could have. When you use mixins, you use functionality that isn't as tightly coupled to the data.   Unlike the example above, a mixin is not intended to be used on its own. It provides new or different functionality.  For example, the standard library has a couple of mixins in the socketserver library.     Forking and threading versions of each type of server can be created   using these mix-in classes. For instance, ThreadingUDPServer is   created as follows:  class ThreadingUDPServer(ThreadingMixIn, UDPServer):     pass       The mix-in class comes first, since it overrides a method defined in   UDPServer. Setting the various attributes also changes the behavior of   the underlying server mechanism.   In this case, the mixin methods override the methods in the UDPServer object definition to allow for concurrency.  The overridden method appears to be process_request and it also provides another method, process_request_thread. Here it is from the source code:   class ThreadingMixIn:         \"\"\"Mix-in class to handle each request in a new thread.\"\"\"          # Decides how threads will act upon termination of the         # main process         daemon_threads = False          def process_request_thread(self, request, client_address):             \"\"\"Same as in BaseServer but as a thread.             In addition, exception handling is done here.             \"\"\"             try:                 self.finish_request(request, client_address)             except Exception:                 self.handle_error(request, client_address)             finally:                 self.shutdown_request(request)          def process_request(self, request, client_address):             \"\"\"Start a new thread to process the request.\"\"\"             t = threading.Thread(target = self.process_request_thread,                                  args = (request, client_address))             t.daemon = self.daemon_threads             t.start()    A Contrived Example  This is a mixin that is mostly for demonstration purposes - most objects will evolve beyond the usefulness of this repr:  class SimpleInitReprMixin(object):     \"\"\"mixin, don't instantiate - useful for classes instantiable     by keyword arguments to their __init__ method.     \"\"\"     __slots__ = () # allow subclasses to use __slots__ to prevent __dict__     def __repr__(self):         kwarg_strings = []         d = getattr(self, '__dict__', None)         if d is not None:             for k, v in d.items():                 kwarg_strings.append('{k}={v}'.format(k=k, v=repr(v)))         slots = getattr(self, '__slots__', None)         if slots is not None:             for k in slots:                 v = getattr(self, k, None)                 kwarg_strings.append('{k}={v}'.format(k=k, v=repr(v)))         return '{name}({kwargs})'.format(           name=type(self).__name__,           kwargs=', '.join(kwarg_strings)           )   and usage would be:  class Foo(SimpleInitReprMixin): # add other mixins and/or extend another class here     __slots__ = 'foo',     def __init__(self, foo=None):         self.foo = foo         super(Foo, self).__init__()   And usage:  >>> f1 = Foo('bar') >>> f2 = Foo() >>> f1 Foo(foo='bar') >>> f2 Foo(foo=None)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "8", "A_Content": "  Perhaps a couple of examples will help.  If you're building a class and you want it to act like a dictionary, you can define all the various __ __ methods necessary.  But that's a bit of a pain.  As an alternative, you can just define a few, and inherit (in addition to any other inheritance) from UserDict.DictMixin (moved to collections.DictMixin in py3k).  This will have the effect of automatically defining all the rest of the dictionary api.  A second example: the GUI toolkit wxPython allows you to make list controls with multiple columns (like, say, the file display in Windows Explorer).  By default, these lists are fairly basic.  You can add additional functionality, such as the ability to sort the list by a particular column by clicking on the column header, by inheriting from ListCtrl and adding appropriate mixins.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "8", "A_Content": "  I think there have been some good explanations here but I wanted to provide another perspective.  In Scala, you can do mixins as has been described here but what is very interesting is that the mixins are actually 'fused' together to create a new kind of class to inherit from. In essence, you do not inherit from multiple classes/mixins, but rather, generate a new kind of class with all the properties of the mixin to inherit from. This makes sense since Scala is based on the JVM where multiple-inheritance is not currently supported (as of Java 8). This mixin class type, by the way, is a special type called a Trait in Scala.  It's hinted at in the way a class is defined:     class NewClass extends FirstMixin with SecondMixin with ThirdMixin     ...  I'm not sure if the CPython interpreter does the same (mixin class-composition) but I wouldn't be surprised. Also, coming from a C++ background, I would not call an ABC or 'interface' equivalent to a mixin -- it's a similar concept but divergent in use and implementation.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "6", "A_Content": "  Maybe an example from ruby can help:  You can include the mixin Comparable and define one function \"<=>(other)\", the mixin provides all those functions:  <(other) >(other) ==(other) <=(other) >=(other) between?(other)   It does this by invoking <=>(other) and giving back the right result.  \"instance <=> other\" returns 0 if both objects are equal, less than 0 if instance is bigger than other and more than 0 if other is bigger.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "6", "A_Content": "  It's not a Python example but in the D programing language the term mixin is used to refer to a construct used much the same way; adding a pile of stuff to a class.   In D (which by the way doesn't do MI) this is done by inserting a template (think syntactically aware and safe macros and you will be close) into a scope. This allows for a single line of code in a class, struct, function, module or whatever to expand to any number of declarations.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "5", "A_Content": "  mixin gives a way to add functionality in a class, i.e you can interact with methods defined in a module by including the module inside the desired class. Though ruby doesn't supports multiple inheritance but provides mixin as an alternative to achieve that.  here is an example that explains how multiple inheritance is achieved using mixin.  module A    # you create a module     def a1  # lets have a method 'a1' in it     end     def a2  # Another method 'a2'     end end  module B    # let's say we have another module     def b1  # A method 'b1'     end     def b2  #another method b2     end end  class Sample    # we create a class 'Sample'     include A   # including module 'A' in the class 'Sample' (mixin)     include B   # including module B as well      def S1      #class 'Sample' contains a method 's1'     end end  samp = Sample.new    # creating an instance object 'samp'  # we can access methods from module A and B in our class(power of mixin)  samp.a1     # accessing method 'a1' from module A samp.a2     # accessing method 'a2' from module A samp.b1     # accessing method 'b1' from module B samp.b2     # accessing method 'a2' from module B samp.s1     # accessing method 's1' inside the class Sample      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "5", "A_Content": "  I just used a python mixin to implement unit testing for python milters.  Normally, a milter talks to an MTA, making unit testing difficult.  The test mixin overrides methods that talk to the MTA, and create a simulated environment driven by test cases instead.  So, you take an unmodified milter application, like spfmilter, and mixin TestBase, like this:  class TestMilter(TestBase,spfmilter.spfMilter):   def __init__(self):     TestBase.__init__(self)     spfmilter.config = spfmilter.Config()     spfmilter.config.access_file = 'test/access.db'     spfmilter.spfMilter.__init__(self)   Then, use TestMilter in the test cases for the milter application:  def testPass(self):   milter = TestMilter()   rc = milter.connect('mail.example.com',ip='192.0.2.1')   self.assertEqual(rc,Milter.CONTINUE)   rc = milter.feedMsg('test1',sender='good@example.com')   self.assertEqual(rc,Milter.CONTINUE)   milter.close()   http://pymilter.cvs.sourceforge.net/viewvc/pymilter/pymilter/Milter/test.py?revision=1.6&view=markup     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "3", "A_Content": "  I read that you have a c# background. So a good starting point might be a mixin implementation for .NET.  You might want to check out the codeplex project at http://remix.codeplex.com/  Watch the lang.net Symposium link to get an overview. There is still more to come on documentation on codeplex page.  regards Stefan      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful", "Language": "Python", "Q_Title": "What is a mixin, and why are they useful?", "Q_Votes": "743", "Q_Content": "    In \"Programming Python\", Mark Lutz mentions \"mixins\". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin?   Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right?   Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?  What separates a mixin from multiple inheritance? Is it just a matter of semantics?     ", "Tags": ["python", "oop", "multiple-inheritance", "mixins"], "A_Votes": "2", "A_Content": "  OP mentioned that he/she never heard of mixin in C++, perhaps that is because they are called Curiously Recurring Template Pattern (CRTP) in C++. Also, @Ciro Santilli mentioned that mixin is implemented via abstract base class in C++. While abstract base class can be used to implement mixin, it is an overkill as the functionality of virtual function at run-time can be achieved using template at compile time without the overhead of virtual table lookup at run-time.   The CRTP pattern is described in detail here  I have converted the python example in @Ciro Santilli's answer into C++ using template class below:  #include <iostream> #include <assert.h>  template <class T> class ComparableMixin { public:     bool operator !=(ComparableMixin &other) {         return ~(*static_cast<T*>(this) == static_cast<T&>(other));     }     bool operator <(ComparableMixin &other) {         return ((*(this) != other) && (*static_cast<T*>(this) <= static_cast<T&>(other)));     }     bool operator >(ComparableMixin &other) {         return ~(*static_cast<T*>(this) <= static_cast<T&>(other));     }     bool operator >=(ComparableMixin &other) {         return ((*static_cast<T*>(this) == static_cast<T&>(other)) || (*(this) > other));     } };  class Integer: public ComparableMixin<Integer> { public:  Integer(int i) {      this->i = i;  }  int i;  bool operator <=(Integer &other) {      return (this->i <= other.i);  }  bool operator ==(Integer &other) {      return (this->i == other.i);  } };  int main() {      Integer i(0) ;     Integer j(1) ;      assert (i < j );     assert (i != j);     assert (j >  i);     assert (j >= i);      return 0; }      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "261", "A_Content": "  I detected the peaks using a local maximum filter. Here is the result on your first dataset of 4 paws:   I also ran it on the second dataset of 9 paws and it worked as well.  Here is how you do it:  import numpy as np from scipy.ndimage.filters import maximum_filter from scipy.ndimage.morphology import generate_binary_structure, binary_erosion import matplotlib.pyplot as pp  #for some reason I had to reshape. Numpy ignored the shape header. paws_data = np.loadtxt(\"paws.txt\").reshape(4,11,14)  #getting a list of images paws = [p.squeeze() for p in np.vsplit(paws_data,4)]   def detect_peaks(image):     \"\"\"     Takes an image and detect the peaks usingthe local maximum filter.     Returns a boolean mask of the peaks (i.e. 1 when     the pixel's value is the neighborhood maximum, 0 otherwise)     \"\"\"      # define an 8-connected neighborhood     neighborhood = generate_binary_structure(2,2)      #apply the local maximum filter; all pixel of maximal value      #in their neighborhood are set to 1     local_max = maximum_filter(image, footprint=neighborhood)==image     #local_max is a mask that contains the peaks we are      #looking for, but also the background.     #In order to isolate the peaks we must remove the background from the mask.      #we create the mask of the background     background = (image==0)      #a little technicality: we must erode the background in order to      #successfully subtract it form local_max, otherwise a line will      #appear along the background border (artifact of the local maximum filter)     eroded_background = binary_erosion(background, structure=neighborhood, border_value=1)      #we obtain the final mask, containing only peaks,      #by removing the background from the local_max mask (xor operation)     detected_peaks = local_max ^ eroded_background      return detected_peaks   #applying the detection and plotting results for i, paw in enumerate(paws):     detected_peaks = detect_peaks(paw)     pp.subplot(4,2,(2*i+1))     pp.imshow(paw)     pp.subplot(4,2,(2*i+2) )     pp.imshow(detected_peaks)  pp.show()   All you need to do after is use scipy.ndimage.measurements.label on the mask to label all distinct objects. Then you'll be able to play with them individually.  Note that the method works well because the background is not noisy. If it were, you would detect a bunch of other unwanted peaks in the background. Another important factor is the size of the neighborhood. You will need to adjust it if the peak size changes (the should remain roughly proportional).     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "40", "A_Content": "  Solution  Data file: paw.txt. Source code:  from scipy import * from operator import itemgetter  n = 5  # how many fingers are we looking for  d = loadtxt(\"paw.txt\") width, height = d.shape  # Create an array where every element is a sum of 2x2 squares.  fourSums = d[:-1,:-1] + d[1:,:-1] + d[1:,1:] + d[:-1,1:]  # Find positions of the fingers.  # Pair each sum with its position number (from 0 to width*height-1),  pairs = zip(arange(width*height), fourSums.flatten())  # Sort by descending sum value, filter overlapping squares  def drop_overlapping(pairs):     no_overlaps = []     def does_not_overlap(p1, p2):         i1, i2 = p1[0], p2[0]         r1, col1 = i1 / (width-1), i1 % (width-1)         r2, col2 = i2 / (width-1), i2 % (width-1)         return (max(abs(r1-r2),abs(col1-col2)) >= 2)     for p in pairs:         if all(map(lambda prev: does_not_overlap(p,prev), no_overlaps)):             no_overlaps.append(p)     return no_overlaps  pairs2 = drop_overlapping(sorted(pairs, key=itemgetter(1), reverse=True))  # Take the first n with the heighest values  positions = pairs2[:n]  # Print results  print d, \"\\n\"  for i, val in positions:     row = i / (width-1)     column = i % (width-1)     print \"sum = %f @ %d,%d (%d)\" % (val, row, column, i)     print d[row:row+2,column:column+2], \"\\n\"   Output without overlapping squares. It seems that the same areas are selected as in your example.  Some comments  The tricky part is to calculate sums of all 2x2 squares. I assumed you need all of them, so there might be some overlapping. I used slices to cut the first/last columns and rows from the original 2D array, and then overlapping them all together and calculating sums.  To understand it better, imaging a 3x3 array:  >>> a = arange(9).reshape(3,3) ; a array([[0, 1, 2],        [3, 4, 5],        [6, 7, 8]])   Then you can take its slices:  >>> a[:-1,:-1] array([[0, 1],        [3, 4]]) >>> a[1:,:-1] array([[3, 4],        [6, 7]]) >>> a[:-1,1:] array([[1, 2],        [4, 5]]) >>> a[1:,1:] array([[4, 5],        [7, 8]])   Now imagine you stack them one above the other and sum elements at the same positions. These sums will be exactly the same sums over the 2x2 squares with the top-left corner in the same position:  >>> sums = a[:-1,:-1] + a[1:,:-1] + a[:-1,1:] + a[1:,1:]; sums array([[ 8, 12],        [20, 24]])   When you have the sums over 2x2 squares, you can use max to find the maximum, or sort, or sorted to find the peaks.  To remember positions of the peaks I couple every value (the sum) with its ordinal position in a flattened array (see zip). Then I calculate row/column position again when I print the results.  Notes  I allowed for the 2x2 squares to overlap. Edited version filters out some of them such that only non-overlapping squares appear in the results.  Choosing fingers (an idea)  Another problem is how to choose what is likely to be fingers out of all the peaks. I have an idea which may or may not work. I don't have time to implement it right now, so just pseudo-code.  I noticed that if the front fingers stay on almost a perfect circle, the rear finger should be inside of that circle. Also, the front fingers are more or less equally spaced. We may try to use these heuristic properties to detect the fingers.  Pseudo code:  select the top N finger candidates (not too many, 10 or 12) consider all possible combinations of 5 out of N (use itertools.combinations) for each combination of 5 fingers:     for each finger out of 5:         fit the best circle to the remaining 4         => position of the center, radius         check if the selected finger is inside of the circle         check if the remaining four are evenly spread         (for example, consider angles from the center of the circle)         assign some cost (penalty) to this selection of 4 peaks + a rear finger         (consider, probably weighted:              circle fitting error,              if the rear finger is inside,              variance in the spreading of the front fingers,              total intensity of 5 peaks) choose a combination of 4 peaks + a rear peak with the lowest penalty   This is a brute-force approach. If N is relatively small, then I think it is doable. For N=12, there are C_12^5 = 792 combinations, times 5 ways to select a rear finger, so 3960 cases to evaluate for every paw.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "26", "A_Content": "  This is an image registration problem. The general strategy is:   Have a known example, or some kind of prior on the data. Fit your data to the example, or fit the example to your data. It helps if your data is roughly aligned in the first place.   Here's a rough and ready approach, \"the dumbest thing that could possibly work\":   Start with five toe coordinates in roughly the place you expect. With each one, iteratively climb to the top of the hill. i.e. given current position, move to maximum neighbouring pixel, if its value is greater than current pixel. Stop when your toe coordinates have stopped moving.   To counteract the orientation problem, you could have 8 or so initial settings for the basic directions (North, North East, etc). Run each one individually and throw away any results where two or more toes end up at the same pixel. I'll think about this some more, but this kind of thing is still being researched in image processing - there are no right answers!  Slightly more complex idea: (weighted) K-means clustering. It's not that bad.   Start with five toe coordinates, but now these are \"cluster centres\".   Then iterate until convergence:   Assign each pixel to the closest cluster (just make a list for each cluster). Calculate the center of mass of each cluster. For each cluster, this is: Sum(coordinate * intensity value)/Sum(coordinate) Move each cluster to the new centre of mass.   This method will almost certainly give much better results, and you get the mass of each cluster which may help in identifying the toes.  (Again, you've specified the number of clusters up front. With clustering you have to specify the density one way or another: Either choose the number of clusters, appropriate in this case, or choose a cluster radius and see how many you end up with. An example of the latter is mean-shift.)  Sorry about the lack of implementation details or other specifics. I would code this up but I've got a deadline. If nothing else has worked by next week let me know and I'll give it a shot.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "12", "A_Content": "  This problem has been studied in some depth by physicists. There is a good implementation in ROOT. Look at the TSpectrum classes (especially TSpectrum2 for your case) and the documentation for them.  References:   M.Morhac et al.: Background elimination methods for multidimensional coincidence gamma-ray spectra. Nuclear Instruments and Methods in Physics Research A 401 (1997) 113-132. M.Morhac et al.: Efficient one- and two-dimensional Gold deconvolution and its application to gamma-ray spectra decomposition. Nuclear Instruments and Methods in Physics Research A 401 (1997) 385-408. M.Morhac et al.: Identification of peaks in multidimensional coincidence gamma-ray spectra. Nuclear Instruments and Methods in Research Physics A 443(2000), 108-125.    ...and for those who don't have access to a subscription to NIM:   Spectrum.doc SpectrumDec.ps.gz SpectrumSrc.ps.gz SpectrumBck.ps.gz      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "9", "A_Content": "  Just a couple of ideas off the top of my head:   take the gradient (derivative) of the scan, see if that eliminates the false calls take the maximum of the local maxima   You might also want to take a look at OpenCV, it's got a fairly decent Python API and might have some functions you'd find useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "9", "A_Content": "  Here is an idea: you calculate the (discrete) Laplacian of the image.  I would expect it to be (negative and) large at maxima, in a way that is more dramatic than in the original images.  Thus, maxima could be easier to find.  Here is another idea: if you know the typical size of the high-pressure spots, you can first smooth your image by convoluting it with a Gaussian of the same size.  This may give you simpler images to process.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "8", "A_Content": "  Using persistent homology to analyze your data set I get the following result (click to enlarge):     This is the 2D-version of the peak detection method described in this SO answer. The above figure simply shows 0-dimensional persistent homology classes sorted by persistence.  I did upscale the original dataset by a factor of 2 using scipy.misc.imresize(). However, note that I did consider the four paws as one dataset; splitting it into four would make the problem easier.  Methodology. The idea behind this quite simple: Consider the function graph of the function that assigns each pixel its level. It looks like this:    Now consider a water level at height 255 that continuously descents to lower levels. At local maxima islands pop up (birth). At saddle points two islands merge; we consider the lower island to be merged to the higher island (death). The so-called persistence diagram (of the 0-th dimensional homology classes, our islands) depicts death- over birth-values of all islands:    The persistence of an island is then the difference between the birth- and death-level; the vertical distance of a dot to the grey main diagonal. The figure labels the islands by decreasing persistence.  The very first picture shows the locations of births of the islands. This method not only gives the local maxima but also quantifies their \"significance\" by the above mentioned persistence. One would then filter out all islands with a too low persistence. However, in your example every island (i.e., every local maximum) is a peak you look for.  Python code can be found here.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "7", "A_Content": "  thanks for the raw data.  I'm on the train and this is as far as I've gotten (my stop is coming up).  I massaged your txt file with regexps and have plopped it into a html page with some javascript for visualization.  I'm sharing it here because some, like myself, might find it more readily hackable than python.  I think a good approach will be scale and rotation invariant, and my next step will be to investigate mixtures of gaussians.  (each paw pad being the center of a gaussian).      <html> <head>     <script type=\"text/javascript\" src=\"http://vis.stanford.edu/protovis/protovis-r3.2.js\"></script>      <script type=\"text/javascript\">     var heatmap = [[[0,0,0,0,0,0,0,4,4,0,0,0,0], [0,0,0,0,0,7,14,22,18,7,0,0,0], [0,0,0,0,11,40,65,43,18,7,0,0,0], [0,0,0,0,14,61,72,32,7,4,11,14,4], [0,7,14,11,7,22,25,11,4,14,65,72,14], [4,29,79,54,14,7,4,11,18,29,79,83,18], [0,18,54,32,18,43,36,29,61,76,25,18,4], [0,4,7,7,25,90,79,36,79,90,22,0,0], [0,0,0,0,11,47,40,14,29,36,7,0,0], [0,0,0,0,4,7,7,4,4,4,0,0,0] ],[ [0,0,0,4,4,0,0,0,0,0,0,0,0], [0,0,11,18,18,7,0,0,0,0,0,0,0], [0,4,29,47,29,7,0,4,4,0,0,0,0], [0,0,11,29,29,7,7,22,25,7,0,0,0], [0,0,0,4,4,4,14,61,83,22,0,0,0], [4,7,4,4,4,4,14,32,25,7,0,0,0], [4,11,7,14,25,25,47,79,32,4,0,0,0], [0,4,4,22,58,40,29,86,36,4,0,0,0], [0,0,0,7,18,14,7,18,7,0,0,0,0], [0,0,0,0,4,4,0,0,0,0,0,0,0], ],[ [0,0,0,4,11,11,7,4,0,0,0,0,0], [0,0,0,4,22,36,32,22,11,4,0,0,0], [4,11,7,4,11,29,54,50,22,4,0,0,0], [11,58,43,11,4,11,25,22,11,11,18,7,0], [11,50,43,18,11,4,4,7,18,61,86,29,4], [0,11,18,54,58,25,32,50,32,47,54,14,0], [0,0,14,72,76,40,86,101,32,11,7,4,0], [0,0,4,22,22,18,47,65,18,0,0,0,0], [0,0,0,0,4,4,7,11,4,0,0,0,0], ],[ [0,0,0,0,4,4,4,0,0,0,0,0,0], [0,0,0,4,14,14,18,7,0,0,0,0,0], [0,0,0,4,14,40,54,22,4,0,0,0,0], [0,7,11,4,11,32,36,11,0,0,0,0,0], [4,29,36,11,4,7,7,4,4,0,0,0,0], [4,25,32,18,7,4,4,4,14,7,0,0,0], [0,7,36,58,29,14,22,14,18,11,0,0,0], [0,11,50,68,32,40,61,18,4,4,0,0,0], [0,4,11,18,18,43,32,7,0,0,0,0,0], [0,0,0,0,4,7,4,0,0,0,0,0,0], ],[ [0,0,0,0,0,0,4,7,4,0,0,0,0], [0,0,0,0,4,18,25,32,25,7,0,0,0], [0,0,0,4,18,65,68,29,11,0,0,0,0], [0,4,4,4,18,65,54,18,4,7,14,11,0], [4,22,36,14,4,14,11,7,7,29,79,47,7], [7,54,76,36,18,14,11,36,40,32,72,36,4], [4,11,18,18,61,79,36,54,97,40,14,7,0], [0,0,0,11,58,101,40,47,108,50,7,0,0], [0,0,0,4,11,25,7,11,22,11,0,0,0], [0,0,0,0,0,4,0,0,0,0,0,0,0], ],[ [0,0,4,7,4,0,0,0,0,0,0,0,0], [0,0,11,22,14,4,0,4,0,0,0,0,0], [0,0,7,18,14,4,4,14,18,4,0,0,0], [0,4,0,4,4,0,4,32,54,18,0,0,0], [4,11,7,4,7,7,18,29,22,4,0,0,0], [7,18,7,22,40,25,50,76,25,4,0,0,0], [0,4,4,22,61,32,25,54,18,0,0,0,0], [0,0,0,4,11,7,4,11,4,0,0,0,0], ],[ [0,0,0,0,7,14,11,4,0,0,0,0,0], [0,0,0,4,18,43,50,32,14,4,0,0,0], [0,4,11,4,7,29,61,65,43,11,0,0,0], [4,18,54,25,7,11,32,40,25,7,11,4,0], [4,36,86,40,11,7,7,7,7,25,58,25,4], [0,7,18,25,65,40,18,25,22,22,47,18,0], [0,0,4,32,79,47,43,86,54,11,7,4,0], [0,0,0,14,32,14,25,61,40,7,0,0,0], [0,0,0,0,4,4,4,11,7,0,0,0,0], ],[ [0,0,0,0,4,7,11,4,0,0,0,0,0], [0,4,4,0,4,11,18,11,0,0,0,0,0], [4,11,11,4,0,4,4,4,0,0,0,0,0], [4,18,14,7,4,0,0,4,7,7,0,0,0], [0,7,18,29,14,11,11,7,18,18,4,0,0], [0,11,43,50,29,43,40,11,4,4,0,0,0], [0,4,18,25,22,54,40,7,0,0,0,0,0], [0,0,4,4,4,11,7,0,0,0,0,0,0], ],[ [0,0,0,0,0,7,7,7,7,0,0,0,0], [0,0,0,0,7,32,32,18,4,0,0,0,0], [0,0,0,0,11,54,40,14,4,4,22,11,0], [0,7,14,11,4,14,11,4,4,25,94,50,7], [4,25,65,43,11,7,4,7,22,25,54,36,7], [0,7,25,22,29,58,32,25,72,61,14,7,0], [0,0,4,4,40,115,68,29,83,72,11,0,0], [0,0,0,0,11,29,18,7,18,14,4,0,0], [0,0,0,0,0,4,0,0,0,0,0,0,0], ] ]; </script> </head> <body>     <script type=\"text/javascript+protovis\">         for (var a=0; a < heatmap.length; a++) {     var w = heatmap[a][0].length,     h = heatmap[a].length; var vis = new pv.Panel()     .width(w * 6)     .height(h * 6)     .strokeStyle(\"#aaa\")     .lineWidth(4)     .antialias(true); vis.add(pv.Image)     .imageWidth(w)     .imageHeight(h)     .image(pv.Scale.linear()         .domain(0, 99, 100)         .range(\"#000\", \"#fff\", '#ff0a0a')         .by(function(i, j) heatmap[a][j][i])); vis.render(); } </script>   </body> </html>        ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "7", "A_Content": "  I'm sure you have enough to go on by now, but I can't help but suggest using the k-means clustering method. k-means is an unsupervised clustering algorithm which will take you data (in any number of dimensions - I happen to do this in 3D) and arrange it into k clusters with distinct boundaries. It's nice here because you know exactly how many toes these canines (should) have.  Additionally, it's implemented in Scipy which is really nice (http://docs.scipy.org/doc/scipy/reference/cluster.vq.html).   Here's an example of what it can do to spatially resolve 3D clusters:   What you want to do is a bit different (2D and includes pressure values), but I still think you could give it a shot.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "6", "A_Content": "  Physicist's solution: Define 5 paw-markers identified by their positions X_i and init them with random positions. Define some energy function combining some award for location of markers in paws' positions with some punishment for overlap of markers; let's say:  E(X_i;S)=-Sum_i(S(X_i))+alfa*Sum_ij (|X_i-Xj|<=2*sqrt(2)?1:0)   (S(X_i) is the mean force in 2x2 square around X_i, alfa is a parameter to be peaked experimentally)  Now time to do some Metropolis-Hastings magic:   1. Select random marker and move it by one pixel in random direction.   2. Calculate dE, the difference of energy this move caused.   3. Get an uniform random number from 0-1 and call it r.   4. If dE<0 or exp(-beta*dE)>r, accept the move and go to 1; if not, undo the move and go to 1. This should be repeated until the markers will converge to paws. Beta controls the scanning to optimizing tradeoff, so it should be also optimized experimentally; it can be also constantly increased with the time of simulation (simulated annealing).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "259", "A_Content": "  You can't get any better than that.  After all, any solution will have to read the entire file, figure out how many \\n you have, and return that result.  Do you have a better way of doing that without reading the entire file? Not sure... The best solution will always be I/O-bound, best you can do is make sure you don't use unnecessary memory, but it looks like you have that covered.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "5", "A_Content": "  Heres another approach that I used when doing something similar for a large telescope:  1) Search for the highest pixel.  Once you have that, search around that for the best fit for 2x2 (maybe maximizing the 2x2 sum), or do a 2d gaussian fit inside the sub region of say 4x4 centered on the highest pixel.  Then set those 2x2 pixels you have found to zero (or maybe 3x3) around the peak center  go back to 1) and repeat till the highest peak falls below a noise threshold, or you have all the toes you need     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "5", "A_Content": "  It's probably worth to try with neural networks if you are able to create some training data... but this needs many samples annotated by hand.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "5", "A_Content": "  a rough outline...  you'd probably want to use a connected components algorithm to isolate each paw region. wiki has a decent description of this (with some code) here: http://en.wikipedia.org/wiki/Connected_Component_Labeling  you'll have to make a decision about whether to use 4 or 8 connectedness. personally, for most problems i prefer 6-connectedness. anyway, once you've separated out each \"paw print\" as a connected region, it should be easy enough to iterate through the region and find the maxima. once you've found the maxima, you could iteratively enlarge the region until you reach a predetermined threshold in order to identify it as a given \"toe\".   one subtle problem here is that as soon as you start using computer vision techniques to identify something as a right/left/front/rear paw and you start looking at individual toes, you have to start taking rotations, skews, and translations into account. this is accomplished through the analysis of so-called \"moments\". there are a few different moments to consider in vision applications:   central moments: translation invariant normalized moments: scaling and translation invariant hu moments: translation, scale, and rotation invariant   more information about moments can be found by searching \"image moments\" on wiki.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "4", "A_Content": "  Perhaps you can use something like Gaussian Mixture Models. Here's a Python package for doing GMMs (just did a Google search) http://www.ar.media.kyoto-u.ac.jp/members/david/softwares/em/     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "3", "A_Content": "  Well, here's some simple and not terribly efficient code, but for this size of a data set it is fine.  import numpy as np grid = np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0],               [0,0,0,0,0,0,0,0,0.4,0.4,0.4,0,0,0],               [0,0,0,0,0.4,1.4,1.4,1.8,0.7,0,0,0,0,0],               [0,0,0,0,0.4,1.4,4,5.4,2.2,0.4,0,0,0,0],               [0,0,0.7,1.1,0.4,1.1,3.2,3.6,1.1,0,0,0,0,0],               [0,0.4,2.9,3.6,1.1,0.4,0.7,0.7,0.4,0.4,0,0,0,0],               [0,0.4,2.5,3.2,1.8,0.7,0.4,0.4,0.4,1.4,0.7,0,0,0],               [0,0,0.7,3.6,5.8,2.9,1.4,2.2,1.4,1.8,1.1,0,0,0],               [0,0,1.1,5,6.8,3.2,4,6.1,1.8,0.4,0.4,0,0,0],               [0,0,0.4,1.1,1.8,1.8,4.3,3.2,0.7,0,0,0,0,0],               [0,0,0,0,0,0.4,0.7,0.4,0,0,0,0,0,0]])  arr = [] for i in xrange(grid.shape[0] - 1):     for j in xrange(grid.shape[1] - 1):         tot = grid[i][j] + grid[i+1][j] + grid[i][j+1] + grid[i+1][j+1]         arr.append([(i,j),tot])  best = []  arr.sort(key = lambda x: x[1])  for i in xrange(5):     best.append(arr.pop())     badpos = set([(best[-1][0][0]+x,best[-1][0][1]+y)                   for x in [-1,0,1] for y in [-1,0,1] if x != 0 or y != 0])     for j in xrange(len(arr)-1,-1,-1):         if arr[j][0] in badpos:             arr.pop(j)   for item in best:     print grid[item[0][0]:item[0][0]+2,item[0][1]:item[0][1]+2]   I basically just make an array with the position of the upper-left and the sum of each 2x2 square and sort it by the sum. I then take the 2x2 square with the highest sum out of contention, put it in the best array, and remove all other 2x2 squares that used any part of this just removed 2x2 square.  It seems to work fine except with the last paw (the one with the smallest sum on the far right in your first picture), it turns out that there are two other eligible 2x2 squares with a larger sum (and they have an equal sum to each other). One of them is still selects one square from your 2x2 square, but the other is off to the left. Fortunately, by luck we see to be choosing more of the one that you would want, but this may require some other ideas to be used to get what you actually want all of the time.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "3", "A_Content": "  It seems you can cheat a bit using jetxee's algorithm.  He is finding the first three toes fine, and you should be able to guess where the fourth is based off that.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "3", "A_Content": "  Interesting problem.  The solution I would try is the following.   Apply a low pass filter, such as convolution with a 2D gaussian mask.  This will give you a bunch of (probably, but not necessarily floating point) values. Perform a 2D non-maximal suppression using the known approximate radius of each paw pad (or toe).   This should give you the maximal positions without having multiple candidates which are close together.  Just to clarify, the radius of the mask in step 1 should also be similar to the radius used in step 2.  This radius could be selectable, or the vet could explicitly measure it beforehand (it will vary with age/breed/etc).  Some of the solutions suggested (mean shift, neural nets, and so on) probably will work to some degree, but are overly complicated and probably not ideal.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "2", "A_Content": "  just wanna tell you guys there is a nice option to find local maxima in images with python.  from skimage.feature import peak_local_max   or for skimage 0.8.0  from skimage.feature.peak import peak_local_max   http://scikit-image.org/docs/0.8.0/api/skimage.feature.peak.html     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "0", "A_Content": "  Maybe a naive approach is sufficient here: Build a list of all 2x2 squares on your plane, order them by their sum (in descending order).   First, select the highest-valued square into your \"paw list\". Then, iteratively pick 4 of the next-best squares that don't intersect with any of the previously found squares.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "0", "A_Content": "  What if you proceed step by step: you first locate the global maximum, process if needed the surrounding points given their value, then set the found region to zero, and repeat for the next one.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array", "Language": "Python", "Q_Title": "Peak detection in a 2D array", "Q_Votes": "749", "Q_Content": "    I'm helping a veterinary clinic measuring pressure under a dogs paw. I use Python for my data analysis and now I'm stuck trying to divide the paws into (anatomical) subregions.  I made a 2D array of each paw, that consists of the maximal values for each sensor that has been loaded by the paw over time. Here's an example of one paw, where I used Excel to draw the areas I want to 'detect'. These are 2 by 2 boxes around the sensor with local maxima's, that together have the largest sum.    So I tried some experimenting and decide to simply look for the maximums of each column and row (can't look in one direction due to the shape of the paw). This seems to 'detect' the location of the separate toes fairly well, but it also marks neighboring sensors.     So what would be the best way to tell Python which of these maximums are the ones I want?   Note: The 2x2 squares can't overlap, since they have to be separate toes!  Also I took 2x2 as a convenience, any more advanced solution is welcome, but I'm simply a human movement scientist, so I'm neither a real programmer or a mathematician, so please keep it 'simple'.   Here's a version that can be loaded with np.loadtxt    Results  So I tried @jextee's solution (see the results below). As you can see, it works very on the front paws, but it works less well for the hind legs.   More specifically, it can't recognize the small peak that's the fourth toe. This is obviously inherent to the fact that the loop looks top down towards the lowest value, without taking into account where this is.   Would anyone know how to tweak @jextee's algorithm, so that it might be able to find the 4th toe too?    Since I haven't processed any other trials yet, I can't supply any other samples. But the data I gave before were the averages of each paw. This file is an array with the maximal data of 9 paws in the order they made contact with the plate.  This image shows how they were spatially spread out over the plate.    Update:  I have set up a blog for anyone interested and I have setup a SkyDrive with all the raw measurements. So to anyone requesting more data: more power to you!     New update:  So after the help I got with my questions regarding paw detection and paw sorting, I was finally able to check the toe detection for every paw! Turns out, it doesn't work so well in anything but paws sized like the one in my own example. Off course in hindsight, it's my own fault for choosing the 2x2 so arbitrarily.  Here's a nice example of where it goes wrong: a nail is being recognized as a toe and the 'heel' is so wide, it gets recognized twice!    The paw is too large, so taking a 2x2 size with no overlap, causes some toes to be detected twice. The other way around, in small dogs it often fails to find a 5th toe, which I suspect is being caused by the 2x2 area being too large.  After trying the current solution on all my measurements I came to the staggering conclusion that for nearly all my small dogs it didn't find a 5th toe and that in over 50% of the impacts for the large dogs it would find more!  So clearly I need to change it. My own guess was changing the size of the neighborhood to something smaller for small dogs and larger for large dogs. But generate_binary_structure wouldn't let me change the size of the array.   Therefore, I'm hoping that anyone else has a better suggestion for locating the toes, perhaps having the toe area scale with the paw size?     ", "Tags": ["python", "image-processing"], "A_Votes": "0", "A_Content": "  I am not sure this answers the question, but it seems like you can just look for the n highest peaks that don't have neighbors.  Here is the gist.  Note that it's in Ruby, but the idea should be clear.  require 'pp'  NUM_PEAKS = 5 NEIGHBOR_DISTANCE = 1  data = [[1,2,3,4,5],         [2,6,4,4,6],         [3,6,7,4,3],        ]  def tuples(matrix)   tuples = []   matrix.each_with_index { |row, ri|     row.each_with_index { |value, ci|       tuples << [value, ri, ci]     }   }   tuples end  def neighbor?(t1, t2, distance = 1)   [1,2].each { |axis|     return false if (t1[axis] - t2[axis]).abs > distance   }   true end  # convert the matrix into a sorted list of tuples (value, row, col), highest peaks first sorted = tuples(data).sort_by { |tuple| tuple.first }.reverse  # the list of peaks that don't have neighbors non_neighboring_peaks = []  sorted.each { |candidate|   # always take the highest peak   if non_neighboring_peaks.empty?     non_neighboring_peaks << candidate     puts \"took the first peak: #{candidate}\"   else     # check that this candidate doesn't have any accepted neighbors     is_ok = true     non_neighboring_peaks.each { |accepted|       if neighbor?(candidate, accepted, NEIGHBOR_DISTANCE)         is_ok = false         break       end     }     if is_ok       non_neighboring_peaks << candidate       puts \"took #{candidate}\"     else       puts \"denied #{candidate}\"     end   end }  pp non_neighboring_peaks      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "481", "A_Content": "  One line, probably pretty fast:  num_lines = sum(1 for line in open('myfile.txt'))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "178", "A_Content": "  I believe that a memory mapped file will be the fastest solution. I tried four functions: the function posted by the OP (opcount); a simple iteration over the lines in the file (simplecount); readline with a memory-mapped filed (mmap) (mapcount); and the buffer read solution offered by Mykola Kharechko (bufcount).  I ran each function five times, and calculated the average run-time for a 1.2 million-line text file.  Windows XP, Python 2.5, 2GB RAM, 2 GHz AMD processor  Here are my results:  mapcount : 0.465599966049 simplecount : 0.756399965286 bufcount : 0.546800041199 opcount : 0.718600034714   Edit: numbers for Python 2.6:  mapcount : 0.471799945831 simplecount : 0.634400033951 bufcount : 0.468800067902 opcount : 0.602999973297   So the buffer read strategy seems to be the fastest for Windows/Python 2.6  Here is the code:  from __future__ import with_statement import time import mmap import random from collections import defaultdict  def mapcount(filename):     f = open(filename, \"r+\")     buf = mmap.mmap(f.fileno(), 0)     lines = 0     readline = buf.readline     while readline():         lines += 1     return lines  def simplecount(filename):     lines = 0     for line in open(filename):         lines += 1     return lines  def bufcount(filename):     f = open(filename)                       lines = 0     buf_size = 1024 * 1024     read_f = f.read # loop optimization      buf = read_f(buf_size)     while buf:         lines += buf.count('\\n')         buf = read_f(buf_size)      return lines  def opcount(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   counts = defaultdict(list)  for i in range(5):     for func in [mapcount, simplecount, bufcount, opcount]:         start_time = time.time()         assert func(\"big_file.txt\") == 1209138         counts[func].append(time.time() - start_time)  for key, vals in counts.items():     print key.__name__, \":\", sum(vals) / float(len(vals))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "76", "A_Content": "  I had to post this on a similar question until my reputation score jumped a bit (thanks to whoever bumped me!).   All of these solutions ignore one way to make this run considerably faster, namely by using the unbuffered (raw) interface, using bytearrays, and doing your own buffering. (This only applies in Python 3.  In Python 2, the raw interface may or may not be used by default, but in Python 3, you'll default into Unicode.)  Using a modified version of the timing tool, I believe the following code is faster (and marginally more pythonic) than any of the solutions offered:  def rawcount(filename):     f = open(filename, 'rb')     lines = 0     buf_size = 1024 * 1024     read_f = f.raw.read      buf = read_f(buf_size)     while buf:         lines += buf.count(b'\\n')         buf = read_f(buf_size)      return lines   Using a separate generator function, this runs a smidge faster:  def _make_gen(reader):     b = reader(1024 * 1024)     while b:         yield b         b = reader(1024*1024)  def rawgencount(filename):     f = open(filename, 'rb')     f_gen = _make_gen(f.raw.read)     return sum( buf.count(b'\\n') for buf in f_gen )   This can be done completely with generators expressions in-line using itertools, but it gets pretty weird looking:  from itertools import (takewhile,repeat)  def rawincount(filename):     f = open(filename, 'rb')     bufgen = takewhile(lambda x: x, (f.raw.read(1024*1024) for _ in repeat(None)))     return sum( buf.count(b'\\n') for buf in bufgen )   Here are my timings:  function      average, s  min, s   ratio rawincount        0.0043  0.0041   1.00 rawgencount       0.0044  0.0042   1.01 rawcount          0.0048  0.0045   1.09 bufcount          0.008   0.0068   1.64 wccount           0.01    0.0097   2.35 itercount         0.014   0.014    3.41 opcount           0.02    0.02     4.83 kylecount         0.021   0.021    5.05 simplecount       0.022   0.022    5.25 mapcount          0.037   0.031    7.46      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "73", "A_Content": "  You could execute a subprocess and run wc -l filename  import subprocess  def file_len(fname):     p = subprocess.Popen(['wc', '-l', fname], stdout=subprocess.PIPE,                                                stderr=subprocess.PIPE)     result, err = p.communicate()     if p.returncode != 0:         raise IOError(err)     return int(result.strip().split()[0])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "32", "A_Content": "  Here is a python program to use the multiprocessing library to distribute the line counting across machines/cores.  My test improves counting a 20million line file from 26 seconds to 7 seconds using an 8 core windows 64 server.  Note: not using memory mapping makes things much slower.  import multiprocessing, sys, time, os, mmap import logging, logging.handlers  def init_logger(pid):     console_format = 'P{0} %(levelname)s %(message)s'.format(pid)     logger = logging.getLogger()  # New logger at root level     logger.setLevel( logging.INFO )     logger.handlers.append( logging.StreamHandler() )     logger.handlers[0].setFormatter( logging.Formatter( console_format, '%d/%m/%y %H:%M:%S' ) )  def getFileLineCount( queues, pid, processes, file1 ):     init_logger(pid)     logging.info( 'start' )      physical_file = open(file1, \"r\")     #  mmap.mmap(fileno, length[, tagname[, access[, offset]]]      m1 = mmap.mmap( physical_file.fileno(), 0, access=mmap.ACCESS_READ )      #work out file size to divide up line counting      fSize = os.stat(file1).st_size     chunk = (fSize / processes) + 1      lines = 0      #get where I start and stop     _seedStart = chunk * (pid)     _seekEnd = chunk * (pid+1)     seekStart = int(_seedStart)     seekEnd = int(_seekEnd)      if seekEnd < int(_seekEnd + 1):         seekEnd += 1      if _seedStart < int(seekStart + 1):         seekStart += 1      if seekEnd > fSize:         seekEnd = fSize      #find where to start     if pid > 0:         m1.seek( seekStart )         #read next line         l1 = m1.readline()  # need to use readline with memory mapped files         seekStart = m1.tell()      #tell previous rank my seek start to make their seek end      if pid > 0:         queues[pid-1].put( seekStart )     if pid < processes-1:         seekEnd = queues[pid].get()      m1.seek( seekStart )     l1 = m1.readline()      while len(l1) > 0:         lines += 1         l1 = m1.readline()         if m1.tell() > seekEnd or len(l1) == 0:             break      logging.info( 'done' )     # add up the results     if pid == 0:         for p in range(1,processes):             lines += queues[0].get()         queues[0].put(lines) # the total lines counted     else:         queues[0].put(lines)      m1.close()     physical_file.close()  if __name__ == '__main__':     init_logger( 'main' )     if len(sys.argv) > 1:         file_name = sys.argv[1]     else:         logging.fatal( 'parameters required: file-name [processes]' )         exit()      t = time.time()     processes = multiprocessing.cpu_count()     if len(sys.argv) > 2:         processes = int(sys.argv[2])     queues=[] # a queue for each process     for pid in range(processes):         queues.append( multiprocessing.Queue() )     jobs=[]     prev_pipe = 0     for pid in range(processes):         p = multiprocessing.Process( target = getFileLineCount, args=(queues, pid, processes, file_name,) )         p.start()         jobs.append(p)      jobs[0].join() #wait for counting to finish     lines = queues[0].get()      logging.info( 'finished {} Lines:{}'.format( time.time() - t, lines ) )      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "11", "A_Content": "  I would use Python's file object method readlines, as follows:  with open(input_file) as foo:     lines = len(foo.readlines())   This opens the file, creates a list of lines in the file, counts the length of the list, saves that to a variable and closes the file again.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "8", "A_Content": "  def file_len(full_path):   \"\"\" Count number of lines in a file.\"\"\"   f = open(full_path)   nr_of_lines = sum(1 for line in f)   f.close()   return nr_of_lines      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "8", "A_Content": "  Kyle's answer   num_lines = sum(1 for line in open('my_file.txt'))   is probably best, an alternative for this is  num_lines =  len(open('my_file.txt').read().splitlines())   Here is the comparision of performance of both   In [20]: timeit sum(1 for line in open('Charts.ipynb')) 100000 loops, best of 3: 9.79 \u00b5s per loop  In [21]: timeit len(open('Charts.ipynb').read().splitlines()) 100000 loops, best of 3: 12 \u00b5s per loop      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "7", "A_Content": "  I got a small (4-8%) improvement with this version which re-uses a constant buffer so it should avoid any memory or GC overhead:  lines = 0 buffer = bytearray(2048) with open(filename) as f:   while f.readinto(buffer) > 0:       lines += buffer.count('\\n')   You can play around with the buffer size and maybe see a little improvement.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "7", "A_Content": "  This code is shorter and clearer. It's probably the best way:  num_lines = open('yourfile.ext').read().count('\\n')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "7", "A_Content": "  one line solution  import os os.system(\"wc -l  filename\")     my snippet                 os.system('wc -l *.txt')           0 bar.txt 1000 command.txt 3 test_file.txt 1003 total      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "6", "A_Content": "  This is the fastest thing I have found using pure python. You can use whatever amount of memory you want by setting buffer, though 2**16 appears to be a sweet spot on my computer.    from functools import partial  buffer=2**16 with open(myfile) as f:         print sum(x.count('\\n') for x in iter(partial(f.read,buffer), ''))   I found the answer here Why is reading lines from stdin much slower in C++ than Python? and tweaked it just a tiny bit.  Its a very good read to understand how to count lines quickly, though wc -l is still about 75% faster than anything else.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "5", "A_Content": "  print open('file.txt', 'r').read().count(\"\\n\") + 1      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "4", "A_Content": "  the result of opening a file is an iterator, which can be converted to a sequence, which has a length:  with open(filename) as f:    return len(list(f))   this is more concise than your explicit loop, and avoids the enumerate.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "4", "A_Content": "  Just to complete the above methods I tried a variant with the fileinput module:  import fileinput as fi    def filecount(fname):         for line in fi.input(fname):             pass         return fi.lineno()   And passed a 60mil lines file to all the above stated methods:  mapcount : 6.1331050396 simplecount : 4.588793993 opcount : 4.42918205261 filecount : 43.2780818939 bufcount : 0.170812129974   It's a little surprise to me that fileinput is that bad and scales far worse than all the other methods...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "4", "A_Content": "  count = max(enumerate(open(filename)))[0]     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "4", "A_Content": "  Here is what I use, seems pretty clean:  import subprocess  def count_file_lines(file_path):     \"\"\"     Counts the number of lines in a file using wc utility.     :param file_path: path to file     :return: int, no of lines     \"\"\"     num = subprocess.check_output(['wc', '-l', file_path])     num = num.split(' ')     return int(num[0])   UPDATE: This is marginally faster than using pure python but at the cost of memory usage. Subprocess will fork a new process with the same memory footprint as the parent process while it executes your command.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "1153", "A_Content": "  You could use a dictionary:  def f(x):     return {         'a': 1,         'b': 2,     }[x]      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "3", "A_Content": "  What about this  def file_len(fname):   counts = itertools.count()   with open(fname) as f:      for _ in f: counts.next()   return counts.next()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "3", "A_Content": "  As for me this variant will be the fastest:  #!/usr/bin/env python  def main():     f = open('filename')                       lines = 0     buf_size = 1024 * 1024     read_f = f.read # loop optimization      buf = read_f(buf_size)     while buf:         lines += buf.count('\\n')         buf = read_f(buf_size)      print lines  if __name__ == '__main__':     main()   reasons: buffering faster than reading line by line and string.count is also very fast     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "3", "A_Content": "  I have modified the buffer case like this:  def CountLines(filename):     f = open(filename)     try:         lines = 1         buf_size = 1024 * 1024         read_f = f.read # loop optimization         buf = read_f(buf_size)          # Empty file         if not buf:             return 0          while buf:             lines += buf.count('\\n')             buf = read_f(buf_size)          return lines     finally:         f.close()   Now also empty files and the last line (without \\n) are counted.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "3", "A_Content": "  A one-line bash solution similar to this answer, using the modern subprocess.check_output function:  def line_count(file):     return int(subprocess.check_output('wc -l {}'.format(file), shell=True).split()[0])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "1", "A_Content": "  How about this?  import fileinput import sys  counter=0 for line in fileinput.input([sys.argv[1]]):     counter+=1  fileinput.close() print counter      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "1", "A_Content": "  How about this one-liner:  file_length = len(open('myfile.txt','r').read().split('\\n'))   Takes 0.003 sec using this method to time it on a 3900 line file  def c():   import time   s = time.time()   file_length = len(open('myfile.txt','r').read().split('\\n'))   print time.time() - s      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "1", "A_Content": "  def line_count(path):     count = 0     with open(path) as lines:         for count, l in enumerate(lines, start=1):             pass     return count      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "1", "A_Content": "  If one wants to get the line count cheaply in Python in Linux, I recommend this method:  import os print os.popen(\"wc -l file_path\").readline().split()[0]   file_path can be both abstract file path or relative path. Hope this may help.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "1", "A_Content": "  Another possibility:   import subprocess  def num_lines_in_file(fpath):     return int(subprocess.check_output('wc -l %s' % fpath, shell=True).strip().split()[0])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "1", "A_Content": "  def count_text_file_lines(path):     with open(path, 'rt') as file:         line_count = sum(1 for _line in file)     return line_count      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "0", "A_Content": "  Why not read the first 100 and the last 100 lines and estimate the average line length, then divide the total file size through that numbers? If you don't need a exact value this could work.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/845058/how-to-get-line-count-cheaply-in-python", "Language": "Python", "Q_Title": "How to get line count cheaply in Python?", "Q_Votes": "745", "Q_Content": "    I need to get a line count of a large file (hundreds of thousands of lines) in python. What is the most efficient way both memory- and time-wise?  At the moment I do:  def file_len(fname):     with open(fname) as f:         for i, l in enumerate(f):             pass     return i + 1   is it possible to do any better?     ", "Tags": ["python", "text-files", "line-count"], "A_Votes": "0", "A_Content": "  what about this?  import sys sys.stdin=open('fname','r') data=sys.stdin.readlines() print \"counted\",len(data),\"lines\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "1135", "A_Content": "  If you'd like defaults you could use the dictionary get(key[, default]) method:  def f(x):     return {         'a': 1,         'b': 2     }.get(x, 9)    # 9 is default if x not found      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "306", "A_Content": "  I've always liked doing it this way  result = {   'a': lambda x: x * 5,   'b': lambda x: x + 7,   'c': lambda x: x - 2 }[value](x)   From here     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "253", "A_Content": "  In addition to the dictionary methods (which I really like, BTW), you can also use if-elif-else to obtain the switch/case/default functionality:  if x == 'a':     # Do the thing elif x == 'b':     # Do the other thing if x in 'bc':     # Fall-through by not using elif, but now the default case includes case 'a'! elif x in 'xyz':     # Do yet another thing else:     # Do the default   This of course is not identical to switch/case - you cannot have fall-through as easily as leaving off the break; statement, but you can have a more complicated test.  Its formatting is nicer than a series of nested ifs, even though functionally that's what it is closer to.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "127", "A_Content": "  My favorite Python recipe for switch/case is:  choices = {'a': 1, 'b': 2} result = choices.get(key, 'default')   Short and simple for simple scenarios.   Compare to 11+ lines of C code:  // C Language version of a simple 'switch/case'. switch( key )  {     case 'a' :         result = 1;         break;     case 'b' :         result = 2;         break;     default :         result = -1; }   You can even assign multiple variables by using tuples:  choices = {'a': (1, 2, 3), 'b': (4, 5, 6)} (result1, result2, result3) = choices.get(key, ('default1', 'default2', 'default3'))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "87", "A_Content": "  class switch(object):     value = None     def __new__(class_, value):         class_.value = value         return True  def case(*args):     return any((arg == switch.value for arg in args))   Usage:  while switch(n):     if case(0):         print \"You typed zero.\"         break     if case(1, 4, 9):         print \"n is a perfect square.\"         break     if case(2):         print \"n is an even number.\"     if case(2, 3, 5, 7):         print \"n is a prime number.\"         break     if case(6, 8):         print \"n is an even number.\"         break     print \"Only single-digit numbers are allowed.\"     break   Tests:  n = 2 #Result: #n is an even number. #n is a prime number. n = 11 #Result: #Only single-digit numbers are allowed.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "41", "A_Content": "  There's a pattern that I learned from Twisted Python code.  class SMTP:     def lookupMethod(self, command):         return getattr(self, 'do_' + command.upper(), None)     def do_HELO(self, rest):         return 'Howdy ' + rest     def do_QUIT(self, rest):         return 'Bye'  SMTP().lookupMethod('HELO')('foo.bar.com') # => 'Howdy foo.bar.com' SMTP().lookupMethod('QUIT')('') # => 'Bye'   You can use it any time you need to dispatch on a token and execute extended piece of code. In a state machine you would have state_ methods, and dispatch on self.state. This switch can be cleanly extended by inheriting from base class and defining your own do_ methods. Often times you won't even have do_ methods in the base class.  Edit: how exactly is that used  In case of SMTP you will receive HELO from the wire. The relevant code (from twisted/mail/smtp.py, modified for our case) looks like this  class SMTP:     # ...      def do_UNKNOWN(self, rest):         raise NotImplementedError, 'received unknown command'      def state_COMMAND(self, line):         line = line.strip()         parts = line.split(None, 1)         if parts:             method = self.lookupMethod(parts[0]) or self.do_UNKNOWN             if len(parts) == 2:                 return method(parts[1])             else:                 return method('')         else:             raise SyntaxError, 'bad syntax'  SMTP().state_COMMAND('   HELO   foo.bar.com  ') # => Howdy foo.bar.com   You'll receive '  HELO   foo.bar.com ' (or you might get 'QUIT' or 'RCPT TO: foo'). This is tokenized into parts as ['HELO', 'foo.bar.com']. The actual method lookup name is taken from parts[0].  (The original method is also called state_COMMAND, because it uses the same pattern to implement a state machine, i.e. getattr(self, 'state_' + self.mode))     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "38", "A_Content": "  My favorite one is a really nice recipe. You'll really like it. It's the closest one I've seen to actual switch case statements, especially in features.  Here's an example:  # The following example is pretty much the exact use-case of a dictionary, # but is included for its simplicity. Note that you can include statements # in each suite. v = 'ten' for case in switch(v):     if case('one'):         print 1         break     if case('two'):         print 2         break     if case('ten'):         print 10         break     if case('eleven'):         print 11         break     if case(): # default, could also just omit condition or 'if True'         print \"something else!\"         # No need to break here, it'll stop anyway  # break is used here to look as much like the real thing as possible, but # elif is generally just as good and more concise.  # Empty suites are considered syntax errors, so intentional fall-throughs # should contain 'pass' c = 'z' for case in switch(c):     if case('a'): pass # only necessary if the rest of the suite is empty     if case('b'): pass     # ...     if case('y'): pass     if case('z'):         print \"c is lowercase!\"         break     if case('A'): pass     # ...     if case('Z'):         print \"c is uppercase!\"         break     if case(): # default         print \"I dunno what c was!\"  # As suggested by Pierre Quentel, you can even expand upon the # functionality of the classic 'case' statement by matching multiple # cases in a single shot. This greatly benefits operations such as the # uppercase/lowercase example above: import string c = 'A' for case in switch(c):     if case(*string.lowercase): # note the * for unpacking as arguments         print \"c is lowercase!\"         break     if case(*string.uppercase):         print \"c is uppercase!\"         break     if case('!', '?', '.'): # normal argument passing style also applies         print \"c is a sentence terminator!\"         break     if case(): # default         print \"I dunno what c was!\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "29", "A_Content": "  class Switch:     def __init__(self, value): self._val = value     def __enter__(self): return self     def __exit__(self, type, value, traceback): return False # Allows traceback to occur     def __call__(self, *mconds): return self._val in mconds  from datetime import datetime with Switch(datetime.today().weekday()) as case:     if case(0):         # Basic usage of switch         print(\"I hate mondays so much.\")         # Note there is no break needed here     elif case(1,2):         # This switch also supports multiple conditions (in one line)         print(\"When is the weekend going to be here?\")     elif case(3,4): print(\"The weekend is near.\")     else:         # Default would occur here         print(\"Let's go have fun!\") # Didn't use case for example purposes      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "23", "A_Content": "  Let's say you don't want to just return a value, but want to use methods that change something on an object. Using the approach stated here would be:  result = {   'a': obj.increment(x),   'b': obj.decrement(x) }.get(value, obj.default(x))   What happens here is that python evaluates all methods in the dictionary. So even if your value is 'a', the object will get incremented and decremented by x.  Solution:  func, args = {   'a' : (obj.increment, (x,)),   'b' : (obj.decrement, (x,)), }.get(value, (obj.default, (x,)))  result = func(*args)   So you get a list containing a function and its arguments. This way, only the function pointer and the argument list get returned, not evaluated. 'result' then evaluates the returned function call.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "15", "A_Content": "  I'm just going to drop my two cents in here.  The reason there isn't a case/switch statement in Python is because Python follows the principle of 'Theres only one right way to do something'.   So obviously you could come up with various ways of recreating switch/case functionality, but the Pythonic way of accomplishing this is the if/elif construct. ie  if something:     return \"first thing\" elif somethingelse:     return \"second thing\" elif yetanotherthing:     return \"third thing\" else:     return \"default thing\"   I just felt PEP 8 deserved a nod here.  One of the beautiful things about Python is its simplicity and elegance.  That is largely derived from principles laid our in PEP 8, including \"There's only one right way to do something\"     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "13", "A_Content": "  expanding on the \"dict as switch\" idea. if you want to use a default value for your switch:  def f(x):     try:         return {             'a': 1,             'b': 2,         }[x]     except KeyError:         return 'default'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "13", "A_Content": "  If you have a complicated case block you can consider using a function dictionary lookup table...   If you haven't done this before its a good idea to step into your debugger and view exactly how the dictionary looks up each function.    NOTE: Do not use \"()\" inside the case/dictionary lookup or it will call each of your functions as the dictionary / case block is created.  Remember this because you only want to call each function once using a hash style lookup.  def first_case():     print \"first\"  def second_case():     print \"second\"  def third_case():     print \"third\"  mycase = { 'first': first_case, #do not use () 'second': second_case, #do not use () 'third': third_case #do not use () } myfunc = mycase['first'] myfunc()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "13", "A_Content": "  If you're searching extra-statement, as \"switch\", I built a python module that extends Python. It's called ESPY as \"Enhanced Structure for Python\" and it's available for both Python 2.x and Python 3.x.  For example, in this case, a switch statement could be performed by the following code:  macro switch(arg1):     while True:         cont=False         val=%arg1%         socket case(arg2):             if val==%arg2% or cont:                 cont=True                 socket         socket else:             socket         break   that can be used like this:  a=3 switch(a):     case(0):         print(\"Zero\")     case(1):         print(\"Smaller than 2\"):         break     else:         print (\"greater than 1\")   so espy translate it in Python as:  a=3 while True:     cont=False     if a==0 or cont:         cont=True         print (\"Zero\")     if a==1 or cont:         cont=True         print (\"Smaller than 2\")         break     print (\"greater than 1\")     break      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "12", "A_Content": "  I didn't find the simple answer I was looking for anywhere on Google search. But I figured it out anyway. It's really quite simple. Decided to post it, and maybe prevent a few less scratches on someone else's head. The key is simply \"in\" and tuples. Here is the switch statement behavior with fall-through, including RANDOM fall-through.  l = ['Dog', 'Cat', 'Bird', 'Bigfoot',      'Dragonfly', 'Snake', 'Bat', 'Loch Ness Monster']  for x in l:     if x in ('Dog', 'Cat'):         x += \" has four legs\"     elif x in ('Bat', 'Bird', 'Dragonfly'):         x += \" has wings.\"     elif x in ('Snake',):         x += \" has a forked tongue.\"     else:         x += \" is a big mystery by default.\"     print(x)  print()  for x in range(10):     if x in (0, 1):         x = \"Values 0 and 1 caught here.\"     elif x in (2,):         x = \"Value 2 caught here.\"     elif x in (3, 7, 8):         x = \"Values 3, 7, 8 caught here.\"     elif x in (4, 6):         x = \"Values 4 and 6 caught here\"     else:         x = \"Values 5 and 9 caught in default.\"     print(x)   Provides:  Dog has four legs Cat has four legs Bird has wings. Bigfoot is a big mystery by default. Dragonfly has wings. Snake has a forked tongue. Bat has wings. Loch Ness Monster is a big mystery by default.  Values 0 and 1 caught here. Values 0 and 1 caught here. Value 2 caught here. Values 3, 7, 8 caught here. Values 4 and 6 caught here Values 5 and 9 caught in default. Values 4 and 6 caught here Values 3, 7, 8 caught here. Values 3, 7, 8 caught here. Values 5 and 9 caught in default.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "12", "A_Content": "  I found that a common switch structure:  switch ...parameter... case p1: v1; break; case p2: v2; break; default: v3;   can be expressed in Python as follows:  (lambda x: v1 if p1(x) else v2 if p2(x) else v3)   or formatted in a clearer way:  (lambda x:      v1 if p1(x) else      v2 if p2(x) else      v3)   Instead of being a statement, the python version is an expression, which evaluates to a value.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "493", "A_Content": "  Solution  My 50 cents for getting a pip freeze-like list from a Python script:  import pip installed_packages = pip.get_installed_distributions() installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version)      for i in installed_packages]) print(installed_packages_list)   As a (too long) one liner:  sorted([\"%s==%s\" % (i.key, i.version) for i in pip.get_installed_distributions()])   Giving:  ['behave==1.2.4', 'enum34==1.0', 'flask==0.10.1', 'itsdangerous==0.24',   'jinja2==2.7.2', 'jsonschema==2.3.0', 'markupsafe==0.23', 'nose==1.3.3',   'parse-type==0.3.4', 'parse==1.6.4', 'prettytable==0.7.2', 'requests==2.3.0',  'six==1.6.1', 'vioozer-metadata==0.1', 'vioozer-users-server==0.1',   'werkzeug==0.9.4']   Scope  This solution applies to the system scope or to a virtual environment scope, and covers packages installed by setuptools, pip and (god forbid) easy_install.  My use case  I added the result of this call to my flask server, so when I call it with http://example.com/exampleServer/environment I get the list of packages installed on the server's virtualenv. It makes debugging a whole lot easier.  Caveats  I have noticed a strange behaviour of this technique - when the Python interpreter is invoked in the same directory as a setup.py file, it does not list the package installed by setup.py.  Steps to reproduce:  Create a virtual environment  $ cd /tmp $ virtualenv test_env New python executable in test_env/bin/python Installing setuptools, pip...done. $ source test_env/bin/activate (test_env) $    Clone a git repo with setup.py  (test_env) $ git clone https://github.com/behave/behave.git Cloning into 'behave'... remote: Reusing existing pack: 4350, done. remote: Total 4350 (delta 0), reused 0 (delta 0) Receiving objects: 100% (4350/4350), 1.85 MiB | 418.00 KiB/s, done. Resolving deltas: 100% (2388/2388), done. Checking connectivity... done.   We have behave's setup.py in /tmp/behave:  (test_env) $ ls /tmp/behave/setup.py /tmp/behave/setup.py   Install the python package from the git repo  (test_env) $ cd /tmp/behave && python setup.py install running install ... Installed /private/tmp/test_env/lib/python2.7/site-packages/enum34-1.0-py2.7.egg Finished processing dependencies for behave==1.2.5a1   If we run the aforementioned solution from /tmp  >>> import pip >>> sorted([\"%s==%s\" % (i.key, i.version) for i in pip.get_installed_distributions()]) ['behave==1.2.5a1', 'enum34==1.0', 'parse-type==0.3.4', 'parse==1.6.4', 'six==1.6.1'] >>> import os >>> os.getcwd() '/private/tmp'   If we run the aforementioned solution from /tmp/behave  >>> import pip >>> sorted([\"%s==%s\" % (i.key, i.version) for i in pip.get_installed_distributions()]) ['enum34==1.0', 'parse-type==0.3.4', 'parse==1.6.4', 'six==1.6.1'] >>> import os >>> os.getcwd() '/private/tmp/behave'   behave==1.2.5a1 is missing from the second example, because the working directory contains behave's setup.py file.  I could not find any reference to this issue in the documentation. Perhaps I shall open a bug for it.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "10", "A_Content": "  The solutions I use:   A combination of 2 of the solutions posted here, which is relatively easy to read and supports defaults.  result = {   'a': lambda x: x * 5,   'b': lambda x: x + 7,   'c': lambda x: x - 2 }.get(whatToUse, lambda x: x - 22)(value)   where  .get('c', lambda x: x - 22)(23)   looks up \"lambda x: x - 2\" in the dict and uses it with x=23   .get('xxx', lambda x: x - 22)(44)   doesn't find it in the dict and uses the default \"lambda x: x - 22\" with x=44.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "8", "A_Content": "  # simple case alternative  some_value = 5.0  # this while loop block simulates a case block  # case while True:      # case 1     if some_value > 5:         print ('Greater than five')         break      # case 2     if some_value == 5:         print ('Equal to five')         break      # else case 3     print ( 'Must be less than 5')     break      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "6", "A_Content": "  I have made a (relatively) flexible and re-usable solution for this. It can be found at GitHub as this gist. If the result of the switch function is callable, it is automatically called.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "6", "A_Content": "  I liked Mark Bies's answer  Since the x variable must used twice, I modified the lambda functions to parameterless.  I have to run with  results[value](value)  In [2]: result = {     ...:   'a': lambda x: 'A',     ...:   'b': lambda x: 'B',     ...:   'c': lambda x: 'C'     ...: }     ...: result['a']('a')     ...:  Out[2]: 'A'  In [3]: result = {     ...:   'a': lambda : 'A',     ...:   'b': lambda : 'B',     ...:   'c': lambda : 'C',     ...:   None: lambda : 'Nothing else matters'      ...: }     ...: result['a']()     ...:  Out[3]: 'A'   Edit: I noticed that I can use None type with with dictionaries. So this would emulate switch ; case else     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "5", "A_Content": "  def f(x):      return 1 if x == 'a' else\\             2 if x in 'bcd' else\\             0 #default   Short and easy to read, has a default value and supports expressions in both conditions and return values.  However, it is less efficient than the solution with a dictionary. For example, Python has to scan through all the conditions before returning the default value.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "4", "A_Content": "  Defining:  def switch1(value, options):   if value in options:     options[value]()   allows you to use a fairly straightforward syntax, with the cases bundled into a map:  def sample1(x):   local = 'betty'   switch1(x, {     'a': lambda: print(\"hello\"),     'b': lambda: (       print(\"goodbye,\" + local),       print(\"!\")),     })   I kept trying to redefine switch in a way that would let me get rid of the \"lambda:\", but gave up.  Tweaking the definition:  def switch(value, *maps):   options = {}   for m in maps:     options.update(m)   if value in options:     options[value]()   elif None in options:     options[None]()   Allowed me to map multiple cases to the same code, and to supply a default option:  def sample(x):   switch(x, {     _: lambda: print(\"other\")      for _ in 'cdef'     }, {     'a': lambda: print(\"hello\"),     'b': lambda: (       print(\"goodbye,\"),       print(\"!\")),     None: lambda: print(\"I dunno\")     })   Each replicated case has to be in its own dictionary; switch() consolidates the dictionaries before looking up the value.  It's still uglier than I'd like, but it has the basic efficiency of using a hashed lookup on the expression, rather than a loop through all the keys.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "4", "A_Content": "  I think the best way is to use the python language idioms to keep your code testable. As showed in previous answers, I use dictionaries to take advantage of python structures and language and keep the \"case\" code isolated in different methods. Below there is a class, but you can use directly a module, globals and functions. The class has methods that can be tested with isolation. Dependending to your needs, you can play with static methods and attributes too.  class ChoiceManager:      def __init__(self):         self.__choice_table = \\         {             \"CHOICE1\" : self.my_func1,             \"CHOICE2\" : self.my_func2,         }      def my_func1(self, data):         pass      def my_func2(self, data):         pass      def process(self, case, data):         return self.__choice_table[case](data)  ChoiceManager().process(\"CHOICE1\", my_data)   It is possible to take advantage of this method using also classes as keys of \"__choice_table\". In this way you can avoid isinstance abuse and keep all clean and testable.  Supposing you have to process a lot of messages or packets from the net or your MQ. Every packet has its own structure and its management code (in a generic way). With the above code it is possible to do something like this:  class PacketManager:      def __init__(self):         self.__choice_table = \\         {             ControlMessage : self.my_func1,             DiagnosticMessage : self.my_func2,         }      def my_func1(self, data):         # process the control message here         pass      def my_func2(self, data):         # process the diagnostic message here         pass      def process(self, pkt):         return self.__choice_table[pkt.__class__](pkt)  pkt = GetMyPacketFromNet() PacketManager().process(pkt)   # isolated test or isolated usage example def test_control_packet():     p = ControlMessage()     PacketManager().my_func1(p)   So complexity is not spread in the code flow but it is rendered in code structure.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "4", "A_Content": "  Most of the answers here are pretty old, and especially the accepted ones, so it seems worth updating.  First, the official Python FAQ covers this, and recommends the elif chain for simple cases and the dict for larger or more complex cases. It also suggests a set of visit_ methods (a style used by many server frameworks) for some cases:  def dispatch(self, value):     method_name = 'visit_' + str(value)     method = getattr(self, method_name)     method()   The FAQ also mentions PEP 275, which was written to get an official once-and-for-all decision on adding C-style switch statements. But that PEP was actually deferred to Python 3, and it was only officially rejected as a separate proposal, PEP 3103. The answer was, of course, no\u2014but the two PEPs have links to additional information if you're interested in the reasons or the history.    One thing that came up multiple times (and can be seen in PEP 275, even though it was cut out as an actual recommendation) is that if you're really bothered by having 8 lines of code to handle 4 cases, vs. the 6 lines you'd have in C or Bash, you can always write this:  if x == 1: print('first') elif x == 2: print('second') elif x == 3: print('third') else: print('did not place')   This isn't exactly encouraged by PEP 8, but it's readable and not too unidiomatic.    Over the more than a decade since PEP 3103 was rejected, the issue of C-style case statements, or even the slightly more powerful version in Go, has been considered dead; whenever anyone brings it up on python-ideas or -dev, they're referred to the old decision.  However, the idea of full ML-style pattern matching arises every few years, especially since languages like Swift and Rust have adopted it. The problem is that it's hard to get much use out of pattern matching without algebraic data types. While Guido has been sympathetic to the idea, nobody's come up with a proposal that fits into Python very well. (You can read my 2014 strawman for an example.) This could change with dataclass in 3.7 and some sporadic proposals for a more powerful enum to handle sum types, or with various proposals for different kinds of statement-local bindings (like PEP 3150, or the set of proposals currently being discussed on -ideas). But so far, it hasn't.  There are also occasionally proposals for Perl 6-style matching, which is basically a mishmash of everything from elif to regex to single-dispatch type-switching.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "4", "A_Content": "  I made this small and clean solution   result = {     'case1':     foo1,      'case2':     foo2,     'case3':     foo3,     'default':   default, }.get(option)()   where foo1(), foo2(), foo3() and default() are functions     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "3", "A_Content": "  I was quite confused after reading the answer, but this cleared it all up:  def numbers_to_strings(argument):     switcher = {         0: \"zero\",         1: \"one\",         2: \"two\",     }     return switcher.get(argument, \"nothing\")   This code is analogous to:  function(argument){     switch(argument) {         case 0:             return \"zero\";         case 1:             return \"one\";         case 2:             return \"two\";         default:             return \"nothing\";     } }   Check the Source for more about dictionary mapping to functions.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "3", "A_Content": "  Inspired by this awesome answer. Requires no other code. Not tested. Realized that fall through does not work properly.  for case in [expression]:     if case == 1:         do_stuff()         # Fall through      if case in range(2, 5):         do_other_stuff()         break      do_default()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "3", "A_Content": "  A solution I tend to use which also makes use of dictionaries is :   def decision_time( key, *args, **kwargs):     def action1()         \"\"\"This function is a closure - and has access to all the arguments\"\"\"         pass     def action2()         \"\"\"This function is a closure - and has access to all the arguments\"\"\"         pass     def action3()         \"\"\"This function is a closure - and has access to all the arguments\"\"\"         pass     return {1:action1, 2:action2, 3:action3}.get(key,default)()   This has the advantage that it doesn't try to evaluate the functions every time, and you just have to ensure that the outer function gets all the information that the inner functions need.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "2", "A_Content": "  If you don't worry losing syntax highlight inside the case suites, you can do the following:  exec {     1: \"\"\" print ('one') \"\"\",      2: \"\"\" print ('two') \"\"\",      3: \"\"\" print ('three') \"\"\", }.get(value, \"\"\" print ('None') \"\"\")   Where value is the value. In C, this would be:  switch (value) {     case 1:         printf(\"one\");         break;     case 2:         printf(\"two\");         break;     case 3:         printf(\"three\");         break;     default:         printf(\"None\");         break; }   We can also create a helper function to do this:  def switch(value, cases, default):     exec cases.get(value, default)   So we can use it like this for the example with one, two and three:  switch(value, {     1: \"\"\" print ('one')     \"\"\",      2: \"\"\" print ('two')     \"\"\",      3: \"\"\" print ('three')     \"\"\", }, \"\"\" print ('None') \"\"\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python", "Language": "Python", "Q_Title": "Replacements for switch statement in Python?", "Q_Votes": "1487", "Q_Content": "    I want to write a function in Python that returns different fixed values based on the value of an input index.    In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?     ", "Tags": ["python"], "A_Votes": "2", "A_Content": "  Expanding on Greg Hewgill's answer - We can encapsulate the dictionary-solution using a decorator:  def case(callable):     \"\"\"switch-case decorator\"\"\"     class case_class(object):         def __init__(self, *args, **kwargs):             self.args = args             self.kwargs = kwargs          def do_call(self):             return callable(*self.args, **self.kwargs)  return case_class  def switch(key, cases, default=None):     \"\"\"switch-statement\"\"\"     ret = None     try:         ret = case[key].do_call()     except KeyError:         if default:             ret = default.do_call()     finally:         return ret   This can then be used with the @case-decorator  @case def case_1(arg1):     print 'case_1: ', arg1  @case def case_2(arg1, arg2):     print 'case_2'     return arg1, arg2  @case def default_case(arg1, arg2, arg3):     print 'default_case: ', arg1, arg2, arg3  ret = switch(somearg, {     1: case_1('somestring'),     2: case_2(13, 42) }, default_case(123, 'astring', 3.14))  print ret   The good news are that this has already been done in NeoPySwitch-module. Simply install using pip:  pip install NeoPySwitch      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "814", "A_Content": "  help('modules')   in a Python shell/prompt.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "226", "A_Content": "  Now, these methods I tried myself, and I got exactly what was advertised:  All the modules.  Alas, really you don't care much about the stdlib, you know what you get with a python install.    Really, I want the stuff that I installed.   What actually, surprisingly, worked just fine was:  pip freeze   Which returned:  Fabric==0.9.3 apache-libcloud==0.4.0 bzr==2.3b4 distribute==0.6.14 docutils==0.7 greenlet==0.3.1 ipython==0.10.1 iterpipes==0.4 libxml2-python==2.6.21   I say \"surprisingly\" because the package install tool is the exact place one would expect to find this functionality, although not under the name 'freeze' but python packaging is so weird, that I am flabbergasted that this tool makes sense.  Pip 0.8.2, Python 2.7.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "72", "A_Content": "   In ipython you can type \"importTab\". In the standard Python interpreter, you can type \"help('modules')\". At the command-line, you can use pydoc modules. In a script, call pkgutil.iter_modules().      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "64", "A_Content": "  Since pip version 1.3, you've got access to:  pip list   Which seems to be syntactic sugar for \"pip freeze\".  It will list all of the modules particular to your installation or virtualenv, along with their version numbers.  Unfortunately it does not display the current version number of any module, nor does it wash your dishes or shine your shoes.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "53", "A_Content": "  In normal shell just use  pydoc modules      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "52", "A_Content": "  I just use this to see currently used modules:  import sys as s s.modules.keys()   which shows all modules running on your python.  For all built-in modules use:  s.modules   Which is a dict containing all modules and import objects.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "19", "A_Content": "  If we need to list the installed packages in the Python shell, we can use the help command as follows  >>help('modules package')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "11", "A_Content": "  I ran into a custom installed python 2.7 on OS X. It required X11 to list modules installed (both using help and pydoc).  To be able to list all modules without installing X11 I ran pydoc as http-server, i.e.:  pydoc -p 12345   Then it's possible to direct Safari to http://localhost:12345/ to see all modules.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "9", "A_Content": "  Very simple searching using pkgutil.iter_modules  from pkgutil import iter_modules a=iter_modules() while True:     try: x=a.next()     except: break     if 'searchstr' in x[1]: print x[1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "9", "A_Content": "  on windows, Enter this in cmd  c:\\python\\libs>python -m pip freeze      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "9", "A_Content": "  As of pip 10, the accepted answer will no longer work.  The development team has removed access to the get_installed_distributions routine.  There is an alternate function in the setuptools for doing the same thing.  Here is an alternate version that works with pip 10:  import pkg_resources installed_packages = pkg_resources.working_set installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version)      for i in installed_packages]) print(installed_packages_list)   Please let me know if it will or won't work in previous versions of pip, too.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "7", "A_Content": "  Aside from using pip freeze I have been installing yolk in my virtual environments.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "6", "A_Content": "   to get all available modules, run sys.modules to get all installed modules (read: installed by pip), you may look at pip.get_installed_distributions()   For the second purpose, example code:  import pip for package in pip.get_installed_distributions():     name = package.project_name # SQLAlchemy, Django, Flask-OAuthlib     key = package.key # sqlalchemy, django, flask-oauthlib     module_name = package._get_metadata(\"top_level.txt\") # sqlalchemy, django, flask_oauthlib     location = package.location # virtualenv lib directory etc.     version = package.version # version number      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "6", "A_Content": "  This solution is primary based on modules importlib and pkgutil and work with CPython 3.4 and CPython 3.5, but has no support for the CPython 2.    Explanation   sys.builtin_module_names - names all built-in modules (look my answer here) pkgutil.iter_modules() - returns an information about all available modules importlib.util.find_spec() - returns an information about importing module, if exists BuiltinImporter - an importer for built-in modules (docs) SourceFileLoader - an importer for a standard Python module (by default has extension *.py) (docs) ExtensionFileLoader - an importer for modules as shared library (written on the C or C++)     Full code  import sys import os import shutil import pkgutil import importlib import collections  if sys.version_info.major == 2:     raise NotImplementedError('CPython 2 is not supported yet')   def main():      # name this file (module)     this_module_name = os.path.basename(__file__).rsplit('.')[0]      # dict for loaders with their modules     loaders = collections.OrderedDict()      # names`s of build-in modules     for module_name in sys.builtin_module_names:          # find an information about a module by name         module = importlib.util.find_spec(module_name)          # add a key about a loader in the dict, if not exists yet         if module.loader not in loaders:             loaders[module.loader] = []          # add a name and a location about imported module in the dict         loaders[module.loader].append((module.name, module.origin))      # all available non-build-in modules     for module_name in pkgutil.iter_modules():          # ignore this module         if this_module_name == module_name[1]:             continue          # find an information about a module by name         module = importlib.util.find_spec(module_name[1])          # add a key about a loader in the dict, if not exists yet         loader = type(module.loader)         if loader not in loaders:             loaders[loader] = []          # add a name and a location about imported module in the dict         loaders[loader].append((module.name, module.origin))      # pretty print     line = '-' * shutil.get_terminal_size().columns     for loader, modules in loaders.items():         print('{0}\\n{1}: {2}\\n{0}'.format(line, len(modules), loader))         for module in modules:             print('{0:30} | {1}'.format(module[0], module[1]))   if __name__ == '__main__':     main()     Usage  For the CPython3.5 (truncated)  $ python3.5 python_modules_info.py  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 30: <class '_frozen_importlib.BuiltinImporter'> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ _ast                           | built-in _codecs                        | built-in _collections                   | built-in _functools                     | built-in _imp                           | None _io                            | built-in _locale                        | built-in _operator                      | built-in _signal                        | built-in _sre                           | built-in _stat                          | built-in _string                        | built-in _symtable                      | built-in _thread                        | built-in (****************************truncated*******************************) ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 227: <class '_frozen_importlib_external.SourceFileLoader'> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ __future__                     | /usr/local/lib/python3.5/__future__.py _bootlocale                    | /usr/local/lib/python3.5/_bootlocale.py _collections_abc               | /usr/local/lib/python3.5/_collections_abc.py _compat_pickle                 | /usr/local/lib/python3.5/_compat_pickle.py _compression                   | /usr/local/lib/python3.5/_compression.py _dummy_thread                  | /usr/local/lib/python3.5/_dummy_thread.py _markupbase                    | /usr/local/lib/python3.5/_markupbase.py _osx_support                   | /usr/local/lib/python3.5/_osx_support.py _pydecimal                     | /usr/local/lib/python3.5/_pydecimal.py _pyio                          | /usr/local/lib/python3.5/_pyio.py _sitebuiltins                  | /usr/local/lib/python3.5/_sitebuiltins.py (****************************truncated*******************************) ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 64: <class '_frozen_importlib_external.ExtensionFileLoader'> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ _bisect                        | /usr/local/lib/python3.5/lib-dynload/_bisect.cpython-35m-x86_64-linux-gnu.so _bz2                           | /usr/local/lib/python3.5/lib-dynload/_bz2.cpython-35m-x86_64-linux-gnu.so _codecs_cn                     | /usr/local/lib/python3.5/lib-dynload/_codecs_cn.cpython-35m-x86_64-linux-gnu.so _codecs_hk                     | /usr/local/lib/python3.5/lib-dynload/_codecs_hk.cpython-35m-x86_64-linux-gnu.so _codecs_iso2022                | /usr/local/lib/python3.5/lib-dynload/_codecs_iso2022.cpython-35m-x86_64-linux-gnu.so (****************************truncated*******************************)   For the CPython3.4 (truncated)  $ python3.4 python_modules_info.py ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 54: <class '_frozen_importlib.BuiltinImporter'> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ _ast                           | built-in _bisect                        | built-in _codecs                        | built-in _collections                   | built-in _datetime                      | built-in _elementtree                   | built-in _functools                     | built-in _heapq                         | built-in _imp                           | None _io                            | built-in _locale                        | built-in _md5                           | built-in _operator                      | built-in _pickle                        | built-in _posixsubprocess               | built-in _random                        | built-in (****************************truncated*******************************) ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 246: <class '_frozen_importlib.SourceFileLoader'> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ __future__                     | /usr/lib/python3.4/__future__.py _bootlocale                    | /usr/lib/python3.4/_bootlocale.py _collections_abc               | /usr/lib/python3.4/_collections_abc.py _compat_pickle                 | /usr/lib/python3.4/_compat_pickle.py _dummy_thread                  | /usr/lib/python3.4/_dummy_thread.py _markupbase                    | /usr/lib/python3.4/_markupbase.py _osx_support                   | /usr/lib/python3.4/_osx_support.py _pyio                          | /usr/lib/python3.4/_pyio.py (****************************truncated*******************************) ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 44: <class '_frozen_importlib.ExtensionFileLoader'> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ _bz2                           | /usr/lib/python3.4/lib-dynload/_bz2.cpython-34m-x86_64-linux-gnu.so _codecs_cn                     | /usr/lib/python3.4/lib-dynload/_codecs_cn.cpython-34m-x86_64-linux-gnu.so _codecs_hk                     | /usr/lib/python3.4/lib-dynload/_codecs_hk.cpython-34m-x86_64-linux-gnu.so _codecs_iso2022                | /usr/lib/python3.4/lib-dynload/_codecs_iso2022.cpython-34m-x86_64-linux-gnu.so _codecs_jp                     | /usr/lib/python3.4/lib-dynload/_codecs_jp.cpython-34m-x86_64-linux-gnu.so _codecs_kr                     | /usr/lib/python3.4/lib-dynload/_codecs_kr.cpython-34m-x86_64-linux-gnu.so _codecs_tw                     | /usr/lib/python3.4/lib-dynload/_codecs_tw.cpython-34m-x86_64-linux-gnu.so _crypt                         | /usr/lib/python3.4/lib-dynload/_crypt.cpython-34m-x86_64-linux-gnu.so (****************************truncated*******************************)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "3", "A_Content": "  In case you have an anaconda python distribution installed, you could also use  $conda list   in addition to solutions described above.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "3", "A_Content": "  pip freeze does it all finding packages however one can simply write the following command to list all paths where python packages are.  >>> import site; site.getsitepackages() ['/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/739993/how-can-i-get-a-list-of-locally-installed-python-modules", "Language": "Python", "Q_Title": "How can I get a list of locally installed Python modules?", "Q_Votes": "758", "Q_Content": "    I would like to get a list of Python modules, which are in my Python installation (UNIX server).  How can you get a list of Python modules installed in your computer?     ", "Tags": ["python", "module", "pip"], "A_Votes": "3", "A_Content": "  I normally use pip list to get a list of packages (with version).  This works in a virtual environment too, of course.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53162/how-can-i-do-a-line-break-line-continuation", "Language": "Python", "Q_Title": "How can I do a line break (line continuation)?", "Q_Votes": "816", "Q_Content": "    I have a long line of code that I want to break up among multiple lines. What do I use and what is the syntax?  For example, adding a bunch of strings,  e = 'a' + 'b' + 'c' + 'd'   and have it in two lines like this:  e = 'a' + 'b' +     'c' + 'd'      ", "Tags": ["python", "syntax", "line-breaks", "long-lines"], "A_Votes": "933", "A_Content": "  What is the line?  You can just have arguments on the next line without any problems:  a = dostuff(blahblah1, blahblah2, blahblah3, blahblah4, blahblah5,              blahblah6, blahblah7)   Otherwise you can do something like this:  if a == True and \\    b == False   Check the style guide for more information.  From your example line:  a = '1' + '2' + '3' + \\     '4' + '5'   Or:  a = ('1' + '2' + '3' +     '4' + '5')   Note that the style guide says that using the implicit continuation with parentheses is preferred, but in this particular case just adding parentheses around your expression is probably the wrong way to go.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/53162/how-can-i-do-a-line-break-line-continuation", "Language": "Python", "Q_Title": "How can I do a line break (line continuation)?", "Q_Votes": "816", "Q_Content": "    I have a long line of code that I want to break up among multiple lines. What do I use and what is the syntax?  For example, adding a bunch of strings,  e = 'a' + 'b' + 'c' + 'd'   and have it in two lines like this:  e = 'a' + 'b' +     'c' + 'd'      ", "Tags": ["python", "syntax", "line-breaks", "long-lines"], "A_Votes": "181", "A_Content": "  From Style Guide for Python Code:     The preferred way of wrapping long lines is by using Python's implied line continuation inside parentheses, brackets and braces. Long lines can be broken over multiple lines by wrapping expressions in parentheses. These should be used in preference to using a backslash for line continuation.      Backslashes may still be appropriate at times. For example, long, multiple with-statements cannot use implicit continuation, so backslashes are acceptable:  with open('/path/to/some/file/you/want/to/read') as file_1, \\         open('/path/to/some/file/being/written', 'w') as file_2:     file_2.write(file_1.read())       Another such case is with assert statements.      Make sure to indent the continued line appropriately. The preferred place to break around a binary operator is after the operator, not before it. Some examples:  class Rectangle(Blob):      def __init__(self, width, height,                  color='black', emphasis=None, highlight=0):         if (width == 0 and height == 0 and                 color == 'red' and emphasis == 'strong' or                 highlight > 100):             raise ValueError(\"sorry, you lose\")         if width == 0 and height == 0 and (color == 'red' or                                            emphasis is None):             raise ValueError(\"I don't think so -- values are %s, %s\" %                              (width, height))         Blob.__init__(self, width, height,                       color, emphasis, highlight)    EDIT: PEP8 now recommends the opposite convention (for breaking at binary operations) used by Mathematicians and their publishers to improve readability.   Donald Knuth's style of breaking before a binary operator aligns operators vertically, thus reducing the eye's workload when determining which items are added and subtracted.  From PEP8: Should a line break before or after a binary operator?:     Donald Knuth explains the traditional rule in his Computers and Typesetting series: \"Although formulas within a paragraph always break after binary operations and relations, displayed formulas always break before binary operations\"[3].      Following the tradition from mathematics usually results in more readable code:  # Yes: easy to match operators with operands income = (gross_wages           + taxable_interest           + (dividends - qualified_dividends)           - ira_deduction           - student_loan_interest)       In Python code, it is permissible to break before or after a binary operator, as long as the convention is consistent locally. For new code Knuth's style is suggested.   [3]: Donald Knuth's The TeXBook, pages 195 and 196     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53162/how-can-i-do-a-line-break-line-continuation", "Language": "Python", "Q_Title": "How can I do a line break (line continuation)?", "Q_Votes": "816", "Q_Content": "    I have a long line of code that I want to break up among multiple lines. What do I use and what is the syntax?  For example, adding a bunch of strings,  e = 'a' + 'b' + 'c' + 'd'   and have it in two lines like this:  e = 'a' + 'b' +     'c' + 'd'      ", "Tags": ["python", "syntax", "line-breaks", "long-lines"], "A_Votes": "60", "A_Content": "  The danger in using a backslash to end a line is that if whitespace is added after the backslash (which, of course, is very hard to see), the backslash is no longer doing what you thought it was.  See Python Idioms and Anti-Idioms (for Python 2 or Python 3) for more.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53162/how-can-i-do-a-line-break-line-continuation", "Language": "Python", "Q_Title": "How can I do a line break (line continuation)?", "Q_Votes": "816", "Q_Content": "    I have a long line of code that I want to break up among multiple lines. What do I use and what is the syntax?  For example, adding a bunch of strings,  e = 'a' + 'b' + 'c' + 'd'   and have it in two lines like this:  e = 'a' + 'b' +     'c' + 'd'      ", "Tags": ["python", "syntax", "line-breaks", "long-lines"], "A_Votes": "21", "A_Content": "  You can break lines in between parenthesises and braces. Additionally, you can append the backslash character \\ to a line to explicitly break it:  x = (tuples_first_value,      second_value) y = 1 + \\     2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53162/how-can-i-do-a-line-break-line-continuation", "Language": "Python", "Q_Title": "How can I do a line break (line continuation)?", "Q_Votes": "816", "Q_Content": "    I have a long line of code that I want to break up among multiple lines. What do I use and what is the syntax?  For example, adding a bunch of strings,  e = 'a' + 'b' + 'c' + 'd'   and have it in two lines like this:  e = 'a' + 'b' +     'c' + 'd'      ", "Tags": ["python", "syntax", "line-breaks", "long-lines"], "A_Votes": "19", "A_Content": "  Put a \\ at the end of your line or enclose the statement in parens ( .. ). From IBM:  b = ((i1 < 20) and      (i2 < 30) and      (i3 < 40))   or  b = (i1 < 20) and \\     (i2 < 30) and \\     (i3 < 40)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/53162/how-can-i-do-a-line-break-line-continuation", "Language": "Python", "Q_Title": "How can I do a line break (line continuation)?", "Q_Votes": "816", "Q_Content": "    I have a long line of code that I want to break up among multiple lines. What do I use and what is the syntax?  For example, adding a bunch of strings,  e = 'a' + 'b' + 'c' + 'd'   and have it in two lines like this:  e = 'a' + 'b' +     'c' + 'd'      ", "Tags": ["python", "syntax", "line-breaks", "long-lines"], "A_Votes": "17", "A_Content": "     From the horse's mouth: Explicit line   joining       Two or more physical lines may be   joined into logical lines using   backslash characters (\\), as follows:   when a physical line ends in a   backslash that is not part of a string   literal or comment, it is joined with   the following forming a single logical   line, deleting the backslash and the   following end-of-line character. For   example:  if 1900 < year < 2100 and 1 <= month <= 12 \\    and 1 <= day <= 31 and 0 <= hour < 24 \\    and 0 <= minute < 60 and 0 <= second < 60:   # Looks like a valid date         return 1       A line ending in a backslash cannot   carry a comment. A backslash does not   continue a comment. A backslash does   not continue a token except for string   literals (i.e., tokens other than   string literals cannot be split across   physical lines using a backslash). A   backslash is illegal elsewhere on a   line outside a string literal.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "962", "A_Content": "  You can make use of the reversed function for this as:  >>> array=[0,10,20,40] >>> for i in reversed(array): ...     print(i)   Note that reversed(...) does not return a list. You can get a reversed list using list(reversed(array)).     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "1046", "A_Content": "  >>> L = [0,10,20,40] >>> L[::-1] [40, 20, 10, 0]   Extended slice syntax is explained well in the Python What's new Entry for release 2.3.5  By special request in a comment this is the most current slice documentation.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "302", "A_Content": "  >>> L = [0,10,20,40] >>> L.reverse() >>> L [40, 20, 10, 0]   Or   >>> L[::-1] [40, 20, 10, 0]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "38", "A_Content": "  This is to duplicate the list:  L = [0,10,20,40] p = L[::-1]  #  Here p will be having reversed list   This is to reverse the list in-place:  L.reverse() # Here L will be reversed in-place (no new list made)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "24", "A_Content": "  I think that the best way to reverse a list in Python is to do:  a = [1,2,3,4] a = a[::-1] print(a) >>> [4,3,2,1]   The job is done, and now you have a reversed list.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "23", "A_Content": "  For reversing the same list use:   array.reverse()   To assign reversed list into some other list use:  newArray = array[::-1]       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "19", "A_Content": "  Using slicing, e.g. array = array[::-1], is a neat trick and very Pythonic, but a little obscure for newbies maybe. Using the reverse() method is a good way to go in day to day coding because it is easily readable.  However, if you need to reverse a list in place as in an interview question, you will likely not be able to use built in methods like these.  The interviewer will be looking at how you approach the problem rather than the depth of Python knowledge, an algorithmic approach is required. The following example, using a classic swap, might be one way to do it:-  def reverse_in_place(lst):      # Declare a function     size = len(lst)             # Get the length of the sequence     hiindex = size - 1     its = size/2                # Number of iterations required     for i in xrange(0, its):    # i is the low index pointer         temp = lst[hiindex]     # Perform a classic swap         lst[hiindex] = lst[i]         lst[i] = temp         hiindex -= 1            # Decrement the high index pointer     print \"Done!\"  # Now test it!! array = [2, 5, 8, 9, 12, 19, 25, 27, 32, 60, 65, 1, 7, 24, 124, 654]  print array                    # Print the original sequence reverse_in_place(array)        # Call the function passing the list print array                    # Print reversed list   **The result:** [2, 5, 8, 9, 12, 19, 25, 27, 32, 60, 65, 1, 7, 24, 124, 654] Done! [654, 124, 24, 7, 1, 65, 60, 32, 27, 25, 19, 12, 9, 8, 5, 2]   Note that this will not work on Tuples or string sequences, because strings and tuples are immutable, i.e., you cannot write into them to change elements.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "16", "A_Content": "  for x in array[::-1]:     do stuff      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "16", "A_Content": "  I find (contrary to some other suggestions) that l.reverse() is by far the fastest way to reverse a long list in Python 3 and 2. I'd be interested to know if others can replicate these timings.  l[::-1] is probably slower because it copies the list prior to reversing it. Adding the list() call around the iterator made by reversed(l) must add some overhead. Of course if you want a copy of the list or an iterator then use those respective methods, but if you want to just reverse the list then l.reverse() seems to be the fastest way.  Functions  def rev_list1(l):     return l[::-1]  def rev_list2(l):     return list(reversed(l))  def rev_list3(l):     l.reverse()     return l   List  l = list(range(1000000))   Python 3.5 timings  timeit(lambda: rev_list1(l), number=1000) # 6.48 timeit(lambda: rev_list2(l), number=1000) # 7.13 timeit(lambda: rev_list3(l), number=1000) # 0.44   Python 2.7 timings  timeit(lambda: rev_list1(l), number=1000) # 6.76 timeit(lambda: rev_list2(l), number=1000) # 9.18 timeit(lambda: rev_list3(l), number=1000) # 0.46      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "11", "A_Content": "  Possible ways,  list1 = [3,4,3,545,6,4,34,243]  list1.reverse()  list1[::-1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "11", "A_Content": "  With reversed and list:  >>> list1 = [1,2,3] >>> reversed_list = list(reversed(list1)) >>> reversed_list >>> [3, 2, 1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "10", "A_Content": "  array=[0,10,20,40] for e in reversed(array):   print e      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "7", "A_Content": "  Using reversed(array) would be the likely best route.   >>> array = [1,2,3,4] >>> for item in reversed(array): >>>     print item   Should you need to understand how could implement this without using the built in reversed.  def reverse(a):     midpoint = len(a)/2     for item in a[:midpoint]:         otherside = (len(a) - a.index(item)) - 1         temp = a[otherside]         a[otherside] = a[a.index(item)]         a[a.index(item)] = temp     return a   This should take O(N) time.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "5", "A_Content": "  If you want to store the elements of reversed list in some other variable, then you can use revArray = array[::-1] or revArray = list(reversed(array)).  But the first variant is slightly faster:  z = range(1000000) startTimeTic = time.time() y = z[::-1] print(\"Time: %s s\" % (time.time() - startTimeTic))  f = range(1000000) startTimeTic = time.time() g = list(reversed(f)) print(\"Time: %s s\" % (time.time() - startTimeTic))   Output:  Time: 0.00489711761475 s Time: 0.00609302520752 s      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "3", "A_Content": "  Strictly speaking, the question is not how to return a list in reverse but rather how to reverse a list with an example list name array.  To reverse a list named \"array\" use array.reverse().  The incredibly useful slice method as described can also be used to reverse a list in place by defining the list as a sliced modification of itself using array = array[::-1].     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "3", "A_Content": "  You can use reversed()  array=[0,10,20,40]  for e in reversed(array):   print e      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "3", "A_Content": "  def reverse(text):     output = []     for i in range(len(text)-1, -1, -1):         output.append(text[i])     return output      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "3", "A_Content": "  Use list comprehension:  [array[n] for n in range(len(array)-1, -1, -1)]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "2", "A_Content": "  The most direct translation of your requirement into Python is this for statement:  for i in xrange(len(array) - 1, -1, -1):    print i, array[i]   This is rather cryptic but may be useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "2", "A_Content": "  Use the reversed function as follow and print it  >>> for element in reversed(your_array): ...     print element      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "2", "A_Content": "  You could always treat the list like a stack just popping the elements off the top of the stack from the back end of the list. That way you take advantage of first in last out characteristics of a stack. Of course you are consuming the 1st array. I do like this method in that it's pretty intuitive in that you see one list being consumed from the back end while the other is being built from the front end.  >>> l = [1,2,3,4,5,6]; nl=[] >>> while l:         nl.append(l.pop())   >>> print nl [6, 5, 4, 3, 2, 1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "2", "A_Content": "  def reverse(text):     lst=[]     for i in range(0,len(text)):         lst.append(text[(len(text)-1)-i])     return ''.join(lst)  print reverse('reversed')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "2", "A_Content": "  list_data = [1,2,3,4,5] l = len(list_data) i=l+1 rev_data = [] while l>0:   j=i-l   l-=1   rev_data.append(list_data[-j]) print \"After Rev:- %s\" %rev_data       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  def reverse(my_list):   L = len(my_list)   for i in range(L/2):     my_list[i], my_list[L-i - 1] = my_list[L-i-1], my_list[i]   return my_list      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  >>> l = [1, 2, 3, 4, 5] >>> print(reduce(lambda acc, x: [x] + acc, l, [])) [5, 4, 3, 2, 1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  You can also use the bitwise complement of the array index to step through the array in reverse:  >>> array = [0, 10, 20, 40] >>> [array[~i] for i, _ in enumerate(array)] [40, 20, 10, 0]   Whatever you do, don't do it this way.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "1", "A_Content": "  ORGANIZING VALUES:  In Python, lists' order too can be manipulated with sort, organizing your variables in numerical/alphabetical order:  Temporarily:  print(sorted(my_list))   Permanent:  my_list.sort(), print(my_list)   You can sort with the flag \"reverse=True\":     print(sorted(my_list, reverse=True))      or      my_list.sort(reverse=True), print(my_list)   WITHOUT ORGANIZING  Maybe you do not want to sort values, but only reverse the values. Then we can do it like this:      print(list(reversed(my_list)))   **Numbers have priority over alphabet in listing order. The Python values' organization is awesome.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "0", "A_Content": "  >>> L = [1, 2, 3, 4] >>> L = [L[-i] for i in range(1, len(L) + 1)] >>> L [4, 3, 2, 1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "0", "A_Content": "  Reversing in-place by switching references of opposite indices:  >>> l = [1,2,3,4,5,6,7]     >>> for i in range(len(l)//2): ...     l[i], l[-1-i] = l[-1-i], l[i] ... >>> l [7, 6, 5, 4, 3, 2, 1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3940128/how-can-i-reverse-a-list-in-python", "Language": "Python", "Q_Title": "How can I reverse a list in Python?", "Q_Votes": "758", "Q_Content": "    How can I do the following in Python?  array = [0, 10, 20, 40] for (i = array.length() - 1; i >= 0; i--)   I need to have the elements of an array, but from the end to the beginning.     ", "Tags": ["python", "list"], "A_Votes": "0", "A_Content": "  Can be done using __reverse__ , which returns a generator.  >>> l = [1,2,3,4,5] >>> for i in l.__reversed__(): ...   print i ...  5 4 3 2 1 >>>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "1391", "A_Content": "  Are you talking about multi-line strings? Easy, use triple quotes to start and end them.  s = \"\"\" this is a very         long string if I had the         energy to type more and more ...\"\"\"   You can use single quotes too (3 of them of course at start and end) and treat the resulting string s just like any other string.  NOTE: Just as with any string, anything between the starting and ending quotes becomes part of the string, so this example has a leading blank (as pointed out by @root45). This string will also contain both blanks and newlines.  I.e.,:  ' this is a very\\n        long string if I had the\\n        energy to type more and more ...'   Finally, one can also construct long lines in Python like this:   s = (\"this is a very\"       \"long string too\"       \"for sure ...\"      )   which will not include any extra blanks or newlines (this is a deliberate example showing what the effect of skipping blanks will result in):  'this is a verylong string toofor sure ...'   No commas required, simply place the strings to be joined together into a pair of parenthesis and be sure to account for any needed blanks and newlines.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "126", "A_Content": "  If you don't want a multiline string but just have a long single line string, you can use parentheses, just make sure you don't include commas between the string segments, then it will be a tuple.  query = ('SELECT   action.descr as \"action\", '          'role.id as role_id,'          'role.descr as role'          ' FROM '          'public.role_action_def,'          'public.role,'          'public.record_def, '          'public.action'          ' WHERE role.id = role_action_def.role_id AND'          ' record_def.id = role_action_def.def_id AND'          ' action.id = role_action_def.action_id AND'          ' role_action_def.account_id = '+account_id+' AND'          ' record_def.account_id='+account_id+' AND'          ' def_id='+def_id)   In a SQL statement like what you're constructing, multiline strings would also be fine.  But if the extra whitespace a multiline string would contain would be a problem, then this would be a good way to achieve what you want.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "102", "A_Content": "  Breaking lines by \\ works for me.  Here is an example:  longStr = \"This is a very long string \" \\         \"that I wrote to help somebody \" \\         \"who had a question about \" \\         \"writing long strings in Python\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "34", "A_Content": "  I found myself happy with this one:  string = \"\"\"This is a very long string, containing commas, that I split up for readability\"\"\".replace('\\n',' ')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "27", "A_Content": "  I find that when building long strings, you are usually doing something like building an SQL query, in which case this is best:  query = ' '.join((  # note double parens, join() takes an iterable     \"SELECT foo\",     \"FROM bar\",     \"WHERE baz\", ))   What Levon suggested is good, but might be vulnerable to mistakes:  query = (     \"SELECT foo\"     \"FROM bar\"     \"WHERE baz\" )  query == \"SELECT fooFROM barWHERE baz\"  # probably not what you want      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "22", "A_Content": "  You can also concatenate variables in when using \"\"\" notation:  foo = '1234'  long_string = \"\"\"fosdl a sdlfklaskdf as as df ajsdfj asdfa sld a sdf alsdfl alsdfl \"\"\" +  foo + \"\"\" aks asdkfkasdk fak\"\"\"   EDIT: Found a better way, with named params and .format():  body = \"\"\" <html> <head> </head> <body>     <p>Lorem ipsum.</p>     <dl>         <dt>Asdf:</dt>     <dd><a href=\"{link}\">{name}</a></dd>     </dl>     </body> </html> \"\"\".format(     link='http://www.asdf.com',     name='Asdf', )  print(body)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "15", "A_Content": "  In Python >= 3.6 you can use Formatted string literals (f string)  query= f'''SELECT   action.descr as \"action\"     role.id as role_id,     role.descr as role     FROM     public.role_action_def,     public.role,     public.record_def,     public.action     WHERE role.id = role_action_def.role_id AND     record_def.id = role_action_def.def_id AND     action.id = role_action_def.action_id AND     role_action_def.account_id = {account_id} AND     record_def.account_id = {account_id} AND     def_id = {def_id}'''      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "8", "A_Content": "  For example:  sql = (\"select field1, field2, field3, field4 \"        \"from table \"        \"where condition1={} \"        \"and condition2={}\").format(1, 2)  Output: 'select field1, field2, field3, field4 from table           where condition1=1 and condition2=2'   if the value of condition should be a string, you can do like this:  sql = (\"select field1, field2, field3, field4 \"        \"from table \"        \"where condition1='{0}' \"        \"and condition2='{1}'\").format('2016-10-12', '2017-10-12')  Output: \"select field1, field2, field3, field4 from table where          condition1='2016-10-12' and condition2='2017-10-12'\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "5", "A_Content": "  I personally find the following to be the best (simple, safe and Pythonic) way to write raw SQL queries in Python, especially when using Python's sqlite3 module:  query = '''     SELECT         action.descr as action,         role.id as role_id,         role.descr as role     FROM         public.role_action_def,         public.role,         public.record_def,         public.action     WHERE         role.id = role_action_def.role_id         AND record_def.id = role_action_def.def_id         AND action.id = role_action_def.action_id         AND role_action_def.account_id = ?         AND record_def.account_id = ?         AND def_id = ? ''' vars = (account_id, account_id, def_id)   # a tuple of query variables cursor.execute(query, vars)   # using Python's sqlite3 module   Pros   Neat and simple code (Pythonic!) Safe from SQL injection Compatible with both Python 2 and Python 3 (it's Pythonic after all) No string concatenation required No need to ensure that the right-most character of each line is a space   Cons   Since variables in the query are replaced by the ? placeholder, it may become a little difficult to keep track of which ? is to be substituted by which Python variable when there are lots of them in the query.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "4", "A_Content": "  I find textwrap.dedent the best for long strings as described here:  def create_snippet():     code_snippet = textwrap.dedent(\"\"\"\\         int main(int argc, char* argv[]) {             return 0;         }     \"\"\")     do_something(code_snippet)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "3", "A_Content": "  Your actual code shouldn't work, you are missing whitespaces at the end of \"lines\" (eg: role.descr as roleFROM...)  There is triplequotes for multiline string:  string = \"\"\"line   line2   line3\"\"\"   It will contain the line breaks and extra spaces, but for SQL that's not a problem.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "3", "A_Content": "  This approach uses just one backslash to avoid an initial linefeed, almost no internal punctuation by using a triple quoted string, strips away local indentation using the textwrap module, and also uses python 3.6 formatted string interpolation ('f') for the account_id and def_id variables. This way looks the most pythonic to me.  import textwrap  query = textwrap.dedent(f'''\\     SELECT action.descr as \"action\",      role.id as role_id,     role.descr as role     FROM      public.role_action_def,     public.role,     public.record_def,      public.action     WHERE role.id = role_action_def.role_id AND     record_def.id = role_action_def.def_id AND     action.id = role_action_def.action_id AND     role_action_def.account_id = {account_id} AND     record_def.account_id={account_id} AND     def_id={def_id}''' )      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "3", "A_Content": "  I usually use something like this:  text = '''     This string was typed to be a demo     on how could we write a multi-line     text in Python. '''   If you want to remove annoying blank spaces in each line, you could do as follows:  text = '\\n'.join(line.lstrip() for line in text.splitlines())      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "2", "A_Content": "  You can also place the sql-statement in a seperate file action.sql and load it in the py file with  with open('action.sql') as f:    query = f.read()   So the sql-statements will be separated from the python code. If there are parameters in the sql statement which needs to be filled from python, you can use string formating (like %s or {field})     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "2", "A_Content": "  \"\u00c0 la\" Scala way (but I think is the most pythonic way as OQ demands):  description = \"\"\"             | The intention of this module is to provide a method to              | pass meta information in markdown_ header files for              | using it in jinja_ templates.              |              | Also, to provide a method to use markdown files as jinja              | templates. Maybe you prefer to see the code than              | to install it.\"\"\".replace('\\n            | \\n','\\n').replace('            | ',' ')   If you want final str without jump lines, just put \\n at the start of the first argument of the second replace:  .replace('\\n            | ',' ')`.   Note: the white line between \"...templates.\" and \"Also, ...\" requires a whitespace after the |.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "1", "A_Content": "  I use a recursive function to build complex SQL Queries. This technique can generally be used to build large strings while maintaining code readability.  # Utility function to recursively resolve SQL statements. # CAUTION: Use this function carefully, Pass correct SQL parameters {}, # TODO: This should never happen but check for infinite loops def resolveSQL(sql_seed, sqlparams):     sql = sql_seed % (sqlparams)     if sql == sql_seed:         return ' '.join([x.strip() for x in sql.split()])     else:         return resolveSQL(sql, sqlparams)   P.S: Have a look at the awesome python-sqlparse library to pretty print SQL queries if needed. http://sqlparse.readthedocs.org/en/latest/api/#sqlparse.format     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "657", "A_Content": "   Checking for __iter__ works on sequence types, but it would fail on e.g. strings in Python 2. I would like to know the right answer too, until then, here is one possibility (which would work on strings, too):  try:     some_object_iterator = iter(some_object) except TypeError as te:     print some_object, 'is not iterable'   The iter built-in checks for the __iter__ method or in the case of strings the __getitem__ method. Another general pythonic approach is to assume an iterable, then fail gracefully if it does not work on the given object. The Python glossary:     Pythonic programming style that determines an object's type by inspection of its method or attribute signature rather than by explicit relationship to some type object (\"If it looks like a duck and quacks like a duck, it must be a duck.\") By emphasizing interfaces rather than specific types, well-designed code improves its flexibility by allowing polymorphic substitution. Duck-typing avoids tests using type() or isinstance(). Instead, it typically employs the EAFP (Easier to Ask Forgiveness than Permission) style of programming.      ...  try:    _ = (e for e in my_object) except TypeError:    print my_object, 'is not iterable'   The collections module provides some abstract base classes, which allow to ask classes or instances if they provide particular functionality, for example:  import collections  if isinstance(e, collections.Iterable):     # e is iterable   However, this does not check for classes that are iterable through __getitem__.      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "1", "A_Content": "  Another option that I think is more readable when the code (e.g variable) is indented and the output string should be a one liner (no newlines):  def some_method():      long_string = \"\"\" a presumptuous long string  which looks a bit nicer  in a text editor when written over multiple lines \"\"\".strip('\\n').replace('\\n', ' ')      return long_string       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/10660435/pythonic-way-to-create-a-long-multi-line-string", "Language": "Python", "Q_Title": "Pythonic way to create a long multi-line string", "Q_Votes": "818", "Q_Content": "    I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:  var long_string = 'some text not important. just garbage to' +                   'illustrate my example';   I tried doing something similar in Python, but it didn't work, so I used \\ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.  Actual code:  query = 'SELECT action.descr as \"action\", '\\     'role.id as role_id,'\\     'role.descr as role'\\     'FROM '\\     'public.role_action_def,'\\     'public.role,'\\     'public.record_def, '\\     'public.action'\\     'WHERE role.id = role_action_def.role_id AND'\\     'record_def.id = role_action_def.def_id AND'\\     'action.id = role_action_def.action_id AND'\\     'role_action_def.account_id = ' + account_id + ' AND'\\     'record_def.account_id=' + account_id + ' AND'\\     'def_id=' + def_id      ", "Tags": ["python", "string", "multiline", "multilinestring"], "A_Votes": "0", "A_Content": "  I like this approach because it privileges reading. In cases where we have long strings there is no way! Depending on the level of indentation you are in and still limited to 80 characters per line... Well... No need to say anything else. In my view the python style guides are still very vague. I took the @Eero Aaltonen approach because it privileges reading and common sense. I understand that style guides should help us and not make our lives a mess. Thanks!   class ClassName():     def method_name():         if condition_0:             if condition_1:                 if condition_2:                     some_variable_0 =\\ \"\"\" some_js_func_call(     undefined,      {         'some_attr_0': 'value_0',          'some_attr_1': 'value_1',          'some_attr_2': '\"\"\" + some_variable_1 + \"\"\"'     },      undefined,      undefined,      true ) \"\"\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "493", "A_Content": "  Duck typing  try:     iterator = iter(theElement) except TypeError:     # not iterable else:     # iterable  # for obj in iterator: #     pass   Type checking  Use the Abstract Base Classes. They need at least Python 2.6 and work only for new-style classes.  import collections  if isinstance(theElement, collections.Iterable):     # iterable else:     # not iterable   However, iter() is a bit more reliable as described by the documentation:     Checking isinstance(obj, Iterable) detects classes that are   registered as Iterable or that have an __iter__() method, but   it does not detect classes that iterate with the __getitem__()   method. The only reliable way to determine whether an object   is iterable is to call iter(obj).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "59", "A_Content": "  I'd like to shed a little bit more light on the interplay of iter, __iter__ and __getitem__ and what happens behind the curtains. Armed with that knowledge, you will be able to understand why the best you can do is  try:     iter(maybe_iterable)     print('iteration will probably work') except TypeError:     print('not iterable')   I will list the facts first and then follow up with a quick reminder of what happens when you employ a for loop in python, followed by a discussion to illustrate the facts.  Facts   You can get an iterator from any object o by calling iter(o) if at least one of the following conditions holds true: a) o has an __iter__ method which returns an iterator object. An iterator is any object with an __iter__ and a __next__ (Python 2: next) method. b) o has a __getitem__ method. Checking for an instance of Iterable or Sequence, or checking for the attribute __iter__ is not enough. If an object o implements only __getitem__, but not __iter__, iter(o) will construct an iterator that tries to fetch items from o by integer index, starting at index 0. The iterator will catch any IndexError (but no other errors) that is raised and then raises StopIteration itself. In the most general sense, there's no way to check whether the iterator returned by iter is sane other than to try it out. If an object o implements __iter__, the iter function will make sure that the object returned by __iter__ is an iterator. There is no sanity check if an object only implements __getitem__. __iter__ wins. If an object o implements both __iter__ and __getitem__, iter(o) will call __iter__. If you want to make your own objects iterable, always implement the __iter__ method.   for loops  In order to follow along, you need an understanding of what happens when you employ a for loop in Python. Feel free to skip right to the next section if you already know.  When you use for item in o for some iterable object o, Python calls iter(o) and expects an iterator object as the return value. An iterator is any object which implements a __next__ (or next in Python 2) method and an __iter__ method.   By convention, the __iter__ method of an iterator should return the object itself (i.e. return self). Python then calls next on the iterator until StopIteration is raised. All of this happens implicitly, but the following demonstration makes it visible:  import random  class DemoIterable(object):     def __iter__(self):         print('__iter__ called')         return DemoIterator()  class DemoIterator(object):     def __iter__(self):         return self      def __next__(self):         print('__next__ called')         r = random.randint(1, 10)         if r == 5:             print('raising StopIteration')             raise StopIteration         return r   Iteration over a DemoIterable:  >>> di = DemoIterable() >>> for x in di: ...     print(x) ... __iter__ called __next__ called 9 __next__ called 8 __next__ called 10 __next__ called 3 __next__ called 10 __next__ called raising StopIteration   Discussion and illustrations  On point 1 and 2: getting an iterator and unreliable checks  Consider the following class:  class BasicIterable(object):     def __getitem__(self, item):         if item == 3:             raise IndexError         return item   Calling iter with an instance of BasicIterable will return an iterator without any problems because BasicIterable implements __getitem__.  >>> b = BasicIterable() >>> iter(b) <iterator object at 0x7f1ab216e320>   However, it is important to note that b does not have the __iter__ attribute and is not considered an instance of Iterable or Sequence:  >>> from collections import Iterable, Sequence >>> hasattr(b, '__iter__') False >>> isinstance(b, Iterable) False >>> isinstance(b, Sequence) False   This is why Fluent Python by Luciano Ramalho recommends calling iter and handling the potential TypeError as the most accurate way to check whether an object is iterable. Quoting directly from the book:     As of Python 3.4, the most accurate way to check whether an object x is iterable is to call iter(x) and handle a TypeError exception if it isn\u2019t. This is more accurate than using isinstance(x, abc.Iterable) , because iter(x) also considers the legacy __getitem__ method, while the Iterable ABC does not.   On point 3: Iterating over objects which only provide __getitem__, but not __iter__  Iterating over an instance of BasicIterable works as expected: Python constructs an iterator that tries to fetch items by index, starting at zero, until an IndexError is raised. The demo object's __getitem__ method simply returns the item which was supplied as the argument to __getitem__(self, item) by the iterator returned by iter.  >>> b = BasicIterable() >>> it = iter(b) >>> next(it) 0 >>> next(it) 1 >>> next(it) 2 >>> next(it) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> StopIteration   Note that the iterator raises StopIteration when it cannot return the next item and that the IndexError which is raised for item == 3 is handled internally. This is why looping over a BasicIterable with a for loop works as expected:  >>> for x in b: ...     print(x) ... 0 1 2   Here's another example in order to drive home the concept of how the iterator returned by iter tries to access items by index. WrappedDict does not inherit from dict, which means instances won't have an __iter__ method.  class WrappedDict(object): # note: no inheritance from dict!     def __init__(self, dic):         self._dict = dic      def __getitem__(self, item):         try:             return self._dict[item] # delegate to dict.__getitem__         except KeyError:             raise IndexError   Note that calls to __getitem__ are delegated to dict.__getitem__ for which the square bracket notation is simply a shorthand.  >>> w = WrappedDict({-1: 'not printed', ...                   0: 'hi', 1: 'StackOverflow', 2: '!', ...                   4: 'not printed',  ...                   'x': 'not printed'}) >>> for x in w: ...     print(x) ...  hi StackOverflow !   On point 4 and 5: iter checks for an iterator when it calls __iter__:  When iter(o) is called for an object o, iter will make sure that the return value of __iter__, if the method is present, is an iterator. This means that the returned object must implement __next__ (or next in Python 2) and __iter__. iter cannot perform any sanity checks for objects which only provide __getitem__, because it has no way to check whether the items of the object are accessible by integer index.  class FailIterIterable(object):     def __iter__(self):         return object() # not an iterator  class FailGetitemIterable(object):     def __getitem__(self, item):         raise Exception   Note that constructing an iterator from FailIterIterable instances fails immediately, while constructing an iterator from FailGetItemIterable succeeds, but will throw an Exception on the first call to __next__.  >>> fii = FailIterIterable() >>> iter(fii) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module> TypeError: iter() returned non-iterator of type 'object' >>> >>> fgi = FailGetitemIterable() >>> it = iter(fgi) >>> next(it) Traceback (most recent call last):   File \"<stdin>\", line 1, in <module>   File \"/path/iterdemo.py\", line 42, in __getitem__     raise Exception Exception   On point 6: __iter__ wins  This one is straightforward. If an object implements __iter__ and __getitem__, iter will call __iter__. Consider the following class  class IterWinsDemo(object):     def __iter__(self):         return iter(['__iter__', 'wins'])      def __getitem__(self, item):         return ['__getitem__', 'wins'][item]   and the output when looping over an instance:  >>> iwd = IterWinsDemo() >>> for x in iwd: ...     print(x) ... __iter__ wins   On point 7: your iterable classes should implement __iter__  You might ask yourself why most builtin sequences like list implement an __iter__ method when __getitem__ would be sufficient.  class WrappedList(object): # note: no inheritance from list!     def __init__(self, lst):         self._list = lst      def __getitem__(self, item):         return self._list[item]   After all, iteration over instances of the class above, which delegates calls to __getitem__ to list.__getitem__ (using the square bracket notation), will work fine:  >>> wl = WrappedList(['A', 'B', 'C']) >>> for x in wl: ...     print(x) ...  A B C   The reasons your custom iterables should implement __iter__ are as follows:   If you implement __iter__, instances will be considered iterables, and isinstance(o, collections.Iterable) will return True. If the the object returned by __iter__ is not an iterator, iter will fail immediately and raise a TypeError. The special handling of __getitem__ exists for backwards compatibility reasons. Quoting again from Fluent Python:      That is why any Python sequence is iterable: they all implement __getitem__ . In fact,   the standard sequences also implement __iter__, and yours should too, because the   special handling of __getitem__ exists for backward compatibility reasons and may be   gone in the future (although it is not deprecated as I write this).      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "28", "A_Content": "  This isn't sufficient: the object returned by __iter__ must implement the iteration protocol (i.e. next method). See the relevant section in the documentation.  In Python, a good practice is to \"try and see\" instead of \"checking\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "18", "A_Content": "  try:   #treat object as iterable except TypeError, e:   #object is not actually iterable   Don't run checks to see if your duck really is a duck to see if it is iterable or not, treat it as if it was and complain if it wasn't.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "16", "A_Content": "  The best solution I've found so far:  hasattr(obj, '__contains__')  which basically checks if the object implements the in operator.  Advantages (none of the other solutions has all three):   it is an expression (works as a lambda, as opposed to the try...except variant) it is (should be) implemented by all iterables, including strings (as opposed to __iter__) works on any Python >= 2.5   Notes:    the Python philosophy of \"ask for forgiveness, not permission\" doesn't work well when e.g. in a list you have both iterables and non-iterables and you need to treat each element differently according to it's type (treating iterables on try and non-iterables on except would work, but it would look butt-ugly and misleading) solutions to this problem which attempt to actually iterate over the object (e.g. [x for x in obj]) to check if it's iterable may induce significant performance penalties for large iterables (especially if you just need the first few elements of the iterable, for example) and should be avoided      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "14", "A_Content": "  In Python <= 2.5, you can't and shouldn't - iterable was an \"informal\" interface.  But since Python 2.6 and 3.0 you can leverage the new ABC (abstract base class) infrastructure along with some builtin ABCs which are available in the collections module:  from collections import Iterable  class MyObject(object):     pass  mo = MyObject() print isinstance(mo, Iterable) Iterable.register(MyObject) print isinstance(mo, Iterable)  print isinstance(\"abc\", Iterable)   Now, whether this is desirable or actually works, is just a matter of conventions. As you can see, you can register a non-iterable object as Iterable - and it will raise an exception at runtime. Hence, isinstance acquires a \"new\" meaning - it just checks for \"declared\" type compatibility, which is a good way to go in Python.  On the other hand, if your object does not satisfy the interface you need, what are you going to do? Take the following example:  from collections import Iterable from traceback import print_exc  def check_and_raise(x):     if not isinstance(x, Iterable):         raise TypeError, \"%s is not iterable\" % x     else:         for i in x:             print i  def just_iter(x):     for i in x:         print i   class NotIterable(object):     pass  if __name__ == \"__main__\":     try:         check_and_raise(5)     except:         print_exc()         print      try:         just_iter(5)     except:         print_exc()         print      try:         Iterable.register(NotIterable)         ni = NotIterable()         check_and_raise(ni)     except:         print_exc()         print   If the object doesn't satisfy what you expect, you just throw a TypeError, but if the proper ABC has been registered, your check is unuseful. On the contrary, if the __iter__ method is available Python will automatically recognize object of that class as being Iterable.  So, if you just expect an iterable, iterate over it and forget it. On the other hand, if you need to do different things depending on input type, you might find the ABC infrastructure pretty useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "11", "A_Content": "  I found a nice solution here:  isiterable = lambda obj: isinstance(obj, basestring) \\     or getattr(obj, '__iter__', False)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "10", "A_Content": "  You could try this:  def iterable(a):     try:         (x for x in a)         return True     except TypeError:         return False   If we can make a generator that iterates over it (but never use the generator so it doesn't take up space), it's iterable. Seems like a \"duh\" kind of thing. Why do you need to determine if a variable is iterable in the first place?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "8", "A_Content": "  According to the Python 2 Glossary, iterables are     all sequence types (such as list, str, and tuple) and some non-sequence types like dict and file and objects of any classes you define with an __iter__() or __getitem__() method. Iterables can be used in a for loop and in many other places where a sequence is needed (zip(), map(), ...). When an iterable object is passed as an argument to the built-in function iter(), it returns an iterator for the object.   Of course, given the general coding style for Python based on the fact that it's \u201cEasier to ask for forgiveness than permission.\u201d, the general expectation is to use  try:     for i in object_in_question:         do_something except TypeError:     do_something_for_non_iterable   But if you need to check it explicitly, you can test for an iterable by hasattr(object_in_question, \"__iter__\") or hasattr(object_in_question, \"__getitem__\"). You need to check for both, because strs don't have an __iter__ method (at least not in Python 2, in Python 3 they do) and because generator objects don't have a __getitem__ method.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "4", "A_Content": "  I often find convenient, inside my scripts, to define an iterable function. (Now incorporates Alfe's suggested simplification):  import collections  def iterable(obj):     return isinstance(obj, collections.Iterable):   so you can test if any object is iterable in the very readable form  if iterable(obj):     # act on iterable else:     # not iterable   as you would do with thecallable function  EDIT: if you have numpy installed, you can simply do: from numpy import iterable,  which is simply something like  def iterable(obj):     try: iter(obj)     except: return False     return True   If you do not have numpy, you can simply implement this code, or the one above.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "4", "A_Content": "  pandas has a built-in function like that:  from pandas.util.testing import isiterable      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "4", "A_Content": "  Since Python 3.5 you can use the typing module from the standard library for type related things:  from typing import Iterable  ...  if isinstance(my_item, Iterable):     print(True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "2", "A_Content": "  def is_iterable(x):     try:         0 in x     except TypeError:         return False     else:         return True   This will say yes to all manner of iterable objects, but it will say no to strings in Python 2. (That's what I want for example when a recursive function could take a string or a container of strings.  In that situation, asking forgiveness may lead to obfuscode, and it's better to ask permission first.)  import numpy  class Yes:     def __iter__(self):         yield 1;         yield 2;         yield 3;  class No:     pass  class Nope:     def __iter__(self):         return 'nonsense'  assert is_iterable(Yes()) assert is_iterable(range(3)) assert is_iterable((1,2,3))   # tuple assert is_iterable([1,2,3])   # list assert is_iterable({1,2,3})   # set assert is_iterable({1:'one', 2:'two', 3:'three'})   # dictionary assert is_iterable(numpy.array([1,2,3])) assert is_iterable(bytearray(\"not really a string\", 'utf-8'))  assert not is_iterable(No()) assert not is_iterable(Nope()) assert not is_iterable(\"string\") assert not is_iterable(42) assert not is_iterable(True) assert not is_iterable(None)   Many other strategies here will say yes to strings. Use them if that's what you want.  import collections import numpy  assert isinstance(\"string\", collections.Iterable) assert isinstance(\"string\", collections.Sequence) assert numpy.iterable(\"string\") assert iter(\"string\") assert hasattr(\"string\", '__getitem__')   Note: is_iterable() will say yes to strings of type bytes and bytearray.   bytes objects in Python 3 are iterable True == is_iterable(b\"string\") == is_iterable(\"string\".encode('utf-8')) There is no such type in Python 2. bytearray objects in Python 2 and 3 are iterable True == is_iterable(bytearray(b\"abc\"))   The O.P. hasattr(x, '__iter__') approach will say yes to strings in Python 3 and no in Python 2 (no matter whether '' or b'' or u''). Thanks to @LuisMasuelli for noticing it will also let you down on a buggy __iter__.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "1", "A_Content": "  The easiest way, respecting the Python's duck typing, is to catch the error (Python knows perfectly what does it expect from an object to become an iterator):  class A(object):     def __getitem__(self, item):         return something  class B(object):     def __iter__(self):         # Return a compliant iterator. Just an example         return iter([])  class C(object):     def __iter__(self):         # Return crap         return 1  class D(object): pass  def iterable(obj):     try:         iter(obj)         return True     except:         return False  assert iterable(A()) assert iterable(B()) assert iterable(C()) assert not iterable(D())   Notes:   It is irrelevant the distinction whether the object is not iterable, or a buggy __iter__ has been implemented, if the exception type is the same: anyway you will not be able to iterate the object. I think I understand your concern: How does callable exists as a check if I could also rely on duck typing to raise an AttributeError if __call__ is not defined for my object, but that's not the case for iterable checking?  I don't know the answer, but you can either implement the function I (and other users) gave, or just catch the exception in your code (your implementation in that part will be like the function I wrote - just ensure you isolate the iterator creation from the rest of the code so you can capture the exception and distinguish it from another TypeError.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "1", "A_Content": "  The isiterable func at the following code returns True if object is iterable. if it's not iterable returns False  def isiterable(object_):     return hasattr(type(object_), \"__iter__\")   example  fruits = (\"apple\", \"banana\", \"peach\") isiterable(fruits) # returns True  num = 345 isiterable(num) # returns False  isiterable(str) # returns False because str type is type class and it's not iterable.  hello = \"hello dude !\" isiterable(hello) # returns True because as you know string objects are iterable      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "0", "A_Content": "  Instead of checking for the __iter__ attribute, you could check for the __len__ attribute, which is implemented by every python builtin iterable, including strings.   >>> hasattr(1, \"__len__\") False >>> hasattr(1.3, \"__len__\") False >>> hasattr(\"a\", \"__len__\") True >>> hasattr([1,2,3], \"__len__\") True >>> hasattr({1,2}, \"__len__\") True >>> hasattr({\"a\":1}, \"__len__\") True >>> hasattr((\"a\", 1), \"__len__\") True   None-iterable objects would not implement this for obvious reasons. However, it does not catch user-defined iterables that do not implement it, nor do generator expressions, which iter can deal with. However, this can be done in a line, and adding a simple or expression checking for generators would fix this problem. (Note that writing type(my_generator_expression) == generator would throw a NameError. Refer to this answer instead.)     You can use GeneratorType from types:  >>> import types >>> types.GeneratorType <class 'generator'> >>> gen = (i for i in range(10)) >>> isinstance(gen, types.GeneratorType) True       --- accepted answer by utdemir   (This makes it useful for checking if you can call len on the object though.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "0", "A_Content": "  It's always eluded me as to why python has callable(obj) -> bool but not iterable(obj) -> bool... surely it's easier to do hasattr(obj,'__call__') even if it is slower.  Since just about every other answer recommends using try/except TypeError, where testing for exceptions is generally considered bad practice among any language, here's an implementation of iterable(obj) -> bool I've grown more fond of and use often:  For python 2's sake, I'll use a lambda just for that extra performance boost... (in python 3 it doesn't matter what you use for defining the function, def has roughly the same speed as lambda)  iterable = lambda obj: hasattr(obj,'__iter__') or hasattr(obj,'__getitem__')   Note that this function executes faster for objects with __iter__ since it doesn't test for __getitem__.  Most iterable objects should rely on __iter__ where special-case objects fall back to __getitem__, though either is required for an object to be iterable. (and since this is standard, it affects C objects as well)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable", "Language": "Python", "Q_Title": "In Python, how do I determine if an object is iterable?", "Q_Votes": "816", "Q_Content": "    Is there a method like isiterable? The only solution I have found so far is to call  hasattr(myObj, '__iter__')   But I am not sure how fool-proof this is.     ", "Tags": ["python", "iterable"], "A_Votes": "-2", "A_Content": "  Apart from regular try and except, you could run help.  temp= [1,2,3,4] help(temp)   help would give all the methods that could be run on that object(it could be any object and may not be a list as per example), which is temp in this case.   Note: This would be something you would manually do.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3289601/null-object-in-python", "Language": "Python", "Q_Title": "null object in Python?", "Q_Votes": "824", "Q_Content": "    How do I refer to the null object in Python?     ", "Tags": ["python", "null"], "A_Votes": "1150", "A_Content": "  In Python, the 'null' object is the singleton None.  The best way to check things for \"Noneness\" is to use the identity operator, is:  if foo is None:     ...      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "468", "A_Content": "  It's difficult to make del df.column_name work simply as the result of syntactic limitations in Python. del df[name] gets translated to df.__delitem__(name) under the covers by Python.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3289601/null-object-in-python", "Language": "Python", "Q_Title": "null object in Python?", "Q_Votes": "824", "Q_Content": "    How do I refer to the null object in Python?     ", "Tags": ["python", "null"], "A_Votes": "54", "A_Content": "  It's not called null as in other languages, but None. There is always only one instance of this object, so you can check for equivalence with x is None (identity comparison) instead of x == None, if you want.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3289601/null-object-in-python", "Language": "Python", "Q_Title": "null object in Python?", "Q_Votes": "824", "Q_Content": "    How do I refer to the null object in Python?     ", "Tags": ["python", "null"], "A_Votes": "34", "A_Content": "  None, Python's null?  There's no null in Python, instead there's None. As stated already the most accurate way to test that something has been given None as a value is to use the is identity operator, which tests that two variables refer to the same object.  >>> foo is None True >>> foo = 'bar'  >>> foo is None False   The basics  There is and can only be one None  None is the sole instance of the class NoneType and any further attempts at instantiating that class will return the same object, which makes None a singleton. Newcomers to Python often see error messages that mention NoneType and wonder what it is. It's my personal opinion that these messages could simply just mention None by name because, as we'll see shortly, None leaves little room to ambiguity. So if you see some TypeError message that mentions that NoneType can't do this or can't do that, just know that it's simply the one None that was being used in a way that it can't.  Also, None is a built-in constant, as soon as you start Python it's available to use from everywhere, whether in module, class, or function. NoneType by contrast is not, you'd need to get a reference to it first by querying None for its class.  >>> NoneType NameError: name 'NoneType' is not defined >>> type(None) NoneType   You can check None's uniqueness with Python's identity function id(). It returns the unique number assigned to an object, each object has one. If the id of two variables is the same, then they point in fact to the same object.  >>> NoneType = type(None) >>> id(None) 10748000 >>> my_none = NoneType() >>> id(my_none) 10748000 >>> another_none = NoneType() >>> id(another_none) 10748000 >>> def function_that_does_nothing(): pass >>> return_value = function_that_does_nothing() >>> id(return_value) 10748000   None cannot be overwritten  In much older version of Python (before 2.4) it was possible to reassign None, but not anymore. Not even as a class attribute or in the confines of a function.  # In Python 2.7 >>> class SomeClass(object): ...     def my_fnc(self): ...             self.None = 'foo' SyntaxError: cannot assign to None >>> def my_fnc():         None = 'foo' SyntaxError: cannot assign to None  # In Python 3.5 >>> class SomeClass: ...     def my_fnc(self): ...             self.None = 'foo' SyntaxError: invalid syntax >>> def my_fnc():         None = 'foo' SyntaxError: cannot assign to keyword   It's therefore safe to assume that all None references are the same. There's no \"custom\" None.  To test for None use the is operator  When writing code you might be tempted to test for Noneness like this:  if value==None:     pass   Or to test for falsehood like this  if not value:     pass   You need to understand the implications and why it's often a good idea to be explicit.  Case 1: testing if a value is None  why do this  value is None   rather than   value==None   The first is equivalent to:  id(value)==id(None)   Whereas the expression value==None is in fact applied like this  value.__eq__(None)   if the value really is None then you'll get what you expected.  >>> nothing = function_that_does_nothing() >>> nothing.__eq__(None) True   In most common cases the outcome will be the same, but the __eq__() method opens a door that voids any guarantee of accuracy, since it can be overridden in a class to provide special behavior.  Consider this class.  >>> class Empty(object): ...     def __eq__(self, other): ...         return not other   So you try it on None and it works  >>> empty = Empty() >>> empty==None True   But then it also works on the empty string  >>> empty=='' True   And yet  >>> ''==None False >>> empty is None False   Case 2: Using None as a boolean  The following two tests  if value:     # do something  if not value:     # do something   are in fact evaluated as  if bool(value):     # do something  if not bool(value):     # do something   None is a \"falsey\", meaning that if cast to a boolean it will return False and if applied the not operator it will return True. Note however that it's not a property unique to None. In addition to False itself, the property is shared by empty lists, tuples, sets, dicts, strings, as well as 0, and all objects from classes that implement the __bool__() magic method to return False.  >>> bool(None) False >>> not None True  >>> bool([]) False >>> not [] True  >>> class MyFalsey(object): ...     def __bool__(self): ...         return False >>> f = MyFalsey() >>> bool(f) False >>> not f True   So when testing for variables in the following way, be extra aware of what you're including or excluding from the test:  def some_function(value=None):     if not value:         value = init_value()   In the above, did you mean to call init_value() when the value is set specifically to None, or did you mean that a value set to 0, or the empty string, or an empty list should also trigger the initialization. Like I said, be mindful. As it's often the case in Python explicit is better than implicit.  None in practice  None used as a signal value  None has a special status in Python. It's a favorite baseline value because many algorithms treat it as an exceptional value. In such scenarios it can be used as a flag to signal that a condition requires some special handling (such as the setting of a default value).  You can assign None to the keyword arguments of a function and then explicitly test for it.  def my_function(value, param=None):     if param is None:         # do something outrageous!   You can return it as the default when trying to get to an object's attribute and then explicitly test for it before doing something special.  value = getattr(some_obj, 'some_attribute', None) if value is None:     # do something spectacular!   By default a dictionary's get() method returns None when trying to access a non-existing key:  >>> some_dict = {} >>> value = some_dict.get('foo') >>> value is None True   If you were to try to access it by using the subscript notation a KeyError would be raised  >>> value = some_dict['foo'] KeyError: 'foo'   Likewise if you attempt to pop a non-existing item  >>> value = some_dict.pop('foo') KeyError: 'foo'   which you can suppress with a default value that is usually set to None  value = some_dict.pop('foo', None) if value is None:     # booom!   None used as both a flag and valid value  The above described uses of None apply when it is not considered a valid value, but more like a signal to do something special. There are situations however where it sometimes matters to know where None came from because even though it's used as a signal it could also be part of the data.  When you query an object for its attribute with getattr(some_obj, 'attribute_name', None) getting back None doesn't tell you if the attribute you were trying to access was set to None or if it was altogether absent from the object. Same situation when accessing a key from a dictionary like some_dict.get('some_key'), you don't know if some_dict['some_key'] is missing or if it's just set to None. If you need that information, the usual way to handle this is to directly attempt accessing the attribute or key from within a try/except construct:  try:     # equivalent to getattr() without specifying a default     # value = getattr(some_obj, 'some_attribute')     value = some_obj.some_attribute     # now you handle `None` the data here     if value is None:         # do something here because the attribute was set to None except AttributeError:     # we're now hanling the exceptional situation from here.     # We could assign None as a default value if required.     value = None      # In addition, since we now know that some_obj doesn't have the     # attribute 'some_attribute' we could do something about that.     log_something(some_obj)   Similarly with dict:  try:     value = some_dict['some_key']     if value is None:         # do something here because 'some_key' is set to None except KeyError:     # set a default      value = None     # and do something because 'some_key' was missing     # from the dict.     log_something(some_dict)   The above two examples show how to handle object and dictionary cases, what about functions? Same thing, but we use the double asterisks keyword argument to that end:  def my_function(**kwargs):     try:         value = kwargs['some_key']          if value is None:             # do something because 'some_key' is explicitly              # set to None     except KeyError:         # we assign the default         value = None         # and since it's not coming from the caller.         log_something('did not receive \"some_key\"')   None used only as a valid value  If you find that your code is littered with the above try/except pattern simply to differentiate between None flags and None data, then just use another test value. There's a pattern where a value that falls outside the set of valid values is inserted as part of the data in a data structure and is used to control and test special conditions (e.g. boundaries, state, etc). Such a value is called a sentinel and it can be used the way None is used as a signal. It's trivial to create a sentinel in Python.  undefined = object()   The undefined object above is unique and doesn't do much of anything that might be of interest to a program, it's thus an excellent replacement for None as a flag. Some caveats apply, more about that after the code.  With function  def my_function(value, param1=undefined, param2=undefined):     if param1 is undefined:         # we know nothing was passed to it, not even None         log_something('param1 was missing')         param1 = None       if param2 is undefined:         # we got nothing here either         log_something('param2 was missing')         param2 = None   With dict  value = some_dict.get('some_key', undefined) if value is None:     log_something(\"'some_key' was set to None\")  if value is undefined:     # we know that the dict didn't have 'some_key'     log_something(\"'some_key' was not set at all\")     value = None   With an object  value = getattr(obj, 'some_attribute', undefined)  if value is None:     log_something(\"'obj.some_attribute' was set to None\") if value is undefined:     # we know that there's no obj.some_attribute     log_something(\"no 'some_attribute' set on obj\")     value = None   As I mentioned earlier custom sentinels come with some caveats. First, they're not keywords like None, so python doesn't protect them. You can overwrite your undefined above at any time, anywhere in the module it's defined, so be careful how you expose and use them. Next, the instance returned by object() is not a singleton, if you make that call 10 times you get 10 different objects. Finally, usage of a sentinel is highly idiosyncratic. A sentinel is specific to the library it's used in and as such its scope should generally be limited to the library's internals. It shouldn't \"leak\" out. External code should only become aware of it, if their purpose is to extend or supplement the library's API.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3289601/null-object-in-python", "Language": "Python", "Q_Title": "null object in Python?", "Q_Votes": "824", "Q_Content": "    How do I refer to the null object in Python?     ", "Tags": ["python", "null"], "A_Votes": "26", "A_Content": "  In Python, to represent the absence of a value, you can use the None value (types.NoneType.None) for objects and \"\" (or len() == 0) for strings. Therefore:  if yourObject is None:  # if yourObject == None:     ...  if yourString == \"\":  # if yourString.len() == 0:     ...   Regarding the difference between \"==\" and \"is\", testing for object identity using \"==\" should be sufficient. However, since the operation \"is\" is defined as the object identity operation, it is probably more correct to use it, rather than \"==\". Not sure if there is even a speed difference.  Anyway, you can have a look at:   Python Built-in Constants doc page. Python Truth Value Testing doc page.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3289601/null-object-in-python", "Language": "Python", "Q_Title": "null object in Python?", "Q_Votes": "824", "Q_Content": "    How do I refer to the null object in Python?     ", "Tags": ["python", "null"], "A_Votes": "1", "A_Content": "  Per Truth value testing, 'None' directly tests as FALSE, so the simplest expression will suffice:  if not foo:      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "1549", "A_Content": "  The best way to do this in pandas is to use drop:  df = df.drop('column_name', 1)   where 1 is the axis number (0 for rows and 1 for columns.)  To delete the column without having to reassign df you can do:  df.drop('column_name', axis=1, inplace=True)   Finally, to drop by column number instead of by column label, try this to delete, e.g. the 1st, 2nd and 4th columns:  df.drop(df.columns[[0, 1, 3]], axis=1)  # df.columns is zero-based pd.Index       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "185", "A_Content": "  Use:  columns = ['Col1', 'Col2', ...] df.drop(columns, inplace=True, axis=1)   This will delete one or more columns in-place. Note that inplace=True was added in pandas v0.13 and won't work on older versions. You'd have to assign the result back in that case:  df = df.drop(columns, axis=1)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "82", "A_Content": "  Drop by index  Delete first, second and fourth columns:  df.drop(df.columns[[0,1,3]], axis=1, inplace=True)   Delete first column:  df.drop(df.columns[[0]], axis=1, inplace=True)   There is an optional parameter inplace so that the original data can be modified without creating a copy.  Popped  Column selection, addition, deletion  Delete column column-name:  df.pop('column-name')   Examples:  df = DataFrame.from_items([('A', [1, 2, 3]), ('B', [4, 5, 6]), ('C', [7,8, 9])], orient='index', columns=['one', 'two', 'three'])   print df:     one  two  three A    1    2      3 B    4    5      6 C    7    8      9   df.drop(df.columns[[0]], axis=1, inplace=True) print df:     two  three A    2      3 B    5      6 C    8      9   three = df.pop('three') print df:     two A    2 B    5 C    8      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "54", "A_Content": "  The actual question posed, missed by most answers here is:  Why can't I use del df.column_name?  At first we need to understand the problem, which requires us to dive into python magic methods.  As Wes points out in his answer del df['column'] maps to the python magic method df.__delitem__('column') which is implemented in pandas to drop the column  However, as pointed out in the link above about python magic methods:     In fact, del should almost never be used because of the precarious circumstances under which it is called; use it with caution!   You could argue that del df['column_name'] should not be used or encouraged, and thereby del df.column_name should not even be considered.  However, in theory, del df.column_name could be implemeted to work in pandas using the magic method __delattr__. This does however introduce certain problems, problems which the del df['column_name'] implementation already has, but in lesser degree.  Example Problem  What if I define a column in a dataframe called \"dtypes\" or \"columns\".  Then assume I want to delete these columns.  del df.dtypes would make the __delattr__ method confused as if it should delete the \"dtypes\" attribute or the \"dtypes\" column.  Architectural questions behind this problem   Is a dataframe a collection of columns? Is a dataframe a collection of rows? Is a column an attribute of a dataframe?   Pandas answers:   Yes, in all ways No, but if you want it to be, you can use the .ix, .loc or .iloc methods. Maybe, do you want to read data? Then yes, unless the name of the attribute is already taken by another attribute belonging to the dataframe. Do you want to modify data? Then no.   TLDR;  You cannot do del df.column_name because pandas has a quite wildly grown architecture that needs to be reconsidered in order for this kind of cognitive dissonance not to occur to its users.  Protip:  Don't use df.column_name, It may be pretty, but it causes cognitive dissonance  Zen of Python quotes that fits in here:  There are multiple ways of deleting a column.     There should be one-- and preferably only one --obvious way to do it.   Columns are sometimes attributes but sometimes not.     Special cases aren't special enough to break the rules.   Does del df.dtypes delete the dtypes attribute or the dtypes column?     In the face of ambiguity, refuse the temptation to guess.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "41", "A_Content": "  A nice addition is the ability to drop columns only if they exist. This way you can cover more use cases, and it will only drop the existing columns from the labels passed to it:  Simply add errors='ignore', for example.:  df.drop(['col_name_1', 'col_name_2', ..., 'col_name_N'], inplace=True, axis=1, errors='ignore')    This is new from pandas 0.16.1 onward. Documentation is here.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "38", "A_Content": "  from version 0.16.1 you can do   df.drop(['column_name'], axis = 1, inplace = True, errors = 'ignore')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "24", "A_Content": "  It's good practice to always use the [] notation. One reason is that attribute notation (df.column_name) does not work for numbered indices:  In [1]: df = DataFrame([[1, 2, 3], [4, 5, 6]])  In [2]: df[1] Out[2]: 0    2 1    5 Name: 1  In [3]: df.1   File \"<ipython-input-3-e4803c0d1066>\", line 1     df.1        ^ SyntaxError: invalid syntax      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "20", "A_Content": "  In pandas 0.16.1+ you can drop columns only if they exist per the solution posted by @eiTanLaVi.  Prior to that version, you can achieve the same result via a conditional list comprehension:  df.drop([col for col in ['col_name_1','col_name_2',...,'col_name_N'] if col in df],          axis=1, inplace=True)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "11", "A_Content": "  TL;DR  A lot of effort to find a marginally more efficient solution.  Difficult to justify the added complexity while sacrificing the simplicity of df.drop(dlst, 1, errors='ignore')  df.reindex_axis(np.setdiff1d(df.columns.values, dlst), 1)   Preamble Deleting a column is semantically the same as selecting the other columns.  I'll show a few additional methods to consider.    I'll also focus on the general solution of deleting multiple columns at once and allowing for the attempt to delete columns not present.    Using these solutions are general and will work for the simple case as well.    Setup Consider the pd.DataFrame df and list to delete dlst  df = pd.DataFrame(dict(zip('ABCDEFGHIJ', range(1, 11))), range(3)) dlst = list('HIJKLM')     df     A  B  C  D  E  F  G  H  I   J 0  1  2  3  4  5  6  7  8  9  10 1  1  2  3  4  5  6  7  8  9  10 2  1  2  3  4  5  6  7  8  9  10     dlst  ['H', 'I', 'J', 'K', 'L', 'M']   The result should look like:  df.drop(dlst, 1, errors='ignore')     A  B  C  D  E  F  G 0  1  2  3  4  5  6  7 1  1  2  3  4  5  6  7 2  1  2  3  4  5  6  7     Since I'm equating deleting a column to selecting the other columns, I'll break it into two types:   Label selection Boolean selection     Label Selection  We start by manufacturing the list/array of labels that represent the columns we want to keep and without the columns we want to delete.   df.columns.difference(dlst)  Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')  np.setdiff1d(df.columns.values, dlst)  array(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype=object)  df.columns.drop(dlst, errors='ignore')  Index(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='object')  list(set(df.columns.values.tolist()).difference(dlst))  # does not preserve order ['E', 'D', 'B', 'F', 'G', 'A', 'C']  [x for x in df.columns.values.tolist() if x not in dlst]  ['A', 'B', 'C', 'D', 'E', 'F', 'G']      Columns from Labels For the sake of comparing the selection process, assume:   cols = [x for x in df.columns.values.tolist() if x not in dlst]   Then we can evaluate     df.loc[:, cols] df[cols] df.reindex(columns=cols) df.reindex_axis(cols, 1)   Which all evaluate to:     A  B  C  D  E  F  G 0  1  2  3  4  5  6  7 1  1  2  3  4  5  6  7 2  1  2  3  4  5  6  7     Boolean Slice  We can construct an array/list of booleans for slicing   ~df.columns.isin(dlst) ~np.in1d(df.columns.values, dlst) [x not in dlst for x in df.columns.values.tolist()] (df.columns.values[:, None] != dlst).all(1)   Columns from Boolean For the sake of comparison    bools = [x not in dlst for x in df.columns.values.tolist()]    df.loc[: bools]   Which all evaluate to:     A  B  C  D  E  F  G 0  1  2  3  4  5  6  7 1  1  2  3  4  5  6  7 2  1  2  3  4  5  6  7     Robust Timing    Functions    setdiff1d = lambda df, dlst: np.setdiff1d(df.columns.values, dlst) difference = lambda df, dlst: df.columns.difference(dlst) columndrop = lambda df, dlst: df.columns.drop(dlst, errors='ignore') setdifflst = lambda df, dlst: list(set(df.columns.values.tolist()).difference(dlst)) comprehension = lambda df, dlst: [x for x in df.columns.values.tolist() if x not in dlst]  loc = lambda df, cols: df.loc[:, cols] slc = lambda df, cols: df[cols] ridx = lambda df, cols: df.reindex(columns=cols) ridxa = lambda df, cols: df.reindex_axis(cols, 1)  isin = lambda df, dlst: ~df.columns.isin(dlst) in1d = lambda df, dlst: ~np.in1d(df.columns.values, dlst) comp = lambda df, dlst: [x not in dlst for x in df.columns.values.tolist()] brod = lambda df, dlst: (df.columns.values[:, None] != dlst).all(1)   Testing    res1 = pd.DataFrame(     index=pd.MultiIndex.from_product([         'loc slc ridx ridxa'.split(),         'setdiff1d difference columndrop setdifflst comprehension'.split(),     ], names=['Select', 'Label']),     columns=[10, 30, 100, 300, 1000],     dtype=float )  res2 = pd.DataFrame(     index=pd.MultiIndex.from_product([         'loc'.split(),         'isin in1d comp brod'.split(),     ], names=['Select', 'Label']),     columns=[10, 30, 100, 300, 1000],     dtype=float )  res = res1.append(res2).sort_index()  dres = pd.Series(index=res.columns, name='drop')  for j in res.columns:     dlst = list(range(j))     cols = list(range(j // 2, j + j // 2))     d = pd.DataFrame(1, range(10), cols)     dres.at[j] = timeit('d.drop(dlst, 1, errors=\"ignore\")', 'from __main__ import d, dlst', number=100)     for s, l in res.index:         stmt = '{}(d, {}(d, dlst))'.format(s, l)         setp = 'from __main__ import d, dlst, {}, {}'.format(s, l)         res.at[(s, l), j] = timeit(stmt, setp, number=100)  rs = res / dres     rs                            10        30        100       300        1000 Select Label                                                            loc    brod           0.747373  0.861979  0.891144  1.284235   3.872157        columndrop     1.193983  1.292843  1.396841  1.484429   1.335733        comp           0.802036  0.732326  1.149397  3.473283  25.565922        comprehension  1.463503  1.568395  1.866441  4.421639  26.552276        difference     1.413010  1.460863  1.587594  1.568571   1.569735        in1d           0.818502  0.844374  0.994093  1.042360   1.076255        isin           1.008874  0.879706  1.021712  1.001119   0.964327        setdiff1d      1.352828  1.274061  1.483380  1.459986   1.466575        setdifflst     1.233332  1.444521  1.714199  1.797241   1.876425 ridx   columndrop     0.903013  0.832814  0.949234  0.976366   0.982888        comprehension  0.777445  0.827151  1.108028  3.473164  25.528879        difference     1.086859  1.081396  1.293132  1.173044   1.237613        setdiff1d      0.946009  0.873169  0.900185  0.908194   1.036124        setdifflst     0.732964  0.823218  0.819748  0.990315   1.050910 ridxa  columndrop     0.835254  0.774701  0.907105  0.908006   0.932754        comprehension  0.697749  0.762556  1.215225  3.510226  25.041832        difference     1.055099  1.010208  1.122005  1.119575   1.383065        setdiff1d      0.760716  0.725386  0.849949  0.879425   0.946460        setdifflst     0.710008  0.668108  0.778060  0.871766   0.939537 slc    columndrop     1.268191  1.521264  2.646687  1.919423   1.981091        comprehension  0.856893  0.870365  1.290730  3.564219  26.208937        difference     1.470095  1.747211  2.886581  2.254690   2.050536        setdiff1d      1.098427  1.133476  1.466029  2.045965   3.123452        setdifflst     0.833700  0.846652  1.013061  1.110352   1.287831     fig, axes = plt.subplots(2, 2, figsize=(8, 6), sharey=True) for i, (n, g) in enumerate([(n, g.xs(n)) for n, g in rs.groupby('Select')]):     ax = axes[i // 2, i % 2]     g.plot.bar(ax=ax, title=n)     ax.legend_.remove() fig.tight_layout()   This is relative to the time it takes to run df.drop(dlst, 1, errors='ignore').  It seems like after all that effort, we only improve performance modestly.    If fact the best solutions use reindex or reindex_axis on the hack list(set(df.columns.values.tolist()).difference(dlst)).  A close second and still very marginally better than drop is np.setdiff1d.  rs.idxmin().pipe(     lambda x: pd.DataFrame(         dict(idx=x.values, val=rs.lookup(x.values, x.index)),         x.index     ) )                        idx       val 10     (ridx, setdifflst)  0.653431 30    (ridxa, setdifflst)  0.746143 100   (ridxa, setdifflst)  0.816207 300    (ridx, setdifflst)  0.780157 1000  (ridxa, setdifflst)  0.861622      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "10", "A_Content": "  Pandas 0.21+ Answer  Pandas version 0.21 has slightly changed the drop method to include both the index and columns parameters to match the signature of the rename and reindex methods.   df.drop(columns=['column_a', 'column_c'])   Personally, I prefer using the axis parameter to denote columns or index because it is the predominant keyword parameter used in nearly all pandas methods. But, now you have some added choices in version 0.21.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "2", "A_Content": "  The dot syntax works in JavaScript, but not in Python.   Python: del df['column_name'] JavaScript: del df['column_name'] or del df.column_name      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe-using-del-df-column-name", "Language": "Python", "Q_Title": "Delete column from pandas DataFrame using del df.column_name", "Q_Votes": "825", "Q_Content": "    When deleting a column in a DataFrame I use:  del df['column_name']   And this works great. Why can't I use the following?  del df.column_name   As you can access the column/Series as df.column_name, I expect this to work.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "0", "A_Content": "  Another way of Deleting a Column in Pandas DataFrame  if you're not looking for In-Place deletion then you can create a new DataFrame by specifying the columns using DataFrame(...) function  as  my_dict = { 'name' : ['a','b','c','d'], 'age' : [10,20,25,22], 'designation' : ['CEO', 'VP', 'MD', 'CEO']}  df = pd.DataFrame(my_dict)   Create a new DataFrame as  newdf = pd.DataFrame(df, columns=['name', 'age'])   You get a result as good as what you get with del / drop     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "526", "A_Content": "  Named tuples were added in 2.6 for this purpose.  Also see os.stat for a similar builtin example.  >>> import collections >>> Point = collections.namedtuple('Point', ['x', 'y']) >>> p = Point(1, y=2) >>> p.x, p.y 1 2 >>> p[0], p[1] 1 2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files", "Language": "Python", "Q_Title": "If Python is interpreted, what are .pyc files?", "Q_Votes": "823", "Q_Content": "    I've been given to understand that Python is an interpreted language... However, when I look at my Python source code I see .pyc files, which Windows identifies as \"Compiled Python Files\". Where do these come in?     ", "Tags": ["python", "compiled", "interpreted-language", "pyc"], "A_Votes": "528", "A_Content": "  They contain byte code, which is what the Python interpreter compiles the source to. This code is then executed by Python's virtual machine.   Python's documentation explains the definition like this:     Python is an interpreted language, as   opposed to a compiled one, though the   distinction can be blurry because of   the presence of the bytecode compiler.   This means that source files can be   run directly without explicitly   creating an executable which is then   run.      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "170", "A_Content": "  For small projects I find it easiest to work with tuples. When that gets too hard to manage (and not before) I start grouping things into logical structures, however I think your suggested use of dictionaries and ReturnValue objects is wrong (or too simplistic).  Returning a dictionary with keys y0, y1, y2 etc doesn't offer any advantage over tuples. Returning a ReturnValue instance with properties .y0 .y1 .y2 etc doesn't offer any advantage over tuples either. You need to start naming things if you want to get anywhere, and you can do that using tuples anyway:  def getImageData(filename):   [snip]   return size, (format, version, compression), (width,height) size, type, dimensions = getImageData(x)   IMHO, the only good technique beyond tuples is to return real objects with proper methods and properties, like you get from re.match() or open(file).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "132", "A_Content": "  A lot of the answers suggest you need to return a collection of some sort, like a dictionary or a list. You could leave off the extra syntax and just write out the return values, comma-separated. Note: this technically returns a tuple.  def f():     return True, False x, y = f() print(x) print(y)   gives:  True False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "54", "A_Content": "  I vote for the dictionary.  I find that if I make a function that returns anything more than 2-3 variables I'll fold them up in a dictionary.  Otherwise I tend to forget the order and content of what I'm returning.  Also, introducing a 'special' structure makes your code more difficult to follow. (Someone else will have to search through the code to find out what it is)  If your concerned about type look up, use descriptive dictionary keys, for example, 'x-values list'.  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "30", "A_Content": "  Another option would be using generators:  >>> def f(x):         y0 = x + 1         yield y0         yield x * 3         yield y0 ** 4   >>> a, b, c = f(5) >>> a 6 >>> b 15 >>> c 1296   Although IMHO tuples are usually best, except in cases where the values being returned are candidates for encapsulation in a class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "22", "A_Content": "  I prefer to use tuples whenever a tuple feels \"natural\"; coordinates are a typical example, where the separate objects can stand on their own, e.g. in one-axis only scaling calculations, and the order is important. Note: if I can sort or shuffle the items without an adverse effect to the meaning of the group, then I probably shouldn't use a tuple.  I use dictionaries as a return value only when the grouped objects aren't always the same. Think optional email headers.  For the rest of the cases, where the grouped objects have inherent meaning inside the group or a fully-fledged object with its own methods is needed, I use a class.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "21", "A_Content": "  >>> def func(): ...    return [1,2,3] ... >>> a,b,c = func() >>> a 1 >>> b 2 >>> c 3      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "20", "A_Content": "  I prefer  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   it seems everything else is just extra code to do the same thing.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "13", "A_Content": "  +1 on S.Lott's suggestion of a named container class.  For python 2.6 and up, a named tuple provides a useful way of easily creating these container classes, and the results are \"lightweight and require no more memory than regular tuples\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "13", "A_Content": "  Python's tuples, dicts, and objects offer the programmer a smooth tradeoff between formality and convenience for small data structures (\"things\"). For me, the choice of how to represent a thing is dictated mainly by how I'm going to use the structure. In C++, it's a common convention to use struct for data-only items and class for objects with methods, even though you can legally put methods on a struct; my habit is similar in Python, with dict and tuple in place of struct.  For coordinate sets, I'll use a tuple rather than a point class or a dict (and note that you can use a tuple as a dictionary key, so dicts make great sparse multidimensional arrays).   If I'm going to be iterating over a list of things, I prefer unpacking tuples on the iteration:  for score,id,name in scoreAllTheThings():     if score > goodScoreThreshold:         print \"%6.3f #%6d %s\"%(score,id,name)   ...as the object version is more cluttered to read:  for entry in scoreAllTheThings():     if entry.score > goodScoreThreshold:         print \"%6.3f #%6d %s\"%(entry.score,entry.id,entry.name)   ...let alone the dict.  for entry in scoreAllTheThings():     if entry['score'] > goodScoreThreshold:         print \"%6.3f #%6d %s\"%(entry['score'],entry['id'],entry['name'])   If the thing is widely used, and you find yourself doing similar non-trivial operations on it in multiple places in the code, then it's usually worthwhile to make it a class object with appropriate methods.   Finally, if I'm going to be exchanging data with non-Python system components, I'll most often keep them in a dict because that's best suited to JSON serialization.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "12", "A_Content": "  Generally, the \"specialized structure\" actually IS a sensible current state of an object, with its own methods.  class Some3SpaceThing(object):   def __init__(self,x):     self.g(x)   def g(self,x):     self.y0 = x + 1     self.y1 = x * 3     self.y2 = y0 ** y3  r = Some3SpaceThing( x ) r.y0 r.y1 r.y2   I like to find names for anonymous structures where possible.  Meaningful names make things more clear.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "2", "A_Content": "  In languages like Python, I would usually use a dictionary as it involves less overhead than creating a new class.  However, if I find myself constantly returning the same set of variables, then that probably involves a new class that I'll factor out.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "2", "A_Content": "  I would use a dict to pass and return values from a function:  Use variable form as defined in form.  form = {     'level': 0,     'points': 0,     'game': {         'name': ''     } }   def test(form):     form['game']['name'] = 'My game!'     form['level'] = 2      return form  >>> print(test(form)) {u'game': {u'name': u'My game!'}, u'points': 0, u'level': 2}   This is the most efficient way for me and for processing unit.  You have to pass just one pointer in and return just one pointer out.  You do not have to change functions' (thousands of them) arguments whenever you make a change in your code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files", "Language": "Python", "Q_Title": "If Python is interpreted, what are .pyc files?", "Q_Votes": "823", "Q_Content": "    I've been given to understand that Python is an interpreted language... However, when I look at my Python source code I see .pyc files, which Windows identifies as \"Compiled Python Files\". Where do these come in?     ", "Tags": ["python", "compiled", "interpreted-language", "pyc"], "A_Votes": "796", "A_Content": "     I've been given to understand that   Python is an interpreted language...   This popular meme is incorrect, or, rather, constructed upon a misunderstanding of (natural) language levels: a similar mistake would be to say \"the Bible is a hardcover book\".  Let me explain that simile...  \"The Bible\" is \"a book\" in the sense of being a class of (actual, physical objects identified as) books; the books identified as \"copies of the Bible\" are supposed to have something fundamental in common (the contents, although even those can be in different languages, with different acceptable translations, levels of footnotes and other annotations) -- however, those books are perfectly well allowed to differ in a myriad of aspects that are not considered fundamental -- kind of binding, color of binding, font(s) used in the printing, illustrations if any, wide writable margins or not, numbers and kinds of builtin bookmarks, and so on, and so forth.  It's quite possible that a typical printing of the Bible would indeed be in hardcover binding -- after all, it's a book that's typically meant to be read over and over, bookmarked at several places, thumbed through looking for given chapter-and-verse pointers, etc, etc, and a good hardcover binding can make a given copy last longer under such use.  However, these are mundane (practical) issues that cannot be used to determine whether a given actual book object is a copy of the Bible or not: paperback printings are perfectly possible!  Similarly, Python is \"a language\" in the sense of defining a class of language implementations which must all be similar in some fundamental respects (syntax, most semantics except those parts of those where they're explicitly allowed to differ) but are fully allowed to differ in just about every \"implementation\" detail -- including how they deal with the source files they're given, whether they compile the sources to some lower level forms (and, if so, which form -- and whether they save such compiled forms, to disk or elsewhere), how they execute said forms, and so forth.  The classical implementation, CPython, is often called just \"Python\" for short -- but it's just one of several production-quality implementations, side by side with Microsoft's IronPython (which compiles to CLR codes, i.e., \".NET\"), Jython (which compiles to JVM codes), PyPy (which is written in Python itself and can compile to a huge variety of \"back-end\" forms including \"just-in-time\" generated machine language).  They're all Python (==\"implementations of the Python language\") just like many superficially different book objects can all be Bibles (==\"copies of The Bible\").  If you're interested in CPython specifically: it compiles the source files into a Python-specific lower-level form (known as \"bytecode\"), does so automatically when needed (when there is no bytecode file corresponding to a source file, or the bytecode file is older than the source or compiled by a different Python version), usually saves the bytecode files to disk (to avoid recompiling them in the future).  OTOH IronPython will typically compile to CLR codes (saving them to disk or not, depending) and Jython to JVM codes (saving them to disk or not -- it will use the .class extension if it does save them).  These lower level forms are then executed by appropriate \"virtual machines\" also known as \"interpreters\" -- the CPython VM, the .Net runtime, the Java VM (aka JVM), as appropriate.  So, in this sense (what do typical implementations do), Python is an \"interpreted language\" if and only if C# and Java are: all of them have a typical implementation strategy of producing bytecode first, then executing it via a VM/interpreter.  More likely the focus is on how \"heavy\", slow, and high-ceremony the compilation process is.  CPython is designed to compile as fast as possible, as lightweight as possible, with as little ceremony as feasible -- the compiler does very little error checking and optimization, so it can run fast and in small amounts of memory, which in turns lets it be run automatically and transparently whenever needed, without the user even needing to be aware that there is a compilation going on, most of the time.  Java and C# typically accept more work during compilation (and therefore don't perform automatic compilation) in order to check errors more thoroughly and perform more optimizations.  It's a continuum of gray scales, not a black or white situation, and it would be utterly arbitrary to put a threshold at some given level and say that only above that level you call it \"compilation\"!-)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files", "Language": "Python", "Q_Title": "If Python is interpreted, what are .pyc files?", "Q_Votes": "823", "Q_Content": "    I've been given to understand that Python is an interpreted language... However, when I look at my Python source code I see .pyc files, which Windows identifies as \"Compiled Python Files\". Where do these come in?     ", "Tags": ["python", "compiled", "interpreted-language", "pyc"], "A_Votes": "128", "A_Content": "  There is no such thing as an interpreted language. Whether an interpreter or a compiler is used is purely a trait of the implementation and has absolutely nothing whatsoever to do with the language.  Every language can be implemented by either an interpreter or a compiler. The vast majority of languages have at least one implementation of each type. (For example, there are interpreters for C and C++ and there are compilers for JavaScript, PHP, Perl, Python and Ruby.) Besides, the majority of modern language implementations actually combine both an interpreter and a compiler (or even multiple compilers).  A language is just a set of abstract mathematical rules. An interpreter is one of several concrete implementation strategies for a language. Those two live on completely different abstraction levels. If English were a typed language, the term \"interpreted language\" would be a type error. The statement \"Python is an interpreted language\" is not just false (because being false would imply that the statement even makes sense, even if it is wrong), it just plain doesn't make sense, because a language can never be defined as \"interpreted.\"  In particular, if you look at the currently existing Python implementations, these are the implementation strategies they are using:   IronPython: compiles to DLR trees which the DLR then compiles to CIL bytecode. What happens to the CIL bytecode depends upon which CLI VES you are running on, but Microsoft .NET, GNU Portable.NET and Novell Mono will eventually compile it to native machine code. Jython: interprets Python sourcecode until it identifies the hot code paths, which it then compiles to JVML bytecode. What happens to the JVML bytecode depends upon which JVM you are running on. Maxine will directly compile it to un-optimized native code until it identifies the hot code paths, which it then recompiles to optimized native code. HotSpot will first interpret the JVML bytecode and then eventually compile the hot code paths to optimized machine code. PyPy: compiles to PyPy bytecode, which then gets interpreted by the PyPy VM until it identifies the hot code paths which it then compiles into native code, JVML bytecode or CIL bytecode depending on which platform you are running on. CPython: compiles to CPython bytecode which it then interprets. Stackless Python: compiles to CPython bytecode which it then interprets. Unladen Swallow: compiles to CPython bytecode which it then interprets until it identifies the hot code paths which it then compiles to LLVM IR which the LLVM compiler then compiles to native machine code.   You might notice that every single one of the implementations in that list (plus some others I didn't mention, like tinypy, Shedskin or Psyco) has a compiler. In fact, as far as I know, there is currently no Python implementation which is purely interpreted, there is no such implementation planned and there never has been such an implementation.  Not only does the term \"interpreted language\" not make sense, even if you interpret it as meaning \"language with interpreted implementation\", it is clearly not true. Whoever told you that, obviously doesn't know what he is talking about.  In particular, the .pyc files you are seeing are cached bytecode files produced by CPython, Stackless Python or Unladen Swallow.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files", "Language": "Python", "Q_Title": "If Python is interpreted, what are .pyc files?", "Q_Votes": "823", "Q_Content": "    I've been given to understand that Python is an interpreted language... However, when I look at my Python source code I see .pyc files, which Windows identifies as \"Compiled Python Files\". Where do these come in?     ", "Tags": ["python", "compiled", "interpreted-language", "pyc"], "A_Votes": "55", "A_Content": "  These are created by the Python interpreter when a .py file is imported, and they contain the \"compiled bytecode\" of the imported module/program, the idea being that the \"translation\" from source code to bytecode (which only needs to be done once) can be skipped on subsequent imports if the .pyc is newer than the corresponding .py file, thus speeding startup a little. But it's still interpreted.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files", "Language": "Python", "Q_Title": "If Python is interpreted, what are .pyc files?", "Q_Votes": "823", "Q_Content": "    I've been given to understand that Python is an interpreted language... However, when I look at my Python source code I see .pyc files, which Windows identifies as \"Compiled Python Files\". Where do these come in?     ", "Tags": ["python", "compiled", "interpreted-language", "pyc"], "A_Votes": "21", "A_Content": "  THIS IS FOR BEGINNERS,  Python automatically compiles your script to compiled code, so called byte code, before running it.  Running a script is not considered an import and no .pyc will be created.   For example, if you have a script file abc.py that imports another module xyz.py, when you run abc.py, xyz.pyc will be created since xyz is imported, but no abc.pyc file will be created since abc.py isn\u2019t being imported.  If you need to create a .pyc file for a module that is not imported, you can use the py_compile and compileall modules.  The py_compile module can manually compile any module. One way is to use the py_compile.compile function in that module interactively:  >>> import py_compile >>> py_compile.compile('abc.py')   This will write the .pyc to the same location as abc.py (you can override that with the optional parameter cfile).  You can also automatically compile all files in a directory or directories using the compileall module.  python -m compileall   If the directory name (the current directory in this example) is omitted, the module compiles everything found on sys.path     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files", "Language": "Python", "Q_Title": "If Python is interpreted, what are .pyc files?", "Q_Votes": "823", "Q_Content": "    I've been given to understand that Python is an interpreted language... However, when I look at my Python source code I see .pyc files, which Windows identifies as \"Compiled Python Files\". Where do these come in?     ", "Tags": ["python", "compiled", "interpreted-language", "pyc"], "A_Votes": "20", "A_Content": "  Python (at least the most common implementation of it) follows a pattern of compiling the original source to byte codes, then interpreting the byte codes on a virtual machine. This means (again, the most common implementation) is neither a pure interpreter nor a pure compiler.  The other side of this is, however, that the compilation process is mostly hidden -- the .pyc files are basically treated like a cache; they speed things up, but you normally don't have to be aware of them at all. It automatically invalidates and re-loads them (re-compiles the source code) when necessary based on file time/date stamps.  About the only time I've seen a problem with this was when a compiled bytecode file somehow got a timestamp well into the future, which meant it always looked newer than the source file. Since it looked newer, the source file was never recompiled, so no matter what changes you made, they were ignored...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files", "Language": "Python", "Q_Title": "If Python is interpreted, what are .pyc files?", "Q_Votes": "823", "Q_Content": "    I've been given to understand that Python is an interpreted language... However, when I look at my Python source code I see .pyc files, which Windows identifies as \"Compiled Python Files\". Where do these come in?     ", "Tags": ["python", "compiled", "interpreted-language", "pyc"], "A_Votes": "20", "A_Content": "  To speed up loading modules, Python caches the compiled content of modules in .pyc.  CPython compiles its source code into \"byte code\", and for performance reasons, it caches this byte code on the file system whenever the source file has changes. This makes loading of Python modules much faster because the compilation phase can be bypassed. When your source file is foo.py , CPython caches the byte code in a foo.pyc file right next to the source.  In python3, Python's import machinery is extended to write and search for byte code cache files in a single directory inside every Python package directory. This directory will be called __pycache__ .  Here is a flow chart describing how modules are loaded:    For more information:  ref:PEP3147 ref:\u201cCompiled\u201d Python files     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files", "Language": "Python", "Q_Title": "If Python is interpreted, what are .pyc files?", "Q_Votes": "823", "Q_Content": "    I've been given to understand that Python is an interpreted language... However, when I look at my Python source code I see .pyc files, which Windows identifies as \"Compiled Python Files\". Where do these come in?     ", "Tags": ["python", "compiled", "interpreted-language", "pyc"], "A_Votes": "10", "A_Content": "  Python's *.py file is just a text file in which you write some lines of code. When you try to execute this file using say \"python filename.py\"  This command invokes Python Virtual Machine. Python Virtual Machine has 2 components: \"compiler\" and \"interpreter\". Interpreter cannot directly read the text in *.py file, so this text is first converted into a byte code which is targeted to the PVM (not hardware but PVM). PVM executes this byte code. *.pyc file is also generated, as part of running it which performs your import operation on file in shell or in some other file.  If this *.pyc file is already generated then every next time you run/execute your *.py file, system directly loads your *.pyc file which won't need any compilation(This will save you some machine cycles of processor).  Once the *.pyc file is generated, there is no need of *.py file, unless you edit it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2998215/if-python-is-interpreted-what-are-pyc-files", "Language": "Python", "Q_Title": "If Python is interpreted, what are .pyc files?", "Q_Votes": "823", "Q_Content": "    I've been given to understand that Python is an interpreted language... However, when I look at my Python source code I see .pyc files, which Windows identifies as \"Compiled Python Files\". Where do these come in?     ", "Tags": ["python", "compiled", "interpreted-language", "pyc"], "A_Votes": "7", "A_Content": "  Python code goes through 2 stages. First step compiles the code into .pyc files which is actually a bytecode. Then this .pyc file(bytecode) is interpreted using CPython interpreter. Please refer to this link. Here process of code compilation and execution is explained in easy terms.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python", "Language": "Python", "Q_Title": "How do you return multiple values in Python? [on hold]", "Q_Votes": "823", "Q_Content": "    The canonical way to return multiple values in languages that support it is often tupling.   Option: Using a tuple  Consider this trivial example:  def f(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return (y0,y1,y2)   However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.  Option: Using a dictionary  The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict.   Consider the following:  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return {'y0':y0, 'y1':y1 ,'y2':y2 }   (edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)  Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,   result['y0']   Option: Using a class  However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:  class ReturnValue(object):   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2  def g(x):   y0 = x + 1   y1 = x * 3   y2 = y0 ** y3   return ReturnValue(y0, y1, y2)   In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.  There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:  class ReturnValue(object):   __slots__ = [\"y0\", \"y1\", \"y2\"]   def __init__(self, y0, y1, y2):      self.y0 = y0      self.y1 = y1      self.y2 = y2   From the Python Reference Manual:     The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.   Option: Using a list  Another suggestion which I'd overlooked comes from Bill the Lizard:  def h(x):   result = [x + 1]   result.append(x * 3)   result.append(y0 ** y3)   return result   This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.  Question  After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?  I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning.   So, how do -you- return multiple values in Python?     ", "Tags": ["python", "coding-style", "return", "return-value"], "A_Votes": "0", "A_Content": "  \"Best\" is a partially subjective decision. Use tuples for small return sets in the general case where an immutable is acceptable. A tuple is always preferable to a list when mutability is not a requirement.   For more complex return values, or for the case where formality is valuable (i.e. high value code) a named tuple is better. For the most complex case an object is usually best. However, it's really the situation that matters. If it makes sense to return an object because that is what you naturally have at the end of the function (e.g. Factory pattern) then return the object.   As the wise man said:     Premature optimization is the root of all evil (or at least most of   it) in programming.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "913", "A_Content": "  If you have several versions of Python installed, /usr/bin/env will ensure the interpreter used is the first one on your environment's $PATH. The alternative would be to hardcode something like #!/usr/bin/python; that's ok, but less flexible.  In Unix, an executable file that's meant to be interpreted can indicate what interpreter to use by having a #! at the start of the first line, followed by the interpreter (and any flags it may need).  If you're talking about other platforms, of course, this rule does not apply (but that \"shebang line\" does no harm, and will help if you ever copy that script to a platform with a Unix base, such as Linux, Mac, etc).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "224", "A_Content": "  That is called the shebang line. As the Wikipedia entry explains:     In computing, a shebang (also called a hashbang, hashpling, pound bang, or crunchbang) refers to the characters \"#!\" when they are the first two characters in an interpreter directive as the first line of a text file. In a Unix-like  operating system, the program loader takes the presence of these two characters as an indication that the file is a script, and tries to execute that script using the interpreter  specified by the rest of the first line in the file.   See also the Unix FAQ entry.  Even on Windows, where the shebang line does not determine the interpreter to be run, you can pass options to the interpreter by specifying them on the shebang line. I find it useful to keep a generic shebang line in one-off scripts (such as the ones I write when answering questions on SO), so I can quickly test them on both Windows and ArchLinux.  The env utility allows you to invoke a command on the path:     The first remaining argument specifies the program name to invoke; it is searched for according to the PATH environment variable. Any remaining arguments are passed as arguments to that program.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "138", "A_Content": "  Expanding a bit on the other answers, here's a little example of how your command line scripts can get into trouble by incautious use of /usr/bin/env shebang lines:  $ /usr/local/bin/python -V Python 2.6.4 $ /usr/bin/python -V Python 2.5.1 $ cat my_script.py  #!/usr/bin/env python import json print \"hello, json\" $ PATH=/usr/local/bin:/usr/bin $ ./my_script.py  hello, json $ PATH=/usr/bin:/usr/local/bin $ ./my_script.py  Traceback (most recent call last):   File \"./my_script.py\", line 2, in <module>     import json ImportError: No module named json   The json module doesn't exist in Python 2.5.  One way to guard against that kind of problem is to use the versioned python command names that are typically installed with most Pythons:  $ cat my_script.py  #!/usr/bin/env python2.6 import json print \"hello, json\"   If you just need to distinguish between Python 2.x and Python 3.x, recent releases of Python 3 also provide a python3 name:  $ cat my_script.py  #!/usr/bin/env python3 import json print(\"hello, json\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "78", "A_Content": "  In order to run the python script, we need to tell the shell three things:   That the file is a script Which interpreter we want to execute the script The path of said interpreter   The shebang #! accomplishes (1.). The shebang begins with a # because the # character is a comment marker in many scripting languages. The contents of the shebang line are therefore automatically ignored by the interpreter.  The env command accomplishes (2.) and (3.). To quote \"grawity,\"     A common use of the env command is to launch interpreters, by making   use of the fact that env will search $PATH for the command it is told   to launch. Since the shebang line requires an absolute path to be   specified, and since the location of various interpreters (perl, bash,   python) may vary a lot, it is common to use:      #!/usr/bin/env perl\u00a0 instead of trying to guess whether it is   /bin/perl, /usr/bin/perl, /usr/local/bin/perl, /usr/local/pkg/perl,   /fileserver/usr/bin/perl, or /home/MrDaniel/usr/bin/perl on the user's   system...      On the other hand, env is almost always in /usr/bin/env. (Except in   cases when it isn't; some systems might use /bin/env, but that's a   fairly rare occassion and only happens on non-Linux systems.)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "38", "A_Content": "  Technically, in Python, this is just a comment line.  This line is only used if you run the py script from the shell (from the command line). This is know as the \"Shebang!\", and it is used in various situations, not just with Python scripts.  Here, it instructs the shell to start a specific version of Python (to take care of the rest of the file.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "38", "A_Content": "  Perhaps your question is in this sense:  If you want to use: $python myscript.py  You don't need that line at all. The system will call python and then python interpreter will run your script.  But if you intend to use: $./myscript.py  Calling it directly like a normal program or bash script, you need write that line to specify to the system which program use to run it, (and also make it executable with chmod 755)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "34", "A_Content": "  The main reason to do this is to make the script portable across operating system environments.    For example under mingw, python scripts use :  #!/c/python3k/python    and under GNU/Linux distribution it is either:  #!/usr/local/bin/python    or   #!/usr/bin/python   and under the best commercial Unix sw/hw system of all (OS/X), it is:  #!/Applications/MacPython 2.5/python   or on FreeBSD:  #!/usr/local/bin/python   However all these differences can make the script portable across all by using:  #!/usr/bin/env python      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "25", "A_Content": "  The exec system call of the Linux kernel understands shebangs (#!) natively  When you do on bash:  ./something   on Linux, this calls the exec system call with the path ./something.  This line of the kernel gets called on the file passed to exec: https://github.com/torvalds/linux/blob/v4.8/fs/binfmt_script.c#L25     if ((bprm->buf[0] != '#') || (bprm->buf[1] != '!'))   This reads the very first bytes of the file, and compares them to #!.  If that is true, then the rest of the line is parsed by the Linux kernel, which makes another exec call with path /usr/bin/env python and current file as the first argument:  /usr/bin/env python /path/to/script.py   and this works for any scripting language that uses # as a comment character.  And yes, you can make an infinite loop with:  printf '#!/a\\n' | sudo tee /a sudo chmod +x /a /a   Bash recognizes the error:  -bash: /a: /a: bad interpreter: Too many levels of symbolic links   #! just happens to be human readable, but that is not required.  If the file started with different bytes, then the exec system call would use a different handler. The other most important built-in handler is for ELF executable files: https://github.com/torvalds/linux/blob/v4.8/fs/binfmt_elf.c#L1305 which checks for bytes 7f 45 4c 46 (which also happens to be human readable for .ELF). This reads the ELF file, puts it into memory correctly, and starts a new process with it. See also: How does kernel get an executable binary file running under linux?  Finally, you can add your own shebang handlers with the binfmt_misc mechanism. For example, you can add a custom handler for .jar files. This mechanism even supports handlers by file extension. Another application is to transparently run executables of a different architecture with QEMU.  I don't think POSIX specifies shebangs however: https://unix.stackexchange.com/a/346214/32558 , although it does mention in on rationale sections, and in the form \"if executable scripts are supported by the system something may happen\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "19", "A_Content": "  It probably makes sense to emphasize one thing that the most have missed, which may prevent immediate understanding. When you type python in terminal you don't normally provide a full path. Instead, the executable is up looked in PATH environment variable. In turn, when you want to execute a Python program directly, /path/to/app.py, one must tell the shell what interpreter to use (via the hashbang, what the other contributors are explaining above).  Hashbang expects full path to an interpreter. Thus to run your Python program directly you have to provide full path to Python binary which varies significantly, especially considering a use of virtualenv. To address portability the trick with /usr/bin/env is used. The latter is originally intended to alter environment in-place and run a command in it. When no alteration is provided it runs the command in current environment, which effectively results in the same PATH lookup which does the trick.  Source from unix stackexchange     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "12", "A_Content": "  It's recommended way, proposed in documentation:     2.2.2. Executable Python Scripts      On BSD\u2019ish Unix systems, Python scripts can be made directly   executable, like shell scripts, by putting the line  #! /usr/bin/env python3.2    from http://docs.python.org/py3k/tutorial/interpreter.html#executable-python-scripts     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "10", "A_Content": "  This is a shell convention that tells the shell which program can execute the script.  #!/usr/bin/env python  resolves to a path to the Python binary.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "9", "A_Content": "  You can try this issue using virtualenv  Here is test.py  #! /usr/bin/env python import sys print(sys.version)   Create virtual environments  virtualenv test2.6 -p /usr/bin/python2.6 virtualenv test2.7 -p /usr/bin/python2.7   activate each environment then check the differences  echo $PATH ./test.py      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "7", "A_Content": "     It seems to me like the files run the same without that line.   If so, then perhaps you're running the Python program on Windows? Windows doesn't use that line\u2014instead, it uses the file-name extension to run the program associated with the file extension.  However in 2011, a \"Python launcher\" was developed which (to some degree) mimics this Linux behaviour for Windows. This is limited just to choosing which Python interpreter is run \u2014 e.g. to select between Python 2 and Python 3 on a system where both are installed. The launcher is optionally installed as py.exe by Python installation, and can be associated with .py files so that the launcher will check that line and in turn launch the specified Python interpreter version.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "4", "A_Content": "  If you're running your script in a virtual environment, say venv, then executing which python while working on venv will display the path to the Python interpreter:  ~/Envs/venv/bin/python  Note that the name of the virtual environment is embedded in the path to the Python interpreter. Therefore, hardcoding this path in your script will cause two problems:   If you upload the script to a repository, you're forcing other users to have the same virtual environment name. This is if they identify the problem first. You won't be able to run the script across multiple virtual environments even if you had all required packages in other virtual environments.   Therefore, to add to Jonathan's answer, the ideal shebang is #!/usr/bin/env python, not just for portability across OSes but for portability across virtual environments as well!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "4", "A_Content": "  It just specifies what interpreter you want to use. To understand this, create a file through terminal by doing touch test.py, then type into that file the following:  #!/usr/bin/env python3 print \"test\"   and do chmod +x test.py to make your script executable. After this when you do ./test.py you should get an error saying:    File \"./test.py\", line 2     print \"test\"                ^ SyntaxError: Missing parentheses in call to 'print'   because python3 doesn't supprt the print operator.  Now go ahead and change the first line of your code to:  #!/usr/bin/env python2   and it'll work, printing test to stdout, because python2 supports the print operator. So, now you've learned how to switch between script interpreters.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "4", "A_Content": "  This is meant as more of historical information than a \"real\" answer.   Remember that back in the day you had LOTS of unix like operating systems whose designers all had their own notion of where to put stuff, and sometimes didn't include Python, Perl, Bash, or lots of other GNU/Open Source stuff at all.   This was even true of different Linux distributions. On Linux--pre-FHS[1]-you might have python in /usr/bin/ or /usr/local/bin/. Or it might not have been installed, so you built your own and put it in ~/bin   Solaris was the worst I ever worked on, partially as the transition from Berkeley Unix to System V. You could wind up with stuff in /usr/, /usr/local/, /usr/ucb, /opt/ etc. This could make for some really long paths. I have memories of the stuff from Sunfreeware.com installing each package in it's own directory, but I can't recall if it symlinked the binaries into /usr/bin or not.   Oh, and sometimes /usr/bin was on an NFS server[2].    So the env utility was developed to work around this.  Then you could write #!/bin/env interpreter and as long as the path was proper things had a reasonable chance of running. Of course, reasonable meant (for Python and Perl) that you had also set the appropriate environmental variables. For bash/ksh/zsh it just worked.   This was important because people were passing around shell scripts (like perl and python) and if you'd hard coded /usr/bin/python on your Red Hat Linux workstation it was going to break bad on a SGI...well, no, I think IRIX put python in the right spot. But on a Sparc station it might not run at all.   I miss my sparc station. But not a lot. Ok, now you've got me trolling around on E-Bay. Bastages.   [1] File-system Hierarchy Standard. https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard  [2] Yes, and sometimes people still do stuff like that. And no, I did not wear either a turnip OR an onion on my belt.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "3", "A_Content": "  Considering the portability issues between python2 and python3, you should always specify either version unless your program is compatible with both.  Some distributions are shipping python symlinked to python3 for a while now - do not rely on python being python2.  This is emphasized by PEP 394:     In order to tolerate differences across platforms, all new code that   needs to invoke the Python interpreter should not specify python, but   rather should specify either python2 or python3 (or the more specific   python2.x and python3.x versions; see the Migration Notes). This   distinction should be made in shebangs, when invoking from a shell   script, when invoking via the system() call, or when invoking in any   other context.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2429511/why-do-people-write-the-usr-bin-env-python-shebang-on-the-first-line-of-a-pyt", "Language": "Python", "Q_Title": "Why do people write the #!/usr/bin/env python shebang on the first line of a Python script?", "Q_Votes": "839", "Q_Content": "    It seems to me like the files run the same without that line.     ", "Tags": ["python", "shell", "shebang"], "A_Votes": "2", "A_Content": "  It tells the interpreter which version of python to run the program with when you have multiple versions of python.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5226311/installing-specific-package-versions-with-pip", "Language": "Python", "Q_Title": "Installing specific package versions with pip", "Q_Votes": "871", "Q_Content": "    I'm trying to install version 1.2.2 of the MySQL_python adaptor, using a fresh virtualenv created with the --no-site-packages option. The current version shown in PyPi is 1.2.3. Is there a way to install the older version? I found an article stating that this should do it:  pip install MySQL_python==1.2.2   When installed, however, it still shows MySQL_python-1.2.3-py2.6.egg-info in the site packages. Is this a problem specific to this package, or am I doing something wrong?     ", "Tags": ["python", "mysql", "pip", "pypi", "mysql-python"], "A_Votes": "637", "A_Content": "  First, I see two issues with what you're trying to do. Since you already have an installed version, you should either uninstall the current existing driver or use pip install -I MySQL_python==1.2.2  However, you'll soon find out that this doesn't work. If you look at pip's installation log, or if you do a pip install -Iv MySQL_python==1.2.2 you'll find that the PyPI URL link does not work for MySQL_python v1.2.2. You can verify this here: http://pypi.python.org/pypi/MySQL-python/1.2.2  The download link 404s and the fallback URL links are re-directing infinitely due to sourceforge.net's recent upgrade and PyPI's stale URL.  So to properly install the driver, you can follow these steps:  pip uninstall MySQL_python pip install -Iv http://sourceforge.net/projects/mysql-python/files/mysql-python/1.2.2/MySQL-python-1.2.2.tar.gz/download      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/5226311/installing-specific-package-versions-with-pip", "Language": "Python", "Q_Title": "Installing specific package versions with pip", "Q_Votes": "871", "Q_Content": "    I'm trying to install version 1.2.2 of the MySQL_python adaptor, using a fresh virtualenv created with the --no-site-packages option. The current version shown in PyPi is 1.2.3. Is there a way to install the older version? I found an article stating that this should do it:  pip install MySQL_python==1.2.2   When installed, however, it still shows MySQL_python-1.2.3-py2.6.egg-info in the site packages. Is this a problem specific to this package, or am I doing something wrong?     ", "Tags": ["python", "mysql", "pip", "pypi", "mysql-python"], "A_Votes": "276", "A_Content": "  You can even use a version range with pip install command. Something like this:  pip install 'stevedore>=1.3.0,<1.4.0'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5226311/installing-specific-package-versions-with-pip", "Language": "Python", "Q_Title": "Installing specific package versions with pip", "Q_Votes": "871", "Q_Content": "    I'm trying to install version 1.2.2 of the MySQL_python adaptor, using a fresh virtualenv created with the --no-site-packages option. The current version shown in PyPi is 1.2.3. Is there a way to install the older version? I found an article stating that this should do it:  pip install MySQL_python==1.2.2   When installed, however, it still shows MySQL_python-1.2.3-py2.6.egg-info in the site packages. Is this a problem specific to this package, or am I doing something wrong?     ", "Tags": ["python", "mysql", "pip", "pypi", "mysql-python"], "A_Votes": "95", "A_Content": "  One way as suggested in this post is to mention version in pip as   pip install -Iv MySQL_python==1.2.2  i.e. Use == and mention the version number to install only that version. -I, --ignore-installed ignores already installed packages.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5226311/installing-specific-package-versions-with-pip", "Language": "Python", "Q_Title": "Installing specific package versions with pip", "Q_Votes": "871", "Q_Content": "    I'm trying to install version 1.2.2 of the MySQL_python adaptor, using a fresh virtualenv created with the --no-site-packages option. The current version shown in PyPi is 1.2.3. Is there a way to install the older version? I found an article stating that this should do it:  pip install MySQL_python==1.2.2   When installed, however, it still shows MySQL_python-1.2.3-py2.6.egg-info in the site packages. Is this a problem specific to this package, or am I doing something wrong?     ", "Tags": ["python", "mysql", "pip", "pypi", "mysql-python"], "A_Votes": "35", "A_Content": "  I believe that if you already have a package it installed, pip will not overwrite it with another version.  Use -I to ignore previous versions.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5226311/installing-specific-package-versions-with-pip", "Language": "Python", "Q_Title": "Installing specific package versions with pip", "Q_Votes": "871", "Q_Content": "    I'm trying to install version 1.2.2 of the MySQL_python adaptor, using a fresh virtualenv created with the --no-site-packages option. The current version shown in PyPi is 1.2.3. Is there a way to install the older version? I found an article stating that this should do it:  pip install MySQL_python==1.2.2   When installed, however, it still shows MySQL_python-1.2.3-py2.6.egg-info in the site packages. Is this a problem specific to this package, or am I doing something wrong?     ", "Tags": ["python", "mysql", "pip", "pypi", "mysql-python"], "A_Votes": "23", "A_Content": "  To install a specific python package version whether it is the first time, an upgrade or a downgrade use:   pip install --force-reinstall MySQL_python==1.2.4   MySQL_python version 1.2.2 is not available so I used a different version. To view all available package versions from an index exclude the version:    pip install MySQL_python==      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5226311/installing-specific-package-versions-with-pip", "Language": "Python", "Q_Title": "Installing specific package versions with pip", "Q_Votes": "871", "Q_Content": "    I'm trying to install version 1.2.2 of the MySQL_python adaptor, using a fresh virtualenv created with the --no-site-packages option. The current version shown in PyPi is 1.2.3. Is there a way to install the older version? I found an article stating that this should do it:  pip install MySQL_python==1.2.2   When installed, however, it still shows MySQL_python-1.2.3-py2.6.egg-info in the site packages. Is this a problem specific to this package, or am I doing something wrong?     ", "Tags": ["python", "mysql", "pip", "pypi", "mysql-python"], "A_Votes": "0", "A_Content": "  Since this appeared to be a breaking change introduced in version 10 of pip, I downgraded to a compatible version:  pip install 'pip<10'    This command tells pip to install a version of the module lower than version 10. Do this in a virutalenv so you don't screw up your site installation of Python.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/54867/what-is-the-difference-between-old-style-and-new-style-classes-in-python", "Language": "Python", "Q_Title": "What is the difference between old style and new style classes in Python?", "Q_Votes": "862", "Q_Content": "    What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?     ", "Tags": ["python", "class", "oop", "types", "new-style-class"], "A_Votes": "491", "A_Content": "  From http://docs.python.org/2/reference/datamodel.html#new-style-and-classic-classes :     Up to Python 2.1, old-style classes were the only flavour available to the user.      The concept of (old-style) class is unrelated to the concept of type:   if x is an instance of an old-style class, then x.__class__   designates the class of x, but type(x) is always <type   'instance'>.       This reflects the fact that all old-style instances, independently of   their class, are implemented with a single built-in type, called   instance.      New-style classes were introduced in Python 2.2 to unify the concepts of class and type.    A new-style class is simply a user-defined type, no more, no less.      If x is an instance of a new-style class, then type(x) is typically   the same as x.__class__ (although this is not guaranteed \u2013 a   new-style class instance is permitted to override the value returned   for x.__class__).      The major motivation for introducing new-style classes is to provide a unified object model with a full meta-model.       It also has a number of immediate benefits, like the ability to   subclass most built-in types, or the introduction of \"descriptors\",   which enable computed properties.      For compatibility reasons, classes are still old-style by default.       New-style classes are created by specifying another new-style class   (i.e. a type) as a parent class, or the \"top-level type\" object if no   other parent is needed.       The behaviour of new-style classes differs from that of old-style   classes in a number of important details in addition to what type   returns.       Some of these changes are fundamental to the new object model, like   the way special methods are invoked. Others are \"fixes\" that could not   be implemented before for compatibility concerns, like the method   resolution order in case of multiple inheritance.      Python 3 only has new-style classes.       No matter if you subclass from object or not, classes are new-style   in Python 3.      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/54867/what-is-the-difference-between-old-style-and-new-style-classes-in-python", "Language": "Python", "Q_Title": "What is the difference between old style and new style classes in Python?", "Q_Votes": "862", "Q_Content": "    What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?     ", "Tags": ["python", "class", "oop", "types", "new-style-class"], "A_Votes": "283", "A_Content": "  Declaration-wise:  New-style classes inherit from object, or from another new-style class.  class NewStyleClass(object):     pass  class AnotherNewStyleClass(NewStyleClass):     pass   Old-style classes don't.  class OldStyleClass():     pass      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/54867/what-is-the-difference-between-old-style-and-new-style-classes-in-python", "Language": "Python", "Q_Title": "What is the difference between old style and new style classes in Python?", "Q_Votes": "862", "Q_Content": "    What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?     ", "Tags": ["python", "class", "oop", "types", "new-style-class"], "A_Votes": "195", "A_Content": "  Important behavior changes between old and new style classes   super added MRO changed (explained below) descriptors added new style class objects cannot be raised unless derived from Exception (example below) __slots__ added   MRO (Method Resolution Order) changed  It was mentioned in other answers, but here goes a concrete example of the difference between classic MRO and C3 MRO (used in new style classes).  The question is the order in which attributes (which include methods and member variables) are searched for in multiple inheritance.  Classic classes do a depth first search from left to right. Stop on first match. They do not have the __mro__ attribute.  class C: i = 0 class C1(C): pass class C2(C): i = 2 class C12(C1, C2): pass class C21(C2, C1): pass  assert C12().i == 0 assert C21().i == 2  try:     C12.__mro__ except AttributeError:     pass else:     assert False   New-style classes MRO is more complicated to synthesize in a single English sentence. It is explained in detail here. One of its properties is that a Base class is only searched for once all its Derived classes have been. They have the __mro__ attribute which shows the search order.   class C(object): i = 0 class C1(C): pass class C2(C): i = 2 class C12(C1, C2): pass class C21(C2, C1): pass  assert C12().i == 2 assert C21().i == 2  assert C12.__mro__ == (C12, C1, C2, C, object) assert C21.__mro__ == (C21, C2, C1, C, object)   New style class objects cannot be raised unless derived from Exception  Around Python 2.5 many classes could be raised, around Python 2.6 this was removed. On Python 2.7.3:  # OK, old: class Old: pass try:     raise Old() except Old:     pass else:     assert False  # TypeError, new not derived from `Exception`. class New(object): pass try:     raise New() except TypeError:     pass else:     assert False  # OK, derived from `Exception`. class New(Exception): pass try:     raise New() except New:     pass else:     assert False  # `'str'` is a new style object, so you can't raise it: try:     raise 'str' except TypeError:     pass else:     assert False      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/54867/what-is-the-difference-between-old-style-and-new-style-classes-in-python", "Language": "Python", "Q_Title": "What is the difference between old style and new style classes in Python?", "Q_Votes": "862", "Q_Content": "    What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?     ", "Tags": ["python", "class", "oop", "types", "new-style-class"], "A_Votes": "35", "A_Content": "  Old style classes are still marginally faster for attribute lookup. This is not usually important, but may be useful in performance-sensitive Python 2.x code:   In [3]: class A:    ...:     def __init__(self):    ...:         self.a = 'hi there'    ...:   In [4]: class B(object):    ...:     def __init__(self):    ...:         self.a = 'hi there'    ...:   In [6]: aobj = A() In [7]: bobj = B()  In [8]: %timeit aobj.a 10000000 loops, best of 3: 78.7 ns per loop  In [10]: %timeit bobj.a 10000000 loops, best of 3: 86.9 ns per loop      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/54867/what-is-the-difference-between-old-style-and-new-style-classes-in-python", "Language": "Python", "Q_Title": "What is the difference between old style and new style classes in Python?", "Q_Votes": "862", "Q_Content": "    What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?     ", "Tags": ["python", "class", "oop", "types", "new-style-class"], "A_Votes": "30", "A_Content": "  Guido has written The Inside Story on New-Style Classes, a really great article about new-style and old-style class in Python.  Python 3 has only new-style class, even if you write an 'old-style class', it is implicitly derived from object.  New-style classes have some advanced features lacking in old-style classes, such as super and the new C3 mro, some magical methods, etc.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/54867/what-is-the-difference-between-old-style-and-new-style-classes-in-python", "Language": "Python", "Q_Title": "What is the difference between old style and new style classes in Python?", "Q_Votes": "862", "Q_Content": "    What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?     ", "Tags": ["python", "class", "oop", "types", "new-style-class"], "A_Votes": "17", "A_Content": "  Here's a very practical, True/False difference. The only difference between the two versions of the following code is that in the second version Person inherits from object. Other than that the two versions are identical, but with different results :  1) old-style classes  class Person():     _names_cache = {}     def __init__(self,name):         self.name = name     def __new__(cls,name):         return cls._names_cache.setdefault(name,object.__new__(cls,name))  ahmed1 = Person(\"Ahmed\") ahmed2 = Person(\"Ahmed\") print ahmed1 is ahmed2 print ahmed1 print ahmed2   >>> False <__main__.Person instance at 0xb74acf8c> <__main__.Person instance at 0xb74ac6cc> >>>   2) new-style classes   class Person(object):     _names_cache = {}     def __init__(self,name):         self.name = name     def __new__(cls,name):         return cls._names_cache.setdefault(name,object.__new__(cls,name))  ahmed1 = Person(\"Ahmed\") ahmed2 = Person(\"Ahmed\") print ahmed2 is ahmed1 print ahmed1 print ahmed2  >>> True <__main__.Person object at 0xb74ac66c> <__main__.Person object at 0xb74ac66c> >>>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/54867/what-is-the-difference-between-old-style-and-new-style-classes-in-python", "Language": "Python", "Q_Title": "What is the difference between old style and new style classes in Python?", "Q_Votes": "862", "Q_Content": "    What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?     ", "Tags": ["python", "class", "oop", "types", "new-style-class"], "A_Votes": "7", "A_Content": "  New-style classes inherit from object and must be written as such in Python 2.2 onwards (i.e. class Classname(object): instead of class Classname:). The core change is to unify types and classes, and the nice side-effect of this is that it allows you to inherit from built-in types.  Read descrintro for more details.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/54867/what-is-the-difference-between-old-style-and-new-style-classes-in-python", "Language": "Python", "Q_Title": "What is the difference between old style and new style classes in Python?", "Q_Votes": "862", "Q_Content": "    What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?     ", "Tags": ["python", "class", "oop", "types", "new-style-class"], "A_Votes": "4", "A_Content": "  New style classes may use super(Foo, self) where Foo is a class and self is the instance.     super(type[, object-or-type])      Return a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing inherited methods that have been overridden in a class. The search order is same as that used by getattr() except that the type itself is skipped.   And in Python 3.x you can simply use super() inside a class with no parameters.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/54867/what-is-the-difference-between-old-style-and-new-style-classes-in-python", "Language": "Python", "Q_Title": "What is the difference between old style and new style classes in Python?", "Q_Votes": "862", "Q_Content": "    What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?     ", "Tags": ["python", "class", "oop", "types", "new-style-class"], "A_Votes": "3", "A_Content": "  Or rather, you should always use new-style classes, unless you have code that needs to work with versions of Python older than 2.2.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "896", "A_Content": "  Apart from tuples being immutable there is also a semantic distinction that should guide their usage. Tuples are heterogeneous data structures (i.e., their entries have different meanings), while lists are homogeneous sequences. Tuples have structure, lists have order.   Using this distinction makes code more explicit and understandable.  One example would be pairs of page and line number to reference locations in a book, e.g.:  my_location = (42, 11)  # page number, line number   You can then use this as a key in a dictionary to store notes on locations. A list on the other hand could be used to store multiple locations. Naturally one might want to add or remove locations from the list, so it makes sense that lists are mutable. On the other hand it doesn't make sense to add or remove items from an existing location - hence tuples are immutable.  There might be situations where you want to change items within an existing location tuple, for example when iterating through the lines of a page. But tuple immutability forces you to create a new location tuple for each new value. This seems inconvenient on the face of it, but using immutable data like this is a cornerstone of value types and functional programming techniques, which can have substantial advantages.  There are some interesting articles on this issue, e.g. \"Python Tuples are Not Just Constant Lists\" or \"Understanding tuples vs. lists in Python\". The official Python documentation also mentions this     \"Tuples are immutable, and usually contain an heterogeneous sequence ...\".   In a statically typed language like Haskell the values in a tuple generally have different types and the length of the tuple must be fixed. In a list the values all have the same type and the length is not fixed. So the difference is very obvious.  Finally there is the namedtuple in Python, which makes sense because a tuple is already supposed to have structure. This underlines the idea that tuples are a light-weight alternative to classes and instances.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "304", "A_Content": "  Difference between list and tuple   Literal  someTuple = (1,2) someList  = [1,2]   Size  a = tuple(range(1000)) b = list(range(1000))  a.__sizeof__() # 8024 b.__sizeof__() # 9088   Due to the smaller size of a tuple operation, it becomes a bit faster, but not that much to mention about until you have a huge number of elements. Permitted operations  b    = [1,2]    b[0] = 3       # [3, 2]  a    = (1,2) a[0] = 3       # Error   That also means that you can't delete an element or sort a tuple.  However, you could add new element to both list and tuple with the only difference that you will change id of the tuple by adding element  a     = (1,2) b     = [1,2]    id(a)          # 140230916716520 id(b)          # 748527696  a   += (3,)    # (1, 2, 3) b   += [3]     # [1, 2, 3]  id(a)          # 140230916878160 id(b)          # 748527696  Usage  As a list is mutable, it can't be used as a key in a dictionary, whereas a tuple can be used.  a    = (1,2) b    = [1,2]   c = {a: 1}     # OK c = {b: 1}     # Error       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "178", "A_Content": "  If you went for a walk, you could note your coordinates at any instant in an (x,y) tuple.  If you wanted to record your journey, you could append your location every few seconds to a list.  But you couldn't do it the other way around.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "71", "A_Content": "  The key difference is that tuples are immutable.  This means that you cannot change the values in a tuple once you have created it.  So if you're going to need to change the values use a List.  Benefits to tuples:   Slight performance improvement. As a tuple is immutable it can be used as a key in a dictionary. If you can't change it neither can anyone else, which is to say you don't need to worry about any API functions etc. changing your tuple without being asked.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "30", "A_Content": "  Lists are mutable; tuples are not.  From docs.python.org/2/tutorial/datastructures.html      Tuples are immutable, and usually contain an heterogeneous sequence of   elements that are accessed via unpacking (see later in this section)   or indexing (or even by attribute in the case of namedtuples). Lists   are mutable, and their elements are usually homogeneous and are   accessed by iterating over the list.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "18", "A_Content": "  Lists are for looping, tuples are for structures i.e. \"%s %s\" %tuple.  Lists are usually homogeneous, tuples are usually heterogeneous.   Lists are for variable length, tuples are for fixed length.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "17", "A_Content": "  It's been mentioned that the difference is largely semantic: people expect a tuple and list to represent different information. But this goes further than a guideline; some libraries actually behave differently based on what they are passed. Take NumPy for example (copied from another post where I ask for more examples):  >>> import numpy as np >>> a = np.arange(9).reshape(3,3) >>> a array([[0, 1, 2],        [3, 4, 5],        [6, 7, 8]]) >>> idx = (1,1) >>> a[idx] 4 >>> idx = [1,1] >>> a[idx] array([[3, 4, 5],        [3, 4, 5]])   The point is, while NumPy may not be part of the standard library, it's a major Python library, and within NumPy lists and tuples are completely different things.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "12", "A_Content": "  This is an example of Python lists:  my_list = [0,1,2,3,4] top_rock_list = [\"Bohemian Rhapsody\",\"Kashmir\",\"Sweet Emotion\", \"Fortunate Son\"]   This is an example of Python tuple:  my_tuple = (a,b,c,d,e) celebrity_tuple = (\"John\", \"Wayne\", 90210, \"Actor\", \"Male\", \"Dead\")   Python lists and tuples are similar in that they both are ordered collections of values. Besides the shallow difference that lists are created using brackets \"[ ... , ... ]\" and tuples using parentheses \"( ... , ... )\", the core technical \"hard coded in Python syntax\" difference between them is that the elements of a particular tuple are immutable whereas lists are mutable (...so only tuples are hashable and can be used as dictionary/hash keys!). This gives rise to differences in how they can or can't be used (enforced a priori by syntax) and differences in how people choose to use them (encouraged as 'best practices,' a posteriori, this is what smart programers do). The main difference a posteriori in differentiating when tuples are used versus when lists are used lies in what meaning people give to the order of elements.   For tuples, 'order' signifies nothing more than just a specific 'structure' for holding information. What values are found in the first field can easily be switched into the second field as each provides values across two different dimensions or scales. They provide answers to different types of questions and are typically of the form: for a given object/subject, what are its attributes? The object/subject stays constant, the attributes differ.  For lists, 'order' signifies a sequence or a directionality. The second element MUST come after the first element because it's positioned in the 2nd place based on a particular and common scale or dimension. The elements are taken as a whole and mostly provide answers to a single question typically of the form, for a given attribute, how do these objects/subjects compare? The attribute stays constant, the object/subject differs.  There are countless examples of people in popular culture and programmers who don't conform to these differences and there are countless people who might use a salad fork for their main course. At the end of the day, it's fine and both can usually get the job done.   To summarize some of the finer details  Similarities:   Duplicates - Both tuples and lists allow for duplicates Indexing, Selecting, & Slicing - Both tuples and lists index using integer values found within brackets. So, if you want the first 3 values of a given list or tuple, the syntax would be the same:  >>> my_list[0:3] [0,1,2] >>> my_tuple[0:3] [a,b,c]  Comparing & Sorting - Two tuples or two lists are both compared by their first element, and if there is a tie, then by the second element, and so on. No further attention is paid to subsequent elements after earlier elements show a difference.  >>> [0,2,0,0,0,0]>[0,0,0,0,0,500] True >>> (0,2,0,0,0,0)>(0,0,0,0,0,500) True    Differences: - A priori, by definition   Syntax - Lists use [], tuples use () Mutability - Elements in a given list are mutable, elements in a given tuple are NOT mutable.   # Lists are mutable: >>> top_rock_list ['Bohemian Rhapsody', 'Kashmir', 'Sweet Emotion', 'Fortunate Son'] >>> top_rock_list[1] 'Kashmir' >>> top_rock_list[1] = \"Stairway to Heaven\" >>> top_rock_list ['Bohemian Rhapsody', 'Stairway to Heaven', 'Sweet Emotion', 'Fortunate Son']  # Tuples are NOT mutable:        >>> celebrity_tuple ('John', 'Wayne', 90210, 'Actor', 'Male', 'Dead') >>> celebrity_tuple[5] 'Dead' >>> celebrity_tuple[5]=\"Alive\" Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: 'tuple' object does not support item assignment  Hashtables (Dictionaries) - As hashtables (dictionaries) require that its keys are hashable and therefore immutable, only tuples can act as dictionary keys, not lists.  #Lists CAN'T act as keys for hashtables(dictionaries) >>> my_dict = {[a,b,c]:\"some value\"} Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: unhashable type: 'list'  #Tuples CAN act as keys for hashtables(dictionaries) >>> my_dict = {(\"John\",\"Wayne\"): 90210} >>> my_dict {('John', 'Wayne'): 90210}    Differences - A posteriori, in usage   Homo vs. Heterogeneity of Elements - Generally list objects are homogenous and tuple objects are heterogeneous. That is, lists are used for objects/subjects of the same type (like all presidential candidates, or all songs, or all runners) whereas  although it's not forced by), whereas tuples are more for heterogenous objects. Looping vs. Structures - Although both allow for looping (for x in my_list...), it only really makes sense to do it for a list. Tuples are more appropriate for structuring and presenting information (%s %s residing in %s is an %s and presently %s % (\"John\",\"Wayne\",90210, \"Actor\",\"Dead\"))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "8", "A_Content": "  The values of list can be changed any time but the values of tuples can't be change.  The advantages and disadvantages depends upon the use. If you have such a data which you never want to change then you should have to use tuple, otherwise list is the best option.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "5", "A_Content": "  Lists are intended to be homogeneous sequences, while tuples are heterogeneous data structures.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "2", "A_Content": "  The PEP 484 -- Type Hints says that the types of elements of a tuple can be individually typed; so that you can say Tuple[str, int, float]; but a list, with List typing class can take only one type parameter: List[str], which hints that the difference of the 2 really is that the former is heterogeneous, whereas the latter intrinsically homogeneous.  Also, the standard library mostly uses the tuple as a return value from such standard functions where the C would return a struct.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "2", "A_Content": "  Difference between list and tuple  Tuples and lists are both seemingly similar sequence types in Python.   Literal syntax  We use parenthesis () to construct tuples and square brackets [ ] to get a new list. Also, we can use call of the appropriate type to get required structure\u200a\u2014\u200atuple or list.  someTuple = (4,6) someList  = [2,6]   Mutability   Tuples are immutable, while lists are mutable. This point is the base the for the following ones.  Memory usage   Due to mutability, you need more memory for lists and less memory for tuples. Extending   You can add a new element to both tuples and lists with the only difference that the id of the tuple will be changed (i.e., we\u2019ll have a new object). Hashing   Tuples are hashable and lists are not. It means that you can use a tuple as a key in a dictionary. The list can't be used as a key in a dictionary, whereas a tuple can be used  tup      = (1,2) list_    = [1,2]   c = {tup   : 1}     # ok c = {list_ : 1}     # error  Semantics   This point is more about best practice. You should use tuples as heterogeneous data structures, while lists are homogenous sequences.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "1", "A_Content": "  First of all, they both are the non-scalar objects (also known as a compound objects) in Python.   Tuples, ordered sequence of elements (which can contain any object with no aliasing issue)   Immutable (tuple, int, float, str) Concatenation using + (brand new tuple will be created of course) Indexing Slicing Singleton (3,) # -> (3) instead of (3) # -> 3  List (Array in other languages), ordered sequence of values   Mutable Singleton [3] Cloning new_array = origin_array[:] List comprehension [x**2 for x in range(1,7)] gives you [1,4,9,16,25,36] (Not readable)    Using list may also cause an aliasing bug (two distinct paths pointing to the same object).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "1", "A_Content": "  A direction quotation from the documentation on 5.3. Tuples and Sequences:     Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples are immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later in this section) or indexing (or even by attribute in the case of namedtuples). Lists are mutable, and their elements are usually homogeneous and are accessed by iterating over the list.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "1", "A_Content": "  As people have already answered here that tuples are immutable while lists are mutable, but there is one important aspect of using tuples which we must remember  If the tuple contains a list or a dictionary inside it, those can be changed even if the tuple itself is immutable.  For example, let's assume we have a tuple which contains a list and a dictionary as  my_tuple = (10,20,30,[40,50],{ 'a' : 10})   we can change the contents of the list as  my_tuple[3][0] = 400 my_tuple[3][1] = 500   which makes new tuple looks like  (10, 20, 30, [400, 500], {'a': 10})   we can also change the dictionary inside tuple as   my_tuple[4]['a'] = 500   which will make the overall tuple looks like  (10, 20, 30, [400, 500], {'a': 500})   This happens because list and dictionary are the objects and these objects are not changing, but the contents its pointing to.  So the tuple remains immutable without any exception     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "904", "A_Content": "  Are you talking about lambda functions? Like  lambda x: x**2 + 2*x - 5   Those things are actually quite useful.  Python supports a style of programming called functional programming where you can pass functions to other functions to do stuff. Example:  mult3 = filter(lambda x: x % 3 == 0, [1, 2, 3, 4, 5, 6, 7, 8, 9])   sets mult3 to [3, 6, 9], those elements of the original list that are multiples of 3. This is shorter (and, one could argue, clearer) than  def filterfunc(x):     return x % 3 == 0 mult3 = filter(filterfunc, [1, 2, 3, 4, 5, 6, 7, 8, 9])   Of course, in this particular case, you could do the same thing as a list comprehension:  mult3 = [x for x in [1, 2, 3, 4, 5, 6, 7, 8, 9] if x % 3 == 0]   (or even as range(3,10,3)), but there are many other, more sophisticated use cases where you can't use a list comprehension and a lambda function may be the shortest way to write something out.   Returning a function from another function  >>> def transform(n): ...     return lambda x: x + n ... >>> f = transform(3) >>> f(4) 7   This is often used to create function wrappers, such as Python's decorators. Combining elements of an iterable sequence with reduce()  >>> reduce(lambda a, b: '{}, {}'.format(a, b), [1, 2, 3, 4, 5, 6, 7, 8, 9]) '1, 2, 3, 4, 5, 6, 7, 8, 9'  Sorting by an alternate key  >>> sorted([1, 2, 3, 4, 5, 6, 7, 8, 9], key=lambda x: abs(5-x)) [5, 4, 6, 3, 7, 2, 8, 1, 9]    I use lambda functions on a regular basis. It took me a while to get used to them, but eventually I came to understand that they're a very valuable part of the language.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "0", "A_Content": "  Lists are mutable and tuples are immutable. Just consider this example.  a = [\"1\", \"2\", \"ra\", \"sa\"]    #list b = (\"1\", \"2\", \"ra\", \"sa\")    #tuple   Now change index values of list and tuple.  a[2] = 1000 print a     #output : ['1', '2', 1000, 'sa'] b[2] = 1000 print b     #output : TypeError: 'tuple' object does not support item assignment.   Hence proved the following code is invalid with tuple, because we attempted to update a tuple, which is not allowed.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "-1", "A_Content": "  List is mutable and tuples is immutable. The main difference between mutable and immutable is memory usage when you are trying to append an item.   When you create a variable, some fixed memory is assigned to the variable. If it is a list, more memory is assigned than actually used. E.g. if current memory assignment is 100 bytes, when you want to append the 101th byte, maybe another 100 bytes will be assigned (in total 200 bytes in this case).   However, if you know that you are not frequently add new elements, then you should use tuples. Tuples assigns exactly size of the memory needed, and hence saves memory, especially when you use large blocks of memory.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/626759/whats-the-difference-between-lists-and-tuples", "Language": "Python", "Q_Title": "What's the difference between lists and tuples?", "Q_Votes": "857", "Q_Content": "    What's the difference?  What are the advantages / disadvantages of tuples / lists?     ", "Tags": ["python", "list", "tuples"], "A_Votes": "-1", "A_Content": "  The basic difference that I have found is that lists are mutable where as tuples are immutable. Tuples are good for computations in which they need not be changed.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "330", "A_Content": "  lambda is just a fancy way of saying function. Other than its name, there is nothing obscure, intimidating or cryptic about it. When you read the following line, replace lambda by function in your mind:  >>> f = lambda x: x + 1 >>> f(3) 4   It just defines a function of x. Some other languages, like R, say it explicitly:  > f = function(x) { x + 1 } > f(3) 4   You see? It's one of the most natural things to do in programming.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "96", "A_Content": "  The two-line summary:   Closures: Very useful.  Learn them, use them, love them. Python's lambda keyword: unnecessary, occasionally useful.  If you find yourself doing anything remotely complex with it, put it away and define a real function.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "71", "A_Content": "  A lambda is part of a very important abstraction mechanism which deals with higher order functions. To get proper understanding of its value, please watch high quality lessons from Abelson and Sussman, and read the book SICP  These are relevant issues in modern software business, and becoming ever more popular.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "57", "A_Content": "  I doubt lambda will go away. See Guido's post about finally giving up trying to remove it. Also see an outline of the conflict.  You might check out this post for more of a history about the deal behind Python's functional features: http://python-history.blogspot.com/2009/04/origins-of-pythons-functional-features.html     Curiously, the map, filter, and reduce functions that originally motivated the introduction of lambda and other functional features have to a large extent been superseded by list comprehensions and generator expressions. In fact, the reduce function was removed from list of builtin functions in Python 3.0. (However, it's not necessary to send in complaints about the removal of lambda, map or filter: they are staying. :-)   My own two cents: Rarely is lambda worth it as far as clarity goes. Generally there is a more clear solution that doesn't include lambda.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "56", "A_Content": "  lambdas are extremely useful in GUI programming. For example, lets say you're creating a group of buttons and you want to use a single paramaterized callback rather than a unique callback per button. Lambda lets you accomplish that with ease:  for value in [\"one\",\"two\",\"three\"]:     b = tk.Button(label=value, command=lambda arg=value: my_callback(arg))     b.pack()   (Note: although this question is specifically asking about lambda, you can also use functools.partial to get the same type of result)  The alternative is to create a separate callback for each button which can lead to duplicated code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "31", "A_Content": "  In Python, lambda is just a way of defining functions inline,  a = lambda x: x + 1 print a(1)   and..  def a(x): return x + 1 print a(1)   ..are the exact same.  There is nothing you can do with lambda which you cannot do with a regular function\u2014in Python functions are an object just like anything else, and lambdas simply define a function:  >>> a = lambda x: x + 1 >>> type(a) <type 'function'>   I honestly think the lambda keyword is redundant in Python\u2014I have never had the need to use them (or seen one used where a regular function, a list-comprehension or one of the many builtin functions could have been better used instead)  For a completely random example, from the article \"Python\u2019s lambda is broken!\":     To see how lambda is broken, try generating a list of functions fs=[f0,...,f9] where fi(n)=i+n. First attempt:  >>> fs = [(lambda n: i + n) for i in range(10)] >>> fs[3](4) 13    I would argue, even if that did work, it's horribly and \"unpythonic\", the same functionality could be written in countless other ways, for example:  >>> n = 4 >>> [i + n for i in range(10)] [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]   Yes, it's not the same, but I have never seen a cause where generating a group of lambda functions in a list has been required. It might make sense in other languages, but Python is not Haskell (or Lisp, or ...)     Please note that we can use lambda and still achieve the desired   results in this way :  >>> fs = [(lambda n,i=i: i + n) for i in range(10)] >>> fs[3](4) 7    Edit:  There are a few cases where lambda is useful, for example it's often convenient when connecting up signals in PyQt applications, like this:  w = PyQt4.QtGui.QLineEdit() w.textChanged.connect(lambda event: dothing())   Just doing w.textChanged.connect(dothing) would call the dothing method with an extra event argument and cause an error. Using the lambda means we can tidily drop the argument without having to define a wrapping function.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "28", "A_Content": "  I find lambda useful for a list of functions that do the same, but for different circumstances. Like the Mozilla plural rules.  plural_rules = [     lambda n: 'all',     lambda n: 'singular' if n == 1 else 'plural',     lambda n: 'singular' if 0 <= n <= 1 else 'plural',     ... ] # Call plural rule #1 with argument 4 to find out which sentence form to use. plural_rule[1](4) # returns 'plural'   If you'd have to define a function for all of those you'd go mad by the end of it. Also it wouldn't be nice with function names like plural_rule_1, plural_rule_2, etc. And you'd need to eval() it when you're depending on a variable function id.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "26", "A_Content": "  Pretty much anything you can do with lambda you can do better with either named functions or list and generator expressions.  Consequently, for the most part you should just one of those in basically any situation (except maybe for scratch code written in the interactive interpreter).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "19", "A_Content": "  I've been using Python for a few years and I've never run in to a case where I've needed lambda. Really, as the tutorial states, it's just for syntactic sugar.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "16", "A_Content": "  I can't speak to python's particular implementation of lambda, but in general lambda functions are really handy.  They're a core technique (maybe even THE technique) of functional programming, and they're also very useuful in object-oriented programs.  For certain types of problems, they're the best solution, so certainly shouldn't be forgotten!  I suggest you read up on closures and the map function (that links to python docs, but it exists in nearly every language that supports functional constructs) to see why it's useful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "16", "A_Content": "  Lambda function it's a non-bureaucratic way to create a function.  That's it. For example, let's supose you have your main function and need to square values. Let's see the traditional way and the lambda way to do this:  Traditional way:  def main(): ... ... y = square(some_number) ... return something  def square(x):     return x**2   The lambda way:  def main(): ... square = lambda x: x**2 y = square(some_number) return something   See the difference?  Lambda functions go very well with lists, like lists comprehensions or map. In fact, list comprehension it's a \"pythonic\" way to express yourself using lambda. Ex:  >>>a = [1,2,3,4] >>>[x**2 for x in a] [1,4,9,16]   Let's see what each elements of the syntax means:     [] : \"Give me a list\"      x**2 : \"using this new-born function\"      for x in a: \"into each element in a\"   That's convenient uh? Creating functions like this. Let's rewrite it using lambda:  >>> square = lambda x: x**2 >>> [square(s) for x in a] [1,4,9,16]   Now let's use map, which is the same thing, but more language-neutral. Maps takes 2 arguments:   (i) one function  (ii) an iterable  And gives you a list where each element it's the function applied to each element of the iterable.  So, using map we would have:  >>> a = [1,2,3,4] >>> squared_list = map(lambda x: x**2, a)   If you master lambdas and mapping, you will have a great power to manipulate data and in a concise way. Lambda functions are neither obscure nor take away code clarity. Don't confuse something hard with something new. Once you start using them, you will find it very clear.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "13", "A_Content": "  One of the nice things about lambda that's in my opinion understated is that it's way of deferring an evaluation for simple forms till the value is needed. Let me explain.   Many library routines are implemented so that they allow certain parameters to be callables (of whom lambda is one). The idea is that the actual value will be computed only at the time when it's going to be used (rather that when it's called). An (contrived) example might help to illustrate the point. Suppose you have a routine which which was going to do log a given timestamp. You want the routine to use the current time minus 30 minutes. You'd call it like so  log_timestamp(datetime.datetime.now() - datetime.timedelta(minutes = 30))   Now suppose the actual function is going to be called only when a certain event occurs and you want the timestamp to be computed only at that time. You can do this like so  log_timestamp(lambda : datetime.datetime.now() - datetime.timedelta(minutes = 30))   Assuming the log_timestamp can handle callables like this, it will evaluate this when it needs it and you'll get the timestamp at that time.   There are of course alternate ways to do this (using the operator module for example) but I hope I've conveyed the point.   Update: Here is a slightly more concrete real world example.   Update 2: I think this is an example of what is called a thunk.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "11", "A_Content": "  As stated above, the lambda operator in Python defines an anonymous function, and in Python functions are closures. It is important not to confuse the concept of closures with the operator lambda, which is merely syntactic methadone for them.  When I started in Python a few years ago, I used lambdas a lot, thinking they were cool, along with list comprehensions. However, I wrote and have to maintain a big website written in Python, with on the order of several thousand function points. I've learnt from experience that lambdas might be OK to prototype things with, but offer nothing over inline functions (named closures) except for saving a few key-stokes, or sometimes not.  Basically this boils down to several points:   it is easier to read software that is explicitly written using meaningful names. Anonymous closures by definition cannot have a meaningful name, as they have no name. This brevity seems, for some reason, to also infect lambda parameters, hence we often see examples like lambda x: x+1  it is easier to reuse named closures, as they can be referred to by name more than once, when there is a name to refer to them by. it is easier to debug code that is using named closures instead of lambdas, because the name will appear in tracebacks, and around the error.   That's enough reason to round them up and convert them to named closures. However, I hold two other grudges against anonymous closures.  The first grudge is simply that they are just another unnecessary keyword cluttering up the language.  The second grudge is deeper and on the paradigm level, i.e. I do not like that they promote a functional-programming style, because that style is less flexible than the message passing, object oriented or procedural styles, because the lambda calculus is not Turing-complete (luckily in Python, we can still break out of that restriction even inside a lambda). The reasons I feel lambdas promote this style are:   There is an implicit return, i.e. they seem like they 'should' be functions. They are an alternative state-hiding mechanism to another, more explicit, more readable, more reusable and more general mechanism: methods.   I try hard to write lambda-free Python, and remove lambdas on sight. I think Python would be a slightly better language without lambdas, but that's just my opinion.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "11", "A_Content": "  Lambdas are actually very powerful constructs that stem from ideas in functional programming, and it is something that by no means will be easily revised, redefined or removed in the near future of Python. They help you write code that is more powerful as it allows you to pass functions as parameters, thus the idea of functions as first-class citizens.  Lambdas do tend to get confusing, but once a solid understanding is obtained, you can write clean elegant code like this:  squared = map(lambda x: x*x, [1, 2, 3, 4, 5])   The above line of code returns a list of the squares of the numbers in the list. Ofcourse, you could also do it like:  def square(x):     return x*x  squared = map(square, [1, 2, 3, 4, 5])   It is obvious the former code is shorter, and this is especially true if you intend to use the map function (or any similar function that takes a function as a parameter) in only one place. This also makes the code more intuitive and elegant.   Also, as @David Zaslavsky mentioned in his answer, list comprehensions are not always the way to go especially if your list has to get values from some obscure mathematical way.  From a more practical standpoint, one of the biggest advantages of lambdas for me recently has been in GUI and event-driven programming. If you take a look at callbacks in Tkinter, all they take as arguments are the event that triggered them. E.g.  def define_bindings(widget):     widget.bind(\"<Button-1>\", do-something-cool)  def do-something-cool(event):     #Your code to execute on the event trigger   Now what if you had some arguments to pass? Something as simple as passing 2 arguments to store the coordinates of a mouse-click. You can easily do it like this:  def main():     # define widgets and other imp stuff     x, y = None, None     widget.bind(\"<Button-1>\", lambda event: do-something-cool(x, y))  def do-something-cool(event, x, y):     x = event.x     y = event.y     #Do other cool stuff   Now you can argue that this can be done using global variables, but do you really want to bang your head worrying about memory management and leakage especially if the global variable will just be used in one particular place? That would be just poor programming style.  In short, lambdas are awesome and should never be underestimated. Python lambdas are not the same as LISP lambdas though (which are more powerful), but you can really do a lot of magical stuff with them.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "1064", "A_Content": "  This information is available in the sys.version string in the sys module:  >>> import sys   Human readable:  >>> print (sys.version) #parentheses necessary in python 3.        2.5.2 (r252:60911, Jul 31 2008, 17:28:52)  [GCC 4.2.3 (Ubuntu 4.2.3-2ubuntu7)]   For further processing:  >>> sys.version_info (2, 5, 2, 'final', 0) # or >>> sys.hexversion 34014192   To ensure a script runs with a minimal version requirement of the Python interpreter add this to your code:  assert sys.version_info >= (2,5)   This compares major and minor version information. Add micro (=0, 1, etc) and even releaselevel (='alpha','final', etc) to the tuple as you like. Note however, that it is almost always better to \"duck\" check if a certain feature is there, and if not, workaround (or bail out). Sometimes features go away in newer releases, being replaced by others.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "1367", "A_Content": "  You can use triple-quoted strings. When they're not a docstring (first thing in a class/function/module), they are ignored.   ''' This is a multiline comment. '''   (Make sure to indent the leading ''' appropriately to avoid an IndentationError.)  Guido van Rossum (creator of Python) tweeted this as a \"pro tip\".  However, Python's style guide, PEP8, favors using consecutive single-line comments, and this is also what you'll find in many projects. Editors usually have a shortcut to do this easily.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "8", "A_Content": "  Lambdas are deeply linked to functional programming style in general. The idea that you can solve problems by applying a function to some data, and merging the results, is what google uses to implement most of its algorithms.    Programs written in functional programming style, are easily parallelized  and hence are becoming more and more important with modern multi-core machines. So in short, NO you should not forget them.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "6", "A_Content": "  First congrats that managed to figure out lambda. In my opinion this is really powerful construct to act with. The trend these days towards functional programming languages is surely an indicator that it neither should be avoided nor it will be redefined in the near future.  You just have to think a little bit different. I'm sure soon you will love it. But be careful if you deal only with python. Because the lambda is not a real closure, it is \"broken\" somehow: pythons lambda is broken     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "5", "A_Content": "     I'm just beginning Python and ran head first into Lambda- which took me a while to figure out.   Note that this isn't a condemnation of anything.  Everybody has a different set of things that don't come easily.     Is lambda one of those 'interesting' language items that in real life should be forgotten?   No.     I'm sure there are some edge cases where it might be needed, but given the obscurity of it,   It's not obscure.  The past 2 teams I've worked on, everybody used this feature all the time.     the potential of it being redefined in future releases (my assumption based on the various definitions of it)   I've seen no serious proposals to redefine it in Python, beyond fixing the closure semantics a few years ago.     and the reduced coding clarity - should it be avoided?   It's not less clear, if you're using it right.  On the contrary, having more language constructs available increases clarity.     This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values...sort of a techie showmanship but maintenance coder nightmare..   Lambda is like buffer overflow?  Wow.  I can't imagine how you're using lambda if you think it's a \"maintenance nightmare\".     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "5", "A_Content": "  I started reading David Mertz's book today 'Text Processing in Python.' While he has a fairly terse description of Lambda's the examples in the first chapter combined with the explanation in Appendix A made them jump off the page for me (finally) and all of a sudden I understood their value.  That is not to say his explanation will work for you and I am still at the discovery stage so I will not attempt to add to these responses other than the following: I am new to Python I am new to OOP Lambdas were a struggle for me Now that I read Mertz, I think I get them and I see them as very useful as I think they allow a cleaner approach to programming.    He reproduces the Zen of Python, one line of which is Simple is better than complex. As a non-OOP programmer reading code with lambdas (and until last week list comprehensions) I have thought-This is simple?.  I finally realized today that actually these features make the code much more readable, and understandable than the alternative-which is invariably a loop of some sort.  I also realized that like financial statements-Python was not designed for the novice user, rather it is designed for the user that wants to get educated.  I can't believe how powerful this language is.  When it dawned on me (finally) the purpose and value of lambdas I wanted to rip up about 30 programs and start over putting in lambdas where appropriate.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "5", "A_Content": "  A useful case for using lambdas is to improve the readability of long list comprehensions. In this example loop_dic is short for clarity but imagine loop_dic being very long. If you would just use a plain value that includes i instead of the lambda version of that value you would get a NameError.  >>> lis = [{\"name\": \"Peter\"}, {\"name\": \"Josef\"}]  >>> loop_dic = lambda i: {\"name\": i[\"name\"] + \" Wallace\" } >>> new_lis = [loop_dic(i) for i in lis]  >>> new_lis [{'name': 'Peter Wallace'}, {'name': 'Josef Wallace'}]   Instead of   >>> lis = [{\"name\": \"Peter\"}, {\"name\": \"Josef\"}]  >>> new_lis = [{\"name\": i[\"name\"] + \" Wallace\"} for i in lis]  >>> new_lis [{'name': 'Peter Wallace'}, {'name': 'Josef Wallace'}]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "5", "A_Content": "  I use lambdas to avoid code duplication. It would make the function easily comprehensible Eg:  def a_func()   ...   if some_conditon:      ...      call_some_big_func(arg1, arg2, arg3, arg4...)   else      ...      call_some_big_func(arg1, arg2, arg3, arg4...)   I replace that with a temp lambda  def a_func()   ...   call_big_f = lambda args_that_change: call_some_big_func(arg1, arg2, arg3, args_that_change)   if some_conditon:      ...      call_big_f(argX)   else      ...      call_big_f(argY)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "5", "A_Content": "  I'm a python beginner, so to getter a clear idea of lambda I compared it with a 'for' loop; in terms of efficiency. Here's the code (python 2.7) -  import time start = time.time() # Measure the time taken for execution  def first():     squares = map(lambda x: x**2, range(10))     # ^ Lambda     end = time.time()     elapsed = end - start     print elapsed + ' seconds'     return elapsed # gives 0.0 seconds  def second():     lst = []     for i in range(10):         lst.append(i**2)     # ^ a 'for' loop     end = time.time()     elapsed = end - start     print elapsed + ' seconds'     return elapsed # gives 0.0019998550415 seconds.  print abs(second() - first()) # Gives 0.0019998550415 seconds!(duh)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "5", "A_Content": "  I can give you an example where I actually needed lambda serious.  I'm making a graphical program, where the use right clicks on a file and assigns it one of three options.  It turns out that in Tkinter (the GUI interfacing program I'm writing this in), when someone presses a button, it can't be assigned to a command that takes in arguments.  So if I chose one of the options and wanted the result of my choice to be:  print 'hi there'   Then no big deal.  But what if I need my choice to have a particular detail.  For example, if I choose choice A, it calls a function that takes in some argument that is dependent on the choice A, B or C, TKinter could not support this.  Lamda was the only option to get around this actually...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "4", "A_Content": "  I use it quite often, mainly as a null object or to partially bind parameters to a function.  Here are examples:  to implement null object pattern:  {     DATA_PACKET: self.handle_data_packets     NET_PACKET: self.handle_hardware_packets }.get(packet_type, lambda x : None)(payload)   for parameter binding:  let say that I have the following API  def dump_hex(file, var)     # some code     pass  class X(object):     #...     def packet_received(data):         # some kind of preprocessing         self.callback(data)     #...   Then, when I wan't to quickly dump the recieved data to a file I do that:     dump_file = file('hex_dump.txt','w') X.callback = lambda (x): dump_hex(dump_file, x) ... dump_file.close()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "4", "A_Content": "  I use lambda to create callbacks that include parameters. It's cleaner writing a lambda in one line than to write a method to perform the same functionality.  For example:  import imported.module  def func():     return lambda: imported.module.method(\"foo\", \"bar\")   as opposed to:  import imported.module  def func():     def cb():         return imported.module.method(\"foo\", \"bar\")     return cb      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/890128/why-are-python-lambdas-useful", "Language": "Python", "Q_Title": "Why are Python lambdas useful? [closed]", "Q_Votes": "833", "Q_Content": "    I'm trying to figure out Python lambdas.  Is lambda one of those \"interesting\" language items that in real life should be forgotten?   I'm sure there are some edge cases where it might be needed, but given the obscurity of it, the potential of it being redefined in future releases (my assumption based on the various definitions of it) and the reduced coding clarity - should it be avoided?    This reminds me of overflowing (buffer overflow) of C types - pointing to the top variable and overloading to set the other field values.  It feels like sort of a techie showmanship but maintenance coder nightmare.     ", "Tags": ["python", "function", "lambda", "closures"], "A_Votes": "2", "A_Content": "  Lambda is a procedure constructor. You can synthesize programs at run-time, although Python's lambda is not very powerful. Note that few people understand that kind of programming.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "280", "A_Content": "  From the command line (note the capital 'V'):  python -V   This is documented in 'man python'.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "89", "A_Content": "  I like sys.hexversion for stuff like this.  http://docs.python.org/library/sys.html#sys.hexversion  >>> import sys >>> sys.hexversion 33883376 >>> '%x' % sys.hexversion '20504f0' >>> sys.hexversion < 0x02060000 True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "60", "A_Content": "  Your best bet is probably something like so:   >>> import sys >>> sys.version_info (2, 6, 4, 'final', 0) >>> if not sys.version_info[:2] == (2, 6): ...    print \"Error, I need python 2.6\" ... else: ...    from my_module import twoPointSixCode >>>    Additionally, you can always wrap your imports in a simple try, which should catch syntax errors. And, to @Heikki's point, this code will be compatible with much older versions of python:   >>> try: ...     from my_module import twoPointSixCode ... except Exception:  ...     print \"can't import, probably because your python is too old!\" >>>      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "48", "A_Content": "  Use platform's python_version from the stdlib:  >>> from platform import python_version >>> print(python_version()) 2.7.8      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "46", "A_Content": "  Put something like:  #!/usr/bin/env/python import sys if sys.version_info<(2,6,0):   sys.stderr.write(\"You need python 2.6 or later to run this script\\n\")   exit(1)   at the top of your script.  Note that depending on what else is in your script, older versions of python than the target may not be able to even load the script, so won't get far enough to report this error. As a workaround, you can run the above in a script that imports the script with the more modern code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "20", "A_Content": "  Here's a short commandline version which exits straight away (handy for scripts and automated execution):  python -c \"print(__import__('sys').version)\"   Or just the major, minor and micro:  python -c \"print(__import__('sys').version_info[:1])\" # (2,) python -c \"print(__import__('sys').version_info[:2])\" # (2, 7) python -c \"print(__import__('sys').version_info[:3])\" # (2, 7, 6)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "7", "A_Content": "  The simplest way  Just type python in your terminal and you can see the version   as like following   desktop:~$ python Python 2.7.6 (default, Jun 22 2015, 18:00:18)  [GCC 4.8.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>>       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "5", "A_Content": "  import sys sys.version.split(' ')[0]   sys.version gives you what you want, just pick the first number :)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "5", "A_Content": "  Like Seth said, the main script could check sys.version_info (but note that that didn't appear until 2.0, so if you want to support older versions you would need to check another version property of the sys module).  But you still need to take care of not using any Python language features in the file that are not available in older Python versions. For example, this is allowed in Python 2.5 and later:  try:     pass except:     pass finally:     pass   but won't work in older Python versions, because you could only have except OR finally match the try. So for compatibility with older Python versions you need to write:  try:     try:         pass     except:         pass finally:     pass      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "4", "A_Content": "  With six module, you can do it by:  import six  if six.PY2:   # this is python2.x else:   # six.PY3   # this is python3.x      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "3", "A_Content": "  Check Python version: python -V or python --version or apt-cache policy python  you can also run whereis python to see how many versions are installed.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "2", "A_Content": "  To see a MSDOS script to check the version before running the Python interpreter (to avoid Python version syntax exceptions) See solution:  How can I check for Python version in a program that uses new language features?  and   MS script; Python version check prelaunch of Python module http://pastebin.com/aAuJ91FQ (script likely easy to convert to other OS scripts.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "2", "A_Content": "  Several answers already suggest how to query the current python version. To check programmatically the version requirements, I'd make use of one of the following two methods:  # Method 1: (see krawyoti's answer) import sys assert(sys.version_info >= (2,6))  # Method 2:  import platform from distutils.version import StrictVersion  assert(StrictVersion(platform.python_version()) >= \"2.6\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "1", "A_Content": "  Just for fun, the following is a way of doing it on CPython 1.0-3.7b2, Pypy, Jython and Micropython.  This is more of a curiosity than a way of doing it in modern code.  I wrote it as part of http://stromberg.dnsalias.org/~strombrg/pythons/ , which is a script for testing a snippet of code on many versions of python at once, so you can easily get a feel for what python features are compatible with what versions of python:  via_platform = 0 check_sys = 0 via_sys_version_info = 0 via_sys_version = 0 test_sys = 0 try:     import platform except (ImportError, NameError):     # We have no platform module - try to get the info via the sys module     check_sys = 1  if not check_sys:     if hasattr(platform, \"python_version\"):         via_platform = 1     else:         check_sys = 1  if check_sys:     try:         import sys         test_sys = 1     except (ImportError, NameError):         # just let via_sys_version_info and via_sys_version remain False - we have no sys module         pass  if test_sys:     if hasattr(sys, \"version_info\"):         via_sys_version_info = 1     elif hasattr(sys, \"version\"):         via_sys_version = 1     else:         # just let via_sys remain False         pass  if via_platform:     # This gives pretty good info, but is not available in older interpreters.  Also, micropython has a     # platform module that does not really contain anything.     print(platform.python_version()) elif via_sys_version_info:     # This is compatible with some older interpreters, but does not give quite as much info.     print(\"%s.%s.%s\" % sys.version_info[:3]) elif via_sys_version:     import string     # This is compatible with some older interpreters, but does not give quite as much info.     verbose_version = sys.version     version_list = string.split(verbose_version)     print(version_list[0]) else:     print(\"unknown\")      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1093322/how-do-i-check-what-version-of-python-is-running-my-script", "Language": "Python", "Q_Title": "How do I check what version of Python is running my script?", "Q_Votes": "861", "Q_Content": "    How can I check what version of the Python Interpreter is interpreting my script?     ", "Tags": ["python", "version"], "A_Votes": "0", "A_Content": "  If you are working on linux just give command python  output will be like this     Python 2.4.3 (#1, Jun 11 2009, 14:09:37)      [GCC 4.1.2 20080704 (Red Hat 4.1.2-44)] on linux2      Type \"help\", \"copyright\", \"credits\" or \"license\" for more   information.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "63", "A_Content": "  Python does have a multiline string/comment syntax in the sense that unless used as docstrings, multiline strings generate no bytecode -- just like #-prepended comments. In effect, it acts exactly like a comment.   On the other hand, if you say this behavior must be documented in the official docs to be a true comment syntax, then yes, you would be right to say it is not guaranteed as part of the language specification.  In any case your editor should also be able to easily comment-out a selected region (by placing a # in front of each line individually). If not, switch to an editor that does.  Programming in Python without certain text editing features can be a painful experience. Finding the right editor (and knowing how to use it) can make a big difference in how the Python programming experience is perceived.  Not only should the editor be able to comment-out selected regions, it should also be able to shift blocks of code to the left and right easily, and should automatically place the cursor at the current indentation level when you press Enter. Code folding can also be useful.    To protect against link decay, here is the content of Guido van Rossum's tweet:     @BSUCSClub Python tip: You can use multi-line strings as multi-line comments. Unless used as docstrings, they generate no code! :-)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "28", "A_Content": "  In Python 2.7 the multiline comment is:  \"\"\" This is a multilline comment \"\"\"   In case you are inside a class you should tab it properly.  For example:  class weather2():    \"\"\"    def getStatus_code(self, url):        world.url = url        result = requests.get(url)        return result.status_code    \"\"\"   I hope it helps!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "24", "A_Content": "  From the accepted answer...     You can use triple-quoted strings. When they're not a docstring (first thing in a class/function/module), they are ignored.   This is simply not true. Unlike comments, triple-quoted strings are still parsed and must be syntactically valid, regardless of where they appear in the source code.  If you try to run this code...  def parse_token(token):     \"\"\"     This function parses a token.     TODO: write a decent docstring :-)     \"\"\"      if token == '\\\\and':         do_something()      elif token == '\\\\or':         do_something_else()      elif token == '\\\\xor':         '''         Note that we still need to provide support for the deprecated         token \\xor. Hopefully we can drop support in libfoo 2.0.         '''         do_a_different_thing()      else:         raise ValueError   You'll get either...  ValueError: invalid \\x escape   ...on Python 2.x or...  SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 79-80: truncated \\xXX escape   ...on Python 3.x.  The only way to do multi-line comments which are ignored by the parser is...  elif token == '\\\\xor':     # Note that we still need to provide support for the deprecated     # token \\xor. Hopefully we can drop support in libfoo 2.0.     do_a_different_thing()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "22", "A_Content": "  AFAIK, Python doesn't have block comments. For commenting individual lines, you can use the # character.  If you are using Notepad++, there is a shortcut for block commenting. I'm sure others like gVim and Emacs have similar features.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "9", "A_Content": "  I think it doesn't, except that a multiline string isn't processed. However, most, if not all Python IDEs have a shortkey for 'commenting out' multiple lines of code.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "5", "A_Content": "  If you put a comment in   \"\"\" long comment here \"\"\"   in the middle of a script, python/linters wont reccognize that. Folding will be messed up, as the above comment is not part of the standard recommendations. Its better to use   # long comment # here.   If you use vim, you can plugins like https://github.com/tpope/vim-commentary, to automatically comment out long lines of comments by pressing Vjgcc. Where Vj selects 2 lines of code, and gcc comments them out.   If you dont want to use plugins like the above you can use search and replace like  :.,.+1s/^/# /g.   This will replace the first character on the current and next line with #.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "3", "A_Content": "  On Python 2.7.13:  Single:  \"A sample single line comment \"   Multiline:  \"\"\" A sample multiline comment on PyCharm \"\"\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "3", "A_Content": "  Well, you can try this (when running the quoted, the input to the first question should quoted with '):  \"\"\" print(\"What's your name? \") myName = input() print(\"It's nice to meet you \" + myName) print(\"Number of characters is \") print(len(myName)) age = input(\"What's your age? \") print(\"You will be \" + str(int(age)+1) + \" next year.\")  \"\"\" a = input() print(a) print(a*5)   Whatever enclosed between \"\"\" will be commented.  If you are looking for single-line comments then it's #.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "3", "A_Content": "  How to comment:   '''    Comment what you want here '''   or   \"\"\"     Comment what you want here  \"\"\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "2", "A_Content": "  Unfortunately stringification not always can be used as commenting out! So it is safer to stick to the standard prepending each line with a #.  Here is an example:  test1 = [1, 2, 3, 4,]       # test1 contains 4 integers  test2 = [1, 2, '''3, 4,'''] # test2 contains 2 integers and the string '3, 4,'     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/7696924/way-to-create-multiline-comments-in-python", "Language": "Python", "Q_Title": "Way to create multiline comments in Python?", "Q_Votes": "848", "Q_Content": "    I have recently started studying Python, but I couldn't find how to implement multi-line comments. Most languages have block comment symbols like   /*   */   I tried this in Python, but it throws an error, so this probably is not the correct way. Does Python actually have a multiline comment feature?     ", "Tags": ["python", "comments"], "A_Votes": "0", "A_Content": "  Multiline comment in Python: For me, both ''' and \"\"\" worked     Ex:   a = 10 b = 20 c = a+b ''' print ('hello') ''' print ('Addition is : ',a+b)      Ex:   a = 10 b = 20 c = a+b \"\"\" print ('hello') \"\"\" print ('Addition is : ',a+b)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "1222", "A_Content": "  The del statement removes an element:  del d[key]   However, this mutates the existing dictionary so the contents of the dictionary changes for anybody else who has a reference to the same instance. To return a new dictionary, make a copy of the dictionary:  def removekey(d, key):     r = dict(d)     del r[key]     return r   The dict() constructor makes a shallow copy. To make a deep copy, see the copy module.    Note that making a copy for every dict del/assignment/etc. means you're going from constant time to linear time, and also using linear space. For small dicts, this is not a problem. But if you're planning to make lots of copies of large dicts, you probably want a different data structure, like a HAMT (as described in this answer).     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "138", "A_Content": "  pop mutates the dictionary.   >>>lol = {\"hello\":\"gdbye\"}  >>>lol.pop(\"hello\")     'gdbye'  >>> lol      {}   If you want to keep the original you could just copy it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "56", "A_Content": "  I think your solution is best way to do it. But if you want another solution, you can create a new dictionary with using the keys from old dictionary without including your specified key, like this:  >>> a {0: 'zero', 1: 'one', 2: 'two', 3: 'three'} >>> {i:a[i] for i in a if i!=0} {1: 'one', 2: 'two', 3: 'three'}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "47", "A_Content": "  The del statement is what you're looking for. If you have a dictionary named foo with a key called 'bar', you can delete 'bar' from foo like this:  del foo['bar']   Note that this permanently modifies the dictionary being operated on. If you want to keep the original dictionary, you'll have to create a copy beforehand:  >>> foo = {'bar': 'baz'} >>> fu = dict(foo) >>> del foo['bar'] >>> print foo {} >>> print fu {'bar': 'baz'}   The dict call makes a shallow copy. If you want a deep copy, use copy.deepcopy.  Here's a method you can copy & paste, for your convenience:  def minus_key(key, dictionary):     shallow_copy = dict(dictionary)     del shallow_copy[key]     return shallow_copy      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "21", "A_Content": "  There're a lot of nice answers, but I want to emphasize one thing.  You can use both dict.pop() method and a more generic del statement to remove items from a dictionary. They both mutate the original dictionary, so you need to make a copy (see details below).  And both of them will raise a KeyError if the key you're providing to them is not present in the dictionary:  key_to_remove = \"c\" d = {\"a\": 1, \"b\": 2} del d[key_to_remove]  # Raises `KeyError: 'c'`   and  key_to_remove = \"c\" d = {\"a\": 1, \"b\": 2} d.pop(key_to_remove)  # Raises `KeyError: 'c'`   You have to take care of this:  by capturing the exception:  key_to_remove = \"c\" d = {\"a\": 1, \"b\": 2} try:     del d[key_to_remove] except KeyError as ex:     print(\"No such key: '%s'\" % ex.message)   and  key_to_remove = \"c\" d = {\"a\": 1, \"b\": 2} try:     d.pop(key_to_remove) except KeyError as ex:     print(\"No such key: '%s'\" % ex.message)   by performing a check:  key_to_remove = \"c\" d = {\"a\": 1, \"b\": 2} if key_to_remove in d:     del d[key_to_remove]   and  key_to_remove = \"c\" d = {\"a\": 1, \"b\": 2} if key_to_remove in d:     d.pop(key_to_remove)   but with pop() there's also a much more concise way - provide the default return value:  key_to_remove = \"c\" d = {\"a\": 1, \"b\": 2} d.pop(key_to_remove, None)  # No `KeyError` here   Unless you use pop() to get the value of a key being removed you may provide anything, not necessary None. Though it might be that using del with in check is slightly faster due to pop() being a function with its own complications causing overhead. Usually it's not the case, so pop() with default value is good enough.    As for the main question, you'll have to make a copy of your dictionary, to save the original dictionary and have a new one without the key being removed.  Some other people here suggest making a full (deep) copy with copy.deepcopy(), which might be an overkill, a \"normal\" (shallow) copy, using copy.copy() or dict.copy(), might be enough. The dictionary keeps a reference to the object as a value for a key. So when you remove a key from a dictionary this reference is removed, not the object being referenced. The object itself may be removed later automatically by the garbage collector, if there're no other references for it in the memory. Making a deep copy requires more calculations compared to shallow copy, so it decreases code performance by making the copy, wasting memory and providing more work to the GC, sometimes shallow copy is enough.  However, if you have mutable objects as dictionary values and plan to modify them later in the returned dictionary without the key, you have to make a deep copy.  With shallow copy:  def get_dict_wo_key(dictionary, key):     \"\"\"Returns a **shallow** copy of the dictionary without a key.\"\"\"     _dict = dictionary.copy()     _dict.pop(key, None)     return _dict   d = {\"a\": [1, 2, 3], \"b\": 2, \"c\": 3} key_to_remove = \"c\"  new_d = get_dict_wo_key(d, key_to_remove) print(d)  # {\"a\": [1, 2, 3], \"b\": 2, \"c\": 3} print(new_d)  # {\"a\": [1, 2, 3], \"b\": 2} new_d[\"a\"].append(100) print(d)  # {\"a\": [1, 2, 3, 100], \"b\": 2, \"c\": 3} print(new_d)  # {\"a\": [1, 2, 3, 100], \"b\": 2} new_d[\"b\"] = 2222 print(d)  # {\"a\": [1, 2, 3, 100], \"b\": 2, \"c\": 3} print(new_d)  # {\"a\": [1, 2, 3, 100], \"b\": 2222}   With deep copy:  from copy import deepcopy   def get_dict_wo_key(dictionary, key):     \"\"\"Returns a **deep** copy of the dictionary without a key.\"\"\"     _dict = deepcopy(dictionary)     _dict.pop(key, None)     return _dict   d = {\"a\": [1, 2, 3], \"b\": 2, \"c\": 3} key_to_remove = \"c\"  new_d = get_dict_wo_key(d, key_to_remove) print(d)  # {\"a\": [1, 2, 3], \"b\": 2, \"c\": 3} print(new_d)  # {\"a\": [1, 2, 3], \"b\": 2} new_d[\"a\"].append(100) print(d)  # {\"a\": [1, 2, 3], \"b\": 2, \"c\": 3} print(new_d)  # {\"a\": [1, 2, 3, 100], \"b\": 2} new_d[\"b\"] = 2222 print(d)  # {\"a\": [1, 2, 3], \"b\": 2, \"c\": 3} print(new_d)  # {\"a\": [1, 2, 3, 100], \"b\": 2222}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "16", "A_Content": "  d = {1: 2, '2': 3, 5: 7} del d[5] print 'd = ', d   Result: d = {1: 2, '2': 3}     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "12", "A_Content": "  Simply call del d['key'].  However, in production, it is always a good practice to check if 'key' exists in d.  if 'key' in d:     del d['key']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "6", "A_Content": "  No, there is no other way than  def dictMinus(dct, val):    copy = dct.copy()    del copy[val]    return copy   However, often creating copies of only slightly altered dictionaries is probably not a good idea because it will result in comparatively large memory demands. It is usually better to log the old dictionary(if even necessary) and then modify it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "5", "A_Content": "  >>> def delete_key(dict, key): ...     del dict[key] ...     return dict ...  >>> test_dict = {'one': 1, 'two' : 2} >>> print delete_key(test_dict, 'two') {'one': 1} >>>   this doesn't do any error handling, it assumes the key is in the dict, you might want to check that first and raise if its not     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "5", "A_Content": "     \u2026 how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?   A dict is the wrong data structure to use for this.  Sure, copying the dict and popping from the copy works, and so does building a new dict with a comprehension, but all that copying takes time\u2014you've replaced a constant-time operation with a linear-time one. And all those copies alive at once take space\u2014linear space per copy.  Other data structures, like hash array mapped tries, are designed for exactly this kind of use case: adding or removing an element returns a copy in logarithmic time, sharing most of its storage with the original.1  Of course there are some downsides. Performance is logarithmic rather than constant (although with a large base, usually 32-128). And, while you can make the non-mutating API identical to dict, the \"mutating\" API is obviously different. And, most of all, there's no HAMT batteries included with Python.2  The pyrsistent library is a pretty solid implementation of HAMT-based dict-replacements (and various other types) for Python. It even has a nifty evolver API for porting existing mutating code to persistent code as smoothly as possible. But if you want to be explicit about returning copies rather than mutating, you just use it like this:  >>> from pyrsistent import m >>> d1 = m(a=1, b=2) >>> d2 = d1.set('c', 3) >>> d3 = d1.remove('a') >>> d1 pmap({'a': 1, 'b': 2}) >>> d2 pmap({'c': 3, 'a': 1, 'b': 2}) >>> d3 pmap({'b': 2})   That d3 = d1.remove('a') is exactly what the question is asking for.  If you've got mutable data structures like dict and list embedded in the pmap, you'll still have aliasing issues\u2014you can only fix that by going immutable all the way down, embedding pmaps and pvectors.    1. HAMTs have also become popular in languages like Scala, Clojure, Haskell because they play very nicely with lock-free programming and software transactional memory, but neither of those is very relevant in Python.  2. In fact, there is an HAMT in the stdlib, used in the implementation of contextvars. The earlier withdrawn PEP explains why. But this is a hidden implementation detail of the library, not a public collection type.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "4", "A_Content": "  Here a top level design approach:  def eraseElement(d,k):     if isinstance(d, dict):         if k in d:             d.pop(k)             print(d)         else:             print(\"Cannot find matching key\")     else:         print(\"Not able to delete\")   exp = {'A':34, 'B':55, 'C':87} eraseElement(exp, 'C')   I'm passing the dictionary and the key I want into my function, validates if it's a dictionary and if the key is okay, and if both exist, removes the value from the dictionary and prints out the left-overs.  Output: {'B': 55, 'A': 34}  Hope that helps!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "3", "A_Content": "  nice one-liner to check if the key is present, delete it, return the value, or default:  ret_val = ('key' in body and body.pop('key')) or 5      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "3", "A_Content": "  Below code snippet will help you definitely, I have added comments in each line which will help you in understanding the code.  def execute():    dic = {'a':1,'b':2}    dic2 = remove_key_from_dict(dic, 'b')      print(dict2)           # {'a': 1}    print(dict)            # {'a':1,'b':2}  def remove_key_from_dict(dictionary_to_use, key_to_delete):    copy_of_dict = dict(dictionary_to_use)     # creating clone/copy of the dictionary    if key_to_delete in copy_of_dict :         # checking given key is present in the dictionary        del copy_of_dict [key_to_delete]       # deleting the key from the dictionary     return copy_of_dict                        # returning the final dictionary   or you can also use dict.pop()  d = {\"a\": 1, \"b\": 2}  res = d.pop(\"c\")  # No `KeyError` here print (res)       # this line will not execute   or the better approach is  res = d.pop(\"c\", \"key not found\") print (res)   # key not found print (d)     # {\"a\": 1, \"b\": 2}  res = d.pop(\"b\", \"key not found\") print (res)   # 2 print (d)     # {\"a\": 1}      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/5844672/delete-an-element-from-a-dictionary", "Language": "Python", "Q_Title": "Delete an element from a dictionary", "Q_Votes": "871", "Q_Content": "    Is there a way to delete an item from a dictionary in Python?  Additionally, how can I delete an item from a dictionary to return a copy (i.e., not modifying the original)?     ", "Tags": ["python", "dictionary", "pop", "del"], "A_Votes": "1", "A_Content": "  Here's another variation using list comprehension:  original_d = {'a': None, 'b': 'Some'} d = dict((k,v) for k, v in original_d.iteritems() if v) # result should be {'b': 'Some'}   The approach is based on an answer from this post: Efficient way to remove keys with empty strings from a dict     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "1764", "A_Content": "  To select rows whose column value equals a scalar, some_value, use ==:  df.loc[df['column_name'] == some_value]   To select rows whose column value is in an iterable, some_values, use isin:  df.loc[df['column_name'].isin(some_values)]   Combine multiple conditions with &:   df.loc[(df['column_name'] == some_value) & df['other_column'].isin(some_values)]     To select rows whose column value does not equal some_value, use !=:  df.loc[df['column_name'] != some_value]   isin returns a boolean Series, so to select rows whose value is not in some_values, negate the boolean Series using ~:  df.loc[~df['column_name'].isin(some_values)]     For example,  import pandas as pd import numpy as np df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),                    'B': 'one one two three two two one three'.split(),                    'C': np.arange(8), 'D': np.arange(8) * 2}) print(df) #      A      B  C   D # 0  foo    one  0   0 # 1  bar    one  1   2 # 2  foo    two  2   4 # 3  bar  three  3   6 # 4  foo    two  4   8 # 5  bar    two  5  10 # 6  foo    one  6  12 # 7  foo  three  7  14  print(df.loc[df['A'] == 'foo'])   yields       A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14     If you have multiple values you want to include, put them in a list (or more generally, any iterable) and use isin:  print(df.loc[df['B'].isin(['one','three'])])   yields       A      B  C   D 0  foo    one  0   0 1  bar    one  1   2 3  bar  three  3   6 6  foo    one  6  12 7  foo  three  7  14     Note, however, that if you wish to do this many times, it is more efficient to make an index first, and then use df.loc:  df = df.set_index(['B']) print(df.loc['one'])   yields         A  C   D B               one  foo  0   0 one  bar  1   2 one  foo  6  12   or, to include multiple values from the index use df.index.isin:  df.loc[df.index.isin(['one','two'])]   yields         A  C   D B               one  foo  0   0 one  bar  1   2 two  foo  2   4 two  foo  4   8 two  bar  5  10 one  foo  6  12      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "152", "A_Content": "  tl;dr  The pandas equivalent to   select * from table where column_name = some_value   is  table[table.column_name == some_value]   Multiple conditions:  table[(table.column_name == some_value) | (table.column_name2 == some_value2)]   or  table.query('column_name == some_value | column_name2 == some_value2')   Code example  import pandas as pd  # Create data set d = {'foo':[100, 111, 222],       'bar':[333, 444, 555]} df = pd.DataFrame(d)  # Full dataframe: df  # Shows: #    bar   foo  # 0  333   100 # 1  444   111 # 2  555   222  # Output only the row(s) in df where foo is 222: df[df.foo == 222]  # Shows: #    bar  foo # 2  555  222   In the above code it is the line df[df.foo == 222] that gives the rows based on the column value, 222 in this case.  Multiple conditions are also possible:  df[(df.foo == 222) | (df.bar == 444)] #    bar  foo # 1  444  111 # 2  555  222   But at that point I would recommend using the query function, since it's less verbose and yields the same result:  df.query('foo == 222 | bar == 444')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "83", "A_Content": "  There are a few basic ways to select rows from a pandas dataframe.   Boolean indexing Positional indexing Label indexing API   For each base type, we can keep things simple by restricting ourselves to the pandas API or we can venture outside the API, usually into numpy, and speed things up.  I'll show you examples of each and guide you as to when to use certain techniques.    Setup The first thing we'll need is to identify a condition that will act as our criterion for selecting rows.  The OP offers up column_name == some_value.  We'll start there and include some other common use cases.  Borrowing from @unutbu:  import pandas as pd, numpy as np  df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),                    'B': 'one one two three two two one three'.split(),                    'C': np.arange(8), 'D': np.arange(8) * 2})     Assume our criterion is column 'A' = 'foo'  1. Boolean indexing requires finding the truth value of each row's 'A' column being equal to 'foo', then using those truth values to identify which rows to keep.  Typically, we'd name this series, an array of truth values, mask.  We'll do so here as well.  mask = df['A'] == 'foo'   We can then use this mask to slice or index the dataframe  df[mask]       A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14   This is one of the simplest ways to accomplish this task and if performance or intuitiveness isn't an issue, this should be your chosen method.  However, if performance is a concern, then you might want to consider an alternative way of creating the mask.    2. Positional indexing has its use cases, but this isn't one of them.  In order to identify where to slice, we first need to perform the same boolean analysis we did above.  This leaves us performing one extra step to accomplish the same task.  mask = df['A'] == 'foo' pos = np.flatnonzero(mask) df.iloc[pos]       A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14   3. Label indexing can be very handy, but in this case, we are again doing more work for no benefit  df.set_index('A', append=True, drop=False).xs('foo', level=1)       A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14   4. pd.DataFrame.query is a very elegant/intuitive way to perform this task.  But is often slower.  However, if you pay attention to the timings below, for large data, query is very efficient.  More so than the standard approach and of similar magnitude as my best suggestion.  df.query('A == \"foo\"')       A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14     My preference is to use the Boolean mask   Actual improvements can be made by modifying how we create our Boolean mask.  mask alternative 1 Use the underlying numpy array and forgo the overhead of creating another pd.Series    mask = df['A'].values == 'foo'   I'll show more complete time tests at the end, but just take a look at the performance gains we get using the sample dataframe.  First we look at the difference in creating the mask  %timeit mask = df['A'].values == 'foo' %timeit mask = df['A'] == 'foo'  5.84 \u00b5s \u00b1 195 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each) 166 \u00b5s \u00b1 4.45 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)   Evaluating the mask with the numpy array is ~ 30 times faster.  This is partly due to numpy evaluation often being faster.  It is also partly due to the lack of overhead necessary to build an index and a corresponding pd.Series object.  Next we'll look at the timing for slicing with one mask versus the other.  mask = df['A'].values == 'foo' %timeit df[mask] mask = df['A'] == 'foo' %timeit df[mask]  219 \u00b5s \u00b1 12.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) 239 \u00b5s \u00b1 7.03 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)   The performance gains aren't as pronounced.  We'll see if this holds up over more robust testing.    mask alternative 2 We could have reconstructed the dataframe as well.  There is a big caveat when reconstructing a dataframe\u2014you must take care of the dtypes when doing so!  Instead of df[mask] we will do this  pd.DataFrame(df.values[mask], df.index[mask], df.columns).astype(df.dtypes)   If the dataframe is of mixed type, which our example is, then when we get df.values the resulting array is of dtype object and consequently, all columns of the new dataframe will be of dtype object.  Thus requiring the astype(df.dtypes) and killing any potential performance gains.  %timeit df[m] %timeit pd.DataFrame(df.values[mask], df.index[mask], df.columns).astype(df.dtypes)  216 \u00b5s \u00b1 10.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each) 1.43 ms \u00b1 39.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)   However, if the dataframe is not of mixed type, this is a very useful way to do it.  Given  np.random.seed([3,1415]) d1 = pd.DataFrame(np.random.randint(10, size=(10, 5)), columns=list('ABCDE'))  d1     A  B  C  D  E 0  0  2  7  3  8 1  7  0  6  8  6 2  0  2  0  4  9 3  7  3  2  4  3 4  3  6  7  7  4 5  5  3  7  5  9 6  8  7  6  4  7 7  6  2  6  6  5 8  2  8  7  5  8 9  4  7  6  1  5         %%timeit mask = d1['A'].values == 7 d1[mask]  179 \u00b5s \u00b1 8.73 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)   Versus  %%timeit mask = d1['A'].values == 7 pd.DataFrame(d1.values[mask], d1.index[mask], d1.columns)  87 \u00b5s \u00b1 5.12 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)   We cut the time in half.    mask alternative 3 @unutbu also shows us how to use pd.Series.isin to account for each element of df['A'] being in a set of values.  This evaluates to the same thing if our set of values is a set of one value, namely 'foo'.  But it also generalizes to include larger sets of values if needed.  Turns out, this is still pretty fast even though it is a more general solution.  The only real loss is in intuitiveness for those not familiar with the concept.  mask = df['A'].isin(['foo']) df[mask]       A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14   However, as before, we can utilize numpy to improve performance while sacrificing virtually nothing.  We'll use np.in1d  mask = np.in1d(df['A'].values, ['foo']) df[mask]       A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14     Timing I'll include other concepts mentioned in other posts as well for reference. Code Below    Each Column in this table represents a different length dataframe over which we test each function. Each column shows relative time taken, with the fastest function given a base index of 1.0.  res.div(res.min())                           10        30        100       300       1000      3000      10000     30000 mask_standard         2.156872  1.850663  2.034149  2.166312  2.164541  3.090372  2.981326  3.131151 mask_standard_loc     1.879035  1.782366  1.988823  2.338112  2.361391  3.036131  2.998112  2.990103 mask_with_values      1.010166  1.000000  1.005113  1.026363  1.028698  1.293741  1.007824  1.016919 mask_with_values_loc  1.196843  1.300228  1.000000  1.000000  1.038989  1.219233  1.037020  1.000000 query                 4.997304  4.765554  5.934096  4.500559  2.997924  2.397013  1.680447  1.398190 xs_label              4.124597  4.272363  5.596152  4.295331  4.676591  5.710680  6.032809  8.950255 mask_with_isin        1.674055  1.679935  1.847972  1.724183  1.345111  1.405231  1.253554  1.264760 mask_with_in1d        1.000000  1.083807  1.220493  1.101929  1.000000  1.000000  1.000000  1.144175   You'll notice that fastest times seem to be shared between mask_with_values and mask_with_in1d  res.T.plot(loglog=True)     Functions    def mask_standard(df):     mask = df['A'] == 'foo'     return df[mask]  def mask_standard_loc(df):     mask = df['A'] == 'foo'     return df.loc[mask]  def mask_with_values(df):     mask = df['A'].values == 'foo'     return df[mask]  def mask_with_values_loc(df):     mask = df['A'].values == 'foo'     return df.loc[mask]  def query(df):     return df.query('A == \"foo\"')  def xs_label(df):     return df.set_index('A', append=True, drop=False).xs('foo', level=-1)  def mask_with_isin(df):     mask = df['A'].isin(['foo'])     return df[mask]  def mask_with_in1d(df):     mask = np.in1d(df['A'].values, ['foo'])     return df[mask]     Testing    res = pd.DataFrame(     index=[         'mask_standard', 'mask_standard_loc', 'mask_with_values', 'mask_with_values_loc',         'query', 'xs_label', 'mask_with_isin', 'mask_with_in1d'     ],     columns=[10, 30, 100, 300, 1000, 3000, 10000, 30000],     dtype=float )  for j in res.columns:     d = pd.concat([df] * j, ignore_index=True)     for i in res.index:a         stmt = '{}(d)'.format(i)         setp = 'from __main__ import d, {}'.format(i)         res.at[i, j] = timeit(stmt, setp, number=50)     Special Timing Looking at the special case when we have a single non-object dtype for the entire dataframe. Code Below    spec.div(spec.min())                       10        30        100       300       1000      3000      10000     30000 mask_with_values  1.009030  1.000000  1.194276  1.000000  1.236892  1.095343  1.000000  1.000000 mask_with_in1d    1.104638  1.094524  1.156930  1.072094  1.000000  1.000000  1.040043  1.027100 reconstruct       1.000000  1.142838  1.000000  1.355440  1.650270  2.222181  2.294913  3.406735   Turns out, reconstruction isn't worth it past a few hundred rows.  spec.T.plot(loglog=True)     Functions    np.random.seed([3,1415]) d1 = pd.DataFrame(np.random.randint(10, size=(10, 5)), columns=list('ABCDE'))  def mask_with_values(df):     mask = df['A'].values == 'foo'     return df[mask]  def mask_with_in1d(df):     mask = np.in1d(df['A'].values, ['foo'])     return df[mask]  def reconstruct(df):     v = df.values     mask = np.in1d(df['A'].values, ['foo'])     return pd.DataFrame(v[mask], df.index[mask], df.columns)  spec = pd.DataFrame(     index=['mask_with_values', 'mask_with_in1d', 'reconstruct'],     columns=[10, 30, 100, 300, 1000, 3000, 10000, 30000],     dtype=float )   Testing    for j in spec.columns:     d = pd.concat([df] * j, ignore_index=True)     for i in spec.index:         stmt = '{}(d)'.format(i)         setp = 'from __main__ import d, {}'.format(i)         spec.at[i, j] = timeit(stmt, setp, number=50)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "41", "A_Content": "  I find the syntax of the previous answers to be redundant and difficult to remember. Pandas introduced the query() method in v0.13 and I much prefer it. For your question, you could do df.query('col == val')  Reproduced from http://pandas.pydata.org/pandas-docs/version/0.17.0/indexing.html#indexing-query  In [167]: n = 10  In [168]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))  In [169]: df Out[169]:            a         b         c 0  0.687704  0.582314  0.281645 1  0.250846  0.610021  0.420121 2  0.624328  0.401816  0.932146 3  0.011763  0.022921  0.244186 4  0.590198  0.325680  0.890392 5  0.598892  0.296424  0.007312 6  0.634625  0.803069  0.123872 7  0.924168  0.325076  0.303746 8  0.116822  0.364564  0.454607 9  0.986142  0.751953  0.561512  # pure python In [170]: df[(df.a < df.b) & (df.b < df.c)] Out[170]:            a         b         c 3  0.011763  0.022921  0.244186 8  0.116822  0.364564  0.454607  # query In [171]: df.query('(a < b) & (b < c)') Out[171]:            a         b         c 3  0.011763  0.022921  0.244186 8  0.116822  0.364564  0.454607   You can also access variables in the environment by prepending an @.  exclude = ('red', 'orange') df.query('color not in @exclude')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "11", "A_Content": "  Faster results can be achieved using numpy.where.   For example, with unubtu's setup -  In [76]: df.iloc[np.where(df.A.values=='foo')] Out[76]:       A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14   Timing comparisons:  In [68]: %timeit df.iloc[np.where(df.A.values=='foo')]  # fastest 1000 loops, best of 3: 380 \u00b5s per loop  In [69]: %timeit df.loc[df['A'] == 'foo'] 1000 loops, best of 3: 745 \u00b5s per loop  In [71]: %timeit df.loc[df['A'].isin(['foo'])] 1000 loops, best of 3: 562 \u00b5s per loop  In [72]: %timeit df[df.A=='foo'] 1000 loops, best of 3: 796 \u00b5s per loop  In [74]: %timeit df.query('(A==\"foo\")')  # slowest 1000 loops, best of 3: 1.71 ms per loop      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "10", "A_Content": "  Here is a simple example    from pandas import DataFrame  # Create data set d = {'Revenue':[100,111,222],       'Cost':[333,444,555]} df = DataFrame(d)   # mask = Return True when the value in column \"Revenue\" is equal to 111 mask = df['Revenue'] == 111  print mask  # Result: # 0    False # 1     True # 2    False # Name: Revenue, dtype: bool   # Select * FROM df WHERE Revenue = 111 df[mask]  # Result: #    Cost    Revenue # 1  444     111      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "7", "A_Content": "  I just tried editing this, but I wasn't logged in, so I'm not sure where my edit went. I was trying to incorporate multiple selection. So I think a better answer is:  For a single value, the most straightforward (human readable) is probably:  df.loc[df['column_name'] == some_value]   For lists of values you can also use:  df.loc[df['column_name'].isin(some_values)]   For example,  import pandas as pd import numpy as np df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),                'B': 'one one two three two two one three'.split(),                'C': np.arange(8), 'D': np.arange(8) * 2}) print(df) #      A      B  C   D # 0  foo    one  0   0 # 1  bar    one  1   2 # 2  foo    two  2   4 # 3  bar  three  3   6 # 4  foo    two  4   8 # 5  bar    two  5  10 # 6  foo    one  6  12 # 7  foo  three  7  14  print(df.loc[df['A'] == 'foo'])   yields       A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14   If you have multiple criteria you want to select against, you can put them in a list and use 'isin':  print(df.loc[df['B'].isin(['one','three'])])   yields        A      B  C   D 0  foo    one  0   0 1  bar    one  1   2 3  bar  three  3   6 6  foo    one  6  12 7  foo  three  7  14   Note, however, that if you wish to do this many times, it is more efficient to make A the index first, and then use df.loc:  df = df.set_index(['A']) print(df.loc['foo'])   yields    A      B  C   D foo    one  0   0 foo    two  2   4 foo    two  4   8 foo    one  6  12 foo  three  7  14      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "3", "A_Content": "  df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),                    'B': 'one one two three two two one three'.split(),                    'C': np.arange(8), 'D': np.arange(8) * 2}) df[df['A']=='foo']  OUTPUT:    A      B  C   D 0  foo    one  0   0 2  foo    two  2   4 4  foo    two  4   8 6  foo    one  6  12 7  foo  three  7  14      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "3", "A_Content": "  To append to this famous question (though a bit too late): You can also do df.groupby('column_name').get_group('column_desired_value').reset_index() to make a new data frame with specified column having a particular value. E.g.  import pandas as pd df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),                    'B': 'one one two three two two one three'.split()}) print(\"Original dataframe:\") print(df)  b_is_two_dataframe = pd.DataFrame(df.groupby('B').get_group('two').reset_index()).drop('index', axis = 1)  #NOTE: the final drop is to remove the extra index column returned by groupby object print('Sub dataframe where B is two:') print(b_is_two_dataframe)   Run this gives:  Original dataframe:      A      B 0  foo    one 1  bar    one 2  foo    two 3  bar  three 4  foo    two 5  bar    two 6  foo    one 7  foo  three Sub dataframe where B is two:      A    B 0  foo  two 1  foo  two 2  bar  two      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "2", "A_Content": "  If you came here looking to select rows from a dataframe by including those whose column's value is NOT any of a list of values, here's how to flip around unutbu's answer for a list of values above:  df.loc[~df['column_name'].isin(some_values)]   (To not include a single value, of course, you just use the regular not equals operator, !=.)  Example:  import pandas as pd df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),                    'B': 'one one two three two two one three'.split()}) print(df)   gives us       A      B 0  foo    one 1  bar    one 2  foo    two 3  bar  three 4  foo    two 5  bar    two 6  foo    one 7  foo  three       To subset to just those rows that AREN'T one or three in column B:  df.loc[~df['B'].isin(['one', 'three'])]   yields       A    B 2  foo  two 4  foo  two 5  bar  two      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas", "Language": "Python", "Q_Title": "Select rows from a DataFrame based on values in a column in pandas", "Q_Votes": "879", "Q_Content": "    How to select rows from a DataFrame based on values in some column in pandas? In SQL I would use:   select * from table where colume_name = some_value.    I tried to look at pandas documentation but did not immediately find the answer.     ", "Tags": ["python", "pandas", "dataframe"], "A_Votes": "1", "A_Content": "  For selecting only specific columns out of multiple columns for a given value in pandas:  select col_name1, col_name2 from table where column_name = some_value.   Options:  df.loc[df['column_name'] == some_value][[col_name1, col_name2]]   or   df.query['column_name' == 'some_value'][[col_name1, col_name2]]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "1433", "A_Content": "  Yes. Use os.path.splitext(see Python 2.X documentation or Python 3.X documentation):  >>> import os >>> filename, file_extension = os.path.splitext('/path/to/somefile.ext') >>> filename '/path/to/somefile' >>> file_extension '.ext'      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "316", "A_Content": "  import os.path extension = os.path.splitext(filename)[1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "98", "A_Content": "  New in version 3.4.  import pathlib  print(pathlib.Path('yourPathGoesHere').suffix)   I'm surprised no one has mentioned pathlib yet, pathlib IS awesome!  If you need all the suffixes (eg if you have a .tar.gz), .suffixes will return a list of them!     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "79", "A_Content": "  import os.path extension = os.path.splitext(filename)[1][1:]   To get only the text of the extension, without the dot.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "55", "A_Content": "  One option may be splitting from dot:  >>> filename = \"example.jpeg\" >>> filename.split(\".\")[-1] 'jpeg'   No error when file doesn't have an extension:  >>> \"filename\".split(\".\")[-1] 'filename'   But you must be careful:  >>> \"png\".split(\".\")[-1] 'png'    # But file doesn't have an extension      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "26", "A_Content": "  worth adding a lower in there so you don't find yourself wondering why the JPG's aren't showing up in your list.  os.path.splitext(filename)[1][1:].strip().lower()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "10", "A_Content": "  Any of the solutions above work, but on linux I have found that there is a newline at the end of the extension string which will prevent matches from succeeding. Add the strip() method to the end. For example:    import os.path extension = os.path.splitext(filename)[1][1:].strip()       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "9", "A_Content": "  With splitext there are problems with files with double extension (e.g. file.tar.gz, file.tar.bz2, etc..)  >>> fileName, fileExtension = os.path.splitext('/path/to/somefile.tar.gz') >>> fileExtension  '.gz'   but should be: .tar.gz  The possible solutions are here     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "7", "A_Content": "  filename='ext.tar.gz' extension = filename[filename.rfind('.'):]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "5", "A_Content": "  Surprised this wasn't mentioned yet:  import os fn = '/some/path/a.tar.gz'  basename = os.path.basename(fn)  # os independent Out[] a.tar.gz  base = basename.split('.')[0] Out[] a  ext = '.'.join(basename.split('.')[1:])   # <-- main part  # if you want a leading '.', and if no result `None`: ext = '.' + ext if ext else None Out[] .tar.gz   Benefits:   Works as expected for anything I can think of No modules No regex Cross-platform Easily extendible (e.g. no leading dots for extension, only last part of extension)   As function:  def get_extension(filename):     basename = os.path.basename(filename)  # os independent     ext = '.'.join(basename.split('.')[1:])     return '.' + ext if ext else None      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "5", "A_Content": "  Although it is an old topic, but i wonder why there is none mentioning a very simple api of python called rpartition in this case:  to get extension of a given file absolute path, you can simply type:  filepath.rpartition('.')[-1]   example:  path = '/home/jersey/remote/data/test.csv' print path.rpartition('.')[-1]   will give you:  'csv'     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "2", "A_Content": "  Another solution with right split:  # to get extension only  s = 'test.ext'  if '.' in s: ext = s.rsplit('.', 1)[1]  # or, to get file name and extension  def split_filepath(s):     \"\"\"     get filename and extension from filepath      filepath -> (filename, extension)     \"\"\"     if not '.' in s: return (s, '')     r = s.rsplit('.', 1)     return (r[0], r[1])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "2", "A_Content": "  You can use a split on a filename:  f_extns = filename.split(\".\") print (\"The extension of the file is : \" + repr(f_extns[-1]))   This does not require additional library     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "1", "A_Content": "  Even this question is already answered I'd add the solution in Regex.   >>> import re >>> file_suffix = \".*(\\..*)\" >>> result = re.search(file_suffix, \"somefile.ext\") >>> result.group(1) '.ext'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "1", "A_Content": "  You can find some great stuff in pathlib module.  import pathlib x = pathlib.PurePosixPath(\"C:\\\\Path\\\\To\\\\File\\\\myfile.txt\").suffix print(x)  # Output  '.txt'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "1", "A_Content": "  Just join all pathlib suffixes.  >>> x = 'file/path/archive.tar.gz' >>> y = 'file/path/text.txt' >>> ''.join(pathlib.Path(x).suffixes) '.tar.gz' >>> ''.join(pathlib.Path(y).suffixes) '.txt'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "0", "A_Content": "  This is a direct string representation techniques : I see a lot of solutions mentioned, but I think most are looking at split. Split however does it at every occurrence of \".\" . What you would rather be looking for is partition.  string = \"folder/to_path/filename.ext\" extension = string.rpartition(\".\")[-1]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "-2", "A_Content": "  # try this, it works for anything, any length of extension # e.g www.google.com/downloads/file1.gz.rs -> .gz.rs  import os.path  class LinkChecker:      @staticmethod     def get_link_extension(link: str)->str:         if link is None or link == \"\":             return \"\"         else:             paths = os.path.splitext(link)             ext = paths[1]             new_link = paths[0]             if ext != \"\":                 return LinkChecker.get_link_extension(new_link) + ext             else:                 return \"\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python", "Language": "Python", "Q_Title": "Extracting extension from filename in Python", "Q_Votes": "897", "Q_Content": "    Is there a function to extract the extension from a filename?     ", "Tags": ["python", "filenames", "file-extension"], "A_Votes": "-2", "A_Content": "  def NewFileName(fichier):     cpt = 0     fic , *ext =  fichier.split('.')     ext = '.'.join(ext)     while os.path.isfile(fichier):         cpt += 1         fichier = '{0}-({1}).{2}'.format(fic, cpt, ext)     return fichier      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install", "Language": "Python", "Q_Title": "Why use pip over easy_install? [closed]", "Q_Votes": "887", "Q_Content": "    A tweet reads:      Don't use easy_install, unless you   like stabbing yourself in the face.   Use pip.   Why use pip over easy_install? Doesn't the fault lie with PyPI and package authors mostly? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to strongly favor pip over easy_install?  (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community)     ", "Tags": ["python", "pip", "setuptools", "easy-install", "pypi"], "A_Votes": "267", "A_Content": "  Many of the answers here are out of date for 2015 (although the initially accepted one from Daniel Roseman is not). Here's the current state of things:   Binary packages are now distributed as wheels (.whl files)\u2014not just on PyPI, but in third-party repositories like Christoph Gohlke's Extension Packages for Windows. pip can handle wheels; easy_install cannot. Virtual environments (which come built-in with 3.4, or can be added to 2.6+/3.1+ with virtualenv) have become a very important and prominent tool (and recommended in the official docs); they include pip out of the box, but don't even work properly with easy_install. The distribute package that included easy_install is no longer maintained. Its improvements over setuptools got merged back into setuptools. Trying to install distribute will just install setuptools instead. easy_install itself is only quasi-maintained. All of the cases where pip used to be inferior to easy_install\u2014installing from an unpacked source tree, from a DVCS repo, etc.\u2014are long-gone; you can pip install ., pip install git+https://. pip comes with the official Python 2.7 and 3.4+ packages from python.org, and a pip bootstrap is included by default if you build from source. The various incomplete bits of documentation on installing, using, and building packages have been replaced by the Python Packaging User Guide. Python's own documentation on Installing Python Modules now defers to this user guide, and explicitly calls out pip as \"the preferred installer program\". Other new features have been added to pip over the years that will never be in easy_install. For example, pip makes it easy to clone your site-packages by building a requirements file and then installing it with a single command on each side. Or to convert your requirements file to a local repo to use for in-house development. And so on.   The only good reason that I know of to use easy_install in 2015 is the special case of using Apple's pre-installed Python versions with OS X 10.5-10.8. Since 10.5, Apple has included easy_install, but as of 10.10 they still don't include pip. With 10.9+, you should still just use get-pip.py, but for 10.5-10.8, this has some problems, so it's easier to sudo easy_install pip. (In general, easy_install pip is a bad idea; it's only for OS X 10.5-10.8 that you want to do this.) Also, 10.5-10.8 include readline in a way that easy_install knows how to kludge around but pip doesn't, so you also want to sudo easy_install readline if you want to upgrade that.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install", "Language": "Python", "Q_Title": "Why use pip over easy_install? [closed]", "Q_Votes": "887", "Q_Content": "    A tweet reads:      Don't use easy_install, unless you   like stabbing yourself in the face.   Use pip.   Why use pip over easy_install? Doesn't the fault lie with PyPI and package authors mostly? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to strongly favor pip over easy_install?  (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community)     ", "Tags": ["python", "pip", "setuptools", "easy-install", "pypi"], "A_Votes": "584", "A_Content": "  From Ian Bicking's own introduction to pip:     pip was originally written to improve on easy_install in the following ways         All packages are downloaded before installation. Partially-completed installation doesn\u2019t occur as a result.   Care is taken to present useful output on the console.   The reasons for actions are kept track of. For instance, if a package is being installed, pip keeps track of why that package was required.   Error messages should be useful.   The code is relatively concise and cohesive, making it easier to use programmatically.   Packages don\u2019t have to be installed as egg archives, they can be installed flat (while keeping the egg metadata).   Native support for other version control systems (Git, Mercurial and Bazaar)   Uninstallation of packages.   Simple to define fixed sets of requirements and reliably reproduce a set of packages.         ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install", "Language": "Python", "Q_Title": "Why use pip over easy_install? [closed]", "Q_Votes": "887", "Q_Content": "    A tweet reads:      Don't use easy_install, unless you   like stabbing yourself in the face.   Use pip.   Why use pip over easy_install? Doesn't the fault lie with PyPI and package authors mostly? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to strongly favor pip over easy_install?  (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community)     ", "Tags": ["python", "pip", "setuptools", "easy-install", "pypi"], "A_Votes": "244", "A_Content": "  Another\u2014as of yet unmentioned\u2014reason for favoring pip is because it is the new hotness and will continue to be used in the future.   The infographic below\u2014from the Current State of Packaging section in the The Hitchhiker's Guide to Packaging v1.0\u2014shows that setuptools/easy_install will go away in the future.    Here's another infographic from distribute's documentation showing that Setuptools and easy_install will be replaced by the new hotness\u2014distribute and pip. While pip is still the new hotness, Distribute merged with Setuptools in 2013 with the release of Setuptools v0.7.       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install", "Language": "Python", "Q_Title": "Why use pip over easy_install? [closed]", "Q_Votes": "887", "Q_Content": "    A tweet reads:      Don't use easy_install, unless you   like stabbing yourself in the face.   Use pip.   Why use pip over easy_install? Doesn't the fault lie with PyPI and package authors mostly? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to strongly favor pip over easy_install?  (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community)     ", "Tags": ["python", "pip", "setuptools", "easy-install", "pypi"], "A_Votes": "166", "A_Content": "  Two reasons, there may be more:   pip provides an uninstall command if an installation fails in the middle, pip will leave you in a clean state.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install", "Language": "Python", "Q_Title": "Why use pip over easy_install? [closed]", "Q_Votes": "887", "Q_Content": "    A tweet reads:      Don't use easy_install, unless you   like stabbing yourself in the face.   Use pip.   Why use pip over easy_install? Doesn't the fault lie with PyPI and package authors mostly? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to strongly favor pip over easy_install?  (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community)     ", "Tags": ["python", "pip", "setuptools", "easy-install", "pypi"], "A_Votes": "111", "A_Content": "  REQUIREMENTS files.  Seriously, I use this in conjunction with virtualenv every day.    QUICK DEPENDENCY MANAGEMENT TUTORIAL, FOLKS  Requirements files allow you to create a snapshot of all packages that have been installed through pip.  By encapsulating those packages in a virtualenvironment, you can have your codebase work off a very specific set of packages and share that codebase with others.  From Heroku's documentation https://devcenter.heroku.com/articles/python  You create a virtual environment, and set your shell to use it. (bash/*nix instructions)  virtualenv env source env/bin/activate   Now all python scripts run with this shell will use this environment's packages and configuration.  Now you can install a package locally to this environment without needing to install it globally on your machine.  pip install flask   Now you can dump the info about which packages are installed with  pip freeze > requirements.txt   If you checked that file into version control, when someone else gets your code, they can setup their own virtual environment and install all the dependencies with:  pip install -r requirements.txt   Any time you can automate tedium like this is awesome.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install", "Language": "Python", "Q_Title": "Why use pip over easy_install? [closed]", "Q_Votes": "887", "Q_Content": "    A tweet reads:      Don't use easy_install, unless you   like stabbing yourself in the face.   Use pip.   Why use pip over easy_install? Doesn't the fault lie with PyPI and package authors mostly? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to strongly favor pip over easy_install?  (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community)     ", "Tags": ["python", "pip", "setuptools", "easy-install", "pypi"], "A_Votes": "79", "A_Content": "  pip won't install binary packages and isn't well tested on Windows.  As Windows doesn't come with a compiler by default pip often can't be used there. easy_install can install binary packages for Windows.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install", "Language": "Python", "Q_Title": "Why use pip over easy_install? [closed]", "Q_Votes": "887", "Q_Content": "    A tweet reads:      Don't use easy_install, unless you   like stabbing yourself in the face.   Use pip.   Why use pip over easy_install? Doesn't the fault lie with PyPI and package authors mostly? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to strongly favor pip over easy_install?  (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community)     ", "Tags": ["python", "pip", "setuptools", "easy-install", "pypi"], "A_Votes": "71", "A_Content": "  UPDATE: setuptools has absorbed distribute as opposed to the other way around, as some thought. setuptools is up-to-date with the latest distutils changes and the wheel format. Hence, easy_install and pip are more or less on  equal footing now.  Source: http://pythonhosted.org/setuptools/merge-faq.html#why-setuptools-and-not-distribute-or-another-name     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install", "Language": "Python", "Q_Title": "Why use pip over easy_install? [closed]", "Q_Votes": "887", "Q_Content": "    A tweet reads:      Don't use easy_install, unless you   like stabbing yourself in the face.   Use pip.   Why use pip over easy_install? Doesn't the fault lie with PyPI and package authors mostly? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to strongly favor pip over easy_install?  (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community)     ", "Tags": ["python", "pip", "setuptools", "easy-install", "pypi"], "A_Votes": "23", "A_Content": "  As an addition to fuzzyman's reply:     pip won't install binary packages and isn't well tested on Windows.      As Windows doesn't come with a compiler by default pip often can't be   used there. easy_install can install binary packages for Windows.   Here is a trick on Windows:   you can use easy_install <package> to install binary packages to avoid building a binary you can use  pip uninstall <package> even if you used easy_install.   This is just a work-around that works for me on windows. Actually I always use pip if no binaries are involved.  See the current pip doku: http://www.pip-installer.org/en/latest/other-tools.html#pip-compared-to-easy-install     I will ask on the mailing list what is planned for that.   Here is the latest update:  The new supported way to install binaries is going to be wheel! It is not yet in the standard, but almost. Current version is still an alpha: 1.0.0a1  https://pypi.python.org/pypi/wheel  http://wheel.readthedocs.org/en/latest/  I will test wheel by creating an OS X installer for PySide using wheel instead of eggs. Will get back and report about this.  cheers - Chris  A quick update:  The transition to wheel is almost over. Most packages are supporting wheel.  I promised to build wheels for PySide, and I did that last summer. Works great!  HINT: A few developers failed so far to support the wheel format, simply because they forget to replace distutils by setuptools. Often, it is easy to convert such packages by replacing this single word in setup.py.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install", "Language": "Python", "Q_Title": "Why use pip over easy_install? [closed]", "Q_Votes": "887", "Q_Content": "    A tweet reads:      Don't use easy_install, unless you   like stabbing yourself in the face.   Use pip.   Why use pip over easy_install? Doesn't the fault lie with PyPI and package authors mostly? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to strongly favor pip over easy_install?  (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community)     ", "Tags": ["python", "pip", "setuptools", "easy-install", "pypi"], "A_Votes": "3", "A_Content": "  Just met one special case that I had to use easy_install instead of pip, or I have to pull the source codes directly.  For the package GitPython, the version in pip is too old, which is 0.1.7, while the one from easy_install is the latest which is 0.3.2.rc1.  I'm using Python 2.7.8. I'm not sure about the underlay mechanism of easy_install and pip, but at least the versions of some packages may be different from each other, and sometimes easy_install is the one with newer version.  easy_install GitPython      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "1068", "A_Content": "  import sys sys.stdout.flush()   Print by default prints to sys.stdout.  References:   http://docs.python.org/reference/simple_stmts.html#the-print-statement http://docs.python.org/library/sys.html http://docs.python.org/library/stdtypes.html#file-objects      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "293", "A_Content": "  Running python -h, I see a command line option:     -u     : unbuffered binary stdout and stderr; also PYTHONUNBUFFERED=x            see man page for details on internal buffering relating to '-u'   Here is the relevant doc.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "248", "A_Content": "  Since Python 3.3, you can force the normal print() function to flush without the need to use sys.stdout.flush(); just set the \"flush\" keyword argument to true.  From the documentation:     print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=False)      Print objects to the stream file, separated by sep and followed by end. sep, end and file, if present, must be given as keyword arguments.      All non-keyword arguments are converted to strings like str() does and written to the stream, separated by sep and followed by end. Both sep and end must be strings; they can also be None, which means to use the default values. If no objects are given, print() will just write end.      The file argument must be an object with a write(string) method; if it is not present or None, sys.stdout will be used. Whether output is buffered is usually determined by file, but if the flush keyword argument is true, the stream is forcibly flushed.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "106", "A_Content": "     How to flush output of Python print?   I suggest five ways of doing this:   In Python 3, call print(..., flush=True) (the flush argument is not available in Python 2's print function, and there is no analogue for the print statement). Call file.flush() on the output file (we can wrap python 2's print function to do this), for example, sys.stdout apply this to every print function call in the module with a partial function, print = partial(print, flush=True) applied to the module global. apply this to the process with a flag (-u) passed to the interpreter command apply this to every python process in your environment with PYTHONUNBUFFERED=TRUE (and unset the variable to undo this).   Python 3.3+  Using Python 3.3 or higher, you can just provide flush=True as a keyword argument to the print function:   print('foo', flush=True)    Python 2 (or < 3.3)  They did not backport the flush argument to Python 2.7 So if you're using Python 2 (or less than 3.3), and want code that's compatible with both 2 and 3, may I suggest the following compatibility code. (Note the __future__ import must be at/very \"near the top of your module\"):  from __future__ import print_function import sys  if sys.version_info[:2] < (3, 3):     old_print = print     def print(*args, **kwargs):         flush = kwargs.pop('flush', False)         old_print(*args, **kwargs)         if flush:             file = kwargs.get('file', sys.stdout)             # Why might file=None? IDK, but it works for print(i, file=None)             file.flush() if file is not None else sys.stdout.flush()   The above compatibility code will cover most uses, but for a much more thorough treatment, see the six module.  Alternatively, you can just call file.flush() after printing, for example, with the print statement in Python 2:  import sys print 'delayed output' sys.stdout.flush()   Changing the default in one module to flush=True  You can change the default for the print function by using functools.partial on the global scope of a module:  import functools print = functools.partial(print, flush=True)   if you look at our new partial function, at least in Python 3:  >>> print = functools.partial(print, flush=True) >>> print functools.partial(<built-in function print>, flush=True)   We can see it works just like normal:  >>> print('foo') foo   And we can actually override the new default:  >>> print('foo', flush=False) foo   Note again, this only changes the current global scope, because the print name on the current global scope will overshadow the builtin print function (or dereference the compatibility function, if using Python 2, in that current global scope).  If you want to do this inside a function instead of on a module's global scope, you should give it a different name, e.g.:  def foo():     printf = functools.partial(print, flush=True)     printf('print stuff like this')   If you declare it a global in a function, you're changing it on the module's global namespace, so you should just put it in the global namespace, unless that specific behavior is exactly what you want.  Changing the default for the process  I think the best option here is to use the -u flag to get unbuffered output.  $ python -u script.py   or    $ python -um package.module   From the docs:     Force stdin, stdout and stderr to be totally unbuffered. On systems where it matters, also put stdin, stdout and stderr in binary mode.      Note that there is internal buffering in file.readlines() and File Objects (for line in sys.stdin) which is not influenced by this option. To work around this, you will want to use file.readline() inside a while 1: loop.   Changing the default for the shell operating environment  You can get this behavior for all python processes in the environment or environments that inherit from the environment if you set the environment variable to a nonempty string:  e.g., in Linux or OSX:  $ export PYTHONUNBUFFERED=TRUE   or Windows:  C:\\SET PYTHONUNBUFFERED=TRUE   from the docs:     PYTHONUNBUFFERED      If this is set to a non-empty string it is equivalent to specifying the -u option.     Addendum  Here's the help on the print function from Python 2.7.12 - note that there is no flush argument:  >>> from __future__ import print_function >>> help(print) print(...)     print(value, ..., sep=' ', end='\\n', file=sys.stdout)      Prints the values to a stream, or to sys.stdout by default.     Optional keyword arguments:     file: a file-like object (stream); defaults to the current sys.stdout.     sep:  string inserted between values, default a space.     end:  string appended after the last value, default a newline.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "65", "A_Content": "  Also as suggested in this blog one can reopen sys.stdout in unbuffered mode:  sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)   Each stdout.write and print operation will be automatically flushed afterwards.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "30", "A_Content": "  Using the -u command-line switch works, but it is a little bit clumsy. It would mean that the program would potentially behave incorrectly if the user invoked the script without the -u option.  I usually use a custom stdout, like this:  class flushfile(object):   def __init__(self, f):     self.f = f    def write(self, x):     self.f.write(x)     self.f.flush()  import sys sys.stdout = flushfile(sys.stdout)   ... Now all your print calls (which use sys.stdout implicitly), will be automatically flushed.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "26", "A_Content": "  With Python 3.x they extended the print() function:  print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=False)   So, you can just do:  print(\"Visiting toilet\", flush=True)     Python Docs Entry     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "17", "A_Content": "  Why not try using an unbuffered file?  f = open('xyz.log', 'a', 0)   OR  sys.stdout = open('out.log', 'a', 0)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "12", "A_Content": "  import sys print 'This will be output immediately.' sys.stdout.flush()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "10", "A_Content": "  Dan's idea doesn't quite work:  #!/usr/bin/env python class flushfile(file):     def __init__(self, f):         self.f = f     def write(self, x):         self.f.write(x)         self.f.flush()  import sys sys.stdout = flushfile(sys.stdout)  print \"foo\"   The result:  Traceback (most recent call last):   File \"./passpersist.py\", line 12, in <module>     print \"foo\" ValueError: I/O operation on closed file   I believe the problem is that it inherits from the file class, which actually isn't necessary. According to the docs for sys.stdout:     stdout and stderr needn\u2019t be built-in   file objects: any object is acceptable   as long as it has a write() method   that takes a string argument.   so changing  class flushfile(file):   to  class flushfile(object):   makes it work just fine.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "6", "A_Content": "  Here is my version, which provides writelines() and fileno(), too:  class FlushFile(object):     def __init__(self, fd):         self.fd = fd      def write(self, x):         ret = self.fd.write(x)         self.fd.flush()         return ret      def writelines(self, lines):         ret = self.writelines(lines)         self.fd.flush()         return ret      def flush(self):         return self.fd.flush      def close(self):         return self.fd.close()      def fileno(self):         return self.fd.fileno()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "5", "A_Content": "  Loved Dan's solution! For python3 do:  import io,sys class flushfile:     def __init__(self, f):         self.f = f     def write(self, x):         self.f.write(x)         self.f.flush() sys.stdout = flushfile(sys.stdout)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "2", "A_Content": "  In Python 3 you can overwrite print function with default set to flush = True   def print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=True):     __builtins__.print(*objects, sep=sep, end=end, file=file, flush=flush)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/230751/how-to-flush-output-of-print-function", "Language": "Python", "Q_Title": "How to flush output of print function?", "Q_Votes": "902", "Q_Content": "    How do I force Python's print function to output to the screen?  This is not a duplicate of Disable output buffering - the linked question is attempting unbuffered output, while this is more general. The top answers in that question are too powerful or involved for this one (they're not good answers for this), and this question can be found on Google by a relative newbie.     ", "Tags": ["python", "python-3.x", "printing", "flush"], "A_Votes": "2", "A_Content": "  I did it like this in Python 3.4:  '''To write to screen in real-time''' message = lambda x: print(x, flush=True, end=\"\") message('I am flushing out now...')      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "1361", "A_Content": "  Whitespace on both sides:  s = \"  \\t a string example\\t  \" s = s.strip()   Whitespace on the right side:  s = s.rstrip()   Whitespace on the left side:  s = s.lstrip()   As thedz points out, you can provide an argument to strip arbitrary characters to any of these functions like this:  s = s.strip(' \\t\\n\\r')   This will strip any space, \\t, \\n, or \\r characters from the left-hand side, right-hand side, or both sides of the string.   The examples above only remove strings from the left-hand and right-hand sides of strings. If you want to also remove characters from the middle of a string, try re.sub:  import re print re.sub('[\\s+]', '', s)   That should print out:  astringexample      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "57", "A_Content": "  Python trim method is called strip:  str.strip() #trim str.lstrip() #ltrim str.rstrip() #rtrim      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "20", "A_Content": "  For leading and trailing whitespace:  s = '   foo    \\t   ' print s.strip() # prints \"foo\"   Otherwise, a regular expression works:  import re pat = re.compile(r'\\s+') s = '  \\t  foo   \\t   bar \\t  ' print pat.sub('', s) # prints \"foobar\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "18", "A_Content": "  You can also use very simple, and basic function: str.replace(), works with the whitespaces and tabs:  >>> whitespaces = \"   abcd ef gh ijkl       \" >>> tabs = \"        abcde       fgh        ijkl\"  >>> print whitespaces.replace(\" \", \"\") abcdefghijkl >>> print tabs.replace(\" \", \"\") abcdefghijkl   Simple and easy.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "12", "A_Content": "  #how to trim a multi line string or a file  s=\"\"\" line one \\tline two\\t line three \"\"\"  #line1 starts with a space, #2 starts and ends with a tab, #3 ends with a space.  s1=s.splitlines() print s1 [' line one', '\\tline two\\t', 'line three ']  print [i.strip() for i in s1] ['line one', 'line two', 'line three']     #more details:  #we could also have used a forloop from the begining: for line in s.splitlines():     line=line.strip()     process(line)  #we could also be reading a file line by line.. e.g. my_file=open(filename), or with open(filename) as myfile: for line in my_file:     line=line.strip()     process(line)  #moot point: note splitlines() removed the newline characters, we can keep them by passing True: #although split() will then remove them anyway.. s2=s.splitlines(True) print s2 [' line one\\n', '\\tline two\\t\\n', 'line three ']      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "4", "A_Content": "  No one has posted these regex solutions yet.  Matching:  >>> import re >>> p=re.compile('\\\\s*(.*\\\\S)?\\\\s*')  >>> m=p.match('  \\t blah ') >>> m.group(1) 'blah'  >>> m=p.match('  \\tbl ah  \\t ') >>> m.group(1) 'bl ah'  >>> m=p.match('  \\t  ') >>> print m.group(1) None   Searching (you have to handle the \"only spaces\" input case differently):  >>> p1=re.compile('\\\\S.*\\\\S')  >>> m=p1.search('  \\tblah  \\t ') >>> m.group() 'blah'  >>> m=p1.search('  \\tbl ah  \\t ') >>> m.group() 'bl ah'  >>> m=p1.search('  \\t  ') >>> m.group() Traceback (most recent call last): File \"<stdin>\", line 1, in <module> AttributeError: 'NoneType' object has no attribute 'group'   If you use re.sub, you may remove inner whitespace, which could be undesirable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "3", "A_Content": "  Whitespace includes space, tabs and CRLF. So an elegant and one-liner string function we can use is translate.   ' hello  apple'.translate(None, ' \\n\\t\\r')  OR if you want to be thorough  import string ' hello  apple'.translate(None, string.whitespace)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "2", "A_Content": "      something = \"\\t  please_     \\t remove_  all_    \\n\\n\\n\\nwhitespaces\\n\\t  \"      something = \"\".join(something.split())   output:   please_remove_all_whitespaces     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "0", "A_Content": "  try translate  >>> import string >>> print '\\t\\r\\n  hello \\r\\n world \\t\\r\\n'    hello   world   >>> tr = string.maketrans(string.whitespace, ' '*len(string.whitespace)) >>> '\\t\\r\\n  hello \\r\\n world \\t\\r\\n'.translate(tr) '     hello    world    ' >>> '\\t\\r\\n  hello \\r\\n world \\t\\r\\n'.translate(tr).replace(' ', '') 'helloworld'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "0", "A_Content": "     (re.sub(' +', ' ',(my_str.replace('\\n',' ')))).strip()   This will remove all the unwanted spaces and newline characters. Hope this help  import re my_str = '   a     b \\n c   ' formatted_str = (re.sub(' +', ' ',(my_str.replace('\\n',' ')))).strip()   This will result :  '   a  \u00a0\u00a0\u00a0\u00a0   b \\n c   ' will be changed to 'a b c'     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "-1", "A_Content": "  Generally, I am using the following method:  >>> myStr = \"Hi\\n Stack Over \\r flow!\" >>> charList = [u\"\\u005Cn\",u\"\\u005Cr\",u\"\\u005Ct\"] >>> import re >>> for i in charList:         myStr = re.sub(i, r\"\", myStr)  >>> myStr 'Hi Stack Over  flow'   Note: This is only for removing \"\\n\", \"\\r\" and \"\\t\" only. It does not remove extra spaces.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace", "Language": "Python", "Q_Title": "How do I trim whitespace?", "Q_Votes": "902", "Q_Content": "    Is there a Python function that will trim whitespace (spaces and tabs) from a string?  Example: \\t example string\\t \u2192 example string     ", "Tags": ["python", "string", "whitespace", "trim", "strip"], "A_Votes": "-2", "A_Content": "  for removing whitespaces from the middle of the string      $p = \"ATGCGAC ACGATCGACC\";  $p =~ s/\\s//g;  print $p;        output: ATGCGACACGATCGACC     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "1244", "A_Content": "  is is identity testing, == is equality testing. what happens in your code would be emulated in the interpreter like this:  >>> a = 'pub' >>> b = ''.join(['p', 'u', 'b']) >>> a == b True >>> a is b False   so, no wonder they're not the same, right?  In other words: is is the id(a) == id(b)     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "446", "A_Content": "  Other answers here are correct: is is used for identity comparison, while == is used for equality comparison. Since what you care about is equality (the two strings should contain the same characters), in this case the is operator is simply wrong and you should be using == instead.  The reason is works interactively is that (most) string literals are interned by default. From Wikipedia:     Interned strings speed up string   comparisons, which are sometimes a   performance bottleneck in applications   (such as compilers and dynamic   programming language runtimes) that   rely heavily on hash tables with   string keys. Without interning,   checking that two different strings   are equal involves examining every   character of both strings. This is   slow for several reasons: it is   inherently O(n) in the length of the   strings; it typically requires reads   from several regions of memory, which   take time; and the reads fills up the   processor cache, meaning there is less   cache available for other needs. With   interned strings, a simple object   identity test suffices after the   original intern operation; this is   typically implemented as a pointer   equality test, normally just a single   machine instruction with no memory   reference at all.   So, when you have two string literals (words that are literally typed into your program source code, surrounded by quotation marks) in your program that have the same value, the Python compiler will automatically intern the strings, making them both stored at the same memory location.  (Note that this doesn't always happen, and the rules for when this happens are quite convoluted, so please don't rely on this behavior in production code!)  Since in your interactive session both strings are actually stored in the same memory location, they have the same identity, so the is operator works as expected.  But if you construct a string by some other method (even if that string contains exactly the same characters), then the string may be equal, but it is not the same string -- that is, it has a different identity, because it is stored in a different place in memory.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "94", "A_Content": "  The is keyword is a test for object identity while == is a value comparison.  If you use is, the result will be true if and only if the object is the same object. However, == will be true any time the values of the object are the same.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "48", "A_Content": "  One last thing to note, you may use the intern function to ensure that you're getting a reference to the same string:  >>> a = intern('a') >>> a2 = intern('a') >>> a is a2 True   As pointed out above, you should probably not be doing is to determine equality on strings.  But this may be helpful to know if you have some kind of weird requirement to use is.  Note that the intern function got moved from being a built in function to being in the module sys for Python 3.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "31", "A_Content": "  is is identity testing, == is equality testing. What this means is that is is a way to check whether two things are the same things, or just equivalent.   Say you've got a simple person object. If it is named 'Jack' and is '23' years old, it's equivalent to another 23yr old Jack, but its not the same person.  class Person(object):    def __init__(self, name, age):        self.name = name        self.age = age     def __eq__(self, other):        return self.name == other.name and self.age == other.age  jack1 = Person('Jack', 23) jack2 = Person('Jack', 23)  jack1 == jack2 #True jack1 is jack2 #False   They're the same age, but they're not the same instance of person. A string might be equivalent to another, but it's not the same object.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "27", "A_Content": "  This is a side note, but in idiomatic python, you will often see things like:  if x is None:      # some clauses   This is safe, because there is guaranteed to be one instance of the Null Object (i.e., None).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "23", "A_Content": "  If you're not sure what you're doing, use the '=='. If you have a little more knowledge about it you can use 'is' for known objects like 'None'.  Otherwise you'll end up wondering why things doesn't work and why this happens:  >>> a = 1 >>> b = 1 >>> b is a True >>> a = 6000 >>> b = 6000 >>> b is a False   I'm not even sure if some things are guaranteed to stay the same between different python versions/implementations.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "16", "A_Content": "  From my limited experience with python, is is used to compare two objects to see if they are the same object as opposed to two different objects with the same value.  == is used to determine if the values are identical.   Here is a good example:  >>> s1 = u'public' >>> s2 = 'public' >>> s1 is s2 False >>> s1 == s2 True   s1 is a unicode string, and s2 is a normal string.  They are not the same type, but are the same value.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "12", "A_Content": "  I think it has to do with the fact that, when the 'is' comparison evaluates to false, two distinct objects are used. If it evaluates to true, that means internally it's using the same exact object and not creating a new one, possibly because you created them within a fraction of 2 or so seconds and because there isn't a large time gap in between it's optimized and uses the same object.  This is why you should be using the equality operator ==, not is, to compare the value of a string object.  >>> s = 'one' >>> s2 = 'two' >>> s is s2 False >>> s2 = s2.replace('two', 'one') >>> s2 'one' >>> s2 is s False >>>    In this example, I made s2, which was a different string object previously equal to 'one' but it is not the same object as s, because the interpreter did not use the same object as I did not initially assign it to 'one', if I had it would have made them the same object.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "11", "A_Content": "  I believe that this is known as \"interned\" strings. Python does this, so does Java, and so do C and C++ when compiling in optimized modes.  If you use two identical strings, instead of wasting memory by creating two string objects, all interned strings with the same contents point to the same memory.  This results in the Python \"is\" operator returning True because two strings with the same contents are pointing at the same string object. This will also happen in Java and in C.  This is only useful for memory savings though. You cannot rely on it to test for string equality, because the various interpreters and compilers and JIT engines cannot always do it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "9", "A_Content": "  I am answering the question even though the question is to old because no answers above quotes the language reference  Actually the is operator checks for identity and == operator checks for equality,  From Language Reference:  Types affect almost all aspects of object behavior. Even the importance of object identity is affected in some sense: for immutable types, operations that compute new values may actually return a reference to any existing object with the same type and value, while for mutable objects this is not allowed. E.g., after a = 1; b = 1, a and b may or may not refer to the same object with the value one, depending on the implementation, but after c = []; d = [], c and d are guaranteed to refer to two different, unique, newly created empty lists. (Note that c = d = [] assigns the same object to both c and d.)  so from above statement we can infer that the strings which is an immutable type may fail when checked with \"is\" and may checked succeed when checked with \"is\"  The same applies for int,tuple which are also immutable types     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "3", "A_Content": "  The == operator test value equivalence. The is operator tests object identity, Python tests whether the two are really the same object(i.e., live at the same address in memory).  >>> a = 'banana' >>> b = 'banana' >>> a is b  True   In this example, Python only created one string object, and both a and b refers to it. The reason is that Python internally caches and reuses some strings as an optimization, there really is just a string 'banana' in memory, shared by a and b; To trigger the normal behavior, you need to use longer strings:  >>> a = 'a longer banana' >>> b = 'a longer banana' >>> a == b, a is b (True, False)   When you create two lists, you get two objects:  >>> a = [1, 2, 3] >>> b = [1, 2, 3] >>> a is b False   In this case we would say that the two lists are equivalent, because they have the same elements, but not identical, because they are not the same object. If two objects are identical, they are also equivalent, but if they are equivalent, they are not necessarily identical.  If a refers to an object and you assign b = a, then both variables refer to the same object:   >>> a = [1, 2, 3] >>> b = a >>> b is a True      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "1", "A_Content": "  is is identity testing, == is equality testing (see Python Documentation).   In most cases, if a is b, then a == b. But there are exceptions, for example:   >>> nan = float('nan') >>> nan is nan True >>> nan == nan False   So, you can only use is for identity tests, never equality tests.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1504717/why-does-comparing-strings-in-python-using-either-or-is-sometimes-produce", "Language": "Python", "Q_Title": "Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?", "Q_Votes": "902", "Q_Content": "    I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.  Now if I open my Python interpreter and do the same \"is\" comparison, it succeeds.  >>> s1 = 'public' >>> s2 = 'public' >>> s2 is s1 True   What am I missing here?     ", "Tags": ["python", "string", "comparison"], "A_Votes": "0", "A_Content": "  is will compare the memory location. It is used for object-level comparison.  == will compare the variables in the program. It is used for checking at value level.   is checks for address level equivalence  == checks for value level equivalence     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "596", "A_Content": "  The reason you need to use self. is because Python does not use the @ syntax to refer to instance attributes. Python decided to do methods in a way that makes the instance to which the method belongs be passed automatically, but not received automatically: the first parameter of methods is the instance the method is called on. That makes methods entirely the same as functions, and leaves the actual name to use up to you (although self is the convention, and people will generally frown at you when you use something else.) self is not special to the code, it's just another object.  Python could have done something else to distinguish normal names from attributes -- special syntax like Ruby has, or requiring declarations like C++ and Java do, or perhaps something  yet more different -- but it didn't. Python's all for making things explicit, making it obvious what's what, and although it doesn't do it entirely everywhere, it does do it for instance attributes. That's why assigning to an instance attribute needs to know what instance to assign to, and that's why it needs self..     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "385", "A_Content": "  Let\u2019s take a simple vector class:  class Vector:     def __init__(self, x, y):         self.x = x         self.y = y   We want to have a method which calculates the length. What would it look like if we wanted to define it inside the class?      def length(self):         return math.sqrt(self.x ** 2 + self.y ** 2)   What should it look like when we were to define it as a global method/function?  def length_global(vector):     return math.sqrt(vector.x ** 2 + vector.y ** 2)   So the whole structure stays the same. How can me make use of this? If we assume for a moment that we hadn\u2019t written a length method for our Vector class, we could do this:  Vector.length_new = length_global v = Vector(3, 4) print(v.length_new()) # 5.0   This works because the first parameter of length_global, can be re-used as the self parameter in length_new. This would not be possible without an explicit self.    Another way of understanding the need for the explicit self is to see where Python adds some syntactical sugar. When you keep in mind, that basically, a call like  v_instance.length()   is internally transformed to  Vector.length(v_instance)   it is easy to see where the self fits in. You don't actually write instance methods in Python; what you write is class methods which must take an instance as a first parameter. And therefore, you\u2019ll have to place the instance parameter somewhere explicitly.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "285", "A_Content": "  Let's say you have a class ClassA which contains a method methodA defined as:  def methodA(self, arg1, arg2):     # do something   and ObjectA is an instance of this class.  Now when ObjectA.methodA(arg1, arg2) is called, python internally converts it for you as:  ClassA.methodA(ObjectA, arg1, arg2)   The self variable refers to the object itself.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "154", "A_Content": "  When objects are instantiated, the object itself is passed into the self parameter.     Because of this, the object\u2019s data is bound to the object. Below is an example of how you might like to visualize what each object\u2019s data might look. Notice how \u2018self\u2019 is replaced with the objects name. I'm not saying this example diagram below is wholly accurate but it hopefully with serve a purpose in visualizing the use of self.     The Object is passed into the self parameter so that the object can keep hold of its own data.  Although this may not be wholly accurate, think of the process of instantiating an object like this: When an object is made it uses the class as a template for its own data and methods. Without passing it's own name into the self parameter, the attributes and methods in the class would remain as a general template and would not be referenced to (belong to) the object. So by passing the object's name into the self parameter it means that if 100 objects are instantiated from the one class, they can all keep track of their own data and methods.  See the illustration below:       ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "65", "A_Content": "  I like this example:  class A:      foo = [] a, b = A(), A() a.foo.append(5) b.foo ans: [5]  class A:      def __init__(self):          self.foo = [] a, b = A(), A() a.foo.append(5) b.foo ans: []      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "33", "A_Content": "  I will demonstrate with code that does not use classes:  def state_init(state):     state['field'] = 'init'  def state_add(state, x):     state['field'] += x  def state_mult(state, x):     state['field'] *= x  def state_getField(state):     return state['field']  myself = {} state_init(myself) state_add(myself, 'added') state_mult(myself, 2)  print( state_getField(myself) ) #--> 'initaddedinitadded'   Classes are just a way to avoid passing in this \"state\" thing all the time (and other nice things like initializing, class composition, the rarely-needed metaclasses, and supporting custom methods to override operators).  Now let's demonstrate the above code using the built-in python class machinery, to show how it's basically the same thing.  class State(object):     def __init__(self):         self.field = 'init'     def add(self, x):         self.field += x     def mult(self, x):         self.field *= x  s = State() s.add('added')    # self is implicitly passed in s.mult(2)         # self is implicitly passed in print( s.field )   [migrated my answer from duplicate closed question]     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "17", "A_Content": "  As well as all the other reasons already stated, it allows for easier access to overridden methods; you can call Class.some_method(inst).  An example of where it\u2019s useful:  class C1(object):     def __init__(self):          print \"C1 init\"  class C2(C1):     def __init__(self): #overrides C1.__init__         print \"C2 init\"         C1.__init__(self) #but we still want C1 to init the class too     >>> C2() \"C2 init\" \"C1 init\"      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "16", "A_Content": "  The following excerpts are from the Python documentation about self:     As in Modula-3, there are no shorthands [in Python] for referencing the object\u2019s members from its methods: the method function is declared with an explicit first argument representing the object, which is provided implicitly by the call.      Often, the first argument of a method is called self. This is nothing more than a convention: the name self has absolutely no special meaning to Python. Note, however, that by not following the convention your code may be less readable to other Python programmers, and it is also conceivable that a class browser program might be written that relies upon such a convention.   For more information, see the Python documentation tutorial on classes.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "11", "A_Content": "  Python is not a language built for Object Oriented Programming unlike Java or C++.   When calling a static method in Python, one simply writes a method with regular arguments inside it.   class Animal():     def staticMethod():         print \"This is a static method\"   However, an object method, which requires you to make a variable, which is an Animal, in this case, needs the self argument  class Animal():     def objectMethod(self):         print \"This is an object method which needs an instance of a class\"   The self method is also used to refer to a variable field within the class.   class Animal():     #animalName made in constructor     def Animal(self):         self.animalName = \"\";       def getAnimalName(self):         return self.animalName   In this case, self is referring to the animalName variable of the entire class. REMEMBER: If you have a variable within a method, self will not work. That variable is simply existent only while that method is running. For defining fields (the variables of the entire class), you have to define them OUTSIDE the class methods.   If you don't understand a single word of what I am saying, then Google \"Object Oriented Programming.\" Once you understand this, you won't even need to ask that question :).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "10", "A_Content": "  Its use is similar to the use of this keyword in Java, i.e. to give a reference to the current object.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "7", "A_Content": "  It\u2019s there to follow the Python zen \u201cexplicit is better than implicit\u201d. It\u2019s indeed a reference to your class object. In Java and PHP, for example, it's called this.  If user_type_name is a field on your model you access it by self.user_type_name.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "4", "A_Content": "  self is an object reference to the object itself, therefore, they are same. Python methods are not called in the context of the object itself. self in Python may be used to deal with custom object models or something.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "3", "A_Content": "  I'm surprised nobody has brought up Lua. Lua also uses the 'self' variable however it can be omitted but still used. C++ does the same with 'this'. I don't see any reason to have to declare 'self' in each function but you should still be able to use it just like you can with lua and C++. For a language that prides itself on being brief it's odd that it requires you to declare the self variable.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "2", "A_Content": "  Is because by the way python is designed the alternatives would hardly work. Python is designed to allow methods or functions to be defined in a context where both implicit this (a-la Java/C++) or explicit @ (a-la ruby) wouldn't work. Let's have an example with the explicit approach with python conventions:  def fubar(x):     self.x = x  class C:     frob = fubar   Now the fubar function wouldn't work since it would assume that self is a global variable (and in frob as well). The alternative would be to execute method's with a replaced global scope (where self is the object).  The implicit approach would be  def fubar(x)     myX = x  class C:     frob = fubar   This would mean that myX would be interpreted as a local variable in fubar (and in frob as well). The alternative here would be to execute methods with a replaced local scope which is retained between calls, but that would remove the posibility of method local variables.  However the current situation works out well:   def fubar(self, x)      self.x = x   class C:      frob = fubar   here when called as a method frob will receive the object on which it's called via the self parameter, and fubar can still be called with an object as parameter and work the same (it is the same as C.frob I think).     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "2", "A_Content": "  First of all, self is a conventional name, you could put anything else (being coherent) in its stead.  It refers to the object itself, so when you are using it, you are declaring that .name and .age are properties of the Student objects (note, not of the Student class) you are going to create.  class Student:     #called each time you create a new Student instance     def __init__(self,name,age): #special method to initialize         self.name=name         self.age=age      def __str__(self): #special method called for example when you use print         return \"Student %s is %s years old\" %(self.name,self.age)      def call(self, msg): #silly example for custom method         return (\"Hey, %s! \"+msg) %self.name  #initializing two instances of the student class bob=Student(\"Bob\",20) alice=Student(\"Alice\",19)  #using them print bob.name print bob.age print alice #this one only works if you define the __str__ method print alice.call(\"Come here!\") #notice you don't put a value for self  #you can modify attributes, like when alice ages alice.age=20 print alice   Code is here      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "1", "A_Content": "  In the __init__ method, self refers to the newly created object; in other class methods, it refers to the instance whose method was called.  self, as a name, is just a convention, call it as you want ! but when using it, for example to delete the object, you have to use the same name: __del__(var), where var was used in the __init__(var,[...])  You should take a look at cls too, to have the bigger picture. This post could be helpful.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "1", "A_Content": "  Take a look at the following example, which clearly explains the purpose of self  class Restaurant(object):       bankrupt = False      def open_branch(self):         if not self.bankrupt:            print(\"branch opened\")  #create instance1 >>> x = Restaurant() >>> x.bankrupt False  #create instance2 >>> y = Restaurant() >>> y.bankrupt = True    >>> y.bankrupt True  >>> x.bankrupt False     self is used/needed to distinguish between instances.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "1", "A_Content": "  The use of the argument, conventionally called self isn't as hard to understand, as is why is it necessary? Or as to why explicitly mention it? That, I suppose, is a bigger question for most users who look up this question, or if it is not, they will certainly have the same question as they move forward learning python. I recommend them to read these couple of blogs:  1: Use of self explained  Note that it is not a keyword.     The first argument of every class method, including init, is always a reference to the current instance of the class. By convention, this argument is always named self. In the init method, self refers to the newly created object; in other class methods, it refers to the instance whose method was called. For example the below code is the same as the above code.   2: Why do we have it this way and why can we not eliminate it as an argument, like Java, and have a keyword instead  Another thing I would like to add is, an optional self argument allows me to declare static methods inside a class, by not writing self.  Code examples:  class MyClass():     def staticMethod():         print \"This is a static method\"      def objectMethod(self):         print \"This is an object method which needs an instance of a class, and that is what self refers to\"   PS:This works only in Python 3.x.  In previous versions, you have to explicitly add @staticmethod decorator, otherwise self argument is obligatory.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/2709821/what-is-the-purpose-of-self", "Language": "Python", "Q_Title": "What is the purpose of self?", "Q_Votes": "898", "Q_Content": "    What is the purpose of the self word in Python? I understand it refers to the specific object created from that class, but I can't see why it explicitly needs to be added to every function as a parameter. To illustrate, in Ruby I can do this:  class myClass     def myFunc(name)         @name = name     end end   Which I understand, quite easily. However in Python I need to include self:  class myClass:     def myFunc(self, name):         self.name = name   Can anyone talk me through this? It is not something I've come across in my (admittedly limited) experience.     ", "Tags": ["python", "class", "oop", "self"], "A_Votes": "-2", "A_Content": "  it's an explicit reference to the class instance object.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python", "Language": "Python", "Q_Title": "What's the canonical way to check for type in Python?", "Q_Votes": "915", "Q_Content": "    What is the best way to check whether a given object is of a given type? How about checking whether the object inherits from a given type?  Let's say I have an object o. How do I check whether it's a str?     ", "Tags": ["python", "types"], "A_Votes": "1134", "A_Content": "  To check if o is an instance of str or any subclass of str, use isinstance (this would be the \"canonical\" way):  if isinstance(o, str):   To check if the type of o is exactly str (exclude subclasses):  if type(o) is str:   The following also works, and can be useful in some cases:  if issubclass(type(o), str):   See Built-in Functions in the Python Library Reference for relevant information.  One more note: in this case, if you're using python 2, you may actually want to use:  if isinstance(o, basestring):   because this will also catch Unicode strings (unicode is not a subclass of str; both str and unicode are subclasses of basestring). Note that basestring no longer exists in python 3, where there's a strict separation of strings (str) and binary data (bytes).  Alternatively, isinstance accepts a tuple of classes. This will return True if x is an instance of any subclass of any of (str, unicode):  if isinstance(o, (str, unicode)):      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python", "Language": "Python", "Q_Title": "What's the canonical way to check for type in Python?", "Q_Votes": "915", "Q_Content": "    What is the best way to check whether a given object is of a given type? How about checking whether the object inherits from a given type?  Let's say I have an object o. How do I check whether it's a str?     ", "Tags": ["python", "types"], "A_Votes": "147", "A_Content": "  The most Pythonic way to check the type of an object is... not to check it.  Since Python encourages Duck Typing, you should just try...except to use the object's methods the way you want to use them.  So if your function is looking for a writable file object, don't check that it's a subclass of file, just try to use its .write() method!  Of course, sometimes these nice abstractions break down and isinstance(obj, cls) is what you need.  But use sparingly.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python", "Language": "Python", "Q_Title": "What's the canonical way to check for type in Python?", "Q_Votes": "915", "Q_Content": "    What is the best way to check whether a given object is of a given type? How about checking whether the object inherits from a given type?  Let's say I have an object o. How do I check whether it's a str?     ", "Tags": ["python", "types"], "A_Votes": "39", "A_Content": "  isinstance(o, str) will return true if o is an str or is of a type that inherits from str.  type(o) is str will return true if and only if o is a str. It will return false if o is of a type that inherits from str. ----     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python", "Language": "Python", "Q_Title": "What's the canonical way to check for type in Python?", "Q_Votes": "915", "Q_Content": "    What is the best way to check whether a given object is of a given type? How about checking whether the object inherits from a given type?  Let's say I have an object o. How do I check whether it's a str?     ", "Tags": ["python", "types"], "A_Votes": "18", "A_Content": "  After the question was asked and answered, type hints were added to Python. Type hints in Python allow types to be checked but in a very different way from statically typed languages. Type hints in Python associate the expected types of arguments with functions as runtime accessible data associated with functions and this allows for types to be checked. Example of type hint syntax:  def foo(i: int):     return i  foo(5) foo('oops')   In this case we want an error to be triggered for foo('oops') since the annotated type of the argument is int. The added type hint does not cause an error to occur when the script is run normally. However, it adds attributes to the function describing the expected types that other programs can query and use to check for type errors.  One of these other programs that can be used to find the type error is mypy:  mypy script.py script.py:12: error: Argument 1 to \"foo\" has incompatible type \"str\"; expected \"int\"   (You might need to install mypy from your package manager. I don't think it comes with CPython but seems to have some level of \"officialness\".)  Type checking this way is different from type checking in statically typed compiled languages. Because types are dynamic in Python, type checking must be done at runtime, which imposes a cost -- even on correct programs -- if we insist that it happen at every chance. Explicit type checks may also be more restrictive than needed and cause unnecessary errors (e.g. does the argument really need to be of exactly list type or is anything iterable sufficient?).  The upside of explicit type checking is that it can catch errors earlier and give clearer error messages than duck typing. The exact requirements of a duck type can only be expressed with external documentation (hopefully it's thorough and accurate) and errors from incompatible types can occur far from where they originate.  Python's type hints are meant to offer a compromise where types can be specified and checked but there is no additional cost during usual code execution.  The typing package offers type variables that can be used in type hints to express needed behaviors without requiring particular types. For example, it includes variables such as Iterable and Callable for hints to specify the need for any type with those behaviors.  While type hints are the most Pythonic way to check types, it's often even more Pythonic to not check types at all and rely on duck typing. Type hints are relatively new and the jury is still out on when they're the most Pythonic solution. A relatively uncontroversial but very general comparison: Type hints provide a form of documentation that can be enforced, allow code to generate earlier and easier to understand errors, can catch errors that duck typing can't, and can be checked statically (in an unusual sense but it's still outside of runtime). On the other hand, duck typing has been the Pythonic way for a long time, doesn't impose the cognitive overhead of static typing, is less verbose, and will accept all viable types and then some.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python", "Language": "Python", "Q_Title": "What's the canonical way to check for type in Python?", "Q_Votes": "915", "Q_Content": "    What is the best way to check whether a given object is of a given type? How about checking whether the object inherits from a given type?  Let's say I have an object o. How do I check whether it's a str?     ", "Tags": ["python", "types"], "A_Votes": "14", "A_Content": "  Here is an example why duck typing is evil without knowing when it is dangerous. For instance: Here is the Python code (possibly omitting proper indenting), note that this  situation is avoidable by taking care of isinstance and issubclassof functions to make sure that when you really need a duck, you don't get a bomb.  class Bomb:     def __init__(self):         \"\"      def talk(self):         self.explode()      def explode(self):         print \"BOOM!, The bomb explodes.\"  class Duck:     def __init__(self):         \"\"     def talk(self):         print \"I am a duck, I will not blow up if you ask me to talk.\"      class Kid:     kids_duck = None      def __init__(self):         print \"Kid comes around a corner and asks you for money so he could buy a duck.\"      def takeDuck(self, duck):         self.kids_duck = duck         print \"The kid accepts the duck, and happily skips along\"      def doYourThing(self):         print \"The kid tries to get the duck to talk\"         self.kids_duck.talk()  myKid = Kid() myBomb = Bomb() myKid.takeDuck(myBomb) myKid.doYourThing()      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python", "Language": "Python", "Q_Title": "What's the canonical way to check for type in Python?", "Q_Votes": "915", "Q_Content": "    What is the best way to check whether a given object is of a given type? How about checking whether the object inherits from a given type?  Let's say I have an object o. How do I check whether it's a str?     ", "Tags": ["python", "types"], "A_Votes": "10", "A_Content": "  isinstance(o, str)   Link to docs     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python", "Language": "Python", "Q_Title": "What's the canonical way to check for type in Python?", "Q_Votes": "915", "Q_Content": "    What is the best way to check whether a given object is of a given type? How about checking whether the object inherits from a given type?  Let's say I have an object o. How do I check whether it's a str?     ", "Tags": ["python", "types"], "A_Votes": "6", "A_Content": "  I think the cool thing about using a dynamic language like Python is you really shouldn't have to check something like that.  I would just call the required methods on your object and catch an AttributeError. Later on this will allow you to call your methods with other (seemingly unrelated) objects to accomplish different tasks, such as mocking an object for testing.  I've used this a lot when getting data off the web with urllib2.urlopen() which returns a file like object. This can in turn can be passed to almost any method that reads from a file, because it implements the same read() method as a real file.  But I'm sure there is a time and place for using isinstance(), otherwise it probably wouldn't be there :)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python", "Language": "Python", "Q_Title": "What's the canonical way to check for type in Python?", "Q_Votes": "915", "Q_Content": "    What is the best way to check whether a given object is of a given type? How about checking whether the object inherits from a given type?  Let's say I have an object o. How do I check whether it's a str?     ", "Tags": ["python", "types"], "A_Votes": "3", "A_Content": "  To Hugo:  You probably mean list rather than array, but that points to the whole problem with type checking - you don't want to know if the object in question is a list, you want to know if it's some kind of sequence or if it's a single object. So try to use it like a sequence.  Say you want to add the object to an existing sequence, or if it's a sequence of objects, add them all  try:    my_sequence.extend(o) except TypeError:   my_sequence.append(o)   One trick with this is if you are working with strings and/or sequences of strings - that's tricky, as a string is often thought of as a single object, but it's also a sequence of characters. Worse than that, as it's really a sequence of single-length strings.  I usually choose to design my API so that it only accepts either a single value or a sequence - it makes things easier. It's not hard to put a [ ] around your single value when you pass it in if need be.  (Though this can cause errors with strings, as they do look like (are) sequences.)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "1486", "A_Content": "  Try:  from random import randint print(randint(0, 9))   More info: https://docs.python.org/3/library/random.html#random.randint     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "291", "A_Content": "  import random print(random.randint(0,9))     random.randint(a, b)   Return a random integer N such that a <= N <= b.  Docs: https://docs.python.org/3.1/library/random.html#random.randint     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "92", "A_Content": "  Try this:  from random import randrange, uniform  # randrange gives you an integral value irand = randrange(0, 10)  # uniform gives you a floating-point value frand = uniform(0, 10)      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "53", "A_Content": "  from random import randint  x = [randint(0, 9) for p in range(0, 10)]   This generates 10 pseudorandom integers in range 0 to 9 inclusive.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "33", "A_Content": "  The secrets module is new in Python 3.6. This is better than the random module for cryptography or security uses.  To randomly print an integer in the inclusive range 0-9:  from secrets import randbelow print(randbelow(10))   For details, see PEP 506.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "18", "A_Content": "  Try this through random.shuffle  >>> import random >>> nums = [x for x in range(10)] >>> random.shuffle(nums) >>> nums [6, 3, 5, 4, 0, 1, 2, 9, 8, 7]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "12", "A_Content": "  Choose the size of the array (in this example, I have chosen the size to be 20). And then, use the following:   import numpy as np    np.random.randint(10, size=(1, 20))   You can expect to see an output of the following form (different random integers will be returned each time you run it; hence you can expect the integers in the output array to differ from the example given below).  array([[1, 6, 1, 2, 8, 6, 3, 3, 2, 5, 6, 5, 0, 9, 5, 6, 4, 5, 9, 3]])      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "11", "A_Content": "  In case of continuous numbers randint or randrange are probably the best choices but if you have several distinct values in a sequence (i.e. a list) you could also use choice:  >>> import random >>> values = list(range(10)) >>> random.choice(values) 5   choice also works for one item from a not-continuous sample:  >>> values = [1, 2, 3, 5, 7, 10] >>> random.choice(values) 7   If you need it \"cryptographically strong\" there's also a secrets.choice in python 3.6 and newer:  >>> import secrets >>> values = list(range(10)) >>> secrets.choice(values) 2      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "8", "A_Content": "  if you want to use numpy then use the following:  import numpy as np print(np.random.randint(0,10))      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "6", "A_Content": "  The original question implies generating multiple random integers.     How can I generate integers between 0 and 9 (inclusive) in Python?   Many responses however only show how to get one random number, e.g. random.randint and random.choice.    Multiple Random Integers  For clarity, you can still generate multiple random numbers using those techniques by simply iterating N times:  import random   N = 5  [random.randint(0, 9) for _ in range(N)] # [9, 7, 0, 7, 3]  [random.choice(range(10)) for _ in range(N)] # [8, 3, 6, 8, 7]   Sample of Random Integers  Some posts demonstrate how to natively generate multiple random integers.1  Here are some options that address the implied question:  random.sample returns k unique selections from a population (without replacement):2  random.sample(range(10), k=N) # [4, 5, 1, 2, 3]   In Python 3.6, random.choices returns k selections from a population (with replacement):  random.choices(range(10), k=N) # [3, 2, 0, 8, 2]   See also this related post using numpy.random.choice.  1Namely @John Lawrence Aspden, @S T Mohammed, @SiddTheKid, @user14372, @zangw, et al.  2@prashanth mentions this module showing one integer.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "5", "A_Content": "  >>> import random >>> random.randrange(10) 3 >>> random.randrange(10) 1   To get a list of ten samples:  >>> [random.randrange(10) for x in range(10)] [9, 0, 4, 0, 5, 7, 4, 3, 6, 8]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "3", "A_Content": "  random.sample is another that can be used  import random n = 1 # specify the no. of numbers num = random.sample(range(10),  n) num[0] # is the required number      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "3", "A_Content": "  Best way is to use import Random function    import random print(random.sample(range(10), 10))   or without any library import:  n={}  for i in range(10):     n[i]=i  for p in range(10):     print(n.popitem()[1])   here the popitems removes and returns an arbitrary value from the dictionary n.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "1", "A_Content": "  Generating random integers between 0 and 9.  import numpy X = numpy.random.randint(0, 10, size=10) print(X)   Output:  [4 8 0 4 9 6 9 9 0 7]      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "0", "A_Content": "  I used variable to control the range  from random import randint  numberStartRange = 1 numberEndRange = 9 randomNumber = randint(numberStartRange, numberEndRange) print(randomNumber)   I used the print function to see the results. You can comment is out if you do not need this.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9", "Language": "Python", "Q_Title": "Generate random integers between 0 and 9", "Q_Votes": "918", "Q_Content": "    How can I generate random integers between 0 and 9 (inclusive) in Python?  i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9     ", "Tags": ["python", "random", "integer"], "A_Votes": "-2", "A_Content": "  I had better luck with this for Python 3.6    str_Key = \"\"                                                                                                 str_RandomKey = \"\"                                                                                           for int_I in range(128):                                                                                           str_Key = random.choice('0123456789')       str_RandomKey = str_RandomKey + str_Key    Just add characters like 'ABCD' and 'abcd' or '^!~=-><' to alter the character pool to pull from, change the range to alter the number of characters generated.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "721", "A_Content": "   \"What are the largest sites built on Django today?\"  There isn't any single place that collects information about traffic on Django built sites, so I'll have to take a stab at it using data from various locations.  First, we have a list of Django sites on the front page of the main Django project page and then a list of Django built sites at djangosites.org.  Going through the lists and picking some that I know have decent traffic we see:   Instagram: What Powers Instagram: Hundreds of Instances, Dozens of Technologies. Pinterest: Alexa rank 37 (21.4.2015) and 70 Million users in 2013 Bitbucket: 200TB of Code and 2.500.000 Users Disqus: Serving 400 million people with Python. curse.com: 600k daily visits. tabblo.com: 44k daily visits, see Ned Batchelder's posts Infrastructure for modern web sites. chesspark.com: Alexa rank about 179k. pownce.com (no longer active): alexa rank about 65k. Mike Malone of Pownce, in his EuroDjangoCon presentation on Scaling Django Web Apps says \"hundreds of hits per second\".  This is a very good presentation on how to scale Django, and makes some good points including (current) shortcomings in Django scalability. HP had a site built with Django 1.5: ePrint center. However, as for novemer/2015 the entire website was migrated and this link is just a redirect. This website was a world-wide service attending subscription to Instant Ink and related services HP offered (*).  \"Can Django deal with 100,000 users daily, each visiting the site for a couple of hours?\"  Yes, see above. \"Could a site like Stack Overflow run on Django?\"  My gut feeling is yes but, as others answered and Mike Malone mentions in his presentation, database design is critical. Strong proof might also be found at www.cnprog.com if we can find any reliable traffic stats. Anyway, it's not just something that will happen by throwing together a bunch of Django models :)   There are, of course, many more sites and bloggers of interest, but I have got to stop somewhere!    Blog post about Using Django to build high-traffic site michaelmoore.com described as a top 10,000 website.  Quantcast stats and compete.com stats.    (*) The author of the edit, including such reference, used to work as outsourced developer in that project.     ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "235", "A_Content": "  We're doing load testing now.  We think we can support 240 concurrent requests (a sustained rate of 120 hits per second 24x7) without any significant degradation in the server performance.  That would be 432,000 hits per hour.  Response times aren't small (our transactions are large) but there's no degradation from our baseline performance as the load increases.  We're using Apache front-ending Django and MySQL.  The OS is Red Hat Enterprise Linux (RHEL).  64-bit.  We use mod_wsgi in daemon mode for Django.  We've done no cache or database optimization other than to accept the defaults.    We're all in one VM on a 64-bit Dell with (I think) 32Gb RAM.   Since performance is almost the same for 20 or 200 concurrent users, we don't need to spend huge amounts of time \"tweaking\".  Instead we simply need to keep our base performance up through ordinary SSL performance improvements, ordinary database design and implementation (indexing, etc.), ordinary firewall performance improvements, etc.  What we do measure is our load test laptops struggling under the insane workload of 15 processes running 16 concurrent threads of requests.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "157", "A_Content": "  Not sure about the number of daily visits but here are a few examples of large Django sites:   disqus.com (talk from djangocon) bitbucket.org (write up) lanyrd.com (source) support.mozilla.com (source code) addons.mozilla.org (source code) (talk from djangocon) theonion.com (write up) The guardian.co.uk comment system uses Django (source) instagram pinterest rdio   Screencast on how to deploy django with scaling in mind http://ontwik.com/python/django-deployment-workshop-by-jacob-kaplan-moss/  Here is a link to list of high traffic Django sites on Quora.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "94", "A_Content": "     What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic)   In the US, Mahalo. I'm told they handle roughly 10 million uniques a month.   Abroad, the Globo network (a network of news, sports, and entertainment sites in Brazil); Alexa ranks them in to top 100 globally (around 80th currently).  Other notable Django users include PBS, National Geographic, Discovery, NASA (actually a number of different divisions within NASA), and the Library of Congress.     Can Django deal with 100k users daily, each visiting the site for a couple of hours?   Yes -- but only if you've written your application right, and if you've got enough hardware. Django's not a magic bullet.     Could a site like StackOverflow run on Django?   Yes (but see above).  Technology-wise, easily: see soclone for one attempt. Traffic-wise, compete pegs StackOverflow at under 1 million uniques per month. I can name at least dozen Django sites with more traffic than SO.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "74", "A_Content": "  Playing devil's advocate a little bit:  You should check the DjangoCon 2008 Keynote, delivered by Cal Henderson, titled \"Why I hate Django\" where he pretty much goes over everything Django is missing that you might want to do in a high traffic website. At the end of the day you have to take this all with an open mind because it is perfectly possible to write Django apps that scale, but I thought it was a good presentation and relevant to your question.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "60", "A_Content": "  Scaling Web apps is not about web frameworks or languages, is about your architecture. It's about how you handle you browser cache, your database cache, how you use non-standard persistence providers (like CouchDB), how tuned is your database and a lot of other stuff...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "45", "A_Content": "  The largest django site I know of is the Washington Post, which would certainly indicate that it can scale well.  Good design decisions probably have a bigger performance impact than anything else. Twitter is often cited as a site which embodies the performance issues with another dynamic interpreted language based web framework, Ruby on Rails - yet Twitter engineers have stated that the framework isn't as much an issue as some of the database design choices they made early on.   Django works very nicely with memcached and provides some classes for managing the cache, which is where you would resolve the majority of your performance issues. What you deliver on the wire is almost more important than your backend in reality - using a tool like yslow is critical for a high performance web application. You can always throw more hardware at your backend, but you can't change your users bandwidth.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "27", "A_Content": "  I was at the EuroDjangoCon conference the other week, and this was the subject of a couple of talks - including from the founders of what was the largest Django-based site, Pownce (slides from one talk here). The main message is that it's not Django you have to worry about, but things like proper caching, load balancing, database optimisation, etc.  Django actually has hooks for most of those things - caching, in particular, is made very easy.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "19", "A_Content": "  I'm sure you're looking for a more solid answer, but the most obvious objective validation I can think of is that Google pushes Django for use with its App Engine framework. If anybody knows about and deals with scalability on a regular basis, it's Google. From what I've read, the most limiting factor seems to be the database back-end, which is why Google uses their own...     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "14", "A_Content": "  I think we might as well add Apple's App of the year for 2011, Instagram, to the list which uses django intensively.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "12", "A_Content": "  Today we use many web apps and sites for our needs. Most of them are highly useful. I will show you some of them used by python or django.  Washington Post  The Washington Post\u2019s website is a hugely popular online news source to accompany their daily paper. Its\u2019 huge amount of views and traffic can be easily handled by the Django web framework. Washington Post - 52.2 million unique visitors (March, 2015)  NASA  The National Aeronautics and Space Administration\u2019s official website is the place to find news, pictures, and videos about their ongoing space exploration. This Django website can easily handle huge amounts of views and traffic. 2 million visitors monthly  The Guardian  The Guardian is a British news and media website owned by the Guardian Media Group. It contains nearly all of the content of the newspapers The Guardian and The Observer. This huge data is handled by Django. The Guardian (commenting system) - 41,6 million unique visitors (October, 2014)  YouTube  We all know YouTube as the place to upload cat videos and fails. As one of the most popular websites in existence, it provides us with endless hours of video entertainment. The Python programming language powers it and the features we love.  DropBox  DropBox started the online document storing revolution that has become part of daily life. We now store almost everything in the cloud. Dropbox allows us to store, sync, and share almost anything using the power of Python.  Survey Monkey  Survey Monkey is the largest online survey company. They can handle over one million responses every day on their rewritten Python website.  Quora  Quora is the number one place online to ask a question and receive answers from a community of individuals. On their Python website relevant results are answered, edited, and organized by these community members.  Bitly  A majority of the code for Bitly URL shortening services and analytics are all built with Python. Their service can handle hundreds of millions of events per day.  Reddit  Reddit is known as the front page of the internet. It is the place online to find information or entertainment based on thousands of different categories. Posts and links are user generated and are promoted to the top through votes. Many of Reddit\u2019s capabilities rely on Python for their functionality.  Hipmunk  Hipmunk is an online consumer travel site that compares the top travel sites to find you the best deals. This Python website\u2019s tools allow you to find the cheapest hotels and flights for your destination.  Click here for more:  25-of-the-most-popular-python-and-django-websites,  What-are-some-well-known-sites-running-on-Django     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "9", "A_Content": "  Yes it can. It could be Django with Python or Ruby on Rails. It will still scale.   There are few different techniques. First, caching is not scaling. You could have several application servers balanced with nginx as the front in addition to hardware balancer(s). To scale on the database side you can go pretty far with read slave in MySQL / PostgreSQL if you go the RDBMS way.  Some good examples of heavy traffic websites in Django could be:   Pownce when they were still there. Discus (generic shared comments manager) All the newspaper related websites: Washington Post and others.   You can feel safe.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "7", "A_Content": "  Here's a list of some relatively high-profile things built in Django:   The Guardian's \"Investigate your MP's expenses\" app Politifact.com (here's a Blog post talking about the (positive) experience. Site won a Pulitzer. NY Times' Represent app EveryBlock Peter Harkins, one of the programmers over at WaPo, lists all the stuff they\u2019ve built with Django on his blog It's a little old, but someone from the LA Times gave a basic overview of why they went with Django. The Onion's AV Club was recently moved from (I think Drupal) to Django.   I imagine a number of these these sites probably gets well over 100k+ hits per day. Django can certainly do 100k hits/day and more. But YMMV in getting your particular site there depending on what you're building.  There are caching options at the Django level (for example caching querysets and views in memcached can work wonders) and beyond (upstream caches like Squid). Database Server specifications will also be a factor (and usually the place to splurge), as is how well you've tuned it. Don't assume, for example, that Django's going set up indexes properly. Don't assume that the default PostgreSQL or MySQL configuration is the right one.  Furthermore, you always have the option of having multiple application servers running Django if that is the slow point, with a software or hardware load balancer in front.  Finally, are you serving static content on the same server as Django? Are you using Apache or something like nginx or lighttpd? Can you afford to use a CDN for static content? These are things to think about, but it's all very speculative. 100k hits/day isn't the only variable: how much do you want to spend? How much expertise do you have managing all these components? How much time do you have to pull it all together?     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "7", "A_Content": "  As stated in High Performance   Django Book  and Go through this Cal Henderson   See further details as mentioned below:  It\u2019s not uncommon to hear people say \u201cDjango doesn\u2019t scale\u201d. Depending on how you look at it, the statement is either completely true or patently false. Django, on its own, doesn\u2019t scale.  The same can be said of Ruby on Rails, Flask, PHP, or any other language used by a database-driven dynamic website.  The good news, however, is that Django interacts beautifully with a suite of caching and load balancing tools that will allow it to scale to as much traffic as you can throw at it.  Contrary to what you may have read online,  it can do so without replacing core components often labeled as \u201ctoo slow\u201d such as the database ORM or the template layer.  Disqus serves over 8 billion page views per month. Those are some huge numbers.   These teams have proven Django most certainly does scale.  Our experience here at Lincoln Loop backs it up.  We\u2019ve built big Django sites capable of spending the day on the Reddit homepage without breaking a sweat.  Django\u2019s scaling success stories are almost too numerous to list at this point.  It backs Disqus, Instagram, and Pinterest. Want some more proof? Instagram was able to sustain over 30 million users on Django with only 3 engineers (2 of which had no back-end development     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1319615/proper-way-to-declare-custom-exceptions-in-modern-python", "Language": "Python", "Q_Title": "Proper way to declare custom exceptions in modern Python?", "Q_Votes": "921", "Q_Content": "    What's the proper way to declare custom exception classes in modern Python? My primary goal is to follow whatever standard other exception classes have, so that (for instance) any extra string I include in the exception is printed out by whatever tool caught the exception.  By \"modern Python\" I mean something that will run in Python 2.5 but be 'correct' for the Python 2.6 and Python 3.* way of doing things. And by \"custom\" I mean an Exception object that can include extra data about the cause of the error: a string, maybe also some other arbitrary object relevant to the exception.  I was tripped up by the following deprecation warning in Python 2.6.2:  >>> class MyError(Exception): ...     def __init__(self, message): ...         self.message = message ...  >>> MyError(\"foo\") _sandbox.py:3: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6   It seems crazy that BaseException has a special meaning for attributes named message. I gather from PEP-352 that attribute did have a special meaning in 2.5 they're trying to deprecate away, so I guess that name (and that one alone) is now forbidden? Ugh.  I'm also fuzzily aware that Exception has some magic parameter args, but I've never known how to use it. Nor am I sure it's the right way to do things going forward; a lot of the discussion I found online suggested they were trying to do away with args in Python 3.  Update: two answers have suggested overriding __init__, and __str__/__unicode__/__repr__. That seems like a lot of typing, is it necessary?     ", "Tags": ["python", "exception"], "A_Votes": "953", "A_Content": "  Maybe I missed the question, but why not:  class MyException(Exception):     pass   Edit: to override something (or pass extra args), do this:  class ValidationError(Exception):     def __init__(self, message, errors):          # Call the base class constructor with the parameters it needs         super(ValidationError, self).__init__(message)          # Now for your custom code...         self.errors = errors   That way you could pass dict of error messages to the second param, and get to it later with e.errors    Python 3 Update: In Python 3+, you can use this slightly more compact use of super():  class ValidationError(Exception):     def __init__(self, message, errors):          # Call the base class constructor with the parameters it needs         super().__init__(message)          # Now for your custom code...         self.errors = errors      ", "isAccepted": "Yes"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "6", "A_Content": "  The developer advocate for YouTube gave a talk about scaling Python at PyCon 2012, which is also relevant to scaling Django.  YouTube has more than a billion users, and YouTube is built on Python.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "5", "A_Content": "  Note that if you're expecting 100K users per day, that are active for hours at a time (meaning max of 20K+ concurrent users), you're going to need A LOT of servers.  SO has ~15,000 registered users, and most of them are probably not active daily.  While the bulk of traffic comes from unregistered users, I'm guessing that very few of them stay on the site more than a couple minutes (i.e. they follow google search results then leave).    For that volume, expect at least 30 servers ... which is still a rather heavy 1,000 concurrent users per server.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "5", "A_Content": "  Another example is rasp.yandex.ru, Russian transport timetable service. Its attendance satisfies your requirements.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "5", "A_Content": "  I have been using Django for over a year now, and am very impressed with how it manages to combine modularity, scalability and speed of development. Like with any technology, it comes with a learning curve. However, this learning curve is made a lot less steep by the excellent documentation from the Django community. Django has been able to handle everything I have thrown at it really well. It looks like it will be able to scale well into the future.  BidRodeo Penny Auctions is a moderately sized Django powered website. It is a very dynamic website and does handle a good number of page views a day.      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "5", "A_Content": "  If you have a site with some static content, then putting a Varnish server in front will dramatically increase your performance. Even a single box can then easily spit out 100 Mbit/s of traffic.  Note that with dynamic content, using something like Varnish becomes a lot more tricky.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "4", "A_Content": "  My experience with Django is minimal but I do remember in The Django Book they have a chapter where they interview people running some of the larger Django applications.  Here is a link.  I guess it could provide some insights.  It says curse.com is one of the largest Django applications with around 60-90 million page views in a month.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "4", "A_Content": "  Even-though there have been a lot of great answers here, I just feel like pointing out, that nobody have put emphasis on..  It depends on the application   If you application is light on writes, as in you are reading a lot more data from the DB than you are writing. Then scaling django should be fairly trivial, heck, it comes with some fairly decent output/view caching straight out of the box. Make use of that, and say, redis as a cache provider, put a load balancer in front of it, spin up n-instances and you should be able to deal with a VERY large amount of traffic.  Now, if you have to do thousands of complex writes a second? Different story. Is Django going to be a bad choice? Well, not necessarily, depends on how you architect your solution really, and also, what your requirements are.  Just my two cents :-)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "4", "A_Content": "  What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Pinterest disqus.com More here https://www.shuup.com/en/blog/25-of-the-most-popular-python-and-django-websites/  Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Yes, but use proper architecture, database design, use of cache, use load balances and multiple servers/ nods  Could a site like Stack Overflow run on Django? Yes, just need to follow answer mentioned in the 2nd question     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "3", "A_Content": "  You can definitely run a high-traffic site in Django. Check out this pre-Django 1.0 but still relevant post here: http://menendez.com/blog/launching-high-performance-django-site/     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "3", "A_Content": "  Check out this micro news aggregator called EveryBlock.  It's entirely written in Django. In fact they are the people who developed the Django  framework itself.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "3", "A_Content": "  I develop high traffic sites using Django for the national broadcaster in Ireland. It works well for us. Developing a high performance site is more than about just choosing a framework. A framework will only be one part of a system that is as strong as it's weakest link. Using the latest framework 'X' won't solve your performance issues if the problem is slow database queries or a badly configured server or network.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "3", "A_Content": "  I don't think the issue is really about Django scaling.   I really suggest you look into your architecture that's what is going to help you with you scaling needs.If you get that wrong there is not point on how well Django performs. Performance != Scale. You can have a system that has amazing performance but does not scale and vice versa.  Is your application database bound? If it is then your scale issues lie there as well. How are you planning on interacting with the database from Django? What happens when you database cannot process requests as fast as Django accepts them? What happens when your data outgrows one physical machine. You need to account for how you plan on dealing with those circumstances.  Moreover, What happens when your traffic outgrows one app server? how you handle sessions in this case can be tricky, more often than not you'd probably require a shared nothing architecture. Again that depends on your application.  In short Languages is not what determines scale, a language is responsible for performance(again depending on your applications different languages perform differently). It is your design and architecture that makes scaling a reality.   I hope it helps, would be glad to help further if you have questions.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "3", "A_Content": "  If you want to use Open source then there are many options for you. But python is best among them it have many libraries and a super awesome community. These are reasons which might change your mind:   Python is very good but it is a interpreted language which makes it slow. But many accelerator and caching services are there which partly solve this problem. If you are thinking about rapid development then Ruby on Rails is best among all. The main motto of this(ROR) framework is to give a comfortable experience to the developers. If you compare Ruby and Python both have nearly same syntaxes. Google App Engine is very good service but it will bind you in its scope, you don't get chance to experiment new things. Instead of it you can use Digital Ocean cloud which will only take $5/Month charge for its simplest droplet. Heroku is another free service where you can deploy your product. Yes! Yes! What you heard is totally correct but here are some examples which are using other technologies   Rails: Github, Twitter(previously), Shopify, Airbnb, Slideshare, Heroku etc. PHP: Facebook, Wikipedia, Flickr, Yahoo, Tumbler, Mailchimp etc.    Conclusion is a framework or language won't do everything for you. A better architecture, designing and strategy will give you a scalable website. Instagram is biggest example,this small team is managing such huge data. Here is one blog about its architecture must read it.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "2", "A_Content": "  Spreading the tasks evenly, in short optimizing each and every aspect including DBs, Files, Images, CSS etc. and balancing the load with several other resources is necessary once your site/application starts growing. OR you make some more space for it to grow. Implementation of latest technologies like CDN, Cloud are must with huge sites. Just developing and tweaking an application won't give your the cent percent satisfation, other components also play an important role.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/886221/does-django-scale", "Language": "Python", "Q_Title": "Does Django scale? [closed]", "Q_Votes": "923", "Q_Content": "    I'm building a web application with Django. The reasons I chose Django were:   I wanted to work with free/open-source tools. I like Python and feel it's a \"long term\" language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn. I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python. I knew the migration to Google App Engine would be easier should I choose to do so in the future. I heard Django was \"nice\".   Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).  My questions:   What's the \"largest\" site that's built on Django today? (I measure size mostly by user traffic) Can Django deal with 100,000 users daily, each visiting the site for a couple of hours? Could a site like Stack Overflow run on Django?      ", "Tags": ["python", "django", "web-applications", "scalability"], "A_Votes": "2", "A_Content": "  The problem is not to know if django can scale or not.   The right way is to understand and know which are the network design patterns and tools to put under your django/symfony/rails project to scale well.  Some ideas can be :   Multiplexing. Inversed proxy. Ex : Nginx, Varnish Memcache Session. Ex : Redis Clusterization on your project and db for load balancing and fault tolerance : Ex : Docker Use third party to store assets. Ex : Amazon S3   Hope it help a bit. This is my tiny rock to the mountain.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1319615/proper-way-to-declare-custom-exceptions-in-modern-python", "Language": "Python", "Q_Title": "Proper way to declare custom exceptions in modern Python?", "Q_Votes": "921", "Q_Content": "    What's the proper way to declare custom exception classes in modern Python? My primary goal is to follow whatever standard other exception classes have, so that (for instance) any extra string I include in the exception is printed out by whatever tool caught the exception.  By \"modern Python\" I mean something that will run in Python 2.5 but be 'correct' for the Python 2.6 and Python 3.* way of doing things. And by \"custom\" I mean an Exception object that can include extra data about the cause of the error: a string, maybe also some other arbitrary object relevant to the exception.  I was tripped up by the following deprecation warning in Python 2.6.2:  >>> class MyError(Exception): ...     def __init__(self, message): ...         self.message = message ...  >>> MyError(\"foo\") _sandbox.py:3: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6   It seems crazy that BaseException has a special meaning for attributes named message. I gather from PEP-352 that attribute did have a special meaning in 2.5 they're trying to deprecate away, so I guess that name (and that one alone) is now forbidden? Ugh.  I'm also fuzzily aware that Exception has some magic parameter args, but I've never known how to use it. Nor am I sure it's the right way to do things going forward; a lot of the discussion I found online suggested they were trying to do away with args in Python 3.  Update: two answers have suggested overriding __init__, and __str__/__unicode__/__repr__. That seems like a lot of typing, is it necessary?     ", "Tags": ["python", "exception"], "A_Votes": "366", "A_Content": "  With modern Python Exceptions, you don't need to abuse .message, or override .__str__() or .__repr__() or any of it. If all you want is an informative message when your exception is raised, do this:  class MyException(Exception):     pass  raise MyException(\"My hovercraft is full of eels\")   That will give a traceback ending with MyException: My hovercraft is full of eels.  If you want more flexibility from the exception, you could pass a dictionary as the argument:  raise MyException({\"message\":\"My hovercraft is full of animals\", \"animal\":\"eels\"})   However, to get at those details in an except block is a bit more complicated. The details are stored in the args attribute, which is a list. You would need to do something like this:  try:     raise MyException({\"message\":\"My hovercraft is full of animals\", \"animal\":\"eels\"}) except MyException as e:     details = e.args[0]     print(details[\"animal\"])   It is still possible to pass in multiple items to the exception and access them via tuple indexes, but this is highly discouraged (and was even intended for deprecation a while back). If you do need more than a single piece of information and the above method is not sufficient for you, then you should subclass Exception as described in the tutorial.  class MyError(Exception):     def __init__(self, message, animal):         self.message = message         self.animal = animal     def __str__(self):         return self.message      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1319615/proper-way-to-declare-custom-exceptions-in-modern-python", "Language": "Python", "Q_Title": "Proper way to declare custom exceptions in modern Python?", "Q_Votes": "921", "Q_Content": "    What's the proper way to declare custom exception classes in modern Python? My primary goal is to follow whatever standard other exception classes have, so that (for instance) any extra string I include in the exception is printed out by whatever tool caught the exception.  By \"modern Python\" I mean something that will run in Python 2.5 but be 'correct' for the Python 2.6 and Python 3.* way of doing things. And by \"custom\" I mean an Exception object that can include extra data about the cause of the error: a string, maybe also some other arbitrary object relevant to the exception.  I was tripped up by the following deprecation warning in Python 2.6.2:  >>> class MyError(Exception): ...     def __init__(self, message): ...         self.message = message ...  >>> MyError(\"foo\") _sandbox.py:3: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6   It seems crazy that BaseException has a special meaning for attributes named message. I gather from PEP-352 that attribute did have a special meaning in 2.5 they're trying to deprecate away, so I guess that name (and that one alone) is now forbidden? Ugh.  I'm also fuzzily aware that Exception has some magic parameter args, but I've never known how to use it. Nor am I sure it's the right way to do things going forward; a lot of the discussion I found online suggested they were trying to do away with args in Python 3.  Update: two answers have suggested overriding __init__, and __str__/__unicode__/__repr__. That seems like a lot of typing, is it necessary?     ", "Tags": ["python", "exception"], "A_Votes": "155", "A_Content": "     \"Proper way to declare custom exceptions in modern Python?\"   This is fine, unless your exception is really a type of a more specific exception:  class MyException(Exception):     pass   Or better (maybe perfect), instead of pass give a docstring:  class MyException(Exception):     \"\"\"Raise for my specific kind of exception\"\"\"   Subclassing Exception Subclasses  From the docs     Exception      All built-in, non-system-exiting exceptions are derived from this class.    All user-defined exceptions should also be derived from this   class.   That means that if your exception is a type of a more specific exception, subclass that exception instead of the generic Exception (and the result will be that you still derive from Exception as the docs recommend). Also, you can at least provide a docstring (and not be forced to use the pass keyword):  class MyAppValueError(ValueError):     '''Raise when my specific value is wrong'''   Set attributes you create yourself with a custom __init__. Avoid passing a dict as a positional argument, future users of your code will thank you. If you use the deprecated message attribute, assigning it yourself will avoid a DeprecationWarning:  class MyAppValueError(ValueError):     '''Raise when a specific subset of values in context of app is wrong'''     def __init__(self, message, foo, *args):         self.message = message # without this you may get DeprecationWarning         # Special attribute you desire with your Error,          # perhaps the value that caused the error?:         self.foo = foo                  # allow users initialize misc. arguments as any other builtin Error         super(MyAppValueError, self).__init__(message, foo, *args)    There's really no need to write your own __str__ or __repr__. The builtin ones are very nice, and your cooperative inheritance ensures that you use it.  Critique of the top answer     Maybe I missed the question, but why not:   class MyException(Exception):     pass   Again, the problem with the above is that in order to catch it, you'll either have to name it specifically (importing it if created elsewhere) or catch Exception, (but you're probably not prepared to handle all types of Exceptions, and you should only catch exceptions you are prepared to handle). Similar criticism to the below, but additionally that's not the way to initialize via super, and you'll get a DeprecationWarning if you access the message attribute:     Edit: to override something (or pass extra args), do this:   class ValidationError(Exception):     def __init__(self, message, errors):          # Call the base class constructor with the parameters it needs         super(ValidationError, self).__init__(message)          # Now for your custom code...         self.errors = errors      That way you could pass dict of error messages to the second param, and get to it later with e.errors   It also requires exactly two arguments to be passed in (aside from the self.) No more, no less. That's an interesting constraint that future users may not appreciate.   To be direct - it violates Liskov substitutability.  I'll demonstrate both errors:  >>> ValidationError('foo', 'bar', 'baz').message  Traceback (most recent call last):   File \"<pyshell#10>\", line 1, in <module>     ValidationError('foo', 'bar', 'baz').message TypeError: __init__() takes exactly 3 arguments (4 given)  >>> ValidationError('foo', 'bar').message __main__:1: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6 'foo'   Compared to:   >>> MyAppValueError('foo', 'FOO', 'bar').message 'foo'      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1319615/proper-way-to-declare-custom-exceptions-in-modern-python", "Language": "Python", "Q_Title": "Proper way to declare custom exceptions in modern Python?", "Q_Votes": "921", "Q_Content": "    What's the proper way to declare custom exception classes in modern Python? My primary goal is to follow whatever standard other exception classes have, so that (for instance) any extra string I include in the exception is printed out by whatever tool caught the exception.  By \"modern Python\" I mean something that will run in Python 2.5 but be 'correct' for the Python 2.6 and Python 3.* way of doing things. And by \"custom\" I mean an Exception object that can include extra data about the cause of the error: a string, maybe also some other arbitrary object relevant to the exception.  I was tripped up by the following deprecation warning in Python 2.6.2:  >>> class MyError(Exception): ...     def __init__(self, message): ...         self.message = message ...  >>> MyError(\"foo\") _sandbox.py:3: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6   It seems crazy that BaseException has a special meaning for attributes named message. I gather from PEP-352 that attribute did have a special meaning in 2.5 they're trying to deprecate away, so I guess that name (and that one alone) is now forbidden? Ugh.  I'm also fuzzily aware that Exception has some magic parameter args, but I've never known how to use it. Nor am I sure it's the right way to do things going forward; a lot of the discussion I found online suggested they were trying to do away with args in Python 3.  Update: two answers have suggested overriding __init__, and __str__/__unicode__/__repr__. That seems like a lot of typing, is it necessary?     ", "Tags": ["python", "exception"], "A_Votes": "41", "A_Content": "  see how exceptions work by default if one vs more attributes are used (tracebacks omitted):  >>> raise Exception('bad thing happened') Exception: bad thing happened  >>> raise Exception('bad thing happened', 'code is broken') Exception: ('bad thing happened', 'code is broken')   so you might want to have a sort of \"exception template\", working as an exception itself, in a compatible way:  >>> nastyerr = NastyError('bad thing happened') >>> raise nastyerr NastyError: bad thing happened  >>> raise nastyerr() NastyError: bad thing happened  >>> raise nastyerr('code is broken') NastyError: ('bad thing happened', 'code is broken')   this can be done easily with this subclass  class ExceptionTemplate(Exception):     def __call__(self, *args):         return self.__class__(*(self.args + args)) # ... class NastyError(ExceptionTemplate): pass   and if you don't like that default tuple-like representation, just add __str__ method to the ExceptionTemplate class, like:      # ...     def __str__(self):         return ': '.join(self.args)   and you'll have  >>> raise nastyerr('code is broken') NastyError: bad thing happened: code is broken      ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1319615/proper-way-to-declare-custom-exceptions-in-modern-python", "Language": "Python", "Q_Title": "Proper way to declare custom exceptions in modern Python?", "Q_Votes": "921", "Q_Content": "    What's the proper way to declare custom exception classes in modern Python? My primary goal is to follow whatever standard other exception classes have, so that (for instance) any extra string I include in the exception is printed out by whatever tool caught the exception.  By \"modern Python\" I mean something that will run in Python 2.5 but be 'correct' for the Python 2.6 and Python 3.* way of doing things. And by \"custom\" I mean an Exception object that can include extra data about the cause of the error: a string, maybe also some other arbitrary object relevant to the exception.  I was tripped up by the following deprecation warning in Python 2.6.2:  >>> class MyError(Exception): ...     def __init__(self, message): ...         self.message = message ...  >>> MyError(\"foo\") _sandbox.py:3: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6   It seems crazy that BaseException has a special meaning for attributes named message. I gather from PEP-352 that attribute did have a special meaning in 2.5 they're trying to deprecate away, so I guess that name (and that one alone) is now forbidden? Ugh.  I'm also fuzzily aware that Exception has some magic parameter args, but I've never known how to use it. Nor am I sure it's the right way to do things going forward; a lot of the discussion I found online suggested they were trying to do away with args in Python 3.  Update: two answers have suggested overriding __init__, and __str__/__unicode__/__repr__. That seems like a lot of typing, is it necessary?     ", "Tags": ["python", "exception"], "A_Votes": "15", "A_Content": "  You should override __repr__ or __unicode__ methods instead of using message, the args you provide when you construct the exception will be in the args attribute of the exception object.     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1319615/proper-way-to-declare-custom-exceptions-in-modern-python", "Language": "Python", "Q_Title": "Proper way to declare custom exceptions in modern Python?", "Q_Votes": "921", "Q_Content": "    What's the proper way to declare custom exception classes in modern Python? My primary goal is to follow whatever standard other exception classes have, so that (for instance) any extra string I include in the exception is printed out by whatever tool caught the exception.  By \"modern Python\" I mean something that will run in Python 2.5 but be 'correct' for the Python 2.6 and Python 3.* way of doing things. And by \"custom\" I mean an Exception object that can include extra data about the cause of the error: a string, maybe also some other arbitrary object relevant to the exception.  I was tripped up by the following deprecation warning in Python 2.6.2:  >>> class MyError(Exception): ...     def __init__(self, message): ...         self.message = message ...  >>> MyError(\"foo\") _sandbox.py:3: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6   It seems crazy that BaseException has a special meaning for attributes named message. I gather from PEP-352 that attribute did have a special meaning in 2.5 they're trying to deprecate away, so I guess that name (and that one alone) is now forbidden? Ugh.  I'm also fuzzily aware that Exception has some magic parameter args, but I've never known how to use it. Nor am I sure it's the right way to do things going forward; a lot of the discussion I found online suggested they were trying to do away with args in Python 3.  Update: two answers have suggested overriding __init__, and __str__/__unicode__/__repr__. That seems like a lot of typing, is it necessary?     ", "Tags": ["python", "exception"], "A_Votes": "6", "A_Content": "  No, \"message\" is not forbidden. It's just deprecated. You application will work fine with using message. But you may want to get rid of the deprecation error, of course.  When you create custom Exception classes for your application, many of them do not subclass just from Exception, but from others, like ValueError or similar. Then you have to adapt to their usage of variables.  And if you have many exceptions in your application it's usually a good idea to have a common custom base class for all of them, so that users of your modules can do  try:     ... except NelsonsExceptions:     ...   And in that case you can do the __init__ and __str__ needed there, so you don't have to repeat it for every exception. But simply calling the message variable something else than message does the trick.  In any case, you only need the __init__ or __str__ if you do something different from what Exception itself does. And because if the deprecation, you then need both, or you get an error. That's not a whole lot of extra code you need per class. ;)     ", "isAccepted": "No"},
{"URL": "https://stackoverflow.com/questions/1319615/proper-way-to-declare-custom-exceptions-in-modern-python", "Language": "Python", "Q_Title": "Proper way to declare custom exceptions in modern Python?", "Q_Votes": "921", "Q_Content": "    What's the proper way to declare custom exception classes in modern Python? My primary goal is to follow whatever standard other exception classes have, so that (for instance) any extra string I include in the exception is printed out by whatever tool caught the exception.  By \"modern Python\" I mean something that will run in Python 2.5 but be 'correct' for the Python 2.6 and Python 3.* way of doing things. And by \"custom\" I mean an Exception object that can include extra data about the cause of the error: a string, maybe also some other arbitrary object relevant to the exception.  I was tripped up by the following deprecation warning in Python 2.6.2:  >>> class MyError(Exception): ...     def __init__(self, message): ...         self.message = message ...  >>> MyError(\"foo\") _sandbox.py:3: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6   It seems crazy that BaseException has a special meaning for attributes named message. I gather from PEP-352 that attribute did have a special meaning in 2.5 they're trying to deprecate away, so I guess that name (and that one alone) is now forbidden? Ugh.  I'm also fuzzily aware that Exception has some magic parameter args, but I've never known how to use it. Nor am I sure it's the right way to do things going forward; a lot of the discussion I found online suggested they were trying to do away with args in Python 3.  Update: two answers have suggested overriding __init__, and __str__/__unicode__/__repr__. That seems like a lot of typing, is it necessary?     ", "Tags": ["python", "exception"], "A_Votes": "-1", "A_Content": "  Try this Example  class InvalidInputError(Exception):     def __init__(self, msg):         self.msg = msg     def __str__(self):         return repr(self.msg)  inp = int(input(\"Enter a number between 1 to 10:\")) try:     if type(inp) != int or inp not in list(range(1,11)):         raise InvalidInputError except InvalidInputError:     print(\"Invalid input entered\")      ", "isAccepted": "No"}
]